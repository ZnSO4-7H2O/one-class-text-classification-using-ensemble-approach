{"title": "AutoMOS: Learning a non-intrusive assessor of naturalness-of-speech", "tag": ["cs.CL", "cs.LG", "stat.ML"], "abstract": "Developers of text-to-speech synthesizers (TTS) often make use of human raters to assess the quality of synthesized speech. We demonstrate that we can model human raters' mean opinion scores (MOS) of synthesized speech using a deep recurrent neural network whose inputs consist solely of a raw waveform. Our best models provide utterance-level estimates of MOS only moderately inferior to sampled human ratings, as shown by Pearson and Spearman correlations. When multiple utterances are scored and averaged, a scenario common in synthesizer quality assessment, AutoMOS achieves correlations approaching those of human raters. The AutoMOS model has a number of applications, such as the ability to explore the parameter space of a speech synthesizer without requiring a human-in-the-loop.", "text": "developers text-to-speech synthesizers often make human raters assess quality synthesized speech. demonstrate model human raters’ mean opinion scores synthesized speech using deep recurrent neural network whose inputs consist solely waveform. best models provide utterance-level estimates moderately inferior sampled human ratings shown pearson spearman correlations. multiple utterances scored averaged scenario common synthesizer quality assessment automos achieves correlations approaching human raters. automos model number applications ability explore parameter space speech synthesizer without requiring human-in-the-loop. evaluate changes text-to-speech synthesizers human raters often employed assess synthesized speech. multiple human ratings audio sample contribute mean opinion score crowdsourced speciﬁc attention rater quality crowdsourcing introduces degree parallelism rating process still relatively costly time-consuming obtain quality testing. numerous systems produced algorithmically produce objective assessments audio quality approximating subjective human assessment including assess speech quality. example pesq polqa target particular space. intrusive assessors assume presence undistorted reference signal facilitate comparisons deriving ratings something exist case synthesized speech tts. nonintrusive assessments anique lcqa proposed evaluate speech quality reference signal available. much research quality assessment targeted telephony emphasis detecting distortions artifacts introduced lossy compression transmission. throughout work synthesizer constitutes snapshot evolving implementation unit selection synthesis algorithm continually growing corpus recorded audio combined speciﬁc synthesis/cost parameters. partition aggregate data synthesizer take utterances given synthesizer allocate masse single training evaluation fold single aggregate metric e.g. synthesizer-level mean mos. authors used human ratings improve correlation unit selection cost. similarly explore means tuning cost functions incorporate subjective preferences. works consider direct optimization synthesizer function synthesizer parameters prior unpublished work trained similar models found could exceed spearman rank correlation true estimated synthesizer mos. however modiﬁcations parameter semantics engine internals render mapping invalid. desirable learn synthesizer assessment operates independently engine internals directly assessing pools waveforms. demonstrate deep recurrent networks model naturalness-of-speech ratings produced human raters synthesizer evaluation using audio waveform input. explore variety deep recurrent architectures incorporate long-term time dependencies. tuned automos model achieves spearman rank correlation ranking different synthesizers. evaluating calibration automos multiple utterances similar predicted ﬁve-fold median correlations competitive sampled human ratings even quantize predicted utterance increments human rater scale. results open door scalable automated tuning continuous quality monitoring engines. audio data varying length example either directly pooling across time dimension recurrent neural networks suggested. encode intuition valuable information exists relatively large time-scales explore family models. particular test family models layer fully-connected layers atop timepooled outputs stack recurrent long short-term memory cells. timeseries input lstm either log-mel spectrogram time-pooled convolution case waveform. consider addition single frame velocity acceleration components timeseries. ﬁnal lstm layer’s outputs max-pooled across time inputs fully-connected hidden layers compute ﬁnal regression values. explored means inducing learning across longer timeframes found performance comparable simpler stacked single-layer lstm. max-pooling non-ﬁnal lstm layers’ outputs adding skip connections ﬁnal hidden layers found improve performance. explore multiple modes predicting training input waveforms predict sufﬁcient statistics train log-likelihood individual human ratings under gaussian predict train utterance-level loss ostrue) predict logits train cross-entropy true -category distribution human ratings cat) per-utterance. train separate outputs learned embedding ground-truth synthesizer providing regularization gradients training process. embeddings initialized randomly; embedding prediction thereof receive gradient training step. best performing model illustrated figure learning rate; decay steps regularization loss strategy synthesizer regression embedding timeseries type timeseries width timeseries -step derivatives lstm layer width; depth lstm timestep stride non-th layers lstm layers feeding hidden layer inputs post-lstm hidden layer width; depth models trained adagrad batches examples asynchronously across workers. ﬁve-fold cross-validation evaluate best found hyperparameters utterances given synthesizer appearing exclusively single fold. data corpus naturalness scores acquired multiple years across multiple instances quality testing google’s engines. tests iterations single english voice used across multiple products. raters scored utterance given -point likert scale naturalness half-point increments. partition training data holdout data utterances given synthesizer partition. data includes ratings across utterances generated synthesizers. utterance quantity synthesizer varies hyperparameter tuning used google cloud’s hypertune explore hyperparameters shown table top-performing tuning runs used cross-entropy categorical training mode. conﬁgurations found eval-set pearson correlations utterance-level predicted true ranging training steps. constrained search space models using convolution+pooling based timeseries found weaker best eval-set correlations around could indicate little value sample-level details dealing synthesized speech could signal insufﬁcient training data. reported gammatone-like learned ﬁlter banks speaker-independent covers much wider range voices observe similar emergent ﬁlters random initialization. initialization gammatone ﬁlters yielded nominal improvements performance relative simple loss true observed little beneﬁt training gaussian predictor individual ratings. estimated variance typically higher true sample variance given utterance. using simpler loss true provided faster training convergence allowing wider variety structural changes. treating predictions categorical using cross-entropy loss slightly outperformed construction tuning runs categorical form gives automos weights hence greater capacity near output layer. evaluation simple baselines comparison consider bias-only model always predicts mean observed utterances’ small nonlinear model takes utterance length input intuition longer utterance includes opportunities make mistakes deemed unnatural. draw human rating utterance show comparison \"sample human rating\" column. errors unbiased increased sample size reduce error. sort utterances predicted evaluate correlations egroup egroup groupings utterances adjacent predicted similar fashion calibration plot. show plots figure figure left calibration plots green represents perfect calibration; blue plots within windows along x-axis. right samples score-over-time animations. visit goo.gl/cnqbsn view. well rank synthesizers relative another? perform evaluation ﬁve-fold cross validation predict utterance using automos instance held-out. average synthesizer-level giving total esynth esynth pairs upon evaluate. results shown table automos tends avoid very-high very-low predictions likely reﬂecting distribution training data. also seems learn patterns data around certain common \"types\" utterances usually achieve high it’s possible different distributions texts synthesizer could yield easily predictable differences synthesizer-mos. future improvement would predicting text evaluating advantage utterance relative baseline. naturalness predictable unit selection costs; here want remove predictive baseline text. begun tuning engine using automos. subsequent human evaluations provide concrete results model evaluation criteria we’ve selected. similarly experiment system continuous quality testing large-scale deployment. possible leverage automos stratiﬁed sampling utterances send human raters. would allow raters focus energy evenly across quality spectrum. probe what’s learned explored artiﬁcial truncation figure methods like layerwise relevance propagation activation difference propagation shown promise image models could interesting apply unit selection cost function. references alías formiga llora efﬁcient reliable perceptual weight tuning unitselection text-to-speech synthesis based active interactive genetic algorithms proof-of-concept. speech communication binder bach montavon müller k.-r. samek layer-wise relevance propagation deep neural network architectures. information science applications pages springer. hoshen weiss wilson speech acoustic modeling multichannel waveforms. ieee international conference acoustics speech signal processing pages ieee. kubichek mel-cepstral distance measure objective speech quality assessment. communications computers signal processing ieee paciﬁc conference volume pages ieee. beerends hollier hekstra perceptual evaluation speech quality method speech quality assessment telephone networks codecs. acoustics speech signal processing proceedings.. ieee international conference volume pages ieee.", "year": 2016}