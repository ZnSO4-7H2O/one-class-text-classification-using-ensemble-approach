{"title": "Learning Causal Graphs with Small Interventions", "tag": ["cs.AI", "cs.IT", "cs.LG", "math.IT", "stat.ML"], "abstract": "We consider the problem of learning causal networks with interventions, when each intervention is limited in size under Pearl's Structural Equation Model with independent errors (SEM-IE). The objective is to minimize the number of experiments to discover the causal directions of all the edges in a causal graph. Previous work has focused on the use of separating systems for complete graphs for this task. We prove that any deterministic adaptive algorithm needs to be a separating system in order to learn complete graphs in the worst case. In addition, we present a novel separating system construction, whose size is close to optimal and is arguably simpler than previous work in combinatorics. We also develop a novel information theoretic lower bound on the number of interventions that applies in full generality, including for randomized adaptive learning algorithms.  For general chordal graphs, we derive worst case lower bounds on the number of interventions. Building on observations about induced trees, we give a new deterministic adaptive algorithm to learn directions on any chordal skeleton completely. In the worst case, our achievable scheme is an $\\alpha$-approximation algorithm where $\\alpha$ is the independence number of the graph. We also show that there exist graph classes for which the sufficient number of experiments is close to the lower bound. In the other extreme, there are graph classes for which the required number of experiments is multiplicatively $\\alpha$ away from our lower bound.  In simulations, our algorithm almost always performs very close to the lower bound, while the approach based on separating systems for complete graphs is significantly worse for random chordal graphs.", "text": "consider problem learning causal networks interventions intervention limited size pearl’s structural equation model independent errors objective minimize number experiments discover causal directions edges causal graph. previous work focused separating systems complete graphs task. prove deterministic adaptive algorithm needs separating system order learn complete graphs worst case. addition present novel separating system construction whose size close optimal arguably simpler previous work combinatorics. also develop novel information theoretic lower bound number interventions applies full generality including randomized adaptive learning algorithms. general chordal graphs derive worst case lower bounds number interventions. building observations induced trees give deterministic adaptive algorithm learn directions chordal skeleton completely. worst case achievable scheme α-approximation algorithm independence number graph. also show exist graph classes sufﬁcient number experiments close lower bound. extreme graph classes required number experiments multiplicatively away lower bound. causality fundamental concept sciences philosophy. mathematical formulation theory causality probabilistic sense received signiﬁcant attention recently formulation advocated pearl considers structural equation models framework cause written deterministic function latent random variable given causally related variables possible infer whether causes causes random samples unless certain assumptions made distribution and/or random variables directed acyclic graphs common tool used representing causal relations. given directed edge shows cause make assumptions data generating process standard inferring causal directions performing experiments so-called interventions. intervention requires modifying process generates random variables experimenter enforce values random variables. process different conditioning explained detail natural problem consider therefore minimizing number interventions required learn causal dag. hauser developed efﬁcient algorithm minimizes number worst case. algorithm based optimal coloring chordal graphs requires interventions learn causal graph chromatic number chordal skeleton. however important open problem appears also considers size used interventions intervention experiment scientist must force variables take random values. unfortunately interventions obtained involve variables. simultaneous enforcing many variables paper consider problem learning causal graph intervention sizes bounded parameter ﬁrst work aware problem eberhardt provided achievable scheme. furthermore shows interventions fully identify causal must satisfy speciﬁc combinatorial conditions called separating system intervention size constrained assumption holds true intervention size hyttinen draw connections causality known separating system constructions. open problem learning algorithm adaptive intervention separating system still needed better? believed adaptivity help worst case still needs separating system. contributions obtain several novel results learning causal graphs interventions bounded size problem separated special case underlying undirected graph complete graph general case underlying undirected graph chordal. complete graph skeletons show adaptive deterministic algorithm needs separating system. implies lower bounds separating systems also hold adaptive algorithms resolves previously mentioned open problem. extend lower bound adaptive algorithms general chordal graphs. show orientations number experiments separating system needed chromatic number skeleton graph. exploit structural properties chordal graphs design deterministic adaptive algorithm uses idea separating systems together adaptability meek rules. simulate algorithm empirically observe performs quite close separating system. algorithm requires much fewer interventions compared separating systems. causal directed acyclic graph random variables directed edge direct cause adopt pearl’s structural equation model independent errors work details). variables cause random variable independent variables. causal relations imply conditional independence relations variables. conditional independence relation following form given conditionally independent disjoint subsets variables this causal dags also called causal bayesian networks. variables bayesian respect joint probability distribution factorized product marginals every variable conditioned parents. relations learned statistically observations also inferred bayesian network using graphical criterion called d-separation assuming distribution faithful graph causal dags said markov equivalent encode cis. causal dags markov separating system matrix distinct columns ones. given bayesian network relation implied d-separation holds true. implied distribution found using dseparation distribution faithful. faithfulness widely accepted assumption since known measure zero distributions faithful equivalent skeleton immoralities. class causal dags encode called markov equivalence class. denote markov equivalence class graph union dags called essential graph denoted always chain graph chordal chain components d-separation criterion used identify skeleton immoralities underlying causal additional edges identiﬁed using fact underlying acyclic immoralities. meek derived local rules introduced recursively applied identify every additional edge repeated application meek rules partially directed graph identiﬁed immoralities longer used yields essential graph. given variables intervention variables experiment performer forces variable take value another independent variable i.e. operation affects joint distribution formalized operator pearl intervention modiﬁes causal follows post intervention d{s} obtained removing connections nodes parents. size intervention number intervened variables i.e. |s|. denote complement orientations edges original inferred. then local meek rules repeatedly applied original directions learnt learn till directed edges identiﬁed. application ci-based algorithms reveal information. meek rules given below oriented s.t. oriented s.t. oriented s.t. oriented s.t. concepts essential graphs markov equivalence classes extended incorporate role interventions interventions process followed intervention. interventional markov equivalence class dags represent probability distributions obtained process applied every intervention denoted similar observational case essential graph graph union dags equivalence class; denoted following sequence therefore interventions performed essential graph graph oriented edges captures causal relations discovered using interventions happened captures initially known causal directions. known chain graph chordal chain components. therefore directed edges removed graph becomes disjoint chordal graphs. skeleton undirected graph obtained directed edges converted undirected edges. induced subgraph immorality disconnected graph union dags skeleton partially directed graph undirected edges different directions directed edges directed question design algorithm computes small interventions given note course unknown directions edges available algorithm. view design active learning process essential graph chain graph undirected chordal components known interventions chain components affect discovery process directed edges components assume undirected chordal graph start with. notion algorithm consider time complexity steps given interventions consider efﬁciently computing using graph e{i...im}. consider following three classes algorithms non-adaptive algorithm choice ﬁxed prior discovery process. adaptive algorithm every step choice deterministic function e{i...im}. randomized adaptive algorithm every step choice random function e{i...im}. problem different complete graphs versus general chordal graphs since rule becomes applicable graph complete. thus give separate treatment case. first provide algorithms three cases learning directions complete graphs vertices. then generalize chordal graph skeletons provide novel adaptive algorithm upper lower bounds performance. section consider case skeleton start with i.e. undirected complete graph known stage starting rules apply. further underlying directed clique. directed clique characterized ordering that subgraph induced incoming edges. denoted ordering denote need following results separating system ﬁrst result regarding adaptive non-adaptive algorithms complete graph. deﬁnition -separating system element subsets |si| every pair subset either pair satisﬁes condition respect said separate pair here consider case katona gave -separating system together lower bound |s|. wegener gave simpler argument lower bound also provided tighter upper bound work give different construction separating system size most⌈log⌈n/k⌉ larger construction wegener. however construction simpler description. lemma labeling procedure produces distinct length labels elements using letters integer alphabet ⌈loga further every digit integer letter used ⌈n/a⌉ times. consider non-adaptive algorithm designs interventions size discover ~kn. separating system worst case already known. prove necessity separating system deterministic adaptive algorithms worst case. theorem adaptive deterministic algorithm designs interventions ﬁnal graph learnt ground truth ordering starting initial skeleton then exists designs separating system. section show total number variable accesses fully identify complete causal theorem fully identify complete causal variables using size-k interventions necessary. also total number variables accessed least lower bound theorem information theoretic. give randomized algorithm requires experiments expectation. provide straightforward generalization authors gave section turn interventions general initial stages chain graph chordal chain components. immoralities throughout graph. work focus chordal chain components. thus work assumed directed graph immoralities whose skeleton chordal. interested recovering using interventions size following provide lower bound adaptive non-adaptive deterministic schemes chordal skeleton coloring number given chordal graph. since chordal graphs perfect clique number. remark separating system nodes gives approximation. however algorithm section exploits chordality performs much better empirically. possible show heuristic also approximation guarantee skip that. theorem exists chordal skeletons algorithm intervention size constraint number interventions required least independence number chromatic numbers respectively. exists chordal graph classes section design adaptive deterministic algorithm anticipates meek rule usage along idea separating system. evaluate experimentally random chordal graphs. first make observations learning connected directed trees skeleton immoralities using meek rule every intervention size tree cycle meek rules apply. lemma every node directed tree immoralities incoming edge. root node incoming edges intervening node alone identiﬁes whole tree using repeated application rule motivation behind algorithm that pair color classes forest choosing right node intervene leaves small subtree unlearnt proof lemma subsequent steps suitable nodes remaining subtrees could chosen edges learnt. give brief description algorithm below. denote initial undirected chordal skeleton coloring number. consider separating system {si}. intervene actual graph intervention corresponding chosen. would like intervene node color consider node color attach score follows. color consider induced forest color classes consider tree containing node degree resulting disjoint trees node removed intervened according proof lemma edge directions trees except would learnt applying meek rules rule directions neighbors would found. class used intervention intervening edges whose directions known meek rules deleted processed recolor sparser graph chromatic number procedure repeated. exact hybrid algorithm described algorithm theorem given undirected choral skeleton underlying directed graph immoralities algorithm ends ﬁnite time returns correct underlying directed graph. algorithm runtime complexity polynomial simulate heuristic namely algorithm randomly generated chordal graphs compare naive algorithm follows intervention sets given separating system theorem algorithms apply meek rules intervention according plot following lower bounds information theoretic max. clique sep. sys. entropic chromatic number based lower bound theorem moreover known separating system constructions maximum clique size references best known separating system shown label max. clique sep. sys. achievable simpler separating system construction shown construction clique sep. sys. upper bound size best known separating system denoted separating system random generation chordal graphs start random ordering vertices. consider every vertex starting vertex probability inversely proportional every σ−}. proportionality constant changed adjust sparsity graph. considered make clique adding edges respecting ordering neighborhood resultant graph corresponding skeleton chordal. also perfect elimination ordering. results interested comparing algorithm naive depends separating system size separating system. size separating system roughly consider values around x-axis plots note that algorithm performs close size separating system i.e. fact always cases average performance naive algorithm goes result points this random chordal graphs structured tree search allows learn edges number experiments quite close lower bound based maximum clique size plots given appendix. information theoretic max. clique sep. sys. entropic max. clique sep. sys. achievable construction clique sep. sys. heuristic algorithm naive sep. sys. based algorithm seperating system information theoretic max. clique sep. sys. entropic max. clique sep. sys. achievable construction clique sep. sys. heuristic algorithm naive sep. sys. based algorithm seperating system figure vertices intervention size bound. number experiments compared heuristic naive algorithm based separating system random chordal graphs. markers represent sizes separating system. green circle markers cyan square markers value correspond number experiments required heuristic algorithm based separating system respectively chordal graphs. note that naive algorithm requires average experiments respectively algorithm requires considered problem adaptively designing interventions bounded size learn causal graph pearl’s sem-ie model. proposed lower upper bounds number interventions needed worst case various classes algorithms causal graph skeleton complete. developed lower upper bounds minimum number interventions required worst case general graphs. characterized extremal graph classes minimum number interventions class close lower bound class close upper bound. case chordal skeletons proposed algorithm combines ideas complete graphs ones skeleton forest application meek rules. empirically randomly generated chordal graphs algorithm performs close lower bound outperforms previous state art. possible future work includes obtaining tighter lower bound chordal graphs would possibly establish tighter approximation guarantee algorithm.", "year": 2015}