{"title": "Spectral Ranking using Seriation", "tag": ["cs.LG", "cs.AI", "stat.ML", "62F07, 06A07, 90C27"], "abstract": "We describe a seriation algorithm for ranking a set of items given pairwise comparisons between these items. Intuitively, the algorithm assigns similar rankings to items that compare similarly with all others. It does so by constructing a similarity matrix from pairwise comparisons, using seriation methods to reorder this matrix and construct a ranking. We first show that this spectral seriation algorithm recovers the true ranking when all pairwise comparisons are observed and consistent with a total order. We then show that ranking reconstruction is still exact when some pairwise comparisons are corrupted or missing, and that seriation based spectral ranking is more robust to noise than classical scoring methods. Finally, we bound the ranking error when only a random subset of the comparions are observed. An additional benefit of the seriation formulation is that it allows us to solve semi-supervised ranking problems. Experiments on both synthetic and real datasets demonstrate that seriation based spectral ranking achieves competitive and in some cases superior performance compared to classical ranking methods.", "text": "abstract. describe seriation algorithm ranking items given pairwise comparisons items. intuitively algorithm assigns similar rankings items compare similarly others. constructing similarity matrix pairwise comparisons using seriation methods reorder matrix construct ranking. ﬁrst show spectral seriation algorithm recovers true ranking pairwise comparisons observed consistent total order. show ranking reconstruction still exact pairwise comparisons corrupted missing seriation based spectral ranking robust noise classical scoring methods. finally bound ranking error random subset comparions observed. additional beneﬁt seriation formulation allows solve semi-supervised ranking problems. experiments synthetic real datasets demonstrate seriation based spectral ranking achieves competitive cases superior performance compared classical ranking methods. study problem ranking items given pairwise comparisons items. problem aggregating binary relations formulated centuries context emerging social sciences voting theories setting study goes back least seeks reconstruct ranking items pairwise comparisons reﬂecting total ordering. case directed graph pairwise comparisons every pair vertices connected exactly possible directed edges usually called tournament graph theoretical computer science literature round robin sports every player plays every player preference marks victory defeat. motivation formulation often stems fact many applications e.g. music images movies preferences easier express relative terms rather absolute ones practice information pairwise comparisons usually incomplete especially case large items data also noisy pairwise comparisons could incorrectly measured inconsistent total order. ranking classical problem formulations vary widely. particular assumptions pairwise preference information obtained vary reference another. subset preferences measured adaptively extract random. settings full preference matrix observed perturbed noise e.g. parametric model assumed permutations reformulates ranking maximum likelihood problem. loss functions performance metrics algorithmic approaches vary well. kenyon-mathieu schudy example derive ptas minimum feedback problem tournaments i.e. problem ﬁnding ranking minimizes number upsets practice complexity method relatively high authors using spectral methods produce efﬁcient algorithms cases classical analytic hierarchy process preference information encoded reciprocal matrix whose perron-frobenius eigenvector provides global ranking. simple scoring methods point difference rule produce efﬁcient estimates computational cost. website ranking methods pagerank hits seek rank pages based hyperlink structure links necessarily express consistent preference relationships adapt pagerank argument ranking pairwise comparisons vigna provides review ranking algorithms given pairwise comparisons particular involving estimation stationary distribution markov chain. ranking also approached prediction problem i.e. learning rank example using support vector machines learn score function. finally bradley-terry-luce framework multiple observations pairwise preferences observed assumed generated generalized linear model maximum likelihood problem usually solved using ﬁxed point algorithms em-like majorization-minimization techniques jiang describes hodgerank algorithm formulates ranking given pairwise comparisons least-square problem. formulation based hodge theory provides tools measure consistency pairwise comparisons existence global ranking. duchi analyze consistency various ranking algorithms given pairwise comparisons query. preferences aggregated standard procedures e.g. computing mean comparisons different users ranking derived using classical algorithms e.g. borda count bradley-terry-model maximum likelihood estimation least squares odd-ratios here show ranking problem directly related another classical ordering problem namely seriation. given similarity matrix items assuming items ordered along chain similarity items decreases distance within chain seriation problem seeks reconstruct underlying linear ordering based unsorted possibly noisy pairwise similarity information. atkins produced spectral algorithm exactly solves seriation problem noiseless case showing similarity matrices computed serial variables ordering eigenvector corresponding second smallest eigenvalue laplacian matrix matches variables. practice means performing spectral ordering similarity matrix exactly reconstructs correct ordering provided items organized chain. adapt results ranking produce efﬁcient spectral ranking algorithm provable recovery robustness guarantees. furthermore seriation formulation allows handle semisupervised ranking problems. fogel show seriation equivalent -sum problem study convex relaxations seriation semi-supervised setting additional structural constraints imposed solution. several authors also focused directly related minimum linear arrangement problem excellent approximation guarantees exist noisy case albeit high polynomial complexity. main contributions paper summarized follows. link seriation ranking showing construct consistent similarity matrix based consistent pairwise comparisons. recover true ranking applying spectral seriation algorithm similarity matrix noisy case show spectral seriation perfectly recover true ranking even pairwise comparisons either corrupted missing provided pattern errors somewhat unstructured. show particular that regime high proportion comparisons observed incorrectly spectral solution robust noise classical scoring based methods. hand comparisons observed show erd¨os-r´enyi graphs i.e. pairwise comparisons observed independently given probability comparisons sufﬁce consistency fiedler vector hence consistency retreived ranking w.h.p. hand need comparisons retrieve ranking whose local perturbations bounded norm. since erd¨os-r´enyi graphs induced graph comparisons connected high probability total number pairs sampled scales need least many comparisons order retrieve ranking therefore consistency result seen optimal polylogarithmic factor. finally seriation results produce semi-supervised ranking solutions. paper organized follows. section recall deﬁnitions related seriation link ranking seriation showing construct well ordered similarity matrices well ranked items. section apply spectral algorithm reorder similarity matrices reconstruct true ranking noiseless case. section show spectral solution remains exact noisy regime random subset comparisons corrupted. section analyze ranking perturbation results comparisons given following erd¨os-r´enyi graph. finally section illustrate results synthetic real datasets compare ranking performance classical spectral scoring based approaches. show write problem ranking given pairwise comparisons seriation problem. seriation problem. seriation problem seeks reorder items given similarity matrix items similar items closer equivalent supposing items placed chain similarity items decreases distance items chain. formalize below following deﬁnition matrix r-matrix symmetric aij+ ai+j lower triangle another formulate r-matrix conditions impose off-diagonal i.e. coefﬁcients decrease move away diagonal. also introduce deﬁnition strict r-matrices whose rows columns cannot permuted without breaking r-matrix monotonicity conditions. call reverse identity permutation permutation puts rows columns matrix reverse order deﬁnition r-matrix called strict-r identity reverse identity permutations permutations reordering r-matrix. r-matrix strict r-constraints strict r-matrix. following pre-r permutation matrix πaπt r-matrix. given pre-r matrix seriation problem consists ﬁnding permutation πaπt r-matrix. note might several solutions problem. particular permutation solution reverse permutation also solution. permutations produce r-matrices called pre-strict-r. constructing similarity matrices pairwise comparisons. given ordered input pairwise comparison matrix show construct similarity matrix strict-r comparisons given consistent identity ranking means similarity items decreases distance ranks. able spectral seriation algorithm described section reconstruct true ranking disordered similarity matrix. ﬁrst show compute pairwise similarity pairwise comparisons items counting number matching comparisons. another formulation allows handle generalized linear model. examples particular instances broader class ranking algorithms derived here. method produces r-matrices pairwise preferences yields valid ranking algorithm. since cikcjk matching signs cikcjk opposite signs counts number matching comparisons reference items smatch compared cikcjk term neutral effect similarity note also next result shows comparisons given consistent identity ranking similarity matrix smatch strict r-matrix. without loss generality assume items ranked increasing order indices. general case simply replace strict-r property pre-strict-r property. proposition given pairwise comparisons items ranked according identity permutation similarity matrix smatch constructed strict r-matrix similarities generalized linear model. suppose paired comparisons generated according generalized linear model i.e. assume outcomes paired comparisons independent pair distinct items item observed ranked higher item probability vector skill parameters function increasing limx→−∞ limx→∞ result shows limit similarity matrix strict r-matrix items properly ordered. proposition items ordered according order decreasing values skill parameters similarity matrix sglm strict matrix high probability number observations goes inﬁnity. notice recover original deﬁnition smatch case binary comparisons though generalized linear model. note also deﬁnitions directly extended setting multiple comparisons available pair aggregated comparisons take fractional values spectral seriation algorithm. spectral computation method originally introduced solve seriation problem based similarity matrices deﬁned previous section. ﬁrst recall deﬁnition fiedler vector deﬁnition fiedler value symmetric nonnegative irreducible matrix smallest non-zero eigenvalue laplacian matrix diag corresponding eigenvector called fiedler vector optimal solution min{yt free case. proposition irreducible pre-r-matrix simple fiedler value fiedler vector repeated values. permutation permuted fiedler vector strictly increasing πaπt πaπt next technical lemmas extend results atkins strict r-matrices used prove theorem next section. ﬁrst shows without loss generality fiedler value simple. lemma irreducible r-matrix uniform shift coefﬁcients simple fiedler value monotonic fiedler vector. proof. states irreducible r-matrix fiedler value simple eigenvalue. since r-matrix among minimal elements. subtracting affect nonnegativity apply monotonicity fiedler vector follows proof. lemma fiedler value simple corresponding fiedler vector monotonic lemma suppose nontrivial maximal interval ar+k contradicts initial assumption. therefore strictly monotonic. proof. r-matrix. ﬁrst suppose distinct indices ar+k ask. lemma fiedler value simple fiedler vector strictly monotonic. hence proposition identity reverse identity permutations produce r-matrices. suppose exist distinct indices ar+k ask. addition identity reverse identity permutations locally reverse order rows columns since matrix arsrs r-matrix ar+k ask. therefore least four different permutations produce r-matrices means strictly serialrank spectral ranking algorithm. section showed similarities smatch sglm pre-strict-r comparisons available consistent underlying ranking items. spectral seriation method reorder matrices produce ranking. spectral ordering requires computing extremal eigenvector cost ﬂops call algorithm serialrank prove following result. theorem given pairwise comparisons totally ordered items assuming ties items algorithm serialrank i.e. sorting fiedler vector matrix smatch deﬁned recovers true ranking items. proof. proposition assumptions proposition smatch pre-strict r-matrix. combining deﬁnition strict-r matrices lemma lemma deduce fiedler value smatch simple fiedler vector repeated values. hence proposition permutations sort fiedler vector increasing decreasing order produce strict r-matrices candidate rankings finally choose candidate rankings picking least upsets. similar results apply sglm given enough comparisons generalized linear model. last result guarantees recovery true ranking items noiseless case. next section study impact corrupted missing comparisons inferred ranking items. figure matrix pairwise comparisons rows ordered according true ranking. corresponding similarity matrix smatch strict rmatrix smatch similarity matrix comparison corrupted corrupted comparison smatch keeps enough strict r-constraints recover right permutation. noiseless case difference coefﬁcients least introducing error coefﬁcients inside green rectangles still enforce strict r-constraints section study robustness serialrank using smatch respect noisy missing pairwise comparisons. noisy comparisons cause ranking ambiguities point score method ambiguities lifted spectral ranking algorithm. show particular serialrank algorithm recovers exact ranking pattern errors random errors numerous. ﬁrst study impact corrupted comparison serialrank extend result multiple corrupted comparisons. similar analysis provided missing comparisons corollary appendix. finally proposition provides estimate number randomly corrupted entries tolerated perfect recovery true ranking. begin recalling deﬁnition point score item. deﬁnition point score item also known point-difference row-sum deﬁned corresponds number wins minus number losses tournament proposition given pairwise comparisons items ranked according indices suppose sign comparison switched smatch deﬁned remains strict-r whereas point score vector ties items items proof. give intuition result figure write true score comparison matrix observations written respectively. means particular ˆcij −cij ˆcji −cji simplify notations denote similarity matrix smatch ﬁrst study impact corrupted comparison point score vector similarly whereas hence incorrect comparison induces ties point score vector show similarity matrix deﬁned breaks ties showing strict r-matrix. writing terms remains r-matrix. note result remains true even need strict inequalities show uniqueness retrieved order. indeed constraints strict except elements rows rows ties broken using fact proposition given pairwise comparisons items ranked according indices suppose signs comparisons indexed switched. following condition holds true proof. write true score comparison matrix observations written respectively without loss generality suppose implies ˆciljl −ciljl cjlil −cjlil simplify notations denote similarity matrix smatch proof proposition corrupted comparisons indexed induce shifts columns rows similarity matrix smatch smatch values remain same. since several corrupted comparisons also need check values intersections rows columns indices corrupted comparisons. formally similar results apply intersections rows columns indices corrupted comparisons coefﬁcients ˆsst sst. ﬁrst observe last equations together assumption mean case corrupted comparison note separation condition pair items necessary. comparison adjacent items corrupted ranking method break resulting tie. case arbitrary number corrupted comparisons condition sufﬁcient condition only. study exact ranking recovery conditions missing comparisons appendix using similar arguments. estimate number randomly corrupted entries tolerated maintaining exact recovery true ranking. proposition given comparison matrix items corrupted comparisons selected uniformly random possible item pairs. algorithm serialrank guarantees probability recovery satisﬁes provided particular implies provided consider case distinct pairs items sampled uniformly random without replacement. denote sampled pairs given pairs sampled. seek bound prob. given pairs non-admissible pairs i.e. containing note every selected pair contributes non-admissible pairs. indeed given selected pair non-admissible pair respect following conditions |s−i| |s−j| given item possible choice output nonadmissible pair resulting non-admissible pairs selected pair section analyze serialrank performs small fraction pairwise comparisons given. show erd¨os-r´enyi graphs i.e. pairwise comparisons observed independently given probability comparisons sufﬁce consistency fiedler vector hence consistency retreived ranking w.h.p. hand need comparisons retrieve ranking whose local perturbations bounded norm. since erd¨os-r´enyi graphs connected high probability total number pairs sampled scales need least many comparisons order retrieve ranking therefore consistency result seen optimal polylogarithmic factor. bounds mostly related work simpliﬁed version shows ranking items according point score precision parameter sampling independently ﬁxed probability comparisons guarantees maximum displacement retrieved ranking true ranking i.e. distance true ranking bounded high probability large enough. sample complexity bounds also studied rank centrality algorithm analysis suppose pairs sampled independently ﬁxed probability comparisons generated sampled pair bradley-terry-luce model ranking items according stationary distribution transition matrix estimated comparisons sampling pairs enough bound relative norm perturbation stationary distribution. however pointed repeated measurements practical e.g. comparisons derived outcomes sports games purchasing behavior customer moreover provide bounds relative norm perturbation ranking. also refer reader recent work rajkumar agarwal provide survey sample complexity bounds rank centrality maximum likelihood estimation least-square ranking based ranking ﬂexible sampling model. however bounds give sampling complexity exact recovery ranking usually prohibitive large difﬁcult interpret. limitations. emphasize sampling models based erd¨os-r´enyi graphs realistic though studied widely literature indeed pairs likely sampled independently. instance ranking movies popular movies ranks likely compared. corrupted comparisons also likely items close rankings. hope extend perturbation analysis general models future work. second limitation perturbation analysis comes setting ordinal comparisons i.e. binary comparisons since many applications several comparisons provided sampled pair. nevertheless setting ordinal comparisons interesting analysis serialrank since numerical experiments suggest setting serialrank provides best results compared methods. note practice easily limitation refer reader numerical experiments section well recent paper cucuringu introduces another ranking algorithm called syncrank provides extensive numerical experiments state-of-the-art ranking algorithms including serialrank. choice laplacian normalized unnormalized. spectral clustering literature several constructions laplacian operators suggested namely unnormalized laplacian symmetric normalized laplacian non-symmetric normalized laplacian. luxburg show stronger consistency results spectral clustering using non-symmetric normalized laplacian. here show fiedler vector normalized laplacian afﬁne function ranking hence sorting fiedler vector still guarantees exact recovery ranking comparisons observed consistent global ranking. contrast asymptotic expression unnormalized laplacian motivated provide analysis serialrank robustness based normalized laplacian though practice unnormalized laplacian valid seems give better results notations. throughout section focus similarity smatch write simplify notations. w.l.o.g. assume following true ranking identity hence r-matrix. write operator norm matrix corresponds maximal absolute eigenvalue symmetric matrices. denotes frobenius norm. refer eigenvalues laplacian quantity denote perturbed analogue. deﬁne residual matrix write normalized fiedler vector laplacian matrix deﬁne degree matrix diag diagonal matrix whose elements row-sums matrix whenever abreviation w.h.p. means inequality true probability greater finally absolute constants whose values allowed vary equation another. assume information preferences incomplete corrupted. speciﬁcally pairwise comparisons independently sampled probability sampled comparisons consistent underlying total ranking probability deﬁne matrix observed comparisons true comparison matrix deﬁned hadamard product symmetric matrix entries results. state main results. ﬁrst bounds perturbations fiedler vector missing corrupted comparisons. note normalized. theorem every large enough goes inﬁnity perturbation fiedler vector goes zero retrieve true ranking reordering fiedler vector. hence bounds provides consistency ranking optimal sampling complexity bound quantiﬁes maximum displacement item’s ranking. seen precision parameter. instance theorem means expect maximum displacement item’s ranking less observing comparisons weaker condition n/µn. sketch proof. proof results relies classical perturbation arguments structured follows. step bound high probability using concentration inequalities step show normalized laplacian linear fiedler vector bound step bound using davis-kahan theorem bounds steps step linearity fiedler vector translate result bound maximum notice arbitrarily diagonal values zeros. indeed similarity element constant convention leads ˜sii items hence could take deﬁnition consider independent associated summation. proof. main argument proof independence order bound constant times standard deviation cij. isolate independent entries perturbation matrix ﬁrst need break anti-symmetry decomposing upper triangular part lower triangular part i.e. xlow step controlling eigengap. following proposition show normalized laplacian similarity matrix constant fiedler value linear fiedler vector. deduce bounds eigengap ﬁrst second third smallest eigenvalues laplacian. proposition lnorm non-symmetric normalized laplacian lnorm linear fiedler vector fiedler value equal proof. ﬁrst eigenvalue laplacian always moreover using results know eigenvalues normalized laplacian different converge asymptotic spectrum limit eigenvalues isolated. hence exists step bounding perturbation fiedler vector compile results previous sections ﬁrst perturbation bound show consistency fiedler vector comparisons missing corrupted. theorem every large enough proof. order davis-kahan theorem need relate perturbations normalized laplacian matrix perturbations similarity degree matrices. simplify notations write i−d−s since normalized laplacian symmetric actually apply davis-kahan theorem symmetric normalized laplacian lsym d−/sd−/. easy lsym absolute constant. finally small weyl’s inequality equation together lemma ensure large enough high probability λ|/. hence apply davis-kahan theorem. compiling constants obtain bounding ranking perturbations serialrank’s ranking derived sorting fiedler vector. consistency result theorem shows estimation error going zero goes inﬁnity sufﬁcient quantify maximum displacement ranking. quantify maximum displacement ranking need bound instead. compared sampling rate would need better component-wise bound extra factor sign indeed bounded high probability quantity less fi|/ sufﬁciently apart. hence |˜πi bounded number pairs sufﬁciently apart. quantify term apart following proposition. theorem every large enough synthetic datasets. ﬁrst synthetic dataset consists matrix pairwise comparisons derived given ranking items uniform randomly distributed corrupted missing entries. second synthetic dataset consists full matrix pairwise comparisons derived given ranking items added local noise similarity nearby items. speciﬁcally given positive integer unif figure measure kendall correlation coefﬁcient true ranking retrieved ranking varying either percentage corrupted comparisons percentage missing comparisons. kendall’s counts number agreeing pairs minus number disagreeing pairs rankings scaled total number pairs takes values experiments performed reported kendall values averaged experiments standard deviation less points interest results suggest serialrank produces accurate rankings point score dashed blue line) rank centrality dashed green line) maximum likelihood dashed magenta line) regimes limited amount corrupted missing comparisons. particular serialrank seems robust corrupted comparisons. hand performance deteriorates rapidly regimes high number corrupted/missing comparisons. exhaustive comparison serialrank state-ofart ranking algorithms refer interested reader recent paper cucuringu introduces another ranking algorithm called syncrank provides extensive numerical experiments. real datasets. ﬁrst real dataset consists pairwise comparisons derived outcomes topcoder algorithm competitions. collected data competitions among coders period year. pairwise comparisons extracted ranking competition averaged pair. topcoder maintains ratings participant updated online scheme competition also included benchmarks. measure performance figure compute percentage upsets closely related kendall reﬁne metric considering participants appearing various values i.e. computing experiment shows serialrank gives competitive results ranking algorithms. notice rankings could probably reﬁned designing similarity matrix taking account speciﬁc nature data. ofﬁcial city liverpool chelsea arsenal everton tottenham united southampton stoke newcastle crystal palace crystal palace swansea west aston villa sunderland hull west brom norwich fulham cardiff liverpool arsenal city chelsea everton tottenham united southampton stoke newcastle swansea crystal palace west hull aston villa west brom sunderland fulham norwich cardiff city liverpool chelsea arsenal everton tottenham united southampton united stoke newcastle crystal palace newcastle west brom swansea hull west brom west west aston villa cardiff crystal palace sunderland fulham hull norwich norwich sunderland fulham cardiff aston villa semi-supervised ranking. illustrate semi-supervised setting interactively enforce constraints retrieved ranking using e.g. semi-supervised seriation algorithm compute rankings england football premier league teams season comparisons deﬁned averaged outcome figure kendall serialrank point score dashed blue line) rank centrality dashed green line) maximum likelihood dashed magenta line). ﬁrst synthetic dataset vary proportion corrupted comparisons proportion observed comparisons proportion observed comparisons comparisons corrupted also vary parameter second synthetic dataset home away games pair teams. shown table half serialrank ranking close ofﬁcial ranking calculated sorting points team however signiﬁcant variations bottom half though number upsets roughly ofﬁcial ranking. test semi-supervised ranking suppose example satisﬁed ranking aston villa explicitly enforce aston villa appears cardiff ofﬁcial ranking. ranking based corresponding semi-supervised seriation problem aston villa last anymore though number disagreeing comparisons remains formulated problem ranking pairwise comparisons seriation problem i.e. problem ordering similarity information. constructing adequate similarity matrix applied spectral relaxation seriation variety synthetic real ranking datasets showing competitive cases superior performance compared classical methods especially noise environments. derived performance bounds algorithm presence corrupted missing comparisons showing serialrank produces state-of-the results ranking based ordinal comparisons comparisons missing. hand e.g. showing exact reconstruction w.h.p. signiﬁcantly optimal bound questions thus remain open pose future research directions. first theoretical perspective possible obtain bound local perturbations ranking using sampled pairs? contrary lower bound spectral algorithms imposing sampled pairs? note questions hold current spectral ranking algorithms. another line research concerns generalization spectral ordering methods ﬂexible settings e.g. enforcing structural priori constraints ranking. hierarchical ranking i.e. running spectral algorithm increasingly reﬁned subsets original data explored too. early experiments suggests works quite well bounds available point. finally would interesting investigate similarity measures could tuned speciﬁc applications order improve serialrank predictive power instance take account information win/loss sports tournaments. additional experiments vein found cucuringu barbeau ‘perron’s result decision admissions tests’ mathematics magazine blum konjevod ravi vempala ‘semideﬁnite relaxations minimum bandwidth braverman mossel noisy sorting without resampling ‘proceedings nineteenth annual acm-siam symposium discrete algorithms’ society industrial applied mathematics rajkumar agarwal statistical convergence perspective algorithms rank aggregation pairwise data ‘proceedings international conference machine learning’ stewart matrix algorithms vol. eigensystems society industrial mathematics. stewart matrix perturbation theory academic press. vigna ‘spectral ranking’ arxiv preprint arxiv. luxburg belkin bousquet ‘consistency spectral clustering’ annals exact recovery results missing entries. here section study impact missing comparison serialrank extend result multiple missing comparisons. proposition given pairwise comparisons items ranked according indices suppose comparison missing smatch deﬁned remains strict-r point score vector remains strictly monotonic. proof. proof technique proposition write true score comparison matrix observations written respectively. means particular simplify notations denote similarity matrix smatch missing i.e. ciljj following condition holds true corollary given pairwise comparisons items ranked according indices suppose comparisons indexed either corrupted missing. condition holds true smatch deﬁned remains strict-r. standard theorems technical lemmas used spectral perturbation analysis ﬁrst recall weyl’s inequality simpliﬁed version davis-kahan theorem found theorem consider symmetric matrix eigenvalues symmetric perturbation eigenvalues notice arbitrarily diagonal values zeros. indeed similarity element constant convention leads ˜sii items hence could take deﬁnition consider independent associated summation. ﬁrst obtain concentration inequality union bound bound max|δi|. notice numerical experiments normalized laplacian. shown ﬁgure results similar serialrank unnormalized laplacian. lose performance terms robustness corrupted comparisons. figure kendall serialrank normalized laplacian row-sum dashed blue line) rank centrality dashed green line) maximum likelihood dashed magenta line). ﬁrst synthetic dataset vary proportion corrupted comparisons proportion observed comparisons proportion observed comparisons comparisons corrupted also vary parameter second synthetic dataset asymptotic fiedler value fiedler vector. results convergence laplacian operators provide description spectrum unnormalized laplacian serialrank. following analysis prove asymptotically normalized apart ﬁrst second eigenvalue spectrum laplacian matrix contained interval moreover characterize eigenfunctions limit laplacian operator differential equation enabling asymptotic approximation fiedler vector. asymptotic expression fiedler vector solution differential equation roots suppose since degree function nonnegative. simple calculations show bounding eigengap. give simple propositions fiedler value third eigenvalue laplacian matrix enable bound eigengap second third eigenvalues. proposition given comparisons indexed true ranking fiedler value smatch choices similarities. results paper shows forming similarity matrix pairwise preferences produce valid ranking algorithm. follows detail options extending results section cardinal comparisons. input comparisons take continuous values several choice similarities made. first possibility sglm. option directly provide similarity serialrank. option much better computational cost. adjusting contrast smatch. instead providing smatch serialrank change contrast similarity i.e. take similarity whose elements powers elements smatch. hierarchical ranking. large dataset goal rank subset items. case ﬁrst perform spectral ranking reﬁne ranking items using either serialrank algorithm comparison submatrix another seriation algorithm convex relaxation last method also allows solve semi-supervised ranking problems given additional information structure solution. acknowledgements. cnrs d´epartement d’informatique ´ecole normale sup´erieure paris inria sierra team research university. authors would like acknowledge support starting grant european research council msr-inria joint centre well support chaire ´economie nouvelles donn´ees data science joint research initiative fonds pour recherche gift soci´et´e g´en´erale cross asset quantitative research.", "year": 2014}