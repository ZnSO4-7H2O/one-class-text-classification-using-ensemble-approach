{"title": "Bayes-Optimal Effort Allocation in Crowdsourcing: Bounds and Index  Policies", "tag": ["cs.LG", "cs.AI", "stat.ML"], "abstract": "We consider effort allocation in crowdsourcing, where we wish to assign labeling tasks to imperfect homogeneous crowd workers to maximize overall accuracy in a continuous-time Bayesian setting, subject to budget and time constraints. The Bayes-optimal policy for this problem is the solution to a partially observable Markov decision process, but the curse of dimensionality renders the computation infeasible. Based on the Lagrangian Relaxation technique in Adelman & Mersereau (2008), we provide a computationally tractable instance-specific upper bound on the value of this Bayes-optimal policy, which can in turn be used to bound the optimality gap of any other sub-optimal policy. In an approach similar in spirit to the Whittle index for restless multiarmed bandits, we provide an index policy for effort allocation in crowdsourcing and demonstrate numerically that it outperforms other stateof- arts and performs close to optimal solution.", "text": "consider effort allocation crowdsourcing wish assign labeling tasks imperfect homogeneous crowd workers maximize overall accuracy continuous-time bayesian setting subject budget time constraints. bayes-optimal policy problem solution partially observable markov decision process curse dimensionality renders computation infeasible. based lagrangian relaxation technique adelman mersereau provide computationally tractable instance-speciﬁc upper bound value bayes-optimal policy turn used bound optimality sub-optimal policy. approach similar spirit whittle index restless multiarmed bandits provide index policy effort allocation crowdsourcing demonstrate numerically outperforms stateof-arts performs close optimal solution. crowdsourcing accomplish large-volume tasks image classiﬁcation document relevance assessment using large pool amateur workers much less expense possible hiring experts developing automatic machine learning method moreover online platforms amazon mechanical turk make crowdsourcing service widely accessible providing marketplace requesters post tasks crowd-workers complete exchange although crowdsourcing less expensive hiring experts number images tasks requester correctly label process nonetheless limited budget. fact compounded noise variability inherent crowd-workers’ responses typically requires single item processed independently several times multiple workers. paper goal sequential allocation workers tasks accurately supports correct aggregated label task subject limited budget limited time horizon. paper focus binary labeling tasks approach also extended multi-class labeling. intuitively much accomplished sophisticated allocation worker effort budgets large relative overall difﬁculty tasks accomplished good scheme allocating workers tasks difﬁcult uniform quality ensured. budgets small however difﬁcult tasks abandoned bulk budget used ensure least easy tasks done correctly. adopt bayesian approach natural crowdsourcing because allows leverage prior information tasks accomplished learned crowdsourcing setting features associated task typically large collections historical data collected previous crowdsourcing campaigns; seeks maximize average-case performance respect prior distribution natural crowdsourcing requesters typically tolerate variability quality interested maximizing aggregate performance across large volume tasks rather ensuring robustness worst-case distribution task characteristics studying asymptotic bewithin bayesian framework formulate study sequential effort allocation partially observable markov decision process using tools dynamic programming. curse dimensionality prevents solving dynamic program optimality provide computationally tractable upper bound expected performance bayes-optimal effort allocation policy. upper bounds useful allow evaluating optimality given heuristic problem instance simply simulating heuristic comparing performance bound. technique obtain upper bound lagrangian relaxation weakly coupled dynamic programs discussed adelman mersereau hawkins proofs present section similar spirit adelman mersereau adelman based proof value functions formulation inﬁnite horizon setting offer proof based initial objective function problem ﬁnite horizon setting. nonetheless crowdsourcing model speciﬁc application general formulation adelman mersereau hawkins then using lagrange multipliers appear upper bound derive index-based heuristic policy similar spirit gittins index policy multi-armed bandits gittins whittle index policy restless bandits whittle show index policy performance close upper bound numerical experiments also outperforms state-of-art policies resource allocation although primary novelty contribution paper ﬁrst characterize performance bayes-optimal policy effort allocation crowdsourcing develop bayesian bandit-style index policies work also novel modeling asynchronous nature crowd-work continuous-time setting contrast previous work effort allocation crowdsourcing assumed instant completion tasks model inspired crowd-workers employed amazon mechanical turk; allowing asynchronous process thus gives closer proximity real situations. major strands former works work related. ﬁrst work effort allocation crowd labeling. much work adopts frequentist viewpoint focuses error bounds inference karger ghosh karger thanh karger proposed allocation algorithm based random graph performance asymptotically order-optimal needs large number workers make relevant. thanh incorporates limited budget lacks notion optimality. none work considers ﬁnite time horizon. also work bayesian ﬂavor; bacharach focused efﬁciency allocation consider optimal solution. among work adopt bayesian framework work similar chen form optimal policy form stochastic dynamic program. although also provide well-motivated heuristic policy work pushes deriving upper bound based formulation optimal policy. second strand resides literature multi-armed bandit stochastic dynamic programming. formulation bayesian-optimal procedure dynamic program considered lovejoy monahan lagrangian relaxation application relaxation method weakly coupled dynamic program discussed setting paper differs previous works task assigned worker enters completion task instant. index-based policy proposed paper uses lagrangian multipliers assign indices draws inspiration whittle consider requester crowdsourcing service independent binary labeling tasks. budget constraint requester allows maximum workers work tasks requires work completed time horizon model arrival workers crowdsourcing system poisson process rate worker enters system requester selects tasks worker label. indicate task assigned worker. denote rest paper.) worker spends random exponential amount time task independent else provides binary label workers always give correct label task ambiguous thus hard categorize workers careless lack background information conduct labeling process. suppose workers homogeneous give noisy unbiased labels. specifically task associated unknown value underlying probability labeled positive worker. distribution label goal requester design policy dynamically assign tasks workers entering system maximize expected reward received based labels obtained crowd-workers. formalize problem statement section control continuous-time markov chain analyzed stochastic dynamic program built embedded discrete-time markov chain. continuoustime markov chain tracks evolution worker assignments posterior distributions results requester’s dynamic assignment policy. transitions occur markov chain workers complete tasks workers arrive start work task. count number transitions indicate state event initial state together describe prior distribution vector zeros. assumption independent beta prior conditionally independent bernoulli responses posterior number workers provided responses remain beta-distributed ﬁrst parameter equal number positive responses second parameter equal number negative responses. practice estimate appropriate values parameters historical data tasks previously labeled crowd. discuss section numerical experiments performed. note assumption beta distribution relaxed without great deal difﬁculty posterior distribution remain exponential family parameterized number positive negative labels observed instance. assumption independence cannot easily generalized necessary decomposition lagrangian relaxation without upper bound section much challenging compute. thus worker budget exhausted time horizon elapsed requester posterior distribution remains beta-distributed. posterior parameter time. time model requester choosing task estimated label based responses crowdworkers receiving reward correctly labeled task incorrectly labeled tasks. expected reward posterior requester obtain s/he chooses positive label s/he chooses negative label thus requester chooses label giving larger reward achieves reward whose expected value posterior deﬁne policy controls requester assigns incoming workers tasks based current state. policy onto give number workers assigned tasks transition caused arriving worker. constrain prevent assigning task worker later lagrangian relaxation relax constraint. added additional constraint task assigned incoming worker. feasible policies problem interest consider larger policies support later theoretical analysis. policies allows assigning incoming worker task even budget time remains still exhaust unit budget optimal policies always assign incoming workers tasks possible. deﬁnes discrete time markov chain state space whose transition kernel indicate pπ|s). transition kernel written similarly worker completes task reports negative label probability occurs completely speciﬁes transition kernel discrete-time markov chain describes continuoustime dynamics worker allocation posterior distribution model completion deﬁne states time horizon elapsed worker budget exhausted allocated workers ﬁnished work. inf{n number events occur including time reach state posterior requester must make his/her ﬁnal determination task labels expected reward posterior s/he receives time βββ). recall goal stated section dynamic allocation policy workers tasks maximizes expected number correctly classiﬁed tasks. deﬁnition markov chain place overarching goal stated formally solving thus complete description transition kernel sufﬁcient describe description suppose system exceeded time horizon outstanding tasks workers currently working canceled time updated worker arrives probability r/q. requester allocates worker task total number arrivals incremented worker budget exceeded requester cannot allocate worker worker completes task ports positive label probability occurs speciﬁcally relax constraint worker assigned task penalize number tasks assigned ensures upper bound holds regardless provide upper bound optimal value original problem made tighter minimizing λλλ. upper bound computed decomposition small dynamic programs ﬁxed dimension solved efﬁciently even grows large. moreover knowing value function reveals optimal policy optimal policy given choosing task assign next worker response previous state time achieve maximum maxz however solving dynamic program computationally infeasible. example discretize continuous time line intervals tasks number states consider workers entering system compute. hence seek ﬁrst provide upper bound optimal value upper bound yardstick measure close heuristic policy performs optimal policy. although solving directly using stochastic dynamic program computationally intractable section show obtain computationally feasible upper bound value using lagrangian relaxation. recall count events state corresponding event. deﬁne number events occurred time arrival i.e. inf{n deﬁne ∆n−) worker assigned task therefore satisﬁes also assign worker task along particular sample path long expected number tasks assigned worker larger returning markov chain model observe worker assigned task tasks completed independently other. observe includes larger policies includes larger still i.e. result relation. value. remains computing upper bound solve inﬁmum theorem explore convexity property problem follow binary search. deﬁne upper bound derived theorem without inﬁmum. first prove convex λλλ. state space dynamic program dimensions. avoid issue decomposing supremum term optimal values dynamic programs task much manageable dimensions. support decomposition write state whole system state task events occurred includes global counter possible values single-task state snx. following development identical section single task deﬁne space policies single-task state elapsed time since last event onto binary decision whether allocate incoming worker task following development construct independent markov chains task controlled respective single-task policy deﬁne before ﬁrst time time horizon elapses worker budget exhausted outstanding workers completed work. reward obtained single task time. following theorem shows bound theorem re-written terms solutions singletask dynamic programming problems obtains reward penalized assigning workers task. theorem convexity approximate achieves inﬁmum setting fibonacci search inﬁmum. constrain units simpler computation tighter bound obtained allowing unit vary sub-gradient descent locate inﬁmum. introduce index-based heuristic policy built lagrangian relaxation used proving upper bound. policy compute task based state greatest value optimal policy decide hire worker state solving assign incoming worker task highest intuition behind policy single-task problem described view cost employing worker. increases decision switches hiring worker hiring switching point tasks worth hiring workers work present algorithm formal way. useful technique reduce amount computation total number workers assigned task reduces size state space dynamic program involved solving additional affect decision made index policy. intuitively unlikely reasonable policy assign number workers task unlike task certain number workers assigned. check validity running numerical experiment concentrate case case stop reach maximum number workers budget allows. bellman’s recursion compute computation upper bound special case given supplement. ﬁrst simulation study compare performances different policies simulated data corresponding upper bounds. second simulation study real dataset simulation. ﬁrst simulations evaluate performance index policy using simulated data compared total reward given generated index policy upper bound also compare performance index policy optimistic knowledge gradient method state-of-art bayesian allocation policy. round simulated process includes generating either arrival worker completion task based arrival rate completion rate distributions speciﬁed section completion task generate label based posterior parameters. process stops exhaust budget i.e. number workers allowed hire reward vary number tasks budget non-informative prior threshold tasks. value simulate process times obtain conﬁdence interval simulated total reward. figure show semi-log plot number tasks average reward task corresponding conﬁdence intervals. simulating remaining tasks dataset ‘historical data’ estimate parameters beta prior across tasks. comes assumption tasks homogeneous hence subset representative larger population. ﬁrst obtain estimate tasks empirical values figure beta distribution method moments. emphasize improved performance offered index policy aspect contribution work. aspect tightness upper bound especially problem instances many tasks. tight upper bound shows index policy within optimal continued algorithmic development provide signiﬁcantly increased performance large-scale crowdsourcing problems characteristics matching particular simulated dataset. ability bound improvement continued algorithmic development particular problem instance class problem instances useful managers companies crowdsourcing wish allocate engineering\\r&d effort. simulations uses real dataset pascal consists tasks comes labels obtained crowdworkers gold standard label. evaluate performance index policy policy thompson sampling widely used frequentist approach upper conﬁdence bound policy metric used evaluate performance accuracy score. speciﬁcally number correctly predicted labels total number tasks. round simulation process still simulate events section event completion read recent label task dataset. process predicted labels compared gold standard labels. still tasks. value simulate process show semi-log plot number tasks accuracy score corresponding conﬁdence intervals. bayesian policies smaller optimality gets larger. index policy performing consistently best among policies. proven chen policy consistent achieve accuracy almost surely number workers goes inﬁnity. demonstrate numerically index policy performs better policy. thus reasonable anticipate index policy consistent asymptotically optimal number workers number tasks goes inﬁnity keeping ratio number workers number tasks constant. formulated effort-allocation problem crowdsourcing continuous time setting budget constraint time constraint. also provide computationally feasible upper bound value bayes-optimal policy using lagrangian relaxation. using lagrange multiplier used proving upper bound also derived index-based policy showed numerical experiments performs close optimal. jabbari vaughan adaptive task assignment crowdsourced classiﬁcation. icml karger shah budget-optimal task allocation reliable crowdsourcing systems. operations research", "year": 2015}