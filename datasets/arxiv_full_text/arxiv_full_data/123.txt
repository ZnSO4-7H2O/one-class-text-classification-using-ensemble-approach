{"title": "Learning to Answer Questions From Image Using Convolutional Neural  Network", "tag": ["cs.CL", "cs.CV", "cs.LG", "cs.NE"], "abstract": "In this paper, we propose to employ the convolutional neural network (CNN) for the image question answering (QA). Our proposed CNN provides an end-to-end framework with convolutional architectures for learning not only the image and question representations, but also their inter-modal interactions to produce the answer. More specifically, our model consists of three CNNs: one image CNN to encode the image content, one sentence CNN to compose the words of the question, and one multimodal convolution layer to learn their joint representation for the classification in the space of candidate answer words. We demonstrate the efficacy of our proposed model on the DAQUAR and COCO-QA datasets, which are two benchmark datasets for the image QA, with the performances significantly outperforming the state-of-the-art.", "text": "image captioning. answer produced image needs conditioned image question. such image involves interactions between image language. illustrated figure image contents complicated containing multiple different objects. questions images speciﬁc requires detailed understanding image content. question what largest blue object picture? need identify blue objects image also compare sizes generate correct answer. question many pieces curtain have? need identify object curtain non-salient region image ﬁgure quantity. successful image model needs built upon good representations image question. recently deep neural networks used learn image sentence representations. particular convolutional neural networks extensively used learn image representation image recognition cnns also demonstrate powerful abilities sentence representation paraphrase sentiment analysis moreover deep neural networks used capture relations image sentence image captioning retrieval. paper propose employ convolutional neural network image question answering proposed provides end-to-end framework convolutional architectures learning image question representations also inter-modal interactions produce answer. speciﬁcally model consists three cnns image encode image content sentence compose words question multimodal convolution layer learn joint representation classiﬁcation space candidate answer words. demonstrate efﬁcacy proposed model daquar coco-qa datasets benchmark datasets image performances signiﬁcantly outperforming state-of-the-art. recently multimodal learning image language become increasingly popular research area artiﬁcial intelligence particular rapid progresses tasks bidirectional image sentence retrieval automatic image captioning order advance multimodal learning push boundary research ai-complete task namely visual question answering image question answering recently proposed. generally takes image free-form natural-language like question image input produces answer image question. paper employ address image problem. proposed model trained triplets consisting answer free-form natural-language like questions image. main contributions propose end-to-end model learning answer questions image. experimental results public image datasets show proposed model surpasses state-of-the-art. employ convolutional architectures encode image content represent question learn interactions image question representations jointly learned produce answer conditioning image question. recently visual turing test open domain task question answering based real-world images proposed resemble famous turing test. human judge presented image question answer question computational models human annotators. based answer human judge needs determine whether answer given human machine geman proposed produce stochastic sequence binary questions given test image answer question limited yes/no. malinowski discussed associated challenges issues regard visual turing test vision language representations common sense knowledge well evaluation. image task resembling visual turing test proposed. malinowski proposed multi-world approach conducts semantic parsing question segmentation image produce answer. deep neural networks also employed image task related research work. work formulates image task generation problem. malinowski al.’s model namely neuralimage-qa feeds image representation question long-short term memory produce answer. model ignores different characteristics questions answers. compared questions answers tend short single word denoting object category color number deep neural network inspired multimodal recurrent neural networks model used lstms representations question answer respectively. image task formulated classiﬁcation problem socalled visual semantic embedding model proposed. lstm employed jointly model image question treating image independent word appending question beginning ending position. such joint representation image question learned used classiﬁcation. however simply treating image individual word cannot help effectively exploit complicated relations image question. thus accuracy answer prediction ensured. order cope drawbacks proposed employ end-toend convolutional architectures image capture complicated inter-modal relationships well representations image question. experimental results demonstrate convolutional architectures achieve better performance image task. containing answers. denotes parameters performing image order make reliable prediction answer question image need adequately represented. based representations relations multimodal inputs learned produce answer. paper ability exploited modeling image sentence individually also capturing relations interactions them. illustrated figure proposed framwork image consists three individual cnns image encoding image content sentence generating question representation multimodal convolution layer fusing image question representations together generate joint representation. finally joint representation softmax layer produce answer. three cnns softmax layer fully coupled proposed end-to-end image framework parameters jointly learned end-to-end fashion. image many research papers employing cnns generate image representations achieve state-ofthe-art performances image recognition paper employ work encode image content image model nonlinear activation function sigmoid relu takes image input outputs ﬁxed length vector image representation. paper chopping softmax layer last relu layer output last fully-connected layer deemed image representation ﬁxed length vector dimension note mapping matrix dimension much smaller hand dimension image representation reduced such total number parameters fusing image question speciﬁcally multimodal convolution process signiﬁcantly reduced. consequently fewer samples needed adequately training model. hand image representation projected space nonlinear activation function increasing nonlinear modeling property image cnn. thus capability learning complicated representations enhanced. result multimodal convolution layer better fuse question image representations together exploit complicated relations interactions produce answer. sentence paper employed model question image convolution models consider convolution unit local receptive ﬁeld shared weights capture rich structures composition properties consecutive words. sentence generating question representation illustrated figure given question word represented word embedding sentence several layers convolution max-pooling performed generate question representation νqt. convolution sequential input convolution unit feature type-f layer deﬁnes size local receptive ﬁeld convolution. concatenates vectors long vector. paper chosen convolution process. parameters within convolution unit shared whole question window covering semantic components sliding beginning end. input ﬁrst convolution layer sentence word embeddings question question. max-pooling convolution process sequential semantic components composed higher semantic representation. however compositions meaningful representations question figure max-pooling process following convolution process performed firstly together stride max-pooling process shrinks half representation quickly make sentence representation. importantly max-pooling process select meaningful compositions ﬁlter unreliable ones. such meaningful composition chair likely pooled compared composition front the. convolution max-pooling processes exploit summarize local relation signals consecutive words. layers convolution max-pooling help summarize local interactions words larger scales ﬁnally reach whole representation question. paper employ three layers convolution max-pooling generate question representation νqt. multimodal convolution layer image representation question representation obtained image sentence cnns respectively. design multimodal convolution layer them shown figure fuses multimodal inputs together generate joint representation answer prediction. image representation treated individual semantic component. based image representation consecutive semantic components question side mulitmodal convolution alternatively lstm could used fuse image question representations example latter work bidirectional lstm employed appending image representation beginning ending position question. argue better employ lstm image task following reason also veriﬁed following experiment section. relations image question complicated. image interact high-level semantic representations composed number words bicycle figure however lstm cannot effectively capture interactions. treating image representation individual word effect image vanish time step lstm result relations image high-level semantic representations words well exploited. contrast model effectively deal problem. sentence ﬁrst compose question high-level semantic representations. multimodal convolution process fuse semantic representations image question together adequately exploit interactions. mutlimodal convolution layer multimodal representation jointly modeling image question obtained. softmax layer shown figure produces answer given image question pair. section ﬁrstly introduce conﬁgurations model image train proposed model. afterwards public image datasets evaluation measurements introduced. finally experimental results presented analyzed. conﬁgurations training three layers convolution max-pooling employed sentence cnn. numbers feature maps three convolution layers respectively. sentence designed ﬁxed architecture needs accommodate maximum length questions. paper maximum length question chosen word embeddings obtained skip-gram model dimension network image cnn. dimension multimodal takes image sentence representations input generate joint representation number feature maps proposed model trained stochastic gradient descent mini batches optimization negative likelihood chosen loss. training process parameters tuned including parameters nonlinear image mapping image sentence multimodal convolution layer softmax layer. moreover word embeddings also ﬁne-tuned. order prevent overﬁtting dropout used. image datasets test compare proposed model public image databases speciﬁcally daquar coco-qa datasets. daquar-all dataset consists training testing samples generated images respectively. images object categories. mainly three types questions dataset speciﬁcally object type object color number objects. answer single word multiple words. daquar-reduced dataset reduced version daquar-all comprising training testing samples. images constrained object categories. images used testing sample generation. daquar-all dataset answer single word multiple words. coco-qa dataset consists training testing samples generated images respectively. four types questions speciﬁcally object number color location. answers single-word. evaluation measurements straightforward evaluating image utilize accuracy measures proportion correctly answered testing questions total testing questions. besides accuracy wu-palmer similarity also used measure performances different models image task. wups calculates similarity words based common subsequence taxonomy tree. experimental results analysis competitor models compare models recently developed models image task speciﬁcally multi-world approach model neural-image-qa approach performances image performances proposed model daquar-all daquarreduced coco-qa datasets illustrated table respectively. daquar-all daquarreduced datasets multiple words answer question treat answer comprising multiple words individual class training testing. daquar-all dataset evaluate performances different image models full answer image question pair single word multiple words. work subset containing samples single word answer created employed comparison proposed model signiﬁcantly outperforms multiworld approach neural-image-qa terms accuracy wups. wups.. speciﬁcally proposed model achieves improvement compared neural-image-qa terms accuracy multiple words single word. results shown table. demonstrate model accurately model image question well interactions thus yields better performances image task. moreover language approach resorts question performs inferiorly approaches jointly model image question. image component thus great help image task. also performances multiple words generally inferior single word. daquar-reduced dataset besides neuralimage-qa approach model also compared single word. moreover methods introduced also reported compared. guess model randomly outputs answer according question type. treats word question equally sums word vectors predict answer logistic regression. lstm performed question without considering image similar language approach img+bow performs multinomial logistic regression based image feature vector obtained summing word vectors question. vis+lstm -vis+blstm versions model. vis+lstm single lstm encode image question direction -vis+blstm uses bidirectional lstm encode image question along directions fully exploit interactions image word question. observed -vis+blstm outperforms vis+lstm margin. observation also found coco-qa dataset shown table demonstrating bidirectional lstm accurately model interactions image question single lstm. proposed model signiﬁcantly outperforms competitor models. speciﬁcally case single word proposed achieves nearly improvement terms accuracy best competitor model -vis+blstm. coco-qa dataset img+bow outperforms vis+lstm -vis+blstm demonstrating img+bow simple multinomial better model interactions image question compared lstms vis+lstm vis+blstm. averaging vis+lstm -vis+blstm img+bow full model developed summarizes interactions image question different perspectives thus yields much better performance. shown table proposed model outperforms competitor models terms three evaluation measurements even full model. reason image representation highly semantic meaning interact high semantic components question. model ﬁrstly uses convolutional architectures compose words highly semantic representations. afterwards composed highly semantic representations convolutional architectures exploit relations interactions answer prediction. such model well model relations image question thus obtain best performances. inﬂuence multimodal convolution layer image question needs considered together image multimodal convolution layer proposed model fuses image question representations together also learns interactions relations multimodal inputs question prediction. effect multimodal convolution layer examined follows. image question representations simply concatenated together input softmax layer answer prediction. train network manner proposed model. results provided table firstly observed without multimodal convolution layer performance image dropped. comparing simple concatenation process fusing image question representations proposed multimodal convolution layer well exploit complicated relationships image question representations. thus better performance answer prediction achieved. secondly approach without multimodal convolution layer outperforms img+bow vis+lstm -vis+blstm terms accuracy. better performance mainly attributed composition ability sentence cnn. even simple concatenation process image representation composed question representation fuse together better image model. inﬂuence image effectiveness sentence observed table without image content accuracy human answering question drops therefore image content critical image task. work question representation obtained sentence predict answer. results listed table firstly without image representation performance proposed signiﬁcantly drops demonstrates importance image component image secondly model consisting sentence performs better lstm image indicates sentence effective generate question representation image compared lstm bow. recall model without multimodal convolution layers outperforms img+bow vis+lstm -vis+blstm explained above. incorporating image representation better modeling ability sentence demonstrated. moreover examine language modeling ability sentence follows. words test questions randomly reshufﬂed. reformulated questions sent sentence check whether sentence still generate reliable question representations make accurate answer predictions. randomly reshufﬂed questions results coco-qa dataset accuracy wups. wups. respectively signiﬁcantly inferior natural-language like questions. result indicates sentence possesses ability modeling natural questions. sentence uses convolution process compose summarize neighboring words. reliable ones higher semantic meanings pooled composed reach ﬁnal sentence representation. such sentence compose natural-language like questions reliable high semantic representations. paper proposed model address image problem. proposed model relies convolutional architectures generate image representation compose consecutive words question representation learn interactions relations image question answer prediction. experimental results public image datasets demonstrate superiority proposed model state-of-the-art methods.", "year": 2015}