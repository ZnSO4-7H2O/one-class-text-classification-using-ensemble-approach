{"title": "A New Data Representation Based on Training Data Characteristics to  Extract Drug Named-Entity in Medical Text", "tag": ["cs.CL", "cs.AI", "cs.LG", "cs.NE", "68Txx", "I.2.4"], "abstract": "One essential task in information extraction from the medical corpus is drug name recognition. Compared with text sources come from other domains, the medical text is special and has unique characteristics. In addition, the medical text mining poses more challenges, e.g., more unstructured text, the fast growing of new terms addition, a wide range of name variation for the same drug. The mining is even more challenging due to the lack of labeled dataset sources and external knowledge, as well as multiple token representations for a single drug name that is more common in the real application setting. Although many approaches have been proposed to overwhelm the task, some problems remained with poor F-score performance (less than 0.75). This paper presents a new treatment in data representation techniques to overcome some of those challenges. We propose three data representation techniques based on the characteristics of word distribution and word similarities as a result of word embedding training. The first technique is evaluated with the standard NN model, i.e., MLP (Multi-Layer Perceptrons). The second technique involves two deep network classifiers, i.e., DBN (Deep Belief Networks), and SAE (Stacked Denoising Encoders). The third technique represents the sentence as a sequence that is evaluated with a recurrent NN model, i.e., LSTM (Long Short Term Memory). In extracting the drug name entities, the third technique gives the best F-score performance compared to the state of the art, with its average F-score being 0.8645.", "text": "essential task information extraction medical corpus drug name recognition. compared text sources come domains medical text special unique characteristics. addition medical text mining poses challenges e.g. unstructured text fast growing terms addition wide range name variation drug. mining even challenging lack labeled dataset sources external knowledge well multiple token representations single drug name common real application setting. although many approaches proposed overwhelm task problems remained poor f-score performance paper presents treatment data representation techniques overcome challenges. propose three data representation techniques based characteristics word distribution word similarities result word embedding training. first technique evaluated standard model i.e. second technique involves deep network classifiers i.e. third technique represents sentence sequence evaluated recurrent model i.e. lstm extracting drug name entities third technique gives best f-score performance compared state average f-score rapid growth information technology provides rich text data resources areas including medical field. abundant amount medical text data used obtain valuable information benefit many purposes. understanding drug interactions example important aspect manufacturing medicines controlling drug distribution market. process produce medicinal product expensive complex task. many recent cases however many drugs withdrawn market discovered interaction drugs hazardous health challenging studies text mining area. difficulties text information extraction keeps increasing increasing size corpora continuous growth humanâ€™s natural language unstructured formatted data among valuable information medical entities drug name compound brand; disease name relations drug drug interaction drug compound relation. need suitable method extract information. embed abundant data resources; however many problems tackled. example large data size unstructured format choosing right limitation annotated datasets. entity drug name recognition primary task medical text data extraction since drug finding essential element solving information extraction problems among derivative work drug name extractions drug-drug interaction drug adverse reaction applications location event time drug name entity recognition faces challenges. first drug name entities usually unstructured texts number entities quickly growing time. thus hard create dictionary always includes entire lexicon date second naming drug also widely varies. abbreviation acronym increase difficulties determining concepts referred terms. third many drug names contain combination non-word word symbols .fourth problem drug name extraction single drug name might represented multiple tokens complexity extracting multiple tokens drugs researchers even ignores case medline drugbank training reason multiple tokens drug drug names. different another domain i.e. entity names biomedical field usually longer. fifth cases drug name combination medical general terms. sixth lack labeled dataset another problem; solved extracting drug name entities. entities contained sentences medical texts. first second techniques created instance dataset tuple formed vectors words. first technique tuple constructed sentences treated sequence whereas second technique tuple made sentence treated sequence. first second techniques evaluated standard mlp-nn model perfomed first experiment. second experiment second data representation technique also applied model i.e. sae. third data representation assumes text sequential entities assessed recurrent model lstm. three data representation techniques based wordvec value characteristics i.e. cosine euclidean distance vectors words. first second techniques apply three different scenarios select possible words represent drug name. scenarios based characteristics training data i.e. drug words distribution usually assumed smaller frequency appearance dataset sentences. drug name candidate selections follows. first case test dataset taken. second case test dataset selected. third case test dataset selected clustering test dataset clusters. trained word embedding formulate sequence data representation applied rnn-lstm. used euclidian distance current input previous input additional feature besides vector words. study vector words provided word embedding methods proposed mikolov obtained semeval competition task http//www.cs.york.ac.uk/semeval-/task.html also used format medical texts english sentences contain drug name entities. extracting drug entity names dataset data representation techniques give best performance f-score values whereas third technique lstm gives best f-score i.e. average f-score third technique i.e. best performance compared previous methods. rest sections paper organized follow section explain previous works dealing name entity extraction medical text sources. framework approach methodology overcome challenges drug name extraction presented section section also describes dataset materials experiment scenarios. section discusses experiment results analysis section explains achievement shortcoming prospects study. section also describes several potential explorations future research. entity recognition biomedical text active research many methods proposed. example gurinder summarizes survey various entity recognition approaches. approaches categorized three models dictionary based rule based learning based methods dictionary based approach uses list terms assist predicting targeted entity included predicted group. although overall precision accurate recall poor since anticipate less terms. rule-based approach defines certain rule describes pattern formation surrounding targeted entity. rule syntactic term lexical term. finally learning approach usually based statistical data characteristics semantic evaluation task best-reported performance challenge f-score studies extract drug names still continue many approaches proposed. crf-based learning common method utilized clinical text information extraction. used best participants semeval challenges clinical text external knowledge aimed increase performance author uses chebi i.e. dictionary small molecular entities. best-achieved performance f-score proposed study author utilizes wordvec representation learning model dinto drug ontology. wordvec representation targeted drug treated current token context windows consists three tokens left three tokens right. additional features included data representation tags lemma windows context orthography feature uppercase lowercase mixed cap. author also used wikipedia text additional resource perform wordvec representation training. best f-score value extracting drug name provided method inside output) annotation token extracting named entity clinical text presented framework active learning approach sequential process initial model generation querying training iteration. algorithm approach also studied features algorithm formulated based token linguistics feature semantic feature. best f-score achieved proposed method entropy-multinomial classifier handcrafted feature extract drug entity. .they classified drug non-drug based token features formulation tokens windows current token hand-crafted features. another approach discovering valuable information clinical text data adopts event-location extraction model examined bjornoe classifier predict drug non-drug entity applied drugbank dataset. best performance achieved method f-score. drawback approach deals single token drug name. overcome ambiguity problem mined medical corpus segment representation method also proposed keretna approach treats word belonging three classes i.e. ambiguous class. ambiguity class member determined identifying whether word appears context not. word falls ambiguous class. three class segments found applied classifier learning. related approach previous work propose pattern learning utilizes regular expression surrounding drug names compounds performance method quite good average f-score limitation dealing unstructured text data. drawbacks need addressed. general almost state methods works based ad-hoc external knowledge always available. requirement handcrafted feature another difficult constraint since datasets contain feature. additional challenge remained unsolved words characteristics need external knowledge additional handcrafted features. overcome multiple tokens problem propose technique treats target entity tokens rather treating target entity single token surrounded tokens used addressing tokens single sample proposed method predict whether tokens drug name not. first experiment evaluate first second data representation techniques apply learning model. second scenario choose second technique gave best result apply different machine learning methods sae. third experiment examined third data representation technique utilizes euclidian distance successive words certain sentence medical text. third data representation lstm model. based resulted f-score value second experiment gives best performance. study using wordvec value characteristics conducted three experiments based different data representation techniques. first second experiment examine conventional tuple data representation whereas third experiment examines sequence data representation. describe organization three experiments section. general proposed method extract drug name entities study consists main phases. first phase data representation formulate feature representation. second phase model training testing evaluation conducted evaluate performance proposed method. applied testing training data. step provides label tuple. third step candidate selection performed minimize noises since actual drug target quantity less compared nondrug name. last step performed experiment mlp-nn model result evaluation. detailed explanation step explained subsection whereas section describe training data analysis foundation proposed method. part first experiment also evaluate impact usage euclidean distance average modelâ€™s regularization. regularization term described subsection model second data representation technique illustrated figure general steps second experiment similar first differences data representation used learning model involved. second experiment used second technique learning model. tree steps third experiment. first step sequence data representation formulation provides sequence training data testing data. second step data labeling generates label training testing data. lstm experiment result evaluation performed third step. detail description tree step presented subsection subsection well. sentences dataset contains four data types i.e. drug group brand drug-n. sentence contains none four types type value null. study extracted drug drug-n. overall drugbank medline datasets quantity drug name target less compared non-drug target. segura present first basic statistics dataset. detailed exploration regarding token distribution training dataset described section. medline sentences training dataset contains single token consists unique tokens. tokens distributions uniform dominated small part unique tokens. unique tokens arranged ranked based frequent appearances sentences quartile distribution following result presented figure represents token number total frequency represents token number total frequency represents token number total frequency represents token number total frequency figure shows majority appearances dominated small amount total tokens. targeted token rarely appear dataset. divide token collections three partitions based frequency presented table shown drug name entity targeted contained part less frequent appearances token similar pattern training data token distribution also emerged drugbank dataset illustrated figure table look specific token distributions position drug name target third part. since frequently appeared words first second parts common words stop words common words medical domain administrator patient effect dose etc. represent dataset utilized word embedding model proposed mikolov treated sentences corpus training dataset testing dataset combined. used wordvec training model cbow model context window length vector dimension result wordvec training representation word dimension vectors. base vector estimated similarities dissimilarities words. description analysis summary wordvec representation result used base reference data representation technique experiment scenarios. taking sample drug targets non-drug vector representation shown drug word similarities another drug non-drug vice versa. samples illustrated table also computed euclidean distance words. table shows average euclidean distance cosine distance drug-drug drug non-drug non-drug non-drug. values average distance show that intuitively feasible group collection word drug group non-drug group based vector representations value. drug-drug drug-drug drug-drug drug-drug drug-drug non-drug non-drug drug non-drug drug non-drug non-drug non-drug non-drug non-drug drug non-drug drug non-drug based training data word embedding analysis formulate feature representation data formatting. first second techniques overcome multiple tokens drawback left unsolved formatting single input data gram model accommodate maximum token acts single drug entity target name. tuples provided sentences training testing data. thus multi-classification approach classifies single input classes. class represents non-drug whereas classes represent drug target also identified many tokens perform drug target. identify class certain tuple belongs determined follows drug tuple tuple first token drug type. token- drug regardless whatever rest tokens tuple classified drug. kind tuple identified class token- drug token- drug regardless last tokens tuple identified class since extracted drug entity ignored token types whether group brand another common token. provide label tuple drug drug-n types tuple reference list. general sequence token tuple dataset contains sequence exactly tuple reference list members tuple dataset identified drug entity. detail algorithm used provide label tuple training data testing data described algorithm technique treats sentences sequence whereas second technique sentence processed sequence. first second techniques evaluated model. third technique treats sentences dataset sequence occurrence current token influenced previous one. treating sentence sequence data representation also classification recognition process suitable model used rnn. applied rnn-lstm third technique. drugbank training data table data samples three relevant fields i.e. sentences character drug position drug name. table illustrates portion dataset label result data table refer drug-n name field dataset dataset number identified drug whereas others classified non-drug entity. complete label illustration dataset provided first technique presented table described section value vector dimension token therefore single data represented lengths one-dimensional vector. modification surface histidine residues abolishes cytotoxic activity clostridium difficile toxin antimicrobial activity ganoderma lucidum extract alone antibiotics. hand surprisingly green gallocatechins -epigallocatechin--o-gallate theasinensin potently enhanced promoter activity naturally sentence sequence occurrence current word conditioned previous one. based wordvec value analysis shown intuitively separate drug word non-drug word euclidean distance. therefore used euclidean distance current words previous represent influence. thus current input represented concatenation wordvec value euclidian distance previous xdi. vector dimension length first values wordvector rest values euclidian distance previous. first word value lstm model task extract drug name medical data text binary classification applied word sentence. formulate word sequence class described table experiment word represents drug name identified class â€™plenaxisâ€™ â€™cytochromeâ€™ â€™p-â€™ whereas words identified class study also utilize wikipedia additional text sources wordvec training used wiki text addition used evaluate impact training data volume improving quality wordâ€™s vector. tokens drug entities target tiny part total tokens. medline dataset token drugs whereas drugbank number drug tokens major part tokens non-drug noises stop word special numerical characters. based fact propose candidate selection step eliminate noises. examine mechanisms candidate selection. first based token distribution. second formed selecting part clustering result data test. first scenario used token appears lower part total token. presented table table whereas second mechanism selected part total token tokens clustered clusters. whereas second term regularization term also called weight decay term. experiment three kinds regularization average euclidean distance. computed based word embedding vector analysis drug target non-drug distinguished looking euclidean distance. thus regularization parameter calculated learning model composed stacked undirected graph learning model associates markov random fields acts feature extractor pre-training process provides initial weights values fine-tuned discriminative process last layer. last layer formed logistic regression standard discriminative classifiers originally developed binary data observation popular type unsupervised model binary data derivative models also proposed tackle continuous/real values suggested consists input hidden output layers. particular characteristic autoencoder target output similar input. interesting structure data estimated applying certain constraint network limits number hidden units. however number hidden units larger imposed sparsity constraints hidden units sparsity constraint used enforce average value hidden unit activation constrained certain value. used model trained trained weight used initialize weight classification. considers previous input determining output current input. powerful applied dataset sequential pattern current state input depends previous time series data sentences nlp. lstm network special kind also consists layers i.e. input layer single recurrent hidden layer output layer main innovation lstm hidden layer consists memory blocks. block includes memory cells. standard form inputs connected cells gates whereas cells connected outputs. gates connected gates cells hidden layer. single standard lstm hidden layer input memory cell output gates validate proposed approach utilized drugbank medline open dataset also used previous researchers. additionally used drug label documents various drug producers regulator internet sites located indonesia following experiments part first experiment. experiments performed evaluate contribution three regularization settings described subsection arranging sentence training dataset -gram words quantity generated sample presented table training testing mlp-nn learning model test data compositions. result model performances datasets i.e. medline drugbank learning phase shown figure figure learning parameters used experiments input nodes hidden layers layer nodes sigmoid activation output nodes softmax function; learning rate momentum epochs used mini-batch scenario training batch size presented errors figure figure errors full batch i.e. mean errors mini batches. training error performance pattern however shows slight different behavior medline drugbank. medline dataset produce different results iterations. whereas training error performance drugbank almost every iteration. different pattern results probably variation quantity training data. illustrated table volume drugbank training data almost four times volume medline dataset. concluded that larger dataset contribution regularization setting significant achieving better performance. smaller dataset however performance better even iterations. first experiment data representation techniques three candidate selection scenarios experiment scenarios. result experiment applies first data representation technique three candidate selection scenarios presented table computing f-score select predicted target provided lowest error medline dataset best performance shown regularization setting error third candidate selection scenario f-score whereas drugbank achieved together regularization setting error test second candidate selection scenario f-score overall concluded drugbank experiments give best f-score performance. candidate selection scenarios also contributed improving performance found medline drugbank best achievement provided second third scenarios respectively. impact data representation technique addition wiki source wordvec training. results presented table table according obtained results presented table regularization gives best f-score. hence accordingly used regularization next experimental scenario. table presents impact data representation technique. looking f-score second technique gives better results datasets i.e. medline drugbank. providing vector word representation. results confirm addition training data improve performance. might fact targeted token drug name uncommon words whereas words used wikiâ€™s sentence commonly used words. hence addition commonly used words make difference drug token non-drug token becomes greater. mlp-nn experimental results scenario second data representation partition data selection drugbank dataset provides best performance f-score. second experiment involves learning model experiment scenario gives best results first experiment. best experiment scenario uses second data representation technique wiki text additional source wordvec training step. nodes hidden layer first also second rbms. used learning parameters follows momentum alpha= used mini-batch scenario training batch size constraints range input data value restricted original developed binary second nodes visible unit nodes hidden unit nodes output unit. used learning parameters first second respectively follows activation function sigmoid tanh; learning rate momentum sparsity target batch size aes. experiment discriminative layer i.e. layer hidden node output nodes softmax activation function. performances using medline drugbank datasets feeding models. best results medline dataset obtained using sae. drugbank gives best results. gives lower average performance datasets. lower performance probably normalization word vector value whereas original value global lstm network used presented figure single lstm block consists stacked hidden layers input node input dimension described subsection hidden layers fully connected. used sigmoid output activation function suitable binary classification. implemented peepholes connection lstm variant gate layers look cell state addition implementing peepholes connection also coupled forget input gates. detail single lstm architecture gate formula computation referred results presented section best among experiments. input data consists components word vector value euclidian distance previous input data. treating input data components adapt adding problem experiment presented jannlab tools modifications part entry conform data settings. node input layer nodes hidden layer node output layer. used parameters learning rate momentum epoch input dimension time sequence frame complete treatment drug sentence sequence representation recognition extract drug name entities best technique shown f-score performance table extraction proposed. utilize certain external knowledge achieve extraction objective. table summarizes f-score performance. among state arts third data representation technique applied lstm model outperforming. also proposed method require external knowledge. external knowledge chebi external knowledge dinto additional feature without external knowledge without external knowledge without external knowledge additional experiment also indonesian language drug label corpus evaluate methodâ€™s performance. regarding indonesian drug label could found certain external knowledge used assist extraction drug name contained drug label. presence hinderance found proposed method suitable previous approaches. drug label texts collected various sites drug distributors producers government regulators; clearly contain training data testing data drugbanks medline datasets. characteristics texts structured sentences contained data. although texts coming various sources similar kind document data cleaning step annotated dataset manually. total quantity dataset performing data representation step described subsection experiment perform times cross-validation scenario randomly selecting data training data data testing. selection scenarios provide excellent f-score excellent f-score performance probably structured sentences texts. best result experiments presented table first second experiments studied various experiment scenarios involves three investigated parameters additional wiki source data representation techniques drug target candidate selection. general wiki addition contributes improving f-score performance. additional source wordvec training enhances quality resulted wordvec. addition common words wiki difference common words uncommon words drug name becomes greater quantity drug token tokens also targeted drug entities small part total tokens. thus majority tokens noise. dealing problem second third candidate selection scenarios show contribution reduce quantity noise. since possibility extract noises reduced recall value f-score value increase well shown first second experiments results. study proposes approach data representation classification extract drug name entities contained sentences medical text documents. suggested approach solves problem multiple tokens single entity remained unsolved previous studies. study also introduces techniques tackle absence specific external knowledge. naturally words contained sentence follow certain sequence patterns i.e. current word conditioned previous words. based sequence notion treatment medical text sentences apply sequence model gives better results. study presented three data representation techniques. first second techniques treat sentence non-sequence pattern evaluated non-sequential classifier whereas third technique treats sentences sequence provide data used input sequential classifier i.e. lstm. performance application lstm models sequence data representation average f-score rendered best result compared state art. widely opened. first step improvement incorporation additional handcrafted features words position capital case beginning word type character also used previous studies presented experiments drug label document proposed methods achieved excellent performance applied structured text. thus effort make sentence dataset i.e. drugbank medline structured also elaborated. regarding lstm model sequence data representation sentences medical text future study tackle multiple entity extractions drug group drug brand drug compounds. another task potential solved lstm model drug drug interaction extraction. experiments also utilizes euclidean distance measure addition wordvec features. addition gives good f-score performance. significance embedding euclidean distance features however needs explored further. work supported higher education science technology development grant funded indonesia ministry research higher education contract /un.r/hkp../", "year": 2016}