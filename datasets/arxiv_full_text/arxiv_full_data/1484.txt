{"title": "Zero-Shot Visual Question Answering", "tag": ["cs.CV", "cs.AI", "cs.CL"], "abstract": "Part of the appeal of Visual Question Answering (VQA) is its promise to answer new questions about previously unseen images. Most current methods demand training questions that illustrate every possible concept, and will therefore never achieve this capability, since the volume of required training data would be prohibitive. Answering general questions about images requires methods capable of Zero-Shot VQA, that is, methods able to answer questions beyond the scope of the training questions. We propose a new evaluation protocol for VQA methods which measures their ability to perform Zero-Shot VQA, and in doing so highlights significant practical deficiencies of current approaches, some of which are masked by the biases in current datasets. We propose and evaluate several strategies for achieving Zero-Shot VQA, including methods based on pretrained word embeddings, object classifiers with semantic embeddings, and test-time retrieval of example images. Our extensive experiments are intended to serve as baselines for Zero-Shot VQA, and they also achieve state-of-the-art performance in the standard VQA evaluation setting.", "text": "figure test questions evaluation setting include words unseen training examples used test question and/or multiple-choice answers. setting evaluates capabilities algorithm generalization beyond training examples. demonstrate beneﬁt additional sources information pretrained intermediate representations test-time terest. ﬁnite exemplars however cover diversity world ideal system prepared consider. secondary problem approach incentive perform well benchmark datasets encourage addressing rare novel words concepts. current methods therefore designed best learn often overﬁt dataset biases. example common consider vocabulary limited frequent words answers dataset. practice thus completely discards rare concepts alone appear training all. example training question many giraffes image currently taken opportunity learn count giraffes speciﬁcally. propose opportunity instead learn count. ideal system therefore able generalize answer questions objects situations present part appeal visual question answering promise answer questions previously unseen images. current methods demand training questions illustrate every possible concept therefore never achieve capability since volume required training data would prohibitive. answering general questions images requires methods capable zero-shot methods able answer questions beyond scope training questions. propose evaluation protocol methods measures ability perform zero-shot highlights signiﬁcant practical deﬁciencies current approaches masked biases current datasets. propose evaluate several strategies achieving zero-shot including methods based pretrained word embeddings object classiﬁers semantic embeddings test-time retrieval example images. extensive experiments intended serve baselines zero-shot also achieve state-of-theart performance standard evaluation setting. task visual question answering spans ﬁelds computer vision natural language processing requiring algorithm answer previously unseen text question image. recent interest part reﬂects enthusiasm indicator progress towards deep scene understanding overarching goal computer vision ability answer truly general questions images would also constitute concrete step towards real artiﬁcial intelligence. number datasets introduced variety methods demonstrated impressive results survey). training current methods relies dataset {questionimageanswer} tuples illustrating question types applied items interest situations invqa training set. label capability zero-shot inspired task zero-shot classiﬁcation. ﬁrst contribution evaluation setting test instances include words present training set. experiments setting expose common weaknesses current systems namely poor generalization over-reliance dataset biases. show datasets contain strong biases render interpretation comparison performances difﬁcult. small number frequent words constitute large fraction correct answers exploiting statistical regularities achieves deceptively strong performance example questions starting many. three correct answer rarely zero seventeen. although biases actually present questions humans methods overﬁt biases improve benchmarks without making signiﬁcant progress towards visual scene understanding. example stateof-the-art method achieves impressive accuracy almost correct answers visualw dataset. however authors also train similar blind model answers question without analyising image achieves accuracy. second ﬁgure really illuminating ﬁrst primary implications current methods evaluating performance particularly good measure method’s ability understand visual scenes. contributions paper summarized follows. deﬁne zero-shot visual question answering problem propose corresponding evaluation setting test instance contains several unseen words i.e. words present training instance. describe evaluate extensively strategies zs-vqa including incorporating auxiliary data training test time. result large improvements zs-vqa also state-of-the-art performance standard setting recent methods variations idea joint embedding image question using deep neural network. image question passed respectively convolutional recurrent neural network produce representations image question joint space together classiﬁer output vocabulary possible answers. consult recent survey literature. systems trained end-to-end i.e. supervision solely ﬁnal output closed datasets images questions correct answers. several datasets available increased size quality remain however expensive produce thus necessarily limited size. drives increased interest using additional sources data. language side word embeddings i.e. vectors used represent words pretrained language modeling task capture semantics mapping words similar meaning similar representations. pretrained embeddings showed beneﬁt example pretrained unsupervised large corpora incorporate words necessarily present training questions/answers. simple strategy enable systems generalize words present training questions. syntactic structure language received much less attention recent work suggest explicit parsing bring useful information image side common representation uses features produced within convolutional neural network pretrained image classiﬁcation. case pretrained word embeddings leverages larger amounts data available pretraining task. methods actual output classiﬁer hidden features. exception authors language explicit intermediate representation vqa. represent image recognized attributes actions objects. paper evaluate traditional features explicit object detections. finally methods consider test-time retrieval additional data knowledge bases importantly data incorporated within learned weights network. behaviour retrieving incorporating external information learned applied test time concepts unseen training. experiment similar principle retrieving additional visual exemplars test time. comparison information knowledge bases purely textual nature. figure test questions proposed zero-shot test split visualw dataset. instance contains unseen words i.e. used training question answer. tick marks indicate correct answers among given multiple choices. butions words known issue datasets generally natural language zhang address related evaluation issues balanced dataset binary questions. contains versions question slightly different images elicit opposite answers. evaluation setting better capture system ability focus meaningful details scene. however feasible binary questions synthetic images. similar motivation zero-shot setting proposed paper advantage applicable real images. visual concepts associated images. example consider question many zebras image zero-shot training question involves zebras. images containing zebras however appear training used train auxiliary components e.g. image classiﬁer recognizes zebras. distinction reﬂects fact cnns pre-trained imagenet commonly used existing methods fact task actually interested multiple-choice training test instance tuple image question multiple answer choices question answers given text natural language. exactly answers marked correct used supervised training evaluation. dataset partitioned training evaluation test splits. table comparison original splits visualw dataset proposed zero-shot splits. proposed version removes large number words training reserving unseen words test time. least appears every test validation instance either question itself correct answer multiple choices. words used questions answers datasets follow long-tail distribution typical natural language words questions answers made words small vocabulary large number words appear infrequently. typical strategy methods focus limited vocabulary limited possible answers. makes training practically easier performance penalty remains reasonable since rare words arise small fraction test instances. however implies fundamental limitation restricted words answers. zero-shot dataset propose formed deﬁning training validation test splits telling task visualw dataset visualw subset visual genome dataset highest quality dataset currently available terms size answer distribution human performance quality multiple choice answers. deﬁne splits every validation test instance zero-shot question deﬁne using least word present training instance. zero-shot instances broken according whether unseen words appears question itself correct answer answers. three sets mutually exclusive multiple unseen words appear question answers. analysis original splits visualw shows test questions qualify zero-shot building zero-shot splits build splits hold distinct subsets words used throughout whole dataset reserve validation test splits respectively. words held-out subsets randomly selected appear less times whole dataset. ensures unseen words semantically rich opposed common verbs stop words. words typically describe ﬁne-grained categories speciﬁc concepts validation test splits formed instances containing least word reserved ensuring overlap sets. training composed remaining instances making sure original splits keep images disjoint training validation/test sets encourage overﬁtting. analysis resulting splits given table note preserve qualities original dataset e.g. approximate distribution question types. also annotate test instances whether contain unseen words question itself correct answer answers. recommend reporting accuracy whole test nondisjoint subsets. provide annotations standard splits making possible report performance zero-shot questions method trained standard splits. splits annotations available authors’ website. consider neural network straightforward architecture. main objective evaluate additional features pretrained representations inputs simple architecture lets evaluate relative isolation. method particularly include attention mechanism contrast many current approaches. application attention proposed features single obvious implementation warrant another research study own. note also proposed improvements evaluated basis relatively simple implementation. goal obtain single best performing model guide future research areas promise provide reference performances basic implementations. figure neural network follows straightforward architecture evaluate impact various features representing input question image multiple-choice answers. obtain respective ﬁxed-size vector representations concatenating bag-of-words different features. three representations passed non-linear mappings combined multiplicative order interactions. ﬁnal logistic regression combined features produces score candidate answer. network architecture similar baselines evaluated studies overall principle inputs i.e. question image candidate answers vector representations common space. mappings produce representations learned interactions elements space capture semantic compatibility. baseline represents question words word represented ﬁxed-length vector look-up table associates every possible word learned vector representation average non-empty vectors question words. refer representation learned word embedding. additional features described below concatenated required giving ﬁnal question features candidate answer treated similarly using optionally concatenated additional features giving answer features multiple choice image represented global features dimension extracted last pooling layer resnet- pretrained image recognition imagenet. note common practice already form transfer learning opposed baseline language representation learns word embeddings scratch. features optionally concatenated additional features described below giving image features learned weights biases logistic function. score represents compatibility between input question image candidate answer. weights biases embeddings trained end-to-end minimize cross-entropy loss using labels correct candidate answers incorrect multiple choices. improved language representations pretrained word embeddings compare learned word embeddings embeddings pretrained language modeling task. common practice advantages. first pretrained embeddings reﬂect word co-occurrences shown empirically capture complex semantic relationships vector space. second pretraining task unsupervised embeddings learned large amounts data covering much richer vocabulary training set. concretely evaluate glove embeddings various dimensions pretrained wikipedia gigaword newswire corpus. sharing embeddings across stems propose sharing embeddings across words stem hypothesize semantic meaning words often important context verb conjugation plural forms nouns. procedure reduces number unique embeddings learned moreover novel words test time appeared another form declension training associated relevant embedding. obvious drawback approach potentially associate representation multiple words different meanings e.g. runner runs runnable. exacerbates issue polysemy already present standard word embeddings. homonyms indeed mapped single thus necessarily ambiguous representation. concretely replace every word input question and/or answer stem obtained either classical porter algorithm dictionary-based algorithm stanford corenlp library sharing embeddings questions answers baseline implementation learns independent embeddings words questions answers. hypothesize inputs could beneﬁt similar representations compare independent embeddings versus common shared one. latter reduces number parameters learn forces semantics questions answers represented identically. test-time exemplar retrieval hallmark feature z.s.–capable methods extensibility novel concepts without retraining. implement capability retrieving test-time exemplar images words test questions and/or answers. concretely build additional representation question and/or candidate answers retrieving top-k images words google images extract global features images average words exemplars. resulting vector dimension referred visual embedding. improved image representations explicit object detection addition global features represent input image consider using explicit detections objects scene. obtain candidate detection yolo method pretrained pascal detections scores class detected object. keep detections certain threshold turn detections ﬁxedsize vector similar words questions associate possible classes learned embedding embeddings detections. semantic object class embeddings detections presented asociate semantic prior classes considered detector. classes however known name experiment associating detections pretrained glove word embedding recognized class. simply replace look-up table pretrained embeddings words corresponding class names. refer representation semantic class embeddings. order embeddings experiment idea imposing order representation question/image candidate answers proposed vendrov vision language tasks whereas baseline uses symmetric product relate idea order embedding place hierarchy modalities measuring compatibility antisymmetric operation details). practically replace imposes partial order spaces candidate answers placed higher hierarchy thus deemed general particular pair question/image. crucially experiment reversed ordering swapping above results dramatically lower performance experiments conduct extensive experiments original zero shot splits visualw dataset. hypothesized premise observe different behaviors cases proposed improvements different impact overall average performance settings. experiment considers variation time baseline model including pretrained word embeddings dimension unless otherwise noted. pretrained word embeddings common practice large positive impact thus constitute facto reference fair comparisons additional improvements. implementation details provided supplementary material. masking inputs ﬁrst obtain indication difﬁculty datasets training model limited input masking question and/or image. forces model rely dataset biases. indeed masking question image input multiple-choice answers model learn pick common ones seen training. observed strategy sufﬁcient achieve high performance standard splits. less effective z.s. setting giving example masking question standard z.s. settings respectively words answers z.s. setting cannot easily guessed. improved representations pretrained word embeddings compare pretrained glove word embeddings dimension embedding learned scratch dimension pretrained word embeddings learned ones largest impact tested improvements standard z.s. settings appreciable correlation accuracy dimension embedding. pretrained embeddings beneﬁcial represent candidate answers questions explained larger amount data available learn latter. evaluate ﬁne-tuning pretrained embeddings relative learning rate network parameters. ﬁne-tuning always proves beneﬁcial z.s. setting favors smaller learning rate suppose ﬁne-tuning rate otherwise signiﬁcantly alter embeddings frequent training words. remaining model co-adapts embeddings rare zero-shot words however updated much leading negative performance impact z.s. setting. finally oberve ﬁne-tuning common shared embedding question answer performs worse independent ones. conclude information captured pretrained embeddings relevant perfectly adequate representation cannot capture ideal semantics questions answers. sharing embeddings across word stems obtain clear beneﬁt sharing embeddings across words common stem procedure reduces number unique embeddings regularizes learning addresses novel words test time mapping known stems. observed impact indeed larger z.s. setting standard one. quality stemming algorithm matter. classical rule-based porter algorithm performs worse baseline improvements obtained modern algorithm test-time exemplar retrieval evaluate proposed visual embeddings representing question candidate answers both. obtain advantage z.s. setting correlated number retrieved examples. beneﬁt appreciable including visual embeddings question answers. indicates network succeed learning correlate visual features input image visual embeddings visual embeddings question answers. possible culprit different nature retrievals google images visualw dataset. surprisingly visual embeddings impact performance negatively standard setting. suspect language cues dataset biimprovements word stemming corenlp order embeddings data augmentation ratio visual emb. exemplars object det. theshold obj. det. class emb. augm. augm table quantitative results standard zero-shot splits visualw dataset proposed improvements generally larger impact z.s. setting. combination proposed improvements signiﬁcantly outperform state-of-the-art. ases exploited standard setting reliable visual embeddings. inclusion latter inference results negative impact frequent enough hurt overall performance. z.s. setting balance shifted test cases beneﬁt visual embeddings resulting beneﬁt overall performance. straightforward implementation using exemplars hints potential beneﬁts. obvious extensions include applying prominent words retrieving exemplars complete expressions test-time novel exemplars akin setting one-shot few-shot recognition methods could adapted here. explicit object detections detections different levels recall yolo varying threshold minimum detection score optimal trheshold lies tight range recall misses important objects high recall overwhelm system irrelevant detections open research question better integrate detections possible attention mechanisms. optimal threshold obtain minor improvement proposed semantic class embeddings. order embeddings proposed order embeddings signiﬁcantly improves symmetric interaction features. crucially verify improvement caused actual order imposed embeddings merely different interactions. replace proposed order reverse results performance well baseline data augmentation propose simple form data augmentation additional training examples incorrect answers. model ultimately measures compatibility question/image candidate answer intuition expand training combinations drawn randomly within mini-batches form additional incorrect candidate answers. procedure proves beneﬁcial larger relative improvement z.s. setting. augmentation ratio correspond fraction additional pairs question candidate answer ﬁnally evaluate model incorporating proposed improvements achieves best performance overall standard z.s. splits. relative gains combined improvements strictly cumulative indicates overlap capability brought each. part individual gains likely attributable increased model capacity beneﬁt saturates point. standard splits best model clearly surpasses existing state-of-the-art dataset also trained baseline best models reduced training data appreciate smooth drop-off performance especially z.s. setting best method indicates good generalization which argued introduction chief objective systems. paper deﬁned setting visual question answering questions answers contain words seen training. rearranged visualw dataset allow evaluation focuses exclusively test cases. setting requires generalization capabilities leads honest evaluation deep image understanding. setting also motivates alternative strategies. showed additional auxiliary data used pretraining language visual representations well test time beneﬁcial zs-vqa traditional setting well. extensions strategies constitute promising directions future research.", "year": 2016}