{"title": "Using Artificial Bee Colony Algorithm for MLP Training on Earthquake  Time Series Data Prediction", "tag": ["cs.NE", "cs.AI", "cs.LG"], "abstract": "Nowadays, computer scientists have shown the interest in the study of social insect's behaviour in neural networks area for solving different combinatorial and statistical problems. Chief among these is the Artificial Bee Colony (ABC) algorithm. This paper investigates the use of ABC algorithm that simulates the intelligent foraging behaviour of a honey bee swarm. Multilayer Perceptron (MLP) trained with the standard back propagation algorithm normally utilises computationally intensive training algorithms. One of the crucial problems with the backpropagation (BP) algorithm is that it can sometimes yield the networks with suboptimal weights because of the presence of many local optima in the solution space. To overcome ABC algorithm used in this work to train MLP learning the complex behaviour of earthquake time series data trained by BP, the performance of MLP-ABC is benchmarked against MLP training with the standard BP. The experimental result shows that MLP-ABC performance is better than MLP-BP for time series data.", "text": "rtificial neural networks novel powerful artificial tool suitable solving combinatorial problems prediction classification anns used extensively solving universal problems intelligently like continuous discrete clustering anns applied different optimisation mathematical problems classification object image recognition signal processing seismic events prediction forecasting bankruptcy tsunami intensity earthquake level different techniques used optimal network performance training anns evolutionary algorithms genetic algorithms partial swarm optimisation differential evolution colony backpropagation algorithm techniques used initialisation optimal weights parameters backpropagation algorithm accepted algorithm used training main task algorithm error using backpropagation minimising output processing accuracy approximation depends selection proper weights neural networks high success rate solving many complex problems still drawbacks especially setting parameter values like initial values connection weights value learning rate momentum. network topology carefully selected algorithm trapped local minima might lead slow convergence even network failure. order overcome disadvantages standard many global optimisation populationbased techniques proposed training improved bp-ant colony artificial colony algorithm populationbased algorithm provide best possible solutions different mathematical problems using inspiration techniques nature common feature population-based algorithms population consisting difficulty customised applying agents solutions depending robustness. therefore population encouraged towards improved solution areas solution space. population-based categorised sections namely evolutionary algorithm si-based algorithm major plan underlying combination take weight matrices anns individuals change weights means operations crossover mutation error produced anns fitness measure guides selection. si-based algorithm advantage global optimisation easy successfully used solving combinatorial optimisation problems clustering training problem self-organising highly different computational mathematical problems. algorithm easily understandable technique training classification problems algorithm uses randomly selected natural techniques colony train optimal weights study algorithm used successfully train earthquake time series data prediction task. performance algorithm compared standard algorithm. paper organised follows brief review algorithms given section section respectively. proposed algorithm training testing network using algorithm detailed section section contains prediction earthquake event. results discussion discussed section finally paper concluded section solve different combinatorial problems also known feed forward neural networks first introduced non-linear successfully applied different combinatorial problems. mostly used information processing pattern recognition prediction seismic activities. section mlp’s characteristics interaction seismic signals explained. works universal approximation inputs signal propagates forward direction. highly used tested different problems time series prediction function approximation error iteration; weights connections iteration; desired output node; actual value output node; number output nodes; number patterns. optimisation target minimise objective function optimising network weights since last decades swarm intelligence focus many researches unique behaviour inherent social insects bonabeau defined attempt design algorithm distributed problem-solving devices inspired collective behaviour social insect colonies animal societies mainly focused behaviour social insects alone termites bees wasps different species. however swarm considered collection interacting agents individuals. ants individual agents immune system considered group cells molecules well crowd swarm people popular population-based stochastic optimisation algorithms adapted solution neighbourhood random number range evaluate them. apply greedy selection process process calculate probability values solutions means fitness values using formula normalise values produce solutions onlookers solutions selected depending evaluate apply greedy selection process onlookers determine abandoned solution exists replace randomly produced solution scout using following equation proposed flowchart algorithm earthquake time series data prediction given figure figure cycle search consists three steps initialisation colony foods three control parameters number food sources equal number employed bees onlooker bees value limit maximum cycle number mlp-abc algorithm. initialisation weights compared output best weight cycle selected scout bees’ phase. bees would continue searching last cycle find best weights networks. food source nectar neglected bees replaced food artificial colony algorithm proposed optimisation classification problem solution based intelligent foraging behaviour honey swarm therefore successful robust multimodal functions included respect algorithm provides solution organised form dividing objects different tasks employed bees onlooker bees scout bees. three bees/tasks determine objects problems sharing information others bees. common duties artificial bees follows employed bees employed bees multidirectional search space food source initialisation area. information possibilities find food source solution space. sharing information onlooker bees performed employee bees. employed produces modification source position memory discovers food source position. provided nectar amount source higher previous source employed memorizes source position forgets one. onlooker bees onlooker bees evaluate nectar amount obtained employed bees choose food source depending probability values calculated using fitness values. purpose fitness-based selection technique used. onlooker bees watch dance hive bees select best food source according probability proportional quality food source. scout bees scout bees select food source randomly without experience. nectar amount food source higher previous source memory memorise position forget previous position. whenever employed bees food source food source well again become scout bees food source memorising best path. detailed pseudocode algorithm shown follows source scout bees. every would produce solution area network greedy selection would decide best food source position. suppose neglected source foods area limited range applied randomly initialised evaluation. operation defined using equation every would produce evaluated solution area network greedy selection decided best food source position. food source equal better nectar food source replaced food source memory. otherwise food source retained memory. basic idea scheme agents bees search best combination weights network. steps finding optimal weights network shown proposed algorithm framework figure figure shows find select best weights replace previous one. greedy selection applied sets values best scout bees randomly selected. research real-time series data seismic event earthquake selected training testing. data southern california earthquake data center holdings selected data included local regional quarry-blast events epicentres latitudes longitudes -.e. four main earthquake parameters namely depth earthquake time occurrence geographical area magnitude earthquakes. significant parameter earthquake magnitude richter scale used simulation earthquake magnitude prediction. data obtained scec website used define input classes test mlp-abc model proposed research. earthquake record southern california january divided fifty data sets day. networks tested prediction earthquake magnitude horizon horizon five mlp-abc mlpbp. neural networks used successfully solve complicated pattern recognition classification problems different domains satellite data data financial forecasting recently also applied earthquake prediction using different models backpropagation neural networks radial-basis function recurrent probabilistic models mostly seismicity indicators parameters. models limited predict earthquake magnitude therefore mlpabc predict magnitude order evaluate performance proposed train benchmark earthquake time series data scheme techniques simulation experiments performed core intel workstation using matlab software. comparison standard training algorithms discussed based simulation results implemented matlab california earthquake data year used taken http//www.data.scec.org/. earthquake parameter magnitude used train using algorithm. data divided datasets training testing. learning rate momentum respectively. noted range weights different experimentations mlp-bp mlp-abc. weight values mlp-abc initialised evaluated fitted using algorithm weight values mlp-bp adjusted range randomly. simulation parameters taken given table besides that minimum value mean square errors selected testing. stopping criteria minimum error mlp-bp mlp-abc stopped mcn. trained inputs hidden output node varying respectively. experiment trials performed training mlp-abc. case started different number parameters random population foods. sigmoid function used activation function network output. value limit equal foodnumber dimension problem foodnumber half colony size number input hidden output nodes neural network running time varied performance stable important designation neural networks current state specific rules decision number hidden nodes. finally mean square errors normalised mean square error calculated mlp-bp mlp-abc algorithms. simulation results showed effectiveness efficiency algorithm. comparison simulation different network structures presented table network parameter objective function evaluation runtimes network shape epochs presented table table maximum cycle numbers less maximum epochs mlp-abc training increases. network structure employed experimentation started inputs hidden output layer four inputs four hidden outputs nodes contained nmse training mlp-abc mlp-bp algorithm earthquake data. table best result network structure. also easily seen proposed algorithm outperforms mlp-bp algorithm training earthquake time series data nmse whereas mlp-bp falls behind nmse process convergence global minima seen figure figure mlp-abc mlp-bp respectively. best results network structure training testing mlpbp mlp-abc given figures respectively. seen figures algorithm prediction follows actual trend training testing phases. overall algorithm shown percent accuracy time series earth quake data mlp-bp algorithm. meanwhile mlp-bp shows accuracy significantly lower mlp-abc. algorithm combines exploration exploitation processes successfully proves high performance training earthquake time series data prediction. powerful ability searching global optimal solution. proper weights algorithms speed initialisation improve prediction accuracy trained nns. simulation results show proposed algorithm successfully train real-time data prediction purpose extends quality given approach. performance compared traditional algorithm. shows significantly higher results backpropagation experiment. also shows higher accuracy prediction. proposed frameworks successfully predicted magnitude earthquake. liao s.-h. c.-h. \"artificial neural networks classification clustering methodologies applications literature analysis expert systems applications ghazali jaafar hussain \"non-stationary stationary prediction financial time series using dynamic ridge polynomial neural network.\" neurocomputing j.connor l.atlas recurrent neural networks andtime series prediction ieee international joint conference neural networks york carrasco pato comparison discrete continuous neural network approaches solve class/teacher timetabling problem.\" european journal operational research chen guojin; miaofen \"application neural image definition recognition\" signal networks processing ieee international conference nov. ./icspc.. leung member chow w.s. hybrid global learning algorithm based global search least squares techniques backpropagation networks neural networks. international conference vol. y.-p. m.-g. evolving neural networks using hybrid colony optimization algorithms. advances neural networks isnn wang zurada b.-l. springer berlin heidelberg. d.e. rumelhart j.l. mcclelland research group parallel distributed processing explorations microstructure cognition vols. darvis. karaboga idea based honey swarm numerical optimization technique report- erciyes university engineering facultycomputer engineering department http//earthquake.usgs.gov/earthquakes/recenteqsww/ l.n. castro f.j. zuben artificial immune systems part basic theory applications technical report feec/unicamp brazil. wang qiang fast method implicit surface reconstruction based radial basis functions network scattered points. international journal neural systems mayorga carrera radial basis function network approach forthe computational inverse continuous time variant functions. international journal neural systems habib shah ph.d student universiti hussein malaysia since current research focuses optimization artificial neural networks using swarm intelligence algorithms. masters computer science federal urdu university arts science technology karachi pakistan bachelors computer science university malakand pakistan currently deputy dean faculty information technology multimedia universiti hussein malaysia graduated ph.d. degree school computing mathematical sciences liverpool john moores university united kingdom topic higher order neural networks financial time series prediction. earlier completed m.sc. degree computer science universiti teknologi malaysia received b.sc. degree computer science universiti sains malaysia rozaida joined academic staff uthm. research area includes neural networks data mining financial time series prediction data analysis physical time series forecasting fuzzy logic. nazri mohd nawi received b.s.degree computer science university science malaysia penang malaysia. m.sc. degree computer science received university technology malaysia skudaijohor malaysia. received ph.d. degree mechanical engineering department swansea university wales swansea. currently associate professor software engineering department universiti hussein malaysia research interests optimization datamining networks.", "year": 2011}