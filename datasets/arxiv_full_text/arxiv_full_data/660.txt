{"title": "Hierarchical Attentive Recurrent Tracking", "tag": ["cs.CV", "cs.AI", "cs.NE"], "abstract": "Class-agnostic object tracking is particularly difficult in cluttered environments as target specific discriminative models cannot be learned a priori. Inspired by how the human visual cortex employs spatial attention and separate \"where\" and \"what\" processing pathways to actively suppress irrelevant visual features, this work develops a hierarchical attentive recurrent model for single object tracking in videos. The first layer of attention discards the majority of background by selecting a region containing the object of interest, while the subsequent layers tune in on visual features particular to the tracked object. This framework is fully differentiable and can be trained in a purely data driven fashion by gradient methods. To improve training convergence, we augment the loss function with terms for a number of auxiliary tasks relevant for tracking. Evaluation of the proposed model is performed on two datasets: pedestrian tracking on the KTH activity recognition dataset and the more difficult KITTI object tracking dataset.", "text": "class-agnostic object tracking particularly difﬁcult cluttered environments target speciﬁc discriminative models cannot learned priori. inspired human visual cortex employs spatial attention separate where what processing pathways actively suppress irrelevant visual features work develops hierarchical attentive recurrent model single object tracking videos. ﬁrst layer attention discards majority background selecting region containing object interest subsequent layers tune visual features particular tracked object. framework fully differentiable trained purely data driven fashion gradient methods. improve training convergence augment loss function terms number auxiliary tasks relevant tracking. evaluation proposed model performed datasets pedestrian tracking activity recognition dataset difﬁcult kitti object tracking dataset. computer vision task class-agnostic object tracking challenging since target-speciﬁc model learnt priori model handle target appearance changes varying lighting conditions occlusion. make even difﬁcult tracked object often constitutes small fraction visual ﬁeld. remaining parts contain distractors visually salient objects resembling target hold relevant information. despite fact recent models often process whole image exposing noise increases associated computational cost heuristic methods decrease size search regions. contrast human visual perception process visual ﬁeld entirety rather acknowledges brieﬂy focuses processing small fractions thereof visual attention. attention mechanisms recently explored machine learning wide variety contexts often providing capabilities machine learning algorithms improve efﬁciency performance state-of-the-art machine learning benchmarks architecture much simpler mechanisms found human visual cortex attention also long studied neuroscientists believe crucial visual perception cognition since inherently tied architecture visual cortex affect information inside whenever visual stimulus present receptive ﬁeld neuron stimuli compete computational resources limited processing capacity. visual attention lead suppression distractors reducing size receptive ﬁeld neuron increasing sensitivity given location visual ﬁeld figure kitti image ground-truth predicted bounding boxes attention glimpse. lower corresponds hierarchical attention model layer extracts attention glimpse layer uses appearance attention build location layer uses location suppress distractors visualised also amplify activity different parts cortex specialised processing different types features leading response enhancement features functional separation visual cortex apparent distinct processing pathways. leaving sensory inputs enter primary visual cortex split dorsal stream responsible estimating spatial relationships ventral stream targets appearance-based features inspired general architecture human visual cortex role attention mechanisms work presents biologically-inspired recurrent model single object tracking videos tracking algorithms typically simple motion models heuristics decrease size search region. interesting whether neuroscientiﬁc insights computational efforts thereby improving efﬁciency performance single object tracking. worth noting visual attention induced stimulus bottom-up fashion back-projections brain regions working memory top-down inﬂuence. proposed approach exploits property create feedback loop steers three layers visual attention mechanisms hierarchical attentive recurrent tracking framework figure ﬁrst stage immediately discards spatially irrelevant input later stages focus producing deictic ﬁlters emphasise visual features particular object interest. factoring problem constituent parts arrive familiar statistical domain; namely maximum likelihood estimation follows interest estimating distribution object locations sequence images given initial location whence tracking commenced. formally given sequence images rh×w× initial location tracked object given bounding conditional probability distribution factorises threefold firstly hierarchy attention mechanisms leads suppressing distractors computational efﬁciency introduced. secondly biologically plausible combination attention mechanisms recurrent neural networks presented object tracking. finally attentionbased tracker demonstrated using real-world sequences challenging scenarios previous recurrent attentive trackers failed. next brieﬂy review related work describing information ﬂows components hierarchical attention section section details losses applied guide attention. section presents experiments kitti datasets comparison related neural network based trackers. section discusses results intriguing properties framework section concludes work. code results available online. related work number recent studies demonstrated visual content captured sequence spatial glimpses foveation paradigm intriguing property computational complexity proportional number steps opposed image size. furthermore fovea centralis retina primates structured maximum visual acuity centre decaying resolution towards periphery cheung show spatial attention capable zooming regular grid sampling sufﬁcient. jaderberg introduced spatial transformer network provides fully differentiable means transforming feature maps conditioned input itself. eslami form attention combination recurrent neural network sequentially locate identify objects image. moreover eslami latent variable estimate presence additional objects allowing adapt number time-steps based input. spatial attention mechanism based dimensional gaussian grid ﬁlters fully differentiable biologically plausible stn. whilst focusing speciﬁc location merits focusing particular appearance features might important. policy feedback connections learn adjust ﬁlters convolutional neural network thereby adapting features present current image improving accuracy brabandere introduced dynamic ﬁlter network ﬁlters computed on-the-ﬂy conditioned input features reduce model size without performance loss. karl showed input-dependent state transitions helpful learning latent markovian state-space system. focus work follow concept estimating expected appearance tracked object. context single object tracking attention mechanisms rnns appear perfectly suited success mostly limited simple monochromatic sequences plain backgrounds cheung applied stns attention mechanisms real-world object tracking failed exploding gradients potentially arising difﬁculty data. ning achieved competitive performance using features object detector inputs long-short memory network requires processing whole image time-step. recent state-of-the-art trackers employ convolutional siamese networks seen unrolled time-steps methods explicitly process small search areas around previous target position produce bounding offset correlation response maximum corresponding target position acknowledge recent work gordon employ based model explicit cropping warping form non-differentiable spatial attention. work presented paper closest share similar spatial attention mechanism guided effectively learn motion model spans multiple time-steps. next section describes additional attention mechanisms relation biological counterparts. hierarchical attention figure hierarchical attentive recurrent tracking framework. spatial attention extracts glimpse input image ventral stream extract appearance-based features dorsal stream computes foreground background segmentation attention glimpse masked features contribute working memory lstm output used figure architecture appearance attention. implemented shared among dorsal stream ventral stream symbol represents hadamard product implements masking visual features locaiton map. inspired architecture human visual cortex structure system around working memory responsible storing motion pattern appearance description tracked object. quantities known would possible compute expected location object next time step. given frame however immediately apparent visual features correspond appearance description. pass would implicitly solve data association problem. non-trivial prefer model explicitly outsourcing computation separate processing stream conditioned expected appearance. results location-map making possible neglect features inconsistent memory tracked object. proceed describing information model. given attention parameters spatial attention module extracts glimpse input image apply appearance attention parametrised appearance comprised dorsal ventral streams obtain object-speciﬁc features used update hidden state lstm. lstm’s output decoded predict spatial current time-step. spatial attention driven top-down signal appearance attention depends top-down well bottom-up signals. bottom-up signals local inﬂuence depend stimulus salience given location top-down signals incorporate global context local processing. attention hierarchy enhanced recurrent connections mimics human visual cortex describe individual components system. spatial attention spatial attention mechanism similar used kahoú rh×h given input image rh×w creates matrices respectively. matrix contains gaussian row; width positions gaussians determine parts image extracted attention glimpse. formally glimpse rh×w deﬁned attention described centres gaussians variances strides centers gaussians consecutive rows matrix axis. contrast work kahoú centres strides estimated hidden state lstm variance depends solely stride. prevents excessive aliasing training caused predicting small variance leading smoother convergence. relationship variance stride approximated using linear regression polynomial basis functions training whole system. glimpse size depends experiment. appearance attention stage transforms attention glimpse ﬁxed-dimensional vector comprising appearance spatial information tracked object. architecture depends experiment. general however implement rh×w rhv×wv×cv number convolutional max-pooling layers. shared among later processing stages corresponds primary visual cortex humans processing splits ventral dorsal streams. ventral stream implemented handles visual features outputs feature maps dorsal stream implemented responsible handling spatial relationships. denote multi-layered perceptron. dorsal stream uses appearance dynamically compute convolutional ﬁlters ψa×b×c superscript denotes size ﬁlters number feature maps ﬁlters corresponding nonlinearities form convolutional layers applied output finally convolutional layer kernel sigmoid non-linearity applied transform output spatial bernoulli distribution value represents probability tracked object occupying corresponding location. location dorsal stream combined appearance-based features extracted ventral stream imitate distractor-suppressing behaviour human brain. also prevents drift allows occlusion handling since object appearance overwritten hidden state input contain features particular tracked object. outputs streams combined hadamard product. state estimation approach relies upon able predict future object appearance location therefore heavily depends upon state estimation. lstm learn trade-off spatio-temporal appearance information data-driven fashion. acts like working memory enabling system robust occlusions oscillating object appearance object rotates comes back original orientation. equations detail state updates. spatial attention time formed cumulative attention updates times learnable parameter initialised small value constrain size updates early training. since spatial-attention mechanism loss train system minimising loss function comprised tracking loss term terms auxiliary tasks regularisation terms. auxiliary tasks essential real-world data since convergence occur without them. also speed learning lead better performance simpler datasets. unlike auxiliary tasks used jaderberg relevant main objective object tracking. order limit number hyperparameters automatically learn loss weighting. loss given network parameters regularisation terms adaptive dataset weights regularisation weight present justify components loss expectations evaluated empirical mean minibatch samples tracking achieve main tracking objective base ﬁrst loss term intersection-over-union predicted bounding ground truth bounding boxes deﬁned area overlap area union invariant object image scale making suitable proxy measuring quality localisation. even though correspond probability distribution often used evaluation follow work express loss term negative figure tracking results dataset starting ﬁrst initialisation frame three boxes overlap exactly time ﬂows left right showing every frame sequence captured fps. colour coding follows figure second shows attention glimpses multiplied appearance attention. spatial attention spatial attention singles tracked object image. estimate parameters system predict object’s motion. case error especially attention glimpse contain tracked object difﬁcult recover. probability event increases decreasing size glimpse employ loss terms. ﬁrst constrains predicted attention cover bounding second prevents becoming large logarithmic arguments appropriately clipped avoid numerical instabilities appearance attention purpose appearance attention suppress distractors keeping full view tracked object focus particular pedestrian moving within group. guide behaviour loss appearance attention encourages picking tracked object. }hv×wv target function. given bounding attention outputs binary mask size output mask corresponds glimpse value equal every location bounding overlaps regularisation apply regularisation model parameters expected value dynamic parameters adaptive loss weights avoid hyper-parameter tuning follow work kendall learn loss weighting initialising weights vector ones kahoú performed pedestrian tracking experiment activity recognition dataset real-world case-study. replicate experiment comparison. code provided authors data preparation also pre-trained feature extractor. unlike them need upscale ground-truth bounding boxes factor downscale evaluation. follow authors glimpse size replicate training procedure exactly exception using rmsprop optimiser learning rate momentum instead stochastic gradient descent momentum. original work reported average test data presented work achieves average score reducing relative error almost factor two. figure presents qualitative results. since demonstrated pedestrian tracking feasible using proposed architecture proceed evaluate model challenging multi-class scenario kitti dataset consists figure curves kitti timesteps. hart presents evaluation train high resolution video sequences multiple instances class posing potential distractors. split sequences sequences train test sets respectively. images dataset much varied implement ﬁrst three convolutional layers modiﬁed alexnet original alexnet takes inputs size downsizes conv layer. since resolution would result tracking performance want upsample extracted glimpse decided replace initial stride four skip max-pooling operations conserve spatial dimensions. feature size input glimpse size apply dropout probability ventral stream comprised single convolutional layer kernel output feature maps. dorsal stream dynamic ﬁlter layers kernels size respectively feature maps each. used hidden units orthogonal initialisation zoneout probability system trained curriculum learning starting sequences length increasing sequence length every epochs epoch length decreasing increasing sequence length. used optimisation settings exception learning rate table figure contain results different variants model ratm tracker kahoú related works. spatial appearance attention loss attention parameters. apply loss appearance attention hart uses described modules; also biggest model million parameters. qualitative results form video bounding boxes attention available online implemented ratm tracker kahoú trained hyperparameters framework since closely related. failed learn even initial curriculum time-steps ratm cannot integrate frame estimate furthermore uses feature-space distance ground-truth predicted attention glimpses error measure insufﬁcient dataset rich backgrounds. better initialised feature extractor weights trained model despite passing stags curriculum achieved poor ﬁnal performance. discussion experiments previous section show possible track real-world objects recurrent attentive tracker. similar tracker kahoú approach uses additional building blocks speciﬁcally bounding-box regression loss loss spatial attention appearance attention additional loss term combines uniﬁed approach. discuss properties modules. spatial attention loss prevents vanishing gradients early experiments suggest using tracking loss causes instance vanishing gradient problem. early training system able estimate object’s motion correctly leading cases extracted glimpse contain tracked object contains part thereof. cases supervisory signal weakly correlated model’s input prevents learning. even object contained within glimpse gradient path loss function rather long since teaching signal pass previous timestep feature extractor stage. penalising attention parameters directly seems solve issue. three examples glimpses locations maps model without appearance loss attention loss forces appearance attention pick tracked object thereby suppressing distractors. figure glimpses corresponding location maps models trained without appearance loss. appearance loss encourages model learn foreground/background segmentation input glimpse. appearance attention loss necessary? given enough data sufﬁciently high model capacity appearance attention able ﬁlter irrelevant input features updating working memory. general however behaviour achieved faster model constrained using appropriate loss. figure shows examples glimpses corresponding location maps model without loss appearance attention. ﬁgure model loss appearance attention able track pedestrian even occluded another human. figure shows that penalised location might object-speciﬁc miss object entirely using appearance attention loss improve results also make model interpretable. spatial attention bias always positive condition system object’s appearance make independent starting location translate initial bounding attention parameters learnable bias create hidden state lstm corresponding visual features. experiments bias always converged positive values favouring attention glimpse slightly larger object bounding box. suggests that discarding irrelevant features desirable object tracking system whole learns trade attention responsibility spatial appearance based attention modules. conclusion inspired cascaded attention mechanisms found human visual cortex work presented neural attentive recurrent tracking architecture suited task object tracking. beyond biological inspiration proposed approach desirable computational cost increased interpretability location maps select features essential tracking. furthermore introducing auxiliary losses able scale challenging real world data outperforming predecessor attempts approaching state-of-the-art performance. future research look extending proposed approach multi-object tracking unlike many single object tracking recurrent nature proposed tracker offer ability attend object turn. acknowledgements would like thank oiwi parker jones martin engelcke discussions valuable insights neil dhir help editing paper. additionally would like acknowledge support uk’s engineering physical sciences research council programme grant doctoral training award donation nvidia titan used work also gratefully acknowledged. references brian cheung. neural attention object tracking. technol. conf. brian cheung eric weiss bruno olshausen. emergence foveal image sampling learning bert brabandere tinne tuytelaars gool. dynamic filter networks. nips eslami nicolas heess theophane weber yuval tassa david szepesvari koray kavukcuoglu geoffrey hinton. attend infer repeat fast scene understanding generative models. nips hinton geoffrey nitish srivastava kevin swersky. overview mini-batch gradient descent daniel gordon farhadi dieter fox. real-time recurrent regression networks object alex graves greg wayne malcolm reynolds harley danihelka agnieszka grabska-barwi´nska sergio gómez colmenarejo edward grefenstette tiago ramalho john agapiou adrià puigdomènech badia karl moritz hermann yori zwols georg ostrovski adam cain helen king christopher summerﬁeld phil blunsom koray kavukcuoglu demis hassabis. hybrid computing using neural network dynamic external memory. nature jaderberg volodymyr mnih wojciech marian czarnecki schaul joel leibo david silver koray kavukcuoglu. reinforcement learning unsupervised auxiliary tasks. arxiv. matej kristan jiri matas aleš leonardis michael felsberg cehovin gustavo fernández tomáš vojí gustav häger georg nebehay roman pﬂugfelder abhinav gupta adel bibi alan lukežiˇc alvaro garcia-martin amir saffari philip torr qiang wang rafael martin-nieto rengarajan pelapur richard bowden chun stefan becker stefan duffner stephen hicks stuart golodetz sunglok choi tianfu thomas mauthner tony pridmore weiming wolfgang hübner xiaomeng wang xinchu zhao shizeng yang yang yang yuezun zhaoyun chen zehua huang chen zhang zhenyu zhibin hong. visual object tracking challenge results. eccv work. david krueger tegan maharaj jános kramár mohammad pezeshki nicolas ballas rosemary anirudh goyal yoshua bengio aaron courville chris pal. zoneout regularizing rnns randomly preserving hidden activations. iclr guanghan ning zhang chen huang zhihai xiaobo haohong wang. spatially supervised recurrent convolutional neural networks visual object tracking. arxiv prepr. arxiv.", "year": 2017}