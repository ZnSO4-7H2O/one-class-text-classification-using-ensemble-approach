{"title": "Cheaper and Better: Selecting Good Workers for Crowdsourcing", "tag": ["stat.ML", "cs.AI", "cs.LG", "stat.AP"], "abstract": "Crowdsourcing provides a popular paradigm for data collection at scale. We study the problem of selecting subsets of workers from a given worker pool to maximize the accuracy under a budget constraint. One natural question is whether we should hire as many workers as the budget allows, or restrict on a small number of top-quality workers. By theoretically analyzing the error rate of a typical setting in crowdsourcing, we frame the worker selection problem into a combinatorial optimization problem and propose an algorithm to solve it efficiently. Empirical results on both simulated and real-world datasets show that our algorithm is able to select a small number of high-quality workers, and performs as good as, sometimes even better than, the much larger crowds as the budget allows.", "text": "crowdsourcing provides popular paradigm data collection scale. study problem selecting subsets workers given worker pool maximize accuracy budget constraint. natural question whether hire many workers budget allows restrict small number topquality workers. theoretically analyzing error rate typical setting crowdsourcing frame worker selection problem combinatorial optimization problem propose algorithm solve efﬁciently. empirical results simulated real-world datasets show algorithm able select small number high-quality workers performs good sometimes even better than much larger crowds budget allows. recent rise crowdsourcing approach made possible collect large amounts human-labeled data solve challenging problems require human intervention large scale relatively cost. micro-task marketplaces amazon mechanical turk requestors hire large numbers online crowd workers complete human intelligence tasks short time payment several cents task. unfortunately inexperience workers labeling qualities often much lower experts. common solution redundancy asking many crowd workers answer questions aggregating answers; combined results crowds often much better individual worker sometimes even good experts phenomenon known wisdom crowds. however crowd workers often different reliabilities diverse backgrounds important weight answers properly aggregating answers. large body work proposed deal uncertainty diversity workers’ reliabilities; methods often form weighted majority voting answers majority workers selected weighting scheme accounts importance different workers according reliabilities. workers’ reliabilities estimated either using gold standard questions known answers statistical methods expectation-maximization work motivated natural question crowd workers necessarily yield better aggregated results less workers? idea wisdom crowds seems suggest conﬁrmative answer since larger crowds wiser. bayesian perspective would true perfect knowledge workers’ prediction model able oracle aggregation procedure performs exact bayesian inference. however practice workers’ prediction model reliabilities never known perfectly risk adding noisy information increase number workers. extreme exist large number spammers submit completely random answers rather good-faith attempts label; adding spammers would certatinly deteriorate results unless able identify perfectly assign zero-weights label aggregation algorithm. even exist extreme spammers median-level workers still decrease overall accuracy dominate small number high-quality workers. fact recent empirical study shows aggregated results small number high-quality workers often accurate much larger crowds. work study phenomenon formulating worker selection problem budget constraint. assume pool workers whose reliabilities tested small number gold standard questions; certain label aggregation algorithm want select subset workers maximizes accuracy budget constraint number workers assigned task na¨ıve commonly used procedure simply select workers highest reliabilities. however noisy nature label aggregation algorithms selecting workers necessarily give best accuracy cause waste resource. study problem simple label aggregation algorithm based weighted majority voting propose worker selection method able select fewer top-ranked workers achieve almost same even better aggregated solutions na¨ıve method uses workers. method derived framing problem combinatorial optimization minimizes upper bound error rate deriving globally optimal algorithm selects group top-ranked workers optimize upper bound error rate. demonstrate efﬁciency algorithm comprehensive experiments number real-world datasets. related work. many literatures estimating workers’ reliabilities eliminating spammers based predeﬁned threshold work instead focuses selecting minimum number highest-ranked workers discarding others note method advantage requiring pre-speciﬁed threshold parameters. work also distinguished another line research online assignment crowdsouring different objectives purposes work. outline. rest paper organized follows. introduce background problem setting section formulate worker selection problem combinatorial optimization problem derive algorithm section numerical experiments presented section give discussions section conclude paper section assume crowd workers items labels classes. notation convenience denote workers items label classes denote ﬁrst integers. assume item associated unknown true label also assume control questions whose true labels item assigned worker labeling possibly inaccuracy answer worker denote workers often different expertise attitude hence different reliabilities. assume i-th worker labels items correctly probability addition assume estimation workers’ reliability estimated either based workers’ performance control items probabilistic inference algorithms like expectation-maximization known reliability estimation label aggregation algorithms including na¨ıve majority voting written form weighted majority voting voting ignores diversity workers performance badly practice. contrast log-odds weighting function flog logit logit logit derived using bayesian rule simple model assumes uniform error across classes; probability random guessing among classes. however practice log-odds conﬁdent close linearized version flinear better stability simpler theoretical analysis note flog flinear properties desirable general weighting functions monotonic increasing functions take zero value positive negative common properties make flinear flog work similarly practice. since flinear stable simpler theoretical analysis focus linear weighted function flinear development worker selection problem labels aggregated problem selecting optimal workers requires predicting error rate given worker unfortunately intractable general. however convenient obtain upper bound error rate linear weighted majority voting. theorem given workers using weighted majority voting linear weights flinear unbiased estimator reliabilities ˆwi}i∈s satisﬁes workers’ labels generated independently according following probability remark note upper bound depends worker reliabilities term fact according proof supplementary term corresponds expected voting score true label wrong labels hence reﬂects conﬁdence weighted majority voting. therefore represents score function worker large weighted majority voting likely give correct prediction. assumption used theorem implies one-coin model workers labels labels correct probability otherwise make mistakes uniformly among remaining classes. common assumption make especially theoretical works ghosh joglekar possible relax general two-coin model arbitrary probability which however lead complex upper bounds. empirical study various real-world datasets remains efﬁcient score function worker section even one-coin assumption seem hold. unfortunately depends workers’ true reliabilities often unknown. instead estimate based ˆwi. following theorem provides unbiased estimator. lemma assume unbiased estimator satisﬁes ˆvar unbiased estimator variance ˆwi. consider ﬁrst term shows workers close either remark encouraged; workers tend answer questions either correctly wrongly hence strongly informative terms predicting true labels. note workers strongly informative eliminate possible value true labels. side workers also means noise however obviously leads biased estimator missing variance term existence variance term critical importance workers large uncertainty reliabilities less favorable compared conﬁdent estimation. since lemma specify ˆvar next theorem provides concrete example based symmetric conﬁdence interval constructed. theorem assume group workers tested control questions number correct answers given worker control questions. unbiased estimator unbiased estimator obtained deﬁned although combinatorial problem neither sub-modular supermodular show exactly solved linearithmic time algorithm shown algorithm algorithm progresses ranking workers according decreasing order sequentially evaluates groups top-ranked workers ﬁnds smallest group maximal score time complexity algorithm space complexity whole workers. following theorem shows algorithm achieves global optimality theorem ﬁxed ˆwi}i∈ω. given algorithm global optimum problem satisﬁes algorithm worker selection algorithm input worker pool estimated reliabilities ˆwi}i∈ω control questions; number label classes cardinality constraint workers item. sort {xi}i∈ω descending order output selected subset workers σ··· simultaneously maximizes score minimizes number workers actually deployed. show fact pareto optimal solution sense exist feasible improves terms demonstrate algorithm using empirical experiments based simulated real-world datasets. empirical results conﬁrm intuition selecting small number top-ranked workers perform good even better using available workers. particular show worker selection algorithm signiﬁcantly outperforms naive procedure uses workers. algorithm tends select small number workers close optimal number top-ranked workers practice. speciﬁc consider following practical scenario experiments assume worker pool worker completed qualify exam control questions required either platform particular task owner. task owner selects subset workers using worker selection algorithm algorithm based performance qualify exam. selected workers distributed answer questions main interest. label aggregation algorithms wmv-linear applied predict ﬁnal labels items. even though worker selection algorithm derived using wmv-linear still label aggregation algorithms worker selected. gives following possible combinations algorithms test wmv-linear workers wmv-linear worker selected algorithm ratio weights selected worker algorithm randomly selected workers workers ranked worker selected also implement worker selection algorithm based plugin estimator followed wmv-linear aggregation algorithm since majority voting tends perform much worse algorithms omit plots clarity. trial algorithms simulated real-world datasets items randomly picked collected data control items workers’ reliabilities ˆwi}i∈ω estimated based accuracy control items trial number workers selected algorithm stored average number workers computed budfigure performance different worker selection methods simulated data. wmv-linear aggregation used cases. simulated workers items binary labels control questions. workers’ reliabilities drawn independently beta. accuracies budget varies. actual number workers used different worker selection methods increases. generate simulated data drawing workers reliability beta randomly generated items true labels uniformly distributed {±}. budget varies figure shows accuracy wmv-linear different worker selection strategies budget changes. wmv-lin selected dominates methods. figure shows actual number workers selected worker selection algorithm wmv-linear based selected workers uses relatively small number workers achieve even better performance wmv-lin uses entire available budge worker selection algorithm based plugin estimator ˆfplug tends select slightly workers achieves slightly worse performance algorithm based bias-corrected estimator implies importance variance term penalizes workers noisy reliability estimation. number control questions controls variance reliability estimation hence inﬂuences results worker selection algorithms. figure shows results vary budget ﬁxed performance algorithms increases increases know accurate information workers’ true reliabilities make better decision choosing workers selecting workers algorithm. addition increases variance decreases difference wmv-linear selected wmv-linear plugin decreases. figure shows results vary prior parameter beta ﬁxed larger means workers likely high reliabilities figure wmv-lin increases increases overall improvement reliabilities workers. performances wmv-lin selected wmv-lin plugin improves slightly probably select several workers heavily affected figure performance different worker selection methods changing number control questions changing parameter reliability prior beta. budget ﬁxed wmv-linear aggregation method cases. test different worker selection methods three real-world datasets collected ourselves crowdsourcing platform clickworkers welinder amazon mechanical turk. crowd-test dataset dataset workers asked answer knowledge-based questions allthetests.com cover topics science math common knowledge sports geography u.s. history politics india. questions options know ground truth beforehand. required worker ﬁnish questions. typical example knowledge-test question follows figure shows performance different methods budget changes. since widely used practice include results using label aggregation algorithm workers selected. performance ﬁrst increases small decreases large enough worker selection algorithm selects much smaller number workers much better performance compared random selection methods. disambiguity dataset task identify wikipedia page given highlighted entity sentence actually refers collected questions technology domain ground truth available hire workers clickworkers required complete questions. typical example follows microsoft .net framework redistributable package install .net framework runtime associated ﬁles required develop applications target .net framework wiki page runtime refer http//en.wikipedia.org/wiki/run-time system http//en.wikipedia.org/wiki/runtime library http//en.wikipedia.org/wiki/run time publicly available. dataset workers asked presented image contains indigo bunting blue grobeak. images total. figure performance comparison real-world datasets. disambiguity dataset workers questions total. bluebird dataset workers questions total. settings figure number worker actually used plotted supplementary. figure show performance different algorithms bluebird disambiguation dataset respectively. results similar figure disambiguation dataset number workers selected usually corresponding number bluebird dataset supplementary plots number workers algorithms actually used datasets. note wmv-lin selected wmv-log selected selected based workers selected algorithm achieve better performance based random selected workers large. shows aggregation based inputs selected workers saves budget also maintains good performance. advantage ensuring unbiased estimate true objective function unknown optimize random estimation biased estimator bias depends ˆwi}i∈ω optimum solution different underlying true solution. unbiased estimator symmetric conﬁdence interval gurantee shown lemma optimizing equivalent optimizing proper conﬁdence bound margin conﬁdence interval often depend workers’ reliabilities. results figure conﬁrm unbiased estimator performance selected workers better biased plugin estimator fplug. wmv-linear perform better flog? empirical results ratio weight good linear weight. mainly high chance workers estimated reliability close number control questions small even truncation prevent weight flog going large weights workers still lead unstable aggregations. however performance flog improves larger heavier truncation ˆwi. top-k workers perform poorly increases? within given pool workers increasingly less reliable workers increases; less reliable workers confuse algorithm causing worse reliability estimation well ﬁnal prediction accuracy. intuition matches empirical results figure performance generally ﬁrst increases small decreases large paper study problem selecting crowd workers achieve best accuracy crowdsourcing labeling tasks. demonstrate worker selection algorithm simultaneously minimize number selected workers minimizing prediction error rate achieving best terms cost efﬁciency. future directions interested developing better selection algorithms based advanced label aggregation algorithms complex probabilistic models. //faculty.fuqua.duke.edu/˜jsoll/. raykar eliminating spammers ranking annotators crowdsourced labeling tasks. journal machine learning research nips bachrach graepel minka guiver. grade test without knowing answers bayesian graphical model adaptive crowdsourcing aptitude testing. icml rosales fung j.g. active learning crowds. icml rosales fung schmidt hermosillo bogoni modeling annotator expertise learning everybody knows something. icml f.l. wauthier m.i. jordan. bayesian bias mitigation crowdsourcing. nips proof. without loss generality denote prevalence true labels i.e. πk∀j denotes probability measure. note even scenario assumed ﬁxed instead random analysis results still hold furthermore assume group workers wmv-linear weights {ˆνi}m majority voting aggregated score item potential label class thus general aggregation rule written argmaxk∈ frequently discuss condition probability expectation variance conditioned event without introducing ambiguity context deﬁne conditional independent given bounded note given voting weight {ˆνi}i∈ bounded. therefore could apply hoeffding concentration inequality bound apparently proof theorem symmetric conﬁdence interval proof. similar proof lemma assume ˆvar deﬁned straightforwardly show lemma corresponding unbaised estimator note ˆwi}i∈ω given optimization problems thus treat random. problems deterministic combinatorial problems. proof show output algorithm achives global maximum problem worker selection problem select worker denote workers permutation want show given globally optimal solution problem cardinality σ··· σ)}). this σ··· assume since value function depdends cardinality {xi}i∈s conﬁguration values {xi}i∈s equal {xi}i∈s. implies exist since x-values therefore replace increase value i.e. \\{i}) {j}) contradicts fact global optimum. thus conclude σ··· σ)}). analysis implies know cardinality global optimal solution workers terms x-values global optimum problem although might unique one. based fact cardinality values min} compute value σ··· min. maximum yielded function values global optimum problem thus corresponding worker global optimum problem algorithm follows exactly procedure described above therefore output globally optimal worker set. mentioned remark theorem show also solves following multiobjective optimization problem simultaneously maximizes score minimizes number workers actually deployed. theorem consider multiple-objective optimization problem pareto optimal solution. proof. theorem suppose global optimum problem implies within sets cardinality could improve thus pareto optimal according deﬁnition context multiple objective optimization.", "year": 2015}