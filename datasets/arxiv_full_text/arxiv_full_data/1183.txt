{"title": "Discovering Hidden Factors of Variation in Deep Networks", "tag": ["cs.LG", "cs.CV", "cs.NE"], "abstract": "Deep learning has enjoyed a great deal of success because of its ability to learn useful features for tasks such as classification. But there has been less exploration in learning the factors of variation apart from the classification signal. By augmenting autoencoders with simple regularization terms during training, we demonstrate that standard deep architectures can discover and explicitly represent factors of variation beyond those relevant for categorization. We introduce a cross-covariance penalty (XCov) as a method to disentangle factors like handwriting style for digits and subject identity in faces. We demonstrate this on the MNIST handwritten digit database, the Toronto Faces Database (TFD) and the Multi-PIE dataset by generating manipulated instances of the data. Furthermore, we demonstrate these deep networks can extrapolate `hidden' variation in the supervised signal.", "text": "deep learning enjoyed great deal success ability learn useful features tasks classiﬁcation. less exploration learning factors variation apart classiﬁcation signal. augmenting autoencoders simple regularization terms training demonstrate standard deep architectures discover explicitly represent factors variation beyond relevant categorization. introduce cross-covariance penalty method disentangle factors like handwriting style digits subject identity faces. demonstrate mnist handwritten digit database toronto faces database multi-pie dataset generating manipulated instances data. furthermore demonstrate deep networks extrapolate ‘hidden’ variation supervised signal. goals representation learning efﬁcient representation input data simpliﬁes tasks object classiﬁcation image restoration supervised algorithms approach problem learning features transform data space different classes linearly separable. however often comes cost discarding variations style pose important general tasks. hand unsupervised learning algorithms autoencoders seek efﬁcient representations data input fully reconstructed implying latent representation preserves factors variation data. however without explicit means factoring apart different sources variation factors relevant speciﬁc task categorization entangled factors across latent variables. goal work combine approaches disentangle class-relevant signals factors variation latent variables standard deep autoencoder. previous approaches separating factors variation data content style form motion relied upon bilinear model architecture units representing different factors combined multiplicatively. approach recently utilized separate facial expression identity using higher-order restricted boltzmann machines downside bilinear approaches general require learning approximate weight tensor corresponding three-way multiplicative combinations units. despite impressive results achieved approach question nevertheless remains whether straightforward separate factors variation using standard nonlinearities feedforward neural networks. earlier work demonstrated class-irrelevant aspects mnist learned including additional unsupervised units alongside supervised ones autoencoder. however model disentangle class-irrelevant factors class-relevant ones. recently utilized variational autoencoder semi-supervised learning paradigm capable separating content style data. work inspiration simple training scheme presented here. autoencoder models shown useful variety machine learning tasks basic autoencoder architecture separated encoding stage decoding stage. training stages jointly optimized reconstruct input data output decoder. work propose using encoding decoding stages autoencoder learn high-level representations factors variation contained data. high-level representation divided sets variables. ﬁrst used discriminative task reconstruction. second used reconstruction. promote disentangling representations autoencoder additional costs network. ﬁrst discriminative cost observed variables. second novel cross-covariance penalty observed latent variables across batch data. penalty prevents latent variables encoding input variations class label. proposed similar penalty terms product jacobians observed latent variables respect input. penalty variables represent class assignment separated encoding factors variations data. analyze characteristics learned representation three image datasets. absence standard benchmark task evaluating disentangling performance evaluation based examining qualitatively factors variation discovered different datasets. case mnist learned factors correspond style slant size. case factors correspond identity case multi-pie identity speciﬁc attributes clothing skin tone hair style. semi-supervised autoencoder given input corresponding class label dataset consider class label high-level representation corresponding input. however representation usually invertible discards much variation contained input distribution. order properly reconstruct autoencoders must learn latent representation preserves input variations dataset. using class labels incorporate supervised learning subset latent variables transforming observed variables shown figure framework remaining latent variable must account remaining variation dataset hypothesize latent variation high-level representation input complementary observed variation. instance class label provided would sufﬁcient decoder properly reconstruct image particular scenario would encode properties digit style slant width etc. provide decoder sufﬁcient information reconstruct original input image. mathematically encoder decoder deﬁned respectively ﬁrst term typical reconstruction cost autoencoder. second term standard supervised cost many potential choices reconstruction cost depending distribution data vector experiments squared-error datasets. observed variables form cost function depends type variables experiments categorical observed variables parametrized one-hot vectors compute tmax. third term unsupervised cross-covariance cost disentangles observed latent variables encoder. xcov penalty disentangle simply sum-squared cross-covariance penalty activations across samples batch size ¯ˆyi ¯ˆzj denote means examples. index examples index feature dimensions. unlike reconstruction supervised terms objective xcov cost computed batch datapoints. possible approximate quantity moving average training found cost robust small batch sizes found issues training mini-batches small derivative provided supplementary material. objective function naturally semi-supervised learning framework. unlabeled data multiplier supervised cost simply zero. general choice depend intended task. larger lead better classiﬁcation performance larger better separation latent observed factors. evaluate autoencoders trained minimize three datasets increasing complexity. network trained using adadelta gradients standard backpropagation. models implemented modiﬁed version pylearn using deconvolution likelihood estimation code mnist handwritten digits database consists training test images handwritten digits size following previous work split training samples training samples validation model selection. toronto faces database consists grayscale face images size these labeled different expressions examples shown figure dataset also contains identity labels used paper. dataset folds training validation test examples. three partitions disjoint contain overlap identities. figure left example images test showing expressions random identity. right example multi-pie images test showing camera poses variable lighting identity. multi-pie datasets consists high-resolution color images subjects. subject recorded camera poses spaced degree intervals head height positioned subject. cameras subjects imaged illumination conditions variety facial expressions. discarded images overhead cameras inconsistencies found image. camera pose illumination data retained supervised labels. small subset images possess facial keypoint information camera pose. perform weak registration appoximately localize face region compute maximum bounding created available facial keypoint coordinates given camera pose. bounding applied images camera pose. resized cropped images pixels convert grayscale. divide dataset training validation test examples. splits determined subject therefore test contains overlap identities training validation sets. example images test shown figure multi-pie dataset contains signiﬁcantly complex factors variation mnist tfd. unlike images multi-pie includes much subject’s body. weak registration also causes signiﬁcant variation subject’s head position scale. sanity check ﬁrst show additional regularization term cost negligibly impacts performance different architectures including convolution maxout dropout. tables show classiﬁcation results mnist comparable previously published results. details network architecture models found supplementary material. learned factors variation begin analysis using mnist dataset. intentionally choose architecture described table ease visualization latent variables. shown figure takes suprisingly simple isotropic normal distribution mean standard deviation visualize transformations latent variables learning decoder used create images different values vary single element linearly interval ﬁxed ﬁxed one-hot vectors corresponding class label shown figure moving across column given digit style maintained class labels varies. suggests network learned class invariant latent representation. center z-space canonical mnist digit style. moving away center digits become stylized also less probable. result reliably reproduced without xcov regularization dimensionality relatively small suggesting network naturally prefers latent representation factors variation absent supervised signal. knowledge describe method generate samples autoencoder competative generative performance supplementary material. moving latent space image space following layer observed latent variables additional layers activations output model image space. visualize function layers compute jacobian output image respect activation hidden units particular layer. analysis provides insight transformation unit applying input generate speciﬁcally measure small perturbation particular unit network affects output figure histogram test variables. generated mnist digits formed setting zero varying generated mnist digits formed setting zero varying calculated variation test set. here index pixel output network index hidden unit layer number. remove hidden units zero activation jacobian since derivatives meaningful. summary results plotted figure jacobian respect units shown figure locally mirror transformations seen figure conﬁrming hypothesis latent space smoothly controls digit style. slanted style generated approaches figure created applying gaborlike ﬁlter vertically oriented parts digit shown second column figure rather viewing unit next layer individually analyze singular value spectrum jacobian. spectrum peaked thus small number directions large effect image output plot singular vectors largest singular value. digits besides ﬁrst component seems create template digit componets make small style adjustments. spectrum degenerate choose random columns jacobian plot better represent layer’s function. notice layer moving encoder output contributions become spatially localized less semantically meaningful. figure jacobians taken activation values lead images. zero digit class. gradients decoder output respect singular vectors jacobian activations ﬁrst layer column vectors jacobian activations second layer note units columns neccesarily unit. plots normalized singular values jacobians respect blue jacobians respect activations ﬁrst layer green jacobians respect activations second layer demonstrate similar manipulations dataset contains substantially complex images mnist fewer labeled examples. training latent representation encodes subject’s identity major factor variation dataset represented expression labels. autoencoder able change expression preserving identity faces never seen model. ﬁrst initialize example test set. replace expression label feeding decoder. figure shows results process. expressions changed leaving facial features largely intact. similar mnist dataset xcov penalty necessary dimensionality convergence training becomes difﬁcult bottleneck. achieve much better reconstruction error xcov penalty high-dimensional xcov penalty simply prevents expression label variation ‘leaking’ latent representation. figure shows decoder unaffected changes without xcov penalty expression variation distributed across hundreds dimensions previously showed autoencoder learns smooth continuous latent representation. similar result observed expression variables despite provided discrete class labels. figure step further. values well beyond encoder could ever output softmax activation vary expression variable given decoder results greatly exagerated expressions extreme positive values seen figure remarkably setting variables extreme negative values results ‘negative‘ facial expressions displayed. negative facial expressions abstract opposites positive counterparts. eyes open extreme closed opposite extreme. consistent regardless expression label holds true abstract facial features open/closed mouth smiling/frowning face. decoder learned meaningful extrapolation facial expression structure explicitly present labeled data creating smooth semantically sensible space values observed variables completely absent class labels. figure left column samples test displaying expressions. expression-labeled columns generated keeping latent variables constant changing rightmost faces model covarriance cost showcase importance cost disentangling expression latent variables. multi-pie sets observed factors shown table softmax layers encoder. ﬁrst encodes camera pose input image second illumination condition. increased complexity images made network substantially deeper figure show images generated decoder iterating camera pose. network tied illumination latent variables images test set. although blurry generated images preserve subject’s illumination identity camera pose changes. figure instead camera position iterate different illumination conditions. also possible interpolate camera lighting positions simply linearly interpolating neighboring camera positions supporting inherent continuity class labels. addition supervised cost unsupervised cross-covariance penalty autoencoder learn disentangle various transformations using standard feedforward neural network components. decoder implicitly learns generate novel manipulations images multiple sets transformation variables. show deep feedforward networks capable learning higher-order factors variation beyond observed labels without need explicitly deﬁne higher-order interactions. finally demonstrate natural ability deep networks learn continuum higher-order factors variation latent observed variables. surprisingly networks extrapolate intrinsic continuous variation hidden discrete class labels. results gives insight potential deep learning discovery hidden factors variation simply accounting known variation. many potential applications exploratory data analysis signal denoising. would like acknowledge everyone redwood center helpful discussion comments. thank nervana systems supporting brian cheung summer project originated continued collaboration. gratefully acknowledge support nvidia corporation donation tesla gpus used research. bruno olshausen supported grant iis-.", "year": 2014}