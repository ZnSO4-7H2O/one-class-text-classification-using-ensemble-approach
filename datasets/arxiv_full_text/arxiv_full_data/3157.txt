{"title": "Gaussian Process Domain Experts for Model Adaptation in Facial Behavior  Analysis", "tag": ["stat.ML", "cs.CV", "cs.LG"], "abstract": "We present a novel approach for supervised domain adaptation that is based upon the probabilistic framework of Gaussian processes (GPs). Specifically, we introduce domain-specific GPs as local experts for facial expression classification from face images. The adaptation of the classifier is facilitated in probabilistic fashion by conditioning the target expert on multiple source experts. Furthermore, in contrast to existing adaptation approaches, we also learn a target expert from available target data solely. Then, a single and confident classifier is obtained by combining the predictions from multiple experts based on their confidence. Learning of the model is efficient and requires no retraining/reweighting of the source classifiers. We evaluate the proposed approach on two publicly available datasets for multi-class (MultiPIE) and multi-label (DISFA) facial expression classification. To this end, we perform adaptation of two contextual factors: 'where' (view) and 'who' (subject). We show in our experiments that the proposed approach consistently outperforms both source and target classifiers, while using as few as 30 target examples. It also outperforms the state-of-the-art approaches for supervised domain adaptation.", "text": "present novel approach supervised domain adaptation based upon probabilistic framework gaussian processes speciﬁcally introduce domain-speciﬁc local experts facial expression classiﬁcation face images. adaptation classiﬁer facilitated probabilistic fashion conditioning target expert multiple source experts. furthermore contrast existing adaptation approaches also learn target expert available target data solely. then single conﬁdent classiﬁer obtained combining predictions multiple experts based conﬁdence. learning model efﬁcient requires retraining/reweighting source classiﬁers. evaluate proposed approach publicly available datasets multi-class multi-label facial expression classiﬁcation. perform adaptation contextual factors ‘where’ ‘who’ show experiments proposed approach consistently outperforms source target classiﬁers using target examples. also outperforms state-of-the-art approaches supervised domain adaptation. human face believed powerful channel conveying non-verbally behavioral traits personality intentions affect among others facial expressions studied message level sign level facial action coding system used. comprehensive anatomically-based system describing facial expressions levels. facs deﬁnes unique several categories head/eye movements. figure proposed gpde model. learning consists training multiple source target experts using available labeled training data pairs input features output labels respectively. adaptation target data performed conditioning latent functions target source experts inference fuse predictions experts means predictive variance role conﬁdence measure. practical importance medicine marketing entertainment automated analysis facial expressions received signiﬁcant research attention last decades. despite rapid advances computer vision machine learning majority models proposed facial expression analysis rely generic classiﬁers. classiﬁers expected generalize well applied data recorded within speciﬁc contexts deﬁned context questions nevertheless possible variations contextual dimensions performance virtually existing generic classiﬁers facial expression analysis expected downgrade largely applied previously unseen data especially pronounced case unseen subjects changes pose illumination environments circumvent challenges lines work proposed. ﬁrst relies carefull design ’context-independent’ image features generic classiﬁers second attempts adaptation target classiﬁers work employ latter approach focus adaptation context questions ‘where’ ‘who’ data. variation head-pose illumination addressed combining illumination invariant techniques hand individual differences among subjects mainly tackled accounting subject information training stage. speciﬁcally original feature extended adding subject-speciﬁc features building person-speciﬁc classiﬁers although approaches showed improvement generic classiﬁers still number challenges address. particular multi-view learning requires large amount images various poses typically available. hand building personalized classiﬁers access adequate collection images target person essential. consequently existing approaches perform re-weighting previosly learned classiﬁers target data training models using additional target data. however suboptimal. thus effective approach adapt already trained generic models facial behavior analysis using small number target data. case context question ‘where’ boils adapting frontal classiﬁer non-frontal view using small number expressive images target view. similarly case subject adaptation model adaptation performed using annotated images target subject needed gain prediction performance approach expected generalize better generic classiﬁers learned available source and/or target data. address challenges mentioned above notion domain adaptation perform tasks view subject adaptation facial expression recognition detection. particular address problem domain adaptation distribution features varies across domains output labels remain same. also known covariate shift domains called source target domain respectively. furthermore supervised setting small number labeled target examples available adaptation process assumed. build model upon probabilistic framework gaussian processes generalize product expert models domain adaptation scenario. speciﬁcally instead adjusting classiﬁer parameters domains propose domainspeciﬁc experts model domain speciﬁc data. moreover instead minimizing error distributions original source target domain data bayesian domain adaptation explain target data conditioning learned source experts. advantage probabilistic formulation adaptation exploit variance predictions combining source target domains results conﬁdent classiﬁer minimizes risk potential negative transfer contrast transductive adaptation approaches need re-trained completely adaptation model efﬁcient requires re-training source model. model outline depicted fig. contributions work summarized follows present novel approach supervised domain adaptation ﬁrst time perform adaptation contextual factors ‘where’ ‘who’ modeling facial expression data. best knowledge ﬁrst work domain facial behavior modeling simultaneously perform adaption multiple outputs existing models ﬁeld attempt model adaptation output independently. probabilistic nature proposed approach provides conﬁdence predicted labels target expressions. contrast majority models purely discriminative thus cannot provide measure ‘reliable’ predictions are. show experiments view subject adaptation proposed model generalize better source target domains together using target samples perform adaptation. furthermore virtually existing domain adaptation approaches fail reach performance target classiﬁers target data become available approach overcomes newly introduced scheme combining source target experts. task motivated good generalization abilities even trained limited amount data property crucial training target expert since available data scarce. majority approaches domain adaptation context facial behavior analysis focus building personalized classiﬁers test subjects. instance uses supervised kernel mean matching align source target data distributions. achieved re-weighting source data which combination target data form input features used train support vector machine classiﬁer fer. likewise uses unsupervised learn person-speciﬁc detectors. attained modifying cost function account source target data adjusting svm’s hyperplane target test data. however results transductive learning approach thus classiﬁer re-learned target subject. two-step learning approach proposed person-speciﬁc pain recognition detection. first data subject regarded different source domains used train weak adaboost classiﬁers. then weak classiﬁers weighted based classiﬁcation performance available target data. adaboost classiﬁers replaced linear svms support vector regression employed learn mapping feature distribution parameters classiﬁer. note that apart works mentioned perform unsupervised adaptation setting. requires less effort terms obtaining labels target sub-sample underlying assumption target data well represented weighted combination source data. however real-world data assumption easily violated resulting poor performance adapted classiﬁer. work adopt supervised approach needs annotated data target domain perform adaptation. this turn allows deﬁne target source experts assuring performance resulting classiﬁer constrained distribution source data unsupervised adaptation approaches. contrary transductive learning approaches approach requires adaptation target expert solely without need re-learn source experts resulting efﬁcient adaptation process. moreover contrast approach none aforementioned works provides measure conﬁdence predicted labels. finally note proposed approach methods mentioned differ recently proposed transfer learning goal latter adapt classiﬁer learned e.g. another different adaptation task addressed work. domain adaptation well studied problem machine learning review relevant supervised adaptation approaches. instance learns transformation maximizes similarity data source target domains enforcing data pairs labels high similarity pairs different labels dissimilar. then k-nn classiﬁer used perform classiﬁcation target data. extension approach multiple source domains. input data assumed generated category-speciﬁc local domain mixtures mixing weights determine underlying domain data classiﬁed using classiﬁer. similarly learns linear asymmetric transformation maximally align target features source domain. attained introducing max-margin constraints allow learning transformation matrix classiﬁer jointly. extends work introducing additional constraints max-margin formulation. speciﬁcally unlabeled data target domain used enforce classiﬁer produce similar predictions similar target-source data. methods attempt directly align target source features several works attempted shared manifold. instance learns non-linear transformation source target data shared latent space along target classiﬁer. likewise ﬁnds low-dimensional subspace preserves structure across domains. subspace facilitated projection functions learned jointly linear classiﬁer. again structure preservation constraints used ensure similar data across domains close subspace. methods tackle adaptation problem deterministic fashion thus provide measure conﬁdence target predictions. contrast approach fully probabilistic non-parametric gps. proposed related recent advances literature domain adaptation. speciﬁcally predictive distribution trained source data used prior making inference target domain. similarly proposed two-layer jointly learns separate discriminative functions source target features labels. intermediate layer facilitates adaptation step variational approximation employed integrate layer. contrast proposed deﬁnes target speciﬁc expert combined principled manner source domain experts. beneﬁt resulting classiﬁer limited distribution source data. also contrast training experts performed independently thus need retrain source classiﬁer. consider supervised setting domain adaptation access large collection labeled source domain data smaller labeled target domain data. input output spaces respectively. assume input space comprised source target domains respectively differ feature distribution. hence case different views subjects. hand correspond labels source target domains. vector contains binary class labels classes. formulate regression problem i.i.d. additive gaussian noise index denotes dependence domain. objective infer latent functions given training dataset following framework place prior functions function values follow gaussian distribution here kernel covariance function assumed shared among label dimensions. work radial basis function kernel kernel hyper-parameters. regression mapping fully deﬁned hyperparameters σv}. training consists ﬁnding hyper-parameters maximize logmarginal likelihood within introduced notation choice learn either independent functions universal function couples data domains. however neither option allows explore idea domain adaptation former learn domain-speciﬁc models latter simplify problem concatenating data domains. straightforward approach obtain model capable performing inference data domains assume existence universal latent function single hyper-parameters authors proposed simple effective three-step approach adaptation eqs. shows ﬁnal prediction combination original prediction based source data only plus correction term. latter shifts mean toward distribution target data improves model’s conﬁdence reducing predictive variance. note originally constrained model learn single latent function conditional log-marginal computed according factorization apart facilitating learning domain experts allows efﬁcient training even larger datasets shown note source experts learned independently target allows model generalize unseen target domains without retraining. predictions. trained gpde need combine predictions expert form overall prediction. follow approach presented readjust predictions source experts using trick gpa. hence predictive distribution given point contribution gpde becomes clear shows overall mean predictions expert weighted precision hence solution gpde favor predictions conﬁdent experts. hand quality domain expert poor gpde weaken contribution overall prediction. algorithm summarizes gpde adaptation procedure. distributions derive posterior gpa. however constraint implicitly assumes marginal distributions data similar. assumption violates general idea domain adaptation deﬁnition marginals signiﬁcantly different attributes cases could perform worse independent trained solely target data possible address issue retrain w.r.t. option compensate differences distributions readjusting hyper-parameters. however comes price retraining model. furthermore allow modeling domain-speciﬁc attributes since predictions still determined mainly source distribution. domain experts product experts. proposed approach assume expert operates subset data i.e. hence follow methodology presented sec. order train domain-speciﬁc learn different latent functions i.e. hyper-parameters within current formulation treat source domain combination multiple source datasets total number source domains training. given mentioned data split assuming conditional independence marginal likelihood approximated note share hyper-parameters across source domains. intuition behind source domain observe different label distribution exploiting available datasets model overall distribution single hyper-parameters however guarantee also able explain target label distribution hyper-parameters. thus also search modeling domainspeciﬁc attributes. similarly sec. learning hyperparameters performed maximizing datasets multipie denver intensity spontaneous facial actions speciﬁcally multipie contains images subjects depicting acted facial expressions neutral disgust surprise smile scream squint captured various angles. experiments used images disfa widely used au-related literature large amount annotated images. contains video recordings subjects watching youtube videos. frame coded terms intensity six-point ordinal scale. experiments selected frequently occurring i.e. treated intensity larger zero active. features geometric features derived facial landmark locations. disfa dataset comes frame-by-frame annotations facial points annotated points multipie obtained discarded contour landmarks leading facial points. registered reference face using afﬁne transform. order remove potential noise artifacts aligned landmark points post-processed retaining energy resulted feature vectors. evaluation procedure. evaluate gpde multiclass multi-label scenarios. also assess adaptation capacity model single multiple source domains. task frontal view i.e. served single source domain inference performed adaptation target domains detection task various subjects train data used multiple source domains adaptation performed time tested subject. evaluate model’s adaptation ability strictly follow training protocol experiment vary cardinality training target data multipie ﬁrst split data -folds then keep increasing cardinality disfa partition data -folds test subject’s sequence ﬁrst frames used target training data inference performed rest frames sequence. order avoid target model overﬁtting temporally neighboring examples test subject. experiments employ classiﬁcation ratio evaluation measure detection imbalance data report score area curve models compared. compare proposed gpde generic models gpsource gptarget. former trained solely source data latter target data used adaptation. furthermore compare state-of-the-art models supervised domain adaptation i.e. asymmetric transfer learning deep instance proposed gpde source domain expert predictions given atldgp employs intermediate combine predictions gpsource gptarget. multi-source experiment also compare gpdess instance gpde subjects treated single source domain. note include comparisons deterministic approaches shown atl-dgp outperforms methods. experiment demonstrate effectiveness proposed approach distributions source target domain differ increasing non-linear manner. purpose evaluate considered algorithms terms ability perform accurate move away frontal pose. example images speciﬁed task seen fig. table summarizes results. generic classiﬁer gpsource exhibits lowest performance fact trained source domain images. important note drop classiﬁcation rate target domain changes indicates inefﬁciency generic classiﬁer deal data different characteristics. hand gptarget trained data points achieves similar performance gpsource since beneﬁts modeling domain-speciﬁc attributes. increase cardinality target training data results signiﬁcant improve classiﬁcation rate. similar trend observed performance adaptation methods inclusion labeled data points target domain adequate shift learned source classiﬁer towards distribution target data. uses extra data condition generic classiﬁer gpsource increase prediction performance. atl-dgp hand facilitates joint learning scheme gpsource gptarget fused together conditioning deep architecture. advantage latter evidenced highest achieved accuracy i.e. however joint training scheme atl-dgp limits adaptation ability high effect source prior. consequently pertrained subjects. adaptation attained gpdess results improved average score compared subject speciﬁc gptarget. point note gpdess perform similarly. reason treating training subjects single source domain gpdess smooths individual differences training subjects treating data single broader source domain. thus contribution target domain expert diminished variations target data explained average source domain. contrary proposed gpde adaptation multiple sources attains best average scores also achieves robust performance evidenced higher auc. finally note gpde performs better target speciﬁc classiﬁer note also proposed gpde reaches full performance samples target domain. important result since obtaining annotations expensive time consuming. table reports detailed results case proposed gpde attains significant improvement compared counterparts suffers loss moreover curves fig. show gpde exhibits robust performance pronounced improvement also similar score latter indicates proposed gpde robust model. finally fig. demonstrate ability proposed gpde fuse predictions individual experts order form overall prediction. selected example used ﬁrst subjects disfa source domains correctly predicted ground truth laformance saturates. disadvantage atl-dgp’s joint learning requires retraining every time target distribution changes. finally proposed gpde uses notion experts unify gpsource gptarget single classiﬁer. achieve gpde measures conﬁdence predictions expert contrast atl-dgp property gpde pronounced adaptation gptarget achieves highest classiﬁcation ratio. gpde performs similarly target expert while atl-dgp underestimate prediction capacity target-speciﬁc classiﬁer thus attain lower results. better insight performance considered methods obtained confusion matrices fig. reported results adaptation proposed gpde takes advantage target-speciﬁc expert signiﬁcantly reduces confusion subtle expressions disgust squint neutral face. section evaluate models multi-label classiﬁcation scenario adaptation performed multiple source domains. challenging setting since dataset comprised naturalistic facial expressions recorded subjects experiencing affect different ways levels. difﬁculty task seen table subject-speciﬁc classiﬁer gptarget trained labeled data points achieves higher score generic classiﬁer gpsource figure importance weight domain expert means normalized predicted precision conﬁdence target speciﬁc expert increases increase cardinality labeled target domain data. gpde correctly predicts activated i.e. cases. allowing reach full performance either source target classiﬁers target samples. future work plan investigate model adaptation context factors also address modeling structure output different target subjects i.e. subj. depicted weights correspond normalized precisions indicate measure conﬁdence domain expert. importance/conﬁdence target expert increases labeled target data adaptation expected. work domain adaptation facial behavior analysis still early stage. conducted experiments adaptation tasks indicate several interesting facts source classiﬁer trained large number data easily outperformed classiﬁer trained examples target domain. furthermore existing adaptation approaches adapt target domain source domain assuming distributions matched. showed experiments view adaptation target data become available target classiﬁer largely outperform existing adaptation approaches. proposed model addresses challenges introducing target expert rasmussen williams. gaussian processes machine learning volume press cambridge rudovic pantic patras. coupled gaussian processes pose-invariant facial expression recognition. ieee tpami", "year": 2016}