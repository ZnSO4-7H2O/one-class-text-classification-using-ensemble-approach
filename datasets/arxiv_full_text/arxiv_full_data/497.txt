{"title": "Direct Acoustics-to-Word Models for English Conversational Speech  Recognition", "tag": ["cs.CL", "cs.NE", "stat.ML"], "abstract": "Recent work on end-to-end automatic speech recognition (ASR) has shown that the connectionist temporal classification (CTC) loss can be used to convert acoustics to phone or character sequences. Such systems are used with a dictionary and separately-trained Language Model (LM) to produce word sequences. However, they are not truly end-to-end in the sense of mapping acoustics directly to words without an intermediate phone representation. In this paper, we present the first results employing direct acoustics-to-word CTC models on two well-known public benchmark tasks: Switchboard and CallHome. These models do not require an LM or even a decoder at run-time and hence recognize speech with minimal complexity. However, due to the large number of word output units, CTC word models require orders of magnitude more data to train reliably compared to traditional systems. We present some techniques to mitigate this issue. Our CTC word model achieves a word error rate of 13.0%/18.8% on the Hub5-2000 Switchboard/CallHome test sets without any LM or decoder compared with 9.6%/16.0% for phone-based CTC with a 4-gram LM. We also present rescoring results on CTC word model lattices to quantify the performance benefits of a LM, and contrast the performance of word and phone CTC models.", "text": "probability word sequence training process thus splits disjoint learning problems makes decoding convoluted process fusion log-likelihoods many candidate word sequences picking likely word sequence. training popular hybrid dnn-hidden markov model also involves multiple steps. recent research neural networks end-to-end learning aims simplify process. includes connectionist temporal classiﬁcation loss encoder-decoder framework particular loss enables training mapping acoustics phone character sequences without frame-level alignment however phone/character-based truly end-to-end acoustics-to-word require dictionary externally-trained decoding perform well. direct acoustics-to-word models natural step towards true end-to-end asr. work recent work soltau liao presented direct acoustics-to-word models. latter trained word models around hours speech youtube data vocabulary words achieved results close state-of-the-art. raises many interesting research questions well word models perform standard public benchmarks advanced state-of-the-art last decades? work brute-force data-intensive setting? word models scale across languages low-resource conditions? help address questions present ﬁrst results using direct acoustics-to-word models well-known public benchmark data sets switchboard callhome. word models require orders magnitude data train reliably compared phone/character-based models. present techniques improve training models hours switchboard hours switchboard+fisher training sets. include incorporating techniques improve training convergence performance word models compared random initialization. word model achieves word error rate .%/.% hub- switchboard/callhome test sets without decoder compared .%/.% phone-based -gram next section presents phone system section describes word system various strategies adopted improve performance error-based comparison word phone systems. conclude paper section directions future work. recent work end-to-end automatic speech recognition shown connectionist temporal classiﬁcation loss used convert acoustics phone character sequences. systems used dictionary separately-trained language model produce word sequences. however truly end-to-end sense mapping acoustics directly words without intermediate phone representation. paper present ﬁrst results employing direct acoustics-to-word models well-known public benchmark tasks switchboard callhome. models require even decoder run-time hence recognize speech minimal complexity. however large number word output units word models require orders magnitude data train reliably compared traditional systems. present techniques mitigate issue. word model achieves word error rate .%/.% hub- switchboard/callhome test sets without decoder compared .%/.% phone-based -gram also present rescoring results word model lattices quantify performance beneﬁts contrast performance word phone models. index terms automatic speech recognition neural networks end-to-end. feed-forward recurrent convolutional deep neural networks signiﬁcantly improved state-of-the-art acoustic models advanced neural network language models exponential also signiﬁcantly out-performed count-based n-gram lms. despite advances building state-of-the-art automatic speech recognition system still cumbersome multi-step exercise. fundamentally linked mathematical framework current systems operate. typically formulated following maximum a-posteriori optimization problem ﬁnding best word sequence given acoustics networks layers neurons forward backward layers. blstm feeds fullyconnected linear layer size followed softmax activation function. used torch binding warpctc tool computing loss gradients. prepared training data sorting utterances decreasing order number frames dividing batches utterance each. used stochastic gradient descent learning rate learning rate half whenever heldout loss decrease parameters neural network assumed uniformly random initial values also clipped gradients stabilize training. models converged epochs. constructed decoding graph similar used table shows word error rate phone system hub- switchboard callhome test sets. using gives consistent gain around absolute wer. reference best -layer -hour hybrid blstm using fmllr+i-vector features context-dependent states standard cross-entropy+sequence training .%/.% switchboard/callhome decoding however decoding phone model almost faster less memory-intensive hybrid blstm model. word models require orders magnitude data train reliably compared conventional systems. mitigate huge need data restricted vocabulary contain words least acoustic examples training data. resulted vocabulary approximately words -hour system approximately words -hour system. created special token denote out-of-vocabulary words. rate hour training data word vocabulary corresponding rate -hour training data word vocabulary. decoding involved simple forward pass acoustic sequence network followed picking highest-scoring word time step repetition/blank removal. mapped token silence symbol scoring. similar phone model setup -layer blstm word model forward backward hidden neurons layer. ﬁnal dense layer mapped dimensions vocabulary size+ ﬁrst training attempt used uniformly-random weight initialization similar phone model. however training failed converge shown denote length-l target symbol sequence consisting phones characters words. denote matrix d-dimensional acoustic feature vectors time steps. conventional cross-entropy loss requires equal common approach solve problem force-aligning yields mapping time symbol instead allows extra blank symbol expands length-l sequence length-t sequences sequence reduces following operations sequence dynamic programming efﬁciently computes function using forward-backward recursion. easy implicitly constructs left-to-right states l-length sequence interpolating symbol states blank states optionally skipped. neural network predicts probability occupying states time steps. forward-backward algorithm trellis computes loss gradients back-propagated neural network used hours segmented speech standard hour switchboard- audio transcripts provided mississippi state university training -hour systems. added hours audio fisher data collection hours callhome audio build -hour systems. built decoding phone models rescoring word models. small -gram used words -hour audio training data vocabulary size words large -gram used vocabulary words additional words several public text data sets trained phone system phones switchboard pronunciation lexicon plus blank symbol. extracted -dimensional logmel ﬁlterbank energies frames every input speech signal stacked successive frames dropped every alternate frame resulting -dimensional logmel features half rate original -dimensional features. stacking+decimation operation provided signiﬁcant speed-up training because sequence length reduces half loss performance. also used -dimensional i-vectors speaker appended feature resulting -dimensional feature vectors. figure despite tuning learning rate amount gradient clipping. hypothesized training blstm learn direct mapping acoustics words ﬂat-start difﬁcult proposition especially small data sets. next discuss techniques experimented -hour mitigate issue. ﬁrst step initialized word blstm phone blstm intuition ability detect sub-word units provides good starting point detecting words. initialized ﬁnal dense layer randomly before. figure shows training validation loss using random initialization initialization using phone blstm network. word model fails converge random initialization converges nicely using phone blstm model starting point also experimented hierarchical bottom blstm layers initialized pre-trained phone model blstm layer randomly initialized. training proceeds multi-task fashion weight phone loss computed branching-off blstm layer ﬁnal word loss. several experiments different observed hierarchical able out-perform full random initialization always worse compared simply initializing entire blstm network phone blstm training word loss. encouraged impact initializing word blstm phone blstm wanted explore better ways initializing ﬁnal dense layer well. weights ﬁnal layer -dimensional vectors word vocabulary. time step dense layer computes product hidden representation weight vector corresponding word resulting scalar score word. words co-occurring frequently natural text likely high scores closer time. thus think -dimensional weight vector word embedding captures word co-occurrence information. intuition glove embeddings initializing ﬁnal dense layer similar technique proposed augmenting neural network externally-trained glove embeddings. glove similar spirit wordvec also tries capture word cooccurrence information. however glove achieves bilinear approximation word co-occurrence matrix. trained sets -dimensional glove embeddings word corpus used training small another word corpus used assigned random vectors blank symbol token. normalized word vector unit norm scaled figure shows glove initialization ﬁnal dense layer average small embeddings yields signiﬁcant improvement training heldout loss. table shows .%/.% absolute improvement switchboard/callhome using glove initialization phone blstm initialization. also note glove embeddings trained bigger word data yield around improvement embeddings trained word set. figure ﬁgure shows word model training heldout losses ﬁrst epochs hour training using different initialization schemes. data chunk x-axis corresponds roughly hours. initialized -hour word model blstm trained -hour phone model glove embeddings trained word text corpus. used input acoustic featurs frame stacking+decimation. output vocabulary words training coverage approximately table compares performance -hour word model results -hour phone model. observe -hour word system achieves .%/.% switchboard/callhome without using best phone system using achieves .%/.%. result encouraging since recognizing speech using word model uses decoder hence takes signiﬁcantly less time memory compared phone model. interesting note gains upon increasing amount training audio hours bigger word model compared phone model figure ﬁgure shows -hour phone word model posteriors utterance switchboard test along phones words respective -best paths. denotes silence phone. gauge impact using rescored output word model word model posteriors spiky shown figure topscoring word blank symbol getting probability mass frame blank symbol dominating overwhelming majority frames. picked time locations words hypotheses took next best words frames. gave consensus network sausage-like lattice containing many nodes number words -best hypotheses. also subtracted word log-priors computed training acoustic logposterior score give acoustic log-likelihood. table shows wers rescoring word lattices higher values give gains. observe .%/.% absolute improvement similar upon using decode phone models table however remaining .%/% rescored word model phone model indicates work needs done improving word model itself. oracle wers switchboard callhome word lattices indicates word system potentially achieve signiﬁcantly lower wer. initial comparison word phone models wanted discrepancy between based type errors committed. table shows substitution deletion insertion rates -hour phone word models observe word lags behind phone model often deletion rate. exception unrescored word model substitution insertion rates phone word models differ less percent. also per-utterance comparison errors committed -hour word phone systems. .%/.% utterances switchboard/callhome test sets word phone systems commit number errors. commit identical errors utterances. word system makes number errors phone system table table shows substitution deletion insertion rates -hour word phone systems switchboard callhome test sets. numbers parentheses show absolute differences respect phone model. paper presented ﬁrst results using direct acoustics-toword models well-benchmarked switchboard callhome data sets. presented techniques initializing word models improving performance using phone blstm hierarchical using glove word embeddings initializing ﬁnal dense layer. -hour word system achieved .%/.% switchboard/callhome data sets compared .%/.% phone system. also showed impact lattice rescoring word model. also observed word system least good phone system around utterances test sets signiﬁcantly faster decode lack future work focus closing word phone systems without scaling amount training data several orders magnitude exploring techniques speeding-up training word models further evaluating word models languages tasks especially low-resource ones. chetlur woolley vandermersch cohen tran catanzaro shelhamer cudnn efﬁcient primitives deep learning arxiv preprint arxiv. warp https//github.com/baidu-research/warp-ctc. multi-accent speech recognition hierarchical grapheme based models proc. icassp hinton deng dahl mohamed jaitly senior vanhoucke nguyen sainath kingsbury deep neural networks acoustic modeling speech recognition shared views four research groups ieee signal processing magazine vol. saon kurata sercu audhkhasi thomas dimitriadis ramabhadran picheny roomi hall english conversational telephone speech recognition humans machines arxiv preprint arxiv. hannun case casper catanzaro diamos elsen prenger satheesh sengupta coates deep speech scaling end-to-end speech recognition arxiv preprint arxiv.", "year": 2017}