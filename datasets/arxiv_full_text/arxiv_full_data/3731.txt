{"title": "Simple, Robust and Optimal Ranking from Pairwise Comparisons", "tag": ["cs.LG", "cs.AI", "cs.IT", "math.IT", "stat.ML"], "abstract": "We consider data in the form of pairwise comparisons of n items, with the goal of precisely identifying the top k items for some value of k < n, or alternatively, recovering a ranking of all the items. We analyze the Copeland counting algorithm that ranks the items in order of the number of pairwise comparisons won, and show it has three attractive features: (a) its computational efficiency leads to speed-ups of several orders of magnitude in computation time as compared to prior work; (b) it is robust in that theoretical guarantees impose no conditions on the underlying matrix of pairwise-comparison probabilities, in contrast to some prior work that applies only to the BTL parametric model; and (c) it is an optimal method up to constant factors, meaning that it achieves the information-theoretic limits for recovering the top k-subset. We extend our results to obtain sharp guarantees for approximate recovery under the Hamming distortion metric, and more generally, to any arbitrary error requirement that satisfies a simple and natural monotonicity condition.", "text": "consider data form pairwise comparisons items goal precisely identifying items value alternatively recovering ranking items. analyze copeland counting algorithm ranks items order number pairwise comparisons show three attractive features computational eﬃciency leads speed-ups several orders magnitude computation time compared prior work; robust theoretical guarantees impose conditions underlying matrix pairwise-comparison probabilities contrast prior work applies parametric model; optimal method constant factors meaning achieves information-theoretic limits recovering k-subset. extend results obtain sharp guarantees approximate recovery hamming distortion metric generally arbitrary error requirement satisﬁes simple natural monotonicity condition. ranking problems involve collection items unknown underlying total ordering items. many applications observe comparisons various pairs items. examples include matches football teams tournament play; consumer’s preference ratings marketing; certain types voting systems politics. given noisy comparisons items often interest true underlying ordering items alternatively given given positive integer subset highly rated items. problems focus paper. substantial literature problem ﬁnding approximate rankings based noisy pairwise comparisons. number papers consider models probability pairwise comparison agreeing underlying order identical across pairs. results break pairs probability agreeing underlying ranking either comes close exactly equal another papers work using parametric models pairwise comparisons address problem recovering parameters associated every individual item. recent line work studies general class models based notion strong stochastic transitivity derives conditions recovering pairwise comparison probabilities themselves. however remains unclear whether results directly extend tight bounds problem recovery items. works consider mixture models every pairwise comparison associated certain individual making comparison assumed preferences across individuals described low-dimensional model. related work papers discuss detail here. wauthier analyze weighted counting algorithm recover approximate rankings; analysis applies speciﬁc model pairwise comparison pair items remains faithful relative positions true ranking probability common across pairs. consider recovery approximate ranking provide results exact recovery. analysis paper shows bounds quite loose results tight total least comparisons. pair papers rajkumar consider ranking several models several metrics. part common setting show counting algorithm consistent terms recovering full ranking automatically implies consistency exactly recovering items. obtain upper bounds sample complexity terms separation threshold identical parameter deﬁned subsequently paper however analysis shows bounds loose least order magnitude. also assume certain high-snr condition probabilities assumption imposed analysis. finally recent work problem chen proposed algorithm called spectral exact recovery items. showed that pairwise observations assumed drawn according bradley-terry-luce parametric model spectral algorithm recovers items correctly high probability certain regularity conditions. addition also show matching lower bounds regularity conditions tight constant factors. guarantees attractive natural algorithm behaves data drawn model. real-world instances pairwise ranking data often found parametric models model variants fail provide accurate references therein). context main contribution paper analyze classical countingbased method ranking often called copeland method show simple optimal robust. analysis require data-generating mechanism follow either parametric assumptions regularity conditions stochastic transitivity. show copeland counting algorithm following properties consider three diﬀerent instantiations problem set-based recovery recovering items perfectly; recovering items allowing certain hamming error tolerance; general recovery problem families satisfy natural set-monotonicity condition. order tackle third problem introduce general framework allows treat variety problems literature uniﬁed manner. remainder paper organized follows. begin section background precise formulation problem. section presents main theoretical results top-k recovery various requirements. section provides results experiments simulated real-world data sets. provide proofs section paper concludes discussion section given noisy pairwise comparisons goals recover items maximum values scores; recover full ordering items deﬁned score vector. notion ranking items scores generalizes explicit rankings popular models literature. indeed discuss shortly models pairwise comparisons considered literature either implicitly explicitly assume concretely consider random-design observation model deﬁned follows. pair associated random number noisy comparisons following binomial distribupair items. assume observation sequences diﬀerent pairs independent. note special case random binomial model reduces case observe exactly observations pair; special case pairs compared form erd˝os-r´enyi random graph. finally generalize results problem satisfying general class requirements families. requirement speciﬁed terms k-sized subsets items allowed required satisfy natural condition setmonotonicity meaning replacing item allowed higher rank item also allowed. section details general framework. clear work makes assumptions form pairwise comparison probabilities. however work context literature brieﬂy review standard models uesd pairwise comparison data. construction parametric model following property pair items also guaranteed every item consequence guaranteed implies ordering items terms quality vector identical ordering terms score vector consequently data actually drawn parametric model recovering strong stochastic transitivity class class strong stochastic transitivity models superset parametric models assume existence quality vector assume speciﬁc form probabilities equation instead class deﬁned assuming existence total ordering items thus broad class models pairwise ranking total ordering deﬁned score vectors coincides underlying ordering used deﬁne models. paper analyze performance counting algorithm without imposing modeling conditions family pairwise probabilities. next three sections establish theoretical guarantees recovery items various requirements. analysis paper focuses simple counting-based algorithm often called copeland method also viewed special case borda count method applies generally observations consist rankings items. describe method applies random-design observation model introduced earlier. section present main theoretical results top-k recovery three settings described earlier. note three settings ordered terms increasing generality advantage least general setting leads simplest form theoretical claim. begin goal exactly recovering top-ranked items. might expect diﬃculty problem turns depend degree separation items remaining items. precisely denote indices items ranked respectively. notation k-separation threshold given shown following theorem success failure recovering entries determined size relative number items observation probability number repetitions particular consider family matrices pairwise comparison matrices generated model model. proof lower bound exact recovery based generalization construction introduced chen adapted general deﬁnition separation threshold standard results random graph then items never used show least compared item. course estimating rank impossible pathological case omit consideration. theorem also used derive guarantees recovery functions underlying ranking. consider problem identifying ranking items case require separations suitably lower bounded precisely study models belong wauthier analyze weighted counting algorithm approximate recovery whenever item ranked independent consequence best ranked item assumed likely meet worst item beat second ranked item instance. analyze approximate ranking kendall maximum displacement metrics. order displacement upper bounded bounds require order pairwise comparisons. comparison model general impose γ-condition analysis observations pairwise probabiltiies. specialized γ-model quantities {∆j}n takes form suﬃcient recover exact total ordering. thus constant corollary guarantees recover multiplicative factor order smaller established wauthier pair papers rajkumar consider ranking several models several metrics. subset models common setting—namely bradley-terry-luce so-called noise models—they show counting algorithm consistent terms recovering full ranking subset items. guarantees obtained low-noise assumpotion namely probability item beating least whenever item ranked higher item assumed underlying ordering. guarantees based sample size least parameter lower bounded again setting allows parameter arbitrarily close zero furthermore discussion above bounds much stronger. moreover rajkumar focus upper bounds alone also prove matching lower bounds sample complexity showing results unimprovable beyond constant factors. noted rajkumar also provide results types ranking problems outside class models treated current paper. recently chen show pairwise observations assumed drawn according bradley-terry-luce parametric model proposed spectral algorithm recovers items correctly high probability certain model satisﬁed. addition also show matching lower bounds separation condition tight constant factors. real-world instances pairwise ranking data often found parametric models model variants fail provide accurate results make assumptions noise furthermore notion ordering items terms scores strictly generalizes notion ordering respect parameters. empirical evaluations presented subsequently counting algorithm signiﬁcantly robust various kinds noise takes several orders magnitude lesser time compute. finally addition notion exact recovery considered next subsections also derive tight guarantees hamming error metric general metrics inspired requirements many relevant applications previous section analyzed performance terms exactly recovering k-ranked subset. although exact recovery suitable applications settings acceptable return subset close correct k-ranked subset. section analyze problem approximate recovery closeness measured hamming result similar theorem except relaxation exact recovery condition allows less constrained deﬁnition separation threshold theorem lower bound part applies even probability matrix restricted parametric model general class. counting algorithm thus optimal estimation relaxed hamming metric well. finally worth making comments constants appearing claims. weaken lower bound required theorem expense lower probability success; instance instead require probability error guaranteed subsequently paper provide results earlier sections investigated recovery items either exactly hamming error. exact recovery quite strict certain applications whereas property hamming error allowing items replaced arbitrary items undesirable. indeed many applications requirements beyond metrics; instance papers exact approximate hamming recovery settings require estimator output items either exactly approximately equal true items. estimate deemed successful? think problem follows. speciﬁed requirement exact approximate hamming recovery associated k-sized subsets possible ranks. estimator deemed successful true ranks chosen items equals subsets. notion generalized recovery refer sets allowed sets. example case might generality denote family k-sized subsets refer family allowed sets. notice allowed deﬁned positions items true ordering items themselves. true underlying ordering items ﬁxed element family speciﬁes items themselves. interpretations depending context deﬁnition terms positions specify requirements deﬁnition terms items evaluate estimator given underlying probability matrix deﬁnition family allowed sets k-set estimate respects structure positions items belongs family goal determine conditions family exist estimators example denote true underlying ordering items. following four popular requirements top-k identiﬁcation respect true permutation pre-speciﬁed parameter note requirements reduces exact recovery requirement moreover requirements rephrased terms families allowed sets. instance focus requirement k-sized subset positions allowable set. paper derive conditions govern k-set recovery allowable systems satisfy natural monotonicity condition. informally monotonicity condition requires items resulting replacing item allowed higher verify condition satisﬁed settings exact hamming-error recovery discussed example condition also satisﬁed four requirements discussed example following theorem establishes conditions produce estimator respects allowable requirement. order state recall score previously deﬁned equation notational convenience also deﬁne every consider monotonic family allowed sets integer every remarks lower bound order. first lower bound continues hold even probability matrix restricted follow parametric model restricted class. second terms threshold lower bound holds necessarily impose conditions lower bound along lines required theorem allowable sets interesting enough. concrete illustration consider requirement deﬁned parameters requirement satisﬁes condition selection item made uniformly random satisﬁes allowable requirement given success random selection algorithm parameter regime lower bounds therefore cannot universal must require conditions allowable sets. section empirically evaluate performance counting algorithm compare spectral algorithm simulations synthetic data well experiments using datasets amazon mechanical turk crowdsourcing platform. figure simulation results comparing spectral counting algorithm terms error rates exact recovery items computation time. histogram fraction instances algorithm failed recover items correctly average value across trials. counting algorithm error across problems spectral accurate parametric models increasingly inaccurate models. histogram plots maximum computation time taken counting algorithm minimum computation time taken spectral across trials. even though maximum-to-minimum comparison unfair counting algorithm involves orders magnitude less computation. begin simulations using synthetically generated data items observation probability pairwise comparison models ranging possible types. panel figure provides histogram plot associated error rates recovering items counting algorithm versus spectral algorithm. corresponds average trials. panel compares times algorithms. value ﬁrst models derived section detail model types given bradley-terry-luce model recall theoretical guarantees spectral algorithm applicable data generated model guaranteed spectral algorithm gives accuracy model. counting algorithm also obtains accuracy importantly counting algorithm requires computational time orders magnitude lower spectral mle. thurstone model thurstone model another parametric model function equation cumulative distribution function standard gaussian distribution. spectral counting algorithm gave accuracy model. modiﬁcation. comparisons among items follow model before remaining item always beats ﬁrst items always loses items. counting algorithm continues achieve accuracy strong stochastic transitivity model simulate independent diagonals construction class. spectral often unsuccessful recovering items counting algorithm always succeeds. mixture models consider sets people opposing preferences. ﬁrst people certain ordering items mind preferences follow model ordering. second people opposite ordering preferences also follow model opposite ordering. overall preference probabilities mixture sets people. simulations observe counting algorithm always successful spectral method often fails. violation separation condition simulate model choice parameter small enough value one-tenth recommended value section observe counting algorithm incurs lower errors spectral algorithm thereby demonstrating robustness. summarize performance algorithms contrasted following way. stated lower bounds satisﬁed consistent theoretical claims copeland counting algorithm succeeds irrespective form pairwise probability distributions. spectral algorithm performs well pairwise comparison probabilities faithful parametric models often unsuccessful otherwise. even condition violated performance counting algorithm remains superior spectral mle. terms computational complexity every instance simulated counting algorithm took several orders magnitude less time compared spectral mle. order evaluate accuracy algorithms consideration require datasets consisting pairwise comparisons questions associated objective veriﬁable ground truth. used cardinal versus ordinal dataset past work three experiments performed paper suitable evaluations here—namely ones question ground truth pairs items chosen uniformly random. three experiments tested workers’ general knowledge audio visual understanding respective tasks involved identifying pair cities greater geographical distance identifying higher frequency piano identifying spelling mistakes paragraph text. number items three experiments respectively. total number pairwise comparisons respectively. fraction pairwise comparisons whose figure evaluation spectral counting algorithm three datasets amazon mechanical turk terms error rates k-subset recovery. three panels plot hamming error recovering items three datasets figure shows results experiments. point plots average across trials. observe counting algorithm consistently outperforms spectral mle. moreover spectral algorithm required orders magnitude computation time compared counting. thus counting algorithm performs well simulated well real data. outperforms spectral number items large also problem sizes small seen experiments. version future reference. integer collection distributions pl}. suppose observe random variable obtained ﬁrst sampling index uniformly random drawing construction random variables inequality zero-mean mutually independent bounded absolute value properties alone would allow obtain tail bound hoeﬀding’s inequality; however order obtain stated result need reﬁned result aﬀorded bernstein’s inequality order derive bound bernstein type remaining step bound second moments random variables hand. straightforward calculations yield symmetry problem allows assume without loss generality prove lower bound ﬁrst constructing ensemble diﬀerent problems considering problem distinguishing them. deﬁne k-sized subset associated matrix pairwise verify construction falls intersection parametric models model. parametric case construction amounts paramk value associated every value. also observe every distribution }ij∈i<j∈ mutually independent distribution follow uniform distribution index suppose given observations components drawn according model consequently marginal distribution mixture distribution models. based observing goal recover correct index underlying lower bound error bound associated test problem. order apply fano’s inequality following result provides control kullback-leibler divergence pair probabilities involved. denote probabilities taken pairwise comparisons drawn according model condition ensures construction valid probability distribution. compute distribution score item equals fano’s inequality obtain claimed lower bound. order apply result ﬁrst obtain upper bound kullback-leibler divergence probability distributions observed data pair problems constructed above. ranking item ranked position every given lower bound satisﬁed theorem ensures probability least counting estimator ranks every item higher every item comparison probabilities. however property mandates estimator identifying underlying distribution errs probability least assuming sets probability distributions satisfying properties exist putting results together yields claimed result. tation rows columns modulo permutation identical values. words distributions diﬀer identities items values pairwise-comparison probabilities among ordered sequence items identical across distributions prove lemma section. given lemma complete proof theorem. bits strings given lemma denote h-sized subset corresponding positions equalling string. also deﬁne sets k−h} \\∪b). note construction valid since sets pairwise comparison probability distributions show sets satisfy required properties. mentioned earlier matrix comparison-probabilities takes values given diﬀers underlying ordering items. particular associate distributions ordering items ranks every item higher every item every item turn higher every item items given guarantees provided lemma distinct construction consequently satisﬁes ﬁrst sets size each. deﬁne associated string ones positions corresponding partition zeros elsewhere. strings hamming weight every pair hamming distance least total number strings equals items. order ensure gets least items remaining chosen items must least items hence symmetry chosen items must contain least items probability least putting arguments remains deal subtle technicality. construction involves items identical scores. recall deﬁnition user-deﬁned requirement case multiple items identical scores considered choice either items valid. following lemma helps overcome issue. order state constructed proof theorem sets ordering items. assignment valid given estimator s-respecting probability least s-respectiin probability least paper analyzed problem recovering highly ranked items based observing noisy comparisons. proved algorithm simply selects items maximum number comparisons constant factors informationtheoretically optimal procedure. results also extend recovering entire ranking items simple corollary. empirical evaluations algorithm takes several orders magnitude lower computation time providing higher accuracy compared prior work. results paper thus underscore philosophy occam’s razor simplest answer often correct. number open questions suggested work. observation model considered based random number observations pairs comparisons. would interesting extend results cases speciﬁc subsets pairs observed. moreover considered random design setting control pairs compared. notion allowable sets introduced paper apply recovery k-sized subsets items; formulation associated results apply recovery partial total orderings items. parallel line literature studies settings pairs compared chosen sequentially data-dependent manner best knowledge line literature considers metric exact recovery items. interest investigate hamming allowable recovery problems active setting. work partially supported grant cif--; force oﬃce scientiﬁc research grant afosr-fa---; oﬃce naval research grant onr-n. addition also supported part microsoft research fellowship.", "year": 2015}