{"title": "Semantics, Representations and Grammars for Deep Learning", "tag": ["cs.LG", "cs.NE", "stat.ML"], "abstract": "Deep learning is currently the subject of intensive study. However, fundamental concepts such as representations are not formally defined -- researchers \"know them when they see them\" -- and there is no common language for describing and analyzing algorithms. This essay proposes an abstract framework that identifies the essential features of current practice and may provide a foundation for future developments.  The backbone of almost all deep learning algorithms is backpropagation, which is simply a gradient computation distributed over a neural network. The main ingredients of the framework are thus, unsurprisingly: (i) game theory, to formalize distributed optimization; and (ii) communication protocols, to track the flow of zeroth and first-order information. The framework allows natural definitions of semantics (as the meaning encoded in functions), representations (as functions whose semantics is chosen to optimized a criterion) and grammars (as communication protocols equipped with first-order convergence guarantees).  Much of the essay is spent discussing examples taken from the literature. The ultimate aim is to develop a graphical language for describing the structure of deep learning algorithms that backgrounds the details of the optimization procedure and foregrounds how the components interact. Inspiration is taken from probabilistic graphical models and factor graphs, which capture the essential structural features of multivariate distributions.", "text": "deep learning currently subject intensive study. however fundamental concepts representations formally deﬁned researchers know them common language describing analyzing algorithms. essay proposes abstract framework identiﬁes essential features current practice provide foundation future developments. backbone almost deep learning algorithms backpropagation simply gradient computation distributed neural network. main ingredients framework thus unsurprisingly game theory formalize distributed optimization; communication protocols track zeroth ﬁrst-order information. framework allows natural deﬁnitions semantics representations grammars much essay spent discussing examples taken literature. ultimate develop graphical language describing structure deep learning algorithms backgrounds details optimization procedure foregrounds components interact. inspiration taken probabilistic graphical models factor graphs capture essential structural features multivariate distributions. introduction deep learning achieved remarkable successes object voice recognition machine translation reinforcement learning tasks practical standpoint problem supervised learning well-understood largely solved least regime labeled data computational power abundant. workhorse underlying deep learning algorithms error backpropagation simply gradient descent distributed across neural network chain rule. gradient descent variants well-understood applied convex nearly convex objectives particular strong performance guarantees stochastic adversarial settings reasons success gradient descent non-convex settings less clear although recent work provided evidence local minima good enough modern convolutional networks close enough convex many results rates convergence apply rate convergence gradient-descent control generalization performance even nonconvex settings taking step back gradient-based optimization provides well-established computational primitives theoretical backing simple cases empirical backing others. first-order optimization thus falls broadly category computing eigenvector inverting matrix given essay proposes abstract optimization algorithms used weight updates focus components deep learning algorithms interact. treating optimization computational primitive encourages shift low-level algorithm design higher-level mechanism design shift attention designing architectures guaranteed learn distributed representations suited speciﬁc objectives. goal introduce language level abstraction designers focus formal speciﬁcations specify plug-and-play optimization modules combine larger learning systems. representation? recall representation learning commonly understood. bengio describe representation learning learning transformations data make easier extract useful information building classiﬁers predictors speciﬁcally deep learning algorithm particular kind representation learning procedure discovers multiple levels representation higher-level features representing abstract aspects data finally lecun state multiple levels representations obtained composing simple non-linear modules transform representation level representation higher slightly abstract level. composition enough transformations complex functions learned. classiﬁcation tasks higher layers representation amplify aspects input important discrimination suppress irrelevant variations quotes describe operation successful deep learning algorithm. lacking characterization makes deep learning algorithm work ﬁrst place. properties must algorithm learn layered representations? mean representation learned layer useful another? what exactly representation? practice almost deep learning algorithms rely error backpropagation align representations learned diﬀerent layers network. suggests answers questions tightly bound ﬁrst-order optimization methods. therefore unsurprisingly bulk paper concerned tracking ﬁrst-order information. framework intended facilitate design general ﬁrst-order algorithms backpropagation. semantics. started need theory meaning semantics encoded neural networks. since nothing special neural networks approach taken inclusive minimalistic. deﬁnition states meaning function implicitly categorizes inputs assigning outputs. next step characterize functions whose semantics encode knowledge turn optimization representations optimizations. nemirovski yudin developed black-box computational model analyze computational complexity ﬁrst-order optimization methods blackbox model abstract view optimization turing machine model speciﬁes communication protocol tracks often algorithm makes queries objective. useful reﬁne nemirovski yudin’s terminology distinguishing black-boxes respond zeroth-order information gray-boxes respond zerothﬁrst-order information preliminaries hand deﬁnition proposes representation function local solution optimization problem. since restrict convex problems ﬁnding global solutions feasible. indeed recent experience shows global solutions often necessary practice local solution similar semantics represents ideal solution. ideal solution usually cannot found computational limitations since problem nonconvex access ﬁnite sample unknown distribution etc. distributed representations game theory provides tools analyzing distributed optimization problems players minimizes losses depend actions also actions players game game theory traditionally focused convex losses since theoretically amenable. here restriction imposed losses diﬀerentiable almost everywhere. allowing nonconvex losses means error-backpropagation reformulated game. interestingly enormous freedom choosing players. correspond individual units layers entire neural networks variety other intermediate choices. advantage game-theoretic formulation thus applies many diﬀerent scales. nonconvex losses local optima essential developing scale-free formalism. even turns particular units particular layer neural network solving convex problem convexity destroyed soon units layers combined form larger learning systems. convexity property preserved general units combined layers layers networks. therefore convenient introduce computational primitive arglocopt denote output ﬁrst-order optimization procedure deﬁnition concern excessive generality. potential criticism formulation broad. little said nonconvex optimization general; introducing games many players jointly optimize arbitary nonconvex functions compounds problem. additional structure required. successful case study found presents detailed game-theoretic analysis rectiﬁer neural networks. analysis rectiﬁer units almost convex. main result rate convergence neural network local optimum controlled regret algorithms applied compute weight updates network. whereas relied heavily speciﬁc properties rectifer nonlinearities paper considers widerange deep learning architectures. nevertheless possible carve interesting subclass nonconvex games identifying composition simple functions essential feature common deep learning architectures. compositionality formalized distributed communication protocols grammars. grammars games. neural networks constructed composing series elementary operations. resulting feedforward computation captured computation graph backpropagation traverses graph reverse recursively computes gradient respect parameters node. section maps feedforward feedback computations onto queries responses arise nemirovski yudin’s model optimization. however queries responses highly structured. query phase players feed parameters computation graph performs feedforward sweep. response phase oracles reveal ﬁrst-order information second computation graph cases response graph simply implements backpropagation. however examples not. three highlighted here section especially sections algorithms response graphs simply implement backprop include diﬀerence target propagation feedback alignment truncated backpropagation time choice made backprop short. examples query response graph diﬀer particular interest since point towards general classes deep learning algorithms. distributed communication protocol game additional structure query response graphs deﬁnition graphs capture compositional structure functions learned neural network compositional structure learning procedure respectively. important purposes feedforward feedback sweeps correspond distinct graphs communication protocol kept distinct optimization procedure. communication protocol speciﬁes information ﬂows networks without specifying players make players treated plug-and-play rational agents provided carefully constructed coordinated ﬁrst-order information optimize finally grammar distributed communication protocol equipped guarantee response graph encodes suﬃcient information players jointly local optimum objective function. paradigmatic example grammar backpropagation. grammar thus game designed perform task. representation learned layer useful another game guaranteed converge local solution objective players interact though grammar. follows players build representations jointly encode knowledge task. caveats. follows provisional. deﬁnitions ﬁrst attempt capture interesting perhaps useful perspective deep learning. essay contains theorems algorithms experiments real work based ideas presented here. essay intended comprehensive. many details left many important aspects covered notably probabilistic bayesian formulations various methods unsupervised pre-training. series worked examples. line provisional nature much essay spent applying framework worked examples error backpropagation supervised model variational autoencoders generative adversarial networks unsupervised learning; deviator-actorcritic model deep reinforcement learning kickback biologically plausible variant backpropagation examples chosen part maximize variety part based familiarity. discussions short; interested reader encouraged consult original papers gaps. last examples particularly interesting since response graphs diﬀer substantially backpropagation. model constructs zeroth-order black-box estimate gradients rather querying ﬁrst-order gray-box. kickback prunes backprop’s response graph replacing gray-boxes black-boxes approximating chain rule local computations. related work bottou gallinari proposed decompose neural networks cooperating modules decomposing general algorithms models collections interacting agents dates back shrieking demons comprised selfridge’s pandemonium long line related work focus components neural networks players rational agents right developed derives work aimed modeling biological neurons game-theoretically related approach semantics based general value functions found sutton remark computation graphs applied backprop basis python library theano provide backbone automatic/algorithmic diﬀerentiation grammars technical term theory formal languages relating chomsky hierarchy apparent relation notion grammar presented here aside relating structural rules governing composition. formal languages deep learning suﬃciently disparate ﬁelds little risk terminological confusion. similarly notion semantics introduced distinct semantics theory programming languages. although game theory originally developed model human interactions pointed directly applicable interacting populations algorithms so-called machina economicus paper goes step propose games played ﬁrst-order communication protocols component foundations deep learning. source inspiration essay bayesian networks markov random ﬁelds. probabilistic graphical models factor graphs provide simple powerful ways encode multivariate distribution’s independencies diagram greatly facilitated design analysis probabilistic algorithms. however comparable framework distributed optimization deep learning. essay intended ﬁrst step direction. semantics representations section deﬁnes semantics representations. short semantics function categorizes inputs; function representation selected optimize objective. connection deﬁnition representation representation learning clariﬁed section possible world semantics introduced lewis formalize meaning sentences terms counterfactuals proposition world. truth depends content state world. rather allowing state world vary convenient introduce possible worlds. denote proposition applied world meaning mapping assigns according whether proposition true. equivalently meaning proposition ordered pair consisting worlds subset worlds true example meaning pblue =that blue subset possible worlds pointing blue object. concept blue rendered explicit exhaustive list possible examples. whereas propositions true false output function neither. however functions optimize criterion refer accurately function represents other. deﬁne representations therefore need take quick detour optimization deﬁnition communication protocol optimizing unknown objective consists user oracle. round user presents query oracle respond ways depending nature protocol protocol speciﬁes player oracle interact without specifying algorithm used player decide points query. next section introduces distributed communication protocols general framework includes variety deep learning architectures special cases without specifying precise algorithms used perform weight updates. intuitively objective quantiﬁes extent functions categorize inputs similarly. operation arglocopt applies ﬁrst-order method function whose semantics resembles optimal solution argoptθ∈θ short representations functions useful semantics usefulness quantifed using speciﬁc objective lower loss higher reward associated function useful relation deﬁnition representations commonly understood deep learning literature discussed section below. remark related work sutton proposed semantics i.e. knowledge world encoded general value functions provide answers speciﬁc questions expected rewards. deﬁnition general approach since associates semantics function. however function must arise optimizing objective semantics accurately represent phenomenon interest. setup admits variety complications practice. firstly typically infeasible even local optimum. instead solution within small local optimum suﬃces. secondly distribution unknown expectation replaced ﬁnite sample. quality resulting representation extensively studied statistical learning theory finally often convenient modify objective example incorporating regularizer. thus detailed presentation would conclude nature deterministic black-box since queried directly nature produces pairs stochastically rather response speciﬁc inputs. notion black-box extended stochastic black-boxes e.g. however prefer keep exposition simple possible. nature samples points distribution estimator chooses parameters operator computes probability density depends parameter operator acts loss. objective mimimize reinforcement learning third example taken reinforcement learning return reinforcement learning section example presented detail. reinforcement learning agent interacts environment often modeled markov decision process consisting state space action space initial distribution states stationary transition distribution reward function agent chooses actions based policy function states actions. goal optimal policy. actor-critic methods break problem pieces critic estimates expected value state-action pairs given current policy actor attempts optimal policy using estimates provided critic. critic typically trained temporal diﬀerence methods denote distribution states time given policy initial state discounted remark temporal diﬀerence learning strictly speaking gradient-based method residual gradient method performs gradient descent bellman error suﬀers double sampling projected ﬁxpoint methods minimize projected bellman error gradient descent nice convergence properties interesting recent proposal implicit learning based implicit gradient descent protocols grammars often useful decompose complex problems simpler subtasks handled specialized modules. examples include variational autoencoders generative adversarial networks actor-critic models. neural networks particularly well-adapted modular designs since units layers even entire networks easily combined analogously bricks lego however conﬁgurations viable models. methodology required distinguish good designs bad. section provides basic language describe bricks glued together useful design tool. idea extend deﬁnitions optimization problems protocols representations section single multi-player optimization problems. classic example ﬁnite game player menu di-actions chooses round. losses speciﬁed individual actions extended linearly distributions actions. natural generalization ﬁnite games convex games parameter spaces compact convex sets loss convex function ith-argument shown players implementing no-regret algorithms guaranteed converge correlated equilibrium convex games query phase. players provide inputs query graph operators transform outputs. response phase. operators oracles response graph input subgradients protocol speciﬁes players oracles communicate without specifying optimization algorithms used players. addition response graph allows general computations simply backpropagating gradients query phase. additional ﬂexibility allows design algorithms sections below. also sometimes necessary computational reasons. example backpropagation time recurrent networks typically runs truncated response graph suppose wish optimize objective function depends moves players. finding global optimum clearly feasible. however able construct protocol players jointly able local optima objective. cases refer protocol grammar guarantee ensures representations constructed players grammar combined coherent distributed representation. ensures representations constructed players transform data useful optimizing shared objective players’ losses need explicitly computed. necessary response phase communicate gradient information needed players locally minimize losses yields local optimum objective. basic building blocks function composition chain rule functions inserted grammars lego-like building blocks function composition queries chain rule responses. function takes inputs provided player chain rule implemented response phase follows. oracleg reports gradient response phase. operator computes products matrix multiplication. projection product onto ﬁrst second components reported player upstream respectively. variational autoencoder uses surrogate objective variational lower bound. maximizing surrogate guaranteed also maximize true objective computational intractable; section remark considerable freedom regarding choice players. examples below players typically chosen layers entire neural networks keep diagrams simple. worth noting zooming players correspond individual units proven useful tool analyzing neural networks game-theoretic formulation thus scale-free coarseﬁne-grained required. mathematical language tracking structure hierarchical systems diﬀerent scales provided operads references therein natural setting study composition operators receive multiple inputs. error backpropagation main example grammar neural network using error backpropagation perform supervised learning. layers network modeled players game. setting layer’s objective network’s loss minimizes using gradient ascent yields backpropagation. protocol extended convolutional networks replacing matrix multiplications performed operator convolutions adding parameterless max-pooling operators representation learning. position relate notion representation deﬁnition standard notion representation learning neural networks. terminology section player learns representation. representations learned diﬀerent players form coherent distributed representation jointly optimize single objective function. deﬁnition comrepresentation above. moreover compositional structure network implies sˆθl posed subrepresentations corresponding optimizations performed diﬀerent players grammar function sˆθj optimized transform inputs form useful network whole. detailed analysis convergence rates. little said general rate converge layers neural network since loss convex. however neural networks decomposed treating individual units players. units linear rectilinear turns network circadian game. circadian structure provides convert results convergence convex optimization methods results global convergence rectiﬁer network local optimum variational autoencoders next example extends unsupervised setting described section suppose observations sampled i.i.d. two-step stochastic process latent value sampled {x}n sampled goal maximum likelihood estimator observed data estimate posterior distribution conditioned observation straightforward approach maximize marginal likelihood however integral typically untractable roundabout tactic required. approach proposed construct neural networks decoder learns generative model approximating encoder learns recognition model posterior approximating turns useful replace encoder deterministic function noise source pnoise compatible. here compatible means sampling equivalent sampling pnoise computing encoder decoder play parameters respectively. operator neural network encodes samples latent variables. operator neural network estimates probability conditioned remaining operators compute variational lower bound ﬁrst guarantee surrogate objective computed query graph yields good solutions. second guarantee response graph communicates correct gradients. generative-adversarial networks recent approach designing generative models construct adversarial game forger curator forger generates samples; curator aims discriminate samples produced forger produced nature. forger aims create samples realistic enough fool curator. environment samples images i.i.d. noise samples i.i.d. forger curator play parameters respectively. operator neural network produces fake image operator neural network estimates probability image fake. remaining operators compute loss curator minimizes forger maximizes note copies operator query graph. response graph implements chain rule tweak multiplies gradient communicated forger ensure forger maximizes loss curator minimizing. generative-adversarial network ﬁrst example response graph simply backpropagate gradients arrow labeled computed whereas backpropagation would minus sign arises adversarial relationship forger curator optimize objective. discussed section actor-critic algorithms decompose reinforcement learning problem components critic learns approximate value function predicts total discounted future reward associated state-action pairs actor searches policy maximizes value appoximation provided critic. action-space continuous natural approach follow gradient shown compute policy gradient given true value function. furthermore suﬃcient conditions provided approximate value function learned critic yield unbiased estimator policy gradient. recently provided analogous results deterministic policies. actor critic deviator play parameters respectively. operator neural network computes actions operator neural network estimates value state-action pairs. operator neural network estimates gradient value function. remaining operator computes bellman gradient error critic deviator minnote instead backpropagating ﬁrst-order information form gradient response graph instead backpropagates zeroth-order information form gradient-estimate computed query graph feedforward sweep. therefore write emphasize gradients communicated actor estimates. critic estimates value function td-learning cloning improved stability deviator estimates value gradient td-learning gradient perturbation trick actor follows correct gradient policy gradient theorem internal workings neural network guaranteed correct chain rule. appealing features algorithm actor insulated critic interacts deviator critic deviator learn diﬀerent features adapted representing value function gradient respectively. previous work used derivative value-function estimate guaranteed compatible function approximation lead problems value-function estimated using functions rectiﬁers smooth kickback finally consider kickback biologically-motivated variant backprop reduced communication requirements problem kickback solves backprop requires distinct kinds signals communicated units feedforward feedback whereas signal type spikes produced cortical neurons. kickback computes estimate backpropagated gradient using signals generated feedforward sweep. kickback also requires gradient loss respect output broadcast units analogous role played diﬀuse chemical neuromodulators response graph contains single oracle broadcasts gradient loss respect network’s output gradient estimates layer computed using mixture oracle local zeroth-order information referred kicks loss functions layers computed query graph. nevertheless gradients communicated layers response graph exact respect layers’ losses purposes convenient focus global objective neural network treat gradients communicated layers estimates gradient global objective respect layers’ weights. guarantee kickback that network coherent gradient estimate ˆδθi computed using zeroth-order kicks sign backpropagated error computed using gradients details. result smalls steps direction gradient estimates guaranteed decrease network’s loss. remark kickback uses single oracle analogous neuromodulatory signal contrast backprop requires oracle layer. rest oracles replaced kicks zeroth-order information gradient-estimates constructed. importantly kick computation layer requires locally available information produced neighboring layers feedforward sweep. feedback signals analogous signals transmitted nmda synapses. recent alternatives backprop also rely backpropagating exact gradients target propagation feedback alignment target propagation makes without gradients implementing autoencoders layer. unfortunately optimization problems force authors introduce correction term involving diﬀerences targets. consequence contrast kickback information required layers diﬀerence target propagation cannot computed locally instead requires recursively backpropagating diﬀerences output layer. feedback alignment solves diﬀerent problem feedback forward weights required equal backprop authors observe using random feedback weights suﬃce. unfortunately diﬀerence target propagation feedback alignment still requires separate feedforward recursively backpropagated training signals weight updates local. unfortunately conceptual level kickback target propagation feedback alignment tackle wrong problem. cortex performs reinforcement learning mammals provided labels clearly deﬁned output layer signals could backpropagate. biologically-plausible deep learning algorithm take advantage particularities reinforcement learning setting. hinton deng dahl mohamed jaitly senior vanhoucke nguyen sainath kingsbury deep neural networks acoustic modeling speech recognition. ieee signal processing magazine mnih kavukcuoglu silver rusu veness bellemare graves riedmiller fidjeland ostrovski petersen beattie sadik antonoglou king kumaran wierstra legg hassabis human-level control deep reinforcement learning. nature rumelhart hinton williams parallel distributed processing. foundations. press schmidhuber deep learning neural networks overview. neural networks robbins monro stochastic approximation method. annals math stat nemirovski yudin cezari’s convergence steepest descent method approximating saddle zinkevich online convex programming generalized inﬁnitesimal gradient ascent. icml cesa-bianchi lugosi prediction learning games. cambridge university press bottou bousquet tradeoﬀs large scale learning. nips shalev-shwartz online learning online convex optimization. foundations trends machine balduzzi deep online convex optimization putting forecaster sleep. arxiv. hardt recht singer train faster generalize better stability stochastic gradient descent. nowozin wright optimization machine learning. press nemirovski yudin problem complexity method eﬃciency optimization. wiley-interscience agarwal bartlett ravikumar wainwright information-theoretic lower bounds oracle neumann morgenstern theory games economic behavior. princeton university press nisan roughgarden tardos vazirani algorithmic game theory cambridge university press griewank walther evaluating derivatives principles techniques algorithmic diﬀerentiation. siam baydin pearlmutter automatic diﬀerentiation algorithms machine learning. jmlr workshop zhang fischer bengio diﬀerence target propagation. ecml pkdd lillicrap cownden tweed ackerman random feedback weights support learning deep neural williams zipser gradient-based learning algorithms recurrent networks computational complexity. backpropagation theory architectures applications. edited chauvin rumelhart lawrence erlbaum associates russell norvig artiﬁcial intelligence modern approach. prentice hall edition gershman horvitz tenenbaum computational rationality converging paradigm intelligence bottou gallinari framework cooperation learning algorithms. nips bottou machine learning machine reasoning essay. machine learning selfridge pandemonium paradigm learning. mechanisation thought processes proc symposium klopf hedonistic neuron theory memory learning intelligence. washington hemi-sphere barto learning statistical cooperation self-interested neuron-like computing elements. human minsky society mind. simon schuster baum toward model intelligence economy agents. machine learning kwee hutter schmidhuber market-based reinforcement learning partially observable worlds. bartheld wang butowt anterograde axonal transport transcytosis recycling neurotrophic factors concept trophic currencies neural networks. molecular neurobiology lewis harris neural market place general formalism linear theory. biorxiv balduzzi besserve towards learning-theoretic analysis spike-timing dependent plasticity. sutton modayil delp degris pilarski white precup horde scalable real-time architecture learning knowledge unsupervised motor interaction. proc. int. conf. agents multiagent systems hopcroft ullman introduction automata theory languages computation. addison-wesley barbu supervised aggregation classiﬁers using artiﬁcial prediction markets. international parkes wellman economic reasoning artiﬁcial intelligence. science frongillo reid convergence analysis prediction markets randomized subspace descent. pearl probabilistic reasoning intelligent systems networks plausible inference. morgan kaufmann kschischang frey loeliger factor graphs sum-product algorithm. ieee trans. inf. theory vapnik nature statistical learning theory. springer sutton barto reinforcement learning introduction. press barto sutton anderson neuronlike adapative elements solve diﬃcult learning sutton learning predict method temporal diﬀerences. machine learning dann neumann peters policy evaluation temporal diﬀerences survey comparison. baird residual algorithms reinforcement learning function approximation. icml sutton maei precup bhatnagar silver szepesv´ari wiewiora fast gradient-descent methods prokhorov wunsch adaptive critic designs. ieee trans. neur. net. hafner riedmiller reinforcement learning feedback control challenges benchmarks dayan twenty-five lessons computational neuromodulation. neuron glorot bordes bengio deep sparse rectiﬁer neural networks. proc. conference artiﬁcial", "year": 2015}