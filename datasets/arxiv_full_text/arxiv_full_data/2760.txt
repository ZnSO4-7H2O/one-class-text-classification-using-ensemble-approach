{"title": "Adaptive Bayesian Sampling with Monte Carlo EM", "tag": ["cs.LG", "cs.AI", "stat.ML"], "abstract": "We present a novel technique for learning the mass matrices in samplers obtained from discretized dynamics that preserve some energy function. Existing adaptive samplers use Riemannian preconditioning techniques, where the mass matrices are functions of the parameters being sampled. This leads to significant complexities in the energy reformulations and resultant dynamics, often leading to implicit systems of equations and requiring inversion of high-dimensional matrices in the leapfrog steps. Our approach provides a simpler alternative, by using existing dynamics in the sampling step of a Monte Carlo EM framework, and learning the mass matrices in the M step with a novel online technique. We also propose a way to adaptively set the number of samples gathered in the E step, using sampling error estimates from the leapfrog dynamics. Along with a novel stochastic sampler based on Nos\\'{e}-Poincar\\'{e} dynamics, we use this framework with standard Hamiltonian Monte Carlo (HMC) as well as newer stochastic algorithms such as SGHMC and SGNHT, and show strong performance on synthetic and real high-dimensional sampling scenarios; we achieve sampling accuracies comparable to Riemannian samplers while being significantly faster.", "text": "present novel technique learning mass matrices samplers obtained discretized dynamics preserve energy function. existing adaptive samplers riemannian preconditioning techniques mass matrices functions parameters sampled. leads signiﬁcant complexities energy reformulations resultant dynamics often leading implicit systems equations requiring inversion high-dimensional matrices leapfrog steps. approach provides simpler alternative using existing dynamics sampling step monte carlo framework learning mass matrices step novel online technique. also propose adaptively number samples gathered step using sampling error estimates leapfrog dynamics. along novel stochastic sampler based nosé-poincaré dynamics framework standard hamiltonian monte carlo well newer stochastic algorithms sghmc sgnht show strong performance synthetic real high-dimensional sampling scenarios; achieve sampling accuracies comparable riemannian samplers signiﬁcantly faster. markov chain monte carlo sampling well-known techniques learning complex bayesian probabilistic models arise machine learning. typically used cases computing posterior distributions parameters closed form feasible mcmc techniques converge reliably target distributions offer provably correct draw samples target parameters arbitrarily complex probability distributions. recently proposed method domain hamiltonian monte carlo formulates target density energy function augmented auxiliary momentum parameters uses discretized hamiltonian dynamics sample parameters preserving energy function. resulting samplers perform noticeably better random walk-based methods terms sampling efﬁciency accuracy stochastic settings uses random minibatches data calculate gradients likelihoods better scalability researchers used fokker-planck correction steps preserve energy face stochastic noise well used auxiliary thermostat variables control effect noise momentum terms batch setting methods exploited energy-preserving dynamics sample efﬁciently random walk-based stochastic samplers primary parameter interest augmented energy function-based samplers mass matrix kinetic energy term; noted various researchers matrix plays important role trajectories taken samplers parameter space interest thereby affecting overall efﬁciency. prior efforts identity matrix pre-calculated value recent work shown signiﬁcant gains efﬁciency well convergent accuracy reformulating mass terms target parameters sampled thereby making sampler sensitive underlying geometry. done imposing positive deﬁnite constraint adaptive mass using metric riemannian manifold probability distributions parametrized target parameters. constraint also satisﬁes condition momenta sampled gaussian mass covariance. often called riemannian preconditioning idea applied batch well stochastic settings derive hmc-based samplers adaptively learn critically important mass matrix data. sometimes sidestepped performing ﬁxed point updates cost additional error restricting oneself simpler formulations honor symmetric positive deﬁnite constraint diagonal matrix latter choice ameliorates added complexity clearly suboptimal context adapting underlying geometry parameter space. thus would ideally need mechanism robustly learn critical mass hyperparameter data without signiﬁcantly adding computational burden. address issue work monte carlo framework. alternative venerable technique mcem used locally optimize maximum likelihood problems posterior probabilities required step cannot computed closed form. work perform existing dynamics derived energy functions monte carlo step holding mass ﬁxed stored samples momentum term learn mass step. address important issue selecting appropriate e-step sampling iterations using error estimates gradually increase sample sizes markov chain progresses towards convergence. combined online method update mass using sample covariance estimates step gives clean scalable adaptive sampling algorithm performs favorably compared riemannian samplers. synthetic experiments high dimensional topic modeling problem complex bayesian nonparametric construction samplers match beat riemannian variants sampling efﬁciency accuracy close observed data denotes model parameters. denotes likelihood data given parameters along bayesian prior denotes auxiliary momentum mentioned above. note second term energy function kinetic energy simply kernel gaussian mass matrix acting covariance. hamilton’s equations motions applied energy function derive following differential equations accent denoting time derivative machine learning applications typically large datasets computing gradients likelihoods every leapfrog step followed metropolis-hastings correction ratio prohibitively expensive. address this uses random minibatches dataset iteration allowing stochastic noise improved scalability removes metropolis-hastings correction steps preserve system energy context additionally apply fokker-planck corrections dynamics stochastic sampler uses techniques preserve canonical gibbs energy researchers also used notion thermostats molecular dynamics literature control behavior momentum terms face stochastic noise; resulting algorithm preserves energy well. mentioned above learning mass matrices mcmc systems important challenge. researchers traditionally used riemannian manifold refomulations address this integrate updating mass sampling steps. authors approach derive adaptive variants ﬁrst-order langevin dynamics well hmc. latter reformulated energy function written dimensionality parameter space. note momentum variable integrated recover desired marginal density spite covariance function machine learning literature authors used diagonal produce adaptive variant algorithm whereas authors derived deterministic stochastic algorithms riemannian variant nosé-poincaré energy resulting adaptive samplers preserving symplecticness well canonical system temperature. algorithm widely used learn maximum likelihood parameter estimates complex probabilistic models. cases expectations likelihoods required step tractable monte carlo simulations posterior instead. resulting monte carlo framework widely studied statistics literature various techniques developed efﬁciently draw samples estimate monte carlo errors step instance expected log-likelihood usually replaced following monte carlo approximation l|θ) represents latent augmentation variables used number samples taken step. applying framework typically carefully tune number samples gathered step since potential distance stationary distribution early phases would necessitate drawing relatively fewer samples progressively sampler nears convergence. work leverage mcem framework learn similar energies using samples discretized dynamics constitute step mcem framework suitable updates performed corresponding step. also novel mechanism dynamically adjust sample count using sampling errors estimated gathered samples described next. riemannian samplers start reformulating energy function making mass function adding suitable terms ensure constancy marginal distributions. approach fundamentally different cast task learning mass maximum likelihood problem space symmetric positive deﬁnite matrices. instance construct following problem standard corresponding step perform suitable updates mass speciﬁcally wrap standard sampler framework perform generalized leapfrog steps obtain proposal updates followed metropolis-hastings corrections step obtained values step. resultant adaptive sampling method shown alg. note framework also applied stochastic samplers preserve energy upto standard discretization errors. wrap sghmc sampler framework well since uses fokker-planck corrections approximately preserve energy presence stochastic noise. call resulting method sghmc-em specify alg. supplementary. thermostat variable constants chosen preserve correct marginals. sgnht dynamics used step maintain energy collected samples step before. call resultant method sgnht-em shown alg. note that unlike standard above perform metropolis-hastings corrections steps gathered samples cases. shown algorithms collect momenta samples epoch leapfrog iterations. s_count denote number samples collected running m-step update. existing riemannian adaptive algorithms literature start modifying energy function whereas framework requirement. long uses sampling mechanism preserves energy correct marginals stochastic sense otherwise used step framework. primary disadvantage riemannian algorithms added complexity dynamics derived modiﬁed energy functions. typically ends using generalized leapfrog dynamics lead implicit systems equations; solve either standard solvers complexity least cubic dimensionality scalability issues high dimensional datasets ﬁxed point updates worsened error guarantees. alternative approach diagonal covariance matrices mentioned earlier ignores coordinate correlations. mcem approach sidesteps issues keeping existing dynamics desired step sampler unchanged. shown experiments match beat riemannian samplers accuracy efﬁciency using suitable sample sizes step updates signiﬁcantly improved sampling complexities runtimes. turn attention task learning sample size step data. nontriviality issue following reasons ﬁrst cannot sampling dynamics convergence step without making whole process prohibitively slow; second account correlation among successive samples especially early process markov chain convergence possibly thinning techniques; third want increase sample count chain matures gets closer stationary disend leverage techniques derived mcem literature statistics ﬁrst evaluate suitable test function target parameters certain subsampled steps using gathered samples current step estimates. conﬁdence intervals created around evaluations gauge relative effect successive mcem estimates monte carlo error. updated values functions using newer m-step estimates intervals increase number samples collected next mcem loop. tioned below evaluate steps create conﬁdence intervals using sample z−α/vs means variances denotes subsample count z−α/ critical value standard gaussian conﬁdence interval mentioned earlier. sgnht-em details procedures. values constants well initial estimates given supplementary. running values denoted s_count hereafter. next turn attention task updating mass matrices using collected momenta samples. shown energy functions above momenta sampled zeromean normal distributions enabling standard covariance estimation techniques literature. however since using discretized mcmc obtain samples address variance arising monte carlo error especially burn-in phase. found running average updates work well experiments; particular updated inverse mass matrix denoted m-step below. note correspond precision matrix gaussian distribution momenta; updating m-step also removes need invert mass matrices leapfrog iterations. curiously found inverse empirical covariance matrix work quite well updates also induce fresh perspective convergence overall mcem procedure. existing convergence analyses statistics literature fall three broad categories almost sure convergence presented increasing sample sizes asymptotic angle presented sequence mcem updates analyzed approximation standard sequence sample size referred s_count above tends inﬁnity asymptotic consistency results obtained multiple gibbs chains letting chain counts iterations tend analysis differs these focusing maximum likelihood situations noted convex optimization problems using convergence techniques sequence iterates recall precision natural parameter normal distribution written exponential family notation log-likelihood concave function natural parameters family; makes max-likelihood convex optimization problem precision even presence linear constraints therefore implies problems unique maximum denoted above. also note update corresponds ﬁrst order update iterates l-regularized objective unit regularization parameter; denoted proposition. energy preserved sampler function mass augmented regularization term. resultant strongly convex optimization problem analyzed using techniques assumptions noted above; provide proof supplementary completeness. note stochasticity proof refer stochastic gradients used leapfrog dynamics algorithms instead think collected momenta samples stochastic minibatch used compute gradient regularized energy function covariance allowing deal monte carlo error indirectly. also note assumption unbiasedness estimates similar distinct assuming mcem samples unbiased; indeed would difﬁcult make latter claim since stochastic samplers general known convergent bias. next develop stochastic version dynamics derived nosé-poincaré hamiltonian followed mcem variant. allows direct comparison riemann manifold formulation mcem framework learning kinetic masses stochastic setting thermostat controls momentum terms desired properties like reversibility symplecticness provided generalized leapfrog discretizations. nosé-poincaré energy function written denotes half-step dynamics signiﬁes noisy stochastic estimates denote stochastic noise terms necessary fokker-planck corrections note solve quadratic equation qt+\u0001/ updates also closed-form opposed implicit system equations proof straightforward application fokker-planck corrections stochastic noise hamiltonian dynamics derived provided supplementary. dynamics ﬁrst develop sg-nphmc algorithm counterpart sghmc sgnht wrap mcem framework create sg-nphmc-em shall demonstrate shortly variant performs comparably sgr-nphmc signiﬁcantly faster. section compare performance mcem-augmented variants sghmc well sgnht standard counterparts mass matrices identity matrix. call augmented versions hmc-em sghmc-em sgnht-em respectively. baselines synthetic experiments addition standard samplers mentioned above also evaluate rhmc sgr-nphmc recent algorithms based dynamic riemann manifold formulations learning mass matrices. topic modeling experiment scalability reasons evaluate stochastic algorithms including recently proposed sgr-nphmc omit hmc-em rhmc. since restrict discussions paper samplers second-order dynamics compare methods sgld sgrld experiment learn parameters unidimensional standard normal distribution batch stochastic settings using data points generated analyzing impact mc-em framework way. compare algorithms mentioned hmc-em sghmc sghmc-em sgnht sgnht-em sg-nphmc sg-nphmc-em along rhmc sgr-nphmc. generative model consists normal-wishart priors mean precision posterior distribution denotes wishart distribution. algorithms number iterations discarding ﬁrst burn-in. batch sizes ﬁxed stochastic algorithms along leapfrog iterations across board. sgr-nphmc rhmc used observed fisher information plus negative hessian prior tensor ﬁxed point iteration implicit system equations arising dynamics both. used fairly high learning rate sghmc sgnht used respectively. sgr-nphmc used show rmse numbers collected post-burn-in samples well per-iteration runtimes table iteration refers complete step full quota leapfrog jumps. improvements afforded mcem framework immediately noticeable; hmc-em matches errors obtained rhmc effect matching sample distribution much faster iteration. stochastic mcem algorithms show markedly better performance well; sgnht-em particular beats sgr-nphmc rmse-τ signiﬁcantly faster simpler updates mass matrices. accuracy improvements particularly noticeable high learning next present results obtained bayesian logistic regression experiment using synthetic real datasets. synthetic case used methodology generated observations mixture normal distributions means mixing weights covariance classify points using linear classiﬁer weights attempt learn weights using samplers. priors weights used metric tensor described riemannian samplers. leapfrog steps riemannian samplers opted ﬁxed point iterations approximate solutions implicit equations. along synthetic setup also bayesian model australian credit heart regression datasets database additional runtime comparisons. australian credit dataset contains datapoints dimensionality heart dataset -dimensional datapoints. synthetic case discard ﬁrst samples burn-in calculate rmse values remaining samples. learning rates chosen values stochastic noise terms selected leapfrog steps chosen stochastic algorithms used batchsize rmse numbers synthetic dataset shown table per-iteration runtimes datasets shown table used initialized s_count hmc-em sghmc-em sgnht-em sg-nphmc-em. mcem framework noticeably improves accuracy almost cases computational overhead. note improvement sg-nphmc terms rmse runtime calculations samplers leapfrog steps ﬁxed s_count values mentioned above. comparisons riemannian algorithms tell clear story though somewhat better accuracy samplers orders magnitude slower. synthetic case instance iteration rhmc takes second using leapfrog steps ﬁxed point iterations implicit leapfrog equations whereas hmc-em simpler much faster. also note m-step calculations mcem framework involve single-step closed form update precision matrix using collected samples every s_count sampling steps; thus amortize cost m-step previous s_count iterations leading negligible changes per-sample runtimes. next turn attention high-dimensional topic modeling experiment using nonparametric gamma process construction. elect follow experimental setup described speciﬁcally poisson factor analysis framework denoting vocabulary documents corpus model observed counts vocabulary terms θk×n models counts latent topics documents denotes factor load matrix encodes relative importance vocabulary terms latent topics. following standard bayesian convention model columns dirichlet using normalized gamma variables priors document-speciﬁc mixing probabilities atom weights generated constructive gamma process deﬁnition refer reader paper details formulation. leads rich nonparametric construction poisson factor analysis model closed-form gibbs updates infeasible thereby providing testing application area stochastic mcmc algorithms. omit metropolis hastings correction-based rhmc samplers evaluation poor scalability. count matrices -newsgroups reuters corpus volume corpora former words documents second vocabulary size documents. used chronological train-test split datasets. following standard convention stochastic algorithms following minibatch learn document-speciﬁc parameters test calculate test perplexities remaining test perplexity commonly used measure evaluations detailed supplementary. noted atom weights three sets components hyperparameters three parallel chains parameters collecting samples momenta hyperparameter chains mcem mass updates. kept mass chain ﬁxed chose number latent topics. initialized s_count e-step sample size algorithms nphmc-em rest. increasing s_count time yielded fairly minor improvements hence kept ﬁxed values simplicity. additional details batch sizes learning rates stochastic noise estimates leapfrog iterations provided supplementary. -newsgroups dataset algorithms burn-in iterations collected samples next steps thereafter stride perplexity calculations. reuters dataset used burn-in iterations. note algorithms iteration corresponds full e-step stochastic minibatch. numbers obtained runs shown table along periteration runtimes. post-burnin perplexityvs-iteration plots -newsgroups dataset shown figure signiﬁcant improvements mcem framework samplers sgnht highly pronounced indeed sg-nphmc samplers lower perplexities obtained sgr-nphmc close order magnitude faster iteration -newsgroups even latter used diagonalized metric tensors ostensibly avoiding implicit systems equations leapfrog steps learn kinetic masses. framework yields nontrivial improvements reuters dataset well. propose theoretically grounded approach learning mass matrices hamiltonian-based samplers including standard stochastic variants using monte carlo framework. addition newly proposed stochastic sampler augment certain existing samplers technique devise algorithms learn kinetic masses dynamically data ﬂexible scalable fashion. experiments conducted synthetic real datasets demonstrate efﬁcacy efﬁciency framework compared existing riemannian manifold-based samplers. thank anonymous reviewers insightful comments suggestions. material based upon work supported national science foundation grant dms-. opinions ﬁndings conclusions recommendations expressed material author necessarily reﬂect views national science foundation.", "year": 2017}