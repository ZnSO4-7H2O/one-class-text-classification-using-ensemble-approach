{"title": "A Formal Measure of Machine Intelligence", "tag": ["cs.AI", "cs.LG"], "abstract": "A fundamental problem in artificial intelligence is that nobody really knows what intelligence is. The problem is especially acute when we need to consider artificial systems which are significantly different to humans. In this paper we approach this problem in the following way: We take a number of well known informal definitions of human intelligence that have been given by experts, and extract their essential features. These are then mathematically formalised to produce a general measure of intelligence for arbitrary machines. We believe that this measure formally captures the concept of machine intelligence in the broadest reasonable sense.", "text": "fundamental problem artiﬁcial intelligence nobody really knows intelligence problem especially acute need consider artiﬁcial systems signiﬁcantly different humans. paper approach problem following take number well known informal deﬁnitions human intelligence given experts extract essential features. mathematically formalised produce general measure intelligence arbitrary machines. believe measure formally captures concept machine intelligence broadest reasonable sense. think recognise intelligence really sure precisely deﬁne measure informally judge intelligence others relying past experiences dealing people. naturally naive approach highly subjective imprecise. principled approach would many standard intelligence tests available. contrary popular wisdom tests correctly applied professional deliver statistically consistent results considerable power predict future performance individuals many mentally demanding tasks. however tests work well humans wish measure intelligence things perhaps monkey machine learning algorithm clearly inappropriate. response problem might develop speciﬁc kinds tests speciﬁc kinds entities; intelligence tests children diﬀer intelligence tests adults. works well testing humans diﬀerent ages comes undone need measure intelligence entities profoundly diﬀerent terms cognitive capacities speed senses environments operate measure intelligence diverse systems meaningful must step back speciﬁcs particular systems establish underlying fundamentals really trying measure. need establish notion intelligence goes beyond speciﬁcs particular kinds systems. diﬃculty readily apparent. consider example memory numerical computation tasks appear intelligence tests regarded deﬁning hallmarks human intelligence. know tasks absolutely trivial machine thus test machine’s intelligence. indeed even mentally demanding task playing chess largely reduced brute force search. technology advances concept intelligence continues evolve develop concept intelligence applicable kinds systems? proposed deﬁnition must encompass essence human intelligence well possibilities consistent way. limited particular senses environments goals limited speciﬁc kind hardware silicon biological neurons. based principles suﬃciently fundamental unlikely alter time. furthermore intelligence measure ideally formally expressed objective practically realisable. paper approaches problem following way. section consider range definitions human intelligence forward well known psychologists. extract common essential features create informal deﬁnition intelligence. section introduces framework construct formal measure intelligence. framework formally deﬁned section section developed formalism produce formal deﬁnition intelligence. section closes short summary. preliminary sketch ideas paper appeared poster shown intelligence measure presented fact variant intelligence order relation appears theory aixi provably optimal universal agent long journal version paper written give proposed measure machine intelligence relation tests much comprehensive treatment. naturally expect bold initiative resistance. however hope reader appreciate value approach formally precise deﬁnition forward better understanding notoriously subjective slippery concept. although deﬁnitions human intelligence given experts ﬁeld vary views cluster around common perspectives. perhaps common perspective roughly stated think intelligence ability successfully operate uncertain environments learning adapting based experience. following often quoted deﬁnitions found express notion intelligence diﬀerent emphasis case deﬁnitions certain common features; cases explicitly stated others implicit. perhaps elementary feature intelligence seen property entity interacting external environment problem situation. indeed much common practically proposed definitions intelligence. referring back concepts regularly refer entity whose intelligence question agent external environment problem situation faces environment. environment could large complex world agent exists similar usual meaning something narrow game tic-tac-toe. second common feature deﬁnitions agent’s intelligence related ability succeed environment. implies agent kind objective. perhaps could consider agent intelligent abstract sense without objective. however without objective ever agent’s intelligence would observable consequences. intelligence then least concrete kind interests comes eﬀect agent objective apply intelligence refer goal. emphasis learning adaption experience deﬁnitions implies environment fully known agent contain surprises situations could anticipated advance. thus intelligence ability deal ﬁxed known environment rather ability deal range possibilities cannot wholly anticipated. means intelligent agent best possible speciﬁc environment particularly suﬃcient time learn. important agent able learn adapt perform well wide range speciﬁc environments. debate still fought unavoidable. nevertheless conﬁdent proposed informal working deﬁnition fairly mainstream. also believe deﬁnition captures interested achieving machines general ﬂexible capacity succeed faced wide range problems situations. even subscribe diﬀerent perspectives nature correct deﬁnition intelligence surely agree central objective anyone wishing extend power usefulness machines. also deﬁnition successfully formalised. previous section identiﬁed three essential components model intelligence agent environment goal. clearly agent environment must able interact other; speciﬁcally agent needs able send signals environment also receive signals sent environment. similarly environment must able receive send signals agent. terminology adopt agent’s perspective communications refer signals agent environment actions signals environment perceptions. missing setup goal. discussed previous section deﬁnition agent’s intelligence requires kind goal agent achieve. implies agent somehow knows goal possibility would goal known advance knowledge built agent. problem however limits agent goal. need allow agents ﬂexible this. goal known advance alternative somehow inform agent goal humans easily done using language. general however possession suﬃciently high level language strong assumption make agent. indeed even something intelligent direct explanation obviously work. fortunately another possibility. deﬁne additional communication channel simplest possible semantics signal indicates good agent’s current situation call signal reward. agent’s goal simply maximise amount reward receives sense goal ﬁxed. limiting though said anything causes diﬀerent levels reward occur. complex setting agent might rewarded winning game solving diﬃcult puzzle. broad perspective then goal ﬂexible. agent succeed environment receive reward must learn structure environment particular needs order reward. surprisingly exactly condition animal achieve goal selectively rewarding certain behaviours. narrow sense animal’s goal ﬁxed perhaps treats broader sense require trick solving puzzle. framework include reward signal part perception generated environment. perceptions also contain nonreward part refer observations. gives complete system interacting agent environment figure goal broad ﬂexible sense implicitly deﬁned environment deﬁnes rewards generated. thus framework test agent given suﬃcient fully deﬁne environment. artiﬁcial intelligence framework used area reinforcement learning appropriately renaming things also describes controller-plant framework used control theory. widely used general structure describe seemingly kind learning control problem. interesting point type framework follows naturally informal deﬁnition intelligence. diﬃculty deal notion success proﬁt. requires existence kind objective goal ﬂexible elegant bring framework using simple reward signal. expected reward cycle higher thus short term successful. hand switched optimal strategy always guessing head thrown not. thus medium term successful. finally agents random actions thus limit equally successful. better agent? want maximise short term rewards agent want maximise medium term rewards agent care long agents equally successful. agent prefer depends temporal preferences something currently outside formulation. standard formalising reinforcement learning assume value rewards decay geometrically future rate given discount parameter reward cycle given history expected value taken histories interacting. increasing towards weight long term rewards heavily conversely reducing balance weighting towards short term rewards. agent sends information environment sending symbols ﬁnite example {lef right orwards backwards}. call action space denote similarly environment sends signals agent symbols ﬁnite called perception space denote reward space denoted always ﬁnite subset rational unit interval every perception consists separate parts; observation reward. example might denote symbols sent lower case variable names actions observations rewards respectively. also index order occur thus agent’s ﬁrst action second action agent environment take turns sending symbols starting environment. produces history observations rewards actions denote oraoraorao restriction ﬁnite action perception spaces deliberate agent able receive generate information without bound single cycle time. course action perception spaces still extremely large required. formally agent function denoted takes current history input chooses next action output. convenient representing agent probability measure actions conditioned current history. thus probability action third cycle given current history oraor. deterministic agent simply always assigns probability action given history. agent produces distribution actions given history left completely open. course artiﬁcial intelligence agent machine computable function. adequate purposes would like single test intelligence machines range tests vary according free parameter. would like temporal preferences included model external possibility might harmonic discounting nice properties particular agent needs look forward future proportional current however even elegant solution possible. look value function equation geometric discounting plays roles. firstly normalises total reward received makes ﬁnite case maximum value secondly weights reward diﬀerent points future eﬀect deﬁnes temporal preference. solve problems without needing external parameter simply requiring total reward returned environment cannot exceed reward summable environment deﬁne value function simply viewing rewards returned environment temporal preference factored thus need this. cost additional condition place environments. previously required reward signal ﬁnite subset additional constraint bounded. seem philosophical problem here. environment artiﬁcial game like chess seems fairly natural meet requirements deﬁnition bounded reward sum. however think environment universe agent lives seems unreasonable expect required respect bound. argument universe notion reward particular agents. strictly speaking reward interpretation state environment. humans built example pain experienced touch something hot. case maybe really part agent rather environment? gave agent complete control rewards framework would become meaningless perfect agent could simply give constant maximum reward. indeed humans cannot easily either least withtaking drugs designed interfere pleasure-pain mechanism. thus accurate framework would consist agent environment separate goal system interpreted state environment rewarded agent appropriately. bounded rewards restriction would part goal system thus philosophical problem occur. however current purposes seem suﬃcient fold goal mechanism environment easily implemented constraint environment generate rewards. formally deﬁned space agents interact other measure performance agent speciﬁc environment. together single performance measure ﬁrstly need deﬁne mean wide range environments. goal produce measure intelligence broad encompassing possible space environments used deﬁnition large possible. given environment probability measure certain structure obvious possibility would consider space probability measures form. unfortunately extremely broad class environments causes problems. space probability measures uncountably inﬁnite cannot list members always describe environments ﬁnite way. solution require environmental measures computable. necessary eﬀective measure intelligence also restrictive. inﬁnite number environments upper bound complexity. furthermore measure describes environment must computable. example although typical sequence generated ﬂipping coin computable probability measure describes process computable. thus even environments behave randomly included space environments. appears largest reasonable space environments. indeed physical system ever shown outside set. physical system found would overturn church-turing thesis alter view universe. must weight environments highly others. consider agent’s perspective problem question asking given several diﬀerent hypotheses consistent data hypothesis considered likely? frequently occurring problem inductive inference must employ philosophical principle decide hypothesis likely. successful approach invoke principle occam’s razor given multiple hypotheses consistent data simplest preferred. generally considered rational intelligent thing consider example following type question commonly appears intelligence tests. sequence test subject needs predict next number. course pattern immediately clear numbers increasing time. intelligent person would easily identify pattern predict next digit however polynomial also consistent data case next number sequence would consider ﬁrst answer likely? perhaps unconsciously principle occam’s razor. furthermore fact test deﬁnes correct answer shows embodies concept occam’s razor. thus although don’t usually mention occam’s razor deﬁning intelligence ability eﬀectively occam’s razor clearly part intelligent behaviour. formal measure intelligence needs reﬂect this. speciﬁcally need test agents least average rewarded correctly applying occam’s razor. formally means priori distribution environments weighted towards simpler environments. problem becomes measure complexity environments? environment computable represented program formally binary string preﬁx universal turing machine thus kolmogorov complexity measure complexity environment measure independent choice additive constant independent thus simply pick universal turing machine correct turn prior distribution taking known algorithmic probability distribution number important properties particularly putting together deﬁne formal measure intelligence arbitrary systems. space programs compute environmental measures summable reward respect preﬁx universal turing machine kolmogorov complexity function. intelligence agent deﬁned random agent. agent lowest intelligence least among actively trying perform badly would makes uniformly random actions. call πrand. general agent successful fail exploit regularities environment matter simple are. follows values πrand typically compared agents thus low. specialised agent. equation agent could intelligence still perform extremely well speciﬁc complex tasks. consider example ibm’s deep blue chess supercomputer represent πdblue. µchess describes game chess πdblue high. however small µchess value function relative agents πdblue plays chess. therefore value low. intuitively deep blue inﬂexible narrow general intelligence. imagine agent basic learning building table observation action pairs keeping statistics rewards follow. time observation seen occurs agent takes action highest estimated expected reward next cycle probability random action probability. call agent πbasic. immediately clear many environments complex simple agent history. natural extension πbasic longer history actions observations rewards internal table. πback agent builds table statistics expected reward conditioned last actions rewards observations. immediately clear πback generalisation πbasic deﬁnition thus adapt regularity πbasic adapt follows general πback would intuitively expect. similar agents increasing complexity adaptability deﬁned still greater intelligence. however complex agents usually diﬃcult theoretically establish whether agent less intelligence another. nevertheless hopefully clear simple examples ﬂexible powerful agent higher machine intelligence. human. extremely simple environments human able identify simple structure exploit maximise reward. complex environments however hard know well human would perform without experimental results. super-human intelligence. easily proven theoretical aixi agent maximally intelligent agent respect aixi proven many universal optimality properties including pareto optimal self-optimising environment possible general agent. thus clear agents high must extremely powerful. meaningful. agent high value must perform well wide range environments particular must perform well almost simple environments. agent existed would clearly powerful practically useful. also sensibly orders intelligence simple learning agents. absolute. gives single real absolute value unlike pass-fail turing test important want make distinctions similar learning algorithms close human level intelligence. general. test clearly non-speciﬁc implementation agent inner workings agent left completely undeﬁned. also general terms senses actuators agent might information exchanged agent environment takes place basic shannon like communication channels. dynamic. aspect test intelligence terminology intelligence testing highly dynamic test normally intelligence tests humans test ability solve one-oﬀ problems. dynamic aspects test test subject interact something learn adapt behaviour accordingly. makes hard test things like individual’s ability quickly pick skills adapt situations. overcome problems sophisticated dynamic tests. tests active tester constantly interacts test subject much like happens formal intelligence measure. fundamental. test based theory information turing computation complexity theory. fundamental ideas likely remain stable time irrespective changes technology. deﬁnition intelligence also weaknesses. fact environmental distribution used invariant multiplicative constant changes reference machine aﬀords protection still means relative intelligence agents change change reference machine. approach problem might limit complexity reference machine example limiting state-symbol complexity. expect highly intelligent machines deal wide range environments varying complexity eﬀect changing simple reference machine another minor. agents less complex reference machine however change could signiﬁcant. theoretical problem distribution environments computable. theoretical deﬁnition intelligence makes measure impossible directly implement. solution tractable measure complexity levin’s complexity schmidhuber’s speed prior consider complexity algorithm determined description length running time. intuitively also makes good sense would usually consider short algorithm takes enormous amount time compute particularly simple one. closely related work ctest intelligence measure fully dynamic interactive c-test purely static sequence prediction test similar standard tests humans. c-test always ensures question unambiguous answer sense always consistent hypothesis signiﬁcantly lower complexity alternatives. perhaps useful kinds tests believe unrealistic limiting. like intelligence test c-test also deal problem incomputability kolmogorov complexity. using levin’s complexity c-test able compute number test problems used test humans. compression test machine intelligence similarly restricted sequence prediction. consider linguistic complexity tests treistergoren narrow. psychometric approach bringsjord schimanski appropriate machine suﬃciently humanlike intelligence. given obvious signiﬁcance formal deﬁnitions intelligence research calls direct measures machine intelligence replace problematic turing test imitation based tests little work done area. paper attempted tackle problem head although test weaknesses also many unique strengths. particular believe expresses essentials", "year": 2006}