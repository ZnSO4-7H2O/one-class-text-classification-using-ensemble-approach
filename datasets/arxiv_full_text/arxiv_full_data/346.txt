{"title": "Analysis of universal adversarial perturbations", "tag": ["cs.CV", "cs.AI", "cs.LG", "stat.ML"], "abstract": "Deep networks have recently been shown to be vulnerable to universal perturbations: there exist very small image-agnostic perturbations that cause most natural images to be misclassified by such classifiers. In this paper, we propose the first quantitative analysis of the robustness of classifiers to universal perturbations, and draw a formal link between the robustness to universal perturbations, and the geometry of the decision boundary. Specifically, we establish theoretical bounds on the robustness of classifiers under two decision boundary models (flat and curved models). We show in particular that the robustness of deep networks to universal perturbations is driven by a key property of their curvature: there exists shared directions along which the decision boundary of deep networks is systematically positively curved. Under such conditions, we prove the existence of small universal perturbations. Our analysis further provides a novel geometric method for computing universal perturbations, in addition to explaining their properties.", "text": "deep networks recently shown vulnerable universal perturbations exist small image-agnostic perturbations cause natural images misclassiﬁed classiﬁers. paper propose quantitative analysis robustness classiﬁers universal perturbations draw formal link robustness universal perturbations geometry decision boundary. speciﬁcally establish theoretical bounds robustness classiﬁers decision boundary models show particular robustness deep networks universal perturbations driven property curvature exists shared directions along decision boundary deep networks systematically positively curved. conditions prove existence small universal perturbations. analysis provides novel geometric method computing universal perturbations addition explaining properties. despite recent success deep neural networks solving complex visual tasks classiﬁers recently shown highly vulnerable perturbations input space. state-of-the-art deep networks empirically shown vulnerable universal perturbations exist small image-agnostic perturbations cause natural images misclassiﬁed. perturbations fundamentally differ random noise regime exploit essential properties deep network misclassify natural images perturbations small magnitude. state-of-the-art classiﬁers highly vulnerable speciﬁc directions input space? directions represent? answer questions follow theoretical approach causes vulnerability geometry decision boundaries induced deep neural networks. deep networks show answering questions lies existence shared directions along decision boundary highly positively curved. establishes fundamental connections geometry robustness universal perturbations thereby reveal unknown properties decision boundaries induced deep networks. studies vulnerability universal perturbations deep neural networks derive generic analysis terms geometric properties boundary. introduce decision boundary models locally model assumes ﬁrst order linear approximation decision boundary holds locally vicinity natural images locally curved model provides second order description decision boundary takes account curvature information. summarize contributions follows locally decision boundary model show classiﬁers vulnerable universal directions long normals decision boundaries vicinity natural images correlated result formalizes proves empirical observations made locally curved decision boundary model robustness universal perturbations instead driven curvature decision boundary; show existence shared directions along decision boundary positively curved implies existence small universal perturbations. show state-of-the-art deep nets satisfy assumption theorem derived locally curved model exist shared directions along decision boundary deep neural networks positively curved. theoretical result consequently captures large vulnerability state-of-the-art deep networks universal perturbations. robustness classiﬁers noise recently gained attention. several works focused analysis robustness properties classiﬁers approaches constructing robust classiﬁers proposed recently several works assessed robustness deep neural networks different regimes adversarial perturbations random noise realistic occlusions robustness ∗the ﬁrst authors contributed equally work. †lts école polytechnique fédérale lausanne switzerland ‡ucla vision university california angeles §ens lyon lyon cnrs ucbl inria université lyon france classiﬁers adversarial perturbations speciﬁcally studied leading theoretical well empirical explanations phenomenon although related adversarial perturbations fundamentally different universal perturbations latter single perturbation added images former adapted image several works attribute high vulnerability perturbations deep nets ﬂexibility high linearity decision boundaries show contrary large curvature decision boundary causes vulnerability universal perturbations. bounds indeed show increasing vulnerability respect curvature decision boundary represent ﬁrst formal result showing tight links robustness large curvature. finally noted works recently studied properties deep networks geometric perspective focus however different analyze robustness geometry decision boundary. consider l-class classiﬁer given datapoint deﬁne estimated label argmaxk component corresponds class. deﬁne distribution natural images main focus paper analyze robustness classiﬁers universal noise. speciﬁcally deﬁne universal noise vector most formally perturbation -universal following constraints satisﬁed perturbation image coined universal represents ﬁxed image-agnostic perturbation causes label change large fraction images sampled data distribution state-of-the-art classiﬁers shown surprisingly vulnerable simple perturbation regime. noted universal perturbations different adversarial perturbations datapoint speciﬁc perturbations sought fool speciﬁc image. adversarial perturbation speciﬁcally deﬁned solution following optimization problem corresponds smallest additive perturbation necessary change label classiﬁer geometric perspective quantiﬁes distance decision boundary addition optimality conditions orthogonal decision boundary illustrated fig. remainder paper analyze robustness classiﬁers universal noise respect geometry decision boundary classiﬁer formally pairwise decision boundary restricting classiﬁer class several recent works attempted explain vulnerability classiﬁers different types perturbations assuming decision boundary model. start analysis similar hypothesis analyze robustness classiﬁers universal perturbations decision boundary model. speciﬁcally study existence universal direction vector sufﬁciently small norm. noted universal direction sought deﬁnition adapted analysis linear classiﬁers. example binary linear classiﬁer universal direction fools data points half data points fooled universal vector therefore consider slightly modiﬁed deﬁnition remainder section. start analysis introducing local decision boundary model. note belongs decision boundary normal decision boundary linear approximation decision boundary classiﬁer therefore given approximation vector hence captures local geometry decision boundary vicinity datapoint assume local decision boundary model vicinity datapoints local classiﬁcation region occurs halfspace equivalently assume outside half-space classiﬁer outputs different label however since analyzing robustness universal directions consider following condition given ball radius centered illustration decision boundary model provided fig. noted linear classiﬁers satisfy decision boundary model decision boundaries globally ﬂat. local decision boundary model however general assume decision boundary linear rather classiﬁcation region vicinity included fig. provides example nonlinear decision boundary satisﬁes model. theoretical results paper assume simplicity exposition. results extended straightforward case takes different values points sampled following result shows classiﬁers following decision boundary model robust small universal perturbations provided normals decision boundary approximately belong dimensional subspace dimension theorem dimensional subspace thatps almost projection operator subspace. assume moreover holds almost then exists universal noise vector proof found appendix relies construction universal perturbation randomly sampling vulnerability classiﬁers universal perturbations attributed shared geometric properties classiﬁer’s decision boundary vicinity different data points. theorem shared geometric property across different data points expressed terms normal vectors neighborhood decision boundary. main assumption theorem speciﬁcally normal vectors neighborhood decision boundary approximately live subspace dimension assumption result shows existence universal perturbations norm order theorem hence shows small universal perturbations misclassifying data points found. remark theorem readily applied assess robustness multiclass linear classiﬁers universal perturbations. fact normal vectors equal normal vectors exactly span subspace dimension hence applying result obtain linear classiﬁers vulnerable universal noise magnitude proportional typical problems leads small universal directions. remark theorem formalizes empirical observations made therefore provides partial expalantion vulnerability deep networks provided locally decision boundary model assumed fact normal vectors vicinity decision boundary deep nets observed approximately span subspace however unlike linear classiﬁers dimensionality subspace typically larger number classes leading large upper bounds norm universal noise decision boundary model. simpliﬁed model decision boundary hence fails exhaustively explain large vulnerability state-of-the-art deep neural networks universal perturbations. fig. illustration decision boundary models considered paper. decision boundary model illustrated note taken outside stripe neighborhood. curved decision boundary model vector chosen grayed area classiﬁed differently consider model decision boundary vicinity data points allows leverage curvature nonlinear classiﬁers. decision boundary model study existence universal perturbations satisfying start establishing informal link curvature decision boundary robustness universal perturbations made clear later section. illustrated fig. norm required perturbation change label classiﬁer along speciﬁc direction smaller decision boundary positively curved decision boundary therefore appears fig. existence universal perturbations attributed existence common directions decision boundary positively curved many data points. remaining section formally prove existence universal perturbations exists common positively curved directions decision boundary. recalling deﬁnitions sec. quadratic approximation decision boundary gives αxrt denotes hessian model second order information captures curvature decision boundary. assume local decision boundary model vicinity datapoints local classiﬁcation region bounded quadratic form. formally assume exists following condition holds almost illustration quadratic decision boundary model shown fig. following result shows existence universal perturbations provided subspace exists decision boundary positive curvature along directions fig. left normal section decision boundary along plane spanned normal vector right geometric interpretation assumption theorem theorem assumes decision boundary along normal sections locally located inside disk radius note difference respect traditional notions curvature express curvature terms osculating circle assumption global. theorem quantiﬁes robustness classiﬁers universal perturbations terms curvature decision boundary along normal sections spanned vectors illustration normal section). fig. provides geometric illustration assumption theorem provided subspace exists curvature decision boundary vicinity datapoints positive theorem shows universal perturbations κ−/. hence curvature sufﬁciently large existence found norm approximately small universal perturbations guaranteed theorem rather assume existence subspace decision boundary positively curved across directions moreover noted that unlike theorem normals decision boundary assumed belong dimensional subspace assumption imposed normal vectors. instead assume existence subspace leading positive curvature points decision boundary vicinity natural images. remark theorem predict vulnerability classiﬁers also provides constructive universal perturbations. fact random vectors sampled subspace predicted universal perturbations section show construction works remarkably well deep networks predicted analysis. ﬁrst evaluate validity assumption theorem deep neural networks existence dimensional subspace decision boundary positively curved along directions sampled subspace. construct subspace directions lead large positive curvature vicinity given training points xn}. recall principal directions point decision boundary correspond eigenvectors matrix denotes projection operator tangent decision boundary denotes hessian decision boundary function evaluated common directions large average curvature minimal perturbation deﬁned therefore subspace span ﬁrst eigenvectors show subspace constructed satisﬁes assumption fig. visualization normal cross-sections decision boundary imagenet cifar- normal cross-sections along universal perturbation computed using algorithm bottom normal cross-sections along random vector uniformly sampled unit sphere theorem deep trained cifar- determine whether decision boundary positively curved directions compute average curvature across random directions points decision boundary i.e. average curvature formally given shown function subspace dimension observe dimension subspace sufﬁciently small average curvature strongly oriented towards positive curvature empirically shows existence subspace decision boundary positively curved data points validation set. empirical evidence hence suggests assumption theorem satisﬁed universal perturbations hence represent random vectors sampled subspace show strong link vulnerability universal perturbations positive curvature decision boundary visualize normal sections decision boundary deep networks trained imagenet cifar- direction respective universal perturbations. speciﬁcally visualize normal sections decision boundary plane universal perturbation computed using universal perturbations algorithm visualizations shown fig. interestingly universal perturbations belong highly positively curved directions decision boundary despite absence geometric constraint algorithm compute universal perturbations. fool data points universal perturbations hence naturally seek common directions embedding space decision boundary positively curved. directions lead small universal perturbations highlighted analysis theorem noted highly curved directions decision boundary rare random normal sections comparatively fact principal curvatures approximately zero points sampled decision boundary vicinity data points. recall theorem suggests novel procedure generate universal perturbations; fact random perturbations predicted universal perturbations. assess validity result fig. illustrates fooling rate universal perturbations sampled uniformly random unit sphere subspace scaled ﬁxed norm assess quality perturbation indicating fig. fooling rate universal perturbation computed using algorithm observe random perturbations sampled provide poweful universal perturbations fooling nearly data points validation set. rate comparable algorithm using much less training points large fooling rates achieved simple procedure conﬁrms curvature governing factor controls robustness classiﬁers universal perturbations analyzed section particular high fooling rates cannot achieved using model section illustrated fig. existence subspace explains high diversity universal perturbations. fig. illustrates different universal perturbations cifar- computed sampling random directions diversity perturbations justiﬁes re-training perturbed images signiﬁcantly improve robustness networks directions still lead universal perturbations even network becomes robust directions. finally interesting note subspace likely shared across datapoitns also different networks support claim fig. shows cosine fig. average curvature averaged validation datapoints function subspace dimension. fooling rate universal perturbations computed using random perturbations subspace positively curved directions subspace collecting normal vectors dotted line corresponds fooling rate using algorithm corresponds largest singular vectors corresponding matrix gathering normal vectors training principal angles subspaces slenet computed lenet models. note ﬁrst principal angles subspaces small leading shared directions subspaces. similar observation made networks trained imagenet appendix. sharing across different networks explains transferability universal perturbations observed paper analyzed robustness classiﬁers universal perturbations decision boundary models. showed classiﬁers satisfying decision model robust universal directions provided normal vectors vicinity natural images correlated. model explains vulnerability e.g. linear classiﬁers model discards curvature information essential fully analyze robustness deep nets universal perturbations. show fact classiﬁers curved decision boundaries robust universal perturbations provided existence shared subspace along decision boundary positively curved empirically verify assumption deep nets. analysis hence explains existence universal perturbations provides purely geometric approach computing perturbations addition explaining many properties perturbations diversity. acknowledgments gratefully acknowledge support nvidia corporation donation titan pascal used research. work partly supported hasler foundation switzerland framework robert project. supported swiss national science foundation grant pelp-. s.s. supported n--- wnf---. tabacof valle exploring space adversarial images ieee international joint conference neural networks tanay grifﬁn boundary tilting persepective phenomenon adversarial examples arxiv preprint arxiv. poole lahiri raghu sohl-dickstein ganguli exponential expressivity deep neural networks transient chaos advances manifolds differential geometry vol. american mathematical society providence chen network network international conference learning representations dasgupta gupta elementary proof theorem johnson lindenstrauss random structures algorithms vol. fig. transferability subspace across different networks. ﬁrst shows normal cross sections along ﬁxed direction vgg- subspace computed caffenet. note positive curvature cases. provide baseline comparison second illustrates normal sections along random directions. fig. shows examples normal cross-sections decision boundary across ﬁxed direction vgg- architecture note decision boundary across ﬁxed direction positively curved networks albeit computing subspace distinct network. sharing across different nets explains transferability universal perturbations observed", "year": 2017}