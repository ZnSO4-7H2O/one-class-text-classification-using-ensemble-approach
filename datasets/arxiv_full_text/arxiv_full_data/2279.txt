{"title": "Learning Structural Weight Uncertainty for Sequential Decision-Making", "tag": ["stat.ML", "cs.AI", "cs.LG"], "abstract": "Learning probability distributions on the weights of neural networks (NNs) has recently proven beneficial in many applications. Bayesian methods, such as Stein variational gradient descent (SVGD), offer an elegant framework to reason about NN model uncertainty. However, by assuming independent Gaussian priors for the individual NN weights (as often applied), SVGD does not impose prior knowledge that there is often structural information (dependence) among weights. We propose efficient posterior learning of structural weight uncertainty, within an SVGD framework, by employing matrix variate Gaussian priors on NN parameters. We further investigate the learned structural uncertainty in sequential decision-making problems, including contextual bandits and reinforcement learning. Experiments on several synthetic and real datasets indicate the superiority of our model, compared with state-of-the-art methods.", "text": "learning probability distributions weights neural networks recently proven beneﬁcial many applications. bayesian methods stein variational gradient descent oﬀer elegant framework reason model uncertainty. however assuming independent gaussian priors individual weights svgd impose prior knowledge often structural information among weights. propose eﬃcient posterior learning structural weight uncertainty within svgd framework employing matrix variate gaussian priors parameters. investigate learned structural uncertainty sequential decisionmaking problems including contextual bandits reinforcement learning. experiments several synthetic real datasets indicate superiority model compared state-of-the-art methods. deep learning achieved state-of-the-art performance wide range tasks including image classiﬁcation language modeling game playing challenge training deep neural networks models overﬁt observed data yielding over-conﬁdent decisions learning tasks. partially learning seeks point estimate model parameters failing quantify parameter uncertainty. natural ameliorate problems adopt bayesian neural network formulation. imposing priors weights utilizes available data infer approximate posterior distribution parameters making subsequent predictions performs model averaging learned uncertainty eﬀectively yielding mixture models bnns shown improved performance modern achitectures including convolutional recurrent networks computational convenience traditional learning typically makes assumptions weight distributions independent isotropic gaussian distributions priors fully factorized gaussian proposals posterior approximation adopting variational inference examining procedure note limitations independent gaussian priors ignore anticipated structural information weights factorized gaussian posteriors lead unreasonable approximation errors underestimate model uncertainty recent attempts made overcome issues. example introduced structural priors matrix variate gaussian distribution impose dependency weights within layer bnn. further nonparametric variational inference methods e.g. stein variational gradient descent iteratively transport particles approximate target posterior distribution svgd represents posterior approximately terms particles endowed guarantees approximation accuracy number particles exactly inﬁnity however since updates within svgd learning involve kernel computation parameter space interest algorithm computationally expensive high-dimensional space. becomes even worse case structural priors large amount additional parameters introduced rendering svgd ineﬃcient directly applied posterior inference. propose eﬃcient learning scheme accurate posterior approximation weights adopting structural prior. provide perspective unify previous structural weight uncertainty methods householder perspective allows svgd approximate target structural distribution lower-dimensional space thus eﬃcient inference. call proposed algorithm structural stein variational gradient descent investigate structural-weightuncertainty framework learning policies sequential decision problems including contextual bandits reinforcement learning. models uncertainty particularly important greater uncertainty weights typically introduces variability decision made policy network naturally leading policy explore. data observed uncertainty decreases allowing decisions made policy network become deterministic environment better understood models structural weight uncertainty inferred proposed svgd. conduct several experiments ﬁrst demonstrating svgd yields eﬀective performance classic classiﬁcation/regression tasks. focus experiments motivating applications sequential decision problems accounting weight uncertainty believed particularly beneﬁcial. applications proposed method demonstrates particular empirical value also computationally practical. results show structural weight uncertainty gives better expressive power describe uncertainty driving better exploration. represents function composition i.e. means evaluated output layer represents nonlinear transformation. example rectiﬁed linear unit activation function weight matrix size number parameters respectively. hence total number parameters needed describe distribution compared traditional bnns employ isotropic gaussian priors factorization. increase parameter dimension leads signiﬁcant computational overhead. problem becomes even severe aspects calculating kernels computation increases proximation repelling term using limited particles inaccurate high dimensions. therefore desirable transform distribution lower-dimensional representation. reparameterization since covariance matrices positive deﬁnite decompose pλλp qλλq corresponding orthogonal matrices diagonal matrices positive diagonal elements. according lemma show following reparameterization based proposition propose layer decomposition one-layer weight matrix prior decomposed linear product matrices illustrated figure layer decomposition provides interesting interpretation original layer equivalent several ﬁrst term right summation drives particles towards high probability regions information sharing across similar particles. second term repels particles away other encouraging coverage entire distribution. svgd applies updates repeatedly samples move closer target distribution iteration. using state-of-the-art stochastic gradient-based algorithms e.g. rmsprop adam svgd becomes highly eﬃcient scalable bayesian inference method. figure illustration proposed techniques reduce parameter size learning distribution decomposition linear product matrices approximation linear product householder matrices. note rectangle indicates note layer decomposition maintains similar computational complexity original layer. reduce computation bottleneck layer decomposition propose represent using householder ﬂows formally householder transformation linear transformation describes reﬂection hyperplane containing origin. householder series householder transformations. since householder ﬂows allow represent householder vectors parameter sizes reduce overall model structured weight priors using parameters. therefore eﬃciently capture structure information slight increase computational cost interestingly method provides unifying perspective previous methods learning structured weight uncertainty. terms prior distributions reparameterization reduces reparameterization reduces terms posterior learning methods svgd reduces svgd; reduces learning solution. structural bnns revisited leverage layer decomposition householder construct equivalent approximating layer standard gaussian weight matrices categorical). note follow proposed techniques reduce parameter size. therefore standard svgd algorithms applied sample posterior distribution model parameter. intuitively svgd kernel function governs interactions particles employs information accelerate convergence provide better principal motivation proposed svgd framework sequential decision problems including contextual multi-arm bandits markov decision processes challenge sequential decision problems face uncertainty exploration/exploitation trade-oﬀ trade-oﬀ either taking actions rewarding according current knowledge taking exploratory actions less immediately rewarding lead better-informed decisions future. bayesian setting exploration/exploration tradeoﬀ naturally addressed imposing uncertainty parameters policy model. step thompson sampling ﬁrst draws parameter samples picks action maximizing expected reward current step i.e. maxa r∼prrt collects data samples observing reward updates posterior policy. apply proposed svgd updates ﬁnal step call sequential decision-making procedure markovian dynamical system. seen extension cmab replacing context notion system state dynamically change according performed actions previous state. formally deﬁnes tuple policy gradient family reinforcement learning methods solves mdps iteratively updating parameters policy instead searching single policy parameterized consider adopting prior learning variational posterior distribution using svgd. following objective function modiﬁed increasing improves performance lead accurate approximation. interestingly small increasing gives signiﬁcant improvement. furthermore large change yields similar performance. therefore unless otherwise speciﬁed. single-layer regression tasks. following public datasets considered hidden units large datasets hidden units small datasets. repeat experiments times datasets except protein yearpredict repeat times once respectively computation considerations batch size large datasets small datasets. datasets randomly split training testing. adopt root mean squared error test log-likelihood evaluation criteria. experimental results shown table observe weight structure information useful algorithms non-parametric assumptions i.e. stein-based methods perform better; iii) combined structure information method achieves state-of-the-art results. testing. two-layer model -x-x- relu activation function used number hidden units layer. training epoch test errors network sizes reported table observe bayesian methods generally perform better optimization counterparts. proposed svgd improves svgd signiﬁcant margin. increasing also improves performance demonstrating advantages incorporating structured weight uncertainty model. details methods compare. wish verify performance gain svgd special structural design network architecture rather increasing number model parameters. demonstrated training hidden units using svgd yields test error slightly parameters network trained svgd worse performance. note advantages svgd sequential decision-making structural priors characterize ﬂexible weight uncertainty thus providing better exploration-exploitation learning policies; eﬃcient approximation scheme provides accurate representation true posterior maintaining similar online-processing speed. experiments demonstrate eﬀectiveness svgd ﬁrst conduct experiments standard regression classiﬁcation tasks real datasets superiority svgd demonstrated experiments contextual bandits reinforcement learning. compare svgd related bayesian learning algorithms including svgd rmsprop optimizer employed speciﬁc declaration. svgd-based methods bandwidth med/ median pairwise distance particles. hyper-parameters experiments conducted single titan gpu. ﬁrst study role hyperparameters svgd number householder transformations number particles investigated classiﬁcation task covertype dataset data points features. simulation ﬁrst simulate contextual-bandit problem mushrooms dataset. following provided features mushroom regarded context. reward given agent eats edible mushroom. otherwise mushroom poisonous agent eats reward received probability agent decides mushroom receives reward two-layer relu hidden units represent policy agent. compared method standard baseline ε-greedy policy respectively evaluate performance diﬀerent algorithm cumulative regret measure loss caused playing suboptimal bandit arms. results plotted figure thompson sampling diﬀerent strategies update policy considered svgd svgd vmg. svgd shows lower regret beginning learning svgd lowest ﬁnal cumulative regret among methods. hypothesize method captures internal weight correlation structural uncertainty eﬀectively help agent learn make less mistakes exploration less observations. news article recommendation consider personalized news article recommendation yahoo time user visits portal news article dynamic pool candidates recommended based user’s proﬁle dataset contains user visits today module -day period visit user candidate articles associated feature vector dimensions goal recommend article user based behavior formally maximize total number clicks recommended articles. procedure regraded cmab problem articles treated arms. reward deﬁned article clicked otherwise. one-layer relu hidden units used policy network. classic linucb also compared baseline. performance evaluated unbiased oﬄine evaluation protocol average normalized accumulated click-through-rate every observations normalized ctrs plotted figure clear svgd consistently outperforms methods. fact svgd perform better svgd baseline linucb indicates structural information helps algorithms better balance exploration exploitation. verify inﬂuence particle size sequential decision problem vary the-ﬁrst-day data. algorithms repeated times mean performances plotted figure observe keeps increasing becomes larger. svgd dominates performance svgd much higher ctrs becomes larger increases. since larger typically leads accurate posterior estimation policy indicating accurately learned structural uncertainty beneﬁcial cmabs. apply svgd policy gradient learning. experiments conducted openai rllab toolkit three classical continuous control tasks considered cartpole swing-up double pendulum cartpole. following settings policy parameterized two-layer neural network tanh activation function. maximal length horizon svgd svgd sample size policy gradient estimation easy task cartpole agents trained episodes. complex tasks cartpole swing-up double pendulum agents trained episodes. consider diﬀerent methods estimate state values reinforce advantage actor critic figure plots mean standard derivation discounted rewards runs. tasks value-estimation setups svgd converges faster svgd ﬁnally converges higher average rewards. results even comparable subtle reward mechanism incorporated encourage exploration. demonstrates simply adding structural information policy networks using svgd improves agent’s exploration ability. also baseline method called svgd* applies svgd train network similar size reparameterized svgd fact proposed svgd eﬃcient bayesian posterior learning scheme weights bnns structural priors. achieve this derive reparametrization unify previous structural priors adopt svgd algorithm accurate posterior learning. transforming lower-dimensional representation svgd avoids computation related kernel matrices highdimensional space. eﬀectiveness framework tested several real-world tasks including regression classiﬁcation contextual bandits reinforcement learning. extensive experimental results demonstrate superiority relative related algorithms. empirical results sequential decision problems suggest beneﬁts including inter-weight structure within model computing policy uncertainty online decision-making uncertain environments. sophisticated methods leveraging uncertainty exploration/exploration balance promising direction future work. example explicitly encouraging exploration using learned structural uncertainty", "year": 2017}