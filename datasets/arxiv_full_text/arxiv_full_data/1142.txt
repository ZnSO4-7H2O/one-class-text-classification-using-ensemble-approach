{"title": "Autostacker: A Compositional Evolutionary Learning System", "tag": ["cs.LG", "cs.NE", "stat.ML"], "abstract": "We introduce an automatic machine learning (AutoML) modeling architecture called Autostacker, which combines an innovative hierarchical stacking architecture and an Evolutionary Algorithm (EA) to perform efficient parameter search. Neither prior domain knowledge about the data nor feature preprocessing is needed. Using EA, Autostacker quickly evolves candidate pipelines with high predictive accuracy. These pipelines can be used as is or as a starting point for human experts to build on. Autostacker finds innovative combinations and structures of machine learning models, rather than selecting a single model and optimizing its hyperparameters. Compared with other AutoML systems on fifteen datasets, Autostacker achieves state-of-art or competitive performance both in terms of test accuracy and time cost.", "text": "figure typical pipeline generated autostacker. column represents layer. node layer represents machine learning primitive model number layers nodes layer speciﬁed beforehand treated hyperparameter. dataset used input ﬁrst layer. following layers prediction results node added dataset synthetic features dataset generated layer input next layer. formatted dataset input outputs modeling pipelines achieve reasonable performance dataset. recent efforts automl autosklearn tpot demonstrate success variety datasets. work present automl architecture called autostacker. inspired stacking method ensemble learning autostacker automatically discovers pipelines made many models. compared automl frameworks autostacker demonstrates competitive performance accuracy time evaluated ﬁfteen datasets. following three properties autostacker allow generalize well data introduce automatic machine learning modeling architecture called autostacker combines innovative hierarchical stacking architecture evolutionary algorithm perform efﬁcient parameter search. neither prior domain knowledge data feature preprocessing needed. using autostacker quickly evolves candidate pipelines high predictive accuracy. pipelines used starting point human experts build autostacker ﬁnds innovative combinations structures machine learning models rather selecting single model optimizing hyperparameters. compared automl systems ﬁfteen datasets autostacker achieves state-of-art competitive performance terms test accuracy time cost. wolpert’s free lunch theorem implies model expected generalize well data. machine learning practitioners upon encountering dataset must models pick best hyperparameters chosen model? successful choice model often requires considerable experience knowledge; good choices hyperparameters often come product time-intensive tuning. automating parts modeling procedure model selection hyperparameter optimization would make fruits machine learning accessible wider community making highly desired academia industry. figure overview pipeline generation. randomly generate initial pipelines feed basic algorithm looping process generate winning pipelines. hyperparameters pipeline explicitly deﬁned user tuned autostacker. datasets still small sparse. tackle challenge cascading always using original dataset stacking layers concatenating synthetic features stacking layer. details provided approach section below. model flexibility existing automl frameworks generate full pipeline includes data preprocessing feature engineering model selection. model selection usually involves optimization single machine learning primitive support vector machine traditional ensemble method boosting autostacker allows ﬂexible combinations many machine learning primitives resulting larger search space. evolutionary search algorithm allow tractably good solutions large space variables variables include type primitive machine learning models conﬁguration settings framework hyperparameters primitive model. work consider elements hyperparameters. instead treating automl optimization problem model search problem large space hyperparameters. exploiting parallel nature evolutionary algorithms autostacker quickly ﬁnds good candidate pipelines. shown results section achieve competitive performance basic version stacking decades-old method ensemble learning ﬁrst layer takes original dataset; next layer outputs classiﬁers ﬁrst layer forth. intuitively later layers learn mistakes classiﬁers previous layers make correct them. related approach cascading taking output model feeding another ﬁrst explored ensemble learning technique work viola jones data series binary classiﬁers. classiﬁer outputs true data travels next classiﬁer; classiﬁer outputs false iteration ends cascade returns false. last classiﬁer reached outputs true cascade returns true. cascaded classiﬁcation models sophisticated approach cascading introduced heitz decompose complex problem scene understanding component problems. believe neither stacking cascading explored automl literature. automl research focused combining tasks machine learning pipeline building intelligent model hyperparameter search. auto-weka selects single machine learning primitive optimizes hyperparameters. auto-weka built weka uses bayesian optimization search optimal hyperparameter settings pipeline. pipeline follows traditional machine learning work process data preprocessing feature engineering single model prediction. however ﬁxed order pipelines especially single model prediction suitable complicated problems small sample datasets. autosklearn follows similar methodology above using scikit-learn machine learning library toolbox well bayesian optimization tune hyperparameters. also several works bayesian optimization designed speciﬁcally large scale parameter conﬁguration problems like automl. example robo includes multiple implementations different bayesian optimization algorithms ﬂexibility changing components process. hyperopt takes advantage sequential model-based optimization considers choice classiﬁcation models preprocessing models together integral optimization problem. bayesian approaches large scale parameter search include smac spearmint perform hyperparameter optimization automl setting recently explored tpot architecture extending traditional data scientists’ pipeline used autoweka autosklearn tpot allows parallel feature engineering prior model prediction. subsequently tpot uses evolutionary algorithms treat parameter conﬁguration problem search problem. aforementioned approaches however focus conﬁguring single machine learning primitive traditional ensemble architectures supplement. autosklearn allows ensemble models built considers traditional ensemble approaches. ensemble selection found robust efﬁcient performance stacking gradient-free numerical optimization tended less efﬁcient easily overﬁt autostacker hand ensemble method default. handles single model ensemble approaches simultaneously basic primitives. cascading architectures generated autostacker allow synergistic combinations primitives correct others mistakes improve generalization. moreover autostacker allows multiple ensemble models used architecture. believe ensemble learning deserves deeper consideration automl process generally robust outperform individual models time thus instead taking traditional route designing automl system learns choose single model optimize encourage autostacker innovative combinations arrangements primitives. hypothesize model ﬂexibility major factor autostacker’s empirical success compared automl systems. toml systems tpot autosklearn. naturally primitives candidate pipeline need optimized well compounding problem. tackle issue using basic evolutionary algorithm rather bayesian optimization suitable hyperparameters. recently seen renaissance ﬁelds machine learning neural network optimization reinforcement learning conﬁrming status optimization workhorse dealing large search spaces. note tpot also uses perform parameter search. model belonging family models governed parameters. call hyperparameters model parameters. automl focus lies choosing appropriate ﬁnding good delegated training process. scope varies different systems. primitive pipeline primitive denotes existing machine learning model decisiontree. addition also include traditional ensemble learning models adaboost bagging. pipeline output autostacker single primitive combination primitives. layer node figure shows architecture autostacker formed multiple stacking layers multiple nodes layers. node represents machine learning primitive model. working process autostacker shown figure sample pipeline built autostacker shown figure pipeline consists multiple layers layer contains multiple nodes. nodes primitive machine learning models. layer takes dataset outputs prediction result denotes prediction result node layer layer’s prediction prediction results back dataset number nodes layer. layer dataset gets synthetic features last layer consists single node. take output last layer ﬁnal output machine learning problem. unlike traditional stacking algorithm ensemble learning feeds prediction results next layer inputs proposed architecture always cascades information directly dataset. best knowledge ﬁrst time algorithm generalized incorporated automl system although similar methods tried practice solve speciﬁc machine learning problems. considerations number items dataset could small. prediction result layer could contain little information problem likely primitives bias outcomes lot. accordingly throwing away dataset could lead high-biased prediction results suitable generalization especially situations could training data future. moreover combining synthetic features dataset implicitly give features weight features important prediction accuracy. throw away dataset regular stacking fully trust primitives individual layers. consequently reduce inﬂuences bias coming individual primitive noise coming dataset. note autostacker provides ways specifying default mode users simply specify maximum range positive integers needed enable autostacker explore different conﬁgurations. advantages here mode frees system constraints allows discover further possible innovative pipelines. search process achieves signiﬁcant speedup. illustrate point experiment section later. another choice explicitly denote value allows systems build pipelines speciﬁc number layers number nodes layer based allowed computational power time. paper basic evolutionary algorithm chosen search algorithm group hyperparameters create better model pipelines. bare-bones involves mutation cross-over sophisticated techniques. show later system already achieve signiﬁcantly better performance straightforward baseline algorithm. algorithm provides details algorithm system. first generate completed pipelines randomly selecting hyperparameters. one-step mutation half pipelines another pipelines. candidates mutation chosen randomly. another pipelines crossover. already another pipelines total. replacing classiﬁer logistic regression classiﬁer. cross-over exchange part pair pipelines’ topology. example take ﬁrst half layers pipeline second half layers another pipeline formalize pipeline. train pipelines evaluate cross validation. pipelines highest validation accuracies selected seed pipelines next generation mutation cross-over. seed pipelines ready another one-step mutation cross-over applied another round evaluation selection executed afterwards. loop continues iterations number iterations speciﬁed users. section presents training testing procedure. training process happens evaluation step shown above. corresponding hierarchical framework pipeline trained layer layer. inside layer primitive also trained independently dataset. next layer trained concatenation previous dataset prediction results previous trained layer. similarly validation process testing process share mechanism validation test respectively. training validating pipelines pick ﬁrst pipelines highest validation accuracies ﬁnal output autostacker. believe pipelines provide better baselines human experts started problem. outputting range modeling options rather single pipeline directly allows user ﬂexibility modeling process. also consider effect small unbalanced datasets; taking datasets difﬁcult guarantee performance validation process fully represent test set. example pipelines validation results might behave differently test dataset. hence consider necessary provide candidates guaranteed better average human experts tune pipelines. another signiﬁcant advantage approach system ﬂexible scale parallelize. huge advantage comes free using evolutionary algorithms. starting initial generation one-step mutation one-step cross-over training validation evaluation pipeline runs independently means worker work pipeline alone. frequent communication sequential decision making among workers worker pipeline separately. workers need share validation results ranked iteration. shot selection based validation accuracy subsequently applied outputs parallel workers. speciﬁcally terms algorithm described above random mutation crossover evaluate function easily parallelized system runs. systems well autosklearn place ﬁnal phase automl challenge tpot autosklearn open-sourced systems. hence current versions systems improved initial published versions authors automl community. recent open-source versions systems experiment. show performance system select datasets benchmark dataset provided collects datasets public data resources openml etc. sample experimental data. according result published tpot arbitrarily choose datasets claimed better results tpot comparing random forest classiﬁer datasets worse performance tpot datasets performance random forest classiﬁer tpot. limit total number datasets show cover cases datasets used tpot. datasets come different problem domains target different machine learning tasks including binary classiﬁcation multi-class classiﬁcation. data preprocessing feature preprocessing currently involved autostacker. would certainly possible preprocessing dataset features another building block hyperparameter autostacker also provide ﬂexibility system. nevertheless paper focus modeling process show contribution architecture automation process. round experiment shufﬂe partition dataset training/testing data. code released. goal autostacker automatically provide better baseline pipeline data scientists. thus baseline choose compare able represent prediction ability pipelines coming initial trials data scientists. baseline pipeline compare chosen random forest classiﬁer number estimators ensemble learning models like random forest shown work well average practice considering multi-model predictions. compare results tpot model recent popular automl currently primitives scikit-learn library xgboost library shown table autostacker users allowed plug primitives like long function signatures consistent current code base. terms basic structure candidate pipelines mentioned above types settings provided autostacker. section show performance default mode autostacker dynamic conﬁgurations. specify maximum number layers maximum number nodes layer section show results test accuracy time cost autostacker well comparisons random forest tpot autosklearn. test accuracy calculated using balanced accuracy refer test accuracy rest paper. rounds experiments random forest classiﬁer rounds experiment tpot based computation time cost. autostacker rounds experiments executed dataset datasets shufﬂed round. testing accuracies shown come ranked pipelines outputted autostacker round. thus ﬁgure contains test results total. autosklearn trials dataset hour time limitation round. notches plot represent conﬁdence intervals median values. experiments using machines memory. many modern approaches architectures achieve excellent results large high dimensional datasets multi-task problems. deep learning example become dominant approach ﬁelds computer vision natural language processing current primitive library modeling structure scale well problems. direction future work could incorporate advanced primitives autostacker’s catalog necessary. autostacker made efﬁcient better search algorithms. many variants evolutionary algorithms expand basic version used work. experimenting different algorithms cause autostacker search faster better pipelines. also believe rigorous statistical analysis help better understand output autostacker certain architectures chosen architectures evolve time. work proposed autostacker automl system inspired stacking cascading evolutionary algorithms. despite lack data preprocessing feature selection autostacker still outperforms competing automl systems wide variety datasets accuracy speed. hope provide benchmark automl bears potential incorporate primitives preprocessing techniques.", "year": 2018}