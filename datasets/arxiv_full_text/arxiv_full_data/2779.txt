{"title": "Distilling a Neural Network Into a Soft Decision Tree", "tag": ["cs.LG", "cs.AI", "stat.ML"], "abstract": "Deep neural networks have proved to be a very effective way to perform classification tasks. They excel when the input data is high dimensional, the relationship between the input and the output is complicated, and the number of labeled training examples is large. But it is hard to explain why a learned network makes a particular classification decision on a particular test case. This is due to their reliance on distributed hierarchical representations. If we could take the knowledge acquired by the neural net and express the same knowledge in a model that relies on hierarchical decisions instead, explaining a particular decision would be much easier. We describe a way of using a trained neural net to create a type of soft decision tree that generalizes better than one learned directly from the training data.", "text": "abstract. deep neural networks proved eﬀective perform classiﬁcation tasks. excel input data high dimensional relationship input output complicated number labeled training examples large hard explain learned network makes particular classiﬁcation decision particular test case. reliance distributed hierarchical representations. could take knowledge acquired neural express knowledge model relies hierarchical decisions instead explaining particular decision would much easier. describe using trained neural create type soft decision tree generalizes better learned directly training data. excellent generalization abilities deep neural nets depend distributed representations hidden layers representations hard understand. ﬁrst hidden layer understand causes activation unit last hidden layer understand eﬀects activating unit hidden layers much harder understand causes eﬀects feature activation terms variables meaningful input output variables. also units hidden layer factor representation input vector feature activations combined eﬀects active features cause appropriate distributed representation next hidden layer. makes diﬃcult understand functional role particular feature activation isolation since marginal eﬀect depends eﬀects units layer. diﬃculties compounded fact deep neural nets make reliable decisions modeling large number weak statistical regularities relationship inputs outputs training data nothing neural network distinguish weak regularities true properties data spurious regularities created sampling peculiarities training set. faced diﬃculties seems wise abandon idea trying understand deep neural network makes classiﬁcation decision understanding individual hidden units decision based directly input data. decision trees however usually generalize well deep neural nets. unlike hidden units neural typical node lower levels decision tree used small fraction training data lower parts decision tree tend overﬁt unless size training exponentially large compared depth tree. paper propose novel resolving tension generalization interpretability. instead trying understand deep neural network makes decisions deep neural network train decision tree mimics input-output function discovered neural network works completely diﬀerent way. large amount unlabelled data neural used create much larger labelled data train decision tree thus overcoming statistical ineﬃciency decision trees. even unlabelled data unavailable possible recent advances generative modeling generate synthetic unlabelled data distribution close data distribution. without using unlabelled data still possible transfer generalization abilities neural decision tree using technique called distillation type decision tree makes soft decisions. soft binary decision trees trained mini-batch gradient descent inner node learned ﬁlter bias leaf node learned distribution inner node probability taking rightmost branch model hierarchical mixture experts expert actually bigot look data training therefore always produces distribution. model learns hierarchy ﬁlters used assign example particular bigot particular path probability bigot learns simple static distribution possible output classes order avoid soft decisions tree introduced inverse temperature ﬁlter activations prior calculating sigmoid. thus probability taking right branch node becomes model used give predictive distribution classes diﬀerent ways namely using distribution leaf greatest path probability averaging distributions leaves weighted respective path probabilities. take predictive distribution leaf greatest path probability explanation prediction simply list ﬁlters along path route leaf together binary activation decisions. average leaf distributions weighted respective path probabilities model achieves marginally better test accuracy leads exponential increase complexity explanation model’s predictive distribution particular case involves ﬁlters nodes. reason remainder paper refer output model referring distribution leaf maximum path probability. train soft decision tree using loss function seeks minimize cross entropy leaf weighted path probability target distribution. single training case input vector target distribution loss unlike decision trees soft decision trees decision boundaries aligned axes deﬁned components input vector. also trained ﬁrst picking size tree using mini-batch gradient descent update parameters simultaneously rather standard greedy approach decides splits node time avoid getting stuck poor solutions training introduced penalty term encouraged internal node make equal left right sub-trees. without penalty tree tended stuck plateaus internal nodes always assigned almost probability sub-trees gradient logistic decision always close zero. penalty cross entropy desired average distribution sub-trees actual average distribution node given hyper-parameter determines strength penalty prior training. penalty based assumption tree making fairly equal alternative sub-trees would usually better suited particular classiﬁcation task practice increase accuracy. however assumption less less valid descends tree; penultimate node tree responsible classes input non-equal proportion penalizing node non-equal split case could hurt accuracy model. found achieved better test accuracy results strength penalty decayed exponentially depth node tree proportional descends tree expected fraction data node sees given training batch decreases exponentially. means computation actual probabilities using sub-trees becomes less accurate. counter maintain exponentially decaying running average actual probabilities time window exponentially proportional depth node. found experimentally achieved much better test accuracy using exponential decay strength penalty depth exponential increase temporal scale window used compute running average. fig. visualization soft decision tree depth trained mnist. images inner nodes learned ﬁlters images leaves visualizations learned probability distribution classes. ﬁnal likely classiﬁcation leaf well likely classiﬁcations edge annotated. take example right internal node level tree potential classiﬁcations thus learned ﬁlter simply learning distinguish digits. result ﬁlter looks presence areas would join ends make number total parameters soft decision trees start overﬁt typically less number total parameters multi-layer neural network starts overﬁt. lower nodes decision tree receive small fraction training data. reﬂected performance mnist. soft decision tree depth able achieve test accuracy training true targets. neural convolutional hidden layers penultimate fully connected layer achieved much better test accuracy able accuracy neural make much better soft decision tree training soft targets composite true labels predictions neural network. soft decision tree trained achieved test accuracy halfway neural soft decision tree trained directly data. main motivation behind work create model whose behavior easy explain; order fully understand particular example given particular classiﬁcation simply examine learned ﬁlters along path root classiﬁcation’s leaf node. crux model rely hierarchical features relies hierarchical decisions instead. hierarchical features traditional neural network allow learn robust novel representations input space past single level become extremely diﬃcult engage with. current attempts explanations neural networks rely gradient descent input particularly excites given neuron results single point manifold inputs meaning inputs could yield pattern neural excitement reﬂect entire manifold. ribeiro propose strategy relies ﬁtting explainable model \"acts absence/presence interpretable components\" behavior deep neural around area interest input space accomplished sampling input space querying model around area interest ﬁtting explainable model output model. avoids problem attempting explain particular output visualizing single point manifold introduces problem necessitating explainable model every area interest input space attempting explain changes model’s behavior ﬁrst order changes discretized interpretation input space. relying hierarchical decisions instead hierarchical features side-step problems decision made level abstraction reader engage directly. tried model several data sets focused spatial input sake visualization. ﬁrst training neural using provide soft targets training soft decision tree tree depth able achieve test accuracy connect dataset comprised board states popular child’s game connect input ﬁnal outcome game target value. without distilling neural best test accuracy achieved decision trees trained gradient descent applied dataset able achieve maximum test accuracy equivalent depth depth provides interesting example utility explainable model examining learned ﬁlters soft decision tree able learn something nature game. examining ﬁrst learned ﬁlter game split distinct types games games players placed pieces edges board games players placed pieces center board. games progress suﬃciently diﬀerent manners beneﬁcial decision tree split root. also model spatial dataset namely letter dataset comprised primitive numerical attributes capital english characters. able achieve test accuracy tree depth trained training data test accuracy distilled ensemble neural nets test accuracy. fig. visualization ﬁrst layers soft decision tree trained connect data set. examining learned ﬁlters game split distinct types games games players placed pieces edges board games players placed pieces center board. described method using trained neural create explicable model form soft decision tree trained stochastic gradient descent using predictions neural give informative targets. soft decision tree uses learned ﬁlters make hierarchical decisions based input example ultimately select particular static probability distribution classes output. soft decision tree generalizes better trained data directly performs worse neural used provide soft targets training essential able explain model classiﬁes particular test case particular soft decision tree still gain beneﬁts deep neural networks using improve training explicable model. christian szegedy yangqing pierre sermanet scott reed dragomir anguelov dumitru erhan vincent vanhoucke andrew rabinovich. going deeper convolutions. proceedings ieee conference computer vision pattern recognition pages yonghui mike schuster zhifeng chen quoc mohammad norouzi wolfgang macherey maxim krikun yuan klaus macherey google’s neural machine translation system bridging human machine translation. arxiv preprint arxiv. alex graves abdel-rahman mohamed geoﬀrey hinton. speech recognition deep recurrent neural networks. acoustics speech signal processing ieee international conference pages ieee yann lecun yoshua bengio geoﬀrey hinton. deep learning. nature goodfellow jean pouget-abadie mehdi mirza bing david warde-farley sherjil ozair aaron courville yoshua bengio. generative adversarial nets. advances neural information processing systems pages cristian buciluˇa rich caruana alexandru niculescu-mizil. model compression. proceedings sigkdd international conference knowledge discovery data mining pages karen simonyan andrea vedaldi andrew zisserman. deep inside convolutional networks visualising image classiﬁcation models saliency maps. arxiv preprint arxiv. dumitru erhan yoshua bengio aaron courville pascal vincent. visualizing higher-layer features deep network. university montreal marco túlio ribeiro sameer singh carlos guestrin. \"why trust you?\" explaining predictions classiﬁer. corr abs/. http//arxiv.org/abs/.. mohammad norouzi maxwell collins matthew johnson david fleet pushmeet kohli. eﬃcient non-greedy optimization decision trees. advances neural information processing systems pages", "year": 2017}