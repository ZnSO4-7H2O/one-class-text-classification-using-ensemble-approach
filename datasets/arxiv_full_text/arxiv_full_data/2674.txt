{"title": "Ensemble Sampling", "tag": ["stat.ML", "cs.AI", "cs.LG"], "abstract": "Thompson sampling has emerged as an effective heuristic for a broad range of online decision problems. In its basic form, the algorithm requires computing and sampling from a posterior distribution over models, which is tractable only for simple special cases. This paper develops ensemble sampling, which aims to approximate Thompson sampling while maintaining tractability even in the face of complex models such as neural networks. Ensemble sampling dramatically expands on the range of applications for which Thompson sampling is viable. We establish a theoretical basis that supports the approach and present computational results that offer further insight.", "text": "thompson sampling emerged effective heuristic broad range online decision problems. basic form algorithm requires computing sampling posterior distribution models tractable simple special cases. paper develops ensemble sampling aims approximate thompson sampling maintaining tractability even face complex models neural networks. ensemble sampling dramatically expands range applications thompson sampling viable. establish theoretical basis supports approach present computational results offer insight. thompson sampling emerged effective heuristic trading exploration exploitation broad range online decision problems. select action algorithm samples model system prevailing posterior distribution determines action maximizes expected immediate reward according sampled model. basic form algorithm requires computing sampling posterior distribution models tractable simple special cases. complex models neural networks exact computation posterior distributions becomes intractable. resort laplace approximation discussed example approach suitable posterior distributions unimodal computations become obstacle complex models like neural networks compute time requirements grow quadratically number parameters. alternative leverage markov chain monte carlo methods computationally onerous especially model complex. practical approximation thompson sampling address complex models problems requiring frequent decisions facilitate fast incremental updating. time required time period learn data generate sample model small grow time. fast incremental method builds laplace approximation concept presented paper study fast incremental method applies broadly without relying unimodality. sanity check offer theoretical assurances apply special case linear bandits. also present computational results involving simple bandit problems well complex neural network models demonstrate efﬁcacy approach. approach inspired applies similar concept complex context deep reinforcement learning without theoretical analysis. essential idea maintain incrementally update ensemble statistically plausible models sample uniformly time period approximation sampling posterior distribution. model initially sampled prior updated manner incorporates data random perturbations diversify models. intention ensemble approximate posterior distribution variance among models diminish posterior concentrates. reﬁne methodology bound incremental regret relative exact thompson sampling broad class online decision problems. bound indicates sufﬁces maintain number models grows logarithmically horizon decision problem ensuring computational tractability approach. consider broad class online decision problems thompson sampling could principle applied though would typically hindered intractable computational requirements. deﬁne random variables respect probability space endowed ﬁltration convention random variables index ft-measurable denote probabilities expectations conditioned decisionassume ﬁnite action chosen randomized policy ft-measurable realization probability mass function actions sampled independently agent associates reward outcome reward function ﬁxed known. denote reward realized time uncertainty induces uncertainty true optimal action -period conditional regret denote example drawn distributed according prior. actions time action selected reward θ⊤at +wt+ observed example denote mapping induced neural network weights suppose actions serve inputs neural network goal select inputs yield desirable outputs. time action selected observed reward associated observation. distributed according prior. idea data pairs used neural network model actions selected trade generating data pairs reduce uncertainty neural network weights offer desirable immediate outcomes. thompson sampling offers heuristic policy selecting actions. time period algorithm samples action posterior distribution optimal action. words thompson sampling uses policy easy equivalent sampling model index posterior distribution models selecting action thompson sampling computationally tractable problem classes like linear bandit problem posterior distribution gaussian parameters updated incrementally efﬁciently kalman ﬁltering outcomes observed. however dealing complex models like neural networks computing posterior distribution becomes intractable. ensemble sampling serves approximation thompson sampling contexts. posterior interpreted distribution statistically plausible models mean models sufﬁciently consistent prior beliefs history observations. interpretation mind thompson sampling thought randomly drawing range statistically plausible models. ensemble sampling aims maintain incrementally update sample ﬁnite models. spirit particle ﬁltering models approximates posterior distribution. workings ensemble sampling ways intricate conventional uses particle ﬁltering however interactions ensemble models selected actions skew distribution. elements ensemble sampling require customization general template presented algorithm algorithm begins sampling models prior distribution. then time period model sampled uniformly ensemble action selected maximize expected reward sampled model resulting outcome observed models updated. produce explicit algorithm must specify model class prior distribution algorithms sampling prior updating models. concrete illustration consider linear bandit though ensemble sampling unwarranted case since thompson sampling efﬁcient linear bandit serves useful context understanding approach. standard algorithms used sample models prior. possible procedure updating models maintains covariance matrix updating according admits intuitive interpretation ˜θtm model randomly perturbed prior randomly perturbed observations. establish appendix deterministic sequence conditioned models ˜θtm independent identically distributed according posterior distribution sense ensemble approximates posterior. observation that deterministic action sequences scheme generates exact samples posterior distribution however stochastic action sequences selected algorithm immediately clear well ensemble approximates posterior distribution. provide bound next section establishes that number models increases regret ensemble sampling quickly approaches thompson sampling. ensemble sampling algorithm described linear bandit problem motivates analogous approach neural network model example approach would begin models connection weights sampled prior. could natural chosen range probable models spans plausible outcomes. incrementally update parameters time model applies number stochastic gradient descent iterations reduce loss function form past analyses thompson sampling relied independence models sampled time periods. ensemble sampling introduces dependencies adversely impact performance. immediately clear whether degree degradation tolerable depends number models ensemble. section establish bound linear bandit context. result serves sanity check ensemble sampling offers insight extend broader model classes though leave formal analysis beyond linear bandit future work. consider linear bandit problem described example denote thompson ensemble sampling policies problem latter based ensemble models generated updated according procedure described section mina∈a denote worst mean reward denote maximal inequality bounds regret realized ensemble sampling regret realized thompson sampling error term since talking cumulative regret error term bounds per-period degradation relative thompson sampling value made arbitrarily small increasing hence sufﬁciently large ensemble per-period loss small. supports viability ensemble sampling. important implication result sufﬁces ensemble size grow logarithmically horizon since thompson sampling requires independence models sampled time sense relies models time period. useful ensemble sampling operate effectively much smaller number logarithmic dependence suitable. actions. conjecture similar bound holds depends instead multiple linear dimension would offer stronger guarantee number actions becomes large inﬁnite though leave proof alternative bound future work. bound theorem notion regret conditioned realization bayesian regret bound removes dependence realization obtained taking expectation integrating conditioned history rewards models ˜θtm comprise ensemble independent identically distributed according posterior distribution veriﬁed algebra done appendix. recall denotes posterior probability explicitly indicate dependence action process superscript tma′. note given action process time thompson sampling would sample next action deterministic then since ˜θtm conditioned history rewards i.i.d. distributed represents empirical distribution samples drawn follows sanov’s theorem that deterministic actions terms action counts particular number times action selected time apply coupling argument introduces dependencies noise terms action counts without changing distributions observable variables. i.i.d. random variables zctat similarly i.i.d random variables ˜wt+m ˜zctat atm. make explicit dependence superscript write denote action counts time action process given hard verify done appendix deterministic action sequences allows apply union bound action counts instead action sequences section present computational results demonstrate viability ensemble sampling. start simple case independent gaussian bandits section move complex models neural networks section section serves sanity check empirical performance ensemble sampling thompson sampling efﬁciently applied case able compare performances algorithms. addition provide simulation results demonstrate ensemble size grows number actions. section goes beyond theoretical analysis section gives computational evidence efﬁcacy ensemble sampling applied complex models neural networks. show ensemble sampling even models achieves efﬁcient learning outperforms ǫ-greedy dropout example neural networks. figure shows per-period regret thompson sampling ensemble sampling applied gaussian bandit independent arms. number models increases ensemble sampling better approximates thompson sampling. results averaged realizations. figure shows minimum number models required expected per-period regret ensemble sampling plus expected per-period regret thompson sampling large time horizon across different numbers actions. results averaged realizations. chose plot shows number models needed seems grow sublinearly number actions stronger bound proved section section follow example show computational results ensemble sampling applied neural networks. figure shows ǫ-greedy ensemble sampling applied bandit problem mapping actions expected rewards represented neuron. speciﬁcally actions mean reward selecting action given weights drawn time period select action observe reward input dimension number actions prior variance noise variance dimension action sampled uniformly except last dimension figure ensemble sampling compared thompson sampling gaussian bandit independent arms. minimum number models required expected per-period regret ensemble sampling plus expected per-period regret thompson sampling gaussian bandits across different numbers arms. time period select action observe reward used input dimension dimension hidden layer number actions prior variance noise variance dimension action sampled uniformly except last dimension ensemble sampling models starts sampling prior distribution independently model time step pick model uniformly random apply greedy action respect model. update ensemble incrementally. time period apply steps stochastic gradient descent model respect loss function besides ensemble sampling heuristics sampling approximate posterior distribution neural networks used develop approximate thompson sampling. ghahramani proposed approach based dropout approximately sample posterior neural networks. figure include results using dropout approximate thompson sampling two-layer neural network bandit. facilitate gradient used leaky relus form internally agents target neural nets still regular relus described above. took stochastic gradient steps minibatch size model update. used learning rate ǫgreedy ensemble sampling learning rate dropout dropping probabilities respectively. results averaged around realizations. figure plots per-period regret ǫ-greedy ensemble sampling single neuron bandit. ensemble sampling even models performs better ǫ-greedy best tuned parameters. increasing size ensemble improves performance. ensemble size achieves orders magnitude lower regret ǫ-greedy. figure show different versions ǫ-greedy applied two-layer neural network model. ǫ-greedy annealing schedule tends perform better ﬁxed figure plots per-period regret dropout approach different dropping probabilities seems perform worse ǫ-greedy. figure plots per-period regret ensemble sampling neural bandit. again ensemble sampling moderate number models outperforms approaches signiﬁcant amount. epsilon=. epsilon=. epsilon=. epsilon=. epsilon=/ epsilon=/ epsilon=/ epsilon=/ dropout=. dropout=. dropout=. dropout=. ensemble= ensemble= ensemble= ensemble= ensemble sampling offers potentially efﬁcient means approximate thompson sampling using complex models neural networks. provided analysis offers theoretical assurances case linear bandit models computational results demonstrate efﬁcacy complex neural network models. motivated largely need effective exploration methods efﬁciently applied conjunction complex models neural networks. ensemble sampling offers approach representing uncertainty neural network models others might also brought bear developing approximate versions thompson sampling analysis various forms approximate thompson sampling remains open. ensemble sampling loosely relates ensemble learning methods though important difference motivation lies fact latter learns multiple models purpose generating accurate model combination former learns multiple models reﬂect uncertainty posterior distribution models. said combining related approaches fruitful. particular practical beneﬁt learning many forms", "year": 2017}