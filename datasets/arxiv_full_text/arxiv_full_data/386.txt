{"title": "End-to-End Tracking and Semantic Segmentation Using Recurrent Neural  Networks", "tag": ["cs.LG", "cs.AI", "cs.CV", "cs.NE", "cs.RO"], "abstract": "In this work we present a novel end-to-end framework for tracking and classifying a robot's surroundings in complex, dynamic and only partially observable real-world environments. The approach deploys a recurrent neural network to filter an input stream of raw laser measurements in order to directly infer object locations, along with their identity in both visible and occluded areas. To achieve this we first train the network using unsupervised Deep Tracking, a recently proposed theoretical framework for end-to-end space occupancy prediction. We show that by learning to track on a large amount of unsupervised data, the network creates a rich internal representation of its environment which we in turn exploit through the principle of inductive transfer of knowledge to perform the task of it's semantic classification. As a result, we show that only a small amount of labelled data suffices to steer the network towards mastering this additional task. Furthermore we propose a novel recurrent neural network architecture specifically tailored to tracking and semantic classification in real-world robotics applications. We demonstrate the tracking and classification performance of the method on real-world data collected at a busy road junction. Our evaluation shows that the proposed end-to-end framework compares favourably to a state-of-the-art, model-free tracking solution and that it outperforms a conventional one-shot training scheme for semantic classification.", "text": "abstract—in work present novel end-to-end framework tracking classifying robot’s surroundings complex dynamic partially observable real-world environments. approach deploys recurrent neural network ﬁlter input stream laser measurements order directly infer object locations along identity visible occluded areas. achieve ﬁrst train network using unsupervised deep tracking recently proposed theoretical framework end-to-end space occupancy prediction. show learning track large amount unsupervised data network creates rich internal representation environment turn exploit principle inductive transfer knowledge perform task it’s semantic classiﬁcation. result show small amount labelled data sufﬁces steer network towards mastering additional task. furthermore propose novel recurrent neural network architecture speciﬁcally tailored tracking semantic classiﬁcation real-world robotics applications. demonstrate tracking classiﬁcation performance method real-world data collected busy road junction. evaluation shows proposed end-to-end framework compares favourably state-of-the-art model-free tracking solution outperforms conventional one-shot training scheme semantic classiﬁcation. complete accurate situational awareness complex dynamic environments pivotal requirement successful safe robot operation. often however remains elusive goal limited ﬁeld view robot’s on-board sensors complex usually wide-ranging occlusions encountered. limitation impose signiﬁcant challenges planner lead otherwise unnecessarily conservative robot behaviour object detection tracking modules speciﬁcally addressing problem ubiquitous robotics. commonly however feature multiple individual data-processing steps designed optimised separately another. traditional model-free approaches make assumptions regards objects involved shapes semantic characteristics often robust. model-based approaches hand limit generality frameworks often require separate object segmentation classiﬁcation steps. fig. typical output proposed system capturing situation around robot form semantic map. stream sensor data ﬁltered recurrent neural network produces classiﬁcation directly visible occluded space several semantic classes. sensor scene observations often incomplete occlusions continuously provides estimates uncovered occlusion-free scene containing information positions objects along classes illustrated figure inspired recently proposed framework deep tracking leverages neural networks end-to-end tracking. however framework deployed predicting occupancy comparatively benign simulated data using simple networks. improve work ways. first motivate signiﬁcant changes original deep tracking architecture demonstrate lead substantial performance gains complex real-world scenarios. particular propose multi-scale convolution address need simultaneously track objects different sizes dynamic memory effectively remember information long periods time static memory learn place-speciﬁc information. secondly effectively learn object semantics extend framework fig. comparison classical multi-stage perception pipeline proposed end-to-end framework multi-stage pipeline requires signiﬁcant amount design effort step pipeline introduces simplifying assumptions resulting restrictions general applicability overall system. demonstrate system data collected busy road intersection show provides signiﬁcantly accurate scene prediction compared alternative approaches network tracks classiﬁes different objects complete occlusion also predicts movements short time horizon. main contributions paper framework allow end-to-end simultaneous tracking semantic classiﬁcation based method deep tracking principle transfer learning. rest paper structured follows. reviewing related works section present problem deﬁnition section iii. section provides overview deep tracking framework section extends framework beyond tracking additionally produce semantic labels output. section proposes architecture allow effective tracking complex real-world scenarios. finally section present empirical evaluation contributions. conclude section viii discuss ﬁndings. multi-stage tracking pipeline illustrated figure pipeline features sequence explicit largely hand-engineered steps consisting object detection considering stream sensor input semantic classiﬁcation data association state estimation ﬁnally occupancy grid generation. instead build recently proposed approach deep tracking featuring recurrent neural network directly maps laser data semantically annotated unoccluded occupancy grid. illustrated bottom figure deep learning approaches successful number domains beneﬁted large amounts data order learn appropriate internal representations leading signiﬁcant performance gains beyond achievable classical methods. case neural network trained end-toend predict space occupancy semantic labels directly laser data. learns perform implicit tracking optimal internal representations hypotheses moving objects respective update procedures classical tracking inferred directly data. successfully apply deep learning appropriate neural network architecture task must chosen. abundant literature exists topic ﬁnding optimal architectures different tasks convolutional networks image processing recurrent neural nets long short term memory gated recurrent units processing sequences. propose novel neural network architecture speciﬁcally tailored real-world object tracking. network shares similarity architectures semantic labelling natural images terms ability produce output resolution. addition provide effective mechanisms track objects different sizes time learn placespeciﬁc information recurrent mechanisms remember information long periods time order track objects effectively even long occlusions. common drawback deep learning approaches need large amounts supervised data training. show network fact trained efﬁciently. network ﬁrst learns track observing stream unlabelled sensor data trying predict next input. turn exploit fact learned representation captures latent higher-order information data easily infer semantic labels tracked objects using small amount labelled data. form inductive transfer knowledge machine learning tasks context neural networks successfully applied range tasks areas multi-task learning form unsupervised pre-training supervised ﬁne-tuning input problem sequence partially observed states world computable directly sensor measurements. represent state discretised grid size parallel ground built locally around sensor. partially observed state world represented binary matrices collectively referred }×m×m ﬁrst matrix encodes whether cell directly observable sensor time second matrix encodes whether cell observed free occupied output wish obtain consists parts. ﬁrst part occlusion-free state world }m×m represented occupancy matrix similar occupancy matrix second part semantic k}m×m revealing cell types objects currently occupying problem therefore resolves solving probability complete state world semantics time given observed input previous time steps formulation also used predict future state simply providing empty input xt+t+n next section ﬁrst outline solution partial problem estimating suggested recently proposed deep tracking framework modiﬁed operation complex real-world scenarios. section extend solution estimate application principle inductive transfer. section focus solving ﬁrst part problem formulated section namely uncovering full unoccluded state environment sequence partially observed states recently proposed deep tracking framework solve problem. however framework demonstrated simulated scenarios composed simple geometric objects using simple network architecture. number improvements architecture needed scale capacity deal complex dynamic real-world data encountered robotics applications. ﬁrst brieﬂy review details framework relevant application present proposed improved architecture. deep tracking method model using recurrent neural network motivated hidden markov models time latent state assumed capture complete information necessary predicting thus element latent state update decoding output modelled parts single neural network trained jointly. equation modelled forward-propagation information hidden layers network equation modelled decoding layer equations performed repeatedly form recurrent neural network continuously update hidden state serving network memory predict making suitable online stream ﬁltering sensor input. ground-truth output easily available case network trained unsupervised fashion. here instead optimising directly network trained predict part yt+n directly observed xt+n. done predicting back-propagating error observed part scene words train network correctly predict subset ground-truth occupancy present future input. demonstrated also shown figure important consequence training strategy that deployment trained network starts correctly imagine objects movement occluded regions. situation occluded input deployment similar training input provided future time network trained predict observable regions. training recurrent neural network produce space occupancy semantic labels network trained predict output fig. consistent future inputs. allows training without need ground-truth information full unoccluded scene. first network learns track predicting correct occupancy using large amounts unlabelled data small labelled data used induce semantic classiﬁcation. section extend solution partial problem presented section full problem simultaneously estimating occlusion-free occupancy scene semantics show achieved relatively easily exploiting knowledge network already learned predict principle inductive transfer signiﬁcance small amount labelled training data needed allow network master additional task. clue resides hidden representation learned unsupervised training tracking viewed universal descriptor state world. captures positions individual objects also motion patterns shapes properties necessary successful prediction scene dynamics. network trained perform well task reasonable assumption make information necessary prediction position objects near future must already contained hidden representation. object semantic class falls category different objects differ mainly shape motion patterns. similar predicting equation extracting achieved simply building classiﬁer predict training classiﬁer extract semantic information straightforward supervisory signal would need provided pixels whether contain actual object visible occluded areas. supervised dataset would difﬁcult produce occluded laser scans available. instead label visible cells available input data contain actual obstacle. predict labels pixels back-propagate error label. principle makes intuitive sense however could result classiﬁer rely much part memory affected presence visible input performing well directly visible parts scene poorly occluded objects prediction driven purely previously remembered information address issue elaborate training procedure necessary. ensure good performance network classifying occluded objects must trained settings. achieved using principle used train network predict train network predict future semantic label ct+n providing input forces network information stored memory back-propagate error compared true label xt+n. entire process illustrated figure simple recurrent neural network proposed demonstrated sufﬁcient simulated dynamic scenario evaluated work. however effective deployment real-world robotics applications poses challenges appropriate architecture must chosen. particular requires ability simultaneously track objects different sizes cars pedestrians effectively remember information long periods time deal occlusions learn exploit place-dependent information presence static obstacles lastly produce output space occupancy it’s label. therefore section present network architecture designed address issues. overview proposed network depicted figure input time processed multi-layer network. layer output previous layer combined it’s activations time implementing recurrence. allows network extract remember information past prediction time output ﬁnal layer converted resulting output simple convolutional decoder. unlike classical convolutional networks network feature pooling maintains resolution layer. addition features four elements critical successful tracking classiﬁcation realistic scenarios multi-scale convolution dynamic memory static memory pair decoders describe below. multi-scale convolution network correctly predict occupancy label location affected presence moving object object must fall receptive ﬁeld neuron ﬁnal layer. receptive ﬁeld part input affecting value neuron. case classical convolution receptive ﬁeld neighbourhood size convolution kernel. size receptive ﬁeld however limits size effectively tractable objects input vastly different sizes realistic settings. increase receptive ﬁeld increase kernel size stack multiple convolutions other. however creates computational challenge number parameters computational complexity grows quadratically ﬁrst case linearly second case. instead stack dilated convolutions receptive ﬁeld grows exponentially number layers. basic idea perform classical convolution skipping pixels convolved pixels layer illustrated figure gives receptive ﬁeld ﬁnal layer dilated convolution used elementary computation step implement dynamic memory described below. fig. proposed architecture tracking semantic classiﬁcation. features dilated convolution enhanced static dynamic memory capabilities whereas producing information cell occupancy it’s semantic class. fig. multi-scale context aggregation preserving image resolution stacking dilated convolutions layer pixels convolved skip pixels. results exponential growth blue receptive ﬁeld size opposed stacking classical convolutions resulting linear growth remember location object properties shape velocity. findings studies recurrent neural networks stress importance specially dedicated units long short term memory support information-caching otherwise training suffers vanishing gradient problem inspired implement convolutional variant gated recurrent units processing step layer. output unit given weighted combination previous output time candidate memory computed output layer bellow forgetting information controlled reset gate static memory allow cell learn unique universally accessible piece information different cells. achieved biases equations per-layer constant case classical convolution learned individually neuron training. shown section allows network learn place-speciﬁc information static occupancy cell usual motion patterns classes particular area used network prediction. decoders finally employ pair simple convolutional decoders decode output ﬁnal layer cell occupancy class label difference class label employ softmax well alternative state-of-the-art model-free tracking solution targeted problem collected minute long stationary robotic platform equipped hokuyo utm-lx laser scanner positioned middle busy urban intersection depicted figure area features dense trafﬁc composed buses cars cyclists pedestrians results extensive amounts occlusion. consequently point time complete scene fully observable. subsampled dataset split minute unsupervised train network minute long test measure occupancy prediction performance. addition hand-labelled scans training classes purpose network semantic training scans test evaluation semantic classiﬁcation accuracy. classes considered pedestrian car/bus cyclist background input network computed laser scans raytracing. cells laser measurement ends marked occupied cells sensor origin marked free cells beyond marked fig. location experiment robot’s point view superimposed illustration laser measurements. area occupied variety different dynamic objects pedestrians cyclists cars. trained network output provided input fig. corresponding aerial view robot environment ability network learn per-pixel information allows adaptation training environment. allows network conﬁdently predict position static obstacles buildings well probability given cell occupied even without sensor input. pavements show higher probabilities centre roads. clarity visualisation show probabilities occupation. tested proposed network architecture described section conﬁgured three hidden layers channels layer. network total number parameters trained hours convergence single nvidia titan memory using unsupervised training procedure described section iv-a. training sequence split mini-batches length every mini-batch network shown frames trained predict next frames leading sequences mini-batch. chosen cover usual length occlusions scene expect would need increased longer-lasting occlusions. next classiﬁer trained hours semantic classiﬁcation task using minute long labelled dataset. dataset skewed contains compare performance proposed end-to-end system traditional multi-stage pipelines evaluate ability predict future movement dynamic objects proposed framework recently proposed state-ofthe-art approach based model-free tracking dynamic objects using kalman ﬁlter. method accepts laser scans performs data clustering association well velocity estimation moving objects. information used predict positions individual points typical input sequences corresponding predicted network output shown figure network able uncover unoccluded scene including space occupancy object labels moreover able update positions dynamic objects temporary occlusion demonstrating learned track recognise objects scene. proposed system justify qualitative observations. occupancy accuracy ground-truth occupancy annotations full unoccluded state available instead measured accuracy predicting future occupancy yt+n respect visible part scene xt+n. metric used train network section binary obstacle prediction show figure computed f-scores predicting consecutive frames averaged test compare original architecture described state-of-the-art multistage pipeline approach prediction accurate near horizon progressively decreases time. expected uncertainty state world increases prediction horizon. cases results outperform alternative approaches demonstrating effectiveness proposed network architecture advantages end-to-end learning. another experiment concerned measuring effectiveness desired ability learn place-speciﬁc information. evaluate visualise network prediction without providing input displayed figure even without input sensor information network able provide estimate expected occupancy probabilities higher locations static obstacles crowded areas scene pavements. propagation information network occur clearly made possible ability network remember information static memory training. semantic accuracy quantify network’s ability classify scene semantics compute confusion matrix shown figure seen network able produce reliable classiﬁcation object classes considered. main source error lies distinguishing fig. network ability correctly predict future occupancy scene time horizon seconds measured consistency future input. time horizon increases quality prediction degrades. proposed neural network architecture performs better original architecture presented well state-of-the-art multi-stage pipeline approach verify value proposed inductive transfer knowledge compare result alternative approach classifying scene semantics takes form one-shot classiﬁcation directly visible obstacles single raw-sensor input. representative solution approach trained three-layer deep convolutional classiﬁer predicting directly despite conducting rigorous parameter tuning classifying directly input yields inferior classiﬁcation accuracy compared classifying hidden representation negative likelihood cor− demonstrates offers powerful semantic descriptor scene used input accurate semantic classiﬁcation. timing forward propagation single input network takes nvidia titan commodity laptop cpu. sufﬁcient enable real-time processing considered stream laser data work presented novel end-to-end trainable solution real-time object tracking classiﬁcation complex partially-observable real-world environments. leveraging representational power recurrent neural networks employing efﬁcient method surpasses representative state-of-the-art model-free method substantially reducing requirement handengineered knowledge. method extended applied number ways. universal schema input output opens possibility apply method situations beyond evaluated accounting robot motion handled moving robot inside grid multisensor multi-robot fusion. additionally knowledge environment captured learning track exploited provide different kinds semantic information bounding boxes. finally inherent ability predict future evolution environment around robot leveraged upon far-sighted planning scenarios. k.o. arras o.m. mozos burgard. using boosted features detection people robotics automation ieee range data. international conference pages april kyunghyun bart merri¨enboer caglar gulcehre dzmitry bahdanau fethi bougares holger schwenk yoshua bengio. learning phrase representations using encoder-decoder statistical machine translation. arxiv preprint arxiv. george dahl dong deng alex acero. context-dependent pre-trained deep neural networks large-vocabulary speech recognition. audio speech language processing ieee transactions alex krizhevsky ilya sutskever geoffrey hinton. imagenet classiﬁcation deep convolutional neural networks. advances neural information processing systems pages quoc building high-level features using large acoustics speech scale unsupervised learning. signal processing ieee international conference pages ieee christoph mertz luis navarro-serment robert maclachlan paul rybski aaron steinfeld arne suppe christopher urmson nicolas vandapel martial hebert chuck thorpe moving object detection laser scanners. journal field robotics mitchell sebastian thrun explanationbased neural network learning robot control. advances neural information processing systems pages peter ondruska ingmar posner. deep tracking seeing beyond seeing using recurrent neural networks. thirtieth aaai conference artiﬁcial intelligence phoenix arizona february jeffrey pennington richard socher christopher manning. glove global vectors word representation. proceedings empiricial methods natural language processing charles richter william vega-brown nicholas roy. bayesian learning safe high-speed navigation proceedings interunknown environments. national symposium robotics research sestri levante italy trung-dung aycard appenrodt. online localization mapping moving object tracking dynamic outdoor environments. intelligent vehicles symposium ieee pages june dominic zeng wang ingmar posner paul newman. model-free detection tracking dynamic objects lidar. international journal robotics research wang david andrew coates andrew end-to-end text recognition convolutional neural networks. pattern recognition international conference pages ieee xingjian zhourong chen wang dit-yan yeung wai-kin wong wang-chun woo. convolutional lstm network machine learning approach advances neural precipitation nowcasting. information processing systems pages shao-wen yang chieh-chih wang. simultaneous egomotion estimation segmentation moving object journal field robotics detection. issn zhao thorpe. qualitative quantitative tracking range image sequence. proceedings ieee computer society conference computer vision pattern recognition cvpr pages washington ieee computer society. isbn ---.", "year": 2016}