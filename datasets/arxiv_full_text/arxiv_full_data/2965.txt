{"title": "Action-Driven Object Detection with Top-Down Visual Attentions", "tag": ["cs.CV", "cs.AI", "cs.LG"], "abstract": "A dominant paradigm for deep learning based object detection relies on a \"bottom-up\" approach using \"passive\" scoring of class agnostic proposals. These approaches are efficient but lack of holistic analysis of scene-level context. In this paper, we present an \"action-driven\" detection mechanism using our \"top-down\" visual attention model. We localize an object by taking sequential actions that the attention model provides. The attention model conditioned with an image region provides required actions to get closer toward a target object. An action at each time step is weak itself but an ensemble of the sequential actions makes a bounding-box accurately converge to a target object boundary. This attention model we call AttentionNet is composed of a convolutional neural network. During our whole detection procedure, we only utilize the actions from a single AttentionNet without any modules for object proposals nor post bounding-box regression. We evaluate our top-down detection mechanism over the PASCAL VOC series and ILSVRC CLS-LOC dataset, and achieve state-of-the-art performances compared to the major bottom-up detection methods. In particular, our detection mechanism shows a strong advantage in elaborate localization by outperforming Faster R-CNN with a margin of +7.1% over PASCAL VOC 2007 when we increase the IoU threshold for positive detection to 0.7.", "text": "abstract—a dominant paradigm deep learning based object detection relies bottom-up approach using passive scoring class agnostic proposals. approaches efﬁcient lack holistic analysis scene-level context. paper present action-driven detection mechanism using top-down visual attention model. localize object taking sequential actions attention model provides. attention model conditioned image region provides required actions closer toward target object. action time step weak ensemble sequential actions makes bounding-box accurately converge target object boundary. attention model call attentionnet composed convolutional neural network. whole detection procedure utilize actions single attentionnet without modules object proposals post bounding-box regression. evaluate top-down detection mechanism pascal series ilsvrc cls-loc dataset achieve state-of-the-art performances compared major bottom-up detection methods. particular detection mechanism shows strong advantage elaborate localization outperforming faster r-cnn margin pascal increase threshold positive detection network based object classiﬁcation methods computer vision community reached human-level performances ilsvrc classiﬁcation task; top- error even superior human showing error thus current research focus visual recognition quickly moving towards richer image understanding problems object detection pixel-level semantic segmentation image description question answering natural language. focus lying object detection problem. long line successful works object detection signiﬁcant progress terms accuracy efﬁciency achieved deep learning approaches quite recent years. among large literature object detection deep learning approaches major state-of-the-art family region pipeline; extracting class agnostic object proposals applying object classiﬁers reﬁning bounding-boxes. researches incorporate r-cnn reported scores ilsvrc’ faster r-cnn ilsvrc’. however even accurate efﬁcient r-cnn pipeline embeds limitation reﬂecting important visual contexts outside proposal caused passive scoring e-mail dgyoorcv.kaist.ac.kr iskweonkaist.ac.kr park paeng lunit inc. south korea. e-mail sgparklunit.io khpaenglunit.io j.-y. adobe research usa. e-mail joleeadobe.com proposal classiﬁers. avoid limitation alternative top-down approaches actively explore location target object taking surrounding context account. however top-down approach deep learning based object detection much investigated yet. paper propose action-driven method top-down object detection. cast object detection problem sequential action problem. introduce visual attention model named attentionnet acts agent determining action taken next step. model takes image region input provides optimal actions getting closer toward target object. detection mechanism attention model fully utilized beginning object detection pipeline. starting whole image large region detection mechanism actively explores location target object ﬁnishes drawing accurate bounding-box. background context surrounding target object also taken consideration since searching scope early stage broad enough. core detection mechanism lies idea taking action sequence order attention model. attention model tells pair actions taken top-left bottom-right corner input image closer target object. instance action could down left corner respectively. simply take actions cropping input image image boundary converges target object. even action inaccurate taking multiple actions results accurate boundary target object ensemble method combines many weak learners produce strong learner. fig. shows real examples detection fig. real detection examples detection mechanism. starting image boundary detection mechanism recursively narrows bounding-box ﬁnal human location visual effects size movement small examples. detection mechanism radically distinct state-of-the-art r-cnn based methods. methods depend bottom-up object proposals score classiﬁers follow top-down search strategy. bottom-up object proposals based characteristic local scene called objectness. proposals driven low-level features trainable mid-level features. contrast top-down mechanism controlled high-level subtasks i.e. detection boxes driven sequence actions. bottom-up approaches inherently faster top-down approach since feed-forward recurrent. however top-down approach strong property coming high-level reasoning context surrounding target object could reﬂected action sequence. thus top-down approach complementary toward next direction object detection. detection mechanism single attention model everything necessary detection pipeline yields state-of-the-art performance. single attention model detect initial regions single instance included detect objects taking sequential actions initial region ﬁnally reﬁne localizations taking extra action sequence. therefore incorporate separate modules object proposals post bounding-box regression. preliminary version work published detect single object class. since generalized detection mechanism handle multiple object classes shared attention model. also given important modiﬁcations determining scaling factors used multi-scale training inference. large literature object detection last decades. object models learned low-level features mid-level part based features models evaluate image regions sliding window fashion. since then raise object proposal methods generate thousands potential bounding-boxes substantially improves detection efﬁciency compared sliding window search. refer readers in-depth study various object proposal methods. recent researches object detection signiﬁcant progress accuracy efﬁciency achieved powerful combination three; highquality object proposals deep network represent proposals data training network framework called r-cnn proposed girshick become dominant paradigm object detection. limit review deep learning approaches. successful performance r-cnn pipeline triggered engineering challenges make real-time. attempt train feed-forward network object proposal speeds proposal step requires per-region classiﬁcation real-time speed. contrast per-region pooling shared convolution feature substantially boosts speed classifying proposals extracting proposal bottleneck. design region proposal network make network classiﬁcation network share convolu detection mechanism introduce detection mechanism assumption input image includes single object instance only. extension mechanism multiple instances described sec. fig. shows frame object detection problem sequential action problem. ﬁrst warp input ﬁxed size image feed attention model named attentionnet. attention model tells pair actions required input closer target object. actions applied top-left corner bottom-right corner input image respectively. deﬁne high-level action follows; right right-down stop reject also deﬁne action directions movement actions opposite attention model indicating fig. apply actions corner cropping input. amount movement constant. cropped image attention model image meets terminal conditions; corners corners. image given corners regarded background image given corners detection result. detected image boundary back-projected bounding-box original input image domain. given stopped bounding-box corresponding output activations softmax normalization detection score discriminatively deﬁned compared r-cnn framework depends object proposals detection starts large area actively reaches terminal point stop signals. early stage procedure take large context surrounding object consideration. large context important identifying class object. beneﬁt highlighted experiment sec. again. compared previous detection-by-regression approaches solve regression problem iterative classiﬁcations high-level actions. even actions early stage could inaccurate subsequent actions become stronger searching scope gradually narrowed object. attention model detection mechanism requires agent determines optimal actions applied corner input. agent regression model tells location coordinate regression difﬁcult task bottom-up approaches inherently feedforward fast lack holistic analysis scene-level context. top-down approach relatively slow recurrent actions larger context taking actions. three recent works similar terms adopting action-driven top-down approach. gonzalez-garcia propose active search strategy depends spatial context region scores previous state. caicedo lazebnik mathe also present actiondriven detection methods agent determining actions trained reinforcement q-learning three works successfully apply top-down approach detection problem however performances still state-of-the-art competitors detector class-speciﬁc. paper extend previous classspeciﬁc model handle multiple classes achieve state-of-the-art performances. introduce another side detection paradigm detection problem framed regression problem. feed-forward network directly estimates bounding-boxes. szegedy trains deep network maps image rectangular mask object. sermanet also employ similar approach network directly estimates bounding-box coordinates. models produce single bounding-box evaluated sliding windows detect multiple instances. quite recently redmon develop regression model produces multiple bounding-boxes class probabilities. estimate bounding-box grid cell convolution feature outputs obtained single feed-forward path. detection-by-regression approaches also related work rely object proposals actively produce boundingboxes. however distinct methods regression proceeds sequentially high-level reasoning. attention model agent long line attention models also related ours. recent years incorporating visual attention idea deep network proposed select regions need attention better visual recognition classiﬁcation caption generation attention model differs supervision. incorporate attention model order determine optimal action closer object whereas models focused representation help target recognition tasks. also train model supervised fashion optimal action labels determined ground-truth bounding-boxes. contrast attention methods cannot directly supervised since target labels include locations signiﬁcant objects. reason often employ reinforcement q-learning design differentiable model could optimized backpropagation weakly supervised fashion. fig. action-driven detection mechanism. attention model tells pair actions taken top-left corner bottom-right corner input image. action deﬁned follows; right right-down stop reject action also deﬁned opposite directions. attention model produces action reject corners reject input. apply actions input feed model meets action stop corners. network compared classiﬁcation task classiﬁes quantized directions. thus choose classiﬁcation model trainable softmax loss. model composed classiﬁcation layers corners layer classiﬁes actions including three movement actions termination actions fully connected ﬁlters size determine action scores corner. choose base network model popular convolutional network architectures. illustration model shown fig. training required actions determinant location target object. always determine optimal action arbitrary region closer ground-truth bounding-box. selecting optimal action time step depend previous action sequence. thus train attention model regardless that. caicedo lazebnik also present action-driven detection mechanism agent. action differently deﬁned horizontal moves vertical moves scale changes aspect ratio changes. given action adopt reinforcement q-learning based reward. despite interesting application reinforcement learning object detection reinforcement method inherently high variance gradient expected reward difﬁcult accurately value approximated deep network limited size training set. contrast since actions designed optimally chosen increase states train attention model softmax loss. make attention model operate scenario devise important process original training images suitable form. inference stage number possible action pairs {→↓}tl {←↑}br positive regions {×tl×br} negative regions. evenly cover cases training augment original training images reformed region set. fig. examples generating training regions learn attention model. dashed rectangle ground-truth. inside groundtruth inner bound times smaller ground-truth outer bound times larger that. region bounds randomly sampled random horizontal ﬂip. ground-truth action label corner assigned automatically. area beyond image boundary ﬁlled zeros. sample regions inner outer bound. inner bound times smaller ground-truth whereas outer bound times larger. area image boundary ﬁlled zeros. important make outer bound sufﬁciently large take large context account training. region horizontally ﬂipped probability assign pair ground-truth action labels corners determined ground-truth boundingbox. also randomly generate negative regions overlapped ground-truth bounding-boxes. regions probably include multiple instances top-right example fig. case simply assign action labels biggest instance. regions also essential training. consider multiple instance detection scenario. attention model trained without regions ﬁnal detection result large initial region probably includes multiple instances ones. make mechanism always narrow biggest instances within visible area must compose mini-batch training select positive negative regions equal portion. batch cases positive regions occupies portion negative regions occupy remaining portion loss training average log-softmax losses computed independently make detection mechanism detect multiple instances verify effectiveness top-down approach bottom-up approach relying region proposals studied strong mid-level activations deep network come object parts distinctive object classes. since r-cnn based detection depends score computed activations inside proposal results often focuses discriminative object parts rather entire object analyze issue design experiment singlehuman detection pascal train alexnet based r-cnn human detector code provided authors also train alexnet based attention model training data. test choose images contain single human instance make test set. highlight difference comes top-down bottom-up approaches choose top- region detection result r-cnn. detection mechanism begins entire image boundary detects instance. measure average precisions standard threshold positive detection. table shows results. bottom-up approach shows top-down approach shows bottom-up approach shows much lower detection performance weak correlation classiﬁcation score proposal entire human body. shown fig. maximally scored object proposal rcnn prone focus discriminative faces rather entire human bodies. contrast detection mechanism reaches terminal point starting boundary target object. fig. qualitative comparison bottom-up top-down approach single-human detection task. left column bottom-up rcnn based method right column top-down method. left column bounding-box top- region cyan boxes top- regions. attention model provides actions toward single instance visible region. section introduce efﬁcient method extend detection mechanism practical scenario image includes multiple instances. solution initialize large instance. call initial glance. also utilize attention model therefore separated model unnecessary. detect instance initial glance merge results reduced number bounding-boxes followed ﬁnal reﬁnement procedure reuse attention model again. required condition region initial glance region contain entire instance sufﬁcient surrounding contexts. assume arbitrary region image feed region attention model. among possible action combinations action prediction tlbr) guarantees region includes entire body instance enough margins. predictions possible region truncating instance background. examples shown fig. input size pixel action corresponds region size equal ground-truth bounding-box original image domain. make regions satisfy tlbr) condition enough margin deﬁne margin factor rescale input size. deﬁne scaling factor multiplied fig. condition window initial glance. among muti-scale muti-aspect ratio windows choose regions predicted corner initial glances make sure entire object instance included. objective determine representative scaling factors used inference stage maximize chance mining initial glances. given training image ground-truth bounding-boxes tr}-size compute scaling factor samples bounding-boxes. representative scaling factors estimated grouping samples. k-means clustering algorithm samples logscale space obtain centroids inference stage rescale test image multiple sizes fig. efﬁcient initial glance mining action maps. large image fully convolutional attention model obtain action corner. regions satisfying condition becomes initial glances. glances given attention model detect instance illustrated fig. input convolutional network limited ﬁxed size since fully connected layer could replaced convolution layer containing size ﬁlters. feed multi-scale multi-aspect ratio images fully convolutional attention model obtain action maps corner. instance base network vgg- pixel neighbor action correspond size regions stride input image. given action maps choose regions satisfy tlbr) condition initial glances. example shown fig. initial glances given attention model detect instance mechanism described fig. instances located side image side image dilates size margin ﬁlled zeros attention model. object instances diverse aspect ratio scale. thus scales aspect ratios input image important successfully mine initial glances inference stage. thus introduce data-driven approach determine scales aspect ratios. assume minimum input size attention model also input image size groundtruth bounding-box size. rescale initial glance attention model recurrently meets ﬁrst image fig. shows real example initial detection. bounding-boxes merged decreased number single-linkage clustering; group bounding-boxes satisfying minimum averaged scores reﬁne result conduct post boundingbox regression re-localizes bounding-boxes. linear regression model maps feature bounding-box one. case employ attention model reﬁnement step. simply rescale bounding-box fig. region rescaling factor shown fig. reinitialized regions attention model result bounding-boxes shown fig. redetection procedure gives chance reject false positives well localization. bounding-boxes merged ﬁnal results section perform human detection task public datasets comprehensively verify strength detection mechanism. among wide range object classes beyond question class human taken center stage object detection decades broad applications. nonetheless human detection uncontrolled natural images still challenging self-occlusions diverse poses clothes. fig. intermediate results detection procedure. shows initial detection results initial glances. boxes merged reﬁne results boxes rescaled factor shrink resulting boxes ﬁnally merged datasets human detection task choose pascal since composed user taken photos flickr image condition completely uncontrolled. human instances sets severely occluded truncated overlapped diverse pose variations scales. pascal include images object classes equally divide trainval test set. following standard protocol used previous human detection researches sets trainval images training report average precision test set. pascal submit results evaluation server receive base network choose vgg-m vgg- base networks attention model. vgg-m designed chatﬁeld variant alexnet small modiﬁcations. stride ﬁlter ﬁrst layer smaller alexnet stride second convolution layer larger. model also composed convolution layers. adopt model lower top- error alexnet ilsvrc classiﬁcation without signiﬁcant increase computation. vgg- designed simonyan zisserman much deeper network composed convolution layers smaller ﬁlter sizes. single model shows error ilsvrc classiﬁcation. pascal series small learn large model. thus initialize base network pre-trained weights ilsvrc cls-loc dataset ﬁne-tune model target task. model pick pre-trained layers except last classiﬁcation layer stack action layers those. parameters follow ﬁne-tuning technique train attention model; initial learning rate pre-trained weights whereas randomly initialized weights learning curve saturated decrease learning rates .-times. inference stage size movement action pixels single attentionnet single attentionnet-reﬁne single person r-cnn bb-regression person r-cnn bb-regression× single person r-cnn bb-regression× single multi single poselets single k-poselets single hog-iii single poselets multi regression multi deepmultibox multi r-cnn multi r-cnn single q-learning q-learning multi multi-class attentionnet multi single attentionnet single attentionnet-reﬁne single attentionnet faster r-cnn single attentionnet-reﬁne faster r-cnn multi r-cnn multi fast r-cnn faster r-cnn multi mr-cnn s-cnn loc. multi multi yolo multi multi-class attentionnet multi *trained superset trainval’+test’+trainval’. zfnet shown table networks composed layers yolo shown table attention model based vgg-m method achieves dataset without reﬁnement step fig. reﬁnement step marked attentionnetreﬁne achieve slightly worse performances attention model equipped vgg- model performances signiﬁcantly increase dataset. reﬁnement step performances also slightly decreased single class detection beneﬁt reﬁnement step observe improves multiclass detection presented sec. reinterpret method regression iterative classiﬁcations compare detection-by-regression methods bounding regression. train person r-cnn bounding regressor bb-regression using ofﬁcial code provided r-cnn authors images person class used positives images used backgrounds make comparison completely fair. initial detection boxes r-cnn given bounding regressor boxes re-localized. method shows shown second block table method repeats actions also repeat bounding-box regression rcnn noted bb-regression× however improvement negligible second third iterations. method beats approaches large margin results verify effectiveness iterative classiﬁcations regression method. detection-by-regression methods network trained produce target object mask bounding-box coordinates purpose class-agnostic object proposals. still method clearly outperforms methods shown table quite recently estimate bounding-box grid cell convolution feature outputs obtained single feed-forward performing real-time. performances methods summarized table yolo convolution layers shows much lower ours. based vgg- achieves state-of-the-art performance however model trained superset trainval’+test’+trainval’. results also verify beneﬁt iterative classiﬁcations compared regression approaches. poselets-based methods related since methods limited single object class among them deep learning approach uses -layered network like ours. however method signiﬁcantly outperforms approaches. results expect method successfully extended multiple classes since human-speciﬁc model detect humans. r-cnn advanced variants successful detection method far. bottom-up methods contrast top-down approach. compare method r-cnn using layers table show around performance method outperforms performance. fair comparison train another r-cnn detect person class noted person r-cnn result similar result -layered network even signiﬁcantly better r-cnn -layered network table performances vgg- based fast r-cnn faster r-cnn summarized table fast r-cnn shows performances method beats performances respectively. method competitive faster r-cnn shows performances. methods fast r-cnn faster r-cnn faster since feed-forward recurrent. also advantageous terms recall take visible regions account. contrast method strong properties driven scene-level contexts. thus expect large performance improvement complementary methods. combine boxes faster r-cnn boxes. rescale scores merge boxes scores results reported second block table achieve signiﬁcantly boosted performances; experiment expect research top-down approach contribute future hybrid model taking advantages approaches. top-down approaches object detection adopt reinforcement learning train agents rewards. performances methods respectively state-of-the-art performance shown table contrast actions designed optimally chosen state train attention model softmax loss achieve much superior performances. multi-class detection mechanism section generalize attention model speciﬁed object class multiple object classes. ﬁrst modify attention model multi-class version sec. explain initial glance mining sec. followed remaining detection procedures sec. ﬁnally present training method sec. attention model class-speciﬁc attention model pair action layers speciﬁed single object class. make model provide actions regarding multiple classes deﬁne action layers class parallelize fig. attention model extended multiple object classes. pair action layers deﬁned class provide class-speciﬁc actions. classiﬁcation layer also deﬁned recognize class input object. region contain entire object body sufﬁcient surrounding contexts. since recurrently shrink initial glance target object movement actions important initial glance truncating target object. given candidate regions choose regions satisfy following conditions initial glances indicate initial glance background truncating target object shown fig. here class prediction classiﬁcation layer action predictions action layers predicted class boost speed recall initial glance mining feed multi-scale multi-aspect ratio images fully convolutional attention model pick initial glances resulting action maps illustrated fig. also follows data-driven method determine scaling factors presented sec. scaling factors estimated ground truth bounding boxes regardless classes training image set. initial detection reﬁnement start initial glances iteratively shrink boundaries movement actions predicted class procedure repeated region rejected ˆc=n+ meets following conditions indicate ﬁnal region foreground class terminates stop actions corners. back-project ﬁnal regions corresponding boxes original input image domain boxes merged initial reﬁnement step rescale initial detection boxes rescaling factor shrink terminate stop actions. ﬁnally merge detection boxes ﬁnal fig. shows real examples procedures. base network. model illustrated fig. classes model composed pairs action layers. given input model always produces class-speciﬁc action pairs. however these determine action pair chosen input since object class input unknown. thus deﬁne extra classiﬁcation layer recognizes input object class able choose action pair. classiﬁcation layer produces -dimensional vector composed background score class scores. since classiﬁcation layer tells whether input background remove reject actions action layers. thus action layer produces -dimensional vector composed movement action scores stop action score. multi-class detection mechanism attention model proceeds follows. input obtain classiﬁcation scores ycls= action scores {ytlc ybrc action scores class ytlc= ybrc=. input predicted background class ˆc=n+ input rejected. choose predicted actions predicted class corners take actions. procedure repeated action predictions corners input rejected ˆc=n+. initial glance detect multiple instances image collect regions called initial glances presented sec. required condition region initial glance model random regions evenly cover various object classes required actions backgrounds. ground-truths including bounding-boxes classes given automatically determine optimal action label corner random region. follows method fig. generate random regions. compose mini-batch training select object regions background regions equal probability described sec. given region class label tcls pair action labels deﬁne three log-softmax losses classiﬁcation layer action layers class. zero-losses given action layers classes. deﬁne ﬁnal loss combining classiﬁcation loss action losses ilsvrc cls-loc dataset googlenet designed szegedy googlenet also deep model convolution layers much faster vgg- showing comparative performance top- error single model. choose model speed training large-scale data. training pick pre-trained layers googlenet except last classiﬁcation layer stack action layers those. parameters parameters necessary training inference equal single class detection mechanism presented sec. except following; number scaling factors rescaling factor evaluation ilsvrc cls-loc dataset. loss fusion parameter score fusion parameter equally multi-class experiments section perform multi-class object detection task public datasets comprehensively verify detection mechanism extended multiple classes. datasets primary evaluation choose pascal dataset. follows standard protocol sets described sec. also select ilsvrc cls-loc dataset verify detection capability large number classes large-scale data. dataset includes images object classes divide training images validation images test images. images annotated object classes part training images contain bounding annotations. images train attention model. evaluate localization submitted localization results test ilsvrc’ evaluation server received top- error. top- error reﬂects classiﬁcation localization errors top- predictions image. metric deﬁned sec. results analysis evaluate multi-class detection model pascal per-class method datasets listed table base network multi-class attention model vgg-m method achieves dataset without reﬁnement step fig. reﬁnement step noted attentionnet-reﬁne performances improved different single class attention model table reﬁnement step gives non-negligible beneﬁt coming re-localizations. note multi-class attention model reused reﬁnement. model size increases vgg- model performances also signiﬁcantly increase dataset. reﬁnement step performances slightly increase presented sec. attention model tells corner direction move. corner moves pixels along direction. input region always resized size size movement constant movement original image domain becomes smaller previous stage shown fig. take look performance varies size movement many movements required detect object instance. table summarizing results. smaller size movement requires movements detect instance. expected accuracy decrease size movement increases. however reality accuracy rather increases starts decrease later. reason iteration chance attention model making false attentionnet attentionnet-reﬁne attentionnet faster r-cnn attentionnet-reﬁne faster r-cnn r-cnn fast r-cnn faster r-cnn yolo mr-cnn s-cnn loc. negative decisions {×tl×br}. results base networks show similar tendency. size movement pixels method shows best accuracy base network. results beat faster r-cnn show zfnet vgg- margins respectively. however size pixels requires much less number movements pixels shows good performances size pixels initial detection experiments. regard method regression stacked classiﬁcations. therefore compare traditional detection-by-regression methods table lists performances. network estimates object mask sliding window shows performance. network directly produces coordinates class-agnostic object proposals shows performance. method beats approaches large margin yolo recent detection-by-regression method layered network estimates bounding-box grid cell convolutional feature map. listed table method shows much lower performance even trained superset composed trainval’+test’+trainval’. variant yolo operates multiple scale feature maps shows state-of-the-art performances dataset. performance slightly worse outperforms large margin also trained superset used yolo. r-cnn advanced variants fast rcnn faster r-cnn typical bottom-up approaches. compare top-down approach them. shown table performances original r-cnn signiﬁcantly worse general. method also beats fast faster r-cnns performance method similar fast rcnn lower faster r-cnn. top-down method demonstrated comparable performances compared state-of-the-art bottom-up method. bottom-up top-down approaches complementary other. bottom-up method feed-forward efﬁcient. also detection proposals advantageous recall. contrast top-down method recursive slower high-level action cascade advantageous scene-level context results less false positives. thus expect large performance improvement complementary approaches. rescale scores merge boxes scores shown second block table results gains +.%. results clearly demonstrate potential mixing top-down bottom-up methods. state ambiguous. shows much worse also shows methods successful top-down methods using reinforcement learning detection reinforcement method high variance gradient expected reward performances state-of-the-art methods. contrast top-down mechanism ﬁrst demonstrates competitive performances compared recent bottom-up methods. detection method another strength driven iterative action classiﬁcations. compared bottommethods localization accurate combines several weak actions estimate ﬁnal detection box. table summarizes performance comparisons different thresholds pascal method without reﬁnement step performance drop threshold increases typical strict conduct reﬁnement step observe smaller performance drop chance correct mis-localizations traditional bounding-box regression r-cnn does. performance drop methods much larger ours method signiﬁcantly beats threshold ﬁnally present localization performance measured top- error large-scale experiment ilsvrc cls-loc dataset. comparison result existing winning methods summarized table entries compared methods ilsvrc localization task. also using bottom-up approaches localization. winning method ﬁrst second places respectively. three methods localize object bounding-box regression dense sliding windows. compared methods method shows much lower error large margin recently challenge faster r-cnn based deep residual network composed layers. method shows small localization error lower ours. however performance mainly comes classiﬁcation performance since localization error including classiﬁcation error well. classiﬁcation error residual network already -times smaller classiﬁcation error also methods table ensemble multiple localization networks localization depends single multi-class attention model. conclusions paper proposed novel method object detection. adopted well-studied classiﬁcation technique object detection presented weak attention model high-level actions closer target object. since actively explorer exact boundingbox target object top-down approach suffer quality initial object proposals also take scene-level context consideration. study important observation top-down approach complementary previous state-of-the-art method using bottom-up approach therefore combining approaches boosts performance object detection. thus believe research top-down approaches combining bottom-up methods likely contribute next direction object detection. acknowledgments work supported technology innovation program funded korea government work also supported national research foundation korea funded korea government references krizhevsky sutskever hinton imagenet classiﬁcation deep convolutional neural networks advances neural information processing systems russakovsky deng krause satheesh huang karpathy khosla bernstein imagenet large scale visual recognition challenge international journal computer vision vol. viola jones rapid object detection using boosted cascade simple features computer vision pattern recognition cvpr proceedings ieee computer society conference vol. felzenszwalb girshick mcallester ramanan object detection discriminatively trained part-based models pattern analysis machine intelligence ieee transactions vol. sermanet eigen zhang mathieu fergus lecun overfeat integrated recognition localization detection using convolutional networks arxiv preprint arxiv. girshick donahue darrell malik rich feature hierarchies accurate object detection semantic segmentation proceedings ieee conference computer vision pattern recognition erhan szegedy toshev anguelov scalable object detection using deep neural networks proceedings ieee conference computer vision pattern recognition ouyang zeng tian yang wang xiong qian deepid-net multi-stage deformable deep convolutional neural networks object detection arxiv preprint arxiv. szegedy sermanet reed anguelov erhan vanhoucke rabinovich going deeper convolutions proceedings ieee conference computer vision pattern recognition gonzalez-garcia vezhnevets ferrari active search strategy efﬁcient object class detection ieee conference computer vision pattern recognition ieee park j.-y. paek kweon attentionnet aggregating weak directions accurate object detection proceedings ieee international conference computer vision m.-m. cheng zhang w.-y. torr bing binarized normed gradients objectness estimation proceedings ieee conference computer vision pattern recognition gregor danihelka graves rezende wierstra draw recurrent neural network image generation proceedings international conference machine learning xiao yang zhang peng zhang application two-level attention models deep convolutional neural network ﬁne-grained image classiﬁcation proceedings ieee conference computer vision pattern recognition yang wang wang huang wang huang look think twice capturing top-down visual attention feedback convolutional neural networks proceedings ieee international conference computer vision kiros courville salakhudinov zemel bengio show attend tell neural image caption generation visual attention proceedings international conference machine learning tompson jain lecun bregler joint training convolutional network graphical model human pose estimation advances neural information processing systems park j.-y. kweon multi-scale pyramid pooling deep convolutional representation proceedings ieee conference computer vision pattern recognition workshops gkioxari hariharan girshick malik using kposelets detecting people localizing keypoints proceedings ieee conference computer vision pattern recognition zhang sohn villegas improving object detection deep convolutional networks bayesian optimization structured prediction proceedings ieee conference computer vision pattern recognition kweon received degrees mechanical design production engineering seoul national university korea respectively degree robotics robotics institute carnegie mellon university pittsburgh toshiba center japan joined department automation design engineering kaist korea currently professor department electrical engineering. received best student paper runner-up award ieee conference computer vision pattern recognition research interests camera sensor fusion color modeling analysis visual tracking visual slam. program co-chair asian conference computer vision general chair accv also editorial board international journal computer vision. member ieee kros. donggeun received degree degree school electrical engineering kaist south korea. present student school department. research interests include representation learning learning large-scale data unsupervised learning visual recognition. student member ieee. sunggyun park received degree degree department industrial systems engineering kaist south korea. present student school department also co-founder research scientist lunit south korea. research interests include stochastic process product pricing machine learning problems related operations management computer vision. student member ieee. kyunghyun paeng received degree school electrical engineering kaist south korea. currently student school department also co-founder research scientist lunit south korea. research interests include computer vision visual recognition weakly supervised learning medical image analysis deep learning. joon-young received degree electrical electronic engineering yonsei university south korea degree degree respectively school electrical engineering kaist south korea. currently working adobe research jose research interests include photometric methods computer vision image enhancement computational photography deep learning video analysis. received samsung humantech paper award", "year": 2016}