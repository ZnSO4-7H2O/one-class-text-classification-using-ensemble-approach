{"title": "Clustering by Descending to the Nearest Neighbor in the Delaunay Graph  Space", "tag": ["stat.ML", "cs.CV", "cs.LG"], "abstract": "In our previous works, we proposed a physically-inspired rule to organize the data points into an in-tree (IT) structure, in which some undesired edges are allowed to occur. By removing those undesired or redundant edges, this IT structure is divided into several separate parts, each representing one cluster. In this work, we seek to prevent the undesired edges from arising at the source. Before using the physically-inspired rule, data points are at first organized into a proximity graph which restricts each point to select the optimal directed neighbor just among its neighbors. Consequently, separated in-trees or clusters automatically arise, without redundant edges requiring to be removed.", "text": "laboratory neuroinformation ministry education china school life science technology university electronic science technology china chengdu china *corresponding author. email liyjuestc.edu.cn bstract previous works proposed physically-inspired rule organize data points in-tree structure undesired edges allowed occur. removing undesired redundant edges structure divided several separate parts representing cluster. work seek prevent undesired edges arising source. using physically-inspired rule data points first organized proximity graph restricts point select optimal directed neighbor among neighbors. consequently separated in-trees clusters automatically arise without redundant edges requiring removed. introduction physically inspired in-tree structure propose physically inspired method organize data points structure shown fig. previous works demonstrated potentials fundamental problems unsupervised dimensionality terms clustering previously focused undesired redundant edges seek prevent undesired edges occurring source. motivation let’s reconsider example -dimensional space viewed horizontal rubber sheet. data points assumed mass rubber sheet curve which turn trigger movement data points places larger curvature eventually points converge several places locally lowest potentials. existence data points changes feature rubber sheet flat curved feature space even uneven consequently trigger movement data points. since data points still constrained space physically speaking cannot happen point locally lowest potential hops points lower potentials. physically inspired rule basically descending nearest neighbor happens ignore existence constraining role space consequently inconsistence physical circumstance arises therefore consider constraining role space approximate space proximity graph similarly restrict rule graph space then redundant edges avoided. method here show procedure implementing idea data points step construct delaunay graph. dataset ={xi constructed delaunay graph delaunay triangulation proximity graphs aims partition space triangular lattices shown fig. positive parameter measures distance certain distance metric then node optional directed node denoted selected among neighbor nodes denoted lower potentials index point selected node kndg null defined nearest node i.e. geometric notions curvature curved space geometry space general relativity bring convenience imagine circumstance space whereas bringing obstacle even cases. therefore ref. paper technically replace notion curvature commonly used physical notion potential make intuitive design physically inspired descending nearest neighbor rule. brings convenience construct uneven space also convenience comprehend generalization rule data points high‐dimensional euclidean space non‐euclidean space function delaunay matlab obtain scatter plots. parameter involved. practice consider case group close points especially overlapped ones potential we’ve done ref. indexes data points used endow order. step identify root. several nice properties point directed node usually called root node; node directed path reach root node. therefore root node viewed representative structure searching along directed edges root node non-root node identified cluster node belongs identified. experiments synthetic datasets tested previous works proposed method appropriate value parameter automatically obtain expected results cases least demonstrates feasibility proposed method automatic clustering strategy. however also failure cases also reveals automatic process reliable imagined without needs previous works human’s interaction additional needs labeled data post-processing dimensionality reduction. discussions conclusions approximate space? would like first discuss proximity graphs e.g. k-nearest-neighbor graph minimal spanning tree relative neighborhood graph inappropriate. k-nn brings additional parameter small initial graph under-approximate space whose constraining role exaggerated consequently small fake clusters occur; large initial graph over-approximate space whose constraining role weaken consequently undesired edge still arise. although share parameter-free feature sparse effect equivalent k-nn small comparison compromise proposal. high-dimensional euclidean space? let’s first consider features euclidean space. flat continuous. accordingly guidelines used construct equivalent graph basic lattices graph overlapped namely redundancy; lattices fill space namely remaining. also gives answer works space since guidelines similarly basic lattice approximated graph line segment space tetrahedron space etc. downloaded http//cs.joensuu.fi/sipu/datasets; http//people.sissa.it/~laio/research/res_clustering.php approximated graph space turns mst. simplex generalization triangle dimension. ‐simplex line segment; ‐simplex triangular; etc. details http//en.wikipedia.org/wiki/simplex give graphs unified name min-max spanning graph which corresponds refers gii. problems solutions method labeled data hard play role human users participate even dealing dataset since intermediate results shown serve reference make effective interactive decision. controllable thing free parameter however large result under-partitioning data points small lead over-partitioning data points. since intermediate information used evaluate ultimate result clustering evaluation indexes judge current value whereas relies reliable indexes are. what’s worse failures occur dataset fig. even good parameter. concrete number neighborhoods point still limited consequently points become artificial root nodes maybe modify smoothing distribution potentials gaussian kernel role limited. meanings paper provides automatic clustering strategy based physically inspired rule; could journey physically inspired structure field computational geometry; problems stated paragraph work pursuit one-time solution problem mimicking completely accordance physical circumstance turns advisable rule design. however conversely demonstrates effectiveness philosophy underlying design simple effective rule followed reliable repair mechanism quite similar process cell replication brings efficiency process reliability result. moreover design creates attractive intermediate product fig. whose attractiveness effective parts also imperfect parts whose salient features leave infinite space imagination repairing significant thing paper method itself negative example demonstrate efficiency beauty ref. efficiency happens mistake beauty happens redundancy. generalization triangulation delaunay d‐dimensional euclidean space meets http//en.wikipedia.org/wiki/triangulation_ rather elaborate error‐free process errors allowed occur repaired reliable mechanisms. efficiency mistake refers rule neglecting role space ref. beauty redundancy refers structure redundant edges ref. delaunay graph. result step colors points denote different potential values. result step colors points denote different clustering assignments different roots points belong. fig. tests several synthetic data sets. clustering results quite consistent visual perception. number clusters visual perception. clustering result totally wrong. yang physically inspired clustering algorithm evolve like particles. arxiv preprint arxiv.. effective semi-supervised divisive clustering algorithm. arxiv preprint arxiv.. generalized affinity propagation clustering algorithm nonspherical cluster discovery. arxiv preprint arxiv.. it-map effective nonlinear dimensionality reduction method interactive clustering. arxiv preprint arxiv.. barber dobkin huhdanpaa quickhull algorithm convex hulls. transactions mathematical software delaunay sphere vide. izv. akad. nauk sssr otdelenie matematicheskii estestvennyka nauk rodriguez laio clustering fast search find density peaks. science fränti virmajoki iterative shrinking method clustering problems. pattern recognit. medico flame novel fuzzy clustering method analysis microarray data. bioinf. zahn graph-theoretical methods detecting describing gestalt clusters. ieee trans. comput. chang yeung robust path-based spectral clustering. pattern recognit. toussaint relative neighbourhood graph finite planar set. pattern recognit.", "year": 2015}