{"title": "Constructive Preference Elicitation by Setwise Max-margin Learning", "tag": ["stat.ML", "cs.AI", "cs.LG", "68T05"], "abstract": "In this paper we propose an approach to preference elicitation that is suitable to large configuration spaces beyond the reach of existing state-of-the-art approaches. Our setwise max-margin method can be viewed as a generalization of max-margin learning to sets, and can produce a set of \"diverse\" items that can be used to ask informative queries to the user. Moreover, the approach can encourage sparsity in the parameter space, in order to favor the assessment of utility towards combinations of weights that concentrate on just few features. We present a mixed integer linear programming formulation and show how our approach compares favourably with Bayesian preference elicitation alternatives and easily scales to realistic datasets.", "text": "optimization problem; represented combinations basic elements subject constraints utility function learned feature representation instance customary many preference elicitation approaches. recommendation made solving constrained optimization problem space feasible instances guided learned utility. preference elicitation conﬁguration problems previously tackled regret-based elicitation minimax regret used robust recommendation criterion technique drive elicitation. main limitation approach lack tolerance respect user inconsistency. indeed learning user utility function requires deal uncertain possibly inconsistent user feedback. bayesian preference elicitation approaches deal problem building probability distribution candidate functions asking queries maximizing informativeness measures expected value information approaches however computationally expensive scale fully constructive scenarios shown experimental results. take space decomposition perspective jointly learn weight vectors representing candidate utility function maximizing diversity vectors consistency available feedback. conﬂicting objectives tend generate equally plausible alternative hypotheses unknown utility. approach elicitation works combining weight vector learning instance generation iteration algorithm produces outcomes weight vectors instances maximizing score according weight vectors. evaluate effectiveness approach testing elicitation method synthetic realworld problems comparing state-of-the-art methods. background ﬁrst introduce notation. boldface letters indicate vectors uppercase letters matrices calligraphic capital letters sets. abbreviate {xi}n {xi} whenever range index clear paper propose approach preference elicitation suitable large conﬁguration spaces beyond reach existing state-of-theart approaches. setwise max-margin method viewed generalization max-margin learning sets produce diverse items used informative queries user. moreover approach encourage sparsity parameter space order favor assessment utility towards combinations weights concentrate features. present mixed integer linear programming formulation show approach compares favourably bayesian preference elicitation alternatives easily scales realistic datasets. introduction preferences play important role variety artiﬁcial intelligence applications task eliciting learning preferences crucial one; typically limited information user’s preferences available cost obtaining additional preference information high. automated assessment preferences received considerable attention starting pioneering works community especially methodology giving rise wide variety extensions within number researchers proposed interactive methods elicit preferences adaptive observing that asking informative questions often possible make near-optimal decisions partial preference information. works assume items decisions available dataset paper propose adaptive elicitation framework takes constructive view preference elicitation enlarging scope selection items among candidates synthesis entirely novel instances. instances solutions given diverse. second want construct conﬁgurations conﬁguration best possible option evaluated according corresponding conﬁgurations maximally diverse among other. options later used formulate queries. ﬁrst goal achieved translating pairwise preferences ranking constraints preferences form become linear inequalities form margin variable ranges responses. non-separable datasets occur practice occasional inconsistencies user feedback handled introducing slack variables similar extensions augmented slacks inequalities take form penalty incurred weight vector viεi olating margin separation pair indifference prefer| ences i.e. slack increases difference estimated utility options. second goal requires jointly maximize utility according corresponding weight vector scoring difference respect conﬁgurations set. achieve maximizing i=wi adding ranking constraints illustrate piece piece. objective composed four parts maximize shared margin minimize total ranking errors incurred weight vector time regularizing magnitude weights quality conﬁgurations {xi} non-negative hyperparameters control inﬂuence various components. weight regularization term copes common scenario user strong preferences attributes indifferent them. penalty frequently used improve sparsity learned models consequent gains generalization ability efﬁciency conﬁrmed empirical ﬁndings constraint enforces correct ranking observed user preferences ensures generated conﬁgurations diverse terms weight vectors maximize. constraints ensure weights context shorthand |xz| indicate vector norm usual product matrix transposition. assume multi-attribute feature space conﬁgurations features. sake simplicity focus binary features only i.e. assuming one-hot encoding categorical features. common choice preference elicitation methods support linearly dependent continuous features discussed later assume feasible conﬁgurations denoted xfeasible expressed conjunction linear constraints. allows formulate arithmetic logical constraints e.g. canonical mapping alse boolean disjunction binary variables rewritten consistently experimental settings previous work model users additive utility functions user’s preferences represented weight vector utility conﬁguration wzxz. remainder paper require weights non-negative bounded per-attribute weights must interval learning actual weight vector unknown learning system must estimated interacting user. mostly focus pairwise comparison queries simplest comparative queries. extended choice sets options common conjoint analysis pairwise comparison conﬁgurations either preferred preferred clear preference items write denote preferences elicited user. setwise max-margin learning non-linear formulation. ﬁrst introduce problem formulation non-linear optimization problem show reduce mixed integer linear program. goal setwise max-margin approach twofold. first given size want weight vectors chosen userprovided preferences satisﬁed largest possible margin maximally fact achieved setting following additional constraints. distinguish cases recall maximizing margin optimizer keep large possible explicit upper bound wmax sufﬁciently large conmin{wmaxxi stant. hand evaluates upper bound wmaxxi hand upper bound reduces min{wmax taking sufﬁciently large constant wmax upper bound simpliﬁes maximized cases attain upper bound thus satisfy explicit lower bound wmax). procedure sketched algorithm note preference elicitation procedure ﬁnal recommendation made solving milp problem conﬁgurations feasible guarantees non-negativity slacks. since require also enforces weights non-negative. note choosing conﬁgurations {xi} weight vectors {wi} simultaneously. look utility loss choosing instead large look figure where simplicity need choose pair represented line partitions space feasible utility weights parts since maximize margin optimizer prefer conﬁgurations partitions weight space even way. subregion corresponding lying close centre. example user indicates preference feasible region become part polytope left line; moreover vector maximize margin classic sense feasible region. milp formulation. initial formulation problematic solve involves quadratic terms mixed continuous integer variables. however problem reformulated mixed integer linear program suitable transformation. technique rather common operational research e.g. goal replace linear constraints. order introduce fresh varievery assuming ables time variables satisfy equation rewrite fourth component objecpij tive function terms variables this bears similarity volumetric approaches important differences ﬁrst consider real items best separator second margin also expressed utility terms third query found optimization process. linearly dependent real attributes. many domains interest items composed boolean real-valued attributes latter depend linearly former. instance case price weight power consumption laptop depend linearly choice components. setting conﬁgurations composed parts boolean real-valued written appropriately sized non-negative cost matrix straightforward extend milp formulation setting. rewrite weight vector utility becomes generalized problem obtained substituting constraints remain same. notable change occurs becomes experiments algorithm usimplemented solving python core milp problem. setmargin source code full experimental setup available https//github.com/stefanoteso/setmargin. compare setmargin three state-of-the-art bayesian approaches bayesian approach selecting queries according restricted informed computationally efﬁcient heuristic approximation value-of-information inference using trueskillt bayesian framework using monte carlo methods bayesian inference asking choice queries selected using greedy optimization expected utility selection iii) query iteration also even faster query selection method based sampling sets utility vectors. probability user prefers conﬁguration deﬁned according classical bradley-terry model xj))− weight vector true underlying user utility. support indifference modelled exponential distribution closeness utilities i.e. expw xj|). parameters simulations experiments setmargin uses internal -fold cross-validation procedure update hyperparameters every iterations. hyperparameters chosen minimize ranking loss user responses collected far. taken taken synthetic dataset. following experimental protocol ﬁrst experiment evaluate behavior proposed method artiﬁcial setting increasingly complex problems. developed synthetic datasets attributes increasing values attribute takes possible values one-hot encoding attributes results features. terms space conﬁgurations synthetic dataset corresponds xfeasible xfeasible cardinality xfeasible grows exponentially dataset comparable size synthetic used larger size space grows much larger ones typically used bayesian preference elicitation literature represents good testbed comparing scalability various methods. feasible conﬁguration space encoded setmargin appropriate milp constraints methods require datasets explicitly grounded. users simulated drawing random utility vectors four different distributions. ﬁrst mimic used uniform distribution individual weight normal distribution mean standard deviation further produced novel sparse versions uniform normal distributions setting zero entries maximum budget iterations methods simplicity. figure report solution quality timing values increasing number collected user responses different competitors four different utility vector distributions datasets solution quality measured terms utility loss maxx∈xfeasible true unknown user utility solution recommended user elicitation phase computafigure comparison setmargin rivoi datasets. represents different sampling distribution user utility. number iterations plotted utility loss cumulative time thick lines indicate median values users standard deviations shown shaded areas. tional cost measured terms cumulative time. given rivoi single-threaded disabled multi-threading running algorithm comparisons. experiments intel xeon cores ram. algorithms iteration corresponds single pairwise query dense weight vector distributions approach achieves results indistinguishable competitors fraction time. indeed bayesian approaches become quickly impractical growing values algorithm easily scale much larger datasets shown later sparse weight vector distributions approach addition substantially faster iteration requires less queries order reach optimal solutions. expected result sparsiﬁcation norm formulation enforcing sparsity weights none approaches designed this. datasets uniform sparse normal distributions ﬁrst third columns report results terms number iterations. seen increasing number weight vectors tends favour earlier convergence especially complex dataset however iteration user asked compare items different values imply different cognitive effort user. second fourth columns report results terms comparing items. case seems best option. cognitive cost user likely extremes formalizing concept efﬁcient query ordering strategy needs face effect noise. modiﬁed sorting algorithm asking queries user resulted performance worsening likely cascading effect inconsistent feedback figure comparison setmargin orange blue green respectively datasets using uniform sparse normal distributions. median standard deviation utility loss values reported increasing number iterations pairwise queries sion dataset used instead explicitly enumerating possible items deﬁned feasible conﬁgurations milp constraints. conﬁguration deﬁned eight attributes computer type manufacturer model monitor size amount storage size price. price attribute deﬁned linear combination attributes fair modeling choice often price well approximated price components plus bias branding. interactions attributes expressed horn clauses dataset includes horn constraints note search space order hundreds thousands candidate conﬁgurations beyond reach existing bayesian approaches. figure reports results setmargin varying using sparse uniform distribution ﬁrst third column report utility loss increasing number iterations queries respectively showing behaviour similar figure overall queries average needed order solution worse optimal thousands available. note vendor ensure considerably smaller number queries cleverly constraining feasible conﬁguration space; since primary benchmarking chose pursue direction further. second fourth columns report cumulative times. note cases standard deviations bump; cases hyperparameters internal cross validation result ill-conditioned optimization problems hard solve. exceptions easily dealt setting appropriate timeout cross validation without affecting results hyperparameters typically performance discarded. conclusion presented max-margin approach efﬁcient preference elicitation large conﬁguration spaces. approach relies extension max-margin learning sets effective generation diverse conﬁgurations used informative preference queries. main advantages elicitation method ability provide recommendations large conﬁguration problems robustness respect erroneous feedback ability encourage sparse utility functions. experimental comparisons state-of-the-art bayesian preference elicitation strategies conﬁrm advantages. future work includes extending approach truly hybrid scenarios studying applicability problems identiﬁcation choquet models acknowledgments supported caritro foundation project supported idex sorbonne universit´es grant anr-idex--. thank craig boutilier motivating discussion topic. boutilier patrascu poupart schuurmans. constraint-based optimization utility elicitation using minimax decision criterion. artiﬁcal intelligence louviere hensher swait. stated choice methods analysis application. cambridge university press cambridge minka. expectation propagation approximate bayesian inference. proceedings uai’ pages tibshirani. regression shrinkage selection lasso. journal royal statistical society. series torra narukawa. modeling decisions information fusion aggregation operators. springer", "year": 2016}