{"title": "Compiling Relational Database Schemata into Probabilistic Graphical  Models", "tag": ["cs.AI", "cs.DB", "cs.LG", "stat.ML"], "abstract": "Instead of requiring a domain expert to specify the probabilistic dependencies of the data, in this work we present an approach that uses the relational DB schema to automatically construct a Bayesian graphical model for a database. This resulting model contains customized distributions for columns, latent variables that cluster the data, and factors that reflect and represent the foreign key links. Experiments demonstrate the accuracy of the model and the scalability of inference on synthetic and real-world data.", "text": "majority scientiﬁc commercial data stored relational databases. probabilistic models datasets would allow probabilistic queries error checking inference missing values machine learning expertise required construct accurate models. fortunately current probabilistic programming tools ease task constructing models work statistical relational learning focused making even easier deﬁne models speciﬁc relational data however within frameworks user still needs specify probabilistic dependencies data requiring level expertise probability statistics domain experts often have thus severely restricting practical applications techniques. hand domain experts spend considerable effort expertise designing database schemata used represent data providing type information table columns foreign relations specify dependencies. work view relational database schemata programs describe probabilistic dependencies exist data. goal simplify task model construction domain expert able construct probabilistic models automatically large number existing databases without manual intervention. using given schema customized fully-bayesian generative graphical model generated. table modeled mixture model along edges model dependencies table models according foreign relationships. underlying model similar relational latent variable models extends incorporating referential uncertainty using parametric approach real-world tractability. variational message passing inference learn parameters model allowing inference missing values probabilistic relational queries. experiments demonstrate accuracy scalability approach using synthetic real world data. section describe given database schema create bayesian graphical model perform inference minimal manual intervention. single table begin description model examining schema contains single table attributes employ mixture model table wherein mixture component used generate attributes latent variable indicates component row. distribution used generate attribute depends data type attribute; gaussian real-valued discrete categorical-valued bernoulli boolean-valued attributes distribution latent generated observed prior. component indicators generated latent discrete distribution observed prior. foreign component link consider table contains single foreign attribute another table data attributes tables respectively modeled described above. foreign attribute table represented figure user-movie-rating schema example schema consisting movie ratings users. attributes shown gray primary keys modeled. data attributes represented variables model foreign relations modeled using indexes table since want links rows reﬂect dependencies tables make component indicator dependent component indicator foreign links speciﬁcally instead using single distribution many discrete distributions number components table select corresponding distribution using gates πb]. also model uncertainty foreign keys discrete distributions allows prediction missing foreign links. idea easily generalized tables arbitrary number foreign keys using additional number discrete distributions database schema input database schema consists number tables attributes foreign relations form directed acyclic graph. building blocks iteratively construct model schema applying single-table model tables without foreign keys using foreign links deﬁne dependencies component indicators tables foreign keys. example consider simple schema consisting three tables shown figure figure shows generated model model user movie tables similar regular mixture model rating table consists additional variables edges foreign links dependencies component indicators across tables. model assumptions described number priors models need speciﬁed. hyper parameters uninformative however specifying number components table crucial. many components result slower inference components produce inaccurate models. non-parametric approaches much slower practice however recent work suggests exploiting conditional exchangeable properties data useful another assumption generated model attributes independently generated given component often hold practice. alternative explore range independent fully-correlated attributes using cross-cutting models inference inference resulting model performed using variational message passing implemented infer.net since model contains strong dependencies deterministic factors inference approaches gibbs sampling practical applied directly. training learn parameters model predict missing values database complexity message passing linear number rows approach also supports probabilistic queries trained model; queries take form small records missing entries. inference used predict marginal posterior belief distributions entries. inference querying also efﬁcient; linear size query foreign keys observed. figure results synthetic data comparison relational model single table model generated using join foreign keys using rmse three real-valued attributes. section present preliminary experiments evaluate accuracy clustering quality scalability schema-based probabilistic models. synthetic user-movies-ratings data typical approach modeling values relational database perform join tables single-table mixture model resulting table. unlike relational model dependencies across rows lost join operation. evaluate effect accuracy compare models treating proportion cells missing create synthetic data schema figure perform inference predict values missing cells. error predictions real-valued attributes shown figure demonstrating schema-based probabilistic model consistently accurate robust presence missing cells. particular rating scores accurate even half values missing. movielens dataset evaluate scalability movielens dataset. schema data similar user-movie-rating database includes attributes. data consists users movies ratings. since number rows leaf table usually much higher tables examine scalability terms size. ﬁxed number iterations inference vary number ratings examine running time. results shown figure show linear trend running time. further ﬁgure also shows increase running time number components table increased. trueskill dataset perform qualitative evaluation clustering rows produced model head-to-head games data xbox matches used herbrich data consists table player table match results consists foreign attributes players along boolean result attribute true ﬁrst player winner. model generated data assigns player three components shown figure also include average result pair clusters. note three clusters correspond excellent good players respectively demonstrating latent clustering used predict skills players without making domain-speciﬁc modeling assumptions. suggest automatically compiling probabilistic graphical models database schemata. approach allows make domain knowledge went design database schema potentially makes probabilistic graphical models directly available large fraction world’s data. inference compiled bayesian model allows prediction values missing cells database detect outliers visualize clustering data answer basic probabilistic relational queries. evaluated accuracy clustering quality scalability approach using combination synthetic real world data found schemabased graphical models lead interesting results. work much progress number avenues future directions. would like explore computationally efﬁcient extensions model non-parametric example models similar using ideas presented also want investigate utility inference techniques gibbs sampling variational bayes methods. work evaluation approach real-world datasets also interest. authors would like thank lucas bordeaux andy gordon minka john guiver valuable discussions insights. also grateful feedback anonymous reviewers nips workshop probabilistic programming. zhao volker tresp hans-peter kriegel. inﬁnite hidden relational models. annual conference uncertainty artiﬁcial intelligence pages arlington virginia auai press. charles kemp joshua tenenbaum thomas grifﬁths takeshi yamada naonori ueda. learning systems concepts inﬁnite relational model. american association artiﬁcial intelligence aaai’ pages aaai press isbn ---. james robert lloyd peter orbanz zoubin ghahramani daniel roy. random function priors exchangeable arrays applications graphs relational data. advances neural information processing systems patrick shafto charles kemp vikash mansinghka matthew gordon joshua tenenbaum. learning cross-cutting systems categories. annual conference cognitive science society", "year": 2012}