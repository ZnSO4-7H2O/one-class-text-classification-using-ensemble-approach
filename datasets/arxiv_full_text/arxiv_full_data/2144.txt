{"title": "LSTM-based Encoder-Decoder for Multi-sensor Anomaly Detection", "tag": ["cs.AI", "cs.LG", "stat.ML"], "abstract": "Mechanical devices such as engines, vehicles, aircrafts, etc., are typically instrumented with numerous sensors to capture the behavior and health of the machine. However, there are often external factors or variables which are not captured by sensors leading to time-series which are inherently unpredictable. For instance, manual controls and/or unmonitored environmental conditions or load may lead to inherently unpredictable time-series. Detecting anomalies in such scenarios becomes challenging using standard approaches based on mathematical models that rely on stationarity, or prediction models that utilize prediction errors to detect anomalies. We propose a Long Short Term Memory Networks based Encoder-Decoder scheme for Anomaly Detection (EncDec-AD) that learns to reconstruct 'normal' time-series behavior, and thereafter uses reconstruction error to detect anomalies. We experiment with three publicly available quasi predictable time-series datasets: power demand, space shuttle, and ECG, and two real-world engine datasets with both predictive and unpredictable behavior. We show that EncDec-AD is robust and can detect anomalies from predictable, unpredictable, periodic, aperiodic, and quasi-periodic time-series. Further, we show that EncDec-AD is able to detect anomalies from short time-series (length as small as 30) as well as long time-series (length as large as 500).", "text": "pankaj malhotra anusha ramakrishnan gaurangi anand lovekesh puneet agarwal gautam shroff {malhotra.pankaj tam.shroff}tcs.com research delhi india example laden machine behaves differently unladen machine. further relevant information pertaining whether machine laden unladen available. amount load machine time unknown change frequently/abruptly example earth digger. machine multiple manual controls captured sensor data. settings becomes difﬁcult predict time-series even near future rendering ineffective prediction-based time-series anomaly detection models ones based exponentially weighted moving average long short-term memory networks lstm networks recurrent models used many sequence learning tasks like handwriting recognition speech recognition sentiment analysis. lstm encoder-decoder models recently proposed sequence-tosequence learning tasks like machine translation lstm-based encoder used input sequence vector representation ﬁxed dimensionality. decoder another lstm network uses vector representation produce target sequence. variants proposed natural language generation reconstruction parsing image captioning propose lstm-based encoder-decoder scheme anomaly detection multi-sensor time-series encoder learns vector representation input time-series decoder uses representation reconstruct time-series. lstm-based encoderdecoder trained reconstruct instances ‘normal’ timemechanical devices engines vehicles aircrafts etc. typically instrumented numerous sensors capture behavior health machine. however often external factors variables captured sensors leading time-series inherently unpredictable. instance manual controls and/or unmonitored environmental conditions load lead inherently unpredictable time-series. detecting anomalies scenarios becomes challenging using standard approaches based mathematical models rely stationarity prediction models utilize prediction errors detect anomalies. propose long short term memory networks based encoder-decoder scheme anomaly detection learns reconstruct ‘normal’ time-series behavior thereuses reconstruction error detect anomalies. experiment three publicly available quasi predictable time-series datasets power demand space shuttle realworld engine datasets predictive unpredictable behavior. show encdecad robust detect anomalies predictable unpredictable periodic aperiodic quasi-periodic time-series. further show encdec-ad able detect anomalies short time-series well long time-series series target time-series input time-series itself. then reconstruction error future timeinstance used compute likelihood anomaly point. show encoder-decoder model learnt using normal sequences used detecting anomalies multi-sensor time-series intuition encoder-decoder pair would seen normal instances training learnt reconstruct them. given anomalous sequence able reconstruct well hence would lead higher reconstruction errors compared reconstruction errors normal sequences. encdec-ad uses normal sequences training. particularly useful scenarios anomalous data available sparse making difﬁcult learn classiﬁcation model normal anomalous sequences. especially true machines undergo periodic maintainance therefore serviced anomalies show sensor readings. encdec-ad consider time-series length point m-dimensional vector readings variables time-instance consider scenario multiple time-series available obtained taking window length larger time-series. ﬁrst train lstm encoderdecoder model reconstruct normal time-series. reconstruction errors used obtain likelihood point test time-series anomalous s.t. point anomaly score point anomalous obtained. higher anomaly score indicates higher likelihood point anomalous. train lstm encoder-decoder reconstruct instances normal time-series. lstm encoder learns ﬁxed length vector representation input time-series lstm decoder uses representation reconstruct time-series using current hidden state value predicted previous time-step. given hidden state encoder time number lstm units hidden layer encoder. encoder decoder jointly trained reconstruct timeseries reverse order i.e. target time-series ﬁnal state encoder used initial state decoder. linear layer lstm decoder layer used predict target. training decoder uses input obtain state figure depicts inference steps lstm encoderdecoder reconstruction model sequence value time instance hidden state encoder time used obtain hidden state encoder time hidden state encoder input sequence used initial state linear layer weight matrix size bias vector decoder used compute decoder uses prediction obtain next hidden state similar divide normal time-series four sets time-series anomalous time-series sets sequences used learn lstm encoder-decoder reconstruction model. used early stopping training encoder-decoder model. reconstruction error vector given error vectors points sequences used estimate parameters normal distribution using maximum likelihood estimation. then point anomaly score supervised setting point sequence predicted anomalous otherwise normal. enough anomalous sequences available threshold likelihood values learnt maximize precision recall anomalous positive class normal negative class. window contains anomalous pattern entire window labeled anomalous. helpful many real-world applications exact position anomaly known. example engine dataset information available machine repaired particular date. last operational runs prior repair assumed anomalous ﬁrst operational runs repair assumed normal. assume since fraction actual anomalous points sequence labeled anomalous high hence lower recall expected. parameters chosen maximum score validation sequences consider four real-world datasets power demand space shuttle valve engine ﬁrst three taken whereas engine dataset proprietary encountered real-life project. engine dataset contains data different applications engine-p time-series quasi-predictable engine-np time-series unpredictable reasons mentioned earlier. experiments consider architectures encoder decoder single hidden layer lstm units each. mini-batch stochastic optimization based adam optimizer used training lstm encoder-decoder. table shows performance encdec-ad datasets. power demand dataset contains univariate time-series readings power demand recorded period year. demand normally high weekdays weekend. within demand high working hours otherwise top-most subplot). week ﬁrst days power demands considered anomalous anomalous sequences corresponding reconstructed sequences anomaly scores regions original time-series anomalous sequences correspond exact location anomaly sequence plots y-axis scale. anomaly scores log-scale. figure ﬁrst power demand). downsample original time-series obtain nonoverlapping sequences window corresponds week. space shuttle dataset contains periodic sequences points cycle cycles. delibrately choose subsequence covers cycle consider sliding windows step size downsample original time-series normal anomalous sequences figure belong time-series respectively. engine dataset contains readings sensors coolant temperature torque accelerator etc. consider differents applications engine engine-p engine-np. engine-p discrete external control states ‘high’ ‘low’. resulting time-series predictable except time-instances control variable changes. hand external control engine-np assume value within certain range changes frequently hence resulting time-series unpredictable. sample sequences control variables engine-p engine-np shown figure respectively. randomly choose engine-p engine-np. reduce multivariate time-series univariate considering ﬁrst principal component applying principal component analysis ﬁrst component captures variance engine-p engine-np. dataset contains quasi-periodic time-series experiment ﬁrst channel qtdb/sel dataset time-series contains anomaly corresponding pre-ventricular contraction consider non-overlapping subsequences since anomaly present dataset sets created. best model i.e. chosen based minimum reconstruction error choose mean standard deviation anomaly scores points observations experiments follows positive likelihood ratio signiﬁcantly higher datasets high positive likelihood ratio values suggest encdec-ad gives signiﬁcantly higher anomaly scores anomalous points compared normal points. periodic time-series experiment varying window lengths window length length cycle window length greater length cycle also consider quasi-periodic time-series encdecad able detect anomalies scenarios. time-series prediction based anomaly detection model lstm-ad gives better results predictable datasets space shuttle power enginep scores respectively. hand encdec-ad gives better results engine-np sequences predictable. best lstm-ad model gives tpr/fpr respectively owing fact time-series predictable hence good prediction model could learnt whereas encdec-ad gives score tpr/fpr respectively. time-series prediction models shown effective anomaly detection using prediction error function prediction error measure severity anomaly recently deep lstms used prediction models lstm-ad prediction model learnt normal time-series using lstm networks used predict future points likelihood prediction error used measure anomaly. encdecad learns representation entire sequence used reconstruct sequence therefore different prediction based anomaly detection models. non-temporal reconstruction models denoising autoencoders anomaly detection deep belief nets proposed. time-series data lstm based encoder-decoder natural extension models. show lstm encoder-decoder based reconstruction model learnt normal time-series viable approach detect anomalies time-series. approach works well detecting anomalies predictable well unpredictable time-series. whereas many existing models anomaly detection rely fact timeseries predictable encdec-ad shown detect anomalies even unpredictable time-series hence robust compared models. fact encdec-ad able detect anomalies time-series length large suggests lstm encoderdecoders learning robust model normal behavior. malhotra pankaj lovekesh shroff gautam agarwal puneet. long short term memory networks anomaly detection time series. esann european symposium artiﬁcial neural networks computational intelligence machine learning sakurada mayu yairi takehisa. anomaly detection using autoencoders nonlinear dimensionality reducproceedings mlsda worktion. shop machine learning sensory data analysis mlsda’ york acm. sutskever ilya vinyals oriol quoc sequence sequence learning neural networks. ghahramani welling cortes lawrence weinberger advances neural information processing systems curran associates inc. vinyals oriol kaiser łukasz terry petrov slav sutskever ilya hinton geoffrey. grammar advances neural information foreign language. processing systems wulsin drausin blanco justin mani litt brian. semi-supervised anomaly detection waveforms using deep belief nets. machine learning applications ninth international conference ieee yadav mohit malhotra pankaj lovekesh sriram shroff gautam. ode-augmented training improves anomaly detection sensor data machines. nips time series workshop http //arxiv.org/abs/.. nong markov chain model temporal behavior anomaly detection. proceedings ieee systems cybernetics information assurance security workshop volume west point bengio samy vinyals oriol jaitly navdeep shazeer noam. scheduled sampling sequence prediction recurrent neural networks. advances neural information processing systems chauhan sucheta lovekesh. anomaly detection time signals deep long short-term memory networks. data science advanced analytics ieee international conference ieee kyunghyun merri¨enboer bart gulcehre caglar bahdanau dzmitry bougares fethi schwenk holger bengio yoshua. learning phrase representations using encoder-decoder statistical machine translation. arxiv preprint arxiv. hayton paul utete simukai king dennis king steve anuzis paul tarassenko lionel. static dynamic novelty detection methods engine health monitoring. philosophical transactions royal society london mathematical physical engineering sciences junshui perkins simon. online novelty detection temporal sequences. proceedings ninth sigkdd international conference knowledge discovery data mining", "year": 2016}