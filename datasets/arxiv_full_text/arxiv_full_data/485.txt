{"title": "Feudal Reinforcement Learning for Dialogue Management in Large Domains", "tag": ["cs.CL", "cs.AI", "cs.NE"], "abstract": "Reinforcement learning (RL) is a promising approach to solve dialogue policy optimisation. Traditional RL algorithms, however, fail to scale to large domains due to the curse of dimensionality. We propose a novel Dialogue Management architecture, based on Feudal RL, which decomposes the decision into two steps; a first step where a master policy selects a subset of primitive actions, and a second step where a primitive action is chosen from the selected subset. The structural information included in the domain ontology is used to abstract the dialogue state space, taking the decisions at each step using different parts of the abstracted state. This, combined with an information sharing mechanism between slots, increases the scalability to large domains. We show that an implementation of this approach, based on Deep-Q Networks, significantly outperforms previous state of the art in several dialogue domains and environments, without the need of any additional reward signal.", "text": "reinforcement learning promising approach solve dialogue policy optimisation. traditional algorithms however fail scale large domains curse dimensionality. propose novel dialogue management architecture based feudal decomposes decision steps; ﬁrst step master policy selects subset primitive actions second step primitive action chosen selected subset. structural information included domain ontology used abstract dialogue state space taking decisions step using different parts abstracted state. this combined information sharing mechanism between slots increases scalability large domains. show implementation approach based deep-q networks signiﬁcantly outperforms previous state several dialogue domains environments without need additional reward signal. task-oriented spoken dialogue systems form personal assistants recently gained much attention academia industry. important modules dialogue manager module charge deciding next action dialogue turn. reinforcement learning studied several years promising approach model dialogue management however dialogue state space increases number possible trajectories needed explored grows exponentially making traditional methods scalable large domains. hierarchical form temporal abstraction proposed order mitigate problem however proposed methods require task deﬁned hierarchical structure usually handcrafted. addition usually require additional rewards subtask. space abstraction instead successfully applied dialogue tasks dialogue state tracking policy transfer domains binary classiﬁers deﬁned slot shared parameters learning general track slots. policy transfer method presented named domain independent parametrisation transforms belief state slot-dependent ﬁxed size representation using handcrafted feature function. idea could also applied large domains since used learn general slot. slot-ﬁlling dialogues method relies space abstraction feudal allow scale domains large number slots. divides task spatially rather temporally decomposing decisions several steps using different abstraction levels sub-decision. framework especially useful tasks large discrete action spaces making attractive large domain dialogue management. paper introduce feudal dialogue policy decomposes decision turn steps. ﬁrst step policy decides takes slot independent slot dependent action. then state slot sub-policy abstracted account features related slot primitive action chosen previously selected subset. model require dialogue management cast continuous composed continuous multivariate belief state space ﬁnite actions reward function given time agent observes belief state executes action receives reward drawn action taken decided policy deﬁned function policy q-value function deﬁned expected return starting state taking action following policy until dialogue time step e{r|bt objective optimal policy i.e. policy maximizes expected return belief state. value-based algorithms optimal policy found greedily taking action maximises slot-ﬁlling sdss belief state space deﬁned ontology structured representation database entities user retrieve talking system. entity properties refereed slots slots take value belief state deﬁned concatenation probability distribution slot plus general features deﬁned summary actions actions either slot dependent conﬁrm...) slot independent inform...). belief space deﬁned ontology therefore belief states different domains different shapes. order transfer knowledge domains domain independent parametrization proposes abstract belief state ﬁxed figure feudal dialogue architecture used work. sub-policies surrounded dashed line shared parameters. simple lines show data double lines sub-policy decisions. size representation. action either slot independent dependent slot feature function φdip deﬁned s∪si stands slot independent actions. therefore order compute policy approximated slot associated action wang presents handcrafted feature function φdip. includes slot independent features belief state summarised representation joint belief state summarised representation belief state slot section gives detailed description φdip function used work. decomposes policy decision turn several sub-decisions using different abstracted parts belief state subdecision. objective task oriented fulﬁll users goal goal observable needs gather enough information correctly fulﬁll therefore turn decompose decision steps ﬁrst decide taking action order gather information user goal taking action fulﬁll user goal part second select action execute previously selected subset. slot-ﬁlling dialogue information gathering actions deﬁned slot dependent actions information providing actions deﬁned architecture feudal policy proposed work represented schematically figure actions divided subsets; slot independent actions inform); slot dependent actions conﬁrm). addition master actions deﬁned corresponds taking action taking action then feature function deﬁned slot well slot independent feature function master feature function feature functions handcrafted function approximator used finally master policy slot independent policy slot speciﬁc policies deﬁned contrary feudal policies slot speciﬁc sub-policies shared parameters order generalise slots dst). differences slots accounted feature function therefore deﬁned models used experiments implemented using pydial toolkit evaluated pydial benchmarking environment environment presents tasks span different size domains different semantic error rates different conﬁgurations action masks user model parameters unfriendly table shows summarised description tasks. models developed paper compared state-ofthe-art algorithms handcrafted policy presented benchmarks. dip-dqn baseline implementation based deep-q networks implemented additional baseline policy named dip-dqn uses hyperparameters implementation released pydial benchmarks. feature function based description used φdip where accounts general features belief state database search method. accounts features joint belief state entropy joint belief. accounts features marginal distribution slot entropy appendix shows detailed description features used work. performance increase considerable largest domains gains points accumulated reward challenging environments compared best benchmarked policies addition fdqn consistently outperforms handcrafted policy environments traditional methods could achieve. env. however results fdqn dip-dqn rather specially dip-dqn. surprisingly results env. differs env. absence action masks outperform every algorithm. analysing dialogues individually could observe that environment policies prone overﬁt action performance fdqn dip-dqn env. also better env. difference environments also lies masks. suggests speciﬁc action mask design helpful algorithms harm performance others. especially severe dip-dqn case shows good performance challenging environments unstable prone overﬁt fdqn. however main purpose action masks reduce number dialogues needed train policy. observing learning curves shown figure fdqn model learn nearoptimal policy large domains dialogues even additional reward used making action masks unnecessary. original summary actions benchmarking environment size number slots. divided subsets size size sub-policy trained sparse reward signal used baselines getting reward dialogue successful otherwise minus dialogue length. results tasks benchmarking environment training dialogues presented table evaluation procedure benchmarks used presenting mean different random seeds testing every seed dialogues. fdqn policy substantially outperforms every policy environments except env. presented novel dialogue management architecture based feudal substantially outperforms previous state several dialogue environments. deﬁning slot dependent policies shared parameters model able learn general slots increasing scalability large domains. unlike methods applied dialogue additional reward signals needed hierarchical structure derived ontology substantially reducing design effort. promising approach would substitute handcrafted feature functions used work neural feature extractors trained jointly policy. would avoid need design feature functions could potentially extended modules making textto-action learning tractable. addition single model potentially used different domains different feudal architectures could make larger action spaces tractable references paweł budzianowski stefan ultes pei-hao nikola mrkˇsi´c tsung-hsien inigo casanueva lina rojas barahona milica gaˇsi´c. subdomain modelling dialogue management hierarchical reinforcement learning. proc sigdial. i˜nigo casanueva paweł budzianowski pei-hao nikola mrkˇsi´c tsung-hsien stefan ultes lina rojas-barahona steve young milica gaˇsi´c. benchmarking environment reinforcement learning based task oriented dialogue management. arxiv preprint arxiv. inigo casanueva thomas hain heidi christensen ricard marxer phil green. knowledge transfer speakers personalised dialogue proceedings annual management. meeting special interest group discourse dialogue. pages milica gaˇsi´c catherine breslin matthew henderson dongho martin szummer blaise thomson pirros tsiakoulis steve young. pomdpbased dialogue manager adaptation extended domains. proceedings sigdial conference. milica gaˇsi´c nikola mrkˇsi´c pei-hao david vandyke tsung-hsien steve young. policy committee adaptation multiautomatic domain spoken dialogue systems. speech recognition understanding ieee workshop ieee pages esther levin roberto pieraccini wieland eckert. using markov decision process learning dialogue strategies. acoustics speech signal processing proceedings ieee international conference ieee volume pages volodymyr mnih koray kavukcuoglu david silver alex graves ioannis antonoglou daan wierstra martin riedmiller. playing atari deep reinforcement learning. arxiv preprint arxiv. alexandros papangelis yannis stylianou. single-model multi-domain dialogue management deep learning. international workshop spoken dialogue systems. olivier pietquin matthieu geist senthilkumar chandramohan herv´e frezza-buet. sampleefﬁcient batch reinforcement learning dialogue management optimization. transactions speech language processing section gives detailed description feature functions φdip used work. differences features used following priority importance features used. potential contribution search featable list features composing features. denotes binary encoding used feature. joint features extracted joint belief computed cartesian product beliefs individual slots. denotes features exist original belief state pei-hao pawel budzianowski stefan ultes milica gasic steve young. sample-efﬁcient actor-critic reinforcement learning supervised data dialogue management. proceedings sigdial pei-hao milica gasic nikola mrksic lina rojasbarahona stefan ultes david vandyke tsunghsien steve young. continuously learning neural dialogue management. arxiv preprint arxiv. stefan ultes lina rojas-barahona pei-hao david vandyke dongho i˜nigo casanueva paweł budzianowski nikola mrkˇsi´c tsung-hsien milica gaˇsi´c steve young. pydial multi-domain statistical dialogue system demo. association computatoolkit. tional linguistics. zhuoran wang tsung-hsien pei-hao learning domainyannis stylianou. independent dialogue policies ontology parameterisation. sigdial conference. pages", "year": 2018}