{"title": "Fidelity-Weighted Learning", "tag": ["cs.LG", "cs.CL", "cs.NE"], "abstract": "Training deep neural networks requires many training samples, but in practice training labels are expensive to obtain and may be of varying quality, as some may be from trusted expert labelers while others might be from heuristics or other sources of weak supervision such as crowd-sourcing. This creates a fundamental quality versus-quantity trade-off in the learning process. Do we learn from the small amount of high-quality data or the potentially large amount of weakly-labeled data? We argue that if the learner could somehow know and take the label-quality into account when learning the data representation, we could get the best of both worlds. To this end, we propose \"fidelity-weighted learning\" (FWL), a semi-supervised student-teacher approach for training deep neural networks using weakly-labeled data. FWL modulates the parameter updates to a student network (trained on the task we care about) on a per-sample basis according to the posterior confidence of its label-quality estimated by a teacher (who has access to the high-quality labels). Both student and teacher are learned from the data. We evaluate FWL on two tasks in information retrieval and natural language processing where we outperform state-of-the-art alternative semi-supervised methods, indicating that our approach makes better use of strong and weak labels, and leads to better task-dependent data representations.", "text": "training deep neural networks requires many training samples practice training labels expensive obtain varying quality trusted expert labelers others might heuristics sources weak supervision crowd-sourcing. creates fundamental qualityversus-quantity trade-off learning process. learn small amount high-quality data potentially large amount weakly-labeled data? argue learner could somehow know take label-quality account learning data representation could best worlds. propose ﬁdelity-weighted learning semi-supervised studentteacher approach training deep neural networks using weakly-labeled data. modulates parameter updates student network per-sample basis according posterior conﬁdence label-quality estimated teacher student teacher learned data. evaluate tasks information retrieval natural language processing outperform state-of-the-art alternative semi-supervised methods indicating approach makes better strong weak labels leads better task-dependent data representations. success deep neural networks date depends strongly availability labeled data costly always easy obtain. usually much easier obtain small quantities high-quality labeled data large quantities unlabeled data. problem best integrate different sources information training active pursuit ﬁeld semi-supervised learning however large class tasks also easy deﬁne so-called weak annotators additional sources weak supervision based heuristics weaker biased classiﬁers trained e.g. non-expert crowd-sourced data data different domains related. easy cheap generate immediately clear additional weakly-labeled data used train stronger classiﬁer task care about. generally almost practical applications machine learning systems deal data samples variable quality. example large dataset images small fraction samples labeled experts rest crowd-sourced using e.g. amazon mechanical turk addition applications labels intentionally perturbed privacy issues assuming obtain large weakly-labeled data addition much smaller training strong labels simplest approach expand training including weakly-supervised samples alternatively pretrain weak data ﬁne-tune observations true function distribution indeed recently shown small amount expert-labeled data augmented large data labels coming heuristic function train accurate neural ranking model downside approaches oblivious amount source noise labels. figure illustration fidelity-weighted learning step pre-train student weak data step teacher observations true function step fine-tune student labels generated teacher taking conﬁdence account. dotted borders blue solid borders depict components trainable non-trainable parameters respectively. paper argue treating weakly-labeled samples uniformly ignores potentially valuable information label quality. instead propose fidelity-weighted learning bayesian semi-supervised approach leverages small amount data true labels generate larger training conﬁdence-weighted weakly-labeled samples used modulate ﬁne-tuning process based ﬁdelity weak sample. directly modeling inaccuracies introduced weak annotator control extent make additional source weak supervision conﬁdently-labeled weak samples close true observed data less uncertain samples away observed data. propose setting consisting main modules. called student charge learning suitable data representation performing main prediction task teacher modulates learning process modeling inaccuracies labels. explain approach much detail section high level works follows pretrain student network weak data learn initial task-dependent data representation pass teacher along strong data. teacher learns predict strong data crucially based student’s learned representation. allows teacher generate labeled training data unlabeled data process correct student’s mistakes leading better ﬁnal data representation better ﬁnal predictor. introduce proposed approach detail section present experimental setup section evaluate task real-world tasks namely document ranking sentence sentiment classiﬁcation. cases outperforms competitive baselines yields state-of-the-art results indicating makes better limited true labeled data thereby able learn better meaningful task-speciﬁc representation data. section provides analysis bias-variance trade-off learning rate suggesting also view perspective vapnik’s learning privileged information framework section situates relative related work paper drawing main conclusions section section describe proposed approach semi-supervised learning access weak supervision assume given large unlabeled data samples heuristic labeling function called weak annotator small highquality samples labeled experts called strong dataset consisting tuples training samples true labels i.e. ={}. consider latter observations true target function trying learn. weak annotator generate labels unlabeled samples. generated labels noisy limited accuracy weak annotator. gives weak dataset consisting tuples training samples weak labels i.e. ={}. note generate large amount weak training datadw almost cost using weak annotator. contrast limited amount observations true function i.e. |ds||dw|. train student samples weakly-annotated data freeze representation-learning component student train teacher strong data yj). apply teacher unlabeled samples obtain soft dataset soft label instance uncertainty label provided teacher. proposed setup comprises neural network called student bayesian function approximator called teacher. training process consists three phases summarize algorithm figure step pre-train student using weak labels generated weak annotator. goal stage learn reasonably good representation data given task. student function neural network consisting parts. ﬁrst part learns data representation second part performs prediction task therefore overall function student trained samples weak dataset ={}. brevity following refer data sample representation obvious context. step train teacher strong data represented terms student representation teacher generate soft dataset consisting sample predicted label conﬁdence pairs data samples. gaussian process teacher capture label uncertainty terms student representation estimated w.r.t strong data. explain ﬁner details appendix present overall description here. prior mean co-variance function chosen learned embedding function step used data samples dense vectors input trained representation strong dataset learn posterior mean mpost posterior co-variance kpost create soft dataset using posterior input samples dw∪ds predicted labels associated uncertainties computed generated labels called soft labels. therefore refer soft dataset. transforms output suitable output space. example classiﬁcation tasks would softmax function produce probabilities one. multidimensional-output tasks vector variances provided vector kpost passed aggregating function generate scalar value uncertainty sample. note train strong dataset generate soft labels uncertainty samples belonging =dw∪ds. practice furthermore divide space data several regions assign region separate trained samples region. division space take advantage knowledge learned several teachers expert speciﬁc region data space. nice side-effect also solves scalability issues increase number regions number points region tractable single train models parallel. algorithm appendix detailed description. step fine-tune weights student network soft dataset modulating magnitude parameter update corresponding teacher-conﬁdence label. student network step ﬁne-tuned using samples soft dataset corresponding uncertainty sample mapped conﬁdence value according equation below used determine step size iteration stochastic gradient descent intuitively data points true labels uncertainty teacher almost zero means high conﬁdence large step-size updating parameters. however data points teacher conﬁdent down-weight per-example loss total learning rate size soft dataset parameters student network regularization term. deﬁne total learning rate usual learning rate chosen optimization algorithm anneals training iterations function label uncertainty computed teacher data point. multiplying terms gives total learning rate. words represents ﬁdelity current sample used multiplicatively modulate note ﬁrst term necessarily depend data point whereas second term does. propose exponentially decrease learning rate data point corresponding soft label unreliable equation positive scalar hyper-parameter. intuitively small results student listens carefully teacher copies knowledge large makes student less attention teacher staying initial weak knowledge. concretely speaking student places trust labels estimated teacher student copies knowledge teacher. hand student puts less weight extrapolation ability parameters student affected correcting information teacher. section apply ﬁrst problem different real tasks document ranking sentiment classiﬁcation. neural networks implemented tensorflow gpﬂow employed developing modules. tasks evaluate performance method compared following baselines weak annotator i.e. unsupervised method used annotating unlabeled data. nnw. student trained weak data. nns. student trained strong data. nns+/w. student trained samples alternately drawn without replacement nnw→s. student trained weak dataset ﬁne-tuned strong dataset nnwω→s. student trained weak data step-size weak sample weighted ﬁxed value ﬁne-tuned strong data. approximation optimal value used mean model student trained weakly labeled data ﬁne-tuned examples labeled problem ﬁrst apply one-dimensional problem illustrate various steps. true function small observations ={xjyj} provided observation might noisy labels obtained human labeler could noisy. weak annotator function sinc provided approximation task obtain good estimate given strong observations weak annotator function easily obtain large observations ={xi˜yi} almost cost consider experiments seen figure taking account label conﬁdence gives better approximation true hidden function. repeated experiment times. average rmse respect true function test points experiments student follows student trained weak data student trained weak data tuned true observations student trained weak data tuned soft labels conﬁdence information provided document ranking task core information retrieval problem challenging ranking model needs learn representation long documents capture notion relevance queries documents. furthermore size publicly available datasets query-document relevance judgments unfortunately quite small employ state-of-the-art pairwise neural ranker architecture student model ranking cast regression task. given training sample triple query documents goal learn function qd+d− >}→r maps data sample scalar output value indicating probability ranked higher respect student follows architecture proposed ﬁrst layer network i.e. representation learning layer qd+d− maps input sample mdimensional real-valued vector. general besides learning embeddings words function learns compose word embedding based global importance order generate query/document table performance approach baseline methods ranking task. indicates improvements respect baseline statistically signiﬁcant level using paired two-tailed t-test bonferroni correction. embeddings. representation layer followed simple fully-connected feed-forward network sigmoidal output unit predict probability ranking higher general schema student illustrated figure details provided appendix teacher implemented clustered algorithm. appendix details. weak annotator well-known unsupervised method scoring query-document pairs based statistics matched terms. details provided appendix description data weak labels data true labels well setup documentranking experiments presented appendix details. results discussions conducted k-fold cross validation report standard evaluation metrics ranking mean average precision top-ranked documents normalized discounted cumulative gain calculated retrieved documents table shows performance datasets. seen provides signiﬁcant boost performance datasets. ranking task student designed particular trained weak annotations hence training network weak supervision i.e. performs better nns. fact ranking complex task requiring many training samples relatively data true labels available. alternating strong weak data training i.e. nns+/w seems bring little improvement. however gain better results typical ﬁne-tuning strategy nnw→s. gain improvement ﬁne-tuning using labels generated teacher without considering conﬁdence score i.e. fwl\\σ. means augmented ﬁne-tuning process generating ﬁne-tuning using teacher better terms quantity terms quality. baseline equivalent setting equation however jump performance include estimated label quality teacher leading best overall results. sentiment classiﬁcation goal predict sentiment sentence. training sample consists sentence sentiment label student sentiment classiﬁcation task convolutional model shown perform best dataset used ﬁrst layer network learns function maps input sentence dense vector representation. inputs ﬁrst passed embedding layer mapping sentence matrix s∈rm×|s| followed series convolutional layers max-pooling. representation layer followed feed-forward layers softmax output layer returns probability distribution three classes. figure presents general schema architecture student. appendix details. teacher task modeled appendix details. weak annotator simple unsupervised lexicon-based method estimate distribution sentiments sentence based sentiment labels terms. details provided appendix table performance proposed approach baseline methods sentiment classiﬁcation task. indicates improvements respect baselinei statistically signiﬁcant level using paired two-tailed t-test bonferroni correction. speciﬁcation data weak labels data true labels along detailed experimental setup given appendix results discussion report macro-f ofﬁcial semeval metric table proposed best performing approach. task since amount data true labels larger compared ranking task performance acceptable. alternately sampling weak strong data gives better results. pretraining weak labels ﬁne-tuning network true labels improves performance. weighting gradient updates weak labels pretraining ﬁne-tuning network true labels i.e. nnwω→s seems work quite well task. similar ranking task ﬁne-tuning based labels generated instead data true labels regardless conﬁdence score works better standard ﬁne-tuning. besides baselines also report best performing systems also convolution-based models using taking conﬁdence consideration outperforms best systems leads highest reported results datasets. mentioned section hyperparameter controls contribution weak strong data training procedure. order investigate inﬂuence ﬁxed everything model ﬁne-tuning stage different values ∈{.....} experiments. figure illustrates performance ranking sentiment classiﬁcation tasks sentiment classiﬁcation ranking gives best results also experimented problem different values three cases observations true function marked data plot observations true function marked data plot weak function extremely approximator true function marked data plot. data experiment turned optimal however data extremely small number observations true function setting higher value acts regularizer relying weak signals eventually leads better generalization. hand data quality weak annotator extremely lower values focus true observations. therefore lets control bias-variance trade-off extreme cases. look rate learning student amount training data varied. performed types experiments tasks ﬁrst experiment available strong data consider different percentages entire weak dataset. second experiment amount weak data provide model varying amounts strong data. standard ﬁne-tuning similar setups baseline models. details experiments problem provided appendix figure presents results experiments. general tasks setups student learns faster teacher. caveat case small amount weak data. case student cannot learn suitable representation ﬁrst step hence performance pretty expected. highly unlikely situation occurs reality obtaining weakly labeled data much easier strong data. empirical observation figure model learns less data also seen evidence support another perspective called learning using privileged information elaborate connection appendix section position approach relative related work semi-supervised learning. learning imperfect labels thoroughly studied literature semi-supervised setup ideas developed utilize weakly even unlabeled data. instance idea self-training pseudo-labeling co-training introduced augmenting training unlabeled data predicted labels. common approach semi-supervised learning unlabeled used learning distribution data. particular neural networks greedy layer-wise pre-training weights using unlabeled data followed supervised ﬁnetuning methods learn unsupervised encoding multiple levels architecture jointly supervised signal alternatively noise cleansing methods proposed remove correct mislabeled samples studies showing weak noisy labels leveraged employing particular architecture deﬁning proper loss function avoid over-ﬁtting imperfections training data direction research focuses modeling pattern noise weakness labels. instance methods generative model correct weak labels discriminative model trained effectively furthermore methods capture pattern noise inserting extra layer separate module tries infer better labels noisy ones supervise training training neural networks using large amounts weakly annotated data attractive approach scenarios adequate amount data true labels available situation often arises practice. paper introduced ﬁdelity-weighted learning student-teacher framework semi-supervised learning presence weakly labeled data. applied document ranking sentiment classiﬁcation empirically veriﬁed speeds training process improves state-of-the-art semi-supervised alternatives. eyal beigman beata beigman klebanov. learning annotation noise. proceedings joint conference annual meeting international joint conference natural language processing afnlp volume -volume association computational linguistics avrim blum mitchell. combining labeled unlabeled data co-training. proceedings eleventh annual conference computational learning theory colt’ mostafa dehghani aliaksei severyn sascha rothe jaap kamps. avoiding teacher’s mistakes training neural networks controlled weak supervision. arxiv preprint arxiv. deriu maurice gonzenbach fatih uzdilli aurelien lucchi valeria luca martin jaggi. swisscheese semeval- task sentiment classiﬁcation using ensemble convolutional neural networks distant supervision. proceedings semeval deriu aurelien lucchi valeria luca aliaksei severyn simon m¨uller mark cieliebak thomas hofmann martin jaggi. leveraging large amounts weakly supervised data multi-language sentiment classiﬁcation. proceedings international international world wide conference thomas desautels andreas krause joel burdick. parallelizing exploration-exploitation tradeoffs gaussian process bandit optimization. journal machine learning research hussam hamdan frederic b´echet patrice bellot. experiments dbpedia wordnet sentiwordnet resources sentiment analysis micro-blogging. second joint conference lexical computational semantics volume dong-hyun lee. pseudo-label simple efﬁcient semi-supervised learning method deep neural networks. workshop challenges representation learning icml volume alexander matthews mark wilk nickson keisuke. fujii alexis boukouvalas pablo le´on-villagr´a zoubin ghahramani james hensman. gpﬂow gaussian process library using tensorflow. journal machine learning research vinod nair geoffrey hinton. rectiﬁed linear units improve restricted boltzmann machines. proceedings international conference machine learning alexander ororbia giles david reitter. learning deep hybrid model semisupervised text classiﬁcation. proceedings conference empirical methods natural language processing nicolas papernot mart´ın abadi ´ulfar erlingsson goodfellow kunal talwar. semi-supervised knowledge transfer deep learning private training data. iclr arxiv preprint arxiv.. alexander ratner christopher daniel selsam christopher r´e. data programming creating large training sets quickly. advances neural information processing systems sara rosenthal preslav nakov svetlana kiritchenko saif mohammad alan ritter veselin stoyanov. semeval- task sentiment analysis twitter. proceedings international workshop semantic evaluation aliaksei severyn alessandro moschitti. twitter sentiment analysis deep convolutional neural networks. proceedings international sigir conference research development information retrieval aliaksei severyn alessandro moschitti. unitn training deep convolutional neural network twitter sentiment classiﬁcation. proceedings international workshop semantic evaluation association computational linguistics denver colorado nitish srivastava geoffrey hinton alex krizhevsky ilya sutskever ruslan salakhutdinov. dropout simple prevent neural networks overﬁtting. mach. learn. res. paroma varma bryan iter peng rose christopher christopher r´e. socratic learning correcting misspeciﬁed generative models using discriminative models. arxiv preprint arxiv. andreas veit neil alldrin chechik ivan krasin abhinav gupta serge belongie. learning noisy large-scale datasets minimal supervision. conference computer vision pattern recognition moved additional details appendices order keep main text focused overall idea fidelity-weighted learning approach. speciﬁcally include details clustered gaussian process approach student network architectures teacher gaussian process model weak annotators experimental data setup connection learning privileged information suggest using several ={gpci} cover entire data space. results better specialization teacher. addition solves scalability issue size strong dataset train large. propose method called clustered gaussian process inspired alleviate issue large sample size. clustered size dataset train teacher. assume allocate teachers entire data space. therefore sees dataset size n/k. simple clustering method centroids clusters cc...ck consists samples {xixi...xin}. take centroid cluster representative sample content. note necessarily belong {xixi...xin}. assign cluster trained samples belonging cluster. precisely cluster assigned whose data points {xixi...xin}. dependency among different clusters train parallel speed-up procedure more. pseudo-code clustered presented algorithm main issue computational resources ﬁrst choose number maximum size dataset resources allow train number clusters accordingly. rest algorithm remains unchanged. ranking task employed student proposed ﬁrst layer network models function learns representation input data samples i.e. consists three components embedding function weighting function compositionality function n→rm. formally function deﬁned denote term query respectively document embedding function maps term dense mdimensional real value vector learned training phase. weighting function assigns weight term vocabulary. shown simulates effect inverse document frequency important feature information retrieval compositionality function projects embedding-weighting pairs mdimensional representation independent value fact normalized weighted element-wise summation terms’ embedding vectors. again shown global term weighting function along embedding function improves performance ranking simulates effect inverse document frequency experiments initialize embedding function wordvec embeddings pre-trained google news weighting function idf. representation layer followed simple fully connected feed-forward network hidden layers followed softmax receives vector representation inputs processed representation learning layer outputs prediction hidden layer network computes denote weight matrix bias term corresponding hidden layer non-linearity. layers follow sigmoid output. employ cross entropy loss student sentiment classiﬁcation task convolutional model shown perform best dataset used ﬁrst layer network learns function maps input sentence vector representation consists embedding function denotes vocabulary number embedding dimensions. function maps sentence matrix s∈rm×|s| column represents embedding word corresponding position sentence. matrix passed convolution layer. layer ﬁlters applied sliding window length generate feature matrix feature skjfkj denotes concatenation word vectors position i+h. concatenation produces feature vector r|s|−h+. vectors aggregated ﬁlters feature matrix ∈rf×. also bias vector result convolution. convolutional layer followed non-linear activation function applied element-wise. afterward output passed pooling layer operates columns feature matrix returning largest value pool architecture similar state-of-the-art model twitter sentiment classiﬁcation semeval representation layer followed feed-forward layer similar ranking task softmax instead sigmoid output layer returns probability distribution three classes. employ cross entropy loss gaussian process teacher experiments. task either regression classiﬁcation order generate soft labels pass mean function applied output student network task e.g. softmax sigmoid. binary classiﬁcation dimensional regression scalar identity. multi-class classiﬁcation multi-dimensional regression tasks aggregation function takes variance several dimensions outputs single measure variance. reasonable choice aggregating function sentiment classiﬁcation task mean variances dimensions. empirically found satisfying value length scale matern/ kernels. also obtain homogeneous linear kernel. constant value hite determines level noise labels. different noise weak labels. term explains fact even true labels might trace noise inaccuracy human labelers. number clusters clustered algorithm ranking task sentiment classiﬁcation task weak annotator document ranking task well-known unsupervised retrieval method. method heuristically scores given pair query-document based statistics matched terms. pairwise document ranking setup given sample probability document ranked higher pqd+d− score obtained weak annotator. weak annotator sentiment classiﬁcation task simple lexicon-based method sentiwordnet assign probabilities token bag-of-words model sentence-level probabilities http//gpflow.readthedocs.io/en/latest/notebooks/regression.html http//gpflow.readthedocs.io/en/latest/notebooks/sgpr_notes.html http//gpflow.readthedocs.io/en/latest/notebooks/multiclass.html weak/true data experiments problem randomly sampled data points weak function data points true function. introduce small amount noise observation true function model noise human labeled data. setup neural network employed problem experiments simple feed-forward network depth layers width neurons layer. used tanh nonlinearity intermediate layers linear output layer. optimizer used adam initial learning rate teacher problem data points also ﬁne-tuning setup experiments section ﬁxed everything model tried running ﬁne-tuning stage different values β∈{.....} experiments. experiments problem section reported numbers averaged trials. ﬁrst experiment size sampled data data |ds| |dw| second |dw| |ds| collections standard trec collections task ad-hoc retrieval ﬁrst collection consists news articles different news agencies homogeneous collection. second collection clueweb category large-scale collection million english documents considered heterogeneous collection. spam documents ﬁltered using waterloo spam scorer default threshold data true labels take query sets contain human-labeled judgments queries robust collection queries experiments clueweb collection. query take documents judged relevant plus number documents judged non-relevant form pairwise combinations among them. data weak labels create query using unique queries appearing query logs query contains queries initiated real users search engine sampled three-month period march ﬁltered large volume navigational queries containing substrings also removed nonalphanumeric characters queries. dataset took queries least hits target corpus using weak annotator method. applying steps collect million queries train robust million queries clueweb. prepare weakly labeled training take retrieved documents using query training query total leads ∼|q|× training samples. setup evaluation whole model conducted -fold cross-validation. however dataset ﬁrst tuned hyper-parameters student ﬁrst step true labels using batched bandits expected improvement acquisition function kept optimal parameters student ﬁxed experiments. size number hidden layers student selected initial learning rate dropout parameter selected {−−} {...} respectively. considered embedding sizes batch size experiments relu non-linear activation function student. adam optimizer training dropout regularization technique. inference time query take retrieved documents using candidate documents re-rank using trained models. indri implementation default parameters collections test model twitter message-level sentiment classiﬁcation semeval- task datasets semeval- subsume test sets previous editions semeval i.e. semeval- semeval-. tweet preprocessed urls usernames masked. data true labels train development data semeval- training semeval--test validation. make results comparable ofﬁcial runs semeval semeval- semeval- test sets data weak labels large corpus containing tweets collected months both training word embeddings creating weakly annotated using lexicon-based method explained section setup similar document ranking task tuned hyper-parameters student ﬁrst step respect true labels validation using batched bandits expected improvement acquisition function kept optimal parameters ﬁxed experiments. size number hidden layers classiﬁer selected tested model both convolutional layers. number convolutional feature maps ﬁlter width selected respectively. initial learning rate dropout parameter selected {e−e−} {...} respectively. considered embedding sizes batch size experiments relu used non-linear activation function student. adam optimizer used training dropout regularizer. section highlight connections work vapnik’s learning using privileged information makes information small correctly labeled data improve performance semi-supervised learning algorithm. main idea behind lupi comes fact humans learn much faster machines. role intelligent teacher plays human learning. framework training data collection triplets pair feature-label additional information provided intelligent teacher ease learning process student. additional information available training time learning machine must rely test time. theory lupi studies leverage teaching signal outperform learning algorithms utilizing normal features example brain images augmented high-level medical even psychological descriptions alzheimer’s disease build classiﬁer predicts probability alzheimer’s disease image test time. known statistical learning theory following bound test error satisﬁed probability denotes training error samples |f|v dimension space functions chosen classes separable i.e. machine learns slow rate easier problems classes separable resulting learning rate difference cases severe. error bound achieved separable problem thousand data points obtainable non-separable problem million data points provided. prohibitive even obtaining large datasets costly. theory lupi shows intelligent teacher reduce resulting faster learning process student. paper proposed teacher-student framework semi-supervised learning. similar lupi student supposed solve main prediction task intelligent teacher provides additional information improve learning. addition ﬁrst train student network obtains initial knowledge weakly labeled data learns good data representation. teacher trained truly labeled data enjoying representation learnt student. extends lupi teacher provides privileged information useful current state student’s knowledge. also extends lupi introducing several teachers specialized correct student’s knowledge related speciﬁc region data space. figure provides evidence assumption privileged information task accelerate learning process student. shows privileged information intelligent teacher affects exponent error bound equation figure shows test error various number samples |ds| true label. expected extremes |ds| small large performance model becomes close models without teacher. reason student enough strong samples learn good model true function. realistic cases |ds||dw| |ds| still large enough informative |dw| model gives lower test error models without intelligent teacher. theory lupi ﬁrst developed proved support vector machines vapnik method knowledge transfer. hinton introduced dark knowledge spiritually close idea context neural networks proposed large network ensemble networks training smaller network test time. turned compressing knowledge large system smaller system improve generalization ability. shown dark knowledge lupi uniﬁed single umbrella called generalized distillation. core idea models machinesteaching-machines. name suggests machine learning knowledge embedded another machine. case student correcting knowledge receiving privileged information label uncertainty teacher. trainable teacher often assumed teacher lupi framework additional true information. show extra information available still lupi setup deﬁne implicit teacher whose knowledge learned true data. approach performance ﬁnal student-teacher system depends clever answer following question information considered privileged knowledge teacher. bayesian teacher proposed teacher bayesian. provides posterior uncertainty label mutual representation introduced module learns mutual embedding student teacher. particular interesting deﬁnes two-way channel teacher student. multiple teachers proposed scalable method introduce several teachers teacher", "year": 2017}