{"title": "A Neural Network Architecture Combining Gated Recurrent Unit (GRU) and  Support Vector Machine (SVM) for Intrusion Detection in Network Traffic Data", "tag": ["cs.NE", "cs.CR", "cs.LG", "stat.ML"], "abstract": "Gated Recurrent Unit (GRU) is a recently-developed variation of the long short-term memory (LSTM) unit, both of which are types of recurrent neural network (RNN). Through empirical evidence, both models have been proven to be effective in a wide variety of machine learning tasks such as natural language processing (Wen et al., 2015), speech recognition (Chorowski et al., 2015), and text classification (Yang et al., 2016). Conventionally, like most neural networks, both of the aforementioned RNN variants employ the Softmax function as its final output layer for its prediction, and the cross-entropy function for computing its loss. In this paper, we present an amendment to this norm by introducing linear support vector machine (SVM) as the replacement for Softmax in the final output layer of a GRU model. Furthermore, the cross-entropy function shall be replaced with a margin-based function. While there have been similar studies (Alalshekmubarak & Smith, 2013; Tang, 2013), this proposal is primarily intended for binary classification on intrusion detection using the 2013 network traffic data from the honeypot systems of Kyoto University. Results show that the GRU-SVM model performs relatively higher than the conventional GRU-Softmax model. The proposed model reached a training accuracy of ~81.54% and a testing accuracy of ~84.15%, while the latter was able to reach a training accuracy of ~63.07% and a testing accuracy of ~70.75%. In addition, the juxtaposition of these two final output layers indicate that the SVM would outperform Softmax in prediction time - a theoretical implication which was supported by the actual training and testing time in the study.", "text": "abien.fred.agarapadamson.edu.ph keywords artificial intelligence; artificial neural networks; gated recurrent units; intrusion detection; machine learning; recurrent neural networks; support vector machine reference format abien fred agarap. neural network architecture combining gated recurrent unit support vector machine intrusion detection network traffic data. icmlc international conference machine learning computing february macau china. york pages. https //doi.org/./. introduction cost global economy cybercrime projected reach trillion. among contributory felonies cybercrime intrusions defined illegal unauthorized network system attackers. intrusion detection system used identify said malicious activity. common method used uncovering intrusions analysis user activities. however aforementioned method laborious done manually since data user activities massive nature. simplify problem automation machine learning must done. study mukkamala janoski sung shows support vector machine artificial neural network used accomplish said task. machine learning separates classes data points using hyperplane. hand computational model represents human brain shows information passed neuron another. approach combining proposed alalshekmubarak smith time-series classification. specifically combined echo state network svm. research presents modified version aforementioned proposal intrusion detection. proposed model recurrent neural network gated recurrent units place esn. rnns used analyzing and/or predicting sequential data making viable candidate intrusion detection since network traffic data sequential nature. abstract gated recurrent unit recently-developed variation long short-term memory unit variants recurrent neural network empirical evidence models proven effective wide variety machine learning tasks natural language processing speech recognition text classification. conventionally like neural networks aforementioned variants employ softmax function final output layer prediction cross-entropy function computing loss. paper present amendment norm introducing linear support vector machine replacement softmax final output layer model. furthermore cross-entropy function shall replaced margin-based function. similar studies proposal primarily intended binary classification intrusion detection using network traffic data honeypot systems kyoto university. results show gru-svm model performs relatively higher conventional gru-softmax model. proposed model reached training accuracy testing accuracy latter able reach training accuracy testing accuracy ≈.%. addition juxtaposition final output layers indicate would outperform softmax prediction time theoretical implication supported actual training testing time study. concepts computing methodologies supervised learning classification; support vector machines; neural networks; security privacy intrusion detection systems; permission make digital hard copies part work personal classroom granted without provided copies made distributed profit commercial advantage copies bear notice full citation first page. copyrights components work owned others must honored. abstracting credit permitted. copy otherwise republish post servers redistribute lists requires prior specific permission and/or fee. request permissions permissionsacm.org. icmlc february macau china association computing machinery. isbn ----//.... https//doi.org/./. l-svm used proposed gru-svm architecture. prediction decision function siдn produces score vector classes. predicted class label data arдmax function used predicted_class arдmax) features learning parameters values. using decision function siдn. loss neural network computed using optimization algorithm used loss minimization optimizer used). optimization adjusts weights biases based computed loss. process repeated neural network reaches desired accuracy highest accuracy possible. afterwards trained model used binary classification given data. dataset kyoto university honeypot systems’ network traffic data used study. statistical features; features dataset additional features according song takakura okabe might pivotal effective investigation intrusion detection. dataset features used study. data preprocessing experiment whole network traffic dataset used i.e. data using dataset experiment normalized first standardization indexing binned feature value standardized mean value given feature standard deviation. efficiency standardscaler.fit_transform function scikit-learn used data standardization study. indexing categories mapped using labelencoder.fit_transform function scikit-learn. dataset normalization continuous features binned done getting quantile features indices served number. process done using qcut function pandas. binning reduces required computational cost improves classification performance dataset. lastly features one-hot encoded making ready models. data analysis effectiveness proposed gru-svm model measured phases experiment training phase test phase. along proposed model conventional gru-softmax also trained tested dataset. first phase experiment utilized total data points dataset. normalization binning revealed high-level inspection duplication occurred. using dataframe.drop_duplicates pandas -line data dropped lines second phase experiment evaluation trained models using total data points dataset. testing dataset also experienced drastic shrinkage size lines lines parameters experiments following accuracy epochs loss time number data points number false positives number false negatives. parameters based ones considered mukkamala janoski sung study compared feed-forward neural network intrusion detection. lastly statistical measures binary classification measured results experiments study conducted laptop computer intel core i-hq .ghz nvidia geforce gpu. hyperparameters used models assigned hand hyper-parameter optimization/tuning models trained lines network traffic data epochs. afterwards trained models tested classify lines network traffic data epochs. specified number lines network traffic data used experiments values divisble batch size class distribution training testing dataset specified table figure shows epochs -line network traffic data gru-svm model able finish training minutes seconds. hand gru-softmax model finished training minutes seconds. discussion empirical evidence presented paper suggests outperforms softmax function terms prediction accuracy used final output layer neural network. finding corroborates claims alalshekmubarak smith tang supports claim practical approach softmax binary classification. gru-svm model outperform gru-softmax terms prediction accuracy also outperformed conventional model terms training time testing time. thus supporting theoretical implication respective algorithm complexities classifier. reported training accuracy testing accuracy posits gru-svm model relatively stronger predictive performance gru-softmax model hence propose theory explain relatively lower performance softmax compared particular scenario. first designed primarily binary classification softmax best-fit multinomial classification. building premise care individual scores classes predicts requires margins satisfied. contrary softmax function always find improve predicted probability distribution ensuring correct class higher/highest probability incorrect classes lower probability. behavior softmax function exemplary excessive problem like binary classification. given sigmoid function special case softmax refer graph classifies network output. inferred graph sigmoid function values tend respond less changes words gradients would small gives rise vanishing gradients problem. indeed problems solved lstm consequently variants gru. behavior defeats purpose lstm solving problems traditional rnn. posit cause misclassifications gru-softmax model. said erroneous manner gru-softmax model reflects favor gru-svm model. comparison exhibited predictive accuracies models reason practicality choosing softmax case. amount training time testing time also considered. computational complexities suggest upper hand softmax. algorithm complexity predictor function hand predictor function softmax algorithm complexity results shown gru-svm model also outperformed gru-softmax model training time testing time. thus corroborates respective algorithm complexities classifiers. jeremy frank. artificial intelligence intrusion detection current future directions. proceedings national computer security conference vol. baltimore anup ghosh aaron schwartzbard michael schatz. learning program behavior profiles intrusion detection.. workshop intrusion detection network monitoring vol. yohan grember stack overflow. arxivhttps//stackoverflow.com/questions/ https//stackoverflow.com/ questions/ urlhttps//stackoverflow.com/questions/ jonathan lustgarten vanathi gopalakrishnan himanshu grover shyam visweswaran. improving classification performance discretization biomedical datasets. amia annual symposium proceedings vol. american medical informatics association srinivas mukkamala guadalupe janoski andrew sung. intrusion detection support vector machines neural networks. proceedings ieee international joint conference neural networks louis pedregosa varoquaux gramfort michel thirion grisel blondel prettenhofer weiss dubourg vanderplas passos cournapeau brucher perrot duchesnay. scikit-learn machine learning python. journal machine learning research delink stolfo wenke andreas prodromidis philip chan. cost-based modeling evaluation data mining application fraud intrusion detection. results project salvatore tsung-hsien milica gasic nikola mrksic pei-hao david vandyke steve young. semantically conditioned lstm-based natural language generation spoken dialogue systems. arxiv preprint arxiv. zichao yang diyi yang chris dyer xiaodong alexander smola eduard hovy. hierarchical attention networks document classification.. hlt-naacl. conclusion recommendation proposed amendment architecture using final output layer binary/non-probabilistic classification task. amendment seen viable fast prediction time compared softmax. test model conducted experiment comparing established gru-softmax model. consequently empirical data attests effectiveness proposed gru-svm model comparator terms predictive accuracy training testing time. work must done validate effectiveness proposed gru-svm model binary classification tasks. extended study proposed model faster multinomial classification would prove prolific well. lastly theory presented explain relatively performance softmax function binary classifier might pre-cursor studies. acknowledgment expression gratitude following people research instructor sincere blanco; technical adviser ryan steven caro; computer science special lecturer roderick alvarez; computer science faculty member edward bustillos; chairperson department computer science raquel bermudez. extension appreciation friends acquaintances lend time read parts paper hyacinth gasmin rhea ferrer jericho mallen deon apelo jameson haldos. utmost appreciation department computer science adamson university faculty students adamson university itself enabling conduct study well support commencement culmination study. lastly definitely least appreciation open source community virtually infinite source information knowledge; kyoto university intrusion detection dataset honeypot system. references martín abadi ashish agarwal paul barham eugene brevdo zhifeng chen craig citro greg corrado andy davis jeffrey dean matthieu devin sanjay ghemawat goodfellow andrew harp geoffrey irving michael isard yangqing rafal jozefowicz lukasz kaiser manjunath kudlur josh levenberg mané rajat monga sherry moore derek murray chris olah mike schuster jonathon shlens benoit steiner ilya sutskever kunal talwar paul tucker vincent vanhoucke vijay vasudevan fernanda viégas oriol vinyals pete warden martin wattenberg martin wicke yuan xiaoqiang zheng. tensorflow large-scale machine learning heterogeneous systems. http//tensorflow.org/ software available tensorflow.org. alalshekmubarak l.s. smith. novel approach combining recurrent neural network support vector machines time series classification. innovations information technology international conference ieee kyunghyun bart merriënboer caglar gulcehre dzmitry bahdanau fethi bougares holger schwenk yoshua bengio. learning phrase representations using encoder-decoder statistical machine translation. arxiv preprint arxiv. chorowski dzmitry bahdanau dmitriy serdyuk kyunghyun yoshua bengio. attention-based models speech recognition. advances neural information processing systems.", "year": 2017}