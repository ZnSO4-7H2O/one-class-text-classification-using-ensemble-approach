{"title": "Reinforced Video Captioning with Entailment Rewards", "tag": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "abstract": "Sequence-to-sequence models have shown promising improvements on the temporal task of video captioning, but they optimize word-level cross-entropy loss during training. First, using policy gradient and mixed-loss methods for reinforcement learning, we directly optimize sentence-level task-based metrics (as rewards), achieving significant improvements over the baseline, based on both automatic metrics and human evaluation on multiple datasets. Next, we propose a novel entailment-enhanced reward (CIDEnt) that corrects phrase-matching based metrics (such as CIDEr) to only allow for logically-implied partial matches and avoid contradictions, achieving further significant improvements over the CIDEr-reward model. Overall, our CIDEnt-reward model achieves the new state-of-the-art on the MSR-VTT dataset.", "text": "zato occurs model exposed training data distribution instead predictions. first using sequence-level training policy gradient approach allow video captioning models directly optimize nondifferentiable metrics rewards reinforcement learning paradigm. also address exposure bias issue using mixed-loss i.e. combining cross-entropy reward-based losses also helps maintain output ﬂuency. next introduce novel entailment-corrected reward checks logically-directed partial matches. current reinforcement-based text generation works traditional phrase-matching metrics reward function. however metrics undirected ngram matching machine-generated caption ground-truth caption hence fail capture directed logical correctness. therefore still give high scores even generated captions contain single critical wrong word words still match ground truth. introduce cident penalizes phrase-matching metric based reward entailment score low. ensures generated caption gets high resequence-to-sequence models shown promising improvements temporal task video captioning optimize word-level cross-entropy loss durfirst using policy graing training. dient mixed-loss methods reinforcement learning directly optimize sentence-level task-based metrics achieving signiﬁcant improvements baseline based automatic metrics human evaluation multiple datasets. next propose novel entailment-enhanced reward corrects phrase-matching based metrics allow logically-implied partial matches avoid contradictions achieving further signiﬁcant improvements cider-reward model. overall cident-reward model achieves state-of-the-art msr-vtt dataset. task video captioning important next step image captioning additional modeling temporal knowledge action sequences several applications online content search assisting visuallyimpaired etc. advancements neural sequenceto-sequence learning shown promising improvements task based encoderdecoder attention hierarchical models however models still trained using wordlevel cross-entropy loss correlate well sentence-level metrics task ﬁnally evaluated moreover models suffer exposure bias attention attention-based seq-to-seq baseline model similar bahdanau architecture encode input frame level video features {fn} bi-directional lstm-rnn generate caption using lstm-rnn attention mechanism. model parameters ground-truth caption cross entropy loss function tmax projection matrix generated word decoder hidden state time step computed using standard recursion attention-based context vector details attention model supplementary reinforcement learning order directly optimize sentence-level test metrics policy gradient represent model parameters. here baseline model acts agent interacts environment time step agent generates word generation end-of-sequence token results reward agent. training objective minimize negative expected reward function ward directed match ground truth caption hence avoiding contradictory unrelated information empirically show ﬁrst cider-reward model achieves significant improvements cross-entropy baseline next cident-reward model achieves signiﬁcant improvements cider-based reward. overall achieve state-of-the-art msr-vtt dataset. past work presented several sequence-tosequence models video captioning using attention hierarchical rnns d-cnn video features joint embedding spaces language fusion etc. using word-level cross entropy loss training policy gradient image captioning recently presented ranzato using mixed sequence level training paradigm non-differentiable evaluation metrics rewards. rennie improve upon using monte carlo roll-outs test inference baseline respectively. paulus presented summarization results rouge rewards mixed-loss setup. recognizing textual entailment traditional task boosted large dataset recently introduced bowman several leaderboard models snli focus decomposable intra-sentence attention model parikh recently pasunuru bansal used multi-task learning combine video captioning entailment video generation. mixed loss reinforcement learning optimizing reinforcement loss doesn’t ensure readability ﬂuency generated caption also chance gaming metrics without actually improving quality output hence training reinforcement based policy gradients mixed loss function weighted combination cross-entropy loss reinforcement learning loss similar previous work mixed loss improves results metric used reward reinforcement loss also ensures better readability ﬂuency cross-entropy loss mixed loss deﬁned tuning parameter used balance losses. annealing faster convergence start optimized cross-entropy loss baseline model move optimizing mixed loss function. caption metric reward previous image captioning papers used traditional captioning metrics cider bleu meteor reward functions based match generated caption sample ground-truth reference. first shown vedantam also experimented curriculum learning ‘mixer’ strategy ranzato xe+rl annealing based decoder time-steps; however mixed loss function strategy performed better terms maintaining output caption ﬂuency. cider based consensus measure across several human reference captions higher correlation human evaluation metrics meteor rouge bleu. showed cider gets better number human references recently rennie showed cider reward image captioning outperforms metrics reward terms improvements cider metric also metrics. line previous works also found cider reward achieves best metric improvements video captioning task also best human evaluation improvements entailment corrected reward although cider performs better metrics reward metrics still based undirected n-gram matching score generated ground truth captions. example wrong caption playing football w.r.t. correct caption playing basketball still gets high score even though captions belong completely different events. similar issues hold case negation wrong action/object generated caption address issue using entailment score correct phrase-matching metric used reward ensuring generated caption logically implied ground-truth caption. achieve accurate entailment score adapt state-of-theart decomposable-attention model parikh trained snli corpus model gives probability whether sampled video caption entailed ground truth caption premise similar traditional metrics overall ‘ent’ score maximum entailment scores generated caption w.r.t. reference human caption cident deﬁned training details hyperparameters tuned validation set. results based -avg-ensemble. supplementary extra training details e.g. learning rate size mixed-loss cident hyperparameters. means entailment score penalize metric reward score decreasing penalty agreement-based formulation ensures trust ciderbased reward cases entailment score also high. using cider−λ also ensures smoothness reward w.r.t. original cider function here hyperparameters tuned dev-set; light tuning found best values intuitive roughly baseline model’s score metric table shows examples sampled generated captions model training cider misleadingly high incorrect captions entailment score helps successfully identify cases penalize reward. datasets datasets msr-vtt videos references/video; youtubetext/msvd videos references/video. standard splits details supp. automatic evaluation several standard automated evaluation metrics meteor bleu cider-d rouge-l human evaluation also present human evaluation comparison baseline-xe cider-rl cident-rl models esp. automatic metrics cannot trusted solely. relevance measures related generated caption w.r.t video content whereas coherence measures readability generated caption. entailment classiﬁer based parikh accurate entailment caption domain hence serving highly accurate reward score. domains future tasks summarization plan multi-domain dataset williams table shows primary results popular msr-vtt dataset. first baseline attention model trained cross entropy loss achieves strong results w.r.t. previous state-of-the-art methods. next policy gradient based mixed-loss model reward cider improves signiﬁcantly baseline metrics cider metric. also achieves statistically signiﬁcant improvements terms human relevance evaluation finally last table shows results novel cident-reward model model achieves statistically signiﬁcant improvements strong cider-rl model automatic metrics note table also report cident reward scores cident-rl model strongly outperforms cider baseline models entailmentcorrected measure. overall also rank msr-vtt leaderboard based ranking criteria. human evaluation also perform small human evaluation studies compare models pairwise. shown table table terms relevance ﬁrst cider-rl model stat. signiﬁcantly outperforms baseline model next cident-rl model significantly outperforms cider-rl model plus -ensemble video+entailment generation multi-task model pasunuru bansal statistical signiﬁcance cider meteor rouge bleu based bootstrap test randomly shufﬂe pairs anonymize model identity human evaluator chooses better caption based relevance coherence ‘not distinguishable’ cases annotator found captions equally good equally bad). table primary video captioning results msr-vtt. cider-rl results statistically signiﬁcant baseline results cident-rl results stat. signif. cider-rl results. human* refers ‘pairwise’ comparison human relevance evaluation cider-rl cident-rl models also tried cider cident reward models youtubetext dataset. table ﬁrst strong improvements cider-rl model cross-entropy baseline. next cident-rl model also shows improvements cider-rl model e.g. bleu entailment-corrected cident score. also achieves signiﬁcant improvements human relevance evaluation discussed sec. cider promising metric reward captioning based previous work’s ﬁndings well ours. investigate metrics reward. using bleu reward found bleu-rl model achieves bleu-metric improvements worse cross-entropy baseline human evaluation. similarly bleuent-rl model achieves bleu bleuent metric improvements worse human evaluation. fig. shows example cidentreward model correctly generates ground-truth style caption whereas cider-reward model produces non-entailed caption caption still high phrase-matching score. several examples supp. ﬁrst presented mixed-loss policy gradient approach video captioning allowing metric-based optimization. next presented entailment-corrected cident reward improves results achieving state-of-theart msr-vtt. future work applying entailment-corrected rewards directed generation tasks image captioning document summarization thank anonymous reviewers helpful comments. work supported google faculty research award faculty award bloomberg data science research grant nvidia awards. non-differentiable metric scores using policy gradients represents model parameters. captioning system baseline attention model acts agent interacts environment time step agent generates word generation end-of-sequence token results reward agent. training objective minimize negative expected reward function given approximation high variance estimating gradient single sample. adding baseline estimator reduces variance without changing expected gradient. hence rewritten follows baseline estimator function time step function model baseline estimator simple linear regressor hidden state decoder time step input. stop back propagation gradients hidden states baseline bias estimator. using chain rule loss function written attention baseline model similar bahdanau architecture encode input frame level video features bi-directional lstm-rnn generate caption using single layer lstm-rnn attention mechanism. frame-level features video clip sequence words forming caption. distribution words time step given previously generated words input video frame-level features given follows non-linear function. previous time step’s hidden state generated word. context vector linear weighted combination encoder hidden states weights attention mechanism deﬁned follows traditional video captioning systems minimize cross entropy loss training typically evaluated using phrase-matching metrics bleu meteor cider rouge-l. discrepancy addressed directly optimizing overall intuition behind gradient formulation reward sampled word sequence greater baseline estimator gradient loss function becomes negative model encourages sampled distribution increasing word probabilities otherwise model discourages sampled distribution decreasing word probabilities. msr-vtt diverse collection video clips commercial video search engine. video human annotated reference captions collected amazon mechanical turk standard split provided i.e. training testing remaining testing. video sample extract inception-v features sampled frames also remove punctuations text data. also evaluate models youtubetext dataset dataset video clips clip annotated average captions humans. standard split given i.e. clips training validation testing. similar preprocessing msr-vtt dataset. apart automatic metrics also present human evaluation comparing cident-reward model cider-reward model esp. automatic metrics cannot trusted solely. human evaluation uses relevance coherence comparison metrics. relevance related generated caption w.r.t. content hyperparameters tuned validation set. main models report results -avg-ensemble model times different initialization random seeds take average probabilities time step decoder inference time. ﬁxed size step lstm-rnn encoder-decoder encoder step size decoder step size lstm hidden size inception-v features video frame-level features. word embedding size also project -dim image features -dim. apply dropout vertical connections proposed zaremba value gradient clip size adam optimizer learning rate baseline cross-entropy loss. trainable weights initialized uniform distribution range test time inference beam search size reward-based models mixed loss optimization train model based weighted combination crossentropy loss reinforcement loss. msrvtt dataset ciderrl model cidentrl model. youtubetext/msvd dataset cider-rl model cident-rl model. learning rate mixed-loss optimization msr-vtt youtubetext/msvd. hyperparameter cident reward formulation roughly equal baseline cross-entropy model’s score metric i.e. msr-vtt cident-rl model youtubetext/msvd cident-rl model. david chen william dolan. collecting highly parallel data paraphrase evaluation. proceedings annual meeting association computational linguistics human language technologies-volume pages association computational linguistics. xinlei chen fang tsung-yi ramakrishna vedantam saurabh gupta piotr doll´ar lawrence zitnick. microsoft coco captions data collection evaluation server. arxiv preprint arxiv.. dagan oren glickman bernardo magnini. pascal recognising textual entailment challenge. machine learning challenges. evaluating predictive uncertainty visual object classiﬁcation recognising tectual entailment pages springer. micah hodosh peter young julia hockenmaier. framing image description ranking task data models evaluation metrics. journal artiﬁcial intelligence research julia baquero alexander gelbukh juan dios b´atiz mendiz´abal. unal-nlp combining soft cardinality features semantic textual similarity relatedness entailment. semeval pages figure output examples cident-rl model produces better entailed captions phrase-matching cider-rl model turn better baseline cross-entropy model. captioning metrics achieve high score even generation exactly entail ground truth high phrase overlap. obviously cause issues inserting single wrong word negation contradiction wrong action/object. hand entailment-enhanced cident score high cider entailment classiﬁer achieve high scores. cider-rl model turn produces better captions baseline cross-entropy model aware sentence-level matching all.", "year": 2017}