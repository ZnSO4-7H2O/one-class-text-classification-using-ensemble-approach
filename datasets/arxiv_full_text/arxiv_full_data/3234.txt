{"title": "A Comparative Study of Gaussian Mixture Model and Radial Basis Function  for Voice Recognition", "tag": ["cs.LG", "cs.CV", "stat.ML"], "abstract": "A comparative study of the application of Gaussian Mixture Model (GMM) and Radial Basis Function (RBF) in biometric recognition of voice has been carried out and presented. The application of machine learning techniques to biometric authentication and recognition problems has gained a widespread acceptance. In this research, a GMM model was trained, using Expectation Maximization (EM) algorithm, on a dataset containing 10 classes of vowels and the model was used to predict the appropriate classes using a validation dataset. For experimental validity, the model was compared to the performance of two different versions of RBF model using the same learning and validation datasets. The results showed very close recognition accuracy between the GMM and the standard RBF model, but with GMM performing better than the standard RBF by less than 1% and the two models outperformed similar models reported in literature. The DTREG version of RBF outperformed the other two models by producing 94.8% recognition accuracy. In terms of recognition time, the standard RBF was found to be the fastest among the three models.", "text": "abstract—a comparative study application gaussian mixture model radial basis function biometric recognition voice carried presented. application machine learning techniques biometric authentication recognition problems gained widespread acceptance. research model trained using expectation maximization algorithm dataset containing classes vowels model used predict appropriate classes using validation dataset. experimental validity performance different versions model using learning validation datasets. results showed close recognition accuracy standard model performing better standard less models outperformed similar models reported literature. dtreg version outperformed models producing recognition accuracy. terms recognition time standard found fastest among three models. keywordsgaussian mixture model radial basis function artificial intelligence computational intelligence biometrics optimal parameters voice pattern recognition dtreg biometrics measurable physical characteristic personal behavioral trait used recognize identity verify identity candidate. biometric recognition personal recognition system based opposed what know what have goal voice recognition biometrics verify individual's identity based voice. voice natural forms communication identifying people voice drawn attention lawyers judges investigators enforcement agencies practitioners forensics. computer forensics application science engineering legal problem digital evidence. synthesis science high level accuracy required financial transactions critical medical records preventing benefit fraud resetting passwords voice indexing. view importance accurate classification vowels voice recognition system need welltrained computational intelligence model acceptable percentage classification accuracy highly desired. gaussian mixture models radial basis function networks identified practice literature promising neural models pattern classification. rest paper organized follows. section reviews literature voice recognition; overview application biometric voice recognition; overview component dtreg software. description data tools used design implementation work discussed section iii. section describes experimental approach followed work criteria quality measurement used evaluate validity. results experiment discussed section conclusions drawn section novel suspect-adaptive technique robust forensic speaker recognition using maximum a-posteori estimation presented technique addressed likelihood ratio computation limited suspect speech data conditions obtaining good calibration performance robustness allowing system weigh relevance suspect specificities depending amount suspect data available estimation. results showed proposed technique outperformed previously proposed non-adaptive approaches. including parallel phone recognition language modeling support vector machine general gaussian mixture models experimental results showed framework achieved equal error rate international journal advanced computer science applications vol. september presented generalized technique using obtained error another related work described language identification shifted delta costar feature vectors achieve performance comparable best phone-based systems. approaches included acoustic scoring tokenization system based variation phonetic recognition language modeling. previously reported results. description major elements lincoln laboratory‟s gaussian mixture model -based speaker verification system built around likelihood ratio test verification using simple effective gmms likelihood functions universal background model alternative speaker representation form bayesian adaptation derive speaker models presented results showed gmm-ubm system proven effective speaker recognition tasks. evaluated related problem dialect identification using gmms features. results showed techniques yields average equal error rate dialects language used equal error rate one. network multilayer feedforward often used strict interpolation multi-dimensional space. term „feedforward‟ means neurons organized form layers layered neural network. basic architecture three-layered neural network shown fig. rbfn three layers including input layer hidden layer output layer. input layer composed input data. hidden layer transforms data input space hidden space using non-linear function. output layer linear yields response network. argument activation function hidden unit rbfn computes euclidean distance input vector center unit. structure rbfn input data i-dimensional vector transmitted hidden unit. activation function hidden units symmetric input space output hidden unit depends radial distance input vector center hidden unit. output hidden unit given support vector machines presented introducing sequence kernel used language identification. gaussian mixture model developed sequence mapping task variable length sequence vectors fixed dimensional space. results demonstrated system yielded performance superior classifier generalized linear discriminant sequence kernel. using vowel detection algorithm segmented rhythmic units related syllables extracting parameters consonantal vowel duration cluster complexity modeled gaussian mixture. results reached correct discrimination stress-timed moratimed syllable-timed classes languages. compared standard acoustic gaussian mixture modeling approach yielded correct identification. presented additive cumulative improvements several innovative techniques applied parallel phone recognition followed language modeling system language identification obtaining relative error reduction base system. started application variable threshold score computation error reduction random selection sentences different sets silence models then compared bias removal technique error reduction gaussian classifier error reduction then included acoustic score gaussian classifier error reduction increased number gaussians multiple-gaussian classifier error reduction finally included additional acoustic hmms language success gaining relative improvement. clustering perspective biometric data cannot adequately modeled single-cluster gaussian model. however often accurately modeled gaussian mixture model i.e. data distribution expressed mixture multiple normal distributions international journal advanced computer science applications vol. september variance acoustic models using hidden markov models order improve word recognition accuracy demonstrated also presented concluded voice quality classified using input features speech recognition. dtreg software builds classification regression decision trees neural radial basis function networks support vector machine gene expression programs discriminant analysis logistic regression models describe data relationships used predict values future observations. also full support time series analysis. analyzes data generates model showing best predict values target variable based values predictor variables. dtreg create classical singletree models also treeboost decision tree forest models consisting ensembles many trees. includes full data transformation language transforming variables creating variables selecting rows analyze classification/regression tools available dtreg radial basis function networks. like standard dtreg-rbf input layer hidden layer output layer. neurons hidden layer contain gaussian transfer functions whose outputs inversely proportional distance center neuron. although implementation different neural networks conceptually similar k-nearest neighbor models. basic idea predicted target value item likely items close values predictor variables. dtreg uses training algorithm developed algorithm uses evolutionary approach determine optimal center points spreads neuron. also determines stop adding neurons network monitoring estimated leave-one-out error terminating error begins increase overfitting. computation optimal weights neurons hidden layer summation layer done using ridge regression. iterative procedure developed author used compute optimal regularization generalized cross-validation error. detailed description dtreg found training testing data obtained experimental -dimensional dataset available training data consists observations testing data consists observations. input variables observation belongs classes vowels classified using trained models. activation function non-linear function many types gaussian multi-quadratic thinspline exponential functions. form basis function selected advance trained rbfn closely related clustering quality training data towards centers. training data width gaussian function. center width associated hidden unit network. weights connecting hidden output units estimated using least mean square method. finally response hidden unit scaled connecting weights output units summed produce overall network output. therefore output network mathematical properties interpolation design matrices promising neural models pattern classification also gained popularity voice recognition presented comparative study application minimal neural network normal elliptical speaker verification. experimental results showed minimal outperforms techniques. another work explicitly modeling voice quality international journal advanced computer science applications vol. september dtreg-rbf flexible; variable target time. ideal one-target classification problems. work different models trained output column target. cumbersome. generally observed execution time increased number centers increased little similarly training testing recognition rates increased number centers increased decreased progressively increased fig. show plots different runs diag full covariance types execution time recognition rates vary number centers. class boundaries generated model training testing shown fig. generally training time increased number hidden neurons increased testing time remained relatively constant except little fluctuations. also training testing times increased gradually number hidden neurons increased began fall gradually points remained relatively constant except little fluctuations points. fig. shows decision boundaries rbf-based classifier using training testing data applied gmms fig. shows contour plot model training data centers. mentioned earlier section disadvantage dtreg-rbf accepts variable target. constitutes major restriction poses difficulties. vowel classes model built training dataset respective class classification. automated this. purpose effective comparison average number neurons training times training testing recognition rates taken. fig. show relationship number hidden neurons execution time classifiers implemented matlab support netlab toolbox obtained freeware dtreg-rbf implemented using dtreg software version descriptive statistics training test data shown table scatter plots training test data shown fig. respectively. methodology work based standard pattern recognition approach classification problem using models expectation rbf. maximization efficient optimization parameters. used forward backward propagation optimize parameters neurons using popular gaussian function transform function hidden layer common literature. parameters models also tuned varied maximum classification accuracy selected. dtreg-rbf dataset default parameter settings. classification accuracy respectively. indicate optimal performance terms execution time classification accuracy obtained approximately point number hidden neurons comparatively terms execution time clearly outperforms dtreg-rbf terms recognition rate clearly visible better since better training better recognition ensure fair judgment average training testing recognition rates models shows performs better margin clear terms recognition accuracies dtreg-rbf model performed best average recognition rate clearly shown fig. comparative study application gaussian mixture model radial basis function neural networks parameters optimized algorithm forward backward propagation biometric recognition vowels implemented. study models produced maximum recognition rates respectively. better recognition rate proposed jean-luc close acoustic version recognition rate well proposed dtreg version produced rate outperforming techniques similar techniques earlier reported literature. study carried using vowel dataset. dtreg-rbf models built default parameter settings left unchanged. done order establish premise valid comparison studies using tool. however time study author aware similar study implemented dtreg software hence ground comparison previous studies. experimental studies evaluate classification regression capability dtreg carried component tools support vector machines probabilistic general regression neural networks cascaded correlation multilayer perceptron decision tree forest logistic regression various classification prediction problems comparison standard versions. furthermore order increase confidence work establish better premise valid comparison generalization larger diverse dataset used. order overcome limitation dataset used fixed data preset training testing plan future study stratified sampling approach used divide datasets training testing sets give dataset equal chance chosen either training testing time implementation executed. international journal advanced computer science applications vol. september previous work hybridization machine learning techniques study commenced combination single hybrid model achieve better learning recognition rates. reported confirmed hybrid techniques perform better individual components used separately. author grateful department information computer science college computer sciences engineering king fahd university petroleum minerals providing computing environment licensed dtreg software purpose research. supervision lahouari ghouti technical evaluation kanaan faisal also appreciated. ramos-castro gonzalez-rodriguez montero-asenjo ortega-garcia \"suspect-adapted estimation within-source distributions likelihood ratio estimation\" speaker language recognition workshop ieee odyssey vol. pp.- june peng \"svm-ubm based automatic language identification using vowel-guided segmentation\" third international conference natural computation icnc rouas farinas pellegrino andre-obrecht rhythmic unit extraction modeling automatic language identification\" speech communication volume issue december pages p.a. torres-carrasquillo d.a. reynolds j.r. deller \"language identification using gaussian mixture model tokenization\" ieee international conference acoustics speech signal processing proceedings. vol. i--i- vol. córdoba l.f. d‟haro san-segundo macías-guarasa fernández j.c. plaza multiple-gaussian classifier language identification using acoustic information pprlm scores jornadas tecnologia habla p.a. torres-carrasquillo singer m.a. kohler r.j. greene d.a. reynolds j.r. deller approaches language identification using gaussian mixture models shifted delta cepstral features proceedings international conference spoken language processing chen huang chang wang \"automatic accent identification using gaussian mixture models\" ieee workshop automatic speech recognition understanding dec. p.a. torres-carrasquillo t.p. gleason d.a. reynolds dialect identification using gaussian mixture models proc. odyssey speaker language recognition workshop toledo spain isca june international journal advanced computer science applications vol. september yang kong \"gaussian mixture density likelihood\" modeling decomposition weighted proceedings world congress intelligent control automation june wuei-he wen-whei discriminative training gaussian mixture bigram models application chinese dialect identification speech communication volume issue march yoon zhuang cole hasegawa-johnson voice quality dependent speech recognition tseng linguistic patterns spontaneous speech special issue language linguistics academica sinica chen hong c.j. harris \"orthogonal forward selection constructing radial basis function network tunable nodes\" icic part lncs springer-verlag berlin heidelberg chikhi batouche \"probabilistic neural method combined radial-bias functions applied reservoir characterization algerian triassic province\" journal geophysics engineering deyi dave tina \"permeability estimation using hybrid genetic programming fuzzy/neural inference approach\" society petroleum engineers annual technical conference exhibition held dallas texas u.s.a. october fatai adesina anifowose formerly research assistant department information computer science king fahd university petroleum minerals saudi arabia. specializes application artificial intelligence working center petroleum minerals research institute university. involved various projects dealing prediction porosity permeability reservoirs using various techniques. recently interested hybridization techniques better performance.", "year": 2012}