{"title": "Adversarial Feature Learning", "tag": ["cs.LG", "cs.AI", "cs.CV", "cs.NE", "stat.ML"], "abstract": "The ability of the Generative Adversarial Networks (GANs) framework to learn generative models mapping from simple latent distributions to arbitrarily complex data distributions has been demonstrated empirically, with compelling results showing that the latent space of such generators captures semantic variation in the data distribution. Intuitively, models trained to predict these semantic latent representations given data may serve as useful feature representations for auxiliary problems where semantics are relevant. However, in their existing form, GANs have no means of learning the inverse mapping -- projecting data back into the latent space. We propose Bidirectional Generative Adversarial Networks (BiGANs) as a means of learning this inverse mapping, and demonstrate that the resulting learned feature representation is useful for auxiliary supervised discrimination tasks, competitive with contemporary approaches to unsupervised and self-supervised feature learning.", "text": "ability generative adversarial networks framework learn generative models mapping simple latent distributions arbitrarily complex data distributions demonstrated empirically compelling results showing latent space generators captures semantic variation data distribution. intuitively models trained predict semantic latent representations given data serve useful feature representations auxiliary problems semantics relevant. however existing form gans means learning inverse mapping projecting data back latent space. propose bidirectional generative adversarial networks means learning inverse mapping demonstrate resulting learned feature representation useful auxiliary supervised discrimination tasks competitive contemporary approaches unsupervised self-supervised feature learning. deep convolutional networks become staple modern computer vision pipeline. training models massive database image-label pairs like imagenet network easily adapts variety similar visual tasks achieving impressive results image classiﬁcation localization tasks. perceptual domains natural language processing speech recognition deep networks proven highly effective well however recent results rely supervisory signal large-scale databases hand-labeled data ignoring much useful information present structure data itself. meanwhile generative adversarial networks emerged powerful framework learning generative models arbitrarily complex data distributions. framework learns generator mapping samples arbitrary latent distribution data well adversarial discriminator tries distinguish real generated samples accurately possible. generator’s goal fool discriminator producing samples close real data possible. trained databases natural images gans produce impressive results interpolations latent space generator produce smooth plausible semantic variations certain directions space correspond particular semantic attributes along data distribution varies. example radford showed trained database human faces learns associate particular latent directions gender presence eyeglasses. natural question arises ostensible semantic juice ﬂowing weights generators learned using framework gans used unsupervised learning rich feature representations arbitrary data distributions? obvious issue generator maps latent samples generated data framework include inverse mapping data latent representation. hence propose novel unsupervised feature learning framework bidirectional generative adversarial networks overall model depicted figure short addition generator standard framework bigan includes encoder maps data latent representations bigan discriminator discriminates data space jointly data latent space versus latent component either encoder output generator input obvious description bigan encoder learn invert generator modules cannot directly communicate another encoder never sees generator outputs computed) vice versa. section argue intuitively formally prove encoder generator must learn invert another order fool bigan discriminator. bigan encoder learns predict features given data prior work gans demonstrated features capture semantic attributes data hypothesize trained bigan encoder serve useful feature representation related semantic tasks fully supervised visual models trained predict semantic labels given images serve powerful feature representations related visual tasks. context latent representation thought label came free without need supervision. alternative approach learning inverse mapping data latent representation directly model predicting generator input given generated data we’ll refer alternative latent regressor later arguing bigan encoder preferable feature learning context well comparing approaches empirically. bigans robust highly generic approach unsupervised feature learning making assumptions structure type data applied theoretical results demonstrate. empirical studies show despite generality bigans competitive contemporary approaches self-supervised weakly supervised feature learning designed speciﬁcally notoriously complex data distribution natural images. dumoulin independently proposed identical model concurrent work exploring case stochastic encoder ability models learn semi-supervised setting. distribution data goal generative modeling capture data distribution using probabilistic model. unfortunately exact modeling probability density function computationally intractable trivial models. generative adversarial networks instead model data distribution transformation ﬁxed latent distribution transformation called generator expressed deterministic feed forward network ez∼pz goal train generator framework trains generator discriminative model distinguish samples data distribution samples generative distribution. generator discriminator learned using adversarial objective goodfellow showed ideal discriminator objective maxd equivalent jensen-shannon divergence distributions adversarial objective directly lend efﬁcient optimization step generator requires full discriminator learned. furthermore perfect discriminator longer provides gradient information generator gradient global local maximum provide strong gradient signal nonetheless goodfellow slightly alter objective generator discriminator updates keeping ﬁxed point characteristics. also propose optimize using alternating optimization switching updates generator discriminator. optimization guaranteed converge empirically works well discriminator generator well balanced. despite empirical strength gans generative models arbitrary data distributions clear applied unsupervised feature representation. possibility learning representations learn inverse mapping regressing generated data back latent input however unless generator perfectly models data distribution nearly impossible objective complex data distribution high-resolution natural images idea prove insufﬁcient. bidirectional generative adversarial networks train generator additionally train encoder encoder induces distribution mapping data points latent feature space generative model. discriminator also modiﬁed take input latent space predicting real generated pz). bigan training objective deﬁned minimax objective bigans share many theoretical properties gans additionally guaranteeing global optimum other’s inverse. bigans also closely related autoencoders loss function. following sections highlight appealing theoretical properties bigans. deﬁnitions pgpz pepx joint distributions modeled generator encoder respectively. joint latent measures regions refer features data samples support supp supp respectively. respectively denote kullback-leibler jensen-shannon divergences probability measures deﬁnition ex∼p start characterizing optimal discriminator generator encoder following goodfellow optimal discriminator allows reformulate objective show reduces jensen-shannon divergence joint distributions pgz. proposition optimal discriminator radon-nikodym derivative measure pgz. theorem global minimum achieved pgz. point proof. proposition jensenshannon divergence therefore global minimum occurs point value finally implies optimal discriminator chance optimal discriminator encoder generator bigan similar optimal discriminator generator framework however important difference bigan optimizes jensen-shannon divergence joint distribution data latent features joint divergence allows characterize properties shown below. ﬁrst present intuitive argument that order fool perfect discriminator deterministic bigan encoder generator must invert other. certainty satisﬁed must encoder pair satisﬁed must generator pair therefore order fool perfect discriminator must satisfy case substitute equality required equality required vice versa giving inversion properties formally show theorem optimal generator encoder invert another almost everywhere support theorem optimal encoder generator almost everywhere; px-almost every pz-almost every theorem characterizes encoder decoder optimum non-convex nature optimization optimum might never reached. experimentally section shows standard datasets approximate inverses; however rarely exact inverses. thus also interesting show objective bigan optimizes terms next show bigans closely related autoencoders loss function. argued section model trained predict features given data learn useful semantic representations. show bigan objective forces encoder exactly this order fool discriminator particular encoder must invert generator proof. given appendix indicator function )=x] ﬁrst term equivalent autoencoder loss indicator )=z] second term shows bigan encoder must invert generator desired property feature learning. objective encourages functions produce valid outputs support respectively. unlike regular autoencoders loss function make assumptions structure distribution data itself; fact structural properties bigan learned part discriminator. practice framework bigan module parametric function whole bigan optimized using alternating stochastic gradient steps. iteration discriminator parameters updated taking steps positive gradient direction encoder parameters generator parameters together updated taking step negative gradient direction −∇θe cases expectation terms goodfellow found objective real generated labels swapped provides stronger gradient signal similarly observed bigan training inverse objective provides stronger gradient signal efﬁciency also update modules simultaneously iteration rather alternating updates updates. appendix details. often useful parametrize output generator encoder different usually smaller space rather original example visual feature learning images input encoder similar resolution images used evaluation. hand generating high resolution images remains difﬁcult current generative models. situation encoder take higher resolution input generator output discriminator input remain resolution. generalize bigan objective functions encoder discriminator identity yields original objective. visual feature learning higher resolution encoder inputs image resizing function downsamples high resolution image lower resolution image output generator. case encoder generator respectively induce probability measures regions joint space pxe)∈r] deﬁned analogously. optimal show generalization theorem deterministic optimal theorem invert another also generalized px-almost every evaluate feature learning capabilities bigans ﬁrst training unsupervised described section transferring encoder’s learned feature representations auxiliary supervised learning tasks. demonstrate bigans able learn meaningful feature representations arbitrary data vectors model agnostic underlying structure well high-dimensional complex distributions evaluate permutation-invariant mnist high-resolution natural images imagenet experiments module parametric deep network. bigan discriminator takes data initial input linear layer thereafter latent representation transformed using learned linear transformation hidden layer dimension added non-linearity input. besides bigan framework presented above considered alternative approaches learning feature representations using different variants. discriminator discriminator standard takes data samples input making learned intermediate representations natural candidates feature representations related tasks. table nearest neighbors classiﬁcation accuracy permutation-invariant mnist test feature space learned bigan latent regressor joint latent regressor autoencoder using distance. alternative appealing requires additional machinery approach used unsupervised feature learning radford hand clear task distinguishing real generated data requires beneﬁts intermediate representations useful semantic feature representations. fact successfully generates true data distribution ignore input data entirely predict unconditionally learning meaningful intermediate representations. latent regressor consider alternative encoder training minimizing reconstruction loss jointly regular training called latent regressor joint latent regressor respectively. sigmoid cross entropy loss naturally maps uniformly distributed output space. intuitively drawback approach that unlike encoder bigan latent regressor encoder trained generated samples never sees real data issue theoretical optimum exactly i.e. perfectly generates data distribution practice highly complex data distributions distribution natural images generator almost never achieve perfect result. fact real data never input type encoder limits utility feature representation related tasks shown later section. ﬁrst present results permutation-invariant mnist permutationinvariant setting digit image must treated unstructured vector case condition designing module multi-layer perceptron agnostic underlying spatial structure data appendix architectural training details. latent distribution continuous uniform distribution. table compares encoding learned bigan-trained encoder baselines described section well autoencoders trained directly minimize either reconstruction error. architecture optimization algorithm used across methods. methods including bigan perform roughly level. result overly surprising given relative simplicity mnist digits. example digits generated nearly perfectly match data distribution making latent regressor baseline method reasonable choice argued section qualitative results presented figure figure convolutional ﬁlters learned three modules bigan trained imagenet database. compare ﬁlters learned discriminator trained architecture well ﬁlters reported noroozi favaro krizhevsky fully supervised imagenet training data often capture interesting aspects. here convnet. experiments encoder architecture follows alexnet ﬁfth last convolution layer also experiment alexnet-based discriminator baseline feature learning approach. latent distribution continuous uniform distribution. additionally experiment higher resolution encoder input images rather used elsewhere using generalization described section appendix architectural training details. qualitative results convolutional ﬁlters learned three modules shown figure ﬁlters learned encoder clear gabor-like structure similar originally reported fully supervised alexnet model ﬁlters also similar grouping structure half color sensitive half edge sensitive. table classiﬁcation accuracy imagenet lsvrc validation various portions network frozen reinitialized trained scratch following evaluation noroozi favaro e.g. conv column ﬁrst three layers conv conv transferred frozen last layers conv conv fully connected layers reinitialized trained fully supervised imagenet classiﬁcation. bigan competitive contemporary visual feature learning methods despite generality. directly comparable methods different base convnet architecture larger intermediate feature maps used.) bigan encoder generator learn approximate inverse mappings shown theoretically theorem appendix present nearest neighbors bigan learned feature space. imagenet classiﬁcation following noroozi favaro evaluate freezing ﬁrst layers pretrained network randomly reinitializing training remainder fully supervised imagenet classiﬁcation. results reported table classiﬁcation detection segmentation evaluate transferability bigan representations pascal computer vision benchmark tasks including classiﬁcation object detection semantic segmentation. classiﬁcation task involves simple binary prediction presence absence given image object categories. object detection semantic segmentation tasks step requiring objects localized semantic segmentation requiring ﬁnest scale pixelwise prediction object identity. detection pretrained model used initialization fast r-cnn training; semantic segmentation model used initialization fully convolutional network training case replacing alexnet model trained fully supervised imagenet classiﬁcation. report results tasks table comparing bigans contemporary approaches unsupervised self-supervised feature learning visual domain well baselines discussed section despite making assumptions underlying structure data bigan unsupervised feature learning framework offers representation competitive existing self-supervised even weakly supervised feature learning approaches visual feature learning still purely generative model ability sample data predict latent representation furthermore bigans outperform discriminator latent regressor baselines discussed section conﬁrming intuition approaches perform well regime highly complex data distributions natural images. version encoder takes higher resolution image output generator performs better still strategy possible baselines modules take generator outputs input. although existing self-supervised approaches shown impressive performance thus tended outshine purely unsupervised approaches complex domain high-resolution images purely unsupervised approaches feature learning pre-training several potential beneﬁts. table classiﬁcation fast r-cnn detection results pascal test segmentation results pascal validation standard mean average precision mean intersection union metrics task. classiﬁcation models trained various portions alexnet model frozen. column linear classiﬁer learned case bigan randomly initialized fully connected layers column three layers trained fully supervised convolution layers frozen. finally column entire network ﬁne-tuned. bigan outperforms unsupervised feature learning approaches including gan-based baselines described section despite generality competitive contemporary self-supervised feature learning approaches speciﬁc visual domain. bigan unsupervised learning approaches agnostic domain data. self-supervised approaches speciﬁc visual domain cases requiring weak supervision video unavailable images alone. example methods applicable permutation-invariant mnist setting explored section data treated vectors rather images. furthermore bigan unsupervised approaches needn’t suffer domain shift pre-training task transfer task unlike self-supervised methods aspect data normally removed corrupted order create non-trivial prediction task. context prediction task network sees small image patches global image structure unobserved. context encoder inpainting task image corrupted removing large areas ﬁlled prediction network creating inputs dramatically different appearance uncorrupted natural images seen transfer tasks. approaches rely auxiliary information unavailable static image domain video egomotion tracking. unlike bigan approaches cannot learn feature representations unlabeled static images. ﬁnally note results presented constitute preliminary exploration space model architectures possible bigan framework expect results improve signiﬁcantly advancements generative image models discriminative convolutional networks alike. authors thank evan shelhamer jonathan long berkeley vision labmates helpful discussions throughout work. work supported darpa afrl muri award awards iis- iis- berkeley artiﬁcial intelligence research laboratory. gpus used work donated nvidia. jeff donahue yangqing oriol vinyals judy hoffman ning zhang eric tzeng trevor darrell. decaf deep convolutional activation feature generic visual recognition. icml yangqing evan shelhamer jeff donahue sergey karayev jonathan long ross girshick sergio guadarrama trevor darrell. caffe convolutional architecture fast feature embedding. arxiv. olga russakovsky deng jonathan krause sanjeev satheesh sean zhiheng huang andrej karpathy aditya khosla michael bernstein alexander berg fei-fei imagenet large scale visual recognition challenge. ijcv proposition encoder generator’s objective optimal discriminator maxd rewritten terms jensen-shannon divergence measures proof. using proposition along generator stochastic deterministic theorems assume encoder generator deterministic functions; i.e. conditionals deﬁned functions. shown proposition bigan objective equivalent jensen-shannon divergence pgz. step show jensen-shannon divergence closely related standard autoencoder loss. omitting scale factor divergence term jensen-shannon divergence given proposition ensures deﬁned pex-almost everywhere well-deﬁned. next show mimics autoencoder loss meaning zero region non-zero otherwise. proposition divergence outside support zero we’ll ﬁrst show region supp pex-almost everywhere. region let’s assume non-zero measure. then using deﬁnition radon-nikodym derivative εpex constant smaller contradiction; hence pex-almost everywhere implying pex-almost everywhere hence deﬁnition also zero. region might non-zero supp supp. finally propositions pex-almost everywhere therefore taking ﬁnite strictly negative value pex-almost everywhere. analogous argument lets rewrite divergence term section provide additional details bigan learning protocol summarized section goodfellow found training objective real generated labels swapped provides stronger gradient signal similarly observed bigan training inverse objective provides stronger gradient signal practice updated moving positive gradient direction inverse objective rather negative gradient direction original objective. also observed learning behaved similarly parameters updated simultaneously iteration rather alternating updates updates took simultaneous updating approach computational efﬁciency. following sections present additional details models training protocols used permutation-invariant mnist imagenet evaluations presented section optimization unsupervised training bigans baseline methods adam optimizer compute parameter updates following hyperparameters used radford step size decayed exponentially starting halfway training. mini-batch size weight decay applied multiplicative weights linear layers weights initialized zero-mean normal distribution standard deviation notable exception bigan discriminator weights directly multiply inputs added spatial convolution outputs initializations scaled convolution kernel size e.g. kernel weights initialized standard deviation times standard initialization. software hardware implement bigans baseline feature learning methods using theano framework based convolutional implementation provided radford imagenet transfer learning experiments caffe framework fast r-cnn reference implementations. computation performed nvidia titan tesla gpu. permutation-invariant mnist experiments consist hidden layers units. ﬁrst hidden layer followed non-linearity; second followed batch normalization non-linearity. second hidden layer case input linear prediction layer appropriate size. leaky relu non-linearity leak used; standard relu non-linearity used. models trained epochs. imagenet experiments encoder architecture follows alexnet ﬁfth last convolution layer local response normalization layers removed batch normalization leaky relu non-linearity applied output convolution unsupervised training time. experiments discriminator generator architecture used radford consisting series four convolutions applied pixel stride followed batch normalization rectiﬁed non-linearity. sole exception discriminator baseline feature learning experiment discriminator alexnet variant described above. generally using alexnet discriminator detrimental visual ﬁdelity resulting generated images likely relatively large convolutional ﬁlter kernel size applied input image well max-pooling layers explicitly discard information input. however fair comparison discriminator’s feature learning abilities bigans architecture used bigan encoder. preprocessing produce data sample ﬁrst sample image database resize proportionally shorter edge length pixels. then crop randomly selected resized image. crop ﬂipped horizontally probability finally crop scaled giving sample", "year": 2016}