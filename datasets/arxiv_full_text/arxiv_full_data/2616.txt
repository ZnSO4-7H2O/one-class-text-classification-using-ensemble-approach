{"title": "Learning Interpretability for Visualizations using Adapted Cox Models  through a User Experiment", "tag": ["stat.ML", "cs.AI", "cs.HC", "cs.LG"], "abstract": "In order to be useful, visualizations need to be interpretable. This paper uses a user-based approach to combine and assess quality measures in order to better model user preferences. Results show that cluster separability measures are outperformed by a neighborhood conservation measure, even though the former are usually considered as intuitively representative of user motives. Moreover, combining measures, as opposed to using a single measure, further improves prediction performances.", "text": "order useful visualizations need interpretable. paper uses userbased approach combine assess quality measures order better model user preferences. results show cluster separability measures outperformed neighborhood conservation measure even though former usually considered intuitively representative user motives. moreover combining measures opposed using single measure improves prediction performances. measuring interpretability major concern machine learning. along classical performance measures accuracy interpretability deﬁnes limit black-box white-box models interpretable models allow understand inputs linked output. paper focuses visualizations high-dimensional data projection. context interpretability refers ability user understand particular visualization model projects data. user chooses particular visualization implicitly states understands points presented i.e. model works. interpretability deﬁned user preferences priori deﬁnition assumed. following freitas others bibal frénay highlights ways measure interpretability heuristics user-based surveys. tailored quality measures visualizations examples heuristics approach. surveys used qualitatively deﬁne understandability visualization asking user feedback. approaches complementary works attempt assess relevance several quality metrics visualization. paper bridges user-based experiment uses meta-learning combine several measures visualization interpretability. section presents visualization quality measures used meta-learning. section introduces family white-box meta-models score interpretability. then section describes user experiment used model interpretability user preferences. finally section discusses experimental results section concludes paper. consider types quality measures visualizations type uses data projection compares points projection. typical measures ﬁrst type focus separability clusters visualization. sedlmair aupetit reviewed evaluated sorted measures terms algorithmic similarity agreement measures sedlmair aupetit hypothesis margin average between-within computes average difference distance point closest neighbor another class closest neighbor class computes ratio average distance points different clusters average distance within clusters. order compare visualization algorithms propose measure second type modeling neighborhood preservation. measure nhauc deﬁned follows. number points dataset number neighbors nearest neighbors point original dataset main goal paper evaluate whether combining state-of-the-art measures different types improve modeling human judgment. asses this experiment asking users express preferences visualizations shown pairs used preferences determine interpretability score. since dataset composed preferences visualizations learning problem rooted preference learning. kind problem order must learned based preferences dataset consists visualizations user-given preferences expressing preferred pairs visualization preference learning algorithm considered modeling user preferences must interpretable logistic regression knowledge measures used meta-features gained. solve problem consider well-known interpretable model used survival analysis model adapted model preference learning problem. indeed case pairwise comparisons objects partial likelihood model adapted follows adapted model learns preference score using measures presented section features visualizations regression differs true logistic regression intercept term. term interpreted understandability score visualization mentioned section experiment collect preferences users. visualizations presented users generated dataset mnist various numbers classes using t-sne various perplexities dataset size logarithmic scale. user interviewed experiment discuss strategies choosing visualizations. used information better understand cases coxpref models agreement user preferences. population experiment consisted ﬁrst-year university students. instructed select displayed visualizations best understood computer positioned numbers. addition options could also select preference case comparison used learning. successive comparisons assumed independent meaning psychological learning bias assumed involved. total preferences collected. user different strategy choosing visualizations grouped batches user. given user random subset preferences selected total number preferences users. thanks subsampling users weight modeling overall strategy. number preferences user aside users provided less preferences; dataset composed preferences. user permutations performed. permutation users used training coxpref model testing. performance measure percentage agreement users model. used performance measure individually compare visualization measures used meta-features. addition types measures presented section number classes also considered meta-learning case visualization chosen randomly. table shows means standard deviations computed permutations table presents percentage measures. measure better performances permutation among measures ﬁrst type discussed section performs well group beaten nhauc measure second type. interestingly nhauc obtains good results despite fact directly apply well-known user-strategy cluster separability strategy conﬁrmed interviews. indeed measures second type original high-dimensional data computation possible human. table coxpref model outperforms individual measures. similar results observed using preferences users. order understand coxpref models fail cases average checked judgment errors coxpref referring users said interviews. could observe involving users open opportunity mistakes unusual behaviors ﬁgure furthermore cases user preference distinguishes semantic pattern makes sense visualization tends choose order assess importance visualization measure score coxpref varied penalization enforce sparsity. nhauc selected ﬁrst. added improvement roughly number classes added third measure improves model roughly additional measures offer minor improvement. using adapted model handle task preference learning observed modeling power measure taking account elements human cannot handle nhauc. furthermore conﬁrmed position leader category. finally showed using white-box model aggregate state-of-the-art measures improve prediction human judgment using information measures different families. work needs conﬁrm results obtained t-sne mnist wide range datasets visualization schemes. figure examples disagreement users coxpref. among visualizations coxpref prefers clearly separated whereas user preferred visualization shows example semantic bias users reported preferred looks like clock grateful prof. bruno dumas help design experiment involving users. also thanks samuel branders fruitful discussions sharing resources models.", "year": 2016}