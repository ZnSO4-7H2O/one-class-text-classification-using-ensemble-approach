{"title": "Dempster-Shafer clustering using Potts spin mean field theory", "tag": ["cs.AI", "cs.NE", "I.2.3; I.2.6; I.5.3"], "abstract": "In this article we investigate a problem within Dempster-Shafer theory where 2**q - 1 pieces of evidence are clustered into q clusters by minimizing a metaconflict function, or equivalently, by minimizing the sum of weight of conflict over all clusters. Previously one of us developed a method based on a Hopfield and Tank model. However, for very large problems we need a method with lower computational complexity. We demonstrate that the weight of conflict of evidence can, as an approximation, be linearized and mapped to an antiferromagnetic Potts Spin model. This facilitates efficient numerical solution, even for large problem sizes. Optimal or nearly optimal solutions are found for Dempster-Shafer clustering benchmark tests with a time complexity of approximately O(N**2 log**2 N). Furthermore, an isomorphism between the antiferromagnetic Potts spin model and a graph optimization problem is shown. The graph model has dynamic variables living on the links, which have a priori probabilities that are directly related to the pairwise conflict between pieces of evidence. Hence, the relations between three different models are shown.", "text": "relative large scale problems. weights priori using con¯ict dempster's rule thus learning process utilized. clustering approach represented great improvement computational complexity compared previous method based iterative optimization although clustering performance equally good. order improve clustering performance hybrid methods also developed recent paper method extended simultaneous clustering determination number clusters iteration neural structure. here neuron output signals represent degree pieces evidence belong corresponding clusters. signals derive probability distribution regarding number clusters gradually iteration transformed determination number clusters. probability distribution back neural structure iteration in¯uence clustering process. large problems need method still lower computational complexity achieved far. attained without sacri®cing clustering performance comparison previous neural method antiferromagnetic potts model powerful solver large dempster±shafer clustering problems. second article purely theoretical; show antiferromagnetic potts model isomorphic graph optimization problem. seem misplaced ®rst glance variables dempster±shafer model natural interpretation terms graph model. papers initially intended preprocessing intelligence information situation analysis antisubmarine warfare developed method much lower computational complexity believe serve general solution preprocessing intelligence data information fusion sect. describe basics dempster±shafer theory. section presents potts spin model corresponding clustering model discussed sect. section shows linearized dempster±shafer con¯ict function maps antiferromagnetic potts model. isomorphism potts model graph model developed sect. resulting relation dempster±shafer model graph model investigated sect. finally sect. compare clustered clusters minimizing metacon¯ict function equivalently minimizing weight con¯ict clusters. previously developed method based hop®eld tank model. however large problems need method lower computational complexity. demonstrate weight con¯ict evidence approximation linearized mapped antiferromagnetic potts spin model. facilitates ef®cient numerical solution even large problem sizes. optimal nearly optimal solutions found dempster±shafer clustering benchmark tests time complexity approximately antiferromagnetic potts spin model graph optimization problem shown. graph model dynamic variables living links priori probabilities directly related pairwise con¯ict pieces evidence. hence relations three different models shown. ntroduction article develop method clustering evidence large scale problems within dempster±shafer theory consider case evidence come multiple events handled independently known event piece evidence related. clustering process separate evidence subsets event subset handled separately. bengtsson schubert department data information fusion division command control warfare technology swedish defence research agency stockholm sweden e-mail schubertfoi.se http//www.foi.se/fusion/ physics spin systems quite different area science utilized here. hop®eld model based physics ising spins review) ®rst model bridge spin systems computer science gained wider interest. potts model generalization ising model spin arbitrary degree freedom instead two. proven useful many complex optimization problems clustering performance computational complexity three different clustering methods potts spin clustering developed article previous developed neural clustering method inspired hop®eld tank iterative optimization initially developed. dempster±shafer theory belief assigned proposition basic probability assignment. proposition represented subset exhaustive mutually exclusive possibilities frame discernment basic probability assignment receive second item information concerning issue different source items combined yield informed view. combining belief functions done calculating orthogonal combination using dempster's rule. simply illustrated combination basic probability belief although situation considered article. partition simply allocation pieces evidence different events. since pieces evidence corresponding different events unrelated evidence belonging particular event analyzed within dempster±shafer paradigm independently pieces evidence. known priori event piece information corresponding problem. could impossible know directly different pieces evidence corresponding event. know subset not. precisely problem facing article. task organize evidence different classes class precisely corresponds particular event unique way. dempster's rule pieces evidence within subset combined indication whether pieces evidence belong together. higher con¯ict less credible belong together. metacon¯ict function reasoning multiple events established. metacon¯ict derived plausibility partitioning correct con¯ict subset viewed piece metalevel evidence partitioning evidence subsets class; sites different classes penalty. spins formalism describe problem terms problem consists minimizing energy function ¯ipping spins different states. spin ¯ipping process takes place simulated annealing whereby complete spin system viewed contained thermal reservoir certain temperature. high temperature spins less random marginally biased interactions temperature lowered discontinuous phenomena phase transitions occur. phase transition parts system become constrained other freeze. finally complete system frozen spins completely biased interactions that hopefully minimum energy function reached. monte carlo simulation spins actual stochastic states simulation usually time consuming. instead mean ®eld model spins deterministic usually time ef®cient. potts model used various forms clustering data complex optimization problems receive several pieces evidence different separate events pieces evidence mixed task arrange according event referring thus partition pieces evidence subsets subset refers particular event. fig. subsets denoted con¯ict pieces evidence combined dempster's rule denoted here thirteen pieces evidence partitioned four subsets. number subsets uncertain also ``domain con¯ict'' con¯ict current hypothesis number subsets prior method partitioning evidence subsets corresponding events. method also handle situation number events uncertain. this subset refers different event reasoning take place event treated separately. nonleading order terms suppressed powers smaller one. moreover con¯ict purely con¯ict free con®guration zero cases. thus actual minimization slightly overestimates con¯ict within subset. port function evidence points precisely unambiguously single nonempty subset simple support function focused basic probability numbers denoted simple support functions focused respectively combined weight con¯ict particular handle data pairwise terms. therefore necessary simplify con¯ict function write con¯ict support functions pairwise con¯icts i.e. linearize con¯ict function. approximation constraint free form clustering consequently benchmark studies dif®cult perform parametric clustering well de®ned energy function optimized. sparsely distributed gaussian clusters size analytical estimates optimal bayes limit made agree fairly large precision numerical results mean ®eld potts model numerical results dempster±shafer clustering discussed sect. contrast naõève expectations feature makes problem simpler solve quite opposite. simulated annealing temperature lowered phase transition occurs corner system freeze partly state corresponding global minima another corner system freezes another global minimum state. border states certainly going give rise additional energy results nonoptimal solution. called frustration studied extensively highly frustrated spin glass models ising spins review). well known mean ®eld theory suitable study spin glass models seen below acceptable solutions found cases dempster±shafer clustering problems. indicates despite degenerate ground state frustration dif®cult problem here. terms clustering describes called parametric clustering data centered around ®ctitious class prototype. isomorphism potts model seen potts energy function expressed recursively dempster±shafer clustering model antiferromagnetic potts spin model solve problem itself virtue dynamics spins. discussed earlier statistical mechanics potts spin mean ®eld approximation supply necessary dynamics. using simulated annealing temperature acts control parameter that sequence phase transitions resolves ®ner ®ner details data; algorithmic structure well suited clustering problems. cost equipartition effect; minimum con®gurations equal number items cluster increases unbalance clusters. done favor balanced solutions intuitively appealing among different global optima. follows. precomputed highest critical temperature starting temperature. choose mean ®eld spins symmetric high temperature state; temperature iterate eqs. problematic events seldom completely empty cluster using equipartition term balanced partitions obtained risk introducing spurious minima. especially large problem sizes proves useful small a-term. exists known isomorphism ferromagnetic potts model graph model spins placed sites degrees freedom graph model bond variables placed edges sites. bond variable belikely bond ferromagnetic potts model corresponding graph model fact obtained marginal distributions combined model containing spins well dynamic bond variables hence dual description model possible either terms spins terms edges both. terministic clustering since ground state completely degenerated spins parallel. adding weak non-site-dependent antiferromagnetic term ferromagnetic system degeneracy broken nonparametric clustering solution obtained stage introduce notion spin cluster de®ned maximal sites identical spins. hand bond cluster maximal nonempty subset occupied bonds path occupied bonds bonds bond cluster relatively simple expression distribution bond model necessary assume full connectivity i.e. sites exists single edge directly connects them. words full connectivity means vertices path single edge. contains essentially pieces information. first vacant bond must nonidentical spins sites. follows also directly since different bond-clusters connected vacant bonds spin bond-cluster must different spin another bond-cluster. secondly spins gives combinatorial weight states generally different different con®gurations. product contains vacant bonds. dif®cult general result start simpli®cation. assume moment vacant bonds sites bond-cluster vacant bonds connect sites different bond-clusters. number sites partition spin directions among bond-clusters possible spin con®gurations. number con®gurations bond-cluster since constraints spins within bond-cluster. moreover qq\u0001\u0001\u0001 ways partition probability. clustering model interactions repellent increase ``distance.'' thus data sense ``close'' small also small bond probability vice versa. distribution pij's fig. illustration bond-clusters formed annealing. simplicity triangulation bonds bondcluster shown. bond-clusters chosen deterministically using condition question occupied bonds connecting different spin-clusters. since jij's independent interactions pij's dependent ones letting gives bond connecting different spin-clusters vacant probability according hence probability vacant bonds spin-clusters goes unity thus highly unlikely occupied. therefore ground state spin/bond model characterized localized spin-clusters bond-clusters identical spin-clusters bonds vacant inside bond-clusters. bond-cluster taken account previous analysis. instance bond-cluster contains single vacant bond number possible spin states reduced vacant bonds sites common cluster comn\u0000 binatorial factor cluster becomes cases additional constraint although combinatorial factors less number possible states with instance single vacant bond inside bond-cluster general large. reason alone con®gurations cannot neglected. turns con®gurations vacant bonds inside bond-clusters disappear ground state reached following reason. ground state spin system consists localized spin-clusters deal resemblance pairwise weight con¯ict. inverse temperature identi®ed therefore physical interpretation. moreover bond probabilities identi®ed product support events sisj. con¯ict interpreted terms graph model edges graph correspond con¯icting pieces evidence bond probability edge precisely product support sisj. points. statistical mechanics probability certain con®guration energy given boltzmann distribution e\u0000bei system freezes state lowest enconsider free energy de®ned consequently bonds ought vacant. however condition fng vacant. crudely speaking seek subject constraint fng easy implies fng thus single large bond-cluster high temperature broken smaller bondclusters temperature lowered eventually bond-clusters remain ground state. fig. illustrated behavior made triangulation sites belonging identical bond-clusters based condition corresponding ferromagnetic potts spin system bonds vacant high temperature occupied ground state. modi®ed ferromagnetic potts clustering model weak constant antiferromagnetic term added need produce single large bond-cluster ground state rather separate bond-clusters representing underlying data structure. issue needs attention; condition relaxed? direct interaction link consequently exist bond variable nij. quantitative analysis depends particular graph therefore practical perform. qualitatively easier happens. graph sparse enough sets sites direct interaction between them. instance exists non-empty sets sites without direct contact spins parallel without affecting energy system. de®nition spin-cluster adjusted mean sets parallel spins interaction them implies sets parallel spins form separate spin-clusters isolated other. thus need upper limit number spin-clusters. moreover probability distribution bonds modi®ed different combinatorial factors depend underlying graph. established connection linearized con¯ict function dempster±shafer theory antiferromagnetic potts spin model. also isomorphism potts model graph optimization problem described previous section. next step dempster±shafer problem graph model related. principle already demonstrated isomorphism linearized dempster±shafer model graph optimization problem. however slight modi®cation con¯ict function made much nicer relation derived. reason choose problem minimum metacon¯ict zero makes good test example evaluating performance. reason believe choice test examples atypical respect performance. potts spin clustering method much faster neural clustering method inspired hop®eld tank. problem clustering pieces evidence seven clusters potts spin methods computation time hop®eld tank type neural clustering computation time difference items evidence) changed independently test examples evidence rather striking potts spin computation time scales small overhead noted smallest problem sizes. time complexity iterative optimization much worse neural methods also compare clustering performance three methods. cluster con¯icts vary strongly cluster cluster occasionally larger con¯icts found. table median mean metacon¯ict runs tabulated problem size method. important note that although optimizing linearized weight con¯ict actual con¯icts cluster calculated table potts spin method able global optimum problem sizes nine cluster. however teneleven-cluster problems metacon¯ict increases rapidly fig. type behavior found hop®eld tank method increase metacon¯ict arises already sixseven-cluster problems. iterative optimization good performance small problem sizes. entropy system. maximum likelihood estimate obtained minimizing subject constraint entropy constant. becomes lagrangian parameter controls average energy gives relative importance energy minimizaimportant note analysis jij's independent parameters pij's dependent ones parameterizes relation. given could choose either jij's pij's independent parameters. chapter compare clustering performance computational complexity three different methods dempster±shafer clustering. first potts spin clustering using simulated annealing discussed previously article. secondly neural clustering inspired hop®eld tank method developed extended investigated ®nally iterative optimization initially developed dempster±shafer clustering minimum metacon¯ict function equal zero since pieces evidence include -element cluster remaining evidence include -element cluster forth. since evidence cluster includes -element intersection nonempty since evidence cluster includes -element intersection also nonempty etc. thus con¯icts zero always table number mean randomly generated problems. potts spin method total number iterations needed depends strongly anneal parameters chosen. parameters chosen reduce number iterafig. gives good overview clustering performance three different methods picture might somewhat misleading evaluating performance. large part increase metacon¯ict increase problem size. cluster contributes total metacon¯ict number cluster increases total metacon¯ict increases well. order eliminate effect must calculate average metacon¯ict cluster. median mean metacon¯icts cluster tabulated problem sizes table notice smaller rise metacon¯ict cluster. instance clustering performance potts spin ten-cluster problem visibly much better hop®eld tank seven-cluster problem fig. fig. also observe wide difference median mean metacon¯ict cluster potts spin method eleven-cluster problem. hence ¯uctuation results large. method still able near optimal partitionings average partition yields higher metacon¯ict cluster. clear indication potts method reached limit produce perfect solutions still produces near optimal solutions. slightly larger problem sizes would still expect method reasonably good longer near optimal partitions. best measure clustering performance metacon¯ict evidence. simply divide average metacon¯ict cluster already found average number pieces evidence cluster table also take account exponential growth number items evidence number clusters grow. remarkable result potts model give signi®cant rise mean metacon¯ict evidence fig. true almost three orders magnitude. methods. able least global optimum zero con¯ict runs problem sizes eleven clusters except case clusters near miss overall metacon¯ict best run. miss result piece evidence small basic probability number misplaced yielding small con¯ict. threads followed paper. first pragmatic reader shown potts model ®nds optimal nearly optimal solutions dempster± shafer clustering problems every case. additionally computation time scales measured number items evidence. computational growth previous hop®eld tank model much lower constant. furthermore mean con¯ict cluster evidence shows signi®cant increase problem scaled valid least problem sizes varying three orders magnitude. three models linearized dempster±shafer antiferromagnetic potts spin model graph optimization problem. possibility interpret dempster± shafer clustering problem graph optimization problem appealing. developed potts spin model dempster± shafer clustering near perfect clustering performance reasonably good computational performance problem sizes think method serve solution preprocessing data many different applications especially intended application preprocessing intelligence data information fusion. bengtsson roivainen using potts glass solving clustering problem neural syst bergsten schubert dempster's rule evidence ordered complete directed acyclic graph approx reason bergsten schubert svensson applying data mining machine learning techniques submarine intelligence analysis. heckerman mannila pregibon uthurusamy proc third conf knowledge disbasic probability number piece evidence uniformly distributed random number thus expected con¯ict pieces evidence known con¯ict. therefore expected con¯ict pieces evidence drawn roughly times higher median times larger mean metacon¯ict evidence received eleven-cluster problem potts spin method table proof average metacon¯ict evidence obtained numerically corresponds much less con¯icting pair pieces evidence cluster. must considered good result given average pieces evidence cluster eleven-cluster problem pieces evidence drawn randomly pairs pairs cluster would con¯ict. different clustering methods able global minimum metacon¯ict function different runs different random basic probability numbers assigned evidence run. again fig. superiority potts spin method analogy potts model. touretzky mozer hasselmo advances neural information processing systems proc conf neural information processing systems press denver cambridge schubert cluster-based speci®cation techniques dempster±shafer theory. froidevaux kohlas symbolic quantitative approaches reasoning uncertainty proc european conf symbolic quantitative approaches reasoning uncertainty fribourg switzerland springer-verlag berlin schubert creating prototypes fast classi®cation dempster±shafer clustering. gabbay kruse nonnengart ohlbach qualitative quantitative practical reasoning proc first conf qualitative quantitative practical reasoning honnef germany springer-verlag berlin gradual determination number clusters using neural network structure. proc information decision control conf adelaide australia ieee piscataway smets practical uses belief functions. laskey prade proc fifteenth conf uncertainty arti®cial intelligence stockholm sweden morgan kaufmann publishers francisco", "year": 2003}