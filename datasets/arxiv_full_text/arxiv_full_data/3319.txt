{"title": "Deep multi-scale video prediction beyond mean square error", "tag": ["cs.LG", "cs.CV", "stat.ML"], "abstract": "Learning to predict future images from a video sequence involves the construction of an internal representation that models the image evolution accurately, and therefore, to some degree, its content and dynamics. This is why pixel-space video prediction may be viewed as a promising avenue for unsupervised feature learning. In addition, while optical flow has been a very studied problem in computer vision for a long time, future frame prediction is rarely approached. Still, many vision applications could benefit from the knowledge of the next frames of videos, that does not require the complexity of tracking every pixel trajectories. In this work, we train a convolutional network to generate future frames given an input sequence. To deal with the inherently blurry predictions obtained from the standard Mean Squared Error (MSE) loss function, we propose three different and complementary feature learning strategies: a multi-scale architecture, an adversarial training method, and an image gradient difference loss function. We compare our predictions to different published results based on recurrent neural networks on the UCF101 dataset", "text": "learning predict future images video sequence involves construction internal representation models image evolution accurately therefore degree content dynamics. pixel-space video prediction viewed promising avenue unsupervised feature learning. addition optical studied problem computer vision long time future frame prediction rarely approached. still many vision applications could beneﬁt knowledge next frames videos require complexity tracking every pixel trajectory. work train convolutional network generate future frames given input sequence. deal inherently blurry predictions obtained standard mean squared error loss function propose three different complementary feature learning strategies multi-scale architecture adversarial training method image gradient difference loss function. compare predictions different published results based recurrent neural networks dataset. unsupervised feature learning video representations promising direction research resources quasi-unlimited progress remaining achieve area quite important. paper address problem frame prediction. signiﬁcant difference classical problem image reconstruction ability model predict future frames requires build accurate trivial internal representations even absence constraints therefore postulate better predictions system better feature representation indeed work srivastava demonstrates learning representations predicting next sequence image features improves classiﬁcation results action recognition datasets. work however focus predicting directly pixel space address inherent problems related approach. performing algorithms action recognition exploit temporal information supervised convolutional network tran spatio-temporal convolutional model simonyan zisserman require months training heavily labeled datasets. could reduced using unsupervised learning. authors compete supervised learning performance imagenet using siamese architecture mine positive negative examples patch triplets videos unsupervised fashion. unsupervised learning video also exploited work vondrick convolutional model trained predict sets future possible actions focuses learning feature space equivariant ego-motion. goroshin trained convolutional network learn linearize motion code space tested norb dataset. beside unsupervised learning video predictive system applications robotics video compression inpainting name few. recently predicting future video sequences appeared different settings ranzato deﬁned recurrent network architecture inspired language modeling predicting frames discrete space patch clusters. srivastava adapted lstm model future frame prediction. deﬁned action conditional autoencoder model predict next frames atari-like games. works dealing natural images blur effect observed predictions different causes. transformation back forth pixel clustered spaces involves averaging predictions overlapping tilings image order avoid blockiness effect result. short term results srivastava less blurry however loss function inherently produces blurry results. indeed using loss comes assumption data drawn gaussian distribution works poorly multimodal distributions. work address problem lack sharpness predictions. assess different loss functions show generative adversarial training successfully employed next frame prediction ﬁnally introduce loss based image gradients designed preserve sharpness frames. combining losses produces visually satisfying results. paper organised follows model section describes different model architectures simple multi-scale adversarial presents gradient difference loss function. experimental section compares proposed architectures losses video sequences sportsm dataset karpathy compare results measure quality image generation computing similarity sharpness measures. models sequence frames predict input frames video sequence. approach based convolutional network alternating convolutions rectiﬁed linear units network displayed figure trained predict several concatenated frames concatenated frames minimizing distance instance predicted frame true frame however network least major ﬂaws convolutions account short-range dependencies limited size kernels. however using pooling would part solution since output resolution input. number ways avoid loss resolution brought pooling/subsampling preserving long-range dependencies. simplest oldest pooling/subsampling many convolution layers another method connections skip pooling/unpooling pairs preserve high frequency information finally combine multiple scales linearly reconstruction process laplacian pyramid approach paper. using loss lesser extent produces blurry predictions increasingly worse predicting future. probability distribution output pixel equally likely modes value vavg minimizes loss data even vavg probability. case norm effect diminishes disappear output value would median equally likely values. tackle problem making model multi-scale. multi-scale version model deﬁned follows snscales sizes inputs network. typically experiments upscaling operator toward size denote downscaled versions size network learns predict coarse guess recursively deﬁne network makes prediction size therefore network makes series predictions starting lowest resolution uses prediction size starting point make prediction size sk+. lowest scale network takes input. architecture illustrated figure speciﬁc details given section trainable parameters denoted minimization performed stochastic gradient descent despite multi-scale architecture search without making assumption space possible conﬁgurations still leads blurry predictions problem order reduce effect next sections introduce adversarial strategy image gradient difference loss. generative adversarial networks introduced goodfellow images patches generated random noise using networks trained simultaneously. work authors propose discriminative network estimate probability sample comes dataset instead produced generative model models simultaneously trained learns generate frames hard classify learns discriminate frames generated ideally trained possible perform better chance. adapted approach purpose frame prediction constitutes knowledge ﬁrst application adversarial training video prediction. generative model typically described previous section. discriminative model takes sequence frames trained predict probability last frames sequence generated note last frames either real generated rest sequence always dataset. allows discriminative model make temporal information learns produce sequences temporally coherent input. since conditioned input frames variability input generator even absence noise noise main intuition adversarial loss theoretically address problem mentioned section imagine sequence frames which dataset next frames either equal probability. explained before training network loss result predicting average frames yavg however sequence composed frames followed frames yavg likely sequence discriminate easily. sequences model able classify fake discriminative model multi-scale convolutional network single scalar output. training pair consists alternated steps described below. sake clarity assume pure difﬁculty generalize algorithm minibatches size summing losses samples. training sample dataset. note sequence frames. train classify input class input class precisely scale perform iteration keeping weights ﬁxed. trained target datapoint target therefore loss function train minimizing loss means generative model making discriminative model confused possible sense discriminate prediction correctly. however practice minimizing loss alone lead instability. always generate samples confuse without close turn learn discriminate samples leading generate confusing samples address problem train generator combined loss composed adversarial loss loss generator therefore trained minimize λadvlg λplp. therefore tradeoff adjust mean λadv parameters sharp predictions adversarial principle similarity ground truth brought second term. process summarized algorithm minibatches size another strategy sharpen image prediction directly penalize differences image gradient predictions generative loss function. deﬁne loss function gradient difference loss combined and/or adversarial loss function. function ground truth image prediction given integer greater equal denotes absolute value function. best knowledge closest related work idea work mahendran vedaldi using total variation regularization generate images learned features. fundamentally different total variation takes reconstructed frame input whereas loss penalises gradient differences prediction true output. second chose simplest possible image gradient considering neighbor pixel intensities differences rather adopting sophisticated norm larger neighborhood sake keeping training time low. provide quantitative evaluation quality video predictions sportsm video clips. train compare conﬁgurations input frames predict future frame. order generate future apply model recursively using newly generated frame input. input frames produce frames simultaneously. second conﬁguration represents signiﬁcantly harder problem presented appendix. sportsm training frames small portion image actually moving rest ﬁxed background. train network randomly selecting temporal sequences patches pixels making sure show enough movement difference frames). data patches ﬁrst normalized values comprised present results several models. unless otherwise stated employed mutliscale architectures. baseline models using losses. gdl- model using combination loss; relative weights λgdl adversarial model uses adversarial loss weighted λadv finally adv+gdl model combination adversarial loss parameters λgdl generative model training generative model architecture presented table contains padded convolutions interlaced relu linearities. hyperbolic tangent added model ensure output values learning rate starts reduced time minibatch size case adversarial training take advantage hardware capabilities. train network small patches since fully convolutional seamlessly apply larger images test time. adversarial training discriminative model also presented table uses standard padded convolutions followed fully connected layers relu linearities. largest scale pooling added convolutions. network trained setting learning rate maximum possible value image intensities. also provide structural similarity index measure wang ranges larger score meaning greater similarity images. figure evaluation accuracy future frames prediction takes moving areas images account. left example frame predictions entire image ground truth; right images masked thresholded optical ﬂow. table comparison accuracy predictions test images. different models trained given frames predict next one. similarity sharpness measures evaluated areas movement. best model ﬁne-tuned training sportsm. dataset images still performed evaluation moving areas displayed figure epicflow method revaud compute different quality measures areas optical higher ﬁxed threshold similarity sharpness measures computed whole images given appendix. numbers clearly indicate strategies perform better predictions terms psnr ssim sharpness. multi-scale model brings improvement used norm outperform simple frame copy moving areas. model improves results since replaces mean median value individual pixel predictions. adversarial predictions leading gains ﬁnally combination multi-scale norm adversarial training achieves best psnr ssim sharpness difference measure. interesting note showed norm poor metric training predictive models psnr test time worst models trained optimising norm although psnr based metric. also include baseline presented ranzato courtesy piotr dollar extrapolates pixels next frame propagating optical previous ones. section compare results obtain grayscale images make predictions extract channel adv+gdl model. ranzato images generated averaging results obtained using different tiling avoid blockiness effect however creating instead blurriness effect. compare psnr ssim values ﬁrst predicted images figure default parameters epic flow computation transformed using matlab code http//vision.middlebury.edu/flow/code/flow-code-matlab.zip. least color channel lower replace corresponding pixel intensity output ground truth compute similarity measures resulting masked images. note results ranzato appear slightly lighter results normalization take place original images therefore errors given reﬂecting full capacity approach. tried apply blind deconvolution method krishnan improve ranzato different results. expected obtained sharpness scores higher image similarity measures deteriorated often contours predictions match exactly targets. importantly ranzato results appear static moving areas. visually optical result appears similar target closer look thin details reveals lines heads people bent squeezed. provided benchmark several strategies next frame prediction evaluating quality prediction terms peak signal noise ratio structural similarity index measure image sharpness. display results small video clips http//cs.nyu.edu/ ˜mathieu/iclr.html. presented architectures losses used building blocks sophisticated prediction models involving memory recurrence. unlike optical algorithms model fully differentiable ﬁne-tuned another task necessary. future work deal evaluation classiﬁcation performances learned figure comparison results basketball dunk dancing clips appearing display frame predictions method along zooms image. psnr ssim values computed moving areas images values parenthesis correspond second frame predictions measures. representations weakly supervised context instance dataset. another extension work could combination current system optical predictions. alternatively could replace optical predictions applications explicitly rereferences ascenso joao brites catarina pereira fernando. improving frame interpolation spatial motion smoothing pixel domain distributed video coding. eurasip conference speech image processing multimedia communications services bromley jane bentz james bottou l´eon guyon isabelle lecun yann moore cliff s¨ackinger eduard shah roopak. signature veriﬁcation using siamese time delay neural network. int. journal pattern recognition artiﬁcial intelligence goodfellow pouget-abadie jean mirza mehdi bing warde-farley david ozair sherjil courville aaron bengio yoshua. generative adversarial networks. nips jain viren murray joseph roth fabian turaga srinivas zhigulin valentin briggman kevin helmstaedter moritz denk winfried seung sebastian supervised learning image restoration convolutional networks. ranzato marc’aurelio szlam arthur bruna joan mathieu micha¨el collobert ronan chopra sumit. video modeling baseline generative models natural videos. corr abs/. revaud jerome weinzaepfel philippe harchaoui zaid schmid cordelia. epicflow edgepreserving interpolation correspondences optical flow. computer vision pattern recognition section trained different multi-scale models architecture described table input frames predict frames simultaneously. image similarity measures given ground truth predictions table ﬁrst eighth predicted frames numbers clearly indicate strategies perform better predictions terms psnr sharpness. model replacing mean intensity median value individual pixel predictions allows improve results. adversarial predictions leading gains ﬁnaly allows predictions achieve best pnsr sharpness. note size network employed simultaneous prediction conﬁguration smaller unique frame prediction setting. compared recursive frame prediction employed rest paper predicting several input simultaneouly leads better long term results worst shorter term ones. performances could reduced design time multi-scale strategies. figure shows comparison predictions based lstms using sequences patches model ranking established terms sharpness psnr remains unchanged sequences. employ setting inputs- output described table note lstm ﬁrst frame prediction sharper models predictions however looking longer term future gradient difference loss leads sharper results. comparing visually notice predictions suffer chessboard effect case. hand employing recursive strategy adversarial training lead much sharper predictions. look like anything close ground truth long term remains realistic. trained model described table different losses predict frame previous ones. provide table similarity sharpness measures different tested models predictions frame predict. evaluation performed full images really meaningful predicting future location static pixels accurately done copying last input frame. table comparison accuracy predictions test images. different models trained given frames predict next one. similarity sharpness measures full images.", "year": 2015}