{"title": "Generate Image Descriptions based on Deep RNN and Memory Cells for  Images Features", "tag": ["cs.CV", "cs.CL", "cs.LG"], "abstract": "Generating natural language descriptions for images is a challenging task. The traditional way is to use the convolutional neural network (CNN) to extract image features, followed by recurrent neural network (RNN) to generate sentences. In this paper, we present a new model that added memory cells to gate the feeding of image features to the deep neural network. The intuition is enabling our model to memorize how much information from images should be fed at each stage of the RNN. Experiments on Flickr8K and Flickr30K datasets showed that our model outperforms other state-of-the-art models with higher BLEU scores.", "text": "generating natural language descriptions images challenging task. traditional convolutional neural network extract image features followed recurrent neural network generate sentences. paper present model added memory cells gate feeding image features deep neural network. intuition enabling model memorize much information images stage rnn. experiments flickrk flickrk datasets showed model outperforms state-of-the-art models higher bleu scores. generating natural language descriptions images became attractive research topic recent years. task generate sentences phrases summarize describe contents shown images. technique machines enabled imitate behaviour human beings able capture semantic meaning encoded images. previous work gupta mannem kulkarni desmond elliott frank keller designed templates sentence descriptions. task templates based images. however approaches strongly limited capability models generate sentence descriptions ﬁxed patterns. approaches transfer task multimodal embedding problem. work farhadi socher ordonez overlap scope information retrieval. goal images sentences appearing trainstate-of-the-art approaches based neural networks. work combined convolutional neural network recurrent neural network generate image descriptions. karpathy develop multimodal task. neural network image features extracted vggnet rnn. conditioned image features previous words generate sequence words recurrently describe images. similar kaparthy’s work vinyals vinyals used googlenet extract image features train lstm sequence generator. report deep complex multimodal sentence generation. approach vggnet employed extract image features deep multilayer chosen sequence generator informatively added memory gate controls image feeding. time step feed word current time step well image features hidden layer rnn. inspired ideas rolls deco visual perception depends short-term memory recurrent natural memory gate designed control input image features hidden layer. output memory gate depends output hidden layer previous time step. feeding hidden layer image features multiplied output gate element-wisely. therefore memory gates memory cells image features. model trained flickrk flickrk datasets hodosh evaluate bleu score model test datasets flickrk flickrk. preliminary results show performance model outperforms stateof-the-art work. proved powerful tool extract image features widely used image classiﬁcation object detection tasks. paper select deep powerful vggnet extract image features. speciﬁcally image vggnet input. forward propagation last fully-connected layer output dimensions vector image features image. sentence representation sentence represented sequence single word. time step deﬁned index word sentence represent position word. suppose sentence contains words time step ﬁrst word second word last word sentence special start token ﬁrst time step indicate start sentence well token last time step sentence. single word represented vector. pretrained word vector models developed wordvec mikolov glove pennington however model trained word vectors scratch instead directly adopted pretrained model since generally retrained word vector achieve higher performance speciﬁc task. dimension dimension hidden layer dimension word vector. dimension dimension vocabulary size. bias terms. vector represents probability word vocabulary next word conditioned input words time step model improve model capacity increase depth adding multiple hidden layers deep transition model reported pascanu shows dt-rnn able increase size family functions represent language modeling. unlike standard equation single hidden layer time step hidden layers stacked together time step dtrnn. forward propagation deep model represent output hidden layers word vector well output last hidden layer previous time step ﬁrst hidden layer then output current hidden layer feeds next hidden layer consecutively. output depends output last hidden layer current time step model deep equation chosen sequence learner sentences. memory cells image features consider control feeding image features deep rnn. instead feeding image features directly gate control magnitude image feature feeds. value gate depends state hidden layers previous time step. represents image image features extracted cnn. dimension maps image features space hidden layers rnn. output gate element-wise multiplication. transfers value last hidden layer previous time step equation) gate bias terms. activation function value ranges based equation image features ﬁrst hidden layer time step multiplied output gate. since value gate depends last hidden layer previous time step gate controls much information image still needed current time step. case image features feed full image features time step. deep network. however model feed image features time step. therefore model still able learn information image even larger time steps. magnitude image features conditioned hidden state previous time step. another word image features encoded based status well model learned. dataset experimented flickrk flickrk datasets introduced hodosh image datasets described independent sentences. therefore image create samples imagesentence pair. images flickrk flickrk respectively. dataset splited development data images test data images rest images training data. data preprocessing procedure work karpathy training training cross entropy loss chosen loss function. stochastic gradient descent minibatch size image-sentence pairs used training. make model converge faster rmsprop annealing policy hinton adopted step size parameter scaled windowaveraged norm gradient. overcome vanishing gradient problem relu chosen activation function. also adopted element-wise clip gradient tricks clipped gradient regularize model norm weights loss function zaremba suggested used dropout ratio layers except hidden layers. equation indicates model large deeper hidden layers leads large capacity. considering size dataset large order prevent overﬁtting adopt small hidden layers experiments equation generate image description sentence description image test dataset generated feeding image features trained model start token. time step directly choose word corresponds highest probability vocabulary output word also input word next time step. following method generate sentence recurrently reach token. evaluate performance bleu score evaluation metrics widely adopted papers focus topic vinyals bleu score evaluate similarity generated sentences ground truth sentences. table table show bleu score several models. shown table table model outperforms results karpathy performance model lower original work vinyals however original work vinyals authors used googlenet extract image features make fair comparison work vinyals downloaded reproduced version vinyals’ http//cs.stanford.edu/ model people/karpathy/neuraltalk/. reproduced model trained flickrk image features feed vinyals’ model extracted vggnet case model. last table performance model better model vinyals models vggnet image features. note even though reproduced model vinyals based flickrk dataset unavailable model still outperforms stateof-the-art works. also tried feed image features ﬁrst time step except ﬁrst time step) well feed full image features time step time steps). results show performance schemes lower feeding image features time step memory cells. paper developed model generating image descriptions. image features extracted vggnet time step multilayer deep image features vector element-wisely multiplied memory vector determined state hidden layer previous time step. experiments flickrk flickrk datasets show model achieves higher performance bleu score. model also beneﬁt complexity ease training. extension work train model larger dataset mscoco increase number hidden layers time step improve performance model. also adopt cnns googlenet extract image features. also work ﬁne-tune cnns datasets future train model tune cnns together.", "year": 2016}