{"title": "A Powerful Generative Model Using Random Weights for the Deep Image  Representation", "tag": ["cs.CV", "cs.LG", "cs.NE"], "abstract": "To what extent is the success of deep visualization due to the training? Could we do deep visualization using untrained, random weight networks? To address this issue, we explore new and powerful generative models for three popular deep visualization tasks using untrained, random weight convolutional neural networks. First we invert representations in feature spaces and reconstruct images from white noise inputs. The reconstruction quality is statistically higher than that of the same method applied on well trained networks with the same architecture. Next we synthesize textures using scaled correlations of representations in multiple layers and our results are almost indistinguishable with the original natural texture and the synthesized textures based on the trained network. Third, by recasting the content of an image in the style of various artworks, we create artistic images with high perceptual quality, highly competitive to the prior work of Gatys et al. on pretrained networks. To our knowledge this is the first demonstration of image representations using untrained deep neural networks. Our work provides a new and fascinating tool to study the representation of deep network architecture and sheds light on new understandings on deep visualization.", "text": "extent success deep visualization training? could deep visualization using untrained random weight networks? address issue explore powerful generative models three popular deep visualization tasks using untrained random weight convolutional neural networks. first invert representations feature spaces reconstruct images white noise inputs. reconstruction quality statistically higher method applied well trained networks architecture. next synthesize textures using scaled correlations representations multiple layers results almost indistinguishable original natural texture synthesized textures based trained network. third recasting content image style various artworks create artistic images high perceptual quality highly competitive prior work gatys pretrained networks. knowledge ﬁrst demonstration image representations using untrained deep neural networks. work provides fascinating tool study representation deep network architecture sheds light understandings deep visualization. recent years deep neural networks especially convolutional neural networks demonstrated highly competitive results object recognition image classiﬁcation advances training growing trend towards understanding inner working deep networks. training large image data dnns develop representation images makes object information increasingly explicit various levels hierarchical architecture. signiﬁcant visualization techniques developed understand deep image representations trained networks inversion techniques developed create synthetic images feature representations similar representations original image several layers network. feature representations function source image approximate inverse used construct image code reducing statistical discrepancy mahendran pretrained alexnet deﬁne squared euclidean loss activations capture representation differences reconstruct image. gatys deﬁne squared loss correlations feature maps layers synthesize natural textures high perceptual quality using pretrained called gatys combine loss correlations proxy style painting loss activations represent content image successfully create artistic images converting artistic style content image inspiring several followups another stream visualization aims understand neuron learned pretrained network synthesize image maximally activates individual features class prediction scores nguyen multifaceted visualization separate visualize different features neuron learns feature inversion neural activation maximization start white noise image calculate gradient backpropagation morph white noise image output natural image. addition regularizers incorporated natural image prior improve visualization quality including α−norm total variation jitter gaussian blur data-driven patch priors etc. method visualizing feature representation intermediate layers sheds light information represented layer pretrained cnn. third researchers trains separate feed-forward upconvolutional layers using representations correlations feature maps produced original network input source image target learn inversion original network. philosophy train another neural network inverse representation speedup visualization image reconstruction texture synthesis even style transfer. instead designing natural prior researchers incorporate adversarial training improve realism generated images. trained upconvolutional network could give similar qualitative results inversion technique three orders magnitude faster previous inversion technique needs forward backward pass pretrained network. technique slightly different previous focus understanding original visualization task. well recognized deep visualization techniques conduct direct analysis visual information contained image representations help understand representation encoded intermediate layers well trained dnns. paper raise fundamental issue researchers rarely address could deep visualization using untrained random weight dnns? would allow separate contribution training contribution network structure. might even give method evaluate deep network architectures without spending days signiﬁcant computing resources training networks could compare them. though gray demonstrated architecture random weights failed generating textures resulted white noise images experiment indicating trained ﬁlters might crucial texture generation conjecture success deep visualization mainly originates intrinsic nonlinearity complexity deep network hierarchical structure rather training architecture cause inversion invariant original image. gatys al.’s unsuccessful attempt texture synthesis using architecture random weights inappropriate scale weighting factors. verify hypothesis three popular inversion tasks visualization using architecture random weights. results strongly suggest true. applying inversion techniques untrained random weights reconstruct high perceptual quality images. results qualitatively better reconstructed images produced pretrained architecture. then synthesize natural textures using random weight vgg. automatic normalization scale squared correlation loss different activation layers succeed generating similar textures prior work gatys well-trained vgg. furthermore continue experiments style transfer combining content image style artwork create artistic imagery using random weight cnn. knowledge ﬁrst demonstration image representations using untrained deep neural networks. work provides fascinating tool study perception representation deep network architecture shed light understandings deep visualization. work inspire possibilities using generative power cnns random weights need long training time multi-gpus. furthermore hard prove trained deep neural networks work well. based networks random weights might able prove properties deep networks. work using random weights shows possible start developing theory deep learning since well-trained weights theorems might impossible. vgg- convolutional neural network trained million-image ilsvrc imagenet dataset using caffe-framework architecture convolutional pooling layers followed fully connected layers illustrated figure ﬁlters size number feature maps pooling applied convolutional layers spatial down-sampling feature maps. pre-processing step subtracts mean value pixel training set. gatys re-train vgg- network using average pooling instead maximum pooling suggest could improve gradient obtain slightly better results consider convolutional pooling layers texture synthesis rescale weights mean activation ﬁlter images positions trained network denoted following discussion. adopt architecture replacing weights purely random values gaussian distribution standard deviation small number like experiments. vgg-based random weight network created described method section used reference network denoted ranvgg following discussion. order better understand deep representation architecture focus three tasks inverting image representation synthesizing texture creating artistic style images. methods similar spirit existing methods main difference random weights instead trained weights apply weighting factors determined pre-process normalize different impact scales different activation layers input layer. another change apply greedy approach build stacked random weight network using inversion technique stabilize visualization quality. inverting deep representations. given representation function rh×w×c rnl×ml layer deep network input image want reconstruct image minimizes loss among representations dimensions number distinct feature maps size vectorised. representations chain non-linear ﬁlter banks even untrained random weights applied network. initialize image white noise apply bfgs gradient descent using standard error backpropagation morph input image target. weighting factor applied normalize gradient impact morphing image pre-processing procedure determine value current layer approximately calculate maximum possible gradient equation back propagate gradient input layer. regard reciprocal absolute mean gradient pixels channels value gradient impact different layers approximately scale. normalization doesn’t affect reconstruction activations single layer added combination content style style transfer task. stabilize reconstruction quality apply greedy approach build stacked random weight network ranvgg based vgg- architecture. select single image reference image starting ﬁrst convolutional layer build stacked random weight sampling selecting ﬁxing weights layer forward order. current layer weights previous layers sample several sets random weights connecting layer. reconstruct target image using rectiﬁed representation layer choose weights yielding smallest loss. experiments next section show success reconstruction using untrained random weight ranvgg. texture synthesis. synthesize natural textures based feature space untrained deep network? address issue refer method proposed gatys correlations feature responses layer texture representation. inner product pairwise feature maps within layer deﬁnes gram matrix seek texture image minimizes loss among correlations representations several candidate layers groundtruth image style transfer. untrained deep network create artistic images? referring prior work gatys feature responses trained imagenet untrained succeed separating recombining content style arbitrary images. objective requires terms content style respectively suitable combination factors. content method reconstruction medium layer representations style method synthesising texture lower higher layer representation correlations. content image style image. combine content former style latter optimizing following objective contributing factors content style respectively. apply regularizer total variation deﬁned squared adjacent pixel’s difference encourage spatial smoothness output image. section evaluates representation inversion texture synthesis style transfer results obtained model using untrained network ranvgg. input image required size want invert representation fully connected layers. else input could arbitrary size. inverting deep representations. select several source images ilsvrc challenge validation data examples inversion task choose monkey image reference image build stacked ranvgg. reconstruction monkey layer ranvgg shown figure convolutional pooling layers retain photographically accurate information image representations reveal invariance even ﬁrst fully connected layers. figure reconstructions monkey layer random weight ranvgg. monkey image well reconstructed activations convolutional layers rectiﬁer average pooling layers could still rough contours ﬁrst fully connected layers. compared inverting technique proposed mahendran consider euclidean loss activations ignore regularizer used capture natural image prior. ranvgg contains layers random weights plus pooling layers. mahendran reference network alexnet contains layers trained weights plus pooling layers. figure shows reach higher perceptive reconstructions. reason fact architecture uses ﬁlters small receptive ﬁeld adopt average pooling. though shallower reference network alexnet adopts larger ﬁlters uses maximum pooling makes harder images well inverted easily leads spikes. that’s used regularizers polish reconstructed image. figure shows examples reconstructions obtained method ranvgg well trained vgg. figure shows convergence loss along gradient descent iterations example images monkey house. reconstruction converges much quicker ranvgg yields higher perceptual quality results. note reconstruction remains even double iteration limits iterations. figure reconstructions layers ranvgg pretrained alexnet contains pooling layers compare results conv conv pool pool. method ranvgg demonstrates higher perceptive quality especially higher layers. note much deeper alexnet even compare pooling layer. figure reconstructions different pooling layers untrained ranvgg pretrained vgg. ranvgg demonstrates higher perceptive quality especially higher layers. pretrained could rarely reconstruct even contours representations ﬁfth pooling layer. figure shows variations example image compared purely random weights ranvgg stacked random weights exhibits lower variations lower reconstruction distances. compared trained stacked ranvgg purely random weights exhibit lower reconstruction distance lower variations. ranvgg demonstrates stable high performance inversion task. texture synthesis. figure shows textures synthesized model ranvgg several natural texture images selected texture website artwork named night starry vincent gohn images generated using increasing number convolutional layers constrain gradient descent. conv ﬁrst conv figure reconstruction qualities conv gradient descent iterations show comparison method ranvgg vgg. illustrations l-bfgs iteration. process untrained ranvgg converges quickly yields higher quality results within iterations compared ﬁnal results iterations pretrained vgg. conv second joint matching conv conv already exhibits high quality texture representations. adding layer conv could slightly improve natural textures. comparison results gatys trained using four convolutional layers conv shown bottom row. experiments show suitable weighted factors calculated automatically method ranvgg could synthesize complex natural textures almost indistinguishable original texture synthesized texture trained vgg. trained generates slightly better textures neatly arranged original textures style transfer. select conv content layer combination conv conv conv style. ratio experiments. ﬁrst compare style transfer results prior work gatys several well-known artworks style night starry vincent gohn schrei edward munch picasso pablo picasso woman henri matisse meadow poplars claude monet shown figure second recasting content university image style artworks obtain different artistic images based untrained ranvgg results comparable work pretrained order magnitude. slightly smoother lines textures attributed training. content style combination chinese paintings scenery photographs shown figure create high perceptual artistic chinese paintings well combine style painting content sceneries. work offers testable hypothesis representation image appearance based network structure. success untrained random weight networks deep visualization raises several fundamental questions area deep learning. researchers developed many visualization techniques understand representation well trained deep networks. however figure generated textures using random weights. corresponds different processing stage random weight network ranvgg. considering lowest layer conv synthesised textures lowest granularity showing local structure. increasing number layers match texture representation higher organizations previous local structure. third forth well synthesis textures original images. lowest corresponds result using trained match texture representation conv conv conv conv could similar visualization using untrained network understanding training network architecture. difference trained network random weight network architecture could explore difference? else could using generative power untrained random weight networks? explore visualization tasks computer vision developed well-trained network image morphing would promising aspect. figure artistic style images untrained ranvgg gatys pretrained select university image several well-known artworks style third column photograph picasso. obtain similar quality results compared gatys al.. figure style transfer chinese paintings untrained ranvgg. select several chinese paintings style including great wall songyan qian painting anonymous author beautiful landscape ping yang. select mountain photographs content images. created images performed untrained ranvgg shown third column seem learned paint rocks clouds paintings ﬁrst column transfer style content draw chinese landscape paintings.", "year": 2016}