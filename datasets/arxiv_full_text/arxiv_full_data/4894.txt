{"title": "A Connection between Generative Adversarial Networks, Inverse  Reinforcement Learning, and Energy-Based Models", "tag": ["cs.LG", "cs.AI"], "abstract": "Generative adversarial networks (GANs) are a recently proposed class of generative models in which a generator is trained to optimize a cost function that is being simultaneously learned by a discriminator. While the idea of learning cost functions is relatively new to the field of generative modeling, learning costs has long been studied in control and reinforcement learning (RL) domains, typically for imitation learning from demonstrations. In these fields, learning cost function underlying observed behavior is known as inverse reinforcement learning (IRL) or inverse optimal control. While at first the connection between cost learning in RL and cost learning in generative modeling may appear to be a superficial one, we show in this paper that certain IRL methods are in fact mathematically equivalent to GANs. In particular, we demonstrate an equivalence between a sample-based algorithm for maximum entropy IRL and a GAN in which the generator's density can be evaluated and is provided as an additional input to the discriminator. Interestingly, maximum entropy IRL is a special case of an energy-based model. We discuss the interpretation of GANs as an algorithm for training energy-based models, and relate this interpretation to other recent work that seeks to connect GANs and EBMs. By formally highlighting the connection between GANs, IRL, and EBMs, we hope that researchers in all three communities can better identify and apply transferable ideas from one domain to another, particularly for developing more stable and scalable algorithms: a major challenge in all three domains.", "text": "generative adversarial networks recently proposed class generative models generator trained optimize cost function simultaneously learned discriminator. idea learning cost functions relatively ﬁeld generative modeling learning costs long studied control reinforcement learning domains typically imitation learning demonstrations. ﬁelds learning cost function underlying observed behavior known inverse reinforcement learning inverse optimal control. ﬁrst connection cost learning cost learning generative modeling appear superﬁcial show paper certain methods fact mathematically equivalent gans. particular demonstrate equivalence sample-based algorithm maximum entropy generator’s density evaluated provided additional input discriminator. interestingly maximum entropy special case energy-based model. discuss interpretation gans algorithm training energy-based models relate interpretation recent work seeks connect gans ebms. formally highlighting connection gans ebms hope researchers three communities better identify apply transferable ideas domain another particularly developing stable scalable algorithms major challenge three domains. generative adversarial networks recently proposed class generative models generator trained optimize cost function simultaneously learned discriminator idea learning objectives relatively ﬁeld generative modeling learning cost reward functions long studied control popularized reinforcement learning problems ﬁelds learning cost function underlying demonstrated behavior referred inverse reinforcement learning inverse optimal control ﬁrst glance connection cost learning cost learning generative models appear superﬁcial; however apply gans setting generator density efﬁciently evaluated result exactly equivalent sample-based algorithm maximum entropy irl. interestingly maxent energy-based model connection suggests method using gans train broader class energy-based models. unknown dynamics using nonlinear function classes neural networks show gradient updates cost policy methods viewed updates discriminator generator gans speciﬁc form discriminator. difference generic discriminator need able evaluate density generator integrate discriminator natural way. traditionally gans used train generative models possible evaluate density. possible evaluate density example autoregressive model typical maximize likelihood data directly. considering connection training appropriate even density values available. example suppose interested modeling complex multimodal distribution model enough capacity represent distribution. maximizing likelihood lead distribution covers modes puts mass parts space negligible density data distribution. might images look extremely unrealistic nonsensical sentences suboptimal robot behavior. generator trained adversarially instead many modes without putting much mass space modes. results lower diversity ensures samples look like could original data. drawing exact correspondence adaptive sample-based algorithms maxent training show phenomenon occurs practically important training signiﬁcantly improve quality samples even generator density exactly evaluated. precisely analogous observed ability inverse reinforcement learning imitate behaviors cannot successfully learned behavioral cloning direct maximum likelihood regression demonstrated behavior. interestingly maximum entropy formulation special case energy-based model learned cost maxent corresponds energy function trained maximum likelihood. hence also show particular form gans used train ebms. recent works recognized connection ebms gans work particularly focus ebms trained maximum likelihood expand upon connection recognized bengio case generator’s density computed. formally highlighting connection gans ebms hope researchers three areas better identify apply transferable ideas domain another. generative adversarial networks approach generative modeling models trained simultaneously generator discriminator discriminator tasked classifying inputs either output generator actual samples underlying data distribution goal generator produce outputs classiﬁed discriminator coming underlying data distribution formally generator takes noise input outputs sample discriminator takes input sample outputs probability sample data distribution. discriminator’s loss average probability assigns correct classiﬁcation evaluated equal mixture real samples outputs generator generator’s loss deﬁned several similar ways. simplest deﬁnition originally proposed simply opposite discriminator’s loss. however provides little training signal generator’s output easily distinguished real samples. common instead discriminator’s confusion deﬁne generator’s loss variants energy function parameters often chosen maximize likelihood data; main challenge optimization evaluating partition function intractable integral high-dimensional problems. common approach estimating requires sampling boltzmann distribution within inner loop learning. sampling approximated using markov chain monte carlo methods; however methods face issues several distinct modes distribution result take arbitrarily large amounts time produce diverse samples. approximate inference methods also used training though energy function incorrectly assign energy modes approximate inference method cannot goal inverse reinforcement learning infer cost function underlying demonstrated behavior typically assumed demonstrations come expert behaving near-optimally unknown cost. section discuss maxent guided cost learning algorithm maxent irl. learned cost function here parametrized state action time step partition function integral exp) trajectories consistent environment dynamics. model optimal trajectories highest likelihood expert generate suboptimal trajectories probability decreases exponentially trajectories become costly. energy-based models parameters optimized maximize likelihood demonstrations. estimating partition function difﬁcult large continuous domains presents main computational challenge. ﬁrst applications model computed exactly dynamic programming however practical small discrete domains impossible domains system dynamics unknown. guided cost learning introduces iterative sample-based method estimating maxent formulation scale high-dimensional state action spaces nonlinear cost functions algorithm estimates training sampling distribution using importance sampling this formula assumes deterministic function previous history. general form equation derived stochastic dynamics however analysis largely remains same probability trajectory written product conditional probabilities conditional probabilities states affected factor likelihood ratios. conveniently optimal sampling distribution demonstration distribution true cost function. thus training procedure results learned cost function characterizing demonstration distribution learned policy capable generating samples demonstration distribution. importance sampling estimate high variance sampling distribution fails cover trajectories high values exp). since demonstrations cost address coverage problem mixing demonstration data samples generated samples. mixture distribution simple approach imitation learning generative modeling train generator policy output distribution data without learning discriminator energy function. tractability data distribution typically factorized using directed graphical model bayesian network. ﬁeld generative modeling approach commonly applied speech language generation tasks also applied image generation like ebms models trained maximizing likelihood observed data points. generative model capacity represent entire data distribution maximizing likelihood directly lead moment-matching distribution tries cover modes leading solution puts much mass parts space negligible probability true distribution. many scenarios preferable instead produce realistic highly probable samples ﬁlling many modes possible trade-off lower diversity. since ebms also trained maximum likelihood energy function exhibit moment-matching behavior limited capacity. however designing ﬂexible energy function represent distribution’s density function generally much easier designing tractable generator ﬂexibility generate samples without complex iterative inference procedure. moreover trained energy function generator trained mode-seeking minimizing divergence generator’s distribution distribution induced energy function. result even generator capacity generative model trained direct maximum likelihood generator trained exhibit mode-seeking behavior long energy function ﬂexible generator. course phenomenon often achieved cost tractability generating samples energy function requires training generator which case forward policy optimization. sequential decision-making domains using direct maximum likelihood known behavioral cloning policy trained supervised learning match actions demonstrating agent conditioned corresponding observations. approach simple often effective small problems moment-matching behavior direct maximum likelihood produce particularly ineffective trajectories compounding errors. policy makes small mistake deviates state distribution seen training making likely make mistake again. issue compounds eventually agent reaches state settings generating samples requires executing policy real world robotics samples generators typically retained efﬁciency. case density computed using fusion distribution past generator densities. training distribution makes catastrophic error generative modeling also faces issue generating variables sequentially. popular approach handling involves incrementally sampling model drawing less data distribution training requires true data distribution sampled training corresponding human algorithmic expert. bengio proposed approximate solution termed scheduled sampling require querying data distribution however approaches alleviate issue solve completely. show generative adversarial modeling implicitly applied setting inverse reinforcement learning data-to-be-modeled expert demonstrations. derivation requires particular form discriminator discuss ﬁrst section making modiﬁcation discriminator obtain algorithm show section discriminator involves learned cost generator represents policy. actual distribution data. traditional algorithm discriminator trained directly output value. generator density evaluated traditional discriminator modiﬁed incorporate density information. instead discriminator estimate value equation directly used estimate ﬁlling value known value. case form discriminator parameters order make connection maxent also replace estimated data density boltzmann distribution. maxent write energy function designate learned cost. discriminator’s output resulting architecture discriminator similar typical model binary classiﬁcation sigmoid ﬁnal layer logz bias sigmoid. adjusted architecture subtracting input sigmoid. modest change allows optimal discriminator completely independent generator discriminator exp) independence generator optimal discrimoptimal inator signiﬁcantly improve stability training. change simple implement applicable setting density cheaply evaluated. course precisely case could directly maximize likelihood might wonder whether worth additional complexity training. experience researchers shown maximizing likelihood directly always effective learn complex behaviors even possible implement. show precise equivalence maxent type suggesting phenomenon occur domains training provide advantages even would possible maximize likelihood directly. section show gans applied problems optimize objective maxent fact variant gans described previous section precisely equivalent guided cost learning. many apparent differences maxent optimization problem. shown making single change—using generator densities evaluated efﬁciently incorporating information discriminator natural way—generative adversarial networks viewed sample-based algorithm maxent problem. connecting gans empirical literature inverse reinforcement learning demonstrates training improve quality samples even generator’s density evaluated exactly. generalizing connection derive adversarial training strategy energy-based models discuss next section. highlighted connection gans guided cost learning application gans ebms follows directly. discussed section primary challenge training ebms estimating partition function done approximately sampling distribution induced energy recent papers proposed adversarial training derive fast estimates partition function particular methods alternate training generator produce samples minimal energy optimizing parameters energy function using samples estimate partition function. implement. discriminator’s output logq) sigmoid trainable bias. discriminator’s loss probability generator’s loss discriminator’s odds deﬁned section bengio proposed similar energy-based model generative image modeling assume could compute generator’s density result importance weights work biased estimator partition function converges true partition function generator correctly samples energy-based model. contrast using generator density unbiased estimate partition function rely assumptions generator. thus even generator cannot learn sample exactly data distribution training procedure consistent. zhao also proposed energy-based model autoencoder discriminator energy given mean-squared error data example discriminator’s reconstruction energy function optimized margin loss generator trained minimize energy. method also form discriminator presented above. interesting direction future exploration consider combining training algorithm discussed objective log-likelihood used ebms different -divergences used gans previously presented gan-like algorithm imitation learning goal recover policy matches expert demonstrations. proposed algorithm called generative adversarial imitation learning adversarial structure. analysis paper provides additional insight gail doing. discussed above gans optimizing objective maxent irl. thus gail policy trained optimize cost learned maxent irl. unlike guided cost learning however ermon typical unconstrained form discriminator generator’s density. case cost function remains implicit within discriminator cannot recovered. hence gail discriminator discarded policy result. bachman precup suggested data generation converted sequential decisionmaking problem solved reinforcement learning method. several recent works proposed methods merging maximum likelihood objectives known reward functions training sequential language generation models rely surrogate reward function bleu score edit distance work assume reward function unknown. proposed learn cost function sequential data generation using gans cost deﬁned probability discriminator classifying generated sequence coming data distribution discriminator take advantage policy’s density values despite fact known experiments also pfau vinyals drew connection optimization problems gans actor-critic methods reinforcement learning suggesting ideas stabilizing training domain could beneﬁcial authors point optimization tricks could also useful imitation learning algorithms two-level optimization structure. work showed equivalence generative adversarial modeling algorithm performing maximum entropy inverse reinforcement learning. derivation used special form discriminator leverages likelihood values generator leading unbiased estimate underlying energy function. natural direction future work experiment combining deep generators provide densities autoregressive models models invertible transformations generative adversarial modeling. approach provide stable training better generators wider applicability discrete problems language. work also suggests algorithm training energy-based models using generative adversarial networks trains neural network model sample distribution induced current energy. method could reduce computational challenges existing mcmc-based solutions.", "year": 2016}