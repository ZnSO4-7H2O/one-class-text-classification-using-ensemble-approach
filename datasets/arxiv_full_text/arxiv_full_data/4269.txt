{"title": "Multi-Instance Dynamic Ordinal Random Fields for Weakly-supervised  Facial Behavior Analysis", "tag": ["cs.CV", "cs.AI"], "abstract": "We propose a Multi-Instance-Learning (MIL) approach for weakly-supervised learning problems, where a training set is formed by bags (sets of feature vectors or instances) and only labels at bag-level are provided. Specifically, we consider the Multi-Instance Dynamic-Ordinal-Regression (MI-DOR) setting, where the instance labels are naturally represented as ordinal variables and bags are structured as temporal sequences. To this end, we propose Multi-Instance Dynamic Ordinal Random Fields (MI-DORF). In this framework, we treat instance-labels as temporally-dependent latent variables in an Undirected Graphical Model. Different MIL assumptions are modelled via newly introduced high-order potentials relating bag and instance-labels within the energy function of the model. We also extend our framework to address the Partially-Observed MI-DOR problems, where a subset of instance labels are available during training. We show on the tasks of weakly-supervised facial behavior analysis, Facial Action Unit (DISFA dataset) and Pain (UNBC dataset) Intensity estimation, that the proposed framework outperforms alternative learning approaches. Furthermore, we show that MIDORF can be employed to reduce the data annotation efforts in this context by large-scale.", "text": "abstract—we propose multi-instance-learning approach weakly-supervised learning problems training formed bags labels bag-level provided. speciﬁcally consider multi-instance dynamic-ordinal-regression setting instance labels naturally represented ordinal variables bags structured temporal sequences. propose multi-instance dynamic ordinal random fields framework treat instance-labels temporally-dependent latent variables undirected graphical model. different assumptions modelled newly introduced high-order potentials relating instance-labels within energy function model. also extend framework address partially-observed mi-dor problems subset instance labels available training. show tasks weakly-supervised facial behavior analysis facial action unit pain intensity estimation proposed framework outperforms alternative learning approaches. furthermore show midorf employed reduce data annotation efforts context large-scale. instance-label within assumed equal different previous works paper focus novel problem refer multi-instance dynamic ordinal regression case bags structured dynamic sequences instances temporal dependencies. moreover instance labels considered ordinal variables take values discrete categories satisfying increasing monotonicity constraints deﬁnition mi-dor enough general deﬁne different weak-relations instance-labels. speciﬁcally focus instances problem maximum relative mi-dor. similar former assume maximum ordinal value within sequence equal label. hand latter assumes weak-label provides information evolution instance ordinal levels within sequence. discuss below important applications context facial behavior analysis address paper. popular modelling framework addressing different weakly-supervised problems traditional single-instance-learning fully supervised setting assumed goal learn model feature vectors annotated terms target label contrast weak supervision assumed thus training formed bags labels baglevel provided. order learn model weakinformation assumes exists underlying relation label labels constituent instances instance standard multi-instance-classiﬁcation labels considered binary variables negative bags assumed contain instances associated negative label. contrast positive bags must contain least positive instance. another example assumption related multi-instance-regression problem real-valued variable maximum ruiz binefa cognitive media technology group pompeu fabra university spain rudovic media cambridge pantic dept. computing imperial college london also faculty electrical engineering mathematics computer science university twente netherlands facial expressions provide information human emotions attitudes mental states automatic analysis become active research ﬁeld computer vision last decade large number potential applications different contexts medicine entertainment. work focus relevant problems automatic facial behavior analysis action unit pain intensity estimation. naturally posed dynamical ordinal regression problems goal predict value ordinal scale instant sequence. speciﬁcally intensity estimation objective predict activation level facial actions frame video. similarly pain intensity estimation task measure intensity level pain felt patient potential solution addressing limitation could annotate larger training sets. however strategy feasible given expense annotation process. contrast explored solution work consists using weakly-supervised paradigm instead fully-supervised one. weakly-supervised approaches learn models using annotations provide partial information task needs solved. weaklabels much easier obtain fully-supervised learning thus allowing larger datasets minimizing lems proposed mi-dorf framework addresses tasks explicitly modelling weak-relation instances sequence labels.. framework ﬁrst approach imposes ordinal constraints instance labels. proposed method also incorporates dynamic information important modeling temporal structure instances within bags modeling dynamic information attempted virtually works account ordinal temporal data structures within existing frameworks. also introduce high-order potentials mi-dorf energy function order model weakly-supervised assumptions. following strategy present variants framework maxmi-dorf relmidorf preliminary version particular maxmi-dorf method presented previous work. models specially designed address maximum relative mi-dor problems respectively. given newly introduced potentials models render standard inference procedures existing latent variable models infeasible derive novel inference procedure. procedure scales well data number computational complexity similar forward-backward algorithm typically employed linear-chains models. also propose partially-observed extension midorf model approach allows leverage available instance labels order increase level supervision model. generalize learning inference procedures mi-dorf models mentioned above making applicable partiallyobserved still weakly-supervised learning tasks. show small portion labeled instances reach performance fully supervised models target tasks thus reducing expensive data annotation efforts large-scale. demonstrate performance proposed methods weakly-supervised pain action unit intensity estimation using benchmark datasets target tasks. show various settings advantages method compared alternative approaches. fig. illustration pain action unit intensity problems addressed work. sequence showing different pain levels bottom example different intensities action unit also represented ordinal scale. annotation effort. example pain intensity estimation much easier obtain label whole sequence terms maximum pain intensity felt recorded subject similarly annotating facial action unit intensities requires huge effort expert coders. contrast segmenting sequences according increasing decreasing evolution intensities less time-consuming. scenarios motivates interest maximum relative mi-dor problems previously introduced. models able learn weak information would allow leverage larger training sets thus potentially build effective models intensity estimation different facial behaviours. work propose multi-instance dynamic ordinal random fields framework address midor problems. build approach notion hidden conditional ordinal random fields similar hcorf mi-dorf undirected graphical model observation labels modelled linear-chain ordinal latent variables. however energy function mi-dorf designed explicitly incorporate multiple instance relation latent instance labels observable sequence weak-labels. main contributions work summarized follows best knowledge previous works explored multi-instance dynamic ordinal regression probexisting approaches usually follow bag-based instance-based paradigms bag-based methods feature vector representation ﬁrst extracted. then representations used train standard singleinstance methods used estimate labels. representation usually computed using different types similarity metrics training instances. examples following paradigm include multi-instance kernel miles mi-graph main limitation approaches learned models make predictions bag-level able estimate instancelabels contrast instance-based methods directly learn model operates instance level. this assumptions incorporated considering instance-labels latent variables. using strategy traditional supervised models adapted incorporate assumptions. examples methods following approach include multi-instance support vector machines milboost gaussian processes logistic regression work follow instancebased paradigm treating instance-labels ordinal latent states latent-dynamic model. particular follow similar idea multi-instance discriminative markov networks energy function markov network designed explicitly model weak-relations between instance labels. however contrast works described above presented mi-dorf framework accounts ordinal structure instance labels also accounting dynamics. popular methods sequence classiﬁcation latentdynamic models hidden conditional random fields hidden-markov-models methods variants dynamic bayesian networks latent states used model conditional distribution observations given sequence label. approaches dynamic information modelled incorporating probabilistic dependence time-consecutive latent states. mi-dorf builds upon hcorf framework considers latent states ordinal variables. however hcorf follows supervised paradigm main goal predict sequence labels latent variables used increase expressive power model. contrast energy function mi-dorf deﬁned explicitly encode multi-instance relationships latent instance labels. note also recent works extended hmms/hcrfs respectively multi instance classiﬁcation. reported results works suggested modeling dynamics beneﬁcial bag-instances exhibit temporal structure. however methods limit consideration case instance labels binary therefore unable solve mi-dor problems. introduced sec. also extend midorf partially-observed setting labels small subset instances available training. scenario previously explored using latent-dynamical models conditional random fields extensions although instance labels incorporated approaches considered suboptimal mi-dor sequence weak-labels need also taken account according assumptions. learning convolutional neural networks gaussian processes among others. however discussed supervised models limited context involve laborious data labelling. work address problems using weakly-supervised learning lies spectrum unsupervised fully supervised paradigms. context previous works explored non-supervised approaches facial behavior analysis. detection zhou proposed aligned cluster analysis unsupervised segmentation clustering facial events videos. experiments showed obtained clusters coherent manual annotations. another example multiple instance classiﬁcation used frames representing action unit activations sequences. different cited approaches focus binary detection address weakly-supervised action unit intensity estimation. proposed mi-dorf model able learn segments labelled according increasing decreasing evolution intensities similar problem recently addressed zhao speciﬁcally ordinal support vector ordinal regression used estimate facial expression intensities using onset appex segments training. however osvr presents limitations context. firstly models instance labels continuous variables sub-optimal modelling ordinal variables. secondly osvr poses mi-dor ranking problem causing scale predicted values necessarily match ground-truth. contrast mi-dorf models instance labels ordinal variables thus allowing better estimate labels scale determining priory number ordinal levels. finally osvr static approach temporal correlations modelled mi-dorf. context weakly-supervised pain intensity estimation approaches previously applied considering weak-label provided sequence then video considered image frames instances. sikka proposed extract bag-of-words representation video segments treat bag-instances. then milboosting applied predict sequencelabels assumption. following bag-based paradigm developed regularized multi-concept method capable discovering different discriminative pain expressions within sequence. recently proposed hidden markov models adaptation standard problem. limitation approaches focus binary detection problem thus unable consider different intensity levels pain. successfully attained proposed mi-dorf. research automatic facial behavior analysis mainly focused fully-supervised setting. speciﬁc problems action unit pain intensity estimation recent works developed models based hcorf metric iii. multi-instance dynamic ordinal regression section formalize mi-dor problem particular instances addressed work maximum midor relative mi-dor. tasks provided fig. factor graph representation proposed mi-dorf framework. node potentials model compatibility given observation latent ordinal value edge potentials take account transition consecutive latent ordinal states ht+. finally high-order potential models multi-instance assumptions relating latent ordinal states bag-label equivalent model mi-dorf deﬁned using auxiliary variables latent ordinal state. auxiliary variables redeﬁnition node edge potentials allows perform efﬁcient inference removing high-order dependency introduced potential maxmi-dorf ordinal node potential potential aims capture compatibility given observation latent ordinal value similar hcorf deﬁned using ordered probit model normal cumulative distribution function potential parameters. speciﬁcally vector projects observations onto ordinal line divided cut-off points every pair contiguous cut-off points divide projection values different bins corresponding different ordinal states difference cdfs provides probability latent state given observation standard deviation gaussian noise contaminating ideal model details). case avoid model overparametrization. type potentials previously training formed pairs structured-inputs labels speciﬁcally temporal sequences observations d-dimensional space. given training-set goal learn model mapping sequences structured-output concretely sequence variables assigning ordinal value observation order learn model necessary incorporate prior knowledge deﬁning multi-instance relation labels latent ordinal states maximum mi-dor assume bag-labels also ordinal variables maximum value must equal relative mi-dor sequence label categorical variable taking four possible values {↑↓∅}. label indicates type evolution within latent labels concretely sequences labelled must increasing ordinal level transition least instant moreover decreasing transitions allowed within sequence. opposite occurs sequences labelled case sequence assumed contain decreasing increasing transitions. finally ordinal values equal formally constraints deﬁned note deﬁnition mi-dor problems differs standard supervised sequence classiﬁcation latent variables. case main goal learn model mapping sequence labels evaluation conditional probability label given exponential number possible latent states efﬁcient inference algorithms need used. case latent-dynamic models hcrf/hcorf forward-backward algorithm applied. pair-wise linear-chain connectivity latent states however case maxmi-dorf inclusion potential introduces high-order dependence label latent states inference methods cardinality potentials previously proposed however algorithms consider case latent variables independent applied case. reasons propose speciﬁc inference method. idea behind apply standard forward-backward algorithm converting energy function deﬁned equivalent preserving linear-chain connectivity latent states introduce auxiliary variables takes binary value denoting whether sub-sequence contains least ordinal state equal deﬁne alternative maxmi-dorf energy function note include potential thus high-order dependence label latent ordinal-states removed. graphical representation mi-dorf redeﬁned energy function illustrated fig.. order show equivalence energies eqs. explain original multi-instance potential incorporated edge temporal potentials. firstly note also takes account proportion ordinal variables equal sequence label. moreover enforces contain greater thus aligning instance labels. however original multi-instance potential also constrained contain least ordinal value achieved using auxiliary wl×l represents real-valued transition matrix standard hcr. hand non-linear function deﬁned log). motivation using maintain range values node edge potentials. speciﬁcally bounds value case node potentials. order model maximum mi-dor assumption deﬁne high-order potential involving label sequence latent variables indicator function note maximum value within equal energy function equal thus probability drops hand assumption increases energy proportionally number latent states equal convenient since sequences annotated particular label likely many latent ordinal states ordinal level. shares relations cardinality potentials also employed binary multi-instance classiﬁcation objective function differentiable standard gradient descent methods applied optimization. l-bfgs quasi-newton method gradient evaluation involves marginal probabilities efﬁciently computed using proposed algorithm sec. iv-c. variables re-deﬁned edge potential case transitions latent ordinal states modelled also auxiliary variables speciﬁcally ordinal state equal sub-sequence fulﬁlls maximum mi-dor assumption thus forced deﬁning special cases beginning sequence energy maximum midor assumption fulﬁlled. otherwise value deﬁned since additional information given. advantage using equivalent energy function standard forward-backward algorithm applied efﬁciently compute conditional probability proposed procedure computational complexity compared using standard forwardbackward traditional linear-chain latent dynamical models. since typically considered similar theoretical complexity. presented algorithm also applied compute marginal probabilities relmi-dorf ordinal node potentials speciﬁed maxmi-dorf. however multi-instance potential deﬁned shown case potential models relaltive mi-dor assumption weak-relation sequence label evolution latent instance labels similar case maxmi-dorf high-order potential relmi-dorf prevents perform inference using standard forward-backward procedure. purpose follow similar strategy described sec. iv-c. however case auxiliary variables deﬁned according possible sequence labels relative mi-dor. concretely {↑↓∅} indicates label subsequence according deﬁnitions given equivalent energy function incorporating auxiliary variables obtained redeﬁning original edge potentials shown energy function becomes sequence level coherent evolution latent instance labels otherwise takes value energy function deﬁned original potentials. case computational complexity still linear terms instances although labels sequence-level easier collect applications feasible annotate small subset case interested learning model using weak-labels also incorporating information additional annotations. refer problem partiallyobserved multi-instance dynamic ordinal regression case formed triples contains ground-truth annotations subset sequence instances. formally subset ordinal labels corresponding annotated instances. setting extend mi-dorf learn model maximizing log-likelihood function conditional probability sequences training set. note case knowledge provided annotated instances incorporated likelihood function. order learn pomi-dorf model algorithms presented secs. applied. however inference need take account annotations sequence. easily achieved redeﬁning original node potentials relmi-dorf maxmi-dorf intuitively observed instance labels treated hard evidences make energy function take value consistent them. strategy previously followed order learn conditional random fields partially-observed setting. presented frameworks designed address multiinstance-learning problems bags structured temporal sequences instances ordinal labels. given attempted before evaluate alternative methods also used problems present limitations either ignore assumptions model dynamic information take account ordinal nature instance labels. single-instance ordinal regression maximum mi-dor posed supervised learning problem noisy labels. main assumption majority instances label bag. order test assumption train standard ordinal regression instance-level setting labels value corresponding bag. baseline considered static-sil approach solve maximum mi-dor problem. static multi-instance ordinal regression maximum mi-dor implemented static multi-instance approach. method inspired mi-svm instance labels considered latent variables iteratively optimized training. initialize parameters ordinal regressor follow procedure described sil-or. then ordinal values instance predicted modiﬁed maximum mi-dor assumption fulﬁlled bag. ordinal regression applied procedure applied iteratively convergence. multi-instance-regression discussed sec. maximum mi-dor problem closely related multiple-instance-regression. order evaluate performance strategy implemented similar method approach model used note maxmi-drf approach similar proposed maxmi-dorf. however maxmi-drf ignores ordinal nature labels models categorical variables. purpose replace maxmi-dorf node potentials multinomial logistic regression model inference performed using algorithm described sec. iv-c. relmi-drf similar maxmi-drf method equivalent relmi-dorf modelling instance labels categorical variables. latent-dynamic models maximum relative mi-dor label sequence-level provided training. therefore possible apply existing latent-dynamic models hcrf hcorf problems. despite methods model dynamics incorporate information provided sequence-labels take account multi-instance assumptions. ordinal support vector regression method presented applied relative mi-dor. however static approach consider dynamic information. moreover models instance labels continuous variables instead ordinal. methods partially-observable mi-dor experiments evaluate max-midorf rel-midorf instance labels also available training order compare performance setting evaluate partially-observed extensions hcrf ordinal versions approaches also implemented work. methods supervised dynamic ordinal regression fully evaluate performance methods trained using weak-labels compare previous described methods related fully-supervised models sequence classiﬁcation corf approaches learned complete information order evaluate performance different methods report results terms instance-labels predictions. note literature results usually reported bag-level. however mi-dor problems goal predict instance labels inside given ordinal nature labels pearson’s correlation mean-average-error intra-class-correlation evaluation metrics. experiments used subset training sequences optimize different regularization weights cross-validation procedure. used standard grid-search regularization parameters chosen different values range maximum mi-dor relative mi-dor synthetic data synthetic data generation given standard benchmarks available mi-dor problems generated synthetic data. order create sequences testing validation. sequences variable length instances maximum mi-dor relative mi-dor. dimensionality feature vectors number ordinal values partially-observed mi-dor randomly choose instance sequence label also used training. table shows results computed average performance datasets maximum relative mi-dor respectively. also report results fully-supervised corf trained considering instance labels. maximum mi-dor discussion maximum midor problem methods obtain lower performance corresponding versions evaluated metrics. expected since approaches ignore multi-instance assumption. moreover hcorf maxmi-dorf obtain better performance compared hcrf maxmi-drf. former model instance labels nominal variables thus ignoring ordinal nature. finally note maxmi-dorf outperforms static methods mi-or mir. although approaches multi-instance assumption incorporate labels ordering take account temporal information. contrast maxmi-dorf able model dynamics latent ordinal states information make better predictions sequence observations noisy. looking results achieved different methods pomi-dor setting derive following conclusions. firstly hcorf hcrf improve performance taking account additional information provided instance labels. however observe that setting corf obtain lower results hcorf hcrf. later able sequencelabel information together provided labelled instances. secondly observe maxmi-drf maxmidorf still achieves better performance methods consider assumption shows importance explicitly incorporate maximum mi-dor assumption model even though instance labels available training. finally note maxmi-dorf obtain best performance even close fully-supervised corf. suggest need annotated instances highly-reduced sequence weak-labels used learning. relative mi-dor discussion relative mi-dor problem observe similar results maximum mi-dor. firstly note non-ordinal approaches obtain worst performance cases. secondly relmi-dorf obtain better performance hcorf explicitly modelling multi-instance-assumption. finally osvr achieves competitive performance terms correlation compared relmi-dorf. however obtains poor results terms icc. discussed sec. osvr considers labels continuous variables explicitly model relative mi-dor assumption. instead ranks instance labels within sequence. therefore fails estimate actual scale predicted values. fig. description procedure used generate synthetic sequences. random matrix modelling transition probabilities consecutive latent ordinal values. ordinal levels assigned random feature vectors according ordinal regressor. example sequence ordinal values obtained using generated transition matrix. feature vector representing observation randomly chosen samples according probability ordinal level. maximum mi-dor ﬁrstly sample sequence ordinal values using random transition matrix representing transition probabilities temporally-consecutive ordinal levels. secondly generate random parameters ordinal regressor deﬁned regressor used compute probabilities ordinal level feature-vectors randomly sampled gaussian distribution. thirdly corresponding sequence observation latent state sequence randomly chosen sampled feature vectors according obtained probability ordinal value. finally sequence-label maximum ordinal state within sequence following maximum mi-dor assumption gaussian noise added feature vectors. fig. illustrates procedure. relative mi-dor follow similar strategy generate synthetic sequences. however transition matrix forced contain probability decreasing transitions case sequence label increasing transitions testing create unsegmented sequences concatenating segments generated following previous procedure. experimental setup results following strategy described above generated different data sets relative maximum mi-dor varying ordinal regressor parameters transition matrix. speciﬁcally dataset composed sequences training experiment test performance maxmidorf weakly-supervised pain intensity estimation. detailed sec. main motivation pain intensity labelling time consuming. however maximum pain felt sequence much easier annotate. unbc dataset unbc shoulder-pain database contains recordings different subjects performing active passive movements rehabilitation sessions. dataset pain intensities frame given terms pspi scale ordinal scale ranges given imbalance high pain intensity levels follow strategy speciﬁcally pain labels grouped ordinal levels frame-by-frame pain annotations considered instance labels maximum mi-dor. hand labels extracted maximum pain level within sequence. order extract facial-descriptors video frame representing instances compute geometry-based facial-descriptor follows. firstly obtain landmark facial-points method described then obtained points aligned mean-shape using procrustes analysis. finally facial descriptor obtained concatenating coordinates aligned points. instance labels provided methods improve performance exploiting additional information. however improvement terms much higher correlation. relative mi-dor sequence labels provide information evolution instance labels within sequence. therefore models achieve good performance predicting sequence-labels even though ordinal levels accurate. contrast instance labels incorporated training better estimation ordinal levels achieved. finally note relmi-dorf porelmi-dor setting achieves competitive performance compared fully-supervised corf. computational cost order show efﬁciency proposed inference algorithms maxmi-dorf relmi-dorf computed average time required process testing sequences synthetic datasets used experiments comparing time required forward-backward procedure employed hcrf hcorf maxmi-dorf times slower similarly forward-backward algorithm times faster relmi-dorf note efﬁciency proposed algorithms better expected according theoretical analysis. implementation experimental setup results similar experiment synthetic data consider scenarios weakly-supervised pain intensity estimation. ﬁrst maximum mi-dor setting labels used. apart baselines described sec. vii-a scenario also evaluate performance approach presented considers pain levels binary variables. purpose milboosting method employed cited work considered videos pain label greater positive. given mi-classiﬁcation methods able make binary predictions output probability indicator intensity levels i.e. output probability normalized also consider partially-observed setting different percentages annotated frames inside sequence also available training. simulates time required annotate dataset signiﬁcantly reduced labelling small subset frames. concretely consider annotated frames sequence. different experimental setups perform leave-one-subject-out cross validation where cycle subjects training testing validation. order reduce computational complexity redundant information temporal consecutive frames down-sampled sequences using time-step seconds. table shows results obtained evaluated methods following described procedure. results fullysupervised corf also reported. discussion looking results maximum mi-dor setting derive following conclusions. firstly approaches obtain worse performance mi-or mir. specially hcorf hcrf obtain poor results. pain events typically sparse sequences frames intensity level therefore assumption critical importance problem order correctly locate pain frames. secondly mi-or obtain better results maxmi-drf. explained latter consider pain levels nominal variables ignorant ordering information different pain intensities. finally milboost trained binary labels also obtains performance compared mi-or mir. suggest current approaches posing weaklysupervised pain detection mi-classiﬁcation problem unable predict accurately target pain intensities. contrast maxmi-dorf obtains best performance across evaluated metrics. attribute fact models assumption ordinal variables. moreover improvement maxmi-dorf compared static approaches mi-or suggests modelling dynamic information beneﬁcial task. partially-observed setting methods improve performance considering additional information provided labelled instances. however note approaches modelling ordinal structure labels still outperforms nominal methods setting. moreover maxmi-dorf also achieves best performance labeled frames. despite approaches also consider instance labels maxmi-dorf better exploits sequence labels information explicitly modelling assumption. worth mentioning considering annotated frames maxmi-dorf obtain competitive performance fully-supervised approaches. concretely outperforms terms icc/corr corf terms mae. suggest effort needed annotate pain intensity databases could highly-reduced using proposed weakly-supervised framework. order give insights issue fig. shows performance terms percentage annotated frames increases. observe maxmi-dorf outperforms methods annotated frames. percentage increases performance partiallyobserved corf hcorf maxmi-dorf comparable achieved fully-supervised corf. however note labelling samples suppose signiﬁcant reduction annotation time real scenario. finally fig. show qualitative examples comparing predictions best evaluated methods different settings. bag-labels used training mi-or predictions less accurate obtained maxmi-dorf. moreover maxmi-dorf estimates better actual pain levels partially-observed setting small subset instance labels used. predictions accurate obtained partially-observed hcorf take account assumption. reﬂected depicted sequences showing proposed maxmi-dorf method outperforms competing approaches target data. section test performance relmi-dorf weakly-supervised action unit intensity estimation. similarly pain intensity labelling requires huge effort expert coders. however segmenting videos according increasing decreasing evolution intensities less time-consuming. disfa dataset employ disfa database popular benchmark intensity estimation. contains naturalistic data consisting annotated sequences different subjects watching videos eliciting different types emotions. speciﬁcally frame-by-frame intensities provided sixpoint ordinal scale know largest available dataset terms number action units annotated. although unbc dataset also provides intensity annotations found number onset appex events limited. therefore discard experiments. best knowledge previous works evaluated disfa weakly-supervised setting. described intensities represent instance labels relative mi-dor problem. previously discussed bags considered onset apex sequences intensity given monotone increasing decreasing segments automatically extracted exhaustive search whole video using groundtruth intensity labels frame-level. procedure simulates given annotator labelled onset offset segments instead speciﬁc intensities frames. number extracted segments indicated table compute facial descriptors frame procedure described sec. vii-d. experimental setup results using segments evaluate different methods using subjectindependent -fold cross validation. speciﬁcally folds used training testing validation purposes. testing trained models evaluated original non-segmented videos. motivation that real scenario onset apex segmentation known testing sequences. also consider partially-observed setting labels frames available training table shows performance obtained evaluated methods computed average considered aus. speciﬁc results terms independent shown table discussion instance labels used training observe hcrf hcorf obtain poor results compared osvr relmi-dorf. explained former methods explicitly model increasing/decreasing intensity constraints provided sequence weak-labels. moreover results obtained relmi-drf compared relmidorf suggest modelling intensities nominal variables suboptimal scenario. also note osvr obtains worse results terms compared relmidorf. given performances terms corr similar shows limitation osvr predict actual scale instance ordinal labels. considering results independent observe relmi-dorf achieves best performance cases. note however results particular methods. attribute fact that activation typically subtle high-intensity levels scarce. looking results partially-observed setting derive following conclusions. firstly methods improve average performance percentage instance labels increases. however improvement signiﬁcant mae. shows that instance labels available training tendency intensity levels captured. however accurate predictions particular ordinal labels requires additional information provided frame-by-frame annotations. illustrate this fig. show predictions attained relmi-dorf using different percentages annotated frames. secondly note approaches modelling ordinal structure labels usually achieves better performance nominal methods terms corr. contrast hcrf obtain lower corf hcorf. explained majority sequence frames intensity level consequence hcrf tends assign frames level thus minimizing absolute error. contrast ordinal methods robust imbalanced intensity levels capture better changes intensities. finally note proposed relmi-dorf method obtain best average performance considering annotated frames. regarding speciﬁc relmi-dorf obtain better results cases competitive performance best method otherwise. finally note relmi-dorf performance annotated frames comparable achieved fully-supervised approaches corf. speciﬁcally supervised outperforms relmi-dorf terms average mae. slightly worse results supervised corf compared relmi-dorf suggest considering intensity annotations frames cause overﬁtting decrease performance unseen test sequences. seen clearly looking results independent relmi-dorf obtain slightly better performance fully-supervised corf cases. conclusion presented results support hypothesis possible proposed relmi-dorf model order reduce annotation effort required intensity estimation. work presented mi-dorf novel task multi-instance dynamic-ordinal regression. best knowledge ﬁrst approach imposes ordinal structure instance labels also attains dynamic modeling within instances. considering different weakrelations instance labels developed variants framework relmi-dorf maxmidorf. moreover extended proposed framework partially-observed mi-dor problems subset instance labels also available training. although presented mi-dorf framework many potential applications multiple domains results context weakly-supervised facial behavior analysis relevant several aspects. mi-dor setting instancelevel annotations available training showed proposed method learn underlying variables signiﬁcantly correlated ground-truth instance labels. even though results setting lower fullysupervised approaches method provides good trade-off annotation effort accuracy intensity predictions. claim replace au/pain annotation process using weak-labels sequence-level setting preferable applications. example focus capturing variation target facial behaviour rather obtaining highly accurate frame labels approach clear advantages fully supervised methods require time-consuming annotation process. hand competitive results partially-observed mi-dorf compared evaluated fully-supervised approaches indicate annotation effort highly-reduced combined weak-information. also worth mentioning recent works deep learning action unit detection intensity estimation although models high modelling power reported results shown signiﬁcant improvements compared traditional shallow methods using hand-crafted features. example recently proposed copula convolutional neural network intensity estimation highly-related approach combines probabilistic graphical model similar employed mi-dorf. even though copula requires intensity labels frames training reported results disfa dataset comparable achieved method. speciﬁcally mi-dorf trained annotated frames obtains better average performance terms mean average error whereas outperformed terms although results directly comparable different experimental settings indicate method trained labels sequence-level small portion labelled frames still show competitive performance. known supervised deep learning models require large number samples effectively trained thus still limits application facial behavior analysis annotation process laborious labelled data scarce. posing facial expression intensity estimation weaklysupervised learning problem would provide opportunity replace limited-size datasets currently used ﬁeld large-scale not-fully labelled databases. therefore coupling deep models proposed framework natural step forward focus future research. zhao j.-y. milcut sweeping line multiple instance learning paradigm interactive image segmentation proc. computer vision pattern recognition. lucey cohn prkachin solomon matthews painful data unbc-mcmaster shoulder pain expression archive database international conference automatic face gesture recognition. rudovic pavlovic pantic context-sensitive dynamic ordinal regression intensity estimation facial action units ieee transactions pattern analysis machine intelligence rudovic pavlovic automatic pain intensity estimation using walecki rudovic pavlovic schuller pantic deep structured learning facial expression intensity estimation proc. computer vision pattern recognition june lafferty mccallum pereira conditional random ﬁelds probabilistic models segmenting labeling sequence data proc. international conference machine learning t˝os´er jeni l˝orincz cohn deep learning facial action unit detection large head poses european conference computer vision workshops. springer zhou hong zhao recurrent convolutional neural network regression continuous pain intensity estimation video ieee conference computer vision pattern recognition workshops meng a.-s. khan tong incremental boosting convolutional neural network facial action unit recognition advances neural information processing systems ruiz rudovic binefa pantic multi-instance dynamic ordinal random ﬁelds weakly-supervised pain intensity estimation asian conference computer vision g¨artner flach kowalczyk smola multi-instance kernels proc. international conference machine learning chen wang miles multiple-instance learning embedded instance selection ieee transactions pattern analysis machine intelligence y.-y. wang acero extracting structured information user queries semi-supervised conditional random ﬁelds sigir conference research development information retrieval. k.-y. chang t.-l. s.-h. learning partially-observed hidden conditional random ﬁelds facial expression recognition proc. computer vision pattern recognition. eleftheriadis rudovic deisenroth pantic variational gaussian process auto-encoder ordinal prediction facial action units asian conference computer vision taipei taiwan november zhou torre cohn unsupervised discovery facial events proc. computer vision pattern recognition hendriks valstar pantic detection concept frames using clustering multi-instance learning proc. int. conf. pattern recognition. sikka dhall bartlett weakly supervised pain localization using multiple instance learning international conference automatic face gesture recognition. walecki rudovic pavlovic pantic variable-state latent conditional random ﬁelds facial expression recognition action unit detection international conference automatic face gesture recognition. fig. obtained unbc data using different percentages labelled instances training set. black line shows performance fully-supervised corf trained instance labels. visualization pain intensity predictions different sequences unbc dataset. bottom mi-or maxmi-dorf without using instance labels. partially-observed hcorf maxmi-dorf using annotated frames. fig. visualization intensity predictions subsequence disfa dataset. bottom relmi-dorf without using instance labels annotated frames. supervised corf using frame labels training. intensity estimation relmi-dorf tends accurate instance labels considered training. using annotated frames relmi-dorf achieves similar accuracy fully-supervised corf.", "year": 2018}