{"title": "Feeling the Bern: Adaptive Estimators for Bernoulli Probabilities of  Pairwise Comparisons", "tag": ["cs.LG", "cs.AI", "cs.IT", "math.IT", "stat.ML"], "abstract": "We study methods for aggregating pairwise comparison data in order to estimate outcome probabilities for future comparisons among a collection of n items. Working within a flexible framework that imposes only a form of strong stochastic transitivity (SST), we introduce an adaptivity index defined by the indifference sets of the pairwise comparison probabilities. In addition to measuring the usual worst-case risk of an estimator, this adaptivity index also captures the extent to which the estimator adapts to instance-specific difficulty relative to an oracle estimator. We prove three main results that involve this adaptivity index and different algorithms. First, we propose a three-step estimator termed Count-Randomize-Least squares (CRL), and show that it has adaptivity index upper bounded as $\\sqrt{n}$ up to logarithmic factors. We then show that that conditional on the hardness of planted clique, no computationally efficient estimator can achieve an adaptivity index smaller than $\\sqrt{n}$. Second, we show that a regularized least squares estimator can achieve a poly-logarithmic adaptivity index, thereby demonstrating a $\\sqrt{n}$-gap between optimal and computationally achievable adaptivity. Finally, we prove that the standard least squares estimator, which is known to be optimally adaptive in several closely related problems, fails to adapt in the context of estimating pairwise probabilities.", "text": "study methods aggregating pairwise comparison data order estimate outcome probabilities future comparisons among collection items. working within ﬂexible framework imposes form strong stochastic transitivity introduce adaptivity index deﬁned indiﬀerence sets pairwise comparison probabilities. addition measuring usual worst-case risk estimator adaptivity index also captures extent estimator adapts instance-speciﬁc diﬃculty relative oracle estimator. prove three main results involve adaptivity index diﬀerent algorithms. first propose three-step estimator termed count-randomize-least squares prove standard least squares estimator known optimally adaptive several closely related problems fails adapt context estimating pairwise probabilities. extensive literature modeling analyzing data form pairwise comparisons items much earliest literature focusing applications voting social choice theory tournaments. advent internet-scale applications particularly search engine ranking online gaming crowdsourcing renewed interest ranking problems particularly statistical computational challenges arise aggregation large data sets paired comparisons. problem aggregating pairwise comparisons inconsistent and/or noisy presents number core challenges including produce consensus ranking paired comparisons estimate notional quality underlying objects estimate probability outcomes subsequent comparisons paper focus third task— problem estimating probability object preferred another. accurate knowledge pairwise comparison probabilities useful various applications including estimating probability customer picking product another estimating probability team beating another. beats item perspective problem estimating comparison probabilities amounts estimating unknown matrix practice expects pairwise comparison probabilities exhibit form structure paper line past work problem assume entries matrix satisfy strong stochastic transitivity constraint. important note constraint considerably weaker standard parametric assumptions often made literature—for instance entries follow bradley-terry-luce thurstone model. constraint quite ﬂexible models satisfying constraint often provide excellent paired comparison data variety applications. also substantial body empirical work validates assumption—for instance papers psychology economics literatures. theoretical front past work studied problem estimating matrices frobenius norm. works focus exclusively global minimax error meaning performance estimator assessed worst-case sense globally entire class. well-known criterion global minimax lead poor understanding estimator especially situations intrinsic diﬃculty estimation task highly variable parameter space situations fruitful benchmark risk estimator so-called oracle estimator provided side-information local structure parameter space. benchmark used show given estimator adaptive sense even though given side-information problem instance able achieve lower risk easier problems results type). paper study problem-speciﬁc diﬃculty estimating pairwise comparison matrix introducing adaptivity index involves size indiﬀerence sets matrix indiﬀerence sets arise many relevant applications correspond subsets items equally desirable. term adaptivity paper derives meaning literature statistics refers property estimator automatically adapting performance complexity problem. confused notion adaptive sampling used context sequential design adaptive learning refers ability obtain samples time sequential data-dependent manner. strongly size largest indiﬀerence set. fact motivates deﬁne adaptivity index benchmarks performance estimator relative oracle estimator given additional side information size indiﬀerence sets deﬁnition estimator lower values index said exhibit better adaptivity oracle estimator adaptivity index remainder paper organized follows. begin section background problem. section devoted statement main results well discussion consequences. section provide proofs main results technical details deferred appendices. finally section presents concluding remarks. matrix m∗ij probability item preferred item paired comparison. accordingly upper lower halves related shifted-skewsymmetry condition m∗ji m∗ij assume m∗ii choice pairs compared understand eﬀects noise models. consequently restrict attention case single observation pair keeping mind extend result observation models techniques similar proposed past work based observing goal paper recover accurate estimate squared frobenius norm full matrix items endowed complete ordering notation indicate item preferred item total ordering satisﬁes condition respect permutation π∗—or π∗-sst short—if intuition underlying constraint follows since dominates true underlying order make noisy comparisons probability preferred least large probability preferred class matrices given turn notion indiﬀerence sets allows ﬁner-grained characterization diﬃculty estimating particular matrix. suppose items partitioned union disjoint sets {pi}s reasons clariﬁed moment term sets indiﬀerence set. write mean pair belong index matrix rn×n respects indiﬀerence partition {pi}s instance special case two-contiguous-block partition matrix must block structure entries equaling diagonal blocks entries equaling upper right block equaling lower left block. intuitively matrices instance buying cars frugal customers indiﬀerent high-priced cars; ranking news items people certain country indiﬀerent domestic news countries. block structures type also studied types matrix estimation problems contexts termed communities blocks level sets depending application consideration. instance papers well references therein discussion structures. section present main results paper statistical computational aspects adaptivity index. begin auxiliary result risk oracle estimator useful subsequent analysis. recall section oracle estimator access additional side information values number sizes indiﬀerence sets true underlying matrix oracle estimator deﬁned estimator incurs lowest possible risk among estimators. ence given value aﬀected number indiﬀerence sets sizes property sharp contrast known results related problem bivariate isotonic regression number indiﬀerence sets play strong role. proposition provides sharp characterization denominator adaptivity index section investigate fundamental limits adaptivity studying numerator disregarding computational constraints. main result section show suitably regularized form least-squares estimation optimal adaptivity logarithmic factors. estimator returning matrix relatively large maximum indiﬀerence set. later analysis section clarify inclusion term essential unregularized form least-squares poor adaptivity properties. regularized least squares estimator cmreg optimal logarithmic factors. estimator cmreg non-trivial solve; involves nonconvex regularizer well nonconvex constraint set. shed light intrinsic complexity computing estimator section investigate adaptivity index achievable estimators computable polynomial time. section propose polynomial-time computable estimator termed count-randomizeleast-squares estimator prove upper bound adaptivity index. order deﬁne estimator requre additional notation. permutation items denote matrices faithful permutation π—that step compute total number wins. order items terms {ni}n step find largest subset items using order computed step permute subset items uniformly random within subset. denote resulting permutation πcrl. step compute least squares estimate assuming permutation πcrl true permutation items optimization problem corresponds projection onto polytope bi-isotone matrices contained within hypercube along skew symmetry constraints. problems form studied past work estimator mcrl indeed computable polynomial time. construction agnostic values provide intuition second step randomization serves discard non-robust information order computed step information corresponds noise bernoulli sampling process opposed structural information matrix. perform second step—eﬀectively retaining considerable bias step —then isotonic regression procedure step amplify leading poorly performing estimator. whether analysis estimator might improved whether another polynomial-time estimator lower adaptivity index estimator. section answer questions negative least conditionally certain well-known conjecture average case complexity theory. precisely prove lower bound relies average-case hardness planted clique problem conjecture hardness assumption widespread literature substantial evidence literature supporting conjecture also used tool proving hardness results sparse related matrix recovery problems least squares estimators type known possess good adaptivity various instance papers references therein various examples phenomena. past work estimator known minimax optimal estimating matrices. section present proofs results. note passing proofs additionally lead auxiliary results independent interest. auxiliary results pertain problem bivariate isotonic regression—that estimating underlying permutation known—an important problem ﬁeld shape-constrained estimation prior works restrict attention expected error assume underlying permutation correctly speciﬁed; results provide exponential tail bounds also address settings permutation misspeciﬁed. section prove general upper bound applies relatively broad class regularized -estimators matrices. given matrix generated model consider estimator form signiﬁcance claim reduces problem controlling error estimator bounding metric entropy computing critical radius remainder section devoted proof claim. case first suppose indeed every matrix identical values entries corresponding items largest indiﬀerence set. since induced sst). least large lower bound estimating matrix class min{n−kk} applying lemma sub-matrices comprises constant matrices hence metric entropy sub-matrix constant-valued columns metric entropy upper bounded identical bound holds sub-matrices finally sub-matrices contained ﬁrst part proof assume greater universal constant. condition gilbert-varshamov bound guarantees existence binary code length minimum hamming distance number code words card codeword matrix deﬁned starting base matrix swapping row/column row/column instance codeword ordering matrix given obtained swapping ﬁrst items indiﬀerence sets. sst). evaluate certain properties matrices allow prove claimed lower bound. consider matrices set. since codewords binary code hamming distance least aforementioned construction correspond distributions random matrix based bernoulli entries matrices interval boundedness condition divergence sandwiched frobenius norm constant factors. applying result current setting yields case otherwise parameter smaller universal constant part constant handle case diﬀerent argument. particular suppose estimator given partition forming indiﬀerence sets needs estimate parameter purpose suﬃcient statistics observation matrix entries observation matrix correspond matches items diﬀerent indiﬀerence sets; note entries total. standard bounds estimation single bernoulli probability estimator must mean-squared error lower bounded finally observe error estimating matrix squared frobenius norm least times error estimating parameter thus established claimed lower bound constant. remains prove tail bound proceed step argument ﬁrst general upper bound given lemma derive weaker version required bound; second reﬁne weaker bound obtain bound estimate consideration either also optimal estimator case suboptimal aggregate estimation problem former case error incurred estimate already handled analysis latter case irrelevant. noise matrix linearized form model. following lemma helps bound ﬁrst term right hand side inequality consistent notation elsewhere paper value deﬁne matrices veriﬁed function t-lipschitz. moreover random matrix entries independent diagonal bounded absolute value satisfy skew-symmetry. consequently ledoux’s concentration theorem guarantees prove upper bound estimator stated theorem order simplify presentation assume without loss generality true permutation items identity permutation πcrl denote permutation obtained second step estimator. following lemma proves useful properties outcomes ﬁrst steps. consider item incorrectly estimating item lying position contributes non-zero error either item item lies -sized items outside largest indiﬀerence set. consequently values error. consequence upper bound analyze third step estimator. problem bivariate isotonic true underlying permutation items known priori. case permutation known approximately need also track associated approximation error. order derive tail bound error bivariate isotonic regression call upon general upper bound proved earlier lemma choices detail consider steps algorithm ﬁrst obtaining total ordering items count number pairwise victories converting partial order putting items subset identiﬁed step equivalence class obtaining total ordering permuting items equivalence class data-independent manner. lemma ensures size equivalence class least consequently number possible partial orders obtained taking union bound cases consider order item located position total order given sums must least items whose sums least particular must least item follows results condition event occurs probability likewise thereby proving claim. diff. consider following partition entries matrix submatrices. submatrix partition submatrix corresponding pairwise comparison probabilities every item indiﬀerence every item indiﬀerence partition ensures partitioned submatrix constant matrix. consequently diff partitioned submatrix sst) metric entropy diff upper bounded metric entropies turn proof lower bound polynomial-time computable estimators stated theorem proceed reduction argument. consider estimator frobenius norm error upper bounded showing estimator satisfying bound subclass used identify planted clique erd˝os-r´enyi random graph. naturally order leverage planted clique conjecture kmax remaining indiﬀerence sets size choose constant multiple within hardness regime parameter planted clique matrix ones sub-matrix top-right zeros corresponding sub-matrix bottom-left entries equal kmax prove lower bounds standard least-squares estimator. central piece proof following lemma characterizes interesting structural property least-squares estimator. observation matrix drawn random. kmax proposition yields upper bound oracle risk. combining upper bound lower bound yields claimed lower bound adaptivity index least squares estimator. earlier construction section know |||y cmls|||f |||y fm|||f m∗|||f guarantees cmls consequently consider line passes points cmls. given line consider auxiliary estimator rn×n denote euclidean projection matrix onto hypercube n×n. projection actually simple closed-form expression simply clips every entry matrix unit interval since projection onto convex non-expansive must cmls matrix written obey monotonicity conditions cmls; conversely rows/columns obey inverted monotonicity conditions speciﬁed rows/columns moreover since matrices cmls satisfy shifted-skew-symmetry matrix addition pair satisfy constraint using elementary facts veriﬁed monotonicity shifted-skew-symmetry conditions matrix thus retained projection arguments imply hence matrix feasible optimization problem optimality cmls must |||y π||| −cmls||| hand since cmls feasible optimization problem proposed notion adaptivity index measure abilities estimator automatically adapt intrinsic complexity problem. notion helps obtain nuanced evaluation estimator informative classical notion worstcase error. provided sharp characterizations optimal adaptivity achieved statistical sense achieved computationally eﬃcient estimators. logarithmic factors results arise corresponding logarithmic factors metric entropy results wellner understanding necessity open question. statistical practice often desire estimators perform well variety diﬀerent senses. believe estimating matrices minimax-optimal rate frobenius norm studied detail paper also computationally diﬃcult. hope formally establish future work. finally developing broader understanding fundamental limits imposed computational considerations statistical problems important avenue continued investigation.", "year": 2016}