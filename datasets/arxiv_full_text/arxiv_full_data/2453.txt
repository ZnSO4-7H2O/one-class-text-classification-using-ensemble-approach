{"title": "Learning to Act Greedily: Polymatroid Semi-Bandits", "tag": ["cs.LG", "cs.AI", "stat.ML"], "abstract": "Many important optimization problems, such as the minimum spanning tree and minimum-cost flow, can be solved optimally by a greedy method. In this work, we study a learning variant of these problems, where the model of the problem is unknown and has to be learned by interacting repeatedly with the environment in the bandit setting. We formalize our learning problem quite generally, as learning how to maximize an unknown modular function on a known polymatroid. We propose a computationally efficient algorithm for solving our problem and bound its expected cumulative regret. Our gap-dependent upper bound is tight up to a constant and our gap-free upper bound is tight up to polylogarithmic factors. Finally, we evaluate our method on three problems and demonstrate that it is practical.", "text": "branislav kveton technicolor labs antonio road suite altos zheng yahoo labs sunnyvale united states azin ashkan technicolor labs antonio road suite altos michal valko inria lille nord europe sequel team avenue halley villeneuve d’ascq france many important optimization problems minimum spanning tree minimum-cost solved optimally greedy method. work study learning variant problems model problem unknown learned interacting repeatedly environment bandit setting. formalize learning problem quite generally learning maximize unknown modular function known polymatroid. propose computationally efﬁcient algorithm solving problem bound expected cumulative regret. gap-dependent upper bound tight constant gap-free upper bound tight polylogarithmic factors. finally evaluate method three problems demonstrate practical. keywords bandits combinatorial optimization matroids polymatroids submodularity many important combinatorial optimization problems minimum-cost minimum spanning tree solved optimally greedy algorithm. problems solved efﬁciently viewed optimization matroids polymatroids speciﬁcally formulated ﬁnding maximum modular function polytope submodular function. work study learning variant problem modular function unknown. learning problem sequential divided episodes. episode learning agent chooses feasible solution problem basis polymatroid; observes noisy weights items nonzero contributions basis; receives product basis weights payoff. goal learning agent maximize expected cumulative return time equivalently minimize expected cumulative regret. many practical problems formulated setting learning routing network delays links network stochastic initially unknown. problem bases spanning trees observed weights delays links spanning tree cost observed delays. paper makes three contributions. first bring together concepts bandits polymatroids propose polymatroid bandits class stochastic learning problems. multi-armed bandit framework solving online learning problems require exploration. framework successfully applied variety problems including combinatorial optimization paper extend bandits combinatorial optimization problems solved greedily. second propose simple algorithm solving problem explores based optimism face uncertainty. refer algorithm optimistic polymatroid maximization properties. first computationally efﬁcient basis episode chosen greedily. second also sample efﬁcient. particular derive gap-dependent upper bound expected cumulative regret show tight constant also derive gap-free upper bound show tight polylogarithmic factors. upper bounds exploit structural properties polymatroids improve general-purpose bounds stochastic combinatorial semi-bandits. finally evaluate three problems. ﬁrst problem synthetic network demonstrate gap-dependent upper bound quite practical order magnitude larger observed regret. second problem learning routing network internet service provider last problem learning recommend diverse movies. three problems solved efﬁciently framework. demonstrates practical solve wide range problems. adopt following notation. write instead instead also write instead instead section ﬁrst introduce polymatroids illustrate practical problems. polymatroid polytope associated submodular function. speciﬁcally polymatroid pair ground items function power non-negative real numbers. function monotonic submodular since monotonic maxima. refer rank polymatroid denote without loss generality assume items submodular indirectly assume optimization polymatroids weighted polymatroid polymatroid associated vector weights e-th entry weight item classical problem polyhedral optimization maximum-weight basis polymatroid basis computed greedily greedy algorithm works follows. first items sorted decreasing order weights assume ties broken arbitrary ﬁxed rule. second computed many existing problems viewed optimization polymatroid instance polymatroids generalize matroids notion independence combinatorial optimization closely related computational efﬁciency. particular matroid ground independent sets vector optimized variables. exponentially many constraints subset therefore cannot solved directly. nevertheless greedy solve problem time. therefore problem efﬁcient form linear programming. many combinatorial optimization concepts ﬂows entropy submodular. therefore optimization concepts involves polymatroids. well-known problem class minimum-cost problem formulated follows. ground source nodes network maximum source nodes cost unit source node minimum-weight basis polymatroid maximum minimum cost refer minimum-cost ﬂow. choice motivated three reasons. first study problem learning greedily. interested bases computed greedily. second many optimization problems interest combinatorial nature bases suitable feasible solutions. instance graphic matroid spanning trees. linear matroid maximal sets linearly independent vectors. bases interpretation. another example recommendations problem section problem greedy minimal items cover topic popular item according bases cannot interpreted way. finally note choice impact notion optimality. particular optimal greedy also optimal since follows that maximum-weight basis polymatroid cannot computed weights unknown. happen practice. instance suppose want recommend diverse popular movies popularity movies initially unknown perhaps movies newly released. work study learning variant maximizing modular function polymatroid solve type problems. entry weight item assume weights drawn i.i.d. unknown. without loss generality assume distribution unit cube that assume anything denote expected weights items assumptions items item associated feasible solution associated arms arms items non-zero contributions arms pulled learning agent receives payoff observes weights items non-zero contributions feedback model known semi-bandit solution problem maximum-weight basis expectation problem equivalent problem therefore solved greedily greedy. choose observation model several reasons. first model natural generalization matroid bandits matroid bandits bases form learning agents observes weights chosen items case equivalent second observation model suitable motivating examples speciﬁcally minimum-cost problem assume learning agent observes costs source nodes contribute maximum ﬂow. movie recommendation problem agent observes individual movies chosen user recommended movies. finally observation model allows derive similar regret bounds matroid bandits i.i.d. sequence weights drawn distribution episode learning agent chooses basis based prior actions observations wt−; gains observes weights items nonzero contributions agent interacts environment episodes. goal agent maximize expected cumulative return equivalently minimize expected cumulative regret learning algorithm designed based optimism face uncertainty principle particular greedy method ﬁnding maximum-weight basis polymatroid expected weight item substituted optimistic estimate refer method optimistic polymatroid maximization ˆwtt− estimate expected weight episode ct−tt− radius conﬁdence interval around estimate denotes number times item selected ﬁrst episodes second compute maximum-weight basis respect using greedy. finally select basis observe weights items update model environment. radius designed high-probability upper bound corresponding weight ˆws. ucbs encourage exploration items observed sufﬁciently often. number past episodes increases better estimates weights conﬁdence intervals shrink starts exploiting rewarding items. term increases time enforces continuous exploration. simplicity exposition assume initialized observing item once. practice initialization step implemented efﬁciently ﬁrst episodes. particular episode chooses ﬁrst item items arbitrary order. corresponding regret bounded basis greedy method therefore extremely computationally efﬁcient. particular suppose function oracle queried time. time complexity episode comparable sorting numbers. design surprising draws prior work major contribution derive tight upper bound regret opm. analysis novel signiﬁcant improvement kveton analyze regret context matroids. roughly speaking analysis kveton leverages augmentation property matroid. analysis based submodularity polymatroid. section organized follows. first propose novel decomposition regret single episode loosely speaking decompose regret parts fractional gains individual items optimal suboptimal bases. part proof relies heavily structure polymatroid major contribution. second apply regret decomposition bound regret third compare regret bounds existing upper bounds prove matching lower bounds finally summarize results item deﬁne largest index expected weight item larger item item contributes simplicity exposition assume item contributes optimal basis guarantees properly deﬁned items item assume regret decomposition based rewriting difference expected returns bases differences returns intermediate solutions obtained interleaving bases. refer solutions augmentations. k-augmentation vector that second claim proved follows. guaranteed observe weight item furthermore chooses item item lemma contradiction assumption. result must true implies instance algorithm combinatorial semi-bandits natural upper bounds regret tighter stochastic combinatorial semi-bandits section show case comparing upper bounds kveton upper bound tighter factor upper bound kveton however notion item-based differs kveton solution-based. hypothetically improvement bound solely different notion gap. rest section argue case. speciﬁcally consider following uniform matroid bandit. items means items feasible. rank-k uniform matroid. distribution weights items weight item distributed independently items. weight item drawn i.i.d. bernoulli distribution mean bunif uniform matroid bandit. optimal solution bunif ﬁrst items largest weights. property bunif gaps coincide kveton particular suboptimal item difference returns best suboptimal solution contains item difference returns item optimal item gaps same bound indeed factor tighter bound kveton prove gap-dependent gap-free lower bounds regret polymatroid bandits. bounds derived class polymatroid bandits equivalent independent bernoulli bandits. speciﬁcally consider following partition matroid bandit. items partition |bi| integer. family independent sets deﬁned partition matroid rank probability distribution weights items weight item distributed independently items. weight item drawn i.i.d. bernoulli distribution mean bpart partition matroid bandit. property bpart equivalent independent bernoulli bandits arms each. optimal item bandit item smallest index. optimal solution also note gaps formalize gap-dependent lower bound introduce notion consistent algorithms. algorithm consistent partition matroid bandit number times item observed episodes. rest analysis focus consistent algorithms. without loss generality. particular deﬁnition consistency inconsistent algorithms perform poorly instances problem therefore cannot achieve logarithmic regret instances. divergence bernoulli variables means ﬁrst inequality existing lower bound bernoulli bandits applied separately part second inequality follows proof matroid bandit bpart viewed independent bernoulli bandits arms each. theorem auer time horizon chosen regret algorithm bandits least least ∆ee∗. bounds linear sublinear words scale favorably quantities interest therefore expect practical. upper bound matches lower bound proposition constant therefore tight. also factor tighter upper bound kveton general class problems stochastic combinatorial semi-bandits upper bound matches lower bound proposition factor gap-dependent upper bound form bound auer multi-armed bandits. suggests sample complexity learning maximum-weight basis polymatroid similar multi-armed bandit problem. major difference deﬁnitions gaps. words learning polymatroids extremely sample efﬁcient. step analysis showing difference expected returns bases expressed differences expected returns intermediate solutions bases difference gains consecutive bases negative entry. decomposition highly non-trivial derived based submodularity problem. important aspect analysis terms bounded necessary therefore upper bounds tight contain quantities native problem maximum number non-zero entries fact assumption items notion complexity never larger maximum number non-zero entries feasible solution common quantity regret bounds combinatorial bandits conduct three experiments. section evaluate tightness regret bounds synthetic problem. section apply problem learning routing networks. finally section evaluate problem recommending diverse movies. experiments episodic. episode chooses basis observes weights items contribute updates model world. sections performance measured expected per-step return episodes compare baselines. ﬁrst baseline maximum-weight basis notion optimality. second baseline ε-greedy policy. policy implemented similarly opm. particular algorithm modiﬁed follows. episode ˆwtt− items probability probability chosen randomly items exploration rate experiments best performing ε-greedy policy class ε-greedy policies ﬁrst experiment evaluate synthetic problem learning minimum-cost ﬂows. experiment shows gap-dependent upper bound practical. experiment larger values setting gap-dependent upper bound tighter gap-free one. experiment network source nodes sink node. network illustrated figure network deﬁned three constraints. first maximum source node second maximum consecutive source nodes figure report regret function number episodes various settings observe three major trends. first regret grows order suggested upper bound. second regret change much consistent fact bound independent finally note bound surprisingly tight. particular larger values times larger actual regret. table report regret episodes various settings observe regret depends suggested upper bound. particular change much doubles double halve note upper bound surprisingly tight never times larger actual regret. second experiment apply problem learning routing networks internet service provider routing network spanning tree goal identify spanning tree lowest expected latency edges. note minimization problem. therefore refer return policy cost. problem formulated graphic matroid bandit form polymatroid bandit. ground edges graph represents topology network. experiment networks rocketfuel dataset nodes edges edges independent forms forest. corresponding rank function deﬁned expected latency recorded dataset; exponential noise. latency ranges milliseconds. noise model motivated observation latency networks mostly explained geographical distances expected table description networks experiments expected per-step costs building minimum spanning trees networks episodes. latencies costs reported milliseconds. movie title american beauty jurassic park saving private ryan matrix fargo shakespeare love comedy romance l.a. conﬁdential e.t. ghostbusters story figure left. return three movie recommendation policies episodes. right. popular movies optimal solution movies shown order decreasing popularity. movie genre highlighted associated movie popular movie genre. figure report results largest networks. observe trends. first cost approaches optimal solution number episodes increases. second performs better ε-greedy policy less episodes. costs policies networks reported table observe outperforms ε-greedy policy typically large margin. learns quickly networks sparse. particular number edges network never four times larger number edges spanning tree. theoretically edge observed least four episodes learns quickly mean latency edge. third experiment evaluated movie recommender. recommender used repeatedly simulated users goal learn recommended diverse movies maximize satisfaction average user system like could used practice identify trending movies. user episode chosen randomly pool users. assume user watches movie movie rated user dataset. expected weight probability movie watched randomly chosen user. results reported figure section observe major trends. first return approaches optimal solution number episodes increases. second performs better ε-greedy policy episodes. optimal solution visualized figure contains movies therefore extremely sparse. polymatroids generalization matroids therefore work viewed generalization matroid semi-bandits signiﬁcantly extend work kveton essentially show problem maximizing modular function subject submodular constraint learned efﬁciently. generalization non-trivial. instance part analysis novel regret decomposition leverages submodularity constraint. structure apparent work kveton problem instance stochastic combinatorial semi-bandit proposed analyzed ucb-like algorithm solving problem. chen kveton proved upper bounds regret algorithm respectively. latter tight instance ucb-like algorithm combinatorial optimization oracle greedy. optimization problem polymatroid therefore derive factor tighter gap-dependent regret bound kveton note gap-free regret bound magnitude. comband follow-the-perturbed-leader geometric resampling online stochastic mirror descent three recently proposed algorithms adversarial combinatorial semi-bandits. achieve optimal regret computationally efﬁcient ofﬂine variant combinatorial optimization problem solved efﬁciently osmd achieves optimal regret guaranteed computationally efﬁcient projection convex hull feasible cannot implemented efﬁciently. problem convex hull projection implemented time time complexity single step osmd several orders magnitude higher time complexity practical large values finally comband guaranteed computationally efﬁcient. based section cesa-bianchi lugosi even problem learning minimum spanning tree instance maximizing modular function polymatroid. several recent papers studied problem learning maximize submodular function papers loosely related work study different problem learning maximize unknown submodular function subject cardinality constraint. learning problem maximizing unknown modular function subject known submodular constraint. work study problem learning greedily. formulate problem learning maximize unknown modular function known polymatroid bandit setting. formulation quite general includes many popular problems learning variants minimum spanning tree minimum-cost ﬂow. propose computationally-efﬁcient method solving problem prove upper bounds regret. gap-dependent upper bound tight constant upper bound matches strongly believe factor eliminated audibert bubeck leave future work. thompson sampling often performs better practice believe relatively straightforward propose thompson-sampling variant replacing ucbs algorithm sampling posterior mean weights also believe regret algorithm bounded proved. reason frequentist analysis thompson sampling resembles result likely analysis thompson-sampling carried similarly paper. work study particular problem maximization modular function polymatroid particular learning setting stochastic semi-bandits. open question whether ideas paper generalize polymatroid problems maximizing modular function intersection matroids learning variants problem learning adversarial setting full-bandit feedback", "year": 2014}