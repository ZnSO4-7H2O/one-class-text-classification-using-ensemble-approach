{"title": "Progressive Growing of GANs for Improved Quality, Stability, and  Variation", "tag": ["cs.NE", "cs.LG", "stat.ML"], "abstract": "We describe a new training methodology for generative adversarial networks. The key idea is to grow both the generator and discriminator progressively: starting from a low resolution, we add new layers that model increasingly fine details as training progresses. This both speeds the training up and greatly stabilizes it, allowing us to produce images of unprecedented quality, e.g., CelebA images at 1024^2. We also propose a simple way to increase the variation in generated images, and achieve a record inception score of 8.80 in unsupervised CIFAR10. Additionally, we describe several implementation details that are important for discouraging unhealthy competition between the generator and discriminator. Finally, we suggest a new metric for evaluating GAN results, both in terms of image quality and variation. As an additional contribution, we construct a higher-quality version of the CelebA dataset.", "text": "describe training methodology generative adversarial networks. idea grow generator discriminator progressively starting resolution layers model increasingly details training progresses. speeds training greatly stabilizes allowing produce images unprecedented quality e.g. celeba images also propose simple increase variation generated images achieve record inception score unsupervised cifar. additionally describe several implementation details important discouraging unhealthy competition generator discriminator. finally suggest metric evaluating results terms image quality variation. additional contribution construct higher-quality version celeba dataset. generative methods produce novel samples high-dimensional data distributions images ﬁnding widespread example speech synthesis image-to-image translation image inpainting currently prominent approaches autoregressive models variational autoencoders generative adversarial networks currently signiﬁcant strengths weaknesses. autoregressive models pixelcnn produce sharp images slow evaluate latent representation directly model conditional distribution pixels potentially limiting applicability. vaes easy train tend produce blurry results restrictions model although recent work improving gans produce sharp images albeit fairly small resolutions somewhat limited variation training continues unstable despite recent progress hybrid methods combine various strengths three behind gans image quality typically consists networks generator discriminator generator produces sample e.g. image latent code distribution images ideally indistinguishable training distribution. since generally infeasible engineer function tells whether case discriminator network trained assessment since networks differentiable also gradient steer networks right direction. typically generator main interest discriminator adaptive loss function gets discarded generator trained. multiple potential problems formulation. measure distance training distribution generated distribution gradients point less random directions distributions substantial overlap i.e. easy tell apart originally jensen-shannon divergence used distance metric recently formulation improved number stable alternatives proposed including least squares absolute deviation margin wasserstein distance thus drastically amplifying gradient problem. large resolutions also necessitate using smaller minibatches memory constraints compromising training stability. insight grow generator discriminator progressively starting easier low-resolution images layers introduce higher-resolution details training progresses. greatly speeds training improves stability high resolutions discuss section formulation explicitly require entire training data distribution represented resulting generative model. conventional wisdom tradeoff image quality variation view recently challenged degree preserved variation currently receiving attention various methods suggested measuring including inception score multi-scale structural similarity birthday paradox explicit tests number discrete modes discovered describe method encouraging variation section propose metric evaluating quality variation section section discusses subtle modiﬁcation initialization networks leading balanced learning speed different layers. furthermore observe mode collapses traditionally plaguing gans tend happen quickly course dozen minibatches. commonly start discriminator overshoots leading exaggerated gradients unhealthy competition follows signal magnitudes escalate networks. propose mechanism stop generator participating escalation overcoming issue evaluate contributions using celeba lsun cifar datasets. improve best published inception score cifar. since datasets commonly used benchmarking generative methods limited fairly resolution also created higher quality version celeba dataset allows experimentation output resolutions pixels. dataset full implementation available https//github.com/tkarras/progressive_growing_of_gans trained networks found https//drive.google.com/open?id=bqlcyyjmiznhfultdyclxu along result images supplementary video illustrating datasets additional results latent space interpolations https//youtu.be/gdecz-qtg. primary contribution training methodology gans start low-resolution images progressively increase resolution adding layers networks visualized figure incremental nature allows training ﬁrst discover large-scale structure image distribution shift attention increasingly ﬁner scale detail instead learn scales simultaneously. generator discriminator networks mirror images always grow synchrony. existing layers networks remain trainable throughout training process. layers added networks fade smoothly illustrated figure avoids sudden shocks already well-trained smaller-resolution layers. appendix describes structure generator discriminator detail along training parameters. observe progressive training several beneﬁts. early generation smaller images substantially stable less class information fewer modes increasing resolution little little continuously asking much simpler question compared goal discovering mapping latent vectors e.g. images. approach conceptual similarity recent work chen koltun practice stabilizes training sufﬁciently reliably synthesize megapixel-scale images using wgan-gp loss even lsgan loss figure training starts generator discriminator spatial resolution pixels. training advances incrementally layers thus increasing spatial resolution generated images. existing layers remain trainable throughout process. refers convolutional layers operating spatial resolution. allows stable synthesis high resolutions also speeds training considerably. right show example images generated using progressive growing another beneﬁt reduced training time. progressively growing gans iterations done lower resolutions comparable result quality often obtained times faster depending ﬁnal output resolution. idea growing gans progressively related work wang multiple discriminators operate different spatial resolutions. work turn motivated durugkar generator multiple discriminators concurrently ghosh opposite multiple generators discriminator. hierarchical gans deﬁne generator discriminator level image pyramid. methods build observation work complex mapping latents high-resolution images easier learn steps crucial difference single instead hierarchy them. contrast early work adaptively growing networks e.g. growing neural neuro evolution augmenting topologies grow networks greedily simply defer introduction pre-conﬁgured layers. sense approach resembles layer-wise training autoencoders gans tendency capture subset variation found training data salimans suggest minibatch discrimination solution. compute feature statistics individual images also across minibatch thus encouraging minibatches generated training images show similar statistics. implemented adding minibatch layer towards discriminator layer learns large tensor projects input activation array statistics. separate statistics produced example minibatch concatenated layer’s output discriminator statistics internally. simplify approach drastically also improving variation. simpliﬁed solution neither learnable parameters hyperparameters. ﬁrst compute standard deviation feature spatial location minibatch. average estimates features spatial locations arrive single value. replicate value concatenate spatial locations minibatch yielding additional feature map. layer could inserted anywhere discriminator found best insert towards experimented richer statistics able improve variation further. parallel work provide theoretical insights beneﬁts showing multiple images discriminator. figure doubling resolution generator discriminator fade layers smoothly. example illustrates transition images images transition treat layers operate higher resolution like residual block whose weight increases linearly refer doubling halving image resolution using nearest neighbor ﬁltering average pooling respectively. torgb represents layer projects feature vectors colors fromrgb reverse; convolutions. training discriminator feed real images downscaled match current resolution network. resolution transition interpolate resolutions real images similarly generator output combines resolutions. alternative solutions variation problem include unrolling discriminator regularize updates repelling regularizer adds loss term generator trying encourage orthogonalize feature vectors minibatch. multiple generators ghosh also serve similar goal. acknowledge solutions increase variation even solution possibly orthogonal leave detailed comparison later time. gans prone escalation signal magnitudes result unhealthy competition networks. earlier solutions discourage using variant batch normalization generator often also discriminator. normalization methods originally introduced eliminate covariate shift. however observed issue gans thus believe actual need gans constraining signal magnitudes competition. different approach consists ingredients neither include learnable parameters. equalized learning rate deviate current trend careful weight initialization instead trivial initialization explicitly scale weights runtime. precise wi/c weights per-layer normalization constant he’s initializer beneﬁt dynamically instead initialization somewhat subtle relates scale-invariance commonly used adaptive stochastic gradient descent methods rmsprop adam methods normalize gradient update estimated standard deviation thus making update independent scale parameter. result parameters larger dynamic range others take longer adjust. scenario modern initializers cause thus possible learning rate large small time. approach ensures dynamic range thus learning speed weights. similar reasoning independently used laarhoven disallow scenario magnitudes generator discriminator spiral control result competition normalize feature vector pixel unit length generator convolutional layer. using variant local response normalizaxy) tion conﬁgured axy/ number feature maps original normalized feature vector pixel respectively. surprising heavy-handed constraint seem harm generator indeed datasets change results much prevents escalation signal magnitudes effectively needed. multi-scale statistical similarity assessing results order compare results another needs investigate large number images tedious difﬁcult subjective. thus desirable rely automated methods compute indicative metric large image collections. noticed existing methods ms-ssim large-scale mode collapses reliably fail react smaller effects loss variation colors textures also directly assess image quality terms similarity training set. build intuition successful generator produce samples whose local image structure similar training scales. propose study considering multiscale statistical similarity distributions local image patches drawn laplacian pyramid representations generated target images starting low-pass resolution pixels. standard practice pyramid progressively doubles full resolution reached successive level encoding difference up-sampled version previous level. single laplacian pyramid level corresponds speciﬁc spatial frequency band. randomly sample images extract descriptors level laplacian pyramid giving descriptors level. descriptor pixel neighborhood color channels denoted denote patches level training w.r.t. generated mean standard deviation color channel estimate statistical similarity computing sliced wasserstein distance efﬁciently computable randomized approximation earthmovers distance using projections intuitively small wasserstein distance indicates distribution patches similar meaning training images generator samples appear similar appearance variation spatial resolution. particular distance patch sets extracted lowestresolution images indicate similarity large-scale image structures ﬁnest-level patches encode information pixel-level attributes sharpness edges noise. experiments section discuss experiments conducted evaluate quality results. please refer appendix detailed description network structures training conﬁgurations. also invite reader consult accompanying video additional result images latent space interpolations. section distinguish network structure training conﬁguration training loss ﬁrst sliced wasserstein distance multi-scale structural similarity evaluate importance individual contributions also perceptually validate metrics themselves. building previous state-of-theart loss function training conﬁguration unsupervised setting using celeba lsun bedroom datasets gulrajani progressive growing small minibatch revised training parameters minibatch discrimination minibatch stddev equalized learning rate pixelwise normalization converged table sliced wasserstein distance generated training images multi-scale structural similarity among generated images several training setups column represents level laplacian pyramid last gives average four distances. figure celeba examples corresponding rows table intentionally non-converged. converged result. notice images show aliasing sharp dataset model learns replicate faithfully. resolution. celeba particularly well suited comparison training images contain noticeable artifacts difﬁcult generator reproduce faithfully. test amplify differences training conﬁgurations choosing relatively low-capacity network structure terminating training discriminator shown total real images. results fully converged. table lists numerical values ms-ssim several training conﬁgurations individual contributions cumulatively enabled baseline ms-ssim numbers averaged pairs generated images calculated described section generated celeba images conﬁgurations shown figure space constraints ﬁgure shows small number examples table signiﬁcantly broader available appendix intuitively good evaluation metric reward plausible images exhibit plenty variation colors textures viewpoints. however captured ms-ssim immediately conﬁguration generates signiﬁcantly better images conﬁguration ms-ssim remains approximately unchanged measures variation outputs similarity training set. hand indicate clear improvement. ﬁrst training conﬁguration corresponds gulrajani featuring batch normalization generator layer normalization discriminator minibatch size enables progressive growing networks results sharper believable output images. correctly ﬁnds distribution generated images similar training set. primary goal enable high output resolutions requires reducing size minibatches order stay within available memory budget. illustrate ensuing challenges decrease minibatch size generated images unnatural clearly visible metrics. stabilize training process adjusting hyperparameters well removing batch normalization layer normalization intermediate test enable minibatch discrimination somewhat surprisingly fails improve metrics including ms-ssim measures output variation. contrast minibatch standard deviation improves average scores images. enable remaining contributions leading overall improvement figure effect progressive growing training speed convergence. timings measured single-gpu setup using nvidia tesla statistical similarity respect wall clock time gulrajani using celeba resolution. graph represents sliced wasserstein distance level laplacian pyramid vertical line indicates point stop training table graph progressive growing enabled. dashed vertical lines indicate points double resolution effect progressive growing training speed resolution. subjective visual quality. finally non-crippled network longer training feel quality generated images least comparable best published results far. figure illustrates effect progressive growing terms metric image throughput. ﬁrst plots correspond training conﬁguration gulrajani without progressive growing. observe progressive variant offers main beneﬁts converges considerably better optimum also reduces total training time factor two. improved convergence explained implicit form curriculum learning imposed gradually increasing network capacity. without progressive growing layers generator discriminator tasked simultaneously ﬁnding succinct intermediate representations large-scale variation small-scale detail. progressive growing however existing low-resolution layers likely already converged early networks tasked reﬁning representations increasingly smaller-scale effects layers introduced. indeed figure largest-scale statistical similarity curve reaches optimal value quickly remains consistent throughout rest training. smaller-scale curves level resolution increased convergence curve equally consistent. non-progressive training figure scale metric converges roughly unison could expected. speedup progressive growing increases output resolution grows. figure shows training progress measured number real images shown discriminator function training time training progresses resolution. progressive growing gains signiﬁcant head start networks shallow quick evaluate beginning. full resolution reached image throughput equal methods. plot shows progressive variant reaches approximately million images hours whereas extrapolated non-progressive variant would take hours reach point. case progressive growing offers roughly speedup. meaningfully demonstrate results high output resolutions need sufﬁciently varied high-quality dataset. however virtually publicly available datasets previously used literature limited relatively resolutions ranging created high-quality version celeba dataset consisting images resolution. refer appendix details generation dataset. contributions allow deal high output resolutions robust efﬁcient fashion. figure shows selected images produced network. megapixel results shown another dataset results vastly varied higher perceptual quality. please refer appendix larger result images well nearest neighbors found training data. accompanying video shows latent space interpolations visualizes progressive training. interpolation works ﬁrst randomize latent code frame blur latents across time gaussian ﬁnally normalize vector hypersphere. trained network tesla gpus days longer observed qualitative differences results consecutive training iterations. implementation used adaptive minibatch size depending current output resolution available memory budget optimally utilized. order demonstrate contributions largely orthogonal choice loss function also trained network using lsgan loss instead wgan-gp loss. figure shows examples images produced using method using lsgan. details setup given appendix figure shows purely visual comparison solution earlier results lsun bedroom. figure gives selected examples seven different lsun categories larger non-curated results lsun categories available appendix video demonstrates interpolations. aware earlier results categories categories work better others feel overall quality high. cifar inception scores best inception scores cifar aware unsupervised label conditioned setups large difference numbers primarily caused ghosts necessarily appear classes unsupervised setting label conditioning remove many transitions. contributions enabled unsupervised setting. appendix shows representative generated images along comprehensive list results earlier methods. network training setup celeba progression limited course. customization wgan-gp’s regularization term eˆx∼pˆx|| γ)/γ]. gulrajani used corresponds -lipschitz noticed fact signiﬁcantly better prefer fast transitions minimize ghosts. tried trick datasets. discussion quality results generally high compared earlier work gans training stable large resolutions long true photorealism. semantic sensibility understanding dataset-dependent constraints certain objects straight rather curved leaves desired. also room improvement micro-structure images. said feel convincing realism within reach especially celeba-hq. acknowledgements would like thank mikael honkavaara tero kuosmanen timi hietanen compute infrastructure. dmitry korobchenko richard calderwood efforts related celeba-hq dataset. oskar elek jacob munkberg hasselgren useful comments. martin heusel hubert ramsauer thomas unterthiner bernhard nessler sepp hochreiter. gans trained time-scale update rule converge local nash equilibrium. nips diederik kingma salimans rafal jozefowicz chen ilya sutskever welling. improved variational inference inverse autoregressive ﬂow. nips volume christian ledig lucas theis ferenc huszar jose caballero andrew aitken alykhan tejani johannes totz zehan wang wenzhe shi. photo-realistic single image super-resolution using generative adversarial network. corr abs/. julien rabin gabriel peyr julie delon marc bernot. wasserstein barycenter application texture mixing. scale space variational methods computer vision a¨aron oord sander dieleman heiga karen simonyan oriol vinyals alex graves kalchbrenner andrew senior koray kavukcuoglu. wavenet generative model audio. corr abs/. a¨aron oord kalchbrenner oriol vinyals lasse espeholt alex graves koray kavukcuoglu. conditional image generation pixelcnn decoders. corr abs/. ting-chun wang ming-yu jun-yan andrew kautz bryan catanzaro. high-resolution image synthesis semantic manipulation conditional gans. corr abs/. zhang hongsheng shaoting zhang xiaolei huang xiaogang wang dimitris metaxas. stackgan text photo-realistic image synthesis stacked generative adversarial networks. iccv generator latent vector conv conv upsample conv conv upsample conv conv upsample conv conv upsample conv conv upsample conv conv upsample conv conv upsample conv conv upsample conv conv conv total trainable parameters discriminator input image conv conv conv downsample conv conv downsample conv conv downsample conv conv downsample conv conv downsample conv conv downsample conv conv downsample conv conv downsample minibatch stddev conv conv fully-connected total trainable parameters table shows network architectures full-resolution generator discriminator celeba-hq dataset. networks consist mainly replicated -layer blocks introduce course training. last conv layer generator corresponds torgb block figure ﬁrst conv layer discriminator similarly corresponds fromrgb. start resolution train networks shown discriminator real images total. alternate phases fade ﬁrst -layer block next images stabilize networks images fade next -layer block images etc. latent vectors correspond random points -dimensional hypersphere represent training generated images leaky relu leakiness layers networks except last layer uses linear activation. employ batch normalization layer normalization weight normalization either network perform pixelwise normalization feature vectors conv layer generator described section initialize bias parameters zero weights according normal distribution unit variance. however scale weights layer-speciﬁc constant runtime described section inject across-minibatch standard deviation additional feature resolution toward discriminator described section upsampling downsampling operations table correspond element replication average pooling respectively. train networks using adam learning rate decay rampdown visualizing generator output given point training exponential running average weights generator decay minibatch size resolutions gradually decrease size according avoid exceeding available memory budget. wgan-gp loss unlike gulrajani alternate optimizing generator discriminator per-minibatch basis i.e. ncritic additionally introduce fourth term discriminator loss extremely furthermore section uses slightly lower-capacity version halve number feature maps conv layers resolution divide subsequent resolutions. leaves feature maps last conv layers. table figure train resolution total images instead also fade layers duration images. gulrajani case table follow training conﬁguration closely possible. particular ncritic \u0001drift minibatch size disable progressive resolution minibatch stddev well weight scaling runtime initialize weights using he’s initializer furthermore modify generator replacing lrelu relu linear activation tanh last layer pixelwise normalization batch normalization. discriminator layer normalization conv conv layers. latent vectors components sampled independently normal distribution. lsgan generally less stable loss function wgan-gp also tendency lose variation towards long runs. thus prefer wgan-gp also produced high-resolution images building lsgan. example images figure lsgan-based. techniques described sections need additional hack lsgan prevents training spiraling control dataset easy discriminator discriminator gradients risk becoming meaningless result. adaptively increase magnitude multiplicative gaussian noise discriminator function discriminator’s output. noise applied input conv conv layer. long history adding noise discriminator generally detrimental image quality ideally would never that according tests case wgan-gp magnitude noise determined ˆdt− exponential moving average discriminator output motivation behind hack lsgan seriously unstable approaches section describe process used create high-quality version celeba dataset consisting images resolution. starting point took collection in-the-wild images included part original celeba dataset. images extremely varied terms resolution visual quality ranging show crowds several people whereas others focus face single person often part face. thus found necessary apply several image processing steps ensure consistent quality center images facial region. processing pipeline illustrated figure improve overall image quality preprocess jpeg image using pre-trained neural networks convolutional autoencoder trained remove jpeg artifacts natural images similar structure proposed adversarially-trained super-resolution network similar ledig handle cases facial region extends outside image employ padding ﬁltering extend dimensions image illustrated fig.. select oriented crop rectangle based facial landmark annotations included figure creating celeba-hq dataset. start jpeg image celeba inthe-wild dataset. improve visual quality jpeg artifact removal super-resolution extend image mirror padding gaussian ﬁltering produce visually pleasing depth-of-ﬁeld effect. finally facial landmark locations select appropriate crop region perform high-quality resampling obtain ﬁnal image resolution represent pixel locations landmarks mouth landmarks respectively indicate center size desired crop rectangle indicate orientation. constructed formulas empirically ensure crop rectangle stays consistent cases face viewed different angles. calculated crop rectangle transform rectangle pixels using bilinear ﬁltering scale resolution using ﬁlter. perform processing images dataset analyze resulting images estimate ﬁnal image quality sort images accordingly discard best images. frequency-based quality metric favors images whose power spectrum contains broad range frequencies approximately radially symmetric. penalizes blurry images well images conspicuous directional features e.g. visible halftoning patterns. selected cutoff point images practical sweet spot variation image quality appeared yield best results. cifar results figure shows non-curated images generated unsupervised setting table compares prior terms inception scores. report scores different ways highest score observed training runs mean standard deviation computed highest scores seen training starting random initializations. arguably latter methodology much meaningful lucky individual runs kind augmentation dataset. mnist-k discrete mode test crippled discriminator metz describe setup generator synthesizes mnist digits simultaneously color channels digits classiﬁed using pre-trained classiﬁer concatenated form number generate total images count many discrete modes covered. also compute divergence modern implementations trivially cover modes divergence thus metz specify fairly low-capacity generator severely crippled discriminators tease differences training methodologies. networks batch normalization. shown table using wgan-gp loss networks speciﬁed metz covers much modes original loss even unrolled original smaller discriminator. divergence arguably accurate metric count acts even favorably. replacing batch normalization normalization improves result considerably also removing trainable parameters discriminators. addition minibatch stddev layer improves scores restoring discriminator capacity within original. progression help much tiny images hurt either. progression table results mnist discrete mode test using tiny discriminators deﬁned metz number covered modes divergence uniform distribution given average standard deviation random initializations. higher better number modes lower better divergence. additional celeba-hq results figure shows nearest neighbors found generated images. figure gives additional generated examples celeba-hq. enabled mirror augmentation tests using celeba celeba-hq. addition sliced wasserstein distance also quote recently introduced fr´echet inception distance computed images. lsun results figures show representative images generated lsun categories. separate network trained category using identical parameters. categories trained using images except bedroom used available data. since images limited amount training data categories enabled mirror augmentation tests additional images table figure shows larger collections images corresponding non-converged setups table training time intentionally limited make differences various methods visible. figure celeba-hq results. next rows nearest neighbors found training data based feature-space distance. used activations layers suggested chen koltun crop highlighted bottom right image used comparison order exclude image background focus search matching facial features. figure additional images generated using celeba-hq dataset. sliced wasserstein distance levels average fr´echet inception distance computed images video latent space interpolations. figure example images generated lsun categories. sliced wasserstein distance given levels average bolded. also quote fr´echet inception distance computed images. figure example images generated lsun categories. sliced wasserstein distance given levels average bolded. also quote fr´echet inception distance computed images. figure example images generated lsun categories. sliced wasserstein distance given levels average bolded. also quote fr´echet inception distance computed images. figure example images generated lsun categories. sliced wasserstein distance given levels average bolded. also quote fr´echet inception distance computed images. figure example images generated lsun categories. sliced wasserstein distance given levels average bolded. also quote fr´echet inception distance computed images. figure example images generated lsun categories. sliced wasserstein distance given levels average bolded. also quote fr´echet inception distance computed images.", "year": 2017}