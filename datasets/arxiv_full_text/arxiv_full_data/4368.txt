{"title": "Analyzing features learned for Offline Signature Verification using Deep  CNNs", "tag": ["cs.CV", "stat.ML"], "abstract": "Research on Offline Handwritten Signature Verification explored a large variety of handcrafted feature extractors, ranging from graphology, texture descriptors to interest points. In spite of advancements in the last decades, performance of such systems is still far from optimal when we test the systems against skilled forgeries - signature forgeries that target a particular individual. In previous research, we proposed a formulation of the problem to learn features from data (signature images) in a Writer-Independent format, using Deep Convolutional Neural Networks (CNNs), seeking to improve performance on the task. In this research, we push further the performance of such method, exploring a range of architectures, and obtaining a large improvement in state-of-the-art performance on the GPDS dataset, the largest publicly available dataset on the task. In the GPDS-160 dataset, we obtained an Equal Error Rate of 2.74%, compared to 6.97% in the best result published in literature (that used a combination of multiple classifiers). We also present a visual analysis of the feature space learned by the model, and an analysis of the errors made by the classifier. Our analysis shows that the model is very effective in separating signatures that have a different global appearance, while being particularly vulnerable to forgeries that very closely resemble genuine signatures, even if their line quality is bad, which is the case of slowly-traced forgeries.", "text": "used train binary classiﬁer. writer-independent approach single global classiﬁer trained using dissimilarity approach using training consisted positive samples negative samples test time distance vector calculated query signature reference signatures classiﬁed using writer-independent classiﬁer. comprehensive review problem refer recent review recent work area explore variety different feature descriptors extended shadow code directional-probabilistic density function local binary patterns gray-level co-occurrence matrix histogram oriented gradients curvelet transform among others. instead relying hand-engineered feature extractors investigate feature learning algorithms applied task. previous research shown learn useful features ofﬂine signature veriﬁcation learning writer-independent features development dataset using formulation obtained results close state-of-the-art gpds dataset compared models rely single feature extractor technique. vein ribeiro used restricted boltzmann machines learning features signature images. however authors considered small users features actually classify signatures reporting visual representation learned weights. khalajzadeh used convolutional neural networks persian signature veriﬁcation considered skilled forgeries. paper analyze method introduced investigating impact depth deep convolutional neural network size embedding layer learning good representations signatures measured classiﬁcation performance different users. using better training techniques training network) improve performance signiﬁcantly achieving state-of-the-art performance equal error rate gpds- dataset surpasses results literature even comparing results model ensembles used. also perform analysis errors committed abstract—research ofﬂine handwritten signature veriﬁcation explored large variety handcrafted feature extractors ranging graphology texture descriptors interest points. spite advancements last decades performance systems still optimal test systems skilled forgeries signature forgeries target particular individual. previous research proposed formulation problem learn features data writer-independent format using deep convolutional neural networks seeking improve performance task. research push performance method exploring range architectures obtaining large improvement state-of-the-art performance gpds dataset largest publicly available dataset task. gpds- dataset obtained equal error rate compared best result published literature also present visual analysis feature space learned model analysis errors made classiﬁer. analysis shows model effective separating signatures different global appearance particularly vulnerable forgeries closely resemble genuine signatures even line quality case slowly-traced forgeries. handwritten signature widely accepted means authentication government legal commercial transactions. signature veriﬁcation systems conﬁrm identity person based signature classify signature samples genuine forgery ofﬂine signature veriﬁcation signatures acquired signature writing process completed scanning document containing signature. contrast online signature veriﬁcation signature captured directly device therefore dynamic information signature available velocity movements. lack dynamic information ofﬂine case makes challenging problem much effort ﬁeld devoted obtaining good feature representation signatures main approaches problem literature writer-dependent approach user training genuine signatures user model visualize quality learned features projection embedding space. visual analysis suggests learned features capture overall aspect signature sufﬁcient perform well separating genuine signatures skilled forgeries cases users complex signatures maintain stable signatures also notice learned features particularly vulnerable slowly-traced forgeries overall signature shape similar line quality poor. central idea learn feature representation ofﬂine signature veriﬁcation writerindependent format function extract features signatures users enrolled system resulting feature vectors train binary classiﬁer user. rationale learning feature representation writer-independent format two-fold learning feature representations directly user impractical given number samples available training ﬁxed representation useful user makes straightforward users system simply using model extract features user’s genuine signatures training writer-dependent classiﬁer. order learn features writer-independent format consider separate sets signatures development contains signatures users enrolled system exploitation contains disjoint users. signatures used learning feature representation signatures hypothesis features learned users relevant discriminate signatures users. hand represents users enrolled system. model trained extract features signatures users train binary classiﬁer user. worth noting skilled forgeries training since practical require forgeries user enrolled system. learn function training deep convolutional neural network development learning discriminate different users. model network output units estimate users signature image. work investigate different architectures learning feature representations. particular evaluate impact depth impact size embedding layer multiple studies suggest depth important address complex learning problems theoretical arguments shown empirically size embedding layer important factor practical considerations since size feature vectors used training classiﬁers user system well performing ﬁnal classiﬁcation. experiments difﬁculty train deep networks convolutional layers fullyconnected layers even using good initialization strategies recommended surprisingly issue network overﬁt training rather training validation losses remained high suggesting issues optimization problem. address issue used batch normalization technique consists normalizing outputs layer individual neuron values zero mean unit variance showed fundamental experiments obtaining good performance. details technique found experiments paper report results using batch normalization since proposed architectures could train network without technique table shows architectures evaluated research. models based alexnet architectures perform remarkably well computer vision problems. speciﬁes layer network. convolutional layers include ﬁrst ﬁlter-size followed number convolutional ﬁlters. pooling layers include size pooling region. unless otherwise indicated stride padding instance conv--s-p refers convolutional layer ﬁlters size stride padding. fully connected layers indicate name layer number output units. instance fc-n refers fully connected layer named output units. network alexnet_nreduced contains layers layers learnable parameters plus pooling layers vgg_n network contains layers layers learnable parameters plus pooling layers. used batch normalization learnable layer network applying non-linearity considered types networks alexnet network similar network proposed without local response normalization dropout alexnetreduced similar network reduced number layers; architecture similar vggreduced similar network reduced number layers. network consider different size embedding layer size feature vectors used training writer-dependent classiﬁers therefore impact cost training classiﬁers users enrolled system well classiﬁcation cost. considering different architectures size embedding layer tested total architectures. images pre-processed centralizing signatures image according center mass; removed background using otsu’s algorithm; inverted images background pixels zero valued; ﬁnally resizing pixels. details preprocessing steps found training deep development network extract feature representations signatures another users train writer-dependent classiﬁers. resize images pixels perform feedforward propagation fully-connect layer used activations layer feature vector image. architectures marked reduced contained fully-connected layers consider last layer softmax embedding layer architectures three fully-connected layers consider layers last fully-connected layers softmax layer. user build training consisted genuine signatures user positive samples genuine signatures users negative samples. train support vector machine classiﬁer dataset considering linear kernel. similarly different weights positive negative class account imbalance many negative samples positive. duplicating positive samples dataset roughly balanced. testing genuine signatures user random forgeries skilled forgeries made targeting user’s signature. conducted experiments gpds- dataset largest publicly available dataset ofﬂine signature veriﬁcation. dataset consists users genuine samples user skilled forgeries. divide dataset exploitation consisting ﬁrst users development consisting remaining users. since work evaluate many different architectures split development training validation using disjoint users set. subset users training models subset users validation. protocol train writer-dependent classiﬁers validation obtain estimate well features learned models generalize users. finally best models train classiﬁers users exploitation performed runs time training network different initialization using random split genuine signatures used training/testing training writer-dependent classiﬁers. report mean standard deviation errors across runs. compare previous work exploitation ﬁrst users ﬁrst users assess impact number genuine signatures user training experiments genuine signatures training evaluated results terms false rejection rate false acceptance rate completeness show results random skilled forgeries. also report equal error rates error frr. case genuine signatures skilled forgeries enable comparison work literature. considered forms calculating eeruser-thresholds using user-speciﬁc decision thresholds; eerglobal threshold using global decision threshold. lastly also report mean area curve averaging aucs receiving operating curves calculated user. calculating exploitation used decision threshold selected validation ﬁrst consider results experiments validation varying depth networks size embedding layer. experiments trained architectures deﬁned table used extract features users validation trained writer-dependent classiﬁers users using reference signatures. analyzed impact classiﬁcation performance different architectures/sizes embedding layer measuring average equal error rate classiﬁers. figures show classiﬁcation results validation using linear svms svms kernel respectively. ﬁrst thing notice that contrary empirical results object recognition observe improved performance deep architectures. figure equal error rates validation models trained linear using representation space learned different architectures different representation sizes figure cumulative frequencies pairs signatures within given distance. genuine-forgery pairs axis shows fraction pairs closer given euclidean distance. genuine-genuine pairs axis shows fraction pairs given distance show overlap genuine-forgery pairs. figure equal error rates validation models trained kernel using representation space learned different architectures different representation sizes best performing models alexnet architecture alexnetreduced using features training linear svms svms kernel respectively. also notice performance linear classiﬁer already quite good demonstrating feature representations learned writer-independent seems generalize well users. another aspect investigated signatures users validation represented embedding layer cnn. analysis took models obtained representations signatures users validation analyzed representation. started analyzing well separated signatures user feature space well compared skilled forgeries figure t-sne projection embedding space genuines signatures authors validation set. point refers signature different users shown different colors targeted users. measured euclidean distance genuine signatures user genuine signatures different users distance pairs genuine signature skilled forgery made user. figure plots cumulative frequency pairs signatures within given distance fraction pairs closer given euclidean distance embedding space. genuine-genuine pairs show inverse cumulative frequency better show overlap curves. particular distance axis expected false rejection rate false acceptance rate used distance-based classiﬁer single genuine signature reference. space projected genuine signatures different users well separated small overlap curves genuine-genuine pairs genuine-random forgery pairs. similar behavior seem genuine-skilled forgeries pairs although curves overlap case. figure t-sne projection embedding space genuine signatures skilled forgeries authors validation set. points refer skilled forgeries shown black border. zoomed area left shows region three skilled forgeries close four genuine signatures user gpds dataset. zoomed area right shows three skilled forgeries user genuine signatures embedding space representation space used t-sne algorithm project samples allows inspect local structure present higher dimensionality representation. figure shows result projection genuine signatures users validation set. point signature color represent different user. signatures different users well separated representation even though samples authors used train suggests learned representation speciﬁc writers training generalize users. figure shows projection genuine signatures skilled forgeries users. skilled forgeries scattered around several users skilled forgeries close representation genuine signatures. zoomed-in area ﬁgure shows skilled forgeries made particular user represented close genuine signatures user. forgeries close resemblance genuine signatures user overall shape. examined ﬁgure take genuine signature skilled forgery user close embedding space. notice overall shape skilled forgery similar genuine signature looking details strokes line quality skilled forgery much worse. noticed behavior users signatures. suggests features learned network useful distinguishing signatures table shows detailed result experiments exploitation set. noticed performance good terms equal error rates global decision thresholds validation effective situations particular using number samples used validation threshold selected. also notice performance using global threshold signiﬁcantly worse using per-user thresholds. note values refer scenario decision threshold optimally selected hard task explore paper. finally table compares best results state-of-the-art. noticed drop classiﬁcation errors compared literature even using samples user writer-dependent training. work presented detailed analysis different architectures learning representations ofﬂine signature veriﬁcation. showed features learned writerindependent format effective signature veriﬁcation achieving large improvement state-of-the-art performance gpds- dataset equal error rate compared reported literature. also showed writer-dependent classiﬁers trained features perform well even limited number samples user linear classiﬁers. analysis signature representations showed learned features mostly useful distinguish signatures general appearance instead ﬁner details. make features relevant distinguishing random forgeries skilled forgeries made quick motion hand makes features less discriminant slowly-traced skilled forgeries forgery looks like genuine signature overall shape poor line quality. future work investigate combination features features particularly targeted discriminate quality strokes. rivard granger sabourin multi-feature extraction selection writer-independent off-line signature veriﬁcation international journal document analysis recognition vol. chen ofﬂine signature veriﬁcation using real adaboost classiﬁer combination pseudo-dynamic features document analysis recognition international conference aug. guerbai chibani hadjadji effective oneclass classiﬁer handwritten signature veriﬁcation based writer-independent parameters pattern recognition vol. jan. hafemann sabourin oliveira writer-independent feature learning ofﬂine signature veriﬁcation using convolutional neural networks neural networks international joint conference ribeiro gonçalves santos kovacec deep learning networks off-line handwritten signature recognition progress pattern recognition image analysis computer vision applications. springer khalajzadeh mansouri teshnehlab persian signature veriﬁcation using convolutional neural networks international journal engineering research technology vol. esrsa publications simonyan zisserman very deep convolutional networks large-scale image recognition arxiv preprint arxiv. glorot bengio understanding difﬁculty training deep feedforward neural networks artiﬁcial intelligence statistics international conference krizhevsky sutskever hinton imagenet classiﬁcation deep convolutional neural networks advances neural information processing systems vargas ferrer travieso alonso off-line handwritten signature gpds- corpus document analysis recognition international conference vol. sep. maaten hinton visualizing data using t-sne journal machine learning research vol. vargas travieso alonso ferrer off-line signature veriﬁcation based gray level information using wavelet transform texture features international conference frontiers handwriting recognition nov. vargas ferrer travieso alonso offline signature veriﬁcation based grey level information using texture features pattern recognition vol. feb.", "year": 2016}