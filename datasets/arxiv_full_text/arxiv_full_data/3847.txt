{"title": "Plan, Attend, Generate: Character-level Neural Machine Translation with  Planning in the Decoder", "tag": ["cs.CL", "cs.NE"], "abstract": "We investigate the integration of a planning mechanism into an encoder-decoder architecture with an explicit alignment for character-level machine translation. We develop a model that plans ahead when it computes alignments between the source and target sequences, constructing a matrix of proposed future alignments and a commitment vector that governs whether to follow or recompute the plan. This mechanism is inspired by the strategic attentive reader and writer (STRAW) model. Our proposed model is end-to-end trainable with fully differentiable operations. We show that it outperforms a strong baseline on three character-level decoder neural machine translation on WMT'15 corpus. Our analysis demonstrates that our model can compute qualitatively intuitive alignments and achieves superior performance with fewer parameters.", "text": "investigate integration planning mechanism encoder-decoder architecture attention character-level machine translation. develop model plans ahead computes alignments source target sequences constructing matrix proposed future alignments commitment vector governs whether follow recompute plan. mechanism inspired strategic attentive reader writer model. proposed model end-to-end trainable fully differentiable operations. show outperforms strong baseline three characterlevel translation tasks wmt’. analysis demonstrates model computes qualitatively intuitive alignments achieves superior performance fewer parameters. character-level neural machine translation attractive research problem addresses important issues encountered word-level nmt. word-level systems suffer problems rare words data sparsity existence compound words without explicit segmentation certain language pairs make learning alignments translations difficult. character-level neural machine translation mitigates issues. work propose augment encoderdecoder model character-level integrating planning mechanism. specifically develop model uses planning improve alignment input output sequences. model’s encoder recurrent neural network reads source encodes sequence vector representations; decoder second generates target translation characterby-character target language. decoder uses attention mechanism align internal state vectors source encoding. creates explicit plan source-target alignments future time-steps based current observation summary past actions. time-step follow modify plan. enables model plan ahead rather attending relevant primarily current generation step. concretely augment decoder’s internal state alignment plan matrix commitment plan vector. alignment plan matrix template alignments model intends follow future time-steps i.e. sequence probability distributions input tokens. commitment plan vector governs whether follow alignment plan current step recompute thus models discrete decisions. planning mechanism inspired strategic attentive reader writer vezhnevets work motivated intuition that although natural language output step-by-step constraints output process necessarily conceived ordered according local step-by-step interactions. sentences conceived word time. planning choosing goal along candidate macro-actions arrive induce coherence sequential outputs like language. learning generate long coherent sequences form alignments long input contexts difficult existing models. performance encoder-decoder models attention deteriorates sequence length increases effect pronounced character-level nmt. character sequences longer word sequences. evaluate proposed model report results character-level translation tasks wmt’ english german english finnish english czech language pairs. almost pairs observe improvements baseline represents state neural character-level translation. experiments model outperforms baseline despite using significantly fewer parameters converges faster training. describe integrate planning mechanism sequence-to-sequence architecture attention model first creates plan computes soft alignment based plan generates time-step decoder. refer model notation encoder input model receives sequence tokens denotes length processes encoder bidirectional rnn. input position obtain annotation vector concatenating forward backward encoder states denote hidden state decoder generating target output token time-step alignment decoder goal mechanism plans parts input sequence focus next time-steps decoding. purpose model computes alignment plan matrix at∈rk×|x| commitment plan vector time-step. matrix stores alignments current next timesteps; conditioned current input i.e. token predicted previous time-step current context computed input annotations recurrent decoder function fdec-rnn receives inputs computes hidden state vector commitment plan vector governs whether follow existing alignment plan shifting forward recompute thus represents discrete decision. model operate discretely recently proposed gumbel-softmax trick conjunction straight-through estimator backpropagate model learns temperature gumbel-softmax proposed gulcehre commitment vector action plan matrix initialized ones; initialization modified training. alignment-plan update decoder updates alignment plan governed commitment plan. denoted first element discretized commitment plan ¯ct. detail discretized commitment plan obtained setting ct’s largest element elements thus binary indicator variable; refer commitment switch. decoder simply advances time index shifting action plan matrix forward shift function controller reads action-plan matrix produce summary plan compute updated alignment plan interpolating previous alignment plan matrix candidate alignment plan matrix ¯at. mixing ratio determined learned update gate ut∈rk×|x| whose elements correspond tokens input sequence shift function shifts commitment vector forward appends -element. model recomputes using single layer followed gumbel-softmax recomputed discretizing one-hot vector alignment repeat order reduce model’s computational cost also propose alternative approach computing candidate alignment-plan matrix every step. specifically propose model variant reuses alignment previous time-step commitment switch activates time model computes alignment. call variant repeat plan attend generate rpag viewed learning explicit segmentation implicit planning mechanism unsupervised fashion. repetition reduce computational complexity alignment mechanism drastically; also eliminates need explicit alignment-plan matrix reduces model’s memory consumption well. provide pseudocode rpag algorithm figure planning mechanism sequenceto-sequence model learns plan execute alignments. distinct standard sequence-tosequence model attention rather using simple predict alignments model makes plan future alignments using alignment-plan matrix decides follow plan learning separate commitment vector. illustrate model decoder layers first layer second layer decoder. planning mechanism conditioned first layer decoder baseline biscale model chung attention mechanisms baseline conditioned layers encoder’s biscale detail). implementation reproduces results original paper within small margin. table shows planning mechanism generally improves translation performance baseline. fewer updates fewer parameters. trained updates training baseline trained updates. used units pag’s encoder decoder baseline used encoder units decoder. total model fewer parameters baseline. tested models beam size seen table layer normalization improves performance model significantly. however according results en→de layer norm affects performance rpag marginally. thus decided train rpag layer norm language pairs. figure show qualitatively model constructs smoother alignments. contrast baseline decoder aligns first characters word generates byte source sequence; remaining characters places largest alignment weight final empty token source sequence. baseline becomes confident word generate first characters generates remainder word mainly relying language-model predictions. illustrated learning curves figure observe converges faster help improved alignments. work addressed fundamental issue neural generation long sequences integrating planning alignment mechanism sequenceto-sequence architectures machine translation problem. proposed different planning mechanisms constructs explicit plans form stored matrices rpag plans implicitly computationally cheaper. approach empirically improves alignments long input sequences. machine translation experiments models planning mechanism outperforms state-of-the-art baseline almost language pairs using fewer parameters. future work plan training corpus pairs denotes tunable parameters. noted proposed model learn recompute often decreases utility planning. order avoid behavior introduce loss penalizes model committing often figure visualize alignments learned rpag baseline model -layer decoder using attention depicted alignments learned rpag smoother baseline. baseline tends much attention last token sequence defaulting empty location alternation relevant locations. model however places higher weight last token usually good alignments exist. observe rpag tends generate less monotonic alignments general. table results different models wmt’ task english german english czech english finnish language pairs. report bleu scores model computed multi-blue.perl script. best-score model language pair appears bold-face. newstest development alexander vezhnevets volodymyr mnih john agapiou simon osindero alex graves oriol vinyals koray kavukcuoglu. strategic attentive writer advances neural learning macro-actions. information processing systems. pages dzmitry bahdanau kyunghyun yoshua bengio. neural machine translation jointly learning international conference align translate. learning representations yoshua bengio nicholas léonard aaron courville. estimating propagating gradients stochastic neurons conditional computation. arxiv preprint arxiv. kyunghyun bart merriënboer dzmitry bahdanau yoshua bengio. properties neural machine translation encoder-decoder approaches. arxiv preprint arxiv. junyoung chung kyunghyun yoshua bengio. character-level decoder without explicit segmentation neural machine translation. arxiv preprint arxiv. minh-thang luong christopher manning. achieving open vocabulary neural machine translation hybrid word-character models. arxiv preprint arxiv. eine republikanische strategie gegen wiederwahl obama republikanische führungspersönlichkeiten haben ihre politik durch notwendigkeit gerechtfertigt wahlbetrug bekämpfen eine republikanische strategie bekämpfung wahlen obama politischen führer republikaner haben ihre politik durch notwendigkeit bekämpfung wahlbetrugs gerechtfertigt generalstaatsanwalt vereinigten staaten dazu gebracht umstrittensten gesetze auszusetzen konnten schaden teilweise begrenzen darüber hinaus unterstreicht herr beaulieu bedeutung diskussion ihrer bedenken ihrer familiengeschichte ihrem arzt", "year": 2017}