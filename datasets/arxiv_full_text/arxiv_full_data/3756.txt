{"title": "MINOS: Multimodal Indoor Simulator for Navigation in Complex  Environments", "tag": ["cs.LG", "cs.AI", "cs.CV", "cs.GR", "cs.RO"], "abstract": "We present MINOS, a simulator designed to support the development of multisensory models for goal-directed navigation in complex indoor environments. The simulator leverages large datasets of complex 3D environments and supports flexible configuration of multimodal sensor suites. We use MINOS to benchmark deep-learning-based navigation methods, to analyze the influence of environmental complexity on navigation performance, and to carry out a controlled study of multimodality in sensorimotor learning. The experiments show that current deep reinforcement learning approaches fail in large realistic environments. The experiments also indicate that multimodality is beneficial in learning to navigate cluttered scenes. MINOS is released open-source to the research community at http://minosworld.org . A video that shows MINOS can be found at https://youtu.be/c0mL9K64q84", "text": "manolis savva princeton university angel chang princeton university alexey dosovitskiy intel labs thomas funkhouser princeton university vladlen koltun intel labs present minos simulator designed support development multisensory models goal-directed navigation complex indoor environments. simulator leverages large datasets complex environments supports ﬂexible conﬁguration multimodal sensor suites. minos benchmark deep-learning-based navigation methods analyze inﬂuence environmental complexity navigation performance carry controlled study multimodality sensorimotor learning. experiments show current deep reinforcement learning approaches fail large realistic environments. experiments also indicate multimodality beneﬁcial learning navigate cluttered scenes. minos released open-source research community http//minosworld.org. skillful mobile operation three-dimensional environments long posited essential milestone road general intelligence despite extensive research navigation remains challenging problem. classical approaches based simultaneous localization mapping sensitive noisy sensory input changes environment. recent deep-learning-based methods potentially robust require extensive training demonstrated perform well simple three-dimensional mazes bottleneck developing benchmarking approaches sensorimotor control logistical difﬁculty operating mobile agent physical world. physical world constrained operate real time; poor performance cause breakage requires repairing replacing physical system; system need supervised human learning process. moreover order ensure proper generalization control system must evaluated wide variety environments. limitations sensorimotor control models often developed benchmarked simulation promising model developed validated transferred physical world paper present minos simulation framework indoor environments designed support development validation multisensory models navigation. minos designed several desiderata mind. first simulator provides access large number realistic environments suncg dataset three-dimensional models furnished houses matterportd dataset reconstructed indoor scenes second simulator supports ﬂexible multimodal sensing including vision depth surface normals touch semantic segmentation. number sensors positions parameters easily speciﬁed client. third simulation framework allows procedural reconﬁguration environments programmatic modiﬁcation scene composition appearance. finally rendering framework speciﬁcally provide high frame-rates hundreds frames second typical workstation support approaches consume millions simulation steps training. minos benchmark indoor navigation algorithms. first establish ﬁxed train/validation/test splits varying complexity suncg matterportd. allows controlled investigation generalization learning-based methods. second three goal-directed navigation tasks pointgoal objectgoal roomgoal. ﬁrst involves purely spatial goal speciﬁcation latter specify object type room type goal. pointgoal task agent provided vector pointing towards goal; physical world signal provided indoor system. semantic goal tasks provide agent semantic information regarding goal room type object type type command provided human user interacting agent. using presented benchmark conduct controlled study approaches sensorimotor learning. evaluate several deep reinforcement learning algorithms navigate towards distal goals using different combinations sensory modalities. complex realistic environments present signiﬁcant challenge existing algorithms. example furnished mediumscale matterportd scenes successful methods complete pointgoal task trials. performance roomgoal task even worse even small matterportd scenes best methods complete task trials. experiments varying sensory modalities demonstrate depth touch particularly powerful individually effective vision learning navigate indoor scenes. combinations sensory modalities effective still especially cluttered environments. experiments illustrate utility presented simulation framework sensorimotor learning research. support research direction minos released open-source research community http//minosworld.org. simulation established approach developing training benchmarking sensorimotor control models. arcade learning environment simulates two-dimensional atari games instrumental recent surge interest deep reinforcement learning platform allows efﬁcient simulation real-time strategy games. project malmo enables simulated agents interface game minecraft torcs carla simulators used study autonomous driving policies. control studied using airsim uesim gazebo simulator used extensively robotics research. vizdoom deepmind simulate stylized immersive three-dimensional labyrinths. come close indoor navigation lack realism terms layout appearance well presence objects scene. work distinguished focus realistic indoor environments. allows development validation sensorimotor control models operate realistic cluttered indoor scenes. akin work ai-thor project focuses realistic indoor environments goals ai-thor work aligned minos distinguished number ways. first leverage large datasets including thousands furnished houses realistic interconnected layouts dozens rooms each opposed single-room environments provided thor. second focus ﬂexibility agent’s sensor suite terms available sensors number parameters. third mindful data-hungry nature many deep algorithms minos developed hundreds simulation steps second typical workstations. development minos initiated fall core functionality completed june time version paper submitted conference publication. since then number independent efforts investigated navigation indoor environments using suncg dataset matterportd dataset minos distinguished several ways. first simulation framework provides ﬂexible user allowing environment conﬁguration object addition/removal material variation fully parameterized placement speciﬁcation multimodal sensor suites arbitrary number sensors. second addition simulator itself provide speciﬁc benchmark tasks navigation algorithms. third figure overview minos framework apis. framework source environments datasets suncg matterportd accessible client api. environment conﬁguration. scripts shown select single-room scenes suncg database training enable semantically consistent retexturing remove chair candle objects. agent controls conﬁguration adjustable discrete continuous navigation parameters resulting demonstrated agent trajectories. agent sensor conﬁguration speciﬁes vision depth normal semantic contact force sensors. leverage simulator study performance learning-based navigation agents cluttered indoor environments. recent work visual navigation used actor-critic model discretizes agent state space explored explicit representations planning work uses auxiliary tasks secondary prediction targets assist learning direct prediction future measurements rewards also appears effective sensorimotor learning immersive environments methods developed different environments lack either realism scale. work provides fair comparison representative stateof-the-art deep navigation models large complex diverse indoor environments. minos ﬂexible efﬁcient customizable framework simulation large-scale indoor environments. figure provides overview framework. describe components system detail. minos simulator designed ﬂexible easy use. generic dataset layer allows framework source environments dataset pool. ﬂexible conﬁguration supports environment conﬁguration selecting subsets environments ﬁlters predicated properties house objects present programmatically creating variations original scenes re-texturing object surfaces semantically consistent fashion well removing replacing furniture; generic sensor speciﬁcation allowing arbitrary conﬁgurations sensors custom type position orientation resolution encoding. multiple concurrent sensor streams type supported. simulator implemented server-client paradigm. webgl-based server focused efﬁciency instances deployed parallel servers offer client apis python wrapper designed support efﬁcient client particularly useful interactive exploration crowdsourced data collection. python client apis communicate backend instances websocket layer allowing distributed training. minos supports navigation arbitrary environments. time writing simulator provides immediate support datasets suncg dataset synthetic furnished houses matterportd dataset reconstructed real buildings example scenes shown figure suncg dataset provides approximately houses rooms different types. models support long-range navigation across layouts complex inter-room intra-room scale matterportd dataset consists multi-ﬂoor residences approximately annotated room regions. residences realistic synthetic suncg houses matching appearance composition real environments closely. matterportd challenging testbed navigation methods. agent represented cylinder proxy geometry parameterized height radius offset ground. deﬁne control commands inject linear angular acceleration step forward step back turn left turn right look look down strafe left strafe right. client maps commands interactive keyboard control whereas receives string identiﬁers applied given time step. command parameterized allow scaling applied acceleration. dynamics agent parameterized mass maximum linear angular speeds coefﬁcient friction. parameters along simulation time-step duration implement continuous navigation agents effectively discretize motion. figure example houses indoor navigation datasets. four environments show overhead view view room coded different color ﬁrst-person views within environment multimodal perception crucial development sensorimotor skills animals artiﬁcial systems support research multimodal sensorimotor control provide ﬂexible generic sensory input speciﬁcation allowing number sensory inputs variety modalities measurements agent velocity acceleration distance direction speciﬁed navigation target normalized episode time measurements used debugging visualization modality-agnostic training inputs indicate progress towards goal. material variation textures colors sampled semantically consistent variation respect training/validation/test splits ensure material conﬁgurations particular objects shared splits. functionality allows signiﬁcant augmentation synthetic environments. randomized retexturing used work dosovitskiy koltun sadeghi levine shown signiﬁcantly generalization. navigation goal speciﬁcation goals speciﬁed arbitrary points space threshold distances success. instances object category room category also speciﬁed goals. speciﬁcally instance category randomly selected instance closest instance agent deﬁned goal. task speciﬁcation task performed agent speciﬁed arbitrary python function computes reward signals episode success failure given agent’s current past observations measurements state. experiments implement navigate task distance check current agent position closest point goal region minos benchmark recent navigation algorithms. assume agent interacts environment discrete time steps episodic setup. episode interaction environment ends maximum number time steps time step agent receives observation scalar reward environment. observation coming different modalities. based observation agent takes action discrete action study four end-to-end navigation algorithms. ﬁrst three based asynchronous advantage actor-critic fourth direct future prediction shown good performance maze navigation task. note since consider agents acting continuous state space include method gupta assumes discrete gridworld-like environment. describe methods detail. feedforward basic version asynchronous advantage actor-critic algorithm feedforward convolutional network used function approximator. agent trained estimate quantities. ﬁrst value function expected discounted rewards current moment episode. second policy distribution actions indicating degree beneﬁt expected action. value function trained multi-step bellman equation recurrent relation stating expected cumulative reward approximated several rewards plus agent’s estimate future time step. policy trained maximize probability actions leading larger-than-average rewards minimize probability actions leading smaller-than-average rewards. achieved policy gradient value function serving baseline. details provided mnih lstm agent feedforward network augmented long short-term memory units trained backpropagation time. vanilla agent behave reactively based current observation; agent unable build internal representation environment execute temporally extended action sequences. lstm provides agent simple memory potentially help alleviate shortcomings feedforward agent. unreal version lstm augmented auxiliary unsupervised tasks. extra tasks provide additional training signals network leading improved convergence stability. auxiliary tasks include value function replay reward prediction pixel control. details provided jaderberg direct future prediction algorithm differs aforementioned methods explicitly maximize future rewards. instead predicts future measurements low-dimensional sensory inputs. actions selected maximize objective function deﬁned terms measurements. method seen monte carlo reinforcement learning decomposed reward. details provided dosovitskiy koltun minos evaluate methods summarized section compare algorithms goal-directed navigation goals speciﬁed either location relative agent semantic meaning. evaluate effectiveness different combinations sensory modalities navigation measure effect environmental complexity methods’ performance. contrast many previous works evaluate agents environment trained rather study generalization previously unseen environments. finally perform experiments suncg environments matterportd environments investigate algorithm performance impacted domain difference synthetic reconstructed scenes. goal-directed navigation tasks sequence trials. trial agent initialized random location indoor environment reach goal location. experiment three ways specifying goals position relative agent semantic category target object target room region work specify spatial goal using euclidean distance normalized direction randomly chosen point. room goal speciﬁed distinct room classes object goal speciﬁed object class agent initialized random position orientation free space house provided target point room object must navigate speciﬁed distance direction towards goal semantic class room object represented one-hot vector. generated combination start goal positions checked navigability using tile-based shortest-path computation. distance direction measurements euclidean distance goal point closest point goal object room. trial ends agent reaches goal ﬁxed timeout steps training agent performs trials environment moving randomly sampled environment. establish speciﬁc subsets environments benchmarking indoor navigation. selected manually verifying realism traversability environment ﬂoorplan. suncg dataset select subset single-ﬂoor houses varying complexity rooms house. dataset split training validation test scenes. houses consist total rooms populated object instances total ﬂoor area approximately average rooms house mean ﬂoor area room. house populated objects average. houses represent variety environments including family homes ofﬁces public spaces restaurants. matterportd dataset adopt training/validation/test split speciﬁed original dataset environments comprise total room regions ﬂoors. average house rooms ﬂoor area providing signiﬁcantly larger interconnected environments navigation. suncg dataset create variants house different complexity empty variant scenes emptied furniture include architectural elements walls ceilings ﬂoors doors windows furnished variant scenes contain full content except people plants. agent represented cylinder proxy geometry height radius continuous state space experiments. motion agent governed simple rigid body physics. actions available agent include linear acceleration forward backward direction well angular acceleration towards left right. discretized action space turn left turn right move forward commands inject linear angular acceleration linear acceleration angular acceleration maximum speeds respectively. settings produce linear steps turns multimodal agent experiments agent provided combinations vision depth contact sensors addition goal signal. vision provided singe grayscale camera located height conﬁgured ﬁeld view images agents pixel resolution. depth sensor co-located vision sensor outputs groundtruth depth range quantized byte precision noise. four contact-force sensors placed height ground surface agent cylinder proxy geometry oriented four cardinal directions respect agent. contact sensor conﬁguration encodes collision impulse responses binary contact signal direction. agents trained tested episodes lasting time steps steps second simulated time. agent trained total time steps corresponding roughly days experience. average training speed four simulation threads steps second amounting approximately steps day. four training processes single nvidia titan pascal yielding total steps epsilon-greedy random exploration schedule starting fully random policy decaying approximately probability random actions training. navigation goal chosen random episode. agents trained future prediction loss measurements time euclidean distance goal normalized direction goal pointgoal task product one-hot representation room category roomgoal task goal room category. on-policy actions chosen selecting action minimizes objective linear combination predicted distance normalized time equal weight. temporal offsets steps. ac-lstm unreal agents trained reward function computing difference euclidean distance goal normalized time time step training hyperparameters reported jaderberg four asynchronous threads. roomgoal task provide one-hot goal room category vector additional input concatenated agent state. test time agents tested episodes scene ﬁxed permuted order scenes pre-sampled starting conﬁgurations selected span range distances goal. agent performance evaluated overall episode success rate reported percentage averaged testing episodes. table shows performance various navigation agents goal-directed navigation variable goal speciﬁcation environment complexity environment realism analyze results. pointgoal pointgoal pointgoal pointgoal pointgoal matterportd furnished pointgoal matterportd furnished medium roomgoal roomgoal roomgoal matterportd furnished table average episode success rate agents trained pointgoal roomgoal tasks tested novel environments varying complexity. suncg ‘small’ refers two-room houses suncg ‘medium’ contains three-to-ﬁve-room houses. matterportd ‘small’ contains environments rooms matterportd ‘medium’ refers environments rooms. note agents exhibit signiﬁcant performance degradation size complexity environment increases. relative performance agents. tasks unreal agent performs best followed ac-lstm. ac-ff failed learn meaningful policy performs worse random agent cases could hyperparameter selection. despite lack memory outperforms ac-lstm unreal smaller less cluttered suncg environments point navigation. challenging setups using larger matterportd environments semantic room navigation task unreal signiﬁcantly outperforms approaches. likely combination memory supervision auxiliary learning. environment complexity. performance methods declines signiﬁcantly large cluttered environments. best-performing agent pointgoal task successful trials simplest two-room empty suncg environments. however complex pointgoal setup matterport houses rooms agents success rate lower. results indicate even simplest scenario performance perfect existing methods fail large cluttered realistic environments. spatial semantic goals. roomgoal task difﬁcult algorithms pointgoal. likely sparsity roomgoal reward signal indicates whether agent room type matching goal room type. previous experiments agents navigating based solely visual input. compare agents equipped different sensor suites investigate impact multimodal sensory input navigation performance objectgoal task navigation target randomly chosen door. adapt visual agent providing alternative additional modalities input create several multimodal agents target distance direction measurements only; vision only; depth only; contact force only; vision contact force; vision depth contact force. table performance trained multimodal agents novel suncg environments. ‘none’ random policy ‘human’ reports human performance test episode average difﬁculty scene. rows report performance agents equipped different sets perceptual modalities. pair columns reports results different setting. left right empty single-room environments empty houses furnished single-room environments furnished houses note single-room environments less challenging small two-room environments table table reports performance agent training several sets novel environments different complexity empty single-room suncg environments empty suncg houses furnished single-room suncg environments furnished suncg houses. simplest setting empty single-room environments agents well. particular combination measurements contact force input performs best likely simplicity sufﬁciency goal direction contact signals navigating towards single target door empty multi-room houses depth modality performs particularly well whereas vision modality increase performance signiﬁcantly. likely fact absence clutter additional beneﬁt visual input limited. full multimodal agent outperforms ablated versions setting. full multimodal agent likewise performs best furnished settings. among individual modalities furnished settings depth confers strongest advantage. presented multimodal simulation platform designed support development multisensory models goal-directed navigation indoor environments. simulator provides suite sensory input modules ﬂexibly combined. leveraging large-scale datasets indoor environments augmenting data controlled variation appearance clutter provide orders magnitude indoor environments training testing previously available. experiments demonstrate current deep reinforcement learning", "year": 2017}