{"title": "Review-Level Sentiment Classification with Sentence-Level Polarity  Correction", "tag": ["cs.CL", "cs.AI", "cs.LG"], "abstract": "We propose an effective technique to solving review-level sentiment classification problem by using sentence-level polarity correction. Our polarity correction technique takes into account the consistency of the polarities (positive and negative) of sentences within each product review before performing the actual machine learning task. While sentences with inconsistent polarities are removed, sentences with consistent polarities are used to learn state-of-the-art classifiers. The technique achieved better results on different types of products reviews and outperforms baseline models without the correction technique. Experimental results show an average of 82% F-measure on four different product review domains.", "text": "abstract propose eﬀective technique solving review-level sentiment classiﬁcation problem using sentence-level polarity correction. polarity correction technique takes account consistency polarities sentences within product review performing actual machine learning task. sentences inconsistent polarities removed sentences consistent polarities used learn state-of-the-art classiﬁers. technique achieved better results diﬀerent types products reviews outperforms baseline models without correction technique. experimental results show average f-measure four diﬀerent product review domains. words sentiment analysis review-level classiﬁcation polarity correction data mining machine learning sentiment classiﬁcation attracted number research studies past decade. prominent literature pang employed supervised machine learning techniques classify positive negative sentiments movie reviews. signiﬁcance work inﬂuenced research community created diﬀerent research directions within ﬁeld sentiment analysis opinion mining. practical beneﬁts also emerged result automatic recommendation movies products using sentiments expressed related review. also applicable business intelligence applications rely customers’ reviews extract ‘satisfaction’ patterns improve proﬁtability. number reviews continued grow sentiments expressed subtle manner important develop eﬀective sentiment classiﬁcation techniques correctly classify sentiments despite natural language ambiguities include irony. work classify sentiments expressed individual product types learning language model classiﬁer. focus online product reviews contain individual product domains express explicit sentiment polarities. example quite common opinion expressed reviews targeted speciﬁc products reviews written. enables reviewer express substantial level sentiments particular product alone without necessarily splitting opinions diﬀerent products. also review sentiments likely expressed speciﬁc aspects particular product. example ipad user express positive sentiment ‘camera quality’ device expresses negative sentiment ‘audio quality’ device. provides useful collaborative information aspects product need improvements. application sentiment classiﬁcation important ordinary users opinion mining sentiment analysis systems. diﬀerent categories sentiments represent actual stances humans particular target product manufacturer example overview many people ‘like’ ‘dislike’ product using number positive negative reviews. similarly sentiment classiﬁcation quite useful ﬁnance industries especially stock market prediction. sentiment classiﬁcation product reviews challenging still active area research. importantly sentiments expressed product review sometimes include ambiguous unexpected sentences often alternated diﬀerent positive negative polarities. causes inconsistencies sentiments expressed consequentially leading mis-classiﬁcation review document. such bag-of-words approach suﬃcient alone. emphasize negative reviews contain positive sentences often express negative sentiments using negative sentences. show example follows problem often degrades accuracy sentiment classiﬁers many review documents mis-classiﬁed opposite category. regarded false positives false negatives case problem non-trivial propose polarity correction technique extracts sentences consistent polarities review. correction technique includes three separate steps. first perform training correction training ‘na¨ıve’ sentence-level polarity classiﬁer identify false negatives positive negative categories. combine true positives sentences false negative sentences opposite categories form training category. second propose sentence-level polarity correction algorithm identify consistent polarities review discarding sentences inconsistent polarities. finally learn diﬀerent machine learning algorithms perform sentiment classiﬁcation task. steps performed four diﬀerent amazon product review domains improved accuracy sentiment classiﬁcation reviews baseline technique give comparable performance standard biagram bag-of-words unigram techniques. terms f-measure technique achieve average product review domains. rest paper organized follows. discuss related research work section section propose training correction technique sentiment classiﬁcation task. section describes sentence-level polarity correction technique corresponding algorithm. machine learning experiments results presented section finally section presents conclusions future work. pang proposed subjectivity summarization technique based minimum cuts classify sentiment polarities imdb movie reviews. intuition identify extract subjective portions review document using minimum cuts graphs. minimum approach takes consideration pairwise proximity information graph cuts partitions sentences likely class. example strongly subjective sentence might lexical dependencies preceding next sentence. thus pang showed minimum cuts graph sentences class. identiﬁed subjective portions result minimum graph cuts classiﬁed either negative positive polarity. approach showed signiﬁcant improvement subjective portion documents. work introduce additional steps extracting subjective sentences. instead extract subjective sentences consistent sentiment polarities. discard subjective sentences inconsistent sentiment polarities contribute noise reduce performance sentiment classiﬁer. thus contrary pang work ability eﬀectively learn sentiments identifying likely subjective sentences consistent sentiments. again emphasize subjective sentences necessarily express sentiments towards subject matter. consider example following excerpt ‘positive-labelled’ movie review ‘real life however consists long stretches boredom dramatic moments characters stand around think thoughts nothing come events resolved. spielberg gives visually spicy historically accurate real life story. like it.’ excerpt sentence subjective sentence contribute sentiment movie. explicit sentiments expressed sentence propose discarding sentences sentence reviews likely improve accuracy sentiment classiﬁer. similarly wilson used instances polar words detect contextual polarity phrases mpqa corpus. phrase detected veriﬁed either polar non-polar phrase using presence opinionated words polarity lexicon. polar phrases processed detect respective contextual polarities used train machine learning techniques. identifying polarity phrase-level expression challenge sentiment analysis. earlier section illustrated example sentences eﬀect. clarity consider sentence saying picture quality camera good’. sentence presence negation word ‘not’ represent ‘negative’ polarity sentence context. fact emphasizes ‘desired state’ ‘picture quality’ camera entity ‘good’. however without eﬀective contextual polarity detection sentences could easily classiﬁed ‘negative’ ordinary machine learning techniques. extent wilson performed manual annotation contextual polarities mpqa corpus train classiﬁer combination features resulting accuracy giving room improvement. sions. compositional semantic approach breaks lexical constituents expression diﬀerent semantic components. thus work used content word negators identify sentiment polarities diﬀerent semantic components expression. content word negators negation words function words never identiﬁed sentiment polarities combined using heuristic rules form overall sentiment polarity feature used train machine learning techniques. interestingly multi-perspective question answering corpus created wiebe combination yielded performance performance ordinary classiﬁer performance achieved choi cardie understandable given mpqa corpus contains well ‘structured’ news articles mostly well written certain topics. moreover sentences expressions contained news articles likely express sequential sentiments reasonable classiﬁcation performance. example likely negative news ‘event’ ‘disaster unfolds tsunami rocks japan’ attract ‘persistent’ negative expressions sentiments news articles. contrast sentiment classiﬁcation product reviews challenging often inconsistent mixed sentiment polarities reviews. illustrated example eﬀect section would interesting know performance heuristics used choi cardie standard product review datasets amazon online product review datasets. detailed review sentiment classiﬁcation techniques review documents provided tang understand sentiment polarity varies sentence sentence hypothesize detecting consistent sentiment patterns reviews could improve sentiment classiﬁer without sophisticated natural language techniques importantly believe every sentence review necessarily contribute classiﬁcation review appropriate class. certain sequential sentences consistent sentiment polarities could suﬃcient represent distinguish sentiment classes review. representative features argued eﬀective classiﬁcation technique. emphasize approach promising easily integrated sentiment classiﬁcation system regardless sentiment detection technique employed. training polarity correction largely ignored sentiment classiﬁcation tasks. earlier emphasized review document could contain positive negative sentences. moreover since reviewers often express sentiments diﬀerent aspects products probable aspects products receive positive sentiments others negative sentiments. negative-labeled product review example likely negative sentiments expressed within ﬁrst portion review followed positive sentiments later portion review aspects product gave satisfactions. could reviewers tend emphasize negative aspects product positive aspects cases polarities expressed alternately discuss section thus using mixed sentiments category training machine learning algorithm result bias reduce accuracy classiﬁer. such propose promising approach reduce bias training ﬁrst learning ‘na¨ıve’ sentence-level classiﬁer sentences positive negative categories. ‘na¨ıve’ classiﬁer could classiﬁer trained surface-level features without necessarily performing sophisticated features engineering since ﬁnal sentiment classiﬁer constructed ﬁne-grained features. example could learn popular na¨ıve bayes classiﬁer unigram features. also possible complexly constructed classiﬁer expense eﬃciency. said that ‘na¨ıve’ classiﬁer used also test sentences positive negative categories. idea identify positive-labelled sentences classiﬁed negative negative-labelled sentences classiﬁed positive. identiﬁed this therefore imperative correct training combining wrongly classiﬁed sentences original respective categories. positive-labelled sentences classiﬁed negative combined original negative sentences negativelabelled sentences classiﬁed positive combined original positive sentences technique result meta classiﬁcation propose include technique part training process ﬁnal sentiment classiﬁer. addition order minimize wrongly classiﬁed sentences implement ‘na¨ıve’ classiﬁer maximize joint-log-probability score given sentence belonging either positive negative categories. ordinary classiﬁers maximize conditional probability categories expense better accuracy. compute joint-log-probability follows probability sentence given class probability sentence belonging either ‘positive’ category ‘negative’ category multivariate distribution positive negative categories. following training correction section propose sentence-level polarity correction reduce mis-classiﬁcation ‘training’ ‘testing’ sets. importantly bag-of-words approach seldom improve accuracy sentiment classiﬁer sentence-level approach could give better improvement since sentiments expressed sentencelevel anyway. however indicated section many review documents tendency contain positive negative sentences regardless individual categories consistent sentence polarities categories might helpful classiﬁcation task would better remove sentences outlier polarities cause inconsistencies using polarity correction approach. note motivated inconsistency problem example section idea sentence-level polarity correction remove inconsistent sentence polarities review. observed sentences inconsistent polarity deviate previous consistent polarity. often polarities sentences given review expressed consistently except outliers polarities. such given polarity expressed consistently number sentences certain point deviate polarity continues number sentences alternately. figure shows illustration depicting possible review consistent polarities inconsistent polarities given -sentence review reviewer expressed negative sentiments ﬁrst three sentences. followed single positive sentence line lines consist another three negative sentences. lines expressed positive sentences. finally line concluded negative sentence. thus regard line line outlier polarities subsequent exact polarity them. polarity correction algorithm removes outliers leaving consistent polarities. noted stage algorithm independent particular sentiment category consider exact subsequent polarities either positive negative since review likely contain polarities discussed earlier. intuition sentences consistent polarity could better represent overall sentiment expressed review document providing wider margin categories major consistent sentiment polarities. note technique diﬀerent intra-sentence polarity detection studied additional thing performed negation tagging tagging words negation word sentence. contrast baseline negation tagging showed improvements correction technique. thus given review document n-number sentences classify sentence ‘na¨ıve’ classiﬁer compare polarity ﬁrst sentence polarity φsn+ next sentence sn−. starting polarity polarity subsequent sentence φsn+ compared polarity prior sentence φλsn+. φλsn+ equals φsn+ sentence stored consistent category otherwise sentence considered outlier. note consistency threshold specifying parameter indicates minimum number subsequent sentence polarities must considered consistent. such consistent sentence polarities lower value ignored. experiment simulate default case. empirical observation shows suﬃciently captures consistent polarities sparse review document containing sentences. figure shows consistent polarities extracted diﬀerent threshold retrieves sentences retrieves sentences performed several experiments correction technique compare performance popular state-of-the-art classiﬁers withpolarity correction techniques. classiﬁers comprises sequential minimum optimization variant support vector machines na¨ıve bayes classiﬁer. used weka machine learning platform bag-of-wordsunigram word bigram features. include word trigram features word unigram word bigram features studied improved sentiment classiﬁcation tasks. conducted performance evaluation comparison baselines dataset domain. selecting best parameters baseline algorithms performed hyperparameters search using auto-weka cross-validation sequential model-based algorithm conﬁguration optimization algorithm bayesian optimization method proposed part auto-weka. performed search using unigram features training domain. unigram features shown robust performance sentiment analysis. product reviews four diﬀerent types product domains includes beauty productsbooks software kitchen. product domain positive reviews negatives reviews identiﬁed based customers’ star ratings according blitzer domain separated documents category training used remaining documents unseen testing set. extracted review text performed sentence boundary identiﬁcation optimizing output medlinesentencemodel available part lingpipe library. baseline implemented sentence-level sentiment classiﬁer using technique similar pang dataset without correction technique. baseline technique worked well sentiment classiﬁcation tasks. baseline work removes objective sentences training testing documents using automatic subjectivity detector component uses subjective sentences sentence-level classiﬁcation. svm−bigram−cor svm−bows−cor svm−unigram−cor svm−bigram svm−bows svm−unigram svm−baseline nb−bigram−cor nb−bows−cor nb−unigram−cor nb−bigram nb−bows nb−unigram nb−baseline svm−bigram−cor svm−bows−cor svm−unigram−cor svm−bigram svm−bows svm−unigram svm−baseline nb−bigram−cor nb−bows−cor nb−unigram−cor nb−bigram nb−bows nb−unigram nb−baseline svm−bigram−cor svm−bows−cor svm−unigram−cor svm−bigram svm−bows svm−unigram svm−baseline nb−bigram−cor nb−bows−cor nb−unigram−cor nb−bigram nb−bows nb−unigram nb−baseline svm−bigram−cor svm−bows−cor svm−unigram−cor svm−bigram svm−bows svm−unigram svm−baseline nb−bigram−cor nb−bows−cor nb−unigram−cor nb−bigram nb−bows nb−unigram nb−baseline example ‘svm-unigram-cor’ depicts model using unigram features correction techniques. standard models identiﬁed algorithm name feature used. baseline models identiﬁed ‘baseline’. model correction techniques outperformed baseline model without correction techniques domains. baseline model technique show comparable performance standard bigram bag-of-words unigram models. surprisingly performed better cases bag-of-words unigram features. hand performed better bigram features. improvement baseline technique comparable performance standard models show importance polarity correction techniques applicable sentiment classiﬁcation. also emphasizes fact using unseen test sets without sentence-level polarity corrections likely lead mis-classiﬁcation result inconsistent polarities within review. perhaps could beneﬁcial consider integration polarity correction techniques independent sentiment classiﬁer accurate sentiment classiﬁcation. limitation polarity correction techniques however could construction performance initial ‘na¨ıve’ classiﬁer performing training sentence-level polarity corrections. also classiﬁer needed trained review domain. time emphasize moderate classiﬁer taking classiﬁer example trained standard bag-of-word features gives average approximately f-measure across domains observed results. therefore believe process likely minimal negligible eﬀect resulting sentiment classiﬁer. such favor eﬃcient classiﬁcation task especially large datasets recommend sophisticated classiﬁers initial correction processes. also like emphasize reasonable sentence-level polarity identiﬁcation technique used place ‘na¨ıve’ classiﬁer correction processes likely work give improved results overall sentiment classiﬁcation task. work proposed training sentence-level polarity correction sentiment classiﬁcation task review documents. performed experiments diﬀerent amazon product review domains show sentiment classiﬁer training sentence-level polarity corrections showed improved performance outperformed state-of-the-art sentiment classiﬁcation baseline review domains. correction techniques ﬁrst remove polarity bias training inconsistent sentence-level polarities training testing sets. given diﬃculty sentiment classiﬁcation task believe improvement shown correction technique promising could lead building accurate sentiment classiﬁer. future integrate training sentence-level polarity correction techniques part independent sentiment detection algorithm perform larger scale experiment large datasets snap data amazon reviews dataset prepared mcauley leskovec.", "year": 2015}