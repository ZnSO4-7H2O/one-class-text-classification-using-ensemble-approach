{"title": "Multimodal Content Analysis for Effective Advertisements on YouTube", "tag": ["cs.AI", "cs.LG", "cs.MM", "cs.NE"], "abstract": "The rapid advances in e-commerce and Web 2.0 technologies have greatly increased the impact of commercial advertisements on the general public. As a key enabling technology, a multitude of recommender systems exists which analyzes user features and browsing patterns to recommend appealing advertisements to users. In this work, we seek to study the characteristics or attributes that characterize an effective advertisement and recommend a useful set of features to aid the designing and production processes of commercial advertisements. We analyze the temporal patterns from multimedia content of advertisement videos including auditory, visual and textual components, and study their individual roles and synergies in the success of an advertisement. The objective of this work is then to measure the effectiveness of an advertisement, and to recommend a useful set of features to advertisement designers to make it more successful and approachable to users. Our proposed framework employs the signal processing technique of cross modality feature learning where data streams from different components are employed to train separate neural network models and are then fused together to learn a shared representation. Subsequently, a neural network model trained on this joint feature embedding representation is utilized as a classifier to predict advertisement effectiveness. We validate our approach using subjective ratings from a dedicated user study, the sentiment strength of online viewer comments, and a viewer opinion metric of the ratio of the Likes and Views received by each advertisement from an online platform.", "text": "nikhita vedula∗ sun∗ hyunhwan lee† harsh gupta∗ mitsunori ogihara‡§ joseph johnson†§ gang ren§ ∗dept. computer science engineering ohio state university; †dept. marketing university miami; store concept reputed quipped half money spend advertising wasted; trouble don’t know half. hence making effective advertisement understands customers’ expectations important commercial company. video advertisements airing television social media crucial medium attracting customers towards product. landmark study lodish examined sales effects commercials found number cases advertising signiﬁcant impact sales. many reasons explain ﬁnding. first good advertising ideas rare. second people advertisements annoying avoid them. typically commercials occur within context program viewers watching. therefore advertisement unwelcome interruption. often advertisements watch replays skip interferes digital content enjoying. finally even advertisement manages hold viewers interest advertisement work viewers close enough attention message embedded advertisement. factors make designing advertisement content challenging critical advertising effectiveness. clear knowledge requirements interests speciﬁc target group customers advertisement meant long improving customer satisfaction loyalty feedback rate online sales company’s reputation. statistical knowledge discovery techniques often used help companies understand characteristics attributes advertisements contribute effectiveness. apart product-speciﬁc attributes crucial techniques involve combination customer-oriented strategies advertisementoriented strategies. many ideas create effective advertisements come psychology literature psychologists show positive negative framing advertisement reason emotion synergy music type message delivered frequency brand mentions popularity endorser seen advertisement making effective advertisement. another area advertisers draw drama. thus dramatic abstract—the rapid advances e-commerce technologies greatly increased impact commercial advertisements general public. enabling technology multitude recommender systems exists analyzes user features browsing patterns recommend appealing advertisements users. work seek study characteristics attributes characterize effective advertisement recommend useful features designing production processes commercial advertisements. analyze temporal patterns multimedia content advertisement videos including auditory visual textual components study individual roles synergies success advertisement. objective work measure effectiveness advertisement recommend useful features advertisement designers make successful approachable users. proposed framework employs signal processing technique cross modality feature learning data streams different components employed train separate neural network models fused together learn shared representation. subsequently neural network model trained joint feature embedding representation utilized classiﬁer predict advertisement effectiveness. validate approach using subjective ratings dedicated user study sentiment strength online viewer comments viewer opinion metric ratio likes views received advertisement online platform. widespread popularity internet growing trend commercial product publicity online advertisements. advertising along product development pricing distribution forms marketing actions managers take sell products services. enough merely design manufacture price distribute product. managers must communicate convince persuade consumers competitive superiority product successful sales. ﬁrms spend millions dollars advertising media radio print digital. ﬁrms spent approximately million advertising. however despite money effort spent marketers often advertising little impact product sales. effective advertising deﬁned advertisements generate enough sales cover costs advertising difﬁcult create. fact john wanamaker originator department elements narrative structure cultural advertisement content audience important creating effective advertisements. ingredients mixed develop effective advertisements still remains heuristic process different agencies developing tacit rules effective advertising. advertisement-speciﬁc user/viewer speciﬁc features play role advertisement’s success. advertisement-speciﬁc features include context topic advertisement based language style emotion expressed advertisement presence celebrities name few. user viewer speciﬁc features include user’s inherent bias towards particular product brand emotion aroused user result watching advertisement user demographics. many times users also provide explicit online relevance feedback form likes dislikes comments. features play important role determining success advertisement. another advertising agencies improve chances coming effective advertisements create multiple versions advertisement test experimentally using small group people represent target consumer. hope group participants pick version advertisement effective marketplace. problem approach production cost multiple advertisements reliance preferences small group participants. availability large repositories digital commercials advances made neural networks user generated feedback loop comments likes dislikes provide examine makes effective advertising. paper propose neuralnetwork based approach achieve goal digital commercial videos. advertisement clip divided sequence frames extract multimedia visual auditory features. apart these also create word-vector embeddings based text transcriptions online advertisements provide textual input model. independent modality features trained individually neural networks produce high level embeddings respective feature spaces. fuse trained models learn multimodal joint embedding advertisement. binary classiﬁer predicts whether advertisement effective/successful ineffective/unsuccessful according various metrics success. also analyze identiﬁed features combine play role making effective appealing commercials including effect emotion expressed advertisement viewer response garners. novel methodological contributions work feature engineering neural network structure design. primary applied contributions work shed light questions governing makes good previous work done targeted advertisement recommendation internet users exploiting content social relevance works authors used visual textual content advertisement along user proﬁle behavior click-through data recommend advertisements users. content-based multimedia feature analysis important aspect design production multimedia content multimedia features temporal patterns known show high-level patterns mimic human media cognition thus useful applications require indepth media understanding computer-aided content creation multimedia information retrieval temporal features prevalent media creation scholarly studies movies research music literature temporal patterns show human-level meanings plain descriptive statistics feature descriptors ﬁelds. simple temporal shapes easy recognize memorize composers music theorists musicologists digital humanists advertising agencies utilize extensively. studies manual inspection patterns human analysts inspect feature visualizations elicit recurring patterns present conceptually. manual approach inefﬁcient dealing large multimedia feature datasets and/or patterns across multiple feature dimensions e.g. correlation patterns audio video feature dimensions multiple time resolutions. rnns lstms work model varied input modalities increased success various machine learning tasks involving sequential data. cnnrnns used generate vector representation videos decode using lstm sequence model sutskever similar approach task machine translation venugopalan lstm model fuse video text data natural language corpus generate text descriptions videos. lstms also successfully used model acoustic phoneme sequences chung empirically evaluated lstms audio signal modelling tasks. further lstms proven effective language models previous work focused modeling multimodal input data deep boltzmann machines various ﬁelds speech language processing image processing medical research authors provide learning algorithm produce good generative model using even though distributions exponential family learning algorithm support real-valued tabular count data. ngiam dbms learn joint representations varied modalities. build classiﬁer trained input data modality test data different modality. authors build multimodal infer textual description image based image-speciﬁc input features vice versa. lexical resources wordnetaffect sentiwordnet sentiful database long used emotion opinion analysis. emotion detection done using affective lexicons distinctions based keywords linguistic rules handle affect expressed interrelated words ﬁrst work social emotion classiﬁcation swat algorithm semeval- task authors propose emotion detection model based latent dirichlet allocation. model leverage terms emotions topics text. authors propose kinds emotional dictionaries word-level topic level detect social emotions. recent years cnns rnns utilized effectively perform emotion detection section begin description multimedia temporal features extracted employed based video frames audio segments textual content commercial advertisements; followed creating joint embedding multimodal inputs. describe method detect emotion advertisements’ linguistic content. visual features video features content timelines extracted image features sampled video frames. speeding signal processing algorithms video frames sampled measured video feature extraction. pixel sampled video measure saturation brightness values dimension reﬂects dominant color distribution important postproduction rendering decisions saturation dimension measures extent color applied gray scale full color. brightness dimension measures intensity light emitted pixel. three feature dimensions closely related human perception color relationships measurement process serves crude model human visual perception feature descriptors video frame include mean value spatial distribution descriptors hue-saturation-brightness values constituent pixels. measuring deviations feature variables different segments screen mean values screen’s sub-segments differences adjacent screen segments calculated. video features mapped time locations form high-resolution timelines. also segment entire time duration video time segments hierarchical signal feature integration process calculate temporal statistics inside segment including temporal mean standard deviation well aggregated differences adjacent frames. auditory features audio signal features include auditory loudness onset density timbre centroid. loudness based computational auditory model applied frequency-domain energy distribution short audio segments ﬁrst segment audio signal short segments ensuring enough resolution time frequency domains calculate fast fourier transform each utilize spectral magnitude frequency-energy descriptor. human auditory system sensitivity varies frequency computational auditory model employed weight response level energy distribution audio segments. loudness thus calculated denote spectral magnitude frequency response strength respectively frequency index range frequency component. similar temporal resolution conversion algorithm section iii-a loudness feature sequence segmented temporal characteristics like mean standard deviation segment used feature variables. high resolution tracks audio onset density measures time density sonic events segment entire video duration onset detection algorithm records onsets time locations large spectral content changes amount change onset signiﬁcance. segment count onsets signiﬁcance value higher threshold normalize segment length onset density. longer segments increased robustness onset detection. reason onset density lower time resolutions measured longer segments total length temporal summarization corresponding high resolution track. timbre dimensions measured short segments similar loudness. timbre centroid measured textual features wordvec successful approach word vector embedding uses two-layer neural network text input generate vector embedding word corpus. preliminary experiments word embedding strategies decided wordvec since found embeddings suitable purpose. ﬁrst pre-processed extracted text transcription advertisement list word tokens. used -dimensional word vectors pre-trained google news dataset https//code.google.com/archive/ p/wordvec/ obtain word embedding token. lstms sequential feature description recurrent neural network generalizes feed forward neural networks sequences learn sequence inputs sequence outputs alignment inputs outputs known ahead time however challenging rnns learn long-range time dependencies handled quite well lstms core lstm unit memory cell controlled three sigmoidal gates values obtained either retained discarded gates make lstm unit input gate deciding whether lstm retains current input forget gate enables lstm forget previous memory context output gate controls amount memory context transferred hidden state memory cell thus encode knowledge inputs lstm model layers encode sequential multimedia features employing model similar architecture three input modalities. based features described section iii-a generate visual feature vector temporal video frames advertisement forms input ﬁrst lstm layer video model. stack another lstm hidden layer this shown figure takes input hidden state encoding output ﬁrst lstm layer. thus ﬁrst hidden layer would create aggregated encoding sequence frames video second hidden layer encodes frame information generate aggregated embedding entire video. next generate audio feature vector temporal audio segments described section iii-a encode hidden layer lstm model. finally textual features ﬁrst encode -dimensional word vector embedding word advertisement text transcription ﬁrst hidden layer lstm model. second lstm hidden layer applied encoding generate output summarized textual embedding advertisement. multimodal deep boltzmann machine classical restricted boltzmann machine undirected graphical model binary-valued visible layers hidden layers gaussian-bernoulli variant model real-valued input data figure mdbm models joint distribution visual features auditory features textual features. layers model binary layers except bottom real valued layer. order avoid learning algorithm getting stuck local optima normalized visual auditory textual input data uniform distribution. obtain high-level feature embeddings ﬁnal hidden layer three respective models audio video text concatenate three hidden layer embeddings layer called fusion layer enables explore correlation three kinds features order minimize impact overﬁtting perform dropout regularization fusion layer dropout probability combined latent vector passed multiple dense layers non-linear activation functions passed ﬁnal softmax layer predict output class advertisement. assume binary classiﬁer advertisements classes effective successful ineffective unsuccessful. thus probability predicting class label vertically stacking rbms form deep boltzmann machine three dbms individually model visual auditory textual features. visible layer number visible units hidden layers number hidden units ﬁrst pre-train modality-speciﬁc individually greedy layer-wise pretraining combine together regard multi layer perceptron tune parameters want learn. affective emotions present linguistic content style advertisement play crucial role invoking positive feelings towards viewers. therefore detected dominant emotion reﬂected advertisement’s textual content compared correlation actual feelings induced sample viewers used approaches detect dominant emotion prevalent linguistic content style advertisement surprise anticipation trust sadness anger fear disgust. ﬁrst approach modeled multi-class classiﬁcation problem using simple neural network consisting single lstm layer dropout regularization. trained text mixture isear dataset wordemotion association lexicon dropout input recurrent connections memory units lstm. output multi-class softmax classiﬁer detect distribution emotions text. tested model advertisement text transcriptions generate emotion distribution. also experimented dictionary-based approach manually constructed dictionary words associated emotion sources emotion lexicon isear wordnetaffect computed dominant emotion advertisement based text comparison dictionary construct additional features network model. though consideration semantic relations words here surprisingly manual validation found results slightly less effective lstm-based model. adding features lstm model appear yield additional beneﬁts evaluated proposed methodology dataset advertisements crawled online website youtube spanning different categories food beverages movie trailers health medicine clothing. ground truth whether advertisement successful/effective based three independent metrics detailed below. user study first user study conducted advertisement video clips using qualtrics survey platform. test environment included professional video playback workstation -inch color accurate production monitor rating laptop high quality loudspeaker system test room sound absorption material wall reverberation time rt). test subject test room rating session. subjects attitude toward brand need lots information brand know going brand know count brand future; attitude toward products product help satisfy desires product cutting edge technology product durable; persuasiveness purchase intensions this commercial changed attitude towards brand this commercial inﬂuence shopping habits would brand happened store; questions solicited ratings ranging ‘strongly disagree’ ‘strongly agree’ questions category used ratings ‘not lot’ three questions category solicited binary answers ‘yes’ ‘no’ averaged questions categories. considered advertisements mean rating ineffective rest effective advertisements. rating results anonymized experiment content procedures approved internal review board respective organizations involved meet standard nielson norman group guidelines. sentiment strength second scraped comments expressed users youtube advertisement calculated strength sentiment expressed using tool called sentistrength sentiment strength scores ranged advertisements mean score threshold considered effective rest ineffective advertisements. number ‘likes’ i.e. explicit positive feedback appreciation received advertisement video youtube clear indicator popularity among viewers. used measure likes advertisement receives total number times viewed visited measure effectiveness. youtube also provides number ‘dislikes’ model linear linear linear logistic regression comment sentiment logistic regression likes/visits logistic regression user study multimodal multimodal multimodal multimodal lstm comment sentiment multimodal lstm likes/visits multimodal lstm user study video-only lstm video-only lstm video-only lstm audio-only lstm comment sentiment audio-only lstm likes/visits audio-only lstm user study text-only lstm text-only lstm text-only lstm negative feedback received advertisement since number always lesser number likes advertisements received consider quantity assessment. advertisements likes views ratio mean ratio values received advertisements considered effective rest ineffective advertisements. classiﬁcation compare method baseline classiﬁers linear logistic regression take input concatenation visual auditory textual features. trained neural network models epochs minimizing binary cross entropy loss function using adam optimizer initial learning rate employed randomly selected advertisements training testing method averaged results runs. table displays f-score accuracy various classiﬁers. multimodal lstm model able achieve best accuracy f-score compared models difference accuracy signiﬁcant. last three rows table represent performance using individual lstm models single input modality. using multimodal joint feature representation gives huge advantage individual models. lstm model classiﬁes advertisements based textual wordvec features appears perform best compared models drilling quality lstm-based classiﬁer found false positive rate i.e. misclassify seemingly ineffective advertisements effective. misclassiﬁcations false negatives reporting effective advertisements ineffective. addition order study effect presence name brand advertisement success investigated performance model removing occurrences brand name advertisement text. found accuracy text-only model reduce nearly accuracy multimodal lstm dropped conﬁrms presence brand name play important role determining success advertisement. also inspected impact position brand name advertisement text i.e. occurrence beginning middle advertisement. signiﬁcant difference performance text-only lstm joint lstm model. comparing ground truth measures model selection displayed table evaluate performance four different algorithms using three ground truth measures described section iv-a. information views likes received advertisement online easiest obtain directly provides real-time opinion general public success. however measure often difﬁcult control adversarial effects noise lacks provenance. metric using comment sentiment strength also easy acquire compute however quality efﬁcacy might somewhat limited accuracy sentiment detection algorithm addition factors described likes-based measure. quality assessment advertisement’s success undoubtedly best judged detailed user study many confounding factors controlled for; however expensive often feasible perform time advertisement needs appraised. note following interesting trend relates selecting best model. regardless measure adopted performance trends near identical. multimodal lstm signiﬁcantly outperforms models followed multimodal logistic regression classiﬁers. rank order algorithmic performance terms accuracy f-score matter measure used ground truth. fact text features alone able achieve higher performance visual auditory features individually also corroborated measures. hence purpose evaluation model selection hypothesize employ metrics derived easily available online information likes views comments received advertisements rather opting often much video feature variation intensity span across temporal segments variation average saturation across spatial zones average saturation span ﬁfth spatial zone average chroma ﬁrst video segment average intensity span third spatial zone average intensity ﬁrst video segment variation intensity span across spatial zones variation chroma span across temporal segments average intensity second video segment average chroma span ﬁfth spatial zone onset spectrum strength second partition audio onset spectrum strength fourth partition audio onset spectrum variation fourth partition audio onset density fourth partition audio timbre width ﬁfth partition audio mean timbre width variation dynamic range second partition audio onset spectrum strength third partition audio said this note using expensive method user study ground truth gives statistically signiﬁcant improvement performance measures. instance difference accuracy lstm evaluated user study ratio likes visits p-value whereas difference f-score p-value using mcnemar’s paired test signiﬁcance. values considered signiﬁcant. multimedia feature analysis additionally seek study multimedia attributes seem contribute success commercial advertisements. purpose experimented three kinds classiﬁers random forests extra trees decision trees select important video audio features contribute high classiﬁcation accuracy responsible distinguishing classes advertisements. obtained classiﬁcation accuracy range classiﬁers. show essential video audio features obtained random forest classiﬁer table extra trees decision tree classiﬁer identiﬁed similar identical features important. case visual attributes average intensity average chroma ﬁrst second video segments found important. understandable beginning advertisements plays crucial role customers deciding whether want continue watching not. also features recognized essential average saturation span average chroma span ﬁfth spatial zone central zone screen. customers attention central area screen. case audio features obtain onset spectrum strength dynamic range second audio partition showcases importance attracting customers beginning advertisement. customers started watching characteristics products introduced advertisements reﬂected audio important effective advertisement. thus audio features onset spectrum strength onset spectrum variation onset density dynamic range considered important consequent ﬁnal audio partitions. order validate importance features respect model performed experiments using proposed model excluding particular audiovisual features input using user study ground truth metric. textual input remained earlier. found signiﬁcant reduction classiﬁcation accuracy lstm based model accuracy based model went used important audiovisual features entire textual feature part input data classify advertisements lstm based models. accuracy models found reduce respectively reduction also possibly loss information feature elimination. however using important features still able manage reasonable classiﬁcation accuracy. thus identiﬁed video audio features indeed essential distinguishing effective ineffective advertisements characterize advertisements well. analysis emotional content ﬁrst divided advertisements dataset categories based topic about identiﬁed dominant emotion present linguistic content. would expect language advertisements seems echo positive emotions surprise. also exhibited negative emotions sadness fear especially categories medicine news movie trailers. sought understand emotions invoked users viewing advertisements correlation dominant emotion identiﬁed advertisement language. table shows comparison dominant emotions detected advertisement text several categories invoked viewers advertisements using lstm-based approach emotion detection according emotion detection algorithm advertisements irrespective advertise reﬂect positive emotions anticipation trust surprise content. general inspire feelings attentiveness enthusiasm excitement among viewers. good fraction viewer responses also neutral towards product categories footwear clothing cars. part advertisement categories invoked negative feelings distress depression worry sadness contained emotions content news medical ailment related commercials exception movie trailers. little correlation emotions perceived movie trailer advertisements user emotions. primarily invoked positive affect enthusiasm anticipation viewers exception less popular movies. also obtained non-intuitive ﬁnds. instance contrary ones expectations found advertisement topic ‘funeral’ detected invoke dominant emotion viewers primarily language used advertisement quite positive several euphemisms. interestingly advertisements popular restaurants advertised discounts consisted terms representing good distribution happiness anticipation trust seemed invoke negative emotions anger irritability good fraction users though emotions dominate. general advertisements shorter length lesser content without brand name tended invoke weaker positive neutral feelings users despite heavy presence positive affect detected them. irrespective kind product advertised. interesting important outcome emotion ‘anger’ aroused towards different advertisements something unexpected. closely analyzing video advertisements question discovered anger primarily detected conjunction advertisements products different brands compared brand seemed belittled. also advertisements discrepancy video content text content primarily seen advertisements ‘fake’ lack authentic sources generated uploaded unregistered users youtube. seeing emotion play crucial role advertisement effectiveness sought include additional feature lstm/dbm model. however since obtain signiﬁcant performance gains report results. individual level shows viewers little attention details watching advertisements. leads type cognitive process called involvement information processing implication advertising advertisements must ﬁrst attract target viewers attention delivering main message. implication line ﬁnding video segments ﬁrst seconds advertisement signiﬁcantly marks table iii. comparison emotions detected advertisement text invoked viewers aggregated selected advertisement topic categories. neutral represents lack emotion. dominant emotions enthusiasm excitement neutral distress depression comfort excitement happiness inﬂuential attentiveness neutral attentiveness neutral excitement neutral inﬂuential enthusiasm entertainment inﬂuential fear worry sadness attentiveness inspirational discovery audio features second audio partition predicts advertisement effectiveness resonates results marketing literature reports message relevant music grab viewers’ attention however results order visual elements auditory elements occur advertisement attracts holds viewers’ attention. ﬁnding video features central part advertisement important effectiveness suggests core message advertisement embedded. also brand mentions advertisement makes effective. result ﬁnds support branding literature conﬁrms effective advertisements clearly communicate brand beneﬁts however ﬁnding temporal location brand-mention irrelevant supported marketing literature. scholars report better convey brand names logos introductory attention-grabbing phase. offer reasons results. first control product category effect. example temporal location brand mention vary whether advertisement conveying information drug disney vacation. second control brands stage product life cycle. example brand name logo appears matter differently dealing brand mature brand. small sample size permit analysis. transcription voice advertisement. means viewers prefer advertisements brand beneﬁts conveyed verbally connect emotionally know information processing literature brains process visual auditory verbal information different neural pathways though visual auditory information grab attention quickly verbal information cognitively demanding hear words extract meaning verbally presented brand information often forms strong associations neural networks taken together ﬁndings show effective advertisements social media websites like youtube involve blending visual auditory linguistic features. creating effective advertisements requires careful sequencing features advertisement ﬁrst draws viewer’s attention drives home brand message. advertisement begins critical effectiveness since beginning sets narrative story contained remainder advertisement. good story without interesting beginning reader rarely moves ﬁnish story work analyze various temporal features multimedia content online advertisement videos include auditory visual textual components study role advertisement success. trained three individual neural network models employing features modalities video audio text fused together resultant representations learn joint embedding. applied joint embedding binary softmax classiﬁer predict advertisement effectiveness success. performance approach validated subjective grounds based user study sentiment strength user comments ratio likes visits youtube respective advertisements. unusual effectiveness lift obtained novel lstm variants propose challenging problem seem line recent efforts image processing computer vision language modeling domains future would like automate feature engineering process utilizing cnns trained datasets imagenet also understand interpret decision process implicit models provide direct recommendations advertisers marketers. also interested developing models capable providing ﬁne-grained outcome advertisement rather binary value ‘effective’ ‘ineffective’ provide additional insights effectiveness. lodish abraham kalmenson livelsberger lubetkin richardson stevens advertising works meta-analysis real world split cable advertising experiments journal marketing research", "year": 2017}