{"title": "Fisher Motion Descriptor for Multiview Gait Recognition", "tag": ["cs.CV", "cs.AI"], "abstract": "The goal of this paper is to identify individuals by analyzing their gait. Instead of using binary silhouettes as input data (as done in many previous works) we propose and evaluate the use of motion descriptors based on densely sampled short-term trajectories. We take advantage of state-of-the-art people detectors to define custom spatial configurations of the descriptors around the target person, obtaining a rich representation of the gait motion. The local motion features (described by the Divergence-Curl-Shear descriptor) extracted on the different spatial areas of the person are combined into a single high-level gait descriptor by using the Fisher Vector encoding. The proposed approach, coined Pyramidal Fisher Motion, is experimentally validated on `CASIA' dataset (parts B and C), `TUM GAID' dataset, `CMU MoBo' dataset and the recent `AVA Multiview Gait' dataset. The results show that this new approach achieves state-of-the-art results in the problem of gait recognition, allowing to recognize walking people from diverse viewpoints on single and multiple camera setups, wearing different clothes, carrying bags, walking at diverse speeds and not limited to straight walking paths.", "text": "goal paper identify individuals analyzing gait. instead using binary silhouettes input data propose evaluate motion descriptors based densely sampled short-term trajectories. take advantage state-of-the-art people detectors deﬁne custom spatial conﬁgurations descriptors around target person obtaining rich representation gait motion. local motion features extracted diﬀerent spatial areas person combined single high-level gait descriptor using fisher vector encoding proposed approach coined pyramidal fisher motion experimentally validated ‘casia’ dataset ‘tum gaid’ dataset ‘cmu mobo’ dataset recent ‘ava multiview gait’ dataset results show approach achieves state-of-the-art results problem gait recognition allowing recognize walking people diverse viewpoints single multiple camera setups wearing diﬀerent clothes carrying bags walking diverse speeds limited straight walking paths. term gait refers person walks. actually humans good recognizing people distance thanks gait provides good identify people without requiring cooperation contrast biometric approaches iris ﬁngerprint analysis. potential applications access control special areas smart video surveillance crucial identify potentially dangerous people without cooperation. although great eﬀort problem recent years still solved. popular approaches gait recognition require computation binary silhouettes people usually applying background segmentation technique. however clear limitation presence dynamic backgrounds and/or static cameras noisy segmentations obtained. deal limitations propose descriptors based local motion points. kind descriptors become recently popular ﬁeld human action recognition main idea build local motion descriptors densely sampled points. then local descriptors aggregated higher level descriptors using histogram-based techniques therefore research question could identify people using local motion features represented fig. represent fig. local trajectories image points figure they? goal work identify people using gait. build pyramidal fisher motion descriptor trajectories points. represent gait motion four diﬀerent subjects. belonging four diﬀerent people. goal local trajectories build high-level descriptor allows identify individuals. paper introduce gait descriptor coined pyramidal fisher vector combines potential recent human action recognition descriptors rich representation provided fisher vectors encoding thorough experimental evaluation carried ‘casia gait’ dataset ‘cmu mobo’ dataset ‘tum gaid’ dataset recent ‘ava multiview gait’ dataset. variety employed datasets allow show robustness gait recognition method presence challenging situations poor silhouette segmentation occlusion body parts strong changes body scale complex subject trajectories changes clothing. important point show discriminative classiﬁer based features handle multiple viewpoints test time removing limitation using several camera viewpoints simultaneously even curved walking paths. comparison previous works also performed showing approach outperforms previous techniques scenarios demonstrating paradigm compete successfully current state-of-the-art gait recognition methods. paper organized follows. presenting related work describe proposed framework gait recognition sec. sections devoted experimental results. overall discussion results expounded sec. ﬁnally conclusions presented sec. many research papers published recent years tackling problem human gait recognition using diﬀerent sources data like inertial sensors foot pressure infrared images traditional images. example survey problem summarizing popular approaches. explicit geometrical models human bodies whereas others image features. sequence binary silhouettes body adopted many works input data. sense popular silhouette-based gait descriptor called gait enery image idea compute temporal averaging binary silhouette target subject. improve gait recognition performance propose computation descriptors popular gait descriptors chrono-gait image authors minimum number gait cycles needed carry successful recognition using descriptor. martin-felez xiang using basic gait descriptor propose ranking model gait recognition. formulation problem allows leverage training data diﬀerent datasets thus improving recognition performance. akae propose temporal super resolution approach deal frame-rate videos gait recognition. achieve impressive results using binary silhouettes people rate -fps. proposes regularized local tensor discriminant analysis method enhanced gabor representation gei. addition author deﬁnes method identify camera viewpoints test time patch distribution features. recently proposed novel discriminant subspace learning method extends methods based matrix-representation discriminant analysis sparse cases obtaining competitive results gait recognition. many works assumed target person follows straight path however iwashita explicitly focus curved trajectories. although curved trajectories speciﬁc goal paper show results proposed method unconstrained trajectory paths highlighting kind trajectory limitation proposal. hand human action recognition related gait recognition sense former also focuses human motion tries categorize motion categories actions walking jumping boxing etc. work wang reference. introduce short-term trajectories densely sampled points describing human actions obtaining state-of-theart results problem. dense trajectories described motion boundary histogram. then describe video sequence using words model finally non-linear χ-kernel classiﬁcation. parallel perronnin dance introduced histogram-based encoding sets local descriptors image categorization fisher vector encoding. instead counting number occurrences visual word concatenation gradient vectors gaussian mixture used. thus obtaining larger richer representation image. borrowing ideas image categorization communities propose paper approach gait recognition combines low-level motion descriptors extracted short-term point trajectories multi-level gait encoding based fisher vectors pyramidal fisher motion gait descriptor. context work gong similar sense propose method uses dense local spatio-temporal features fisher-based representation rearranged tensors. however signiﬁcant diﬀerences instead dealing single camera viewpoint integrate system several camera viewpoints; instead using local features available sequence person detector focus ones related target subject; information provided person detector enables richer representation including coarse geometrical information spatial grid deﬁned person bounding-box. conference version paper presented current version three important improvements introduced person detector employs combination full-body upper-body detectors resulting robust tool occlusions happen body parts; recover broken tracks detections histogram-based linking process obtaining longer tracks allow better representation gait; three databases included experimental results section ‘cmu motion body’ dataset ‘casia gait’ dataset ‘tum gaid’ dataset. databases conducted variety signiﬁcant experiments evaluate robustness method evaluate minimum number frames necessary identify subject test time take advantage information multiple cameras build classiﬁer able identify subjects multiple views; identify subjects employing upper lower body. moreover designed speciﬁc experiments carry thorough comparison previous methods conclude method outperforms state-of-the-art gait recognition approaches scenarios. section present proposed framework address problem gait recognition. fig. summarizes pipeline approach. start computing local motion descriptors tracklets densely sampled points whole scene since assume static background person detector remove point trajectories related people addition spatially divide person regions aggregate local motion descriptors mid-level descriptors finally discriminative classiﬁer used identify subjects figure pipeline gait recognition. steps input sequence video frames. densely sampled points tracked. people detection helps remove trajectories related gait. descriptor computed ﬁltered tracklets. descriptor input discriminative classiﬁer output subject identity. kernel median ﬁltering rounded position minimize drifting eﬀect tracking limited frames. postprocessing step noisy uninformative trajectories removed. short-term trajectories represented fig. green lines considered point described divergence related axial motion expansion scaling eﬀects whereas curl related rotation image plane. hyperbolic terms compute magnitude shear follow tracking-by-detection strategy detect people detection framework felzenszwalb then apply clique partitioning algorithm ferrari group detections tracks. short tracks low-scored detections considered false positives discarded processing. able recover broken tracks linking non-overlapping detections returned full-body detector. note none covers full height person. detections returned upper-body detector. highest scored lead expected full-body geometrical transformation full-body final obtained combination detections non-maxima suppression. note re-scored combination procedure. bounding-box compose track. finally compare similarity tracks distance. especially useful detector misses person period time. addition remove false positives generated static objects measure displacement detection along sequence. thus discarding tracks showing static behaviour. person tracks ﬁnally kept used ﬁlter trajectories related people keep tracklets pass through least bounding-box person track. focus trajectories contain information gait. people detection. video frame pedestrian detector upper-body detector since pedestrian detector favors detection people standing legs rest idea using upper-body detector able detect people holding poses covered pedestrian detector people legs partially occluded. since classes detections upper-bodies full-bodies likely found inside therefore deﬁne procedure similar kl¨aser’s combine detections. firstly detections geometrically transformed detection scores classes scaled range make comparable. then detection select unused overlaps current detection greater combining threshold then selected marked ‘used’ added detection deﬁned score resulting original detection scores non-maxima-suppression procedure applied obtain subset used processing. example resulting shown fig. four window detections ﬁnal fb-like aspect-ratio scores. fisher motion. described above low-level features based motion properties extracted person-related local trajectories. order build person-level gait descriptor need summarize local features. propose fisher vectors encoding seen extension words representation builds gaussian mixture model gaussian corresponds visual word. whereas image represented number occurrences visual word image described gradient vector computed generative probabilistic model. dimensionality number gaussians dimensionality local motion descriptors example case dimensionality local motion descriptors gaussians then would dimensions. paper term fisher motion refer computed video low-level motion features. total number local descriptors denotes gradient operator respect following proposal compare videos natural kernel gradients fisher kernel fisher information matrix. symmetric positive deﬁnite cholesky decomposition rewritten dot-product normalized vectors with lλgλ. then known fisher vector video stated capability description improved applying signed square-root followed normalization. adopt ﬁnding descriptor. pyramidal representation. borrow idea building pyramidal representation gait motion. since bounding-box covers whole body single person propose spatially divide cells. then fisher vector computed inside cell spatio-temporal grid. build pyramidal representation combining diﬀerent grid conﬁgurations. then ﬁnal feature vector used represent time interval computed concatenation cell-level fisher vectors levels pyramid. figure avamvg dataset. diﬀerent people recorded camera viewpoints. dataset contains female male subjects performing diﬀerent trajectories indoor scenario. note cameras prone show people partially occluded. last stage pipeline train discriminative classiﬁer distinguish diﬀerent human gaits. since multiclass problem train binary support vector machines one-vs-all strategy. although kernel popular choice bow-based descriptors linear kernel typically enough rich feature representation provides. people detection code published authors computing local motion features code published authors fisher vector encoding classiﬁcation carried using code included library vlfeat. order validate approach carry diverse experiments four datasets multi-view dataset mobo dataset casia datasets gaid dataset. experiments answer among others following questions combination trajectorybased features valid approach gait recognition? learn diﬀerent camera viewpoints single classiﬁer? improve recognition rate spatially dividing human body region? eﬀect using pca-based dimensionality reduction recognition performance? inﬂuence sequence length recognition performance? necessary descriptor whole components? proposed model generalize well unrestricted walk trajectories? ﬁrst dataset perform experiments multi-view dataset gait recognition avamvg subjects perform walking trajectories indoor environment. trajectory recorded color cameras placed around room crossed subjects performance. fig. shows scenario available camera viewpoints. note depending viewpoint performed trajectory people appear diverse scales even showing partially occluded body parts. particular camera viewpoints represented fig. likely show partially visible bodies time four cameras. therefore experiments without loss generality four cameras trajectories follow linear path whereas remaining seven trajectories curved. released videos since multiple viewpoints instance assign single label majority voting viewpoints. approach helps deal labels wrongly assigned individual viewpoints. note instead training independent classiﬁer camera viewpoint train single classiﬁer samples obtained diﬀerent camera viewpoints allowing classiﬁer learn relevant gait features subject multiple viewpoints. order increase amount training samples generate mirror sequences thus doubling amount samples available learning. table recognition results avamvg experiments entry contains percentage correct recognition multiview setup parenthesis recognition single view. corresponds diﬀerent conﬁguration gait descriptor. dictionary size. best results marked bold. table recognition results avamvg experiment entry contains percentage correct recognition multiview setup parenthesis recognition single view. corresponds diﬀerent length test sequence. size used best results marked bold. experiment baseline. popular words approach baseline compared approach. experiment trajectories leave-one-out strategy trajectories sample dictionary sizes interval interval pfm. pfms single level rows column results experiment included tab. rows ‘bow’ ‘pfm’. experiment half body features. focusing compare tab. four conﬁgurations trajectories spatial partition body using half body using bottom half body using concatenation bottom half body experiment dimensionality reduction. since dimensionality typically large evaluate experiment impact dimensionality reduction ﬁnal recognition performance. principal component analysis original low-level features vectors. descriptor experiment trajectories results experiment included tab. ‘pfm+pcal’ indicates low-level feature vectors compressed dimensions; ‘pfm+pcah’ indicates ﬁnal feature vectors compressed dimensions; ‘pfm+pcal+pcah’ means lowlevel features intially compressed dimensions ﬁnal vectors dimensions; ﬁnally ‘pfm+pcal+pcah+pyr’ corresponds level pyramid compression indicated name. experiment inﬂuence sequence length. goal experiment evaluate inﬂuence sequence length recognition process. purpose test time single subsequence framesextracted around middle sequence. tab. corresponds diﬀerent number frames range dictionary size ﬁxed components. table recognition results avamvg experiment entry contains percentage correct recognition given camera training–test split. corresponds diﬀerent camera viewpoint. size used best results marked bold. trj=+ experiment testing single camera. previous results assume multicamera enviroment test time combine information diverse viewpoints. however many real situations viewpoint available test time. experiment present breakdown recognition rates camera. results experiment summarized tab.. conﬁguration ‘pfm-len’ learnt previous experiment corresponds diﬀerent camera viewpoint experiment feature selection. previous experiments local motion vectors dimensions obtained concatenation four kind features normalized coordinates div+curl curl+shear div+shear goal experiment evaluate contribution type local feature gait recognition process. case learn independent dictionaries feature type instead single dictionary concatenated local features done before. then concatenate resulting feature-speciﬁc fvs. tab. summarizes results experiment. corresponds diﬀerent conﬁguration descriptor ‘ftxxxx indicates features used encoded xxxx string follows normalized coordinates value means used whereas value means used. example string ‘ft’ means descriptors used. experiment training straight paths testing curved paths. experiment descriptor experiment trajectories training trajectories testing. note latter sequences subjects perform curved trajectories thus changing viewpoint results experiment summarized tab. column correspond diﬀerent test trajectory. trajectory multiview sequences evaluated corresponding individual camera viewpoints. table recognition results avamvg experiment entry contains percentage correct recognition multiview setup parenthesis recognition single view. corresponds diﬀerent conﬁguration gait descriptor. ‘ftxxxx indicates selected subfeatures used describe dense trajectories. size used best results marked bold. experiment pfm-ft pfm-ft pfm-ft pfm-ft pfm-ft pfm-ft pfm-ft pfm-ft pfm-ft pfm+pcalx+pcah-ft pfm+pcalx+pcah-ft pfm+pcalx+pcah-ft pfm+pcalx+pcah-ft pfm+pcalx+pcah-ft table recognition results curved trajectories avamvg. training trajectories column indicates tested trajectory corresponds diﬀerent conﬁguration gait descriptor. size used best results marked bold. test= test= test= test= experiment pfm-ft pfm+pcalx+pcah-ft pfm+pcalx+pcah-ft pfm+pcalx+pcah-ft pfm+pcalx+pcah-ft pfm+pcalx+pcah-ft pfm+pcalx+pcah+pyr-ft pfm+pcalx+pcah+pyr-ft pfm+pcalx+pcah+pyr-ft column ‘trj=x+y contains percentage correct recognition partition instance level parenthesis video level column ‘avg’ contains average three partitions. column refers number centroids used quantizing low-level features descriptor. ‘bow’ corresponds baseline approach ‘pfm-fb’ corresponds full body rows ‘pfm-h’and ‘pfm-h’ correspond half bottom half body respectively. ‘pfm’ corresponds single-level obtained concatenation descriptors extracted bottom half body. ‘pfm+pcal’ corresponds proposal reducing dimensionality low-level motion descriptors building ‘pfm+pcah’ corresponds proposal reducing dimensionality ﬁnal descriptor dimensions learning classiﬁers ‘pfm+pcal+pcah’ corresponds proposal reducing dimensionality low-level descriptors ﬁnal descriptor ‘pfm+pcal+pcah+pyr’ corresponds two-level pyramidal conﬁguration ﬁrst level spatial partitions second level obtained dividing bounding parts along vertical axis done previously. addition applied low-level descriptors ﬁnal vector. columns). done previous experiments diﬀerent conﬁgurations evaluated. entry table contains percentage correct recognition multiview setup parenthesis recognition video. seven tested trajectories trajectory number perfect recognition rate achieved multiview setup. contrast trajectory number resulted hardest trying classify individual cameras although majority voting strategy multiview setup clearly contributed boost recognition rate opinion main diﬃculty dealing kind curved trajectories fragmentation person tracks partial occlusions turn implies loss dense tracks therefore less motion features available characterizing gait subject. regard number frames needed recognize person proposed framework tab. local motion features consecutive frames recognition rate multiview setup nearly perfect although monocular setup conﬁguration reaches modest increase number used frames obtain average multiview camera. focus results obtained four used cameras tab. camera ‘cam’ yields perfect recognition rate average. note camera viewpoint person’s trajectory nearly proﬁle thus allowing suitable computation point tracks long time figure mobo dataset. diﬀerent people recorded camera viewpoints walking treadmill. four walking patterns included dataset ball incline slow fast. recall trajectories densely sampled points used level features described using descriptor compound four subtypes features. tab. eﬀect removing time subtypes. results show weakest subtype feature normalized coordinates shown ‘pfm-ft’. addition selecting part descriptor results bottom rows table show eﬀect dimensionality reduction pca. contrast results previously reported tab. whole vector level features reduced ﬁxed size case subtypes indepedently reduced fraction original size. example ‘pcalx’ indicates dimensions kept. mobo contains video sequences subjects performing four diﬀerent walking patterns treadmill slow walk fast walk incline walk walking ball. recorded camera viewpoints. experiments similar ones presented evaluate proposed framework gait recognition. note that contrast avamvg dataset people actually displace along room mobo dataset actual displacement person body people walking treadmill. therefore available motion trajectories associated body whole. addition videos people move arms freely holding ball thus removing motion pattern associated arms swing. experiments four cameras done previous section multiple cameras available testing majority voting strategy followed deliver single label subject. experiment training multiple walking patterns. experiment time three walking patterns training remaining testing therefore report average four recognition rates. results experiment summarized tab. correspond diﬀerent conﬁguration. combine diﬀerent subtypes features diverse pca-based dimensionality reductions dictionary sizes. experiment inﬂuence sequence length. goal experiment evaluate inﬂuence sequence length recognition process. purpose test time subsequence frames extracted around middle sequence. tab. corresponds diﬀerent table recognition results mobo experiment entry contains percentage correct recognition multiview setup parenthesis recognition single view. corresponds diﬀerent conﬁguration gait descriptor. size used four camera viewpoints used training. best results marked bold. trj=f+i+b trj=s+f+i trj=s+f+b trj=s+i+b experiment pfm-ft pfm+pcalx+pcah-ft pfm+pcalx+pcah-ft pfm+pcalx+pcah-ft pfm+pcalx+pcah-ft pfm+pcalx+pcah-ft pfm+pcalx+pcah-ft pfm+pcalx+pcah-ft pfm+pcalx+pcah-ft pfm+pcalx+pcah-ft pfm+pcalx+pcah-ft pfm+pcalx+pcah-ft pfm+pcalx+pcah+pyr-ft pfm+pcalx+pcah+pyr-ft number frames range dictionary size ﬁxed either conﬁguration ‘pfm+pcalx+pcah-ft’. experiment testing single camera. previous results assume multicamera enviroment test time combine information diverse viewpoints. however many real situations viewpoint available test time. experiment present breakdown recognition rates camera. results experiment summarized tab.. conﬁguration ‘pfm+pcalx+pcah-ft’ learnt previous experiment corresponds diﬀerent camera viewpoint. experiment training single walking pattern. experiment train models single walking pattern time test patterns. tab. summarizes results experiment. rows correspond training walking patterns whereas columns correspond test patterns. table allows comparison previously published results dataset. results shown tab. correspond experiment since number possible combinations parameters show table subset representative ones. conﬁgurations containing suﬃx ‘pyr’ correspond single level vertical partitions note best conﬁgurations ‘pfm+pcalx+pcah-ft’ means selected level motion features initially reduced original dimensionality ﬁnal descriptor reduced dimensions classiﬁcation stage. case obtain perfect mean recognition rate multiview setup mean accuracy viewpoint. indicates clear success proposed descriptor dataset low-dimensional feature vectors. focusing dimensionality reduction ﬁnal vector reducing dimensions implies small decrease accuracy obtaining compact representation gait. extreme case compression evaluated experiment represented ‘pfm+pcalx+pcah-ft’ however accuracy worsens less worth mentioning perfect mean recognition accuracy achieved multiview setup using level descriptor since high accuracy obtained without using level results reported bottom rows tab. levels used included completeness evaluation. regard experiment inﬂuence sequence length performance evaluated results included tab. show perfect mean recognition rate achieved using features table recognition results mobo experiment entry contains percentage correct recognition multiview setup parenthesis recognition single view. corresponds particular length test sequences. size used best results marked bold. table recognition results mobo experiment entry contains percentage correct recognition single view setup. conﬁguration pfm+pcalx+pcah-ft-len. corresponds diﬀerent camera. size used results obtained camera case ‘pfm+pcalx+pcah-ft-len’ summarized tab. note cameras achieve mean perfect recognition rate means viewpoints needed accurate identiﬁcation individuals pfm. previously observed experiments ‘avamvg’ proﬁle viewpoints favor recognition process. table recognition results mobo experiment single type trajectory used training. conﬁguration ft=. acronyms trn=training pattern tst=test pattern s=slow f=fast i=incline b=ball results shown tab. correspond experiment particular used following conﬁguration features dictionaries; single level vertical partitions. compression performed experiment. increase number training samples video sequences split subsequences length frames overlap frames. case worst recognition results obtained training stage carried ball sequences. result reasonable since classiﬁers never seen motion arms present walking types results context authors report results training slow walk testing fast walk ball obtaining accuracy respectively. case obtain accuracy fast walk improve ball case also compare results published case train slow walk test ball obtaining second case train fast walk test slow walk obtaining accuracy. case obtain respectively. comparing results reported outperform cases training slow walk testing ball training fast walk testing slow walk obtaining accuracy respectively. rest cases obtain similar results. authors perform experiments cases training slow walk testing fast walk training fast walk testing slow walk obtaining respectively. case obtain cases. recent paper reported results dataset combination training fast walk testing slow walk achieving figure casia dataset. casia-b. people recorded diﬀerent camera viewpoints walking indoors. three situations included dataset normal walking walking coat walking bag. casia-c. diﬀerent people recorded outdoors night infrared camera. four situations included dataset normal walking slow walking fast walking walking bag. casia-b subjects perform walking trajectories indoor environment. action captured viewpoints. three situations considered normal walk wearing coat carrying ﬁrst camera viewpoint included dataset last intermediate ones separated examples seen fig. casia-c subjects perform walking trajectories outdoor environment night. action captured single viewpoint infrared camera. four situations considered normal walk fast walk slow walk carrying examples seen bottom fig. sets experiments similar ones presented evaluate performance proposed framework videos resolution comparison ones previously used experiments. addition challenging dataset larger amount people diﬀerent scenarios outdoor night conditions. experiment training single camera testing diﬀerent cameras. goal experiment evaluate capacity generalization proposed system changes camera viewpoint. experiment carried casia-b. model trained sequences ‘nm’ scenario classify sequences scenario. recognition percentages experiment summarized table tab. correspond training camera viewpoint whereas columns correspond test camera viewpoints. table state-of-the-art casia-b camera percentage correct recognition several methods camera acronyms ‘subjs’ number subjects used test; ‘train’ number sequences person used training; ‘test’ number sequences person used test. best results marked bold. experiment robustness clothing carrying objects. goal experiment evaluate robustness proposed system changes shape changing clothing carrying bags. experiment carried casia-b. model trained sequences ‘nm’ scenario classify sequences scenarios ‘cl’ ‘bg’ recognition percentages experiment summarized tables tab. tab. correspond training camera viewpoint whereas columns correspond test camera viewpoints. viewpoints whereas columns test cameras. suﬁx ‘sil’ indicates binary silhouettes used deﬁne people location instead person detector. values italics included reference used computation ‘avg’. test table recognition results casia-b experiment test time subject viewed several cameras thus opinion viewpoint combined decide identity target subject. column ‘acc’ contains percentage correct recognition multiview setup. parenthesis monocular accuracy. pcah= used cases ﬁnal descriptor. experiment ﬁrstly several camera viewpoints train single model test diﬀerent viewpoints independently. results experiment presented tab. show rows diﬀerent number cameras used training. case cameras training mean recognition accuracy test camera viewpoints ‘nm’ scenario. also evaluate experiment behaviour system multiple viewpoints available test time. thus combining opinion individual viewpoints. results summarized tab. corresponds diﬀerent test scenario column ‘acc’ shows percentage recognition achieved individual opinions test cameras combined majority voting. experiment gait recognition night. goal experiment evaluate performance proposed descriptor infrared images taken outdoors. purpose casia-c dataset. since previously used person detector showed poor performance infrared images casia-c carried background segmentation deﬁne bounding-box persons sequences. purpose learnt gaussian mixture model video frames. implementation included matlab. video frame bounding-box ﬁtted obtained foreground pixels ensuring ﬁxed aspect ratio remaining stages remain explained sec. bottom tab. shows recognition percentages achieved system. subject sequences subset ‘fn’ used training remaining sequences used testing. note that example used three sequences subject training instead use. case setup column ‘fn’ pcal+pcah+k; column ‘fs’ pcal+pcah+k; column ‘fq’ pcal+pcah+k; column ‘fb’ pcal+pcah+k. case ‘fs’ dictionary size reduced using layers pfm. experiment eﬀect person detection system performance. goal experiment evaluate impact person detection module ﬁnal performance system. particular instead using detection module binary silhouettes obtained gmmtable state-of-the-art casia-b multiview training. percentage correct recognition multiple viewpoints combined training. column corresponds test camera viewpoint scenario ‘nm’. best results marked bold. table state-of-the-art casia-c. percentage correct recognition casia-c diverse methods. column corresponds diﬀerent scenario. best results marked bold. based background segmentation ﬁlter initially estimated dense tracks. tried hardest scenario casia-b wearing coats results included tab. indicated keyword ‘sil’. although included table also tried experiment binary silhouettes provided authors dataset obtained lower results realised silhouettes missing. additionally tab. accuracy ‘cl’ increased using background segmentation. results shown table tab. correspond experiment cases training testing camera obtain almost perfect identiﬁcation subjects. value decreases testing diﬀerent cameras. although similar viewpoints cases drops accuracy lower previously trained system tested people wearing coats tab. testing camera trained achieves average accuracy fig. examples people wearing coat clearly show diﬃculty scenario legs people occluded ankle case people wearing bags average accuracy obtained diagonal tab. results context works tab. contains results training testing camera three scenarios. bottom shows best results scenario along average performance. note approach improves state-of-the-art average previous experiments independent classiﬁer trained viewpoint. contrast tab. shows single classiﬁer trained including several viewpoints column ‘training cams’ indicates cameras used training whereas subsequent columns indicate test cameras. note scenarios ‘nm’ ‘bg’ recognition rate nearly perfect test viewpoints. cases lowest scores located frontal back viewpoints dense tracklets present small displacements therefore less discriminative decreasing average performance case scenario ‘cl’ average accuracy increases using twolevels shown ‘k-pyr’. results comparable state-of-the-art ones shown tab. approach improves best known result knowledge using even less training sequences results second part figure gaid dataset. people recorded viewpoint walking indoors seasons. three situations included dataset normal walking walking walking coating shoes. first session second session experiment seen tab. majority voting strategy test cameras allows achieve higher recognition rates previously shown datasets. example case ‘cl’ consider viewpoint independent video sequence obtain accuracy value grows multiview setup. regard experiment case scenario ‘cl’ average recognition improves what opinion indicates person detector good behaviour general improved cases people wear clothing deforms expected shape person finally focus casia-c. results experiment summarized ‘pfm’ tab. indicate proposed descriptor suitable outdoors infrared images achieving perfect recognition results four situations despite diﬃculty kind images seen bottom fig. compare previous state-of-the-art approaches system establishes state-of-the-art scenarios dataset showing similar results two. gaid subjects perform walking trajectories indoor environment. ﬁrst trajectory performed left right second right left. therefore sides subjects recorded. recording sessions performed january subjects wear heavy jackets mostly winter boots second april subjects wear diﬀerent clothes. examples seen fig. shows three subjects recorded ﬁrst session. recorded diﬀerent walking condition bottom shows three subjects recorded second session walking conditions ﬁrst session. hereinafter following nomenclature used refer every four walking conditions considered normal walk carrying backpack approximately wearing coating shoes used clean rooms hygiene conditions elapsed time table recognition results gaid experiment entry contains percentage correct recognition. corresponds diﬀerent conﬁguration gait descriptor. size used best results marked bold. hofmann designed recommended experiments performed database. purpose split database partitions subjects training building models subjects validation subjects testing. finally experiments proposed validating robustness algorithms diﬀerent factors. experiment four ﬁrst sequences normal walking training sequences normal walking coating shoes respectively testing. therefore build classiﬁer using normal walking whereas test performed diﬀerent walking conditions conﬁguration. experiment identiﬁcation temporal test set. goal experiment evaluate inﬂuence recording diﬀerent seasons changes illumination clothes etc. experiment training ﬁrst four sequences normal walking recorded ﬁrst session testing sequences normal walking coating shoes respectively recorded second session. results experiment summarized tab. corresponds diﬀerent conﬁguration. experiment used temporal partitioning increase number samples number subjects available training temporal partitions overlap frames partitions. details presented below. table recognition results gaid experiment entry contains percentage correct recognition. corresponds diﬀerent conﬁguration gait descriptor. size used ‘len’ indicates number frames used temporal partition. best results marked bold. table state-of-the-art gaid. percentage correct recognition gaid diverse methods. column corresponds diﬀerent scenario. best results marked bold. wearing coating shoes higher values necessary sequences diﬀerent walking conditions algorithm requires larger dictionaries representing gait information. table tab. results experiment experiment obtain lower accuracy high variability train test sequences. moreover number samples available training classiﬁer makes harder obtain discriminant information needed identiﬁcation subjects. avoid lack split original training sequences independent subsequences frames frames overlap. thus sequence obtain subsamples allow train better classiﬁer. note tab. rows follow pattern pfm+pcal+pcah+lenxx corresponds frames partition. case best conﬁguration partitions lower number frames produces overﬁtting high number subsamples produced. hand partitions higher number frames produce subsamples huge diﬀerences number frames. follow pattern indicates used full sequence without partitions best case normal gait pfm+pcal+pcah without time partition train test samples similar. case achieves accuracy case carrying best conﬁguration pfm+pcal+pcah+t+o reaches accuracy finally wearing coating shoes case best result conﬁguration pfm+pcal+pcah+t+o results time partition useful experiments variability training test samples high. reasoning applies dictionary size tables indicate dictionaries allow algorithm achieve better results experiments diﬀerent conditions richer representation obtained consequently better generalization. results context works tab. contains results experiments particular bottom shows best results scenario taken tabs along average performance. ﬁrst method specialized temporal identiﬁcation authors report experiments case cannot obtain average accuracy. note approach improves state-of-the-art average lowest accuracy reached obtain value lower best result. rest cases method outperforms obtains similar results state-of-the-art. summarize main overall ﬁndings based experimental results obtained datasets. first results presented tables indicate proposed pipeline valid approach gait recognition obtaining correct recognition multiview setup avamvg mobo datasets casia-b. addition fv-based formulation surpasses bow-based stated authors problem image categorization moreover large dimensionality drastically reduced applying without worsening ﬁnal performance. example tab. reducing dimensions low-level motion descriptors ﬁnal allows achieve similar recognition rate decreasing focus idea spatially dividing human body computing diﬀerent gait descriptors results tab. show discriminantive features localized lower-body conﬁrms intuition addition although slight manner upper-body features contribute deﬁnition gait well. focusing tab. observe generalizes fairly well derived results obtained testing curved trajectories. note kind situations clearly beneﬁts multiple cameras indicated results yielded single cameras improved combined. dealing changing body viewpoints deformations body parts highlights importance good person tracker able properly group person detections along time. actually results reported work curved trajectories improve ones published conference version thanks stage links broken tracks persons regard level tab. tab. similar results obtained singletwo-level conﬁgurations. although tried additional third level pyramid recognition rate increase. fact indicates that situations enough single vertical partition person’s bounding-box obtain accurate results. however complicated scenarios wearing coats resolution videos casia-b using levels shows beneﬁts shown tab. concerning contribution subtypes descriptors experimental results suggest strictly necessary normalized coordinates safely omitted cases combination div+curl curl+shear enough achieve high recognition accuracy shown tab. tab. although deﬁned gait recognition problem multiple-camera setup results reported tables single camera case indicate proposed method also valid monocular environments. thus widening range application approach. known limitation approach handle trajectories perpendicular camera plane informative enough point trajectories cannot computed. example case ‘cl’ tab. opinion particular cases addition shape-based features could help. regard changes appearance people results casia-b gaid system able deal well people wearing bags although improvement needed strong changes clothing. addition although system initially designed deal outdoor infrared images results casia-c clearly indicates descriptor oﬀers state-ofthe-art results kind data. summary conclude proposed allows identify subjects gait using basis local motion coarse structural information moreover need either segmenting aligning gait cycle subject done previous works. tracking plus tracklets ﬁltering computation classiﬁcation makes total around seconds kind -frames video sequence. clearly computational bottleneck located person detection module. however based person detector could used instead. latter case system could achieve around fps. future improvement could speed-up dense tracking module restricting computation tracklets smaller image regions guided person detector previously instead processing whole image frame then removing unuseful tracklets currently done work. presented approach recognizing human gait video sequences. method builds motion-based representation human gait combining densely sampled local features fisher vectors pyramidal fisher motion. results show allows obtain high recognition rate multicamera setup evaluated datasets avamvg mobo casia single camera setup like gaid. case avamvg perfect identiﬁcation individuals achieved combine information diﬀerent cameras subjects follow straight path. addition pipeline shows good behaviour unconstrained paths shown experimental results model trained subjects performing straight walking trajectories tested curved trajectories. case mobo seen method able deal diﬀerences speed well cases movement arms available regard conﬁguration observed beneﬁcial decorrelate low-level motion features ﬁnal descriptor order achieve high recognition results turn decreasing computational burden test time classiﬁcation linear extremely fast -dimensional vectors. experimental results also show single camera viewpoint enough recognition many cases even using short time interval video sequence computed around second length sequence allows perfect recognition mobo single viewpoint. furthermore experiments casia-b casia-c gaid show system scales properly number subjects able handle changes appearance speed well able deal recordings taken indoors outdoors night. since person detector localize subjects proposed system restricted deal scenarios static backgrounds. moreover motion features used paper easily adapted static cameras removing global aﬃne motion proposed jain work partially funded research projects tin- broca ﬁnanced feder spanish ministry science technology; project tic- also thank david l´opez help setup avamvg dataset. portions research paper casia gait database collected institute automation chinese academy sciences.", "year": 2016}