{"title": "Online Tool Condition Monitoring Based on Parsimonious Ensemble+", "tag": ["cs.LG", "cs.AI"], "abstract": "Accurate diagnosis of tool wear in metal turning process remains an open challenge for both scientists and industrial practitioners because of inhomogeneities in workpiece material, nonstationary machining settings to suit production requirements, and nonlinear relations between measured variables and tool wear. Common methodologies for tool condition monitoring still rely on batch approaches which cannot cope with a fast sampling rate of metal cutting process. Furthermore they require a retraining process to be completed from scratch when dealing with a new set of machining parameters. This paper presents an online tool condition monitoring approach based on Parsimonious Ensemble+, pENsemble+. The unique feature of pENsemble+ lies in its highly flexible principle where both ensemble structure and base-classifier structure can automatically grow and shrink on the fly based on the characteristics of data streams. Moreover, the online feature selection scenario is integrated to actively sample relevant input attributes. The paper presents advancement of a newly developed ensemble learning algorithm, pENsemble+, where online active learning scenario is incorporated to reduce operator labelling effort. The ensemble merging scenario is proposed which allows reduction of ensemble complexity while retaining its diversity. Experimental studies utilising real-world manufacturing data streams and comparisons with well known algorithms were carried out. Furthermore, the efficacy of pENsemble was examined using benchmark concept drift data streams. It has been found that pENsemble+ incurs low structural complexity and results in a significant reduction of operator labelling effort.", "text": "on-demand framework tool replaced right time paradigm brings significant cost saving industry replacing sharp tools early often incurs frequent shutdown machining process leads dramatic increase tool costs whereas worn tool potentially damages surface finishing dimensional integrity work piece intensifies vibration level cutting process. tool longer desired functionality blunt entails high cutting force resulting expensive energy cost nutshell success allows advanced scheduling maintenance activities proactive allocation replacement parts enhanced fleet deployment decisions based estimated progression component life consumption. usually involves tasks namely sensing monitoring sensing phase used capture cutting signals sensors tcm. sensing classified types modes namely direct indirect. indirect sensing committed completing cutting process optical measurement surface-finishing measurement chip-size measurement etc. indirect sensing nevertheless compatible online tool condition monitoring must take place engaging cutting process without intermittent stoppage imposes unavoidable time loss sake measurement prevent production waste direct sensing hand relies correlated process variables vibration spindle current acoustic emission force determine tool wear. collected directly sensor data acquisition unit installation correct position among three force signal well-known most-correlated variable tool wear higher cutting force required tool blunt. second phase namely monitoring aims perform predictive analytics measured signals. existing monitoring approaches categorized three groups namely first principle data-driven hybrid. first department faculty engineering boulder university teknologi brunei brunei darussalam edwin lughofer department knowledge-based mathematical systems johanes kepler university witold pedrycz department electrical computer engineering university alberta canada tegoeh tjahjowidodo school mechanical aerospace engineering nanyang technological university singapore abstract— tool condition monitoring plays vital role reduce maintenance cost industry. generates information possible unsafe states machining process occur faults component predicted early support management life-cycle. faults could isolated minimize catastrophic effects leading complete shutdown overall production process. accurate diagnosis tool wear metal turning process remains open challenge scientists industrial practitioners inhomogeneities work-piece material non-stationary machining settings suit production requirements non-linear relations measured variables tool wear. common methodologies tool condition monitoring still rely batch approaches cannot cope fast sampling rate metal cutting process. furthermore require retraining process completed scratch dealing machining parameters. paper presents online tool condition monitoring approach based parsimonious ensemble+ unique feature pensemble+ lies highly flexible principle ensemble structure baseclassifier structure automatically grow shrink based characteristics data streams. moreover online feature selection scenario integrated actively sample relevant input attributes. paper presents advancement newly developed ensemble learning algorithm pensemble online active learning scenario incorporated reduce operator’s labelling effort. ensemble merging scenario proposed allows reduction ensemble complexity retaining diversity. real-world manufacturing data streams comparisons well-known algorithms carried out. furthermore efficacy pensemble+ examined using benchmark concept drift data streams. found pensemble+ incurs structural complexity results significant reduction operator’s labelling effort. first author acknowledges support start-up grant. third author acknowledges support austrian comet-k programme linz center mechatronics funded austrian federal government federal state upper austria. fourth author acknowledges support natural sciences engineering research council canada canada research chair computational intelligence. mahardhika pratama school computer science engineering nanyang technological university eric dimla mechanical engineering principle approach usually derives exact mathematical model degrading system including component. approach however problem-specific sometimes hard applied intricate inter-related nature manufacturing system. approach impractical fact machining process highly influenced number dynamic factors temperature cutting fluids chip formation workpiece tool materials etc. data-driven approach offers alternative former predictive analytics purely done using input/output data recorded number sensors data acquisition unit. approach makes intelligent techniques emulate dynamics tool condition learning process manufacturing data. tool wear progression measured considering plane-faced tool geometry approach flank wear underlying variable tool life. intelligent approaches feature generalization capability deployed monitor tool condition realtime mode engaging cutting process model created learning process. hybrid approach combines first-principle data-driven approaches executed parallel take advantages strength approaches. downside approach obvious expensive computational cost recent progress research reported data-driven approach gained increasing popularity community deployed verylittle capital expenditure done using exclusively sensory data require complicated pre-setting requirements assumption and/or simplification inherent first principle approach. data-driven method still requires advanced data analytics least three reasons existing approaches rely batch learning approach fully compatible online realtime processing. requires complete dataset covering possible situations monitoring process complete retraining scratch observing pattern monitoring process; existing approaches constructed static structure predetermined process runs. approaches self-adaptive thereby unable adapt variations machining parameters. also evident machining process often affected external disturbances lead previously learned concept invalid; existing approaches mostly designed crisp certain hidden nodes cope imprecision uncertainty noisy nature machining processes. industries integrated so-called internet-of-things current trend automation data exchange called industry calls advancements existing predictive maintenance cope online dynamic characteristics machining process concept evolving intelligent systems provides promising approach online predictive maintenance features important properties online learning dynamic evolving structure. trait appealing suitable real-time deployment modest computational resources. dynamic evolving structure capable tracking variation data streams prevents loss generalization capabilities presence shift drift data streams. research area grown rapidly manifested extensions variations eiss encountered literature vast majority existing eiss constructed single base-model evolving nature generated automatic partitioning input output space fuzzy rule neuron understood ensemble paradigm capable improving model’s generalization classification decision drawn collection local experts. ensemble method handles bias-variance dilemma better single model counterpart provided local experts exhibit good diversity. advantage normally achieved incorporating weak local experts. despite already mature reported literature works ensemble learning scenario utilize non-evolving even batched base classifier. results costly computational overhead memory burdens. evolving base-classifier helps ensemble classifier robust deal local concept drift offers better exploration local region static classifiers. local concept drift refers situation drift occurs local regions different intensities speeds. works literature incorporated evolving base classifiers different ensemble configurations bagging boosting stacking. works however crafted static ensemble structure cannot adapt concept drift. moreover suffer absence drift detection scenario identifies presence concept drift. worth noting drift detection becomes vital practice algorithm adapt drift also inform change occurs allow in-depth analysis system’s behavior. paper presents novel data-driven tool condition monitoring methodology benefiting recent progress area data stream analytics. evolving ensemble classifier namely parsimonious classifier+ forward. pensemble+ handles aforementioned limitations fact works fully single-pass fashion data directly discarded learned without requirement secondary memory archival storage. furthermore adopts fully evolving working scenario ensemble structure base-classifier structure automatically generated pruned data streams. moreover underlying innovation pensemble+ compared root pensemble implied facts pensemble+ equipped online active learning scenario actively selects training samples model updates. trait vital online tool condition monitoring relieves operator’s annotation effort; pensemble+ introduces notion ensemble merging scenario aims maintain ensemble complexity level improving diversity ensemble classifier. significance-based pruning strategy enhances technique existing literature often compromises model’s diversity. pensemble+ constructed generalized version dynamic weighted majority puts forward open ensemble structure. unlike original extension pensemble+ equipped online active learning scenario automatically selects training samples model updates based bayesian conflict measure analyses conflict level feature space target space. online active learning scenario utilizes dynamic threshold mechanism copes rapidly changing environments. realm tool condition monitoring problem online active learning scenario resolves major bottleneck supervised learner happens overdependent operator’s feedback. pensemble+’s structure automatically generated using drift detection method devised pensemble+ adopts penalty reward scenario base-classifier punished making misclassification whereas reward granted provided returns correct prediction. reward scenario additional phase respect original meant retain diversity ensemble classifier. worth-noting strength ensemble classifier compared single classifier lies diversity aspect addresses bias variance dilemma better single classifier robust various forms uncertainty noise etc. case however must interpreted care data stream context happens non-stationary outdated irrelevant classifier undermines final predictive decision. complexity reduction scenario incorporated ensemble merging scenario focuses redundancy issue. redundancy issue analyzed inspecting mutual information base-classifiers. classifiers significant amount mutual information merged. ensemble merging scenario offers plausible tradeoff diversity simplicity since scan poor classifiers rather focus redundant classifiers. another unique feature pensemble+ shown online feature selection scenario dynamically samples relevant input attributed training process. mechanism assigns numeric weight every input attribute every training observation allows arrive different subsets input attributes training process. pensemble+ deploys evolving fuzzy classifier namely pclass local expert adopts open structure. provides additional flexibility base-classifier level. furthermore pensemble+ implemented variants pclass namely axis-parallel multivariate. difference lies rule premise axis-parallel rule exploits gaussian rule diagonal inverse covariance matrix multivariate rule features advanced version former non-diagonal inverse covariance matrix. major contributions paper outlined follows paper puts forward perspective online tool condition monitoring approach based novel evolving ensemble classifier. unique features approach seen capabilities handling three bottlenecks existing data-driven time space complexity concept drifts data uncertainty; novel ensemble classifier namely pensemble+ proposed. algorithm goes step ahead compared existing ensemble classifier evolving classifier deployed base-classifier. variants pclass namely axis-parallel multivariate used base-classifier; pensemble+ also features online feature selection capable extracting relevant input attributes demand; another unique feature pensemble+ shown online active learning scenario automatically sampling relevant samples model updates ensemble merging scenario offering complexity reduction without compromising diversity ensemble classifier; real-world experiment metal-turning process carried real-world manufacturing data collected preprocessed. turns flank-wear factor affecting tool life chip-breaker geometry inserts greatly affects mechanics machining. experiment done types tool inserts chip breaker geometry coated uncoated grades. tools utilized cutting steel predictive analytics tool condition undertaken three sensory variables cutting force dynamic cutting force vibration. underlying goal identify cutter condition fly. experiment used fresh insert continued worn state without artificial actions wear tool. efficacy pensemble+ experimentally validated online tool condition monitoring metal cutting process compared number recently published algorithms learn++.nse learn++.cds pensemble pclass additional numerical results also served using popular concept drift problems literature. advantage pensemble+ evident experimental study attained significant improvement time space sample complexity even compared single classifier without substantial compromise accuracy. paper structured follows section encompasses learning policy pensemble+ learning procedure base classifier pclass; section outlines experimental procedure machining setup; section elaborates numerical results; concluding remarks drawn last section paper. section elaborates fundamental working principle pensemble+ including ensemble learning mechanism learning scenario base-classifier. overview pensemble+ learning mechanism depicted fig. pensemble+ executes data streams chunk chunk basis data chunk online active learning scenario meant shrink data chunk size relieve operator’s labelling effort. learning process continues online feature selection scenario assigns numeric feature weights every input attributes. performance base classifier evaluated based predictive performance reported observation misclassification triggers penalty reducing voting’s weight reward augments complexity reduction scenario pensemble+ deploys newly developed evolving classifier namely pclass base-classifier order attains greater flexibility handling concept drift individual local regions. phenomenon known local concept drift literature. evident concept change applies particular input regions different rates severities. fuzzy rule pclass pclass class first-order evolving fuzzy classifiers constructed takagi sugeno kang fuzzy system rule consequent implements firstorder linear function rule premise built upon multivariate gaussian function generating non-axis-parallel ellipsoidal clusters. although original pclass utilizes multivariate gaussian function non-diagonal inverse covariance matrix simplified version pclass also realized pensemble+ diagonal covariance matrix used. comparison aims provide overview ensemble performance different base-classifiers. rule growing strategy pclass pclass makes three rule growing modules namely datum significance data quality volume measure. datum significance method derived theory statistical contribution presented method aims estimate potential contribution rule data point lifespan. method assumes data samples uniformly distributed statistical contribution estimated using gaussian function kernel function. method utilizes uniform distribution assumption loses spatial information data streams. drawback addressed introducing sliding-window-based approach calculates accumulated firing strengths across data points sliding window. size sliding window often problem-dependent. method introduced answer bottleneck aims extract density information data samples. strategy inspired notion recursive density estimation pclass extends method multivariate gaussian function integrates weighting function cope outlier drawback furthermore third rule growing module checks volume winning rule. aims limit size fuzzy rules over-sized rules risks socalled cluster delamination problem. cluster cover distinct data distributions must noted that pensemble+ pclass also implemented axis-parallel ellipsoidal rule pensemble+ analyze effect different base-classifiers. formulas original pclass used except diagonal covariance matrix deployed instead nondiagonal version. rule pruning recall strategy pclass pclass equipped rule pruning scenarios namely extended rule significance potential+ methods. approach shares principle method except statistical contribution fuzzy rule estimated instead data point. component aims scan inconsequential rules play significant role lifespan. rules pruned without compromising generalization performance. method hand functions capture outdated rules longer relevant represent current data distribution. trait made possible inspecting density evolution fuzzy rules. method presents modification potential method potential method used rule pruning scenario method differs approach based inverse multi-quadratic function lieu cauchy function. addition pclass incorporates so-called rule recall scenario. scenario allows previously pruned rules reactivated future. scenario refers case concept reappears future. consider introduce rule overcome situation strategy catastrophically erases past learning history. situation undesired learning local region must restarted scratch again. undertake ensemble merging procedure based maximum correlation index discard i-th local expert undertakes drift detection method drift introduces base classifier elseif warning nothing prepare possible drift next observation elseif stable train winning classifier method presents weight decay term retain small bounded weight vector. strategy inspired concept generalized recursive least square incorporates weight decay term cost function fwgrls also seen variation fuzzily weighted recursive least square method addition weight decay term. advantage weight decay term safeguard weight vector keep values small. worth noting adopt simplified form grls method second term ignored. leads similar formulas fwrls method except presence weight decay term. strategy meant improve model’s generalization compactness rule base since rule small weight vector easily detected method. exist several types weight decay term quadratic quartic multimodal etc. quadratic weight decay term selected pclass since weight vector proportionally decreases initial values. pensemble+ developed generalized version adopts open structure paradigm. learning scenario clearly differs original least facets) voting weight given chance increase strategy aims retain diversity ensemble classifier; drift detection strategy deployed introduce baseclassifier whereas original base-classifier added global prediction returns misclassification; ensemble merging scenario based maximum information compression online feature selection scenario absent original dwm. algorithm illustrates fundamental working principle pensemble+. pensemble+ works chunk-by-chunk basis base classifier exists first classifier created using first data chunk. learning procedure starts online active learning scenario evaluating sample’s contribution whether deserves learning process. bayesian conflict measure deployed measure conflicts input output space. sample accepted model updates provided satisfies dynamic sampling criteria. data sample meets dynamic sampling criteria learning process continues labelling process followed online feature selection scenario. online feature selection selects relevant input features assigning crisp weights makes possible arrive different combinations feature subsets every training episode. predictive performance base classifier examined afterward classifier returning misclassification penalized decreasing voting weight whereas reward given increasing voting weight correct prediction made decreasing reward factor selected global prediction ensemble classifier inferred weighted class. voting weight base classifier normalized allow proportional voting weights among local experts. class maximum weight chosen predicted class. procedure followed ensemble merging procedure meant capture redundant classifiers. classifiers high mutual information coalesced. last phase drift detection scenario categorizing dynamic data streams three conditions stable warning drift. drift signaled baseclassifier introduced. action performed warning condition since phase depicts transition period drift confirmed. situation usually occurs presence gradual drift. winning classifier updated using newest data chunk stable phase keep upto-date recent concept prevent over-fitting. winning classifier selected lowest predictive error mse. learning components pensemble+ detailed follows online active learning strategy online active learning scenario urgently required complex manufacturing process cost obtaining true class label. usually requires complete shutdown machining process since flank wear evaluated visual inspection least delay expected receive true class label. pensemble+ features online active learning scenario based extended conflict ignorance paradigm evaluates conflict feature target domain. strategy derived conflict ignorance method conventional fuzzy classifier underlying difference lies dynamic sampling paradigm bayesian posterior probability estimation input output space. none works however investigate method within context ensemble classifier. matter fact ensemble learning scenario requires innovation sample evaluation strategy since consists collection local experts evolved different data space. must start fact data sample incur different conflict degrees different local experts. although sample evaluation strategy take place local level centralistic sample evaluation strategy base classifiers together roof produce predicted class label formed. strategy chosen suit online feature selection module pensemble+ also adopts centralistic feature selection scenario. moreover found make substantial difference since maximum operator ultimately committed performing local sample evaluation analyze confidence ensemble classifier. bayesian conflict measure input target space utilized evaluate conflict level local expert. bayesian approach preferred standard distance firing strength measure encompasses prior probability joint –category class probability. sample conflicting scope current fuzzy rule also occupies unclean region shared different class samples. moreover prior probability required take account cluster’s population since highly populated cluster tends frozen. longer responsive accept training stimuli characteristic rule premise update affected cluster’s support. conflict output space hand measured classifier’s truncated output. classifier’s output taken preference degree determined respect dominant classes since intuitively informs degree closeness decision boundary. sample conflicting falls near two-decision stand joint-class category probability upper likelihood function lower likelihood function prior probability. joint-class category probability prior probability defined follows j-th class i-th cluster. softened adding operation. approach useful category choice phase provides higher likelihood newly created cluster selected winning rule. joint-class category probability estimated number j-th class i-th rule signifies purity degree fuzzy rule class overlapping condition likely found case unpurified cluster. likelihood function defined similar crisp version using mahalanobis distance follows advantage bayesian approach also clear fuzzy rules occupy almost similar proximity data sample prior probability. volume fuzzy rules obtained ease determinant operator. precise estimation required calculated shown gamma function eigenvalue utilised. note determinant return negative volumes definition signed volume. classes obtained highest second highest outputs pclass. worth mentioning pclass characterizes regression-based classifier constructed mimo architecture scatters rule consequent output. evident formula portrays classifier’s confusion perfectly significant conflict indicated classifier produce conclusive prediction conflict threshold. higher value parameter higher number training samples accepted model updates whereas lower value parameter fewer number training samples discarded model updates. sample supposed good candidate model updates results significant conflict base classifiers. strategy aims enhance diversity ensemble classifier preventing redundant samples learned. furthermore budget controlling maximum labelling cost inserted approach useful true class label expensive obtained bioinformatics applications. online active learning also function address class imbalance issue. first imbalance factor estimated find minority majority classes. online active learning loose minority class samples point balanced proportion target classes achieved. minority class samples always sampled attain equal class distribution. since true class label unknown realm online active learning scenario estimated posterior probability input output space class imbalanced budget scenarios already actualized omitted keep presentation concise. online feature selection scenario online feature selection scenario based method method generalized well suited ensemble working scenario since original version covers implementation single linear regression. unique feature approach lies fact makes possible arrive different subsets input attributes assigning binary weights words removes risk discontinuity provides likelihood every input feature selected every observation. method cannot directly implemented ensemble learning scenario sensitivity input attributes analyzed respect base classifiers. issue leads carry scenario centralistic manner. fuzzy rules base-classifiers together perform procedure. note mechanism made possible fact pclass adopts local learning scenario every rule loosely coupled output covariance matrix. let’s recall fuzzy rule pclass comes follows procedure starts examining prediction single pclass created rules ensemble classifiers fuzzy rules together construct single classifier. takes place model returns method upper lower output weight vector applying standard cost function. stochastic gradient descent utilized adjust output weight rather fwgrls method pclass since method undertaken centralistic manner different optimization objective base-classifier level. moreover stochastic gradient descent much easier executed fwgrls method output covariance matrix assigned performing scenario. strategy also required examine whether values output weight vector concentrated within ball thus pruning small values remote ball center compromise model’s generalization. contribution input attribute informed dominance output weight vector. realm fuzzy system rule consequent output weight vector steers direction tendency rule output space. addition output weight vector stable gradient information sensitivity analysis. contribution input attribute expressed form number fuzzy rules across base-classifiers. note data standardization must performed context different input ranges obscure true contribution input attributes. suppose desired input dimensionality smaller original input dimension input input attributes permanently forgotten reactivated future whenever called current data distribution cyclic drift. method also covers case partial input information required cost feature extraction costly. partial input information similar full input version recounted paper. sensitivity measure also used ets+ nonetheless ets+ adopts hard input pruning mechanism superfluous features permanently discarded without opportunity picked again. ensemble pruning scenario main bottleneck ensemble classifier data stream application found issue computational space complexity incurs considerable complexity consists large collection base classifiers. nonetheless ensemble pruning scenario often counterproductive classifier’s accuracy since limits diversity ensemble classifier underlying strength ensemble classifier. ensemble pruning scenario discards superfluous classifiers either poor classifier outdated classifier. although classifiers play little lifespan remain important generate diverse output space. realm dynamic evolving learning environments significance base classifiers usually changes rapidly accordance context. using ensemble pruning scenario necessary integrate recall capability already pruned classifiers turn useful cover future data distribution. plausible approach complexity reduction ensemble classifier putting forward ensemble merging scenario. analyses mutual information base classifiers base classifiers featuring strong mutual information merged single classifier. mutual information quantified comparing classification output classifiers. mutual significance-based criterion measures correlation base classifiers. analysis mutual information performed using correlation measure provided satisfy online learning requirements. nonlinear correlation measure often accurate linear correlation measure scalable online real-time processing requires simplified assumptions follow normal distribution maximal compression index measure correlation base classifiers. approach robust conventional pearson correlation index since insensitive rotation translation calculates amount information loss ignoring base classifier significant difference exists small information ignored base classifier already covered pair. expressed follows translation mean expression nowhere insensitive rotation perpendicular distance point line dependent rotation. ensemble merging condition follows merging threshold. lower value threshold implies less merging process performed training process whereas higher value threshold induces aggressive merging process committed training process. merging decision taken classifiers discarded. classifier lower accuracy selected pruning process another retained. drift detection scenario dynamic pensemble+ controlled drift detection scenario aims discover abnormal patterns leading possible change data stream dynamics. drift detection based hoeffding’s inequalities classifies dynamics data streams three categories namely normal warning drift. normal phase means variation data streams found change still needs investigation warning phase. drift phase means change certain data streams. advantage method lies assumption-free probability density function. assumes data streams independent bounded random variables. drift detection scenario carried inspecting statistics data streams moving average without weight. although weighted moving average variant also exist standard moving average deployed since sensitive abrupt change weighted version also easy-to-use call specific tuning scenario weight adjustment. statistics data drift detection starts finding cutting point pinpoints switch point data distributions turn partitions data chunk three groups. switch point signal directly drift condition prevent outlier’s effects rather in-depth investigations must performed ascertain status data distribution whether drift really presents. line fact gradual drift three exists transition period depicts distributions. data point said point given following condition met. next step determine status data streams formulating hypothesis test. null hypothesis rejected size drift’s status returned whereas warning status version derived ease. drift detection strategy adopts similar concept statistical process control except assumption normal distribution removed. standard deviation confidence interval replaced significance level significance levels implemented determine conflict level data streams. correspond levels drift detection scenario namely warning drift warning. hypothesis inspects dynamic data streams switching point. meant substantiate presence drift data streams. null hypothesis happens maintained stable condition signaled. set-up consisted lang swing centre-lathe onto kistler tool-post dynamometer platform mounted three mutually perpendicular components cutting force. kistler tri-axial accelerometer used measure three mutually perpendicular components vibration underside tool holder. kistler charge amplifier kistler power supply/coupler used amplify decouple cutting force acceleration signals. cutting carried alloy steel work-piece brinell hardness composition tool holder sandvik ssbcr throwaway inserts sandvik coromant type scmt material three cutting speeds feed-rates respectively used constant depth signals recorded using amplicon data acquisition card mounted personal computer samples channel sampling rate recorded computer analysis. flank wear values determined effect surface quality equipment. well-known blunt tool imposes higher cutting force leads costly scrap even damages made machine. cutting conditions incorporated input vector sets assure underlying process parameters would less sensitive changes cutting conditions total input time-domain frequency-domain attributes collected identify five conditions tool. typical sensor used measure desired parameter parameters influencing measurement considered interfering measurement. example dynamometer often used measuring cutting forces correlated process interest. complex non-linear nature cutting process sensor co-operation desired also necessary. essentially sensor fusion relies fact fusion different source signals probable mediocre quality yields better results signal used comprehensive review synergistic integration multi-sensor information found typical application scenarios found sensor fusion traditionally performed application statistical methods regression analyses heuristic rules machine learning approach recently gained popularity tcm. metal turning processes flank crater wear usually prevalent forms tool wear cutting plane-faced geometry occurrence unavoidable. judicious choice cutting conditions remedy forms wear frittering notch nose. investigation coated un-coated carbide inserts chip breaker geometry reduce chip/tool contact utilized order minimize crater wear. process interrupted occasionally record flank/nose wear lengths measured tool maker’s microscope. wear criterion used guide strictly applied. decision percentage wear cutting tool used classification benchmark either worn sharp rather subjective. test began fresh tool insert cutting continued either tool failed flank/ nose wear accumulated excessively. following guideline employed determining tool class instrumentation set-up allow simultaneous recording static dynamic cutting forces. parameters mathematically extracted recorded cutting force signals. dynamic forces found calculating oscillatory part sampled force signals meanwhile arithmetic mean sampled cutting force signals taken represent static cutting force components. obtained dynamic data passed forward component dynamic force eliminated. total power contained spectrum taken values calculation together static forces formed input data samples. total data samples less could said represent cases namely binary multi-class simulated prediction phase. binary case formed grouping fresh nominally sharp group three assigned another group. multi-class case consists classes represents following toolcondition. -fold cross experimental procedure follows validation procedure hand meant avoid data order dependency problem utilizes -fold process data distributed mutually exclusive bins. first used test generalization power model remainder bins exploited evolve model. process moves next testing samples others used training samples. repeated bins used examine accuracy model. data stream environment created presenting data small batches training process. table summarizes details numerical study including characteristics datasets experimental procedure. pensemble+ benchmarked pensemble happens predecessor proposed algorithm exhibit extent proposed methodologies paper capable improving numerical results pensemble. pensemble characterizes fully evolving fuzzy classifier using pclass base classifier. however suffers absence online active learning scenario still utilizes generalization-based ensemble pruning scenarios. pensemble+ implemented types pclass axis-parallel multivariate perceive effect base-classifier overall learning performance. difference seen rule premise different ellipsoidal clusters generated automatically. simulation carried matlab laptop intel core ram. matlab codes pensemble+ provided in). benchmarked algorithms evaluated criteria classification rate fuzzy rule base classifier network parameters input attribute seen table pensemble+ capable delivering competitive accuracy less training samples pensemble. context binary classification problem pensemble+ even beats pensemble almost criteria. also confirmed pensemble+ saves around total training function contributes lowering fuzzy rule requirement. numerical study benchmark problems section elaborates numerical study using three popular concept drift problems namely hyperplane susy. pensemble+ compared algorithms evaluated performance metrics. experimental procedure follows periodic hold-out process training process carried using data streams testing phase utilizes even data stream. procedure simulates real data stream environments past samples discarded seen. table shows numerical results consolidated algorithms. hyperplane problem problem obtained data stream generator massive online analysis features binary classification problem main task classify data point classes respect random hyperplane d-dimensional feature space. class property problem lies gradual concept drift first data drawn distribution probability one. concept gradually shifts another data distribution point second concept completely replaces first concept. problem consists data samples concept drift occurs k-th samples. problem simulated using periodic hold-out scenario time stamps. time stamp involves samples samples used train model remainder samples serve validation samples. numerical results presented average time stamps. pensemble+ delivered encouraging numerical results sample consumption producing comparable accuracy. online active learning scenario capable significantly reducing number training samples pensemble+ attracts total training samples training process. moreover ensemble merging strategy relieves computational space complexity getting redundant classifiers. classifier sharing strong mutual information classifiers discarded without substantial loss generalization power. also observed pensemble+ multivariate gaussian rule achieves comparable numerical result axis-parallel gaussian rule. advantage seen terms fuzzy rule multivariate gaussian function leads compact parsimonious rule base axis-parallel rule. nonetheless multivariate gaussian function causes slightly higher network parameters stored memory. classification rate fuzzy rule input attribute network parameters execution time training samples ensemble size classification rate fuzzy rule input attribute network parameters training samples execution time ensemble size classification rate fuzzy rule input attribute network parameters training samples execution time ensemble size three times experiment data samples uniformly drawn range experiment imbalanced version problem introduced ditzler polikar minority class around total data samples. experiment carried chunk chunk mode chunk comprises data samples. number chunk drift applied every chunk. dynamic behavior ensemble structure depicted fig. fig. portrays trace fuzzy rules. fig. visualizes dynamic feature selection mechanism pensemble+ fig. exhibits trace training samples. problem illustrates although pensemble+’s accuracy slightly inferior pensemble attains much lower sample consumption comparable structural complexity. moreover pensemble+ unlike pensemble fully operates fully supervised manner demands high operator labelling efforts. pensemble+ produces similar performance different base-classifiers. observed fig. pensemble+ features fully open structure ensemble structure grows shrinks dynamically data streams. local expert automatically generated concept drift detected data streams. fig. also confirms pensemble+ drifts properly identified drift detection scenario pensemble+ integrating local experts. efficacy ensemble merging scenario also evident fig. classifier strong redundancy gotten without compromise classifier’s generalization. unlike existing variants ensemble learners pensemble+ deploys fully evolving local expert pclass. facet substantiated fig. fuzzy rules added pruned demand. trait helps handle concept drift better static classifier since network structure expanded data point carries significant novelty training process. moreover inactive rules pruned aspect alleviate issue overfitting. another unique property pensemble+ found dynamic feature selection scenario different subsets input attributes pensemble+. salient characteristic visualized fig. exhibits number times input attributes activated. fig. also implies input features activated deactivated demand training process. efficacy online active learning scenario shown fig. contributes dramatically lower number training samples model updates. first pensemble+ calls samples labelled learned training process. figure gradually decreases pensemble+ gets mature seeing past training samples. note sample significance examined absence true class labels. susy problem susy problem popular dataset. presents binary classification problem aims classify signal process produces supersymmetric particles background process not. problem input features first input features kinematic properties last features simply function first attributes. consists -millions data samples .-millions samples reserved training samples last samples used testing samples. simulate data stream environments data come batches timestamps. case study demonstrates scalability pensemble+ large-scale applications. exhibits significant improvement predecessor pensemble terms runtime. attributed online active learning scenario brings sample consumption level. local experts added removed demand fly. although pensemble+ works chunk chunk basis revisit previously acquired data chunk. memory demand hence remains independent total number data chunks. furthermore ensemble merging scenario reduces memory complexity numerical examples perceive pensemble+ parsimonious compact network structure. multivariate gaussian function brings positive effect alleviate computational structural burdens pensemble+. result however comes cost slight deterioration predictive performance. balakrishnan kannatey-asibu trabelsi emel sensor fusion approach cutting tool monitoring proc. conf. production research technology asme publication univ. california berkely dimla jnr. lister leighton multi-sensor integration method signals metal cutting operation application multi-layer perceptron neural networks international conference artificial neural networks july cambridge dimla jnr. lister leighton sensor fusion cutting tool state identification metal turning application perceptron neural networks ifac’s safeprocess august hull paper proposes novel tool condition monitoring methodology taking advantage evolving ensemble fuzzy classifier pensemble+. pensemble+ offers extension pensemble integrating online active learning scenario ensemble merging scenario. learning components improve viability pensemble real-world deployment reduce sample consumption labelling effort ensemble complexity modest level. real-world experiments carried real-world manufacturing data metal turning process collected. addition numerical examples using well-known data streams provided. shown pensemble+ delivers encouraging performance silva costa gouvea lacerda alves leite high impedance fault detection power distribution systems usingwavelet transform evolving neural network electric power systems research vol. costa angelov guedes fully unsupervised fault detection identification based recursive density estimation selfevolving cloud-based classifier neurocomputing vol. frias-blanco campo-avilla ramos-jimenes moralesbueno ortiz-diaz caballero-mota online non-parametric drift detection methods based hoeffding’s bounds ieee transactions knowledge data engineering vol. rong sundararajan huang saratchandran sequential adaptive fuzzy inference system nonlinear system identiﬁcation time series prediction fuzzy sets systems vol. g.-b. huang saratchandran sundararajan generalized growing pruning neural network function approximation ieee transactions neural networks vol. bouchachia dela dynamic online ensemble learning algortihm european symposium artificial neural networks computational intelligence machine learning kasabov song denfis dynamic evolving neural-fuzzy inference system application time series prediction ieee transactions fuzzy systems .vol .pp. dovzan logar skrjanc implementation evolving fuzzy model monitoring system waste-water treatment process ieee transactions fuzzy systems vol. h.-j. rong sundarajan g.-b. huang g.-s. zhao extended sequential adaptive fuzzy inference system classiﬁcation problems evolving systems vol. bifet holmes pfahringer kirkby gavalda ensemble methods evolving data streams proceedings sigkdd international conference knowledge discovery data mining m.pratama s.anavatti j.lu recurrent classifier based incremental meta-cognitive-based scaffolding algorithm ieee transactions fuzzy systems vol. i.zliobaite a.bifet b.pfahringer g.holmes active learning drifting streaming data‖ ieee transactions neural networks learning systems vol.no. pp.-", "year": 2017}