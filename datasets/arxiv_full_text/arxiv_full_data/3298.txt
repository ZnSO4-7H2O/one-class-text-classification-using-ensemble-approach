{"title": "A Novel Approach for Stable Selection of Informative Redundant Features  from High Dimensional fMRI Data", "tag": ["cs.CV", "cs.LG", "stat.ML", "I.5.2"], "abstract": "Feature selection is among the most important components because it not only helps enhance the classification accuracy, but also or even more important provides potential biomarker discovery. However, traditional multivariate methods is likely to obtain unstable and unreliable results in case of an extremely high dimensional feature space and very limited training samples, where the features are often correlated or redundant. In order to improve the stability, generalization and interpretations of the discovered potential biomarker and enhance the robustness of the resultant classifier, the redundant but informative features need to be also selected. Therefore we introduced a novel feature selection method which combines a recent implementation of the stability selection approach and the elastic net approach. The advantage in terms of better control of false discoveries and missed discoveries of our approach, and the resulted better interpretability of the obtained potential biomarker is verified in both synthetic and real fMRI experiments. In addition, we are among the first to demonstrate the robustness of feature selection benefiting from the incorporation of stability selection and also among the first to demonstrate the possible unrobustness of the classical univariate two-sample t-test method. Specifically, we show the robustness of our feature selection results in existence of noisy (wrong) training labels, as well as the robustness of the resulted classifier based on our feature selection results in the existence of data variation, demonstrated by a multi-center attention-deficit/hyperactivity disorder (ADHD) fMRI data.", "text": "objective functional magnetic resonance imaging measure brain activity task process emotion noninvasive safe means. numerous functional imaging studies reported neural activities experience specific emotions cognitive activities demonstrated potentials functional imaging classification cognitive states identification mental disorders. paper consider learning fmri data pattern recognition problem mainly focus accurately stably identify relevant features participate given cognitive task closely related certain mental disorders. paper mainly consider binary classification problems discriminating patients certain mental discorder normal persons classifying different cognative states though proposed idea also extended case regression know rapid development data capture storage technologies curse dimensionality becomes common issue many fields including field pattern recognition machine learning curse dimensionality often refers extremely high dimensional feature space. therefore feature selection dimensional reduction critical many pattern recognition applications medical image analysis computer vision speech recognition many paper consider related challeges neuroimaging data based pattern recognition besides curse dimensionality feature selection another common difficulty lies small number training samples varied reasons. high dimensionality small-sample-size issue number features variables overwhelmingly larger sample size important distinction neural imaging data analysis many kinds data analysis problems data analysis social media important need feature selection neuroimaging data analysis often inspired lines evidence. selected features used establish classifier better classification prediction accuracy also make predictors faster costeffective provides valuable information better understanding underlying processing generated data. selected features often considered potential biomarker medical diagnosis shed light biological processing involved various diseases suggest novel targets therefore relatively restrict control false positive false negatives selecting discriminative features strongly required. thus perform accurate stable feature selection becomes challenge also important problem neuroimaging analysis. bstract— recognition different cognitive states detection mental disorders function magnetic resonance imaging attracted increasing attention. often formulated pattern recognition problem classify different cognitive states discriminate patients mental disorders normal controls. feature selection among important components helps enhance classification accuracy also even important provides potential biomarker discovery. however traditional multivariate methods likely obtain unstable unreliable results case extremely high dimensional feature space limited training samples features often correlated redundant. order improve stability generalization interpretations discovered potential biomarker enhance robustness resultant classifier redundant informative features need also selected. therefore introduced novel feature selection method combines recent implementation stability selection approach elastic approach. compared traditional stability selection implebaseline model proposed method achieves better empirical sensitivity elastic encourages grouping effect besides sparsity thus making feature redundancy. compared feature selection method based plain elastic method achieves finite sample control certain error rates false discoveries transparent principle choosing proper amount regularization robustness feature selection results incorporation stability selection. advantage terms better control false discoveries missed discoveries approach resulted better interpretability obtained potential biomarker verified synthetic real fmri experiments. addition among first demonstrate robustness feature selection benefiting incorporation stability selection also among first demonstrate possible unrobustness classical univariate twosample t-test method. specifically show robustness feature selection results existence noisy training labels well robustness resulted classifier based feature selection results existence data variation demonstrated multi-center attention-deficit/hyperactivity disorder fmri data variation across different centers. index terms—medical image analysis feature selection elastic high dimensional feature space stability selection function magnetic resonance imaging yilun wang school mathematical sciences center information biomedicine university electronic science technology china chengdu sichuan china. also center applied mathematics cornell university ithaca zhiqiang yifeng wang xiaona wang junjie zheng xujun duan huafu chen laboratory neuroinformation ministry education school life science technology center information biomedicine university electronic science technology china chengdu sichuan china. overcome common challege number samples medical imaging data generally much smaller dimension feature space focus sparsity-based feature selection methods sparsity motivated prior knowledge discriminative features small portion whole features medical image analysis problems. sparsity considered blessing dimensionality sparsity alone sufficient making reasonable stable inferences. plain sparse learning models vide overly sparse hard-to-interpret solutions selected features often scattered. specifically highly correlated features small portion representative discriminate features selected resulting large false negative rate potential biomarker hard trust interpret. words resulted classifier might still achieve high classification accuracy also concise discovered biomarkers might incomplete reliable enough interpretability. particular neuroimage analysis general exists intrinsic spatial feature correlations. example measure voxel correlated measures neighbors phenomena widely observed. performing feature selection existing works focus select minimum discriminative features eliminate redundant though also discriminative features. beneficial main purpose establish concise simple classifier. however purpose mainly discover potential interpretable biomarkers plain sparsity based feature selection methods enough unlikely select redundant features. moreover demonstrate help reduendant informative features resulted classifier robust many cases. method tries consider grouped influence adding regularization traditional -norm penalty establish network. -norm regularization encourages grouping effect strongly correlated features tend model together. elastic used medical imaging analysis reconstruction localizing tumors images combined x-ray computed tomography positron emission tomography mass spectrometry imaging processing however like existing research elastic regression method mainly focus fitting model cares prediction accuracy. feature selections lacks scheme control false positives false negatives. recently several efforts finite control false discoveries variable selection statistical community. example stability selection important class methods high dimensional data analysis finite control false positives. special ensemble learning procedure stability selection effective approach stably reliably perform feature selection structure estimation based subsampling training samples interpretable potential biomarkers instead commonly focused classification accuracy. propose novel algorithm increase sensitivity performance traditional stability selection existence correlated redundant features. better performance validated synthetic problems real problems. notice that main benefit stable comprehensive discriminative feature selection discover better reliable interpretable potential biomarkers. meanings biomarkers often field-specific. first briefly review several commonly used feature selection methods fmri data analysis beyond sparsity related methods. typical methods feature selection fmri data univariate feature selection strategies t-test analysis variable pearson correlation using simple univariate statistical parameters directly testable easily interpretable computationally tractable. selecting subsets features preprocessing step independent chosen predictor. however recent studies demonstrated mental representations embedded distributed neural population code captured activity pattern across multiple voxels addition demonstrate sample t-test method robust case wrong labels paper. thus univariate method enough fmri feature selection. existing multivariate feature selection methods fmri data also called multi-voxel pattern analysis voxels considered features. mvpa emerging approach applies decoding scheme voxels entire brain volume simultaneously. mvpa proven highly useful decode different patterns brain activities existing multivariate methods support vector machine logistic regression work well task classification prediction. however feature selection results based obtained weights voxels training logistic regression models fail provide stable reliable feature selection results especially correlated redundant features exist though resultant classifier might still achieve satisfying classification accuracy. among mvpa sparsity regularized models widely adopted field fmri data analysis challenge high dimensional feature space relatively samples mentioned above however sparsity alone insufficient make interpretable stable inferences discriminative features especially many discriminative features highly correlated other. correspondingly ones make fact active voxels often grouped together clusters beyond elastic method ones also propose structured sparsity models enforcing structured constraints solution. example discriminative voxels grouped together clusters groups often known prior information however practice explicit grouping information often available beforehand. note multivariate feature section methods lack guaranteed control false discoveries feature selection results. therefore stability selection also applied fmri studies achieved better results paper achieve accurate reliable feature selection neuroimaging data analysis order achieve better interpretability discovered potential biomarkers. proposed novel feature selection method combining recent implementation stability selection elastic model order achieve better control false discovery rate missed discovery rate. framework stability selection chosen baseline model elastic rather tive redundant features. complete interpretable potential biomarkers revealed scientific meanings also discussed. moreover among first demonstrate unrobustness widely used two-sample t-test method show robustness benefited incorporation stability selection. specifically designed several experiments show robustness feature selection results based simulation data noisy labels well robustness resulted classifier based redundant informative features demonstrated multi-center attention-deficit/hyperactivity disorder fmri data variation across different centers. note paper deal fmri data also brain networks considered example feature extraction fmri. show proposed algorithm applicable voxel feature space also extracted feature space based fmri data. organization paper follows. section first briefly review stability selection recent variant well elastic methods feature selection respectively. method based proposed. section give detailed description neuroimaging experimental settings. section results feature selection method simulation data real fmri data including multicenter affective disorder given compared state-of-the-art alternatives. section short summary work possible future directions discussed. feature selection originates machine learning statistics. general redundant features often considered provide additional information even relevant features classification prediction accuracy main goal. traditionally purpose feature selection reduce risk overfitting hence improve generalization performance resulted classifier well reduce disturbance data noise classification accuracy. paper feature selection avoiding over-fitting generating concise reliable classifier also help discover potential biomarkers possible diagnosis affective disorder certain affective responses. therefore redundant features also informative need selected better interpretation discovered biomarkers i.e. control false positives false negatives need considered. addition pointed redundant informative features help enhance robustness resulted classifier verified point multi-center fmri data analysis. need make certain prior knowledge help achieve reliable feature selection reduce variance results example prior knowledge small portion features discriminative features among them. paper mainly focus embedded methods feature selection easier incorporate prior knowledge adoption regularization terms alternatives filters methods examples regularization based embedded methods lasso elastic ridge regression briefly reviewed below. paper adopted widely used supervise learning method select important features given labeled training data. linear models ensemble linear models proved sufficient produce effective classifiers fmri data high-dimensionality feature space relatively small number training samples feature main basis feature selection. common hypotheses made neuroimaging data analysis sparsity grouping effect. sparsity means relevant highly discriminative voxels implied classification task; grouping effect means feature correlations. example neuroimaging imaging data exists ``compact structure relevant discriminative voxels grouped several distributed clusters strongly correlated inwardly. general grouping effect necessarily mean correlated features neighbored spatially contiguous though might common take voxels neuroimaging data features. example connections different regions features features high correlations necessarily neighbored connections. short hypotheses need made feature selection algorithms designed. elastic based hybrid regularization lows ‖𝑦𝑦−𝑤𝑤𝑤𝑤‖+𝜆𝜆|𝑤𝑤|+𝜆𝜆‖𝑤𝑤‖ parameter regularization; parameter regularization. elastic select reltogether. particularly useful number features much number samples shown fmri data. regularization adopted however elastic respects hypotheses fmri data elastic based feature selection fails provide stable feature selection result i.e. lack finite sample control false discovery rate like existing multivariate feature selection methods. among recent efforts stability selection lasso refitting lasso model repeatedly subsamples data keeps features appear consistently lasso model across subsamples therefore incorporate idea stability selection elastic order achieve empirical control false discoveries. features together elastic net. elastic helps better take correlation property features consideration therefore often results smaller missed recovery rate informative though probably redundant features. subsampling features besides training samples expected make selection redundant though informative feature efficient reduction mutual masking relevant features. order achieve control false discoveries missed discoveries propose combine recent implementation stability selection elastic net. stability selection covariate subsampling random subsampling avoids case certain features take effect fixed combination therefore improve generalization feature selection result. paid price probably high false negative rate i.e. many true relevant features missed. contrary elastic takes feature correlation consideration help reduce missed discovery rate stability selection already proved able control false discoveries practice combination expected reduce false negatives. first gave overall description algorithmic framework. first denote number resamplings resampling step stability selection every subsampling random submatrices given training data matrix ℝ𝑛𝑛×𝑝𝑝 denoted submatrices 𝑋𝑋�𝑗𝑗 size⌊𝑛𝑛/𝐿𝐿⌋×⌊𝑝𝑝/𝑉𝑉⌋. corresponding label vector denoted as𝑦𝑦𝑗𝑗∈ ℝ⌊𝑛𝑛/𝐿𝐿⌋×. indices features denote feature. feature selected submatrix 𝑋𝑋�𝑗𝑗 𝑤𝑤𝑓𝑓=. otherwise estimate 𝑤𝑤𝑓𝑓 random submatrices 𝑋𝑋�𝑗𝑗∈ℝ⌊𝑛𝑛/𝐿𝐿⌋×⌊𝑝𝑝/𝑉𝑉⌋ 𝑦𝑦𝑗𝑗∈ ℝ⌊𝑛𝑛/𝐿𝐿⌋× based baseline model--elastic net. feature 𝑤𝑤𝑓𝑓 feature considered relevant feature. denote s�𝑋𝑋��=�𝑓𝑓 𝑤𝑤𝑓𝑓≠� features selected based 𝑤𝑤∈ℝ⌊𝑝𝑝/𝑉𝑉⌋× procedure reby 𝐒𝐒𝐒𝐒=𝑵𝑵� �𝒇𝒇∈𝐒𝐒�𝑿𝑿��� indicator function. would like point original stability selection proposed mainly random subsampling observations i.e. rows paper also pointed random subsampling terms observations general guarantee finite control false positives even though different base methods adopted. therefore using complicated base method elastic rather itives still achieved. moreover expect better empirical performance control missed discoveries benefiting incorporation correlation features elastic well subsampling subsampling features. first give brief review stability selection. stability selection originally proposed mainly subsampling observations. considers variable selection statistics also called feature selection machine learning community. motivation many feature learning selection methods share drawbacks unstable respect small variations data i.e. performs feature selection deferent sets training data coming source results still significant. mentioned above concern prediction main goal. however makes identification relevant features quite difficult. bility selection randomly chosen subsamples half size training samples. final selection obtained picking features whose selection frequency across repetitions exceeds certain threshold. variant stability selection named complementary pairs stability selection proposed still based subsampling training samples. stability selection able control false discoveries effectively empirically gives theoretical guarantees asymptotically consistent model selection. authors considered extension original stability selection proposed extension considers subsampling observations also considers subsampling features. given training data matrix ℝ𝑛𝑛×𝑝𝑝 extended stadom submatrices size ⌊𝑛𝑛/𝐿𝐿⌋×⌊𝑝𝑝/𝑉𝑉⌋ returning eter showed bigger results variance reduction. feature subsampling conducted solve problem mutual masking relevant features problem happens relevant feature intercorrelated. discussed automatic choice thorny theoretical question. practice ones found final results sensitive choice i.e. taking smaller subsample training samples degrade final performance. case memory parallelization ones choose relatively large initial intuitive analysis shows certain circumstances restricting search random subset increases probability correct recovery however precise rule optimal choice subsamples size left future study. paper respectively. spatial contiguousness like proposed applicable. however feature space still general high dimensional number samples typically relatively small i.e. n<<p still holds. cases correlation features i.e. columns still exists therefore proposed algorithm still applicable depend spatial contiguousness. words considering feature selection fmri data consider voxels feature data also consider connections features generate brain network based fmri data. study developed novel data-driven feature selection approach integrating elastic idea stability selection method. results synthetic data real neuroimaging data including multi-center data affective disorder indicated novel integrated approach valuable method potential biomarker extraction pattern recognition fmri data. demonstrate better control false discovery missed discovery proposed method. robustness feature selections existence label noise would also like show completeness feature selection algorithm helps generate robust accurate classifier multicenter fmri data analysis. point synthetic data real fmri data verify point. based true fmri data demonstrate scientific meanings better feature selection results context potential neuroscience biomarker discovery. point need robustness reliability feature selection often amplified challenge label noise. paper design robust test label noise simulation/synthetic data. previous study proved label noise potentially harmful feature noise highlighting importance dealing type noise. detailed description generating procedure presented following subsection point data noise data variation. often hard obtain high quality training data practice. form training data depends specific tasks source data quality. highly noisy nature high consumption nature fmri data robust stable feature selection method quite necessary. demonstrate advantage algorithm aspect multi-center adhd data data variation significant across different centers. make multi-center adhd data show selection redundant informative features help construct robust classifier. traditionally challenge construct robust classifier data variation across different centers. test data datasets x∈ℝ𝑛𝑛×𝑝𝑝 mation elastic regularization parameter regularization parameter fraction terms columns scores ss=. output stability scores terms rows x←𝑋𝑋𝑦𝑦←𝑦𝑦ℒ whereℒ⊂ {…𝑛𝑛} card=⌊𝛼𝛼𝑛𝑛⌋ updated ℝ⌊𝛼𝛼𝑛𝑛⌋×𝑃𝑃 updated y∈ℝ⌊𝛼𝛼𝑛𝑛⌋. terms columnsx←𝑋𝑋 where {…𝑝𝑝} card=⌊𝛽𝛽𝑝𝑝⌋ estimate 𝑤𝑤∈ℝ⌊𝛽𝛽𝑝𝑝⌋ s�𝑋𝑋��=�𝑓𝑓 𝑤𝑤𝑓𝑓≠� ss=𝑁𝑁∑ �𝑓𝑓∈s�𝑋𝑋��� know stability selection variants belong family general ensemble learning methods. however focus feature selection existing ensemble learning algorithms focus achieving better classification accuracy. algorithm following idea stability selection aims achieve feature selection controlled false positive rate. moreover unlike existing feature selection methods would like find informative though redundant features better interpretation potential biomarker also achieving robust classifier seldom mentioned existing literatures demonstrated section notice neuroimaging data analysis directly considering data taking voxels features perform pattern recognition classification. existed efforts exact appropriate feature extraction neuroimaging data depending different circumstances because appropriate features important achieve effective classification prediction accuracy well obtain useful potential biomarkers subjects normal correct normal vision free medications neurological psychiatric disorders. task dataset steady-state experimental design consisted trials trial comprised face image stimulation fixation. participants asked judge whether face neutral happy fact faces neutral. dataset compared comparable length resting-state dataset scanned task session. image brain data four subjects removed final analysis large head motions resting-state task data obtained using scanner university electronic science technology china. parameters follows repetition time echo time degree flip angle axial slices matrix field view. multi-center adhd data furthermore used multi-center fmri data test performance feature selection algorithm. data downloaded adhd- consortium global competition acquired different sites peking university york university child study center. children healthy controls remaining patients adhd york university site. children healthy controls remaining patients adhd peking university site. unlike face recognition fmri data brain connectivities features instead voxels data. details generate brain network given below. data-processing procedure face recognition fmri data multi-center adhd functional images preprocessed using data processing assistant resting-state fmri preprocessing steps included slice timing; spatial transformation included realignment normalization performed using threedimensional rigid body registration head motion. realigned images spatially normalized standard stereotaxic space using montreal neurological institute echo-planar imaging template. spatial smoothing filter employed brain’s three-dimensional volume isotropic gaussian kernel increase signal-to-noise ratio. then fmri time series task condition high-pass filter cut-off used remove low-frequency noise. multi-center adhd data consider brain networks thus proceed following pre-processing. subject multi-center fmri data divided anatomical regions interests according automated anatomical labeling atlas that representative time series region obtained averaging fmri time series voxels regions dparsf fig. synthetic fmri image. spatial distribution assumed active regions; three assumed stimulation patterns alternate points rest points task conditions. subregion respectively current study time point signals pixels features identify potential ones could classify active time periods blank time periods. second active temporal pattern designed discriminative pattern. active time points designed label inactive time points designed label identify discriminative features pixels subregions would discriminative clustered features correspondingly. fmri data face recognition experiments proposed algorithm baseline model--elastic assumed provide initial selection procedure subsampling thus hope values sparse parameters large features selected iteration; small case selection probability high features. stability selection make choice regularization parameters ranfixed values compared alternative one-time elastic data without subsampling used parameters determined based cross-validation mentioned paragraph. domized logistic proposed algorithms less sensiters elastic sub-problem iteration randomized logistic regression algorithm random logistic regression experiments. calculating discriminative voxels different pattern recognition methods test robust performance involved method condition training samples certain number wrong labeling. shows results robustness test. maps estimated discriminative voxels different methods synthetic data labels true method together l-svm methods find accurately discriminative regions. software. representative time series temporally bandpass filtered several sources spurious variance removed regression along first derivatives head motion parameters white matter signal cerebrospinal fluid signal. functional connectivity pair regions evaluated using pearson correlation coefficients resulting dimensional functional connectivity feature vectors subject. functional connections features used pattern recognition. alternative methods comparison fig. maps estimated discriminative voxels different methods synthetic data. maps labels ture. maps label wrong. maps five label wrong. maps label wrong. recognition methods including t-test -svm -svm logistic regression ℓlogistic regression randomized logistic regression elastic net. randomized loℓsvm ℓsvm ℓlogistic regression logistic regression written based available ℓlogistic regression code manuscript third column approach); pstg obtained method logistic rand-l; detected method elastic logistic rand-l captured method elastic logistic therefore three approaches including method logistic reveal five regions. however method obtained complete spatially continuous regions resulting distinguishing results. furthermore approach detect clustered regions methods line opinions steady-state brain responses high signal-to-noise ratio brain regions respond cognitive tasks high notice l-logisitc l-svm reveals voxels expected summary fig. showed method detect five regions involved time course facial recognition including pstg smc. five regions core regions face recognition stream visual information processing motor output. current results indicate method better detecting features cognitive activities alternative approaches. specifically achieve better false discovery control missed discover control advantage quite important revealing meaningful biomarkers either medical diagnosis cognitive study. shown second subplot accurately discriminative regions region shown first subplot. hard understand two-sample t-test based means variables distinct groups groups obviously different region result t-test might false positives. l-svm slightly surprises case find true discriminative regions labels true. however number wrong label increases result becomes disorderly unsystematic. l-logistic regression lsvm return over-sparse solutions hard discriminate interpret expected. single elastic able approximately find right regions labels true problem l-svm functions excessively relied quality data. randomized l-logistic classical stability selection method cannot return satisfying result especially labels wrong. results showed method better robust performance methods case existence wrong labels. results fig. show number wrong label increased change selected features methods small. even labels wrong method approximately find true discriminative regions indicating method good robust characteristic terms feature selection. intuitive explanation subsampling procedure provide stable feature section solution ensemble classifiers provide enhanced classification performance results fig. show precision-recall curve method five labels wrong. precision fraction retrieved instances relevant recall fraction relevant instances retrieved. still keeping good control false positives method sensitive. fmri scanning subjects conditions resting-state face stimuli. condition lasted min. according cardinal haemodynamic response function blood oxygen level dependent response strongest time points data used mean time points data. then number samples subject samples resting-state face stimuli state respectively. used averaged data based subjects. anchored five regions visual processing right fusiform face area right posterior superior temporal gyrus motor action left sensorimotor cortex describe time course face recognition. pstg core regions face recognition thought involved early perception facial features feedforward projection pstg connection pstg thought important processing dynamic changes face suggested could implicated facial emotion expression recognition activity sensorimotor areas serves marker correctly recognizing emotional faces well captured approach elastic logistic strategy evaluate performance classifier among first efforts perform cross valshow fig. classifier could reach using highest ranked feature. taking subject’s discriminative score threshold receiver operating characteristic curve classifier yielded shown fig. area curve proposed method indicating good classification power. since fmri data collected different centers systematic differences possibly caused different types machines settings method shows stable robust result case data variation first applied feature selection method data peking university. calculating score feature weight region could evaluated summing one-half feature scores associated region represent relative contributions different regions. regions showed greater weights others. specifically defined region significantly higher weight weight least standard deviation greater average weight regions previous studies regions higher weights included left precentral gyrus right superior frontal gyrus right rolandic operculum left olfactory cortex left anterior cingulate cortex left meddle cingulate cortex left lingual gyrus right inferior occipital gyrus left superior occipital gyrus bilateral fusiform gyrus left inferior parietal lobe left supramarginal gyrus right angular gyrus right temporal pole region left exhibited highest weight. fig. displays regions. fig. rendering plot regions significantly higher weight classification. size node represented magnitude normalized region weight. left. right related default mode network ventral attention network dorsal attention network executive control network visual network recent study pointed altered resting state functional connectivity adhd also found affected methylphenidate primary treatment adhd importantly five networks reported malfunctioned patients adhd studies using adhd- dataset high consistency among studies indicates method successfully detect core networks abnormal adhd. results therefore demonstrated effective method selecting true positive features rejecting false negative features real resting state fmri data. fig. predictive accuracy function number features used classification process using linear svm. features ranked according different weights descending order descending order combines stability selection elastic fmri data often correlative redundant features high dimensionality. tested effectiveness algorithm synthetic dataset real fmri datasets especially multi-center data mental disorder results indicated algorithm could effectively select discriminative features high dimensional data better empirical control false positives negatives. results suggest method suitable revealing potential biomarkers alternative approaches. accurate complete robust discovering true discriminative features provides sound support scientific research neuroscience certain degree. addition classifier based feature selection results algorithm achieve superior prediction accuracy robustness demonstrated multi-center data analysis first time best knowledge. however results mostly empirical might need perform theoretical support terms possible bounds false positive rate especially false negative rate future work. furthermore effectively distinguish true positives false positives needs better addressed. addition robustness data variation label noise might need theoretical analysis though empirically demonstrated paper. fig. shows predictive accuracy varies number relevant features used classification process. horizontal axis represents value number selected features divided .the l-svm achieves best accuracy highest ranked features used; randomized l-logistic achieves best accuracy highest ranked features used; elastic achieves best accuracy highest ranked features used; sample t-test achieves best accuracy highest ranked features used; logistic achieves best accuracy highest ranked features used; logistic achieves best accuracy highest ranked features used; achieves best accuracy highest ranked features used. highest classification performance corresponding different feature selection methods listed table corresponding sensitivity specificity also listed. shows method performs better methods terms accuracy also sensitivity specificity terms classification accuracy. summarize method demonstrated effective better robust performance methods selecting redundant informative features especially multi-center case data variation across different centers. shown robustness method terms feature selection exist noisy wrong labels first numerical experiments based synthetic data. multicenter data based experiment demonstrates accuracy completeness feature selection also help generate robust accurate classifier existence data variation. phenomenon accords related studies", "year": 2015}