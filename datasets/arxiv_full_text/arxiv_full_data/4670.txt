{"title": "Latent Contextual Bandits and their Application to Personalized  Recommendations for New Users", "tag": ["cs.LG", "cs.AI"], "abstract": "Personalized recommendations for new users, also known as the cold-start problem, can be formulated as a contextual bandit problem. Existing contextual bandit algorithms generally rely on features alone to capture user variability. Such methods are inefficient in learning new users' interests. In this paper we propose Latent Contextual Bandits. We consider both the benefit of leveraging a set of learned latent user classes for new users, and how we can learn such latent classes from prior users. We show that our approach achieves a better regret bound than existing algorithms. We also demonstrate the benefit of our approach using a large real world dataset and a preliminary user study.", "text": "personalized recommendations users also known cold-start problem formulated contextual bandit problem. existing contextual bandit algorithms generally rely features alone capture user variability. methods inefﬁcient learning users’ interests. paper propose latent contextual bandits. consider beneﬁt leveraging learned latent user classes users learn latent classes prior users. show approach achieves better regret bound existing algorithms. also demonstrate beneﬁt approach using large real world dataset preliminary user study. introduction general desire recommender systems quickly start providing good recommendations users particularly challenging prior information users available. often known cold-start problem. despite lack prior information users systems typically interacted millions previous users. therefore problem cast instance lifelong learning across sequential decision making tasks information prior users leveraged help improve recommendations user? standard techniques like collaborative ﬁltering provide good answers challenge approaches typically limited myopically providing single recommendation rather reasoning multi-step interactions system user. important because across sequence interactions useful system actively gather information order maximize beneﬁt longer individual question. approach model users contextual bandit model single shared model parameters prior users’ data leveraged model parameters interacting user. example algorithms linucb thompson sampling linear payoffs coﬁneucb however approaches work well many available features describe users capture user variability. features available need fall back population average make poor recommendations current individual. extreme learning algorithms linucb thompson sampling linear payoffs learn scratch user separately. systems provide full personalization individual take enormous amount interactions achieve this yielding little value long period instead propose approach provides partial personalization. assume users described belonging ﬁnite latent classes. class associated different model parameters within class individuals share parameters. compared extreme approaches mentioned above partial personalization fully rely user features capture user variability instead leverages users’ latent class structure quickly start providing good recommendations users. latent class structure explored noncontextual multi-armed bandits setting contextual setting closely related work club club learns underlying graph structure users based user similarities serves group users taking advantage learned graph structure. however show later algorithm theoretically empirically better club. paper focus latent contextual bandit setting. consider beneﬁt using learned latent classes obtain latent classes prior data online. also provide formal analysis regret setting building recent progress latent variable learning regression model mixtures using tensor methods bound performance obtained learning leveraging latent models learned data. demonstrate beneﬁt approach simulation unbiased ofﬂine evaluation using large real world dataset well predata learn latent models. therefore phase bootstrap phase algorithm. short phase cause high model estimation error early stage phase long phase cause large regret phase section discuss pick length phase overall regret bound. real world systems usually already huge interactions made prior users phase needed. phase train/re-train latent models using data collected phases show learn latent models section practice want re-train latent models batch users instead user. meanwhile phase leverage learned latent models improve performance tasks though many ways this propose approach ﬁrst constructs policy learned latent model uses contextual bandit algorithm adaptively select across policies task. policy function takes context input returns distribution arms. example policy could function always return highest expected reward estimated learned latent model. already exist numerous contextual bandit algorithms take input ﬁnite policies compete best policy inside policy build upon existing works. however phase offers multiple advantages relative prior works policy often smaller policies considered generic contextual bandit approaches; automatically constructs policies assuming problem setting holds policies sufﬁcient enable optimal performance task contrast standard contextual bandit approaches achieve performance good input policies precisely constructs policy learned latent model runs preselected contextual bandit algorithm takes learned policies latent contextual bandit tasks discuss speciﬁc choices ways construct policies section shortly provide theoretical analysis approach section learn latent models past users model latent user classes using mixture linear regressions mixture linear regressions consists mixture components linear regression model. model parameters mixture proportion variance response. efﬁcient vector likelihood mixture linear regressions deﬁned approach problem formulation assume sequence contextual bandit tasks contextual bandit task involves multi-step interactions particular user. users inﬁnite. user belongs ﬁnite latent classes. denote latent class user users within latent class share similar interests behaviors. task assumed last steps. task time step algorithm observes current user arms together d-dimensional feature vectors xtua atu. ||xtua|| feature vector xtua captures information user time example xtua could linear concatenation user feature vectors. assume size ﬁxed |atu| feature vectors together referred context {xtua|a atu}. algorithm recommends current user receives reward user. assume reward noisy linear function current user’s latent class. precisely latent class associated weight vector reward given latent contextual bandits algorithm latent contextual bandits described algorithm learns latent models prior users leverages learned models make recommendations users. algorithm consists phases. phase simply runs linucb algorithm ﬁrst users collects pulled arms rewards. reason phase initially starts scratch prior users training while paper assume users come sequentially interact algorithm approach also handle interleaved users. describe later phase algorithm doesn’t matter users interleave linucb used. phase current clusters parameters user he/she ﬁrst arrive entire time interact user. classic algorithm learn mixture model expectationmaximization algorithm. however guarantee convergence globally optimal parameters provide ﬁnite sample guarantees quality resulting parameter estimates. hand tensor decomposition based methods describe shortly give ﬁnite sample guarantees used derived regret bound. learn latent models using spectral experts anandkumar showed tensor decomposition efﬁciently recover parameters wide class latent variable models. exploited special tensor structure derived second third-order moments observations apply robust tensor power method recover model parameters. spectral experts built anandkumar al.’s work provide provably consistent estimator mixture linear regressions. algorithm uses spectral experts estimate parameters mixture linear regressions. later section also parameter error bound provided spectral experts bound regret algorithm. computationally expensive. therefore following section also derive implement computationally efﬁcient gibbs sampling based procedure estimate parameters mixtures linear regressions. learn latent models using gibbs sampling gibbs sampling efﬁcient inference technique learn latent models large scale dataset. derive sampling procedure dirichlet process mixtures linear regressions. using dirichlet process prior need specify number latent models. speciﬁcally assume prior follow normal-inversegamma distribution prior follows distribution used stick-breaking construction dirichlet process. generative process follows gamma latent model ﬁrst term equation given chinese restaurant process second term equation posterior predictive distribution given rh−u follows multivariate t-distribution sample adopt auxiliary variable method leverage learned models users ˆβn} learned latent models. deﬁne policies based models. types policies deﬁne deterministic probabilistic. deterministic maps context constructed polices used many contextual bandit algorithms serve users. policies deterministic possible contextual bandit algorithms include epoch-greedy ilovetoconbandits generalized thompson sampling policies probabilistic possible contextual bandit algorithms include exp.p algorithm choice depends desired outcome shortly consider speciﬁc choices theoretical analysis empirical results. theoretical analysis section analyze lcb’s expected regret. assume latent models learned using spectral experts algorithm. number users phase number users phase total u=j+ total number interactions. denote ﬁrst positive integers convenience deﬁne true policy user deterministic policy constructed theoretical analysis make minor changes algorithm first instead running single linucb instance users phase separate linucb instance user. reason realizability assumption single linucb instance runs users linear regret second collect i.i.d. samples user select arms uniformly random ﬁrst interactions user training latent models using spectral experts i.i.d. samples. spectral experts requires i.i.d. training examples theoretical guarantee parameter error bound. assume constant denote minimum euclidean distance latent models ||βh βh|| following theorems show problem-independent expected regret bound independent problemdependent expected regret bound depends theorem assume constructs deterministic policies. contextual bandits algorithm optimal regret bound problem-independent expected regret bound respect true policy best model user within estimated models. also recall true model user ˆβcu estimate returned spectral experts. achieves highest expected cumulative reward based deﬁnition achieves higher expected cumulative reward equation follows equation follows bounding last term applying cauchy-schwarz inequality. similarly exexp achieves regret finally adding regret bound phase phase prove theorem. results context compare regret results several approaches. compare following algorithms population exp.p runs single exp.p model users individual exp.p runs separate exp.p model user population linucb runs single linucb model users individual linucb runs separate linucb model user exp.p enum-policies enumerates policies mapping possible contexts possible arms runs exp.p user club lcb. table shows expected regret algorithm; also shows policy algorithm competing deriving regret bound. keep mind comparisons realizability assumption user belongs latent models. within algorithms table compete true policy user population linucb doesn’t distinguish users different classes competing best average policy users; population/individual exp.p requires pre-deﬁned policies input compete best inside policy instead true policy user. remaining algorithms compete true policy user; however achieves best expected regret bound. problem-independent regret bound individual linucb linear respect contexts’ feature dimension often large. deﬁne total number contexts. exp.p enum-policies term problem-independent regret bound often large even inﬁnite. lcb’s problem-independent regret bound hand square root dependence min{k table also shows problem-dependent regret bound club analyzed gentile club’s problem-dependent regret bounds depends however club square root dependence square root dependence constant. moreover analysis club shows club’s expected regret user linear respect constant order enormous small. meantable expected regret bounds baseline algorithms. denote number policies three exp.p variants number latent models club. denote total number contexts. following algorithms approach. choose generalized thompson sampling algorithm simulation spectral experts learn latent models time/memory constrains large real world dataset gibbs sampling learn latent models; similar except instead learning latent models provide true latent models algorithm. club; population linucb runs single linucb instance users; individual linucb runs separate linucb instance user; random selects uniformly random. linucb increased regret also increased. also individual linucb started learn good model user outperformed population linucb however still much higher regret lcb. simulation artiﬁcially created latent models shown figure model parameters assigned higher weights. users sampled uniformly random latent models. user interaction generated arms |atu| associated feature vector xtua sampled uniformly normalized ||xtua|| sampled reward xtua phase re-trained latent models every users. ﬁrst experiment ﬁxed users reported averaged per-user regret number users. results shown figure regret lower club lower population linucb. second experiment ﬁxed number users varied users. figure shows averaged per-user regret outperformed club experiments real world dataset evaluated algorithm news feed dataset provided yahoo. dataset contained users visits month period. visit user shown news articles down. user clicks logged. news categories news article belonged categories. therefore articles represented -dimensional binary feature vector. user features available privacy issues. best knowledge case perfect solution unbiased ofﬂine evaluation. stationary algorithm propensity scoring however algorithm nonstationary propensity score available dataset. state-of-the-art solution rejection sampling based replay method however rejection sampling quite sample inefﬁcient dataset policy generated dataset biased towards exploitation. therefore adopted queue method sample efﬁcient ofﬂine evaluation method non-contextual bandits extended contextual case. deﬁned queues user. queues user initialized click labels articles shown user. example article belonged categories click label added corresponding queues. finally project -dimensional article feature space -dimensional lower space category represented dense vector. ﬁxed number interactions user users ensure users users. reported relative algorithm’s divided data conﬁdentiality. ﬁrst experiment batch training algorithm pre-trained users tested users. relative test users reported. used training users learn latent models directly phase test users without re-training latent models. figure shows experiment results. achieved highest outperformed club moreover club outperformed population linucb reason rewards real dataset binary noisy samples user enough club learn good regression model user hence learn good latent graph structure. second experiment varied number latent models similar batch training algorithm pre-trained users tested users. result shown figure models started take beneﬁt latent class structure outperformed club linucb. latent models approach improved respectively compared club population linucb. third experiment simulated real world environment users came sequentially interacted algorithm. users used phase phase latent models trained re-trained after every users. collect i.i.d data points better learn latent models picked arms uniformly random ﬁrst interactions user used data points train/re-train latent models. algorithms reported relative every users. results pilot results user study section show pilot results user study users algorithm. compared algorithms population linucb lcb. since experiments section used yahoo real world dataset learned models directly used user study. used learned latent models section directly phase lcb. population linucb used learned population linucb model section initialize linucb model used user study. users interacted algorithms developed android platform. users. user interaction requested latest news articles yahoo news service real time. similar section news article represented -dimensional vector. algorithm selected articles user received user feedback table shows mean standard deviation achieved algorithms. pilot results outperformed population linucb. user study users algorithms progress. conclusion paper propose latent contextual bandits contextual bandits algorithm learns latent structure users leverages learned latent structure make personalized recommendations users. prove problem-independent problem-dependent regret bound respect true policies users. regret bounds signiﬁcantly improved baseline algorithms. demonstrate beneﬁt approach using simulation unbiased ofﬂine evaluation large real world dataset well preliminary user study. acknowledgments work supported cmu-yahoo inmind project. also gratefully acknowledge assistance and/or helpful feedback liangjie hong suju rajan michal valko saloni potdar zhengyang ruan linxi mingzhi zeng pilot study participants. references alekh agarwal daniel satyen kale john langford lihong robert schapire. taming monster fast simple algorithm proceedings intercontextual bandits. national conference machine learning pages navin goyal. thompson sampling contextual bandits proceedings international linear payoffs. conference machine learning pages animashree anandkumar rong daniel sham kakade matus telgarsky. tensor decompositions learning latent variable models. journal machine learning research alina beygelzimer john langford lihong reyzin robert schapire. contextual bandit algorithms supervised learning guarantees. proceedings international conference artiﬁcial intelligence statistics pages arun tejasvi chaganty percy liang. spectral experts estimating mixtures proceedings interlinear regressions. national conference machine learning pages tong zhang. epoch-greedy algorithm multi-armed advances neural bandits side information. information processing systems pages curran associates inc. lihong john langford robert schapire. contextual-bandit approach perproceedings sonalized news article recommendation. international conference world wide pages lihong john langford xuanhui wang. unbiased ofﬂine evaluation contextualbandit-based news article recommendation algorithms. proceedings fourth international conference search data mining pages travis mandel yun-en emma brunskill zoran popovic. queue method handling delay heuristics prior data evaluation bandits. twenty-ninth aaai conference artiﬁcial intelligence alex strehl john langford lihong sham kakade. learning logged implicit exadvances neural information proploration data. cessing systems pages yisong hong carlos guestrin. hierarchical exploration accelerating contextual bandits. proceedings international conference machine learning pages", "year": 2016}