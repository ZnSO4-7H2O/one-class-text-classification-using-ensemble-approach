{"title": "Spatial Semantic Scan: Jointly Detecting Subtle Events and their Spatial  Footprint", "tag": ["cs.LG", "cs.CL", "stat.ML"], "abstract": "Many methods have been proposed for detecting emerging events in text streams using topic modeling. However, these methods have shortcomings that make them unsuitable for rapid detection of locally emerging events on massive text streams. We describe Spatially Compact Semantic Scan (SCSS) that has been developed specifically to overcome the shortcomings of current methods in detecting new spatially compact events in text streams. SCSS employs alternating optimization between using semantic scan to estimate contrastive foreground topics in documents, and discovering spatial neighborhoods with high occurrence of documents containing the foreground topics. We evaluate our method on Emergency Department chief complaints dataset (ED dataset) to verify the effectiveness of our method in detecting real-world disease outbreaks from free-text ED chief complaint data.", "text": "many methods proposed detecting emerging events text streams using topic modeling. however methods shortcomings make unsuitable rapid detection locally emerging events massive text streams. describe spatially compact semantic scan developed speciﬁcally overcome shortcomings current methods detecting spatially compact events text streams. scss employs alternating optimization using semantic scan estimate contrastive foreground topics documents discovering spatial neighborhoods high occurrence documents containing foreground topics. evaluate method emergency department chief complaints dataset verify eﬀectiveness method detecting real-world disease outbreaks free-text chief complaint data. keywords event detection latent dirichlet allocation topic modeling eﬃcient topic model inference streaming document collections labeled topics time online online kernel topic models adaptive topic models dynamic topic models latent variable model geographic lexical variation discovering geographical topics twitter stream topic posterior contraction analysis text streams ubiquitous data processing knowledge discovery workﬂows. analysis summarization diﬃcult unstructured nature sparsity canonical bag-of-words representation massive scale web-scale text streams like twitter yelp reviews noise present word variations mispellings dialects slang. topic modeling mixed-membership model used summarize corpus text documents latent topics topic sparse distribution words. however traditional topic modeling methods like latent dirichlet allocation slow analyzing web-scale text streams also assume concept drift topics learned time. variations like online dynamic topic models topics time non-parametric topics time relax assumption concept drift learned topics time make strong assumptions evolution topics time. paper propose spatially compact semantic scan developed overcome shortcomings scalable detection spatially localized emerging topics text streams. background section introduce important terminology used rest paper describe latent dirichlet allocation collapsed gibbs sampling used inference. related work section present literature survey compare scss related previous work event detection text streams. methodology section motivate describe spatially compact semantic scan results section present results comparing scss state-of-the-art methods described related work section. discuss results possible avenues future work discussions section conclude report conclusions section latent dirichlet allocation bayesian mixed-membership topic model treats text document mixture various topics i.e. multinomial distributions words. described section spatially compact semantic scan improvement semantic scan detect emerging topics spatio-temporal text corpora emerging topic occurs documents spatially located close other. described detail section foreground documents documents contain emerging topics called foreground documents appropriate portion corpus called foreground corpus. division entire corpus foreground background corpora designated user method. user needs specify dividing timestamp documents collected timestamp designated background documents documents collected timestamp designated foreground documents. dataset chose documents background documents documents foreground documents. foreground topics also called topics emerging topics. topics alongbackground topics considered generated foreground documents generative process. here brieﬂy describe latent dirichlet allocation topic model since forms foundation scss. assumes documents generated mixture topics topics distributions words. model also intuitive polyhedral interpretation documents reside low-dimensional topic simplex embedded high-dimensional word simplex. parameter inference topic model therefore aims dimensionality reduction using small number latent topics best explain observed documents using latent topics. assumption necessarily true practiceit useful assumption helps denoising discovering frequent distinctive word co-occurrences text corpora. unique words dictionary. since parameter multinomial distribution words naturally assumed generated dirichlet prior parameter documents total. multinomial distribution topics document parameterized generated dirichlet distribution parameter generate word document ﬁrst sample topic position sampled topic sample actual word multinomial distribution parameter φzij plate diagram shows plates topics documents words within documents indicating templates need repeated corresponding number times obtain full probabilistic graphical model inference unknown parameters performed. observed words position document indicated darkened circles plate diagram unobserved variables inferred indicated empty circles. exact inference intractable general posterior unobserved parameters obtained using gibbs sampling variational inference. recent research found model identiﬁable assumptions separability i.e. topic anchor word occurs topic positive probability hence appears documents topic generating mixture topics work found model identiﬁable weaker assumptions z−ij denote particular instance topic assignments excluding assignment position document. aggregate statistics calculated also without considering topic assignment position document. easily calculated subtracting contribution counts resulting topic assignment position document. collapsed gibbs sampling proceeds words corpus sequentially. word position document calculates multinomial topic probability conditioned observed corpus topic assignments corpus z−ij. calculation governed following formula gibbs sampling samples topic topic multinomial distribution updates statistics adding count contribution newly sampled topic word position wij. algorithm moves next word position repeats topic multinomial calculation topic sampling statistics updates. process sequentially going words corpus sampling known eventually converge sampling stationary distribution topic model intial burn-in period typical mcmc sampling methods. gibbs gibbs sampling-based inference methods described similar semantic scan setting describe below perhaps closest work literature compare method. gibbs gibbs semantic scan begin learning topic assignments words background documents begin inference foreground documents. three methods also hold topic assignments words background documents ﬁxed performing sampling topic assignments foreground documents. however distinction method allows additional topics assigned words foreground documents gibbs gibbs not. allowing topics learned entirely foreground documents leads precise topics characterize emerging events text stream well. fact setting number topics semantic scan gives gibbs. background topics allowed change learned semantic scan gibbs. thus semantic scan generalizes gibbs purpose emerging event detection. labeled another paper closely resembles experimental setup. supervised method diﬀerent partitions corpus constrained contain diﬀerent sets topics. helpful multi-labeled text corpus text document possibly assigned multiple labels human labelers explicitly indicate topics contains. label associated topic document assumed contain topics corresponding labels gibbs sampling. setup associate background documents subset topics assigned foreground documents corrrespondence method labeled really becomes clear. however simplistic solution ignores fact number foreground documents available emerging event detection orders magnitude smaller number background documents collected years even decades. applying labeled naively would mean performing gibbs sampling entire corpus background foreground documents every time receive batch documents. scss method need perform gibbs sampling foreground documents much computationally eﬃcient labeled lda. topics time non-markov continuous-time model topical trends presents graphical model relaxes assumption markovian evolution natural parameters topic model. instead topic associated continuous beta distribution timestamps normalized interval topics remain static time however occurrence topics corpus varies non-paramteric topics time variation algorithm allows number topics determined corpus. however topics still constrained evolve smoothly time. online employs online variational bayes inference determine posterior distribution latent variables topic model. algorithm based online stochastic optimization shown provide equivalently good topics lesser time compared batch variational bayes algorithm. algorithm requires learning rate latent factor detection tracking online non-negative matrix factorization suggests using currently learnt topics along documents learn topics. approach similar variant semantic scan background topics used initialization step mcmc procedure foreground topics held ﬁxed inference foreground topics. drawback foreground topics found using method might include background topics span help precisely emerging foreground topics since detected topics might mixture latent factors. kernel topic models topic model incorporate spatial temporal hierarchical social metadata text documents topic model assuming document represented real-valued features generated realvalued functions sampled gaussian process prior passing features softmax function obtain document-topic proportions probability simplex. adaptation gaussian process latent variable model document-topic proportions obtained manner similar gplvm topics sampled dirichlet prior lda. kernel topic models make distinction background foreground documents might unable detect spatially localized emerging events small number foreground documents compared large background corpus. like many models kernel topic models also cannot applied event detection since ability detect event emerging foreground documents without signiﬁcant modiﬁcation additions algorithm. propose online version topic detection tracking. however method makes strong assumption evolution topics parameter dirichlet prior generating topic linear combination topic vector previous iterations algorithm. smoothness strict form imposed evolution topics allow method detect rapidly emerging topics subtle spatially localized topics hidden stream. addition assumption number topics constant time topic parameters evolve smoothly time. reason believe true since addition topic mean topic disappeared corpus. dynamic topic models extends model allowing natural multinomial parameters evolve consecutive time slices. standard markovian assumption state space models. model best illustrated using plate diagram shown ﬁgure shows extends topic model shown ﬁgure clearly illustrates markovian evolution parameters topic model. propose hierarchical model consisting pure topics suﬀer variations region form regional topics ﬁnally generate documents. model assumes ﬁxed number regions pure topics exist form regional variants every region. region modeled using bivariate gaussian distribution assumes region center regional topics concentrated eﬀect regional topics decays away center. consideriing bivariate gaussian distribution modeling location documents scss possible implies eﬀect topic decays away epicenter. might true case steady state disease outbreak documents aﬀected spatial neighborhood equally likely contain emerging topic. propse another topic model modeling text documents annotated geospatial coordinates. also model locations documents drawn bivariate gaussian distribution. however goal model geographically localized topics topic dominant region rather discover regional variants pure topics case deal spatial aspect topic models address detection emerging spatially localized topic. recent work suggests theoretical justiﬁcation typical topic models work well short documents like tweets. justiﬁes additional novel contributions need incorporate topic modeling improve outcome topic modeling spatio-temporal corpus short text documents. explanation number background documents number foreground documents total number documents corpus consisting background documents corpus consisting foreground documents composite corpus consisting documents background document foreground document document words background document words foreground document words document number background topics number foreground topics total number topics number words single document number unique words dictionary hyperparameter distribution severity hyperparameter center spatial region size spatial region nodes spatial region sparsity parameter subset variable capturing topic dirichlet hyperparameter mixture topics dirichlet hyperparameter mixture topics background topics ..tb foreground topics ..tf topics dirichlet hyperparameter generating background topics dirichlet hyperparameter generating foreground topics multinomial parameter document-specific topic mixture sampled topic word position sampled word position method capture spatial coherence emerging topic i.e. want detect documents contain emerging topic spatially close other. spatial proximity interpreted broad sense. simplest case mean documents contain topic actually generated geospatial locations close other. sophisticated case consider documents contain topic closer ways. example tweets generated users follow twitter considered close heterogeneous network structure twitter social graph. could useful detecting topics spread virally social network. example stock market crash undue market volatality could source discussion tweets among traders york london hong kong follow other. although cities geographically distributed believe market-related tweets emerging cities similarity measures derived underlying network structure. semantic scan neill murray method learns temporally emerging events text stream. method learns background topics background documents contain emerging event interest. documents comes semantic scan learns topics documents contrasting already learnt background topics relearn topics. describe detail here method spatially compact semantic scan builds incorporate spatial cohesion documents containing emerging topic well. original semantic scan learns emerging topics without taking spatial information account performs spatial scan identify emerging spatial cluster documents assigned topics. contrast scss coherently integrates spatial model aﬀected locations emerging topic model semantic scan thus enabling learnmore precisely focused spatially localized topics improve overall detection performance. semantic scan model detecting emerging topics illustrated using plate diagram ﬁgure notation used model explained table bayesian generative model outlined follows choose -dimensional dirichlet hyperparameter generating documentspeciﬁc topic distributions total number topics including background foreground topics. inference procedure consists phases shown ﬁgure ﬁrst phase learn background topics using collapsed gibbs sampling background documents. second phase keep ﬁrst topics ﬁxed learn topics allowing document-topic distributions foreground documents change gibbs sampling procedure. details collapsed gibbs sampling procedure refer reader section number background topics suﬃcient learnt background topics well ﬁxing background topics detection topic propels topic capture emerging trends text stream. span ﬁxed background topics explains words documents produced background data-generating process irrelevant emerging topic. plate diagram ﬁgure shows model inference performed second phase. model shows words documents well topics learned ﬁrst phase observed variables second phase perform collapsed gibbs sampling inference learn emerging topics topic modeling step neill assigns document topics using em-like approach performs circular expectation-based poission spatial scan order detect circular neighborhood zipcodes aﬀected outbreak. order ensure emerging topic also spatially regularized occur spatially nearby documents place hierarchical prior spatial regions whose documents aﬀected emergence topic. proposed topic model illustrated using plate diagram ﬁgure notation used plate diagram described table document generation process follows ﬁrst select subset zipcodes documents contain topic. this select center spatial region neighborhood size zipcodes nearest neighbors form circular neighborhood scn. construct arbitrarily shaped spatial region choose sparsity parameter sample zipcodes probability gives zipcodes documents zipcodes contain foreground topics. zipcode associated severity sampled beta distribution parameterized indicates proposrtion documents zipcode contain foreground topics. document located zipcode sample document-speciﬁc output bernoulli experiment indicating document contain topic using severity emerging topic indicated documents outside generated using topics distribution characteristics. documents outside distribution topics since document supposed contain topic. possible constrain hyperparameter topic distributions using hyperparameter however case uniform symmetric priors. sampled multinomial parameters sample topic word position document. sampled topic used index topic vectors parameters multinomial distribution words. using topic chosen word position sample word topic. completes generation process foreground documents text corpus emerging spatially localized topics. entire bayesian generative model outlined follows note variables marked hatched texture plate diagram ﬁgure observed variables inferred. inference proceeds mcmc sampling whose stationary distribution gives posterior distribution unobserved variables. inference posterior distribution variables done using generalized fast subset sums framework allows eﬃcient inference variables given likelihood ratio document. results alternating mcmc inference happens conditioned values remaining variables sampling variables proceeds conditioned inference iterate conditional here last step interchanging products product sums carried marginalizing possible values topic assignment variable considerably speeds computation likelihood terms exponential linear time. calculated likelihood ratio document calculate posterior probability event emerging topics localized given neighborhood centered consisting locations follows )thus posterior probability neighborhood showing outbreak foreground topics documents proportional product smoothed likelihood ratios documents neighborhood. finally calculate normalizer phase similar second phase semantic scan inference described earlier changes incorporate foreground documents believe actually contain emerging topics therefore composed background topics. believe document foreground topics therfore include part foreground documents gibbs sampling happens second phase semantic scan. believe document foreground topics indicated spatial inference based document-speciﬁc likelihood ratios therfore include document part foreground documents gibbs sampling happens second phase semantic scan. decided documents gibbs sampling done assigning values proceed collapsed gibbs sampling according procedure described section obtain foreground topics document-speciﬁc distributions topics used inference dataset consists text complaints noted staﬀ emergency departments allegheny county hospitals. dataset includes complaints complaint associated date recorded zipcode hospital complaint recorded code assigned. external manual classiﬁcation diseases using codes used create semi-synthetic disease outbreaks described below. external piece information associated text complaint assumed known detection methods used evaluating methods only. practice many cases code unknown incorrect ﬁnal assignment billing purposes patient’s visit. order geospatial coordinates complaint associated zipcode centroid latitude longitude coordinates zipcode area. thus dataset document short text complaint followed date recorded geospatial coordinates zipcode recorded code. perform leave-one-out validation scss alongwith baseline methods. treat documents background documents documents foreground documents. pick frequent codes dataset. codes remove complaints background foreground data corresponding code. create outbreaks corresponding heldicd code foreground documents belonging outbreak created sampling calculating neighborhood sampling sparsity parameter sampling scn. generate datapoint outbreak sample text document uniformly held-out text complaints location uniformly zipcodes held-out codes create outbreaks each resulting total outbreaks scss baselines. running methods assume -day moving window outbreak detection. methods like scss spatial necessary perform spatial scan last step since methods also output detected spatial region. methods including original semantic scan perform assignment documents topics circular spatial scan outlined semantic scan paper described section allows background foreground topics holds background topics ﬁxed learning foregroudn emerging topics incoming batch documents. background foreground topics used evaluation. ground topics. topic learning focuses foreground topics incoming batch documents. foreground topics used evaluation; background topics model. topics. static topics learned beginning ss-static performs document assignment sptial scan steps incoming batch documents. background topics used evaluation; foreground topics model. incorporates temporal aspect document modeling timestamps assigned topic sampled beta distribution speciﬁc topic. total topics used evaluation model. comparison scss modiﬁed additionally modeling spatial coordinates assigned topic sampled spatial gaussian distribution speciﬁc topic. total topics used evaluation model. refer variants olda. olda. respectively. hyperparameter online algorithm controls quickly topics adapt changes topics text stream. total topics used evaluation model. foreground documents belonging diﬀerent classes using prediction document’s assignment performing spatial scan obtained document assignments. graphs spatial precision recall overlap found ﬁgure three metrics plotted outbreak x-axis ranges observe scss spatial precision recall overlap almost double baselines. three metrics improve steadily duration intensity outbreak increases. number days. notice scss signiﬁcantly better document precision overlap compared baselines. document recall scss naive bayes similar performance naive bayes exceeds scss performance several points graph. however indicates naive bayes classifying documents part outbreak. considered together document precision overlap still conclude scss performs signiﬁcantly better baselines compared graphs fraction outbreaks detected number days data required detect outbreak found ﬁgure metrics plotted number false positives year x-axis. expected fraction outbreaks detected increases allow false positives year. similarly number days data required detect outbreak decreases allow false positives year. note scss performance metrics comparable ssemerging better ss-emerging false positive rates. scss performance signiﬁcantly better baselines metrics. however coupled performance precision recall overlap metrics scss beats baselines compared many baselines like spatial online state-of-the-art methods literature temporal event detection text streams. proposed topic model ﬁnding spatially compact temporally emerging topics real-world text corpora. evaluated model real-world data disease outbreak detection presented results section demonstrate eﬃcacy method. promising future directions considering ﬁnding subtle emerging topics mining residuals documents i.e. component document vectors explained currently learnt topics. newly emerging topic tend create clusters residual space mined topics high density regions using algorithm like dbscan spatial data-structure like r-tree", "year": 2015}