{"title": "Towards Reverse-Engineering Black-Box Neural Networks", "tag": ["stat.ML", "cs.CR", "cs.CV", "cs.LG"], "abstract": "Many deployed learned models are black boxes: given input, returns output. Internal information about the model, such as the architecture, optimisation procedure, or training data, is not disclosed explicitly as it might contain proprietary information or make the system more vulnerable. This work shows that such attributes of neural networks can be exposed from a sequence of queries. This has multiple implications. On the one hand, our work exposes the vulnerability of black-box neural networks to different types of attacks -- we show that the revealed internal information helps generate more effective adversarial examples against the black box model. On the other hand, this technique can be used for better protection of private content from automatic recognition models using adversarial examples. Our paper suggests that it is actually hard to draw a line between white box and black box models.", "text": "seong joon augustin bernt schiele mario fritz max-planck institute informatics saarland informatics campus saarbr¨ucken germany {joonmaxaugschielemfritz}mpi-inf.mpg.de many deployed learned models black boxes given input returns output. internal information model architecture optimisation procedure training data disclosed explicitly might contain proprietary information make system vulnerable. work shows attributes neural networks exposed sequence queries. multiple implications. hand work exposes vulnerability black-box neural networks different types attacks show revealed internal information helps generate effective adversarial examples black model. hand technique used better protection private content automatic recognition models using adversarial examples. paper suggests actually hard draw line white black models. code available goo.gl/mbyfsv. black-box models take sequence query inputs return corresponding outputs keeping internal states model architecture hidden. deployed black boxes usually purpose protecting intellectual properties privacy-sensitive training data. work aims inferring information internals black models ultimately turning white models. reverse-engineering black model many implications. hand legal implications intellectual properties involving neural networks internal information model proprietary training data privacy sensitive. disclosing hidden details also render model susceptible attacks adversaries. hand gaining information black-box model useful scenarios. e.g. work utilising adversarial examples protecting private regions photographs automatic recognisers scenarios gaining knowledge recognisers increase chance protecting one’s privacy. either crucial research topic investigate type amount information gained black-box access model. make ﬁrst step towards understanding connection white black approaches previously thought distinct classes. introduce term model attributes refer various types information trained neural network model. group three types architecture optimisation process training data approach problem standard supervised learning task applied models. first collect diverse white-box models expected similar target black least certain extent. then collected meta-training train another model takes model input returns corresponding model attributes output. importantly since want predict attributes test time black-box models information available attribute prediction query input-output pairs. experiments input-output pairs allow predict model attributes surprisingly well. summary contribute investigation type amount internal information black-box model extracted querying; novel metamodel methods reason outputs static query inputs also actively optimise query inputs extract information; study factors like size meta-training quantity quality queries dissimilarity meta-training models test black empirical veriﬁcation revealed information leads greater susceptibility black-box model adversarial example based attack. line work extracting exploiting information black-box learned models. ﬁrst describe papers extracting information discuss ones attacking network using extracted information model extraction attacks either reconstruct exact model parameters build avatar model maximises likelihood query input-output pairs target model tramer shown efﬁcacy equation solving attacks avatar method retrieving internal parameters non-neural network models. papernot also used avatar approach goal generating adversarial examples. avatar approach ﬁrst assumes model hyperparameters like model family training data discriminatively train metamodel predict hyperparameters themselves. such approach complementary avatar approach. membership inference attacks determine given data sample included training data particular ateniese also trains decision tree metamodel classiﬁers trained different datasets. work goes beyond inferring training data showing even model architecture optimisation process inferred. using obtained cues launch effective focused attacks black box. adversarial image perturbations example attack. aips small perturbations input network mislead. research topic ﬂourished recently shown needed amount perturbation completely mislead image classiﬁer nearly invisible effective aips require gradients target network. papers proposed different ways attack black boxes. grouped three approaches. approximate gradients numerical gradients caveat thousands millions queries needed compute single depending image size. avatar approach train white network supposedly similar target note metamodel complementary avatar approach avatar network hyperparemters determined metamodel. exploit transferability adversarial examples; shown aips generated network also fool networks particular shown generating aips ensemble networks make transferable. show work aips transfer better within architecture family across property exploited metamodel generating targetted aips. want type amount internal information black-box model revealed sequence queries. approach ﬁrst building metamodels predicting model attributes evaluating performance black-box models. main approach metamodel described ﬁgure nutshell metamodel classiﬁer black model input returns predicted model attributes output. describe detail metamodel learns infer model section main methods introduced context mnist digit classiﬁers. mnist classiﬁers fully representative generic learned models computational edge takes minutes train reasonable performance. could thus prepare diverse mnist classiﬁers within days meta-training evaluation metamodels. stress however proposed approach generic respect task data type models. also focus model attributes cover hyperparameters common neural network mnist classiﬁers range predictable attributes conﬁned list. need dataset classiﬁers train evaluate metamodels. explain mnist-nets constructed dataset mnist digit classiﬁers; procedure task data generic. every model mnist-nets shares convnet skeleton architecture conv blocks blocks linear classiﬁer. convolution optional max-pooling non-linear activation activation type chosen. block structure linear mapping non-linear activation optional dropout convnet structure already covers many lenet variants best performing architectures mnist. apart architectural hyperparameters increase diversity along axes optimisation process training data. along optimisation axis vary optimisation algorithm training batch size also consider training mnist classiﬁers either entire mnist training disjoint halves four disjoint quarters table comprehensive list model attributes altered mnist-nets. number trainable parameters training data size directly controlled derived attributes. also augment mnist-nets ensembles classiﬁers whose procedure described later. order learn generalisable features metamodel needs trained diverse models. base architecture described already several free parameters like number layers existence dropout maxpooling layers type nonlinear activation. number possible combinations controllable options table also select random seeds control initialisation training data shufﬂing {··· resulting unique models. training large number models intractable; sampled trained them. models trained order make sure mnist-nets realistically represents commonly used mnist classiﬁers pruned low-performance classiﬁers resulting classiﬁers. ensembles trained classiﬁers constructed grouping identical classiﬁers given identical ones augmented mnist-nets combinations. ensemble augmentation resulted ﬁnal models. appendix table statistics attributes large sample size attributes evenly covered. attribute prediction arbitrarily easy including black-box model meta-training set. introduce multiple splits mnist-nets varying requirements generalization. unless stated otherwise every split training testing leftover models. random split randomly assigns training test splits respectively. split training test models come distribution. introduce harder extrapolation splits. separate attributes training test splits. designed simulate difﬁcult domain gaps meta-training models signiﬁcantly different black box. speciﬁc examples splits shown metamodel predicts attribute black-box model test split submitting query inputs observing outputs. trained meta-training models training split propose three approaches metamodels collectively name kennen. ﬁgure overview. kennen-o ﬁrst selects ﬁxed queries i=···n dataset. training testing always queries submitted. kennen-o learns classiﬁer order-sensitively concatenated query outputs ]i=···n simultaneous prediction attributes training objective distribution meta-training models ground truth label attribute cross-entropy loss. learned parameter prediction attribute black experiments model classiﬁer multilayer perceptron hidden layers hidden units. last layer consists parallel linear layers simultaneous prediction attributes. preliminary experiments performed better linear classiﬁers. optimisation problem equation solved approximating expectation empirical training split classiﬁers epochs. query inputs used random subset images validation performance sensitive choice queries next methods describe actively craft query inputs potentially outside natural image distribution. note kennen-o applied type model output structure long output embedded euclidean space. show method effectively extract information even output top-k ranking. kennen-i crafts single query input meta-training models trained repurpose digit classiﬁer model attribute classiﬁer single attribute crafted input drives classiﬁer leak internal information digit prediction. learned input submitted test black-box model attribute predicted reading digit prediction example kennen-i max-pooling layer prediction crafts input predicted generic mnist digit classiﬁers max-pooling layers ones without. ﬁgure visual examples. -dimensional output digit classiﬁer condition image ensures input stays valid image image dimension loss together attribute label guides digit prediction reveal attribute instead. note optimisation problem identical training digit classiﬁers except ground truth attribute label rather digit label loss averaged models instead images input instead model optimised. learned query input attribute black predicted particular gradient information simple effective kennen-i predict single attribute time cannot predict attributes classes kennen-io introduced overcomes limitations. kennen-i also unrealistic exploration needs stealthy submits unnatural images system. also unlike kennen-o kennen-i requires end-to-end differentiability training models although still requires black-box access test models overcome drawbacks kennen-i predict attribute time number predictable classes attaching additional interpretation module output. ﬁnal method kennen-io combines kennen-i kennen-o approaches input generator output interpreters used. able reason multiple query outputs layers kennen-io supports optimisation multiple query inputs well. table comparison metamodel methods. table full names attributes. queries used every method below except kennen-i uses single query. output column shows output representation prob ranking top- bottom- attribute black predicted differentiability meta-training models black-box access test model improve stability covariate shift initialise kennen-o epochs. afterwards gradient updates introduced procedure constructing dataset classiﬁers well novel metamodels learn extract information black-box classiﬁers. section evaluate ability kennen extract information black-box mnist digit classiﬁers. measure class-balanced attribute prediction accuracy attribute list attributes table given queries probability output kennen-o already performs random chance predicting diverse attributes neural network output indeed contains rich information black box. particular presence dropout max-pooling predicted high precision. outputs networks trained dropout layers form clusters explaining good prediction performance. surprising optimisation details like algorithm batch size also predicted well random chance observe training data attributes also predicted high accuracy table shows comparison kennen-o/i/io. kennen-i relatively performance kennen-i relies cheap resource query single-label output. kennen-i also performant predicting kernel size pooling attributes closely linked spatial structure input. conjecture kennen-i relatively effective attributes. kennen-io superior kennen-o/i attributes average accuracy examine potential factors contribute successful prediction black internal attributes. measure prediction accuracy metamodels vary number meta-training models number queries quality query output. figure kennen-o performance size meta-training number queries quality queries unless stated otherwise probability outputs models train kennen-o. curve linearly scaled random chance performs perfect predictor performs trained kennen-o different number meta-training classiﬁers ranging ﬁgure trend. observe diminishing return also performance saturated collecting larger meta-training improve performance. ﬁgure kennen-o performance number queries probability output. average performance saturates queries. hand queries already retrieve ample information neural network. many black-box models return top-k ranking single-label output. represent top-k ranking outputs assigning exponentially decaying probabilities digits small probability remaining. table kennen-o performance comparison among probability top- ranking bottom- top- outputs average accuracies respectively. performance drops coarser outputs compared random chance single-label bottom- outputs already leak great amount information black also notable bottom- outputs contain much information outputs; note high-performance classiﬁers top- predictions rather uniform across models thus much less freedom leak auxiliary information. figure shows interpolation top- top- ranking. observe jump second likely predictions contain information likely ones additional output label exhibits diminishing return. seen results random split. realistic scenarios meta-training model distribution fully covering possible black models. show damaging scenario extrapolation split experiments. e-splits split training testing models based attributes example assign shallower models training split deeper ones testing split. example refer layers splitting attribute. since e-split classes splitting attributes zero training examples evaluate prediction accuracies non-splitting attributes. splitting attributes subset entire attribute deﬁne e-split accuracy e.acc mean prediction accuracy non-splitting attributes easier comparison report normalised accuracy normalised accuracies r-split multiple e-splits presented table consider three axes choices splitting attributes e-split architecture optimisation data example e-conv-fc presents results metamodel trained shallower nets compared test black model surprisingly e-split performances lower r-split ones advisable cover expected black-box attributes meta-training. nonetheless e-split performances kennen-io still chance level failing cover attributes meta-training damaging. table normalised accuracies kennen-o kennen-io splits. denote e-split splitting attributes attr attr e-attr-attr. splitting criteria also shown. splitting attributes ﬁrst attribute inherits previous criteria. comparing kennen-o kennen-io generalisability observe kennen-io consistently outperforms kennen-o severe extrapolation left future work investigate intriguing fact utilising out-of-domain query inputs improves generalisation metamodel. surprising metamodels extract inner details great precision generalisability. section provides glimpse possible metamodel input output analyses. full answers questions beyond scope paper. analyse inputs metamodels convince inputs contain discriminative features model attributes. input high dimensional t-sne visualisation method. roughly speaking t-sne embeds high dimensional data points onto -dimensional plane pairwise distances best respected. colour-code embedded data points according model attributes. clusters same-coloured points indicate highly discriminative features. visualisation input data points shown appendix ﬁgures kennen-o kennen-io respectively. experimental details appendix case kennen-o observe attributes form clear clusters input space e.g. tanh binary dropout attribute rmsprop alg. attributes however seems clusters complicated represented -dimensional space. kennen-io observe improved clusters pool submitting crafted query inputs kennen-io induces query outputs better clustered increasing chance successful prediction. show confusion matrices kennen-o/io analyse failure modes. appendix ﬁgures kennen-o kennen-io alike observe confusion occurs frequently similar classes. attributes conv confusion occurs similar trend observed strong indication exists semantic attribute information neural network outputs metamodels learn semantic information generalise opposed merely relying artifacts. observation agrees conclusion extrapolation experiments metamodels generalise. compared kennen-o kennen-io confusion matrices exhibit greater concentration masses correct class among similar attribute classes former re-conﬁrms greater accuracy latter indicates improved ability extract semantic generalisable features query outputs. this again agrees kennen-io generalises better kennen-o. veriﬁed novel kennen metamodels black-box access neural network exposes much internal information. shown single-label outputs already reveals great deal black box. black-box classiﬁer quite different metatraining classiﬁers performance best metamodel kennen-io– decreases; however prediction accuracy black internal information still surprisingly high. mnist experiments computationally cheap massive number controlled experiments possible provide additional imagenet experiments practical implications realistic image classiﬁers. section kennen-o introduced predict single attribute black-box imagenet classiﬁers architecture family section step extracted information attack black boxes adversarial examples. computationally prohibitive train imagenet classiﬁers scratch previous section. resorted pytorch pretrained imagenet classiﬁers. classiﬁers come families squeezenet vgg-batchnorm resnet densenet variants respectively appendix table summary classiﬁers. observe large intra-family diversity small inter-family separability terms layers parameters performances. family prediction task trivial e.g. simply inferring performance. predict classiﬁer family black-box query output using method kennen-o architecture kennen-i kennen-io used computational reasons also used principle. conduct cross validations evaluation. also perform random sampling queries imagenet validation set. total random tries averaged. aips carefully crafted additive perturbations input image purpose misleading target model predict wrong labels among variants aips efﬁcient robust gaman appendix ﬁgure examples aips; perturbation nearly invisible. typical algorithms require gradients target network available black box. mainly three approaches generating aips black boxes proposed numerical gradient avatar network transferability. show metamodel strengthens transferability based attack. hypothesize empirically show aips transfer better within architecture family across. using property ﬁrst predict family black generate aips instances family generation aips multiple targets proposed ﬁrst systemically show aips generalise better within family generated multiple instances family. ﬁrst verify hypothesis aips transfer better within family. within-family leave-one-out cross validation generate aips using instances family test holdout. using exact test black gives lower bound within-family performance. across-family still leave random instance generating family match generating size within-family cases. also include use-all case generate aips network family. table results. report misclassiﬁcation rate deﬁned −top- accuracy random imagenet validation images. observe within-family performances dominate across-family ones target black family identiﬁed generate effective aips. finally trying target network effective focusing resources empirically show reverse-engineering enables effective attacks. consider multiple scenarios. white means target model fully known generated specifically model. black means exact target unknown make distinction family known table misclassiﬁcation rates different scenarios. target fully speciﬁed neither exact target family known aips generated multiple families reverse-engineering takes place aips generated predicted family attacks become effective almost reach family-oracle case metamodel predict architecture families imagenet classiﬁers high accuracy. additionally show reverse-engineering enables focused attack black-boxes. presented ﬁrst results inference diverse neural network attributes sequence input-output queries. novel metamodel methods kennen successfully predict attributes related architecture also training hyperparameters even difﬁcult scenarios additionally shown imagenet experiments reverse-engineering black makes vulnerable adversarial examples. references giuseppe ateniese giovanni felici liugi mancini angelo spognardi antonio villani domenico vitali. hacking smart machines smarter ones extract meaningful data machine learning classiﬁers. ijsn pin-yu chen huan zhang yash sharma jinfeng cho-jui hsieh. zeroth order optimization based black-box attacks deep neural networks without training substitute models. acmccs-w huang zhuang laurens maaten kilian weinberger. densely connected convolutional networks. proceedings ieee conference computer vision pattern recognition forrest iandola song matthew moskewicz khalid ashraf william dally kurt keutzer. squeezenet alexnet-level accuracy fewer parameters <.mb model size. arxiv nicolas papernot patrick mcdaniel goodfellow somesh berkay celik anathram swami. practical black-box attacks deep learning systems using adversarial examples. nicolas papernot patrick mcdaniel goodfellow somesh berkay celik ananthram swami. practical black-box attacks deep learning systems using adversarial examples. asiaccs complement kennen-o results main paper kennen-io results. ﬁgure similarly kennen-o kennen-io shows diminishing return number training models number queries increase. performance saturates queries fully saturate training samples. kennen-o selects random queries mnist validation measure sensitivity kennen-o performance respect choice queries discuss possibility optimise queries. queries trained kennen-o independent samples query sets. mean standard deviations shown ﬁgure sensitivity greater smaller number queries still minute instead solving combinatorial problem ﬁnding optimal query inputs dataset proposed kennen-io efﬁciently solves continuous optimisation problem query inputs entire input space. compared kennen-io kennen-o multiple query samples ﬁgure observe kennen-io better kennen-o query samples level. remark exists trade-off detectability effectiveness exploration. kennen-io extracts information target model effectively increases detectability attack submitting out-of-domain inputs. possible optimise sample natural queries dataset distribution natural inputs strong attack; developing method would interesting future work. describe detailed procedure metamodel input visualisation experiment first test-split black-box models collected. model query images passed resulting dimensional input data points. used t-sne embed data points onto -dimensional plane. data point coloured according attribute class. results kennen-o kennen-io shown ﬁgures since t-sne sensitive initialisation embedding times different random initialisations; qualitative observations largely identical. section show examples aips. ﬁgure examples aips perturbed images. perturbation nearly invisible human eyes. also generated aips respect diverse architecture families multiple norm levels. ﬁgure image results diverse patterns depending architecture family. table distribution attributes mnist-nets attribute-wise classiﬁcation performance observe attributes evenly distributed corresponding classiﬁcation accuracies also correlate much attributes. thus make sure classiﬁcation accuracy alone cannot strong predicting attributes. figure performance kennen-io different number queries size training curves linearly scaled attribute random chance performs perfect predictor performs figure kennen-o/io performance different number queries. kennen-o shown independent query samples level dots spread horizontally visualisation purpose. mean standard deviations also shown. table details imagenet classiﬁers. describe family squeezenet vggbatchnorm resnet densenet verbally show model statistics member family. observe intra-family diversity inter-family similarity terms top- validation error number trainable parameters. figure adversarial perturbations input image generated diverse imagenet classiﬁer families different norm constraints. perturbation images normalised maximal perturbation visualisation. observe diverse patterns across classiﬁer families within ball.", "year": 2017}