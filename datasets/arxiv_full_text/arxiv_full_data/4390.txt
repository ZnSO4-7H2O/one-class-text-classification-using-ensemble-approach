{"title": "Transfer Learning by Asymmetric Image Weighting for Segmentation across  Scanners", "tag": ["cs.CV", "stat.ML"], "abstract": "Supervised learning has been very successful for automatic segmentation of images from a single scanner. However, several papers report deteriorated performances when using classifiers trained on images from one scanner to segment images from other scanners. We propose a transfer learning classifier that adapts to differences between training and test images. This method uses a weighted ensemble of classifiers trained on individual images. The weight of each classifier is determined by the similarity between its training image and the test image.  We examine three unsupervised similarity measures, which can be used in scenarios where no labeled data from a newly introduced scanner or scanning protocol is available. The measures are based on a divergence, a bag distance, and on estimating the labels with a clustering procedure. These measures are asymmetric. We study whether the asymmetry can improve classification. Out of the three similarity measures, the bag similarity measure is the most robust across different studies and achieves excellent results on four brain tissue segmentation datasets and three white matter lesion segmentation datasets, acquired at different centers and with different scanners and scanning protocols. We show that the asymmetry can indeed be informative, and that computing the similarity from the test image to the training images is more appropriate than the opposite direction.", "text": "supervised learning successful automatic segmentation images single scanner. however several papers report deteriorated performances using classiﬁers trained images scanner segment images scanners. propose transfer learning classiﬁer adapts diﬀerences training test images. method uses weighted ensemble classiﬁers trained individual images. weight classiﬁer determined similarity training image test image. examine three unsupervised similarity measures used scenarios labeled data newly introduced scanner scanning protocol available. measures based divergence distance estimating labels clustering procedure. measures asymmetric. study whether asymmetry improve classiﬁcation. three similarity measures similarity measure robust across diﬀerent studies achieves excellent results four brain tissue segmentation datasets three white matter lesion segmentation datasets acquired diﬀerent centers diﬀerent scanners scanning protocols. show asymmetry indeed informative computing similarity test image training images appropriate opposite direction. manual biomedical image segmentation timeconsuming subject intrainterexpert variability thus recent years advances made automate process. good performance supervised voxelwise classiﬁcation veronika cheplygina biomedical imaging group rotterdam erasmus medical center netherlands. medical image analysis group eindhoven university technology netherlands. manually labeled images used train supervised classiﬁers used successfully many applications. include brain tissue segmentation white matter lesion segmentation however supervised classiﬁers need labeled data representative target data needs segmented order successful. multicenter studies longitudinal studies diﬀerences scanners scanning protocols inﬂuence appearance voxels causing classiﬁer deteriorate applied data diﬀerent center. example show independent datasets classiﬁer performs well dataset separately performance degrades substantially classiﬁer trained dataset tested other. study segmentation three datasets different centers shows large performance classiﬁer trained same-center images classiﬁers trained diﬀerent-center images despite using intensity normalization. segmentation approaches literature address multi-center problem. recent survey segmentation shows surveyed papers papers used multi-center data used datasets lesion challenge survey therefore states robustness multi-center datasets remaining challenges automatic segmentation. even multicenter data used evaluation still assume presence labeled training data center. example uses lesion challenge datasets scans each joint -fold cross-validation. means fold classiﬁer trained subjects necessarily includes subjects centers. segmentation multi-scanner images sometimes addressed target-speciﬁc atlas selection multi-atlas label propagation although papers speciﬁcally focus images diﬀerent feature distributions selecting atlases similar test image could help alleviate diﬀerences training test data. however details make methods less suitable multi-center situations. zikic class probabilities based model intensities images additional features. diﬀerences feature distributions images could produce inaccurate model features would therefore introduce additional class overlap. transfer learning techniques employed order explicitly deal diﬀerences source target data. methods recently started emerge medical imaging applications. approaches frequently rely small amount labeled target data name few) unsupervised respect target favorable tasks annotation costly. latter case typically transfer achieved weighing training samples diﬀerences training target data minimized. example weight training images divergence kullbackpropose approach voxelwise classiﬁcation similarity-weighted ensemble random forests approach general applied segmentation task. classiﬁers trained once diﬀerent source image. target image classiﬁer outputs fused weighted averaging weights determined similarity source image target image. method require labeled data acquired test conditions computationally eﬃcient readily applied novel target images. method conceptually similar multi-atlas segmentation explicit focus diﬀerent training test distributions currently underexplored literature. furthermore medical image segmentation little attention paid asymmetric similarity measures. measures shown informative classiﬁcation tasks pattern recognition applications best knowledge investigated context similarity-weighted ensembles. novelty contribution lies comparison diﬀerent unsupervised asymmetric similarity measures allow onthe-ﬂy addition training testing data insights best deal asymmetric similarity measures brain segmentation. paper builds upon preliminary conference paper applied method segmentation. present work also apply method segmentation. addition investigate diﬀerent parameters affect classiﬁer performance provide insight asymmetry considered. outperform previous benchmark results four three datasets acquired diﬀerent conditions. task method also able outperform same-study classiﬁer trained images acquired conditions test data. scans older subjects scans ibsr young adults. subjects inﬂuences class priors tissues encountered images subjects relatively cerebrospinal ﬂuid less gray matter young adults. diﬀerences study populations inﬂuence class priors. average percentage voxels lesions respectively. diﬀerences subjects also vary relatively small large rss. subject least lesion voxels patient lesion voxels approach segmentation voxelwise classiﬁcation. therefore represent voxel vector features describing appearance voxel. prior feature extraction initial image normalization performed. normalization included bias-ﬁeld correction method inversion hasteodd images normalizing voxel intensities percentile range matching interval data range matching performed inside manually annotated brain masks. scans modalities obtained diﬀerent resolutions co-registered scan. range matching performed inside manually annotated brain masks masks generated {intensity gradient magnitude absolute value laplacian intensity} convolution gaussian kernel position voxel normalized size brain. illustrate despite initial normalization features result slightly diﬀerent distributions diﬀerent tissue types show embedding subset voxels diﬀerent datasets fig. voxels training image train random forest classiﬁer method applicable supervised classiﬁers output posterior probabilities. used speed inherent multi-class ability success medical image analysis tasks brain tumor segmentation ultrasound tissue characterization segmentation ensemble learning method. idea combine several weak diverse classiﬁers decision trees strong learner forest. train decision tree training voxels ﬁrst subsampled. tree built recursively adding nodes. node features randomly subsampled feature chosen splits voxels groups according speciﬁed splitting measure. commonly used measure decrease gini impurity. gini impurity voxels measures often randomly sampled voxel would misclassiﬁed labeled according class priors set. words impurity zero splitting group contains voxels single class only. splitting continues leaf nodes pure maximum allowed depth reached. training completed features chosen splits used calculate overall importance feature forest. test time voxel passed decision trees. subsampling data features training trees diverse therefore tree voxel ends different leaf node. class labels class label proportions leaf nodes combined output posterior probability test voxel. classify voxel ensemble rfs. test time method ﬁrst computes distance test image training images described section voxel classiﬁed classiﬁers outputs combined weighted average rule weights inversely proportional image distances. overview approach shown fig. trained voxels diﬀerent image output posterior probabilities. ensemble decision determined weighted average posteriors weights inversely proportional distance images inﬂuences scaling weights. high similar images even higher weight dissimilar images downweighted more. investigation parameter presented section section describe measuring distance images represented voxels described high-dimensional feature space. ideally small images similar thus training classiﬁer image lead good classiﬁcation performance image. sanity check therefore also examine supervised distance measure acts oracle well three measures labeled target data. distance measures explained below. oracle distance target labels evaluate well trained classiﬁer performs target image. instead using classiﬁcation error mean square error posterior probabilities distinguishes classiﬁers slightly inaccurate. denote posterior probability class given m-th classiﬁer distance deﬁned figure visualisation voxels diﬀerent-study images segmentation task. after initial normalization voxels image uniformly sampled images diﬀerent source feature vectors computed. t-sne embedding feature vectors performed visualisation. classiﬁer perform well voxels class diﬀerent images close together always case here. task note area right clusters voxels images quite dissimilar. task clusters lesion voxels diﬀerent images almost overlap. feature vectors feature vector describing voxel label indicating class voxel. information scanner and/or scanning protocol image originates from. figure overview method illustrated segmentation training images. training time voxels training image used train classiﬁer. test time voxels test image classiﬁed trained classiﬁer weights determined based similarity test image training images. weighted average outputs ﬁnal output method. target labels using clustering procedure. assumes image voxels class similar appearance i.e. form clusters feature space. assume many clusters classes. performing clustering assigning clusters diﬀerent classes label estimation possible. thus deﬁne dclu performing unsupervised clustering replacing true labels i.e. computing pairs intensity within cluster. -class unsupervised clustering k-means calculate average intensity order increasing intensity. segmentation prior knowledge based intensity flair scan. -class unsupervised clustering k-means calculate average intenclustering approach depends classiﬁer clustering algorithm used. also propose classiﬁer-independent approach assumption probability density functions source image target image similar labeling propose evaluate similarity pdfs kullback-leibler divergence similar approach diﬀerence weights determined jointly used weight samples determine weights individually weight classiﬁer outputs. image distance low. therefore even similarity high possible classiﬁer information large regions target feature space. example illustrating concept shown fig. asymmetry seen noise removed distance symmetrized example averaging case expect outperform however asymmetry contains information task performed removing symmetrization likely deteriorate performance. section describe experimental setup diﬀerent ways test method corresponding results. first compare diﬀerent image distances section followed comparison competing methods section provide insight diﬀerences image distances asymmetric versions. experiments conducted task images four sources task images three sources. experiments voxels image training classiﬁers voxels image evaluating classiﬁers. sample voxels randomly within brain mask. subset voxels within brain mask following appear bright flair images train test voxels within brain mask normalized flair intensity subset sample voxels ways. training evaluating classiﬁers oversample class voxels times likely sampled non-wml voxels. calculating distances test time target labels available voxels sampled randomly. rather viewing voxels image distribution view discrete point bag. advantage disadvantage approach omitted hand need choose kernel width hand outliers would smoothed greatly inﬂuence results. distance characterizes bags well even high-dimensional situations deﬁned three proposed measures asymmetric. however compute asymmetric versions dbag ddiv dclu requires labels computed direction. compute distances target samples source data alternatively direction reversed computing distances source samples target samples finally distance symmetrized example averaging denote avg. based results pattern recognition classiﬁcation tasks preliminary results segmentation hypothesis ensemble similarities outperforms ensemble similarities opposite direction distance target samples inﬂuence image distance. target samples mismatched image distance large. words high weight assigned classiﬁer means samples target image classiﬁer seen similar samples training. figure example three images asymmetric distances play role. average nearest neighbor distance measured source target zero sources average nearest neighbor distance measured target source larger source green outliers target. ﬁrst investigate eﬀect choice image distance classiﬁer. compare ensemble uniform weights three unsupervised distances well oracle gives optimistically biased results weights determined using test image labels. examine asymmetric symmetrized versions. error rates diﬀerent weight strategies shown fig. performances oracle demonstrate suitable weights good performances attainable. note oracle since uses target labels presented order impression best possible performances. example results demonstrate experiment study ibsr atypical images cannot classiﬁed well even supervised weights used. unsupervised similarities performs quite well task poorly task. understand result examine estimation labels clustering procedure alone i.e. matching cluster class label assigning label voxels belonging cluster. task median error worse methods. however estimated labels still prove useful assessing similarity achieves better results clustering alone. task clustering procedure alone median error poor. numbers lesion voxels clustering procedure able capture lesion class well. task gives best results overall. asymmetric versions show similar trends. hypothesized measuring similarity target source samples outperforms opposite direction. task situation respect asymmetry diﬀerent. three versions quite similar performances best choice case. particular results poor unc. explained prevalence lesions dataset. voxels target images lesions image distances inﬂuenced lesion voxel distances therefore noisy. hand therefore used image distances beneﬁt relying larger source lesion voxels. compare weighted ensemble baselines previous methods literature. baselines single classiﬁer trained source images ensemble uniform weights classiﬁer task compare approach wsvm. results shown table approach always outperforms training single classiﬁer outperforms uniform weights performance chb. compared wsvm methods performs better worse unc. however considering images result signiﬁcantly outperforms methods. based ability determine feature importance examine features deemed important training source classiﬁers weighting classiﬁers aﬀects feature importance. note splitting criterion used determine importance decrease gini impurity feature importances generally independent. example presence correlated features always chosen splits instead importance would high. however unlikely occur large number trees relatively small total number features. empirically veriﬁed whether could happen datasets comparing feature importances feature importances classiﬁer trained without important feature. correlations indicating feature correlations large inﬂuence determining feature importance. classiﬁers trained image classiﬁer feature importances associated examine average importances randomly selected target image. compare several alternatives importances averaged training ensemble same-study images averaging importances reﬂects best case scenario training ensemble diﬀerent-study images averaging importances uniform weights training diﬀerent-study images averaging importances weights given proposed method task importances shown fig. relative importance features similar across datasets therefore show intensities target study. intensity important feature followed features extracted smallest scale three sets tasks. rows correspond diﬀerent weighting techniques baselines uniform weights oracle weights clustering weights boxplot shows overall classiﬁcation errors diﬀerent colors indicate test images diﬀerent studies. task compare approach brain tissue segmentation tool weighted weights training images minimizing divergence training test data trains weighted svm. note wsvm weights images jointly weight classiﬁers individual basis. results shown table figure relative feature importance ensemble taskfor rss. intensity represent features scales respectively location features. columns show diﬀerent strategies training same-study images using uniform weights training diﬀerent-study images using uniform weights weights distance. figure relative feature importance ensemble task x-axis t/pd flair indicate features modality. columns show diﬀerent strategies training same-study images using uniform weights training diﬀerent-study images using uniform weights weights distance. larger scales location features) other. diﬀerent study plots importance intensity slightly lower weighting strategies help restore this i.e. columns similar same study situation. task importances shown fig. flair features important followed t/pd flair features important less unc. diﬀerences between weighting strategies larger task. seen brings importances closer samestudy plots look similar diﬀerent study plots. suggests might logical choice although case reﬂected classiﬁer performances. ﬁers eﬀect ensemble. larger diﬀerences classiﬁer weights become pronounced less classiﬁers responsible decisions ensemble. words higher translates selecting relevant classiﬁers. weights inﬂuence performance ensemble ways ranking scaling. distance measure weights diﬀerent ranking diﬀerent scaling aﬀects performance. demonstrate choice leads results fig. show distance matrices weights computed. column examine target image’s distances source images compute rank correlation distance supervised distance. average rank correlations distance measure. examine eﬀect weight scaling parameter weights. fig. shows proportion classiﬁers receives total weight diﬀerent values proportion would classiﬁers equal weights. ensembles similar classihigher coeﬃcient means method ranks source images similarly supervised distance therefore likely perform better. task highest correlation coeﬃcient best choice. consistent results shown section figure classiﬁers receive total weight function scaling parameter higher means weights uniformly distributed amongst classiﬁers lower means relevant classiﬁers selected. demonstrate computational eﬃciency method section present training testing times proposed approach. times indicative code optimized reduce computation time. classiﬁers trained once training time around seconds image done parallel. note training needs done once irrespective amount test images. test time parts consider calculating distances evaluating trained classiﬁers test image. calculating distances timeconsuming step. test image fastest method dclu followed dbag ddiv evaluation fast around seconds test image. figure visualization oracle dsup three versions dbag green distance high distance. dbag diagonal elements equal zero better visualization average distance matrix. shows average spearman coeﬃcient distance oracle distance. present weighted classiﬁer segmentation segmentation across scanners scanning protocols. show robust performances across datasets requiring labeled training data acquired target conditions requiring retraining classiﬁer. following sections discuss results well advantages limitations method detail. enced performance methods discuss section. ﬁrst diﬀerence distribution class priors task. classes equally sized classes highly imbalanced. second diﬀerence heterogeneity class balance class proportions diﬀerent images. although task subjects ibsr subjects class proportions across across ibsr ibsr similar. task class proportions different subject. furthermore source images similar class proportions always available especially target study. better understand heterogeneity task fig. show supervised distance matrix dsup shows performance classiﬁers images well visualization distances matrix. task matrix visualization show clusters cluster cluster ibsr ibsr. every target image always similar source image available. situation diﬀerent task. distances matrix uniform less clear similar images case. although using scanning protocol training image testing image necessarily eﬀective. task dissimilar dataset others demonstrated large diﬀerence same-study diﬀerent-study performances target study. because contain lesions classiﬁer overestimates number lesions leading many false positives pattern also seen rates several methods reported. rate controlled adjusting classiﬁer threshold studies segmentation showed tuning threshold improve performance. however tuned threshold using training data would help case tuned threshold test data optimistically biasing results. investigate whether diﬀerent classiﬁer threshold could improve results study experimented extension method informed total number lesion voxels target study. threshold total number voxels classiﬁed lesions equal true total number lesion voxels target study. threshold close default without large changes performance informed threshold much higher leading large improvement performance. question further investigation threshold without using prior knowledge target data. distance eﬀective task performed poorly lesion class could captured cluster. expect using sophisticated label estimation procedure would help achieve better results task well. could achieved example initializing cluster centers means training data constraining size clusters similar images similar. good performances show reasonable assumption datasets. however appropriate task classes evenly sized task lesion voxels contribute little distribution distance distance ways estimate similarity i.e. distributions feature vectors. however general similarity deﬁned ways example examining image similarity rather feature distribution similarity using properties external images. example task classifying alzheimer’s disease across datasets wachinger used features weight training images classiﬁer trained image features alone. weighting strategy takes characteristics account implicitly. example dataset older subjects older subjects receive higher weights younger subjects ibsr. would interesting investigate similarity measures unsupervised respect target data. possibility staple stands simultaneous truth performance level estimation. staple takes collection candidate segmentations input outputs estimate hidden true segmentation well performance measure achieved candidate thus giving candidate weight. approach taken staple weights combining classiﬁers segmentation. however output staple consensus segmentation would less appropriate similar images many highly dissimilar images task. used distances weight classiﬁer outputs. classiﬁer associated feature importances weighting classiﬁer outputs also implicitly changes feature importances ensemble. comparing weighted feature importances best case scenario feature importances also allows weights reasonable i.e. bring feature importances closer best case scenario. task three versions similar eﬀect feature importances. however task noticeable diﬀerences appeared reasonable measure even though reﬂected classiﬁer performances. important result eﬀect asymmetry similarity measures. task measuring similarity target data source data best choice symmetrizing similarity deteriorated results. supports hypothesis ignores important target samples classiﬁer information parts target data. hand task best choice terms classiﬁcation error. table result strongly inﬂuenced results number lesions low. number lesions distance includes lesion voxels. such lesion voxels suﬃciently inﬂuence image distances informative lesion non-lesion classiﬁcation. matching larger sets lesions voxels training image target data resulted distances informative. paper focused unsupervised transfer learning assuming labeled target data available. recent works transfer learning medical image analysis take diﬀerent strategy assume labeled target data available always case. method absence labeled target data means diﬀerences source target data handled. consider case distributions images ferent example decision boundary shifted and/or rotated. unsupervised distance measures output distance zero trained classiﬁer necessarily helpful classifying target image. another point labeled target data would helpful setting classiﬁer threshold discussed none training images similar classiﬁer might reliable. classiﬁer could also output uncertainty along predicted label. considerations important translating classiﬁers clinical practice. related point consider similarity training image thus accuracy classiﬁer independently. however performance ﬁnal ensemble depends factors accuracy base classiﬁers diversity base classiﬁers therefore adding accurate diverse classiﬁers effective adding slightly less good classiﬁers disagree several cases. applied approach segmentation tasks brain images brain tissue segmentation white matter lesion segmentation. however three similarity measures prior knowledge brain tissue lesions. such approach restricted applications applied tasks training test distributions diﬀerent. expect approach beneﬁcial simlikewise asymmetry similarity measures unique brain segmentation. previous work found asymmetry informative classifying sets feature vectors several pattern recognition applications outside medical imaging ﬁeld default strategy would symmetrize similarities. however found task eﬀective symmetrizing could deteriorate results. suggests might widespread issue. similarities abundant medical imaging important weighting training samples weighting candidate segmentations classiﬁers even using k-nearest neighbor classiﬁer. therefore urge researchers consider whether asymmetry might informative applications well. proposed ensemble approach transfer learning training test data originate diﬀerent distributions. ensemble weighted combination classiﬁers classiﬁer trained source image dissimilar test target image. investigated three weighting methods depend distance measures source image target image clustering distance divergence measure distance measure. distance measures unsupervised respect target image i.e. labeled data target image required. showed weighing classiﬁers outperforms training classiﬁer data assigning uniform weights source classiﬁers. best performing distance measure asymmetric distance measure based averaging nearest neighbor distances feature vectors describing voxels source target images. showed asymmetry important factor must carefully considered rather noise must removed symmetrizing distance. applied method diﬀerent applications brain tissue segmentation white matter lesion segmentation achieved excellent results seven datasets acquired diﬀerent centers different scanners scanning protocols. additional advantage method classiﬁers need retraining novel target data becomes available. therefore believe approach useful longitudinal multi-center studies multiple protocols used well clinical practice. research performed part research project transfer learning biomedical image analysis ﬁnanced netherlands organization scientiﬁc research grant thank martin styner permission lesion challenge data.", "year": 2017}