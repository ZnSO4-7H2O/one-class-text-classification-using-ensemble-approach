{"title": "Explain Images with Multimodal Recurrent Neural Networks", "tag": ["cs.CV", "cs.CL", "cs.LG", "I.2.6; I.2.7; I.2.10"], "abstract": "In this paper, we present a multimodal Recurrent Neural Network (m-RNN) model for generating novel sentence descriptions to explain the content of images. It directly models the probability distribution of generating a word given previous words and the image. Image descriptions are generated by sampling from this distribution. The model consists of two sub-networks: a deep recurrent neural network for sentences and a deep convolutional network for images. These two sub-networks interact with each other in a multimodal layer to form the whole m-RNN model. The effectiveness of our model is validated on three benchmark datasets (IAPR TC-12, Flickr 8K, and Flickr 30K). Our model outperforms the state-of-the-art generative method. In addition, the m-RNN model can be applied to retrieval tasks for retrieving images or sentences, and achieves significant performance improvement over the state-of-the-art methods which directly optimize the ranking objective function for retrieval.", "text": "paper present multimodal recurrent neural network model generating novel sentence descriptions explain content images. directly models probability distribution generating word given previous words image. image descriptions generated sampling distribution. model consists sub-networks deep recurrent neural network sentences deep convolutional network images. sub-networks interact multimodal layer form whole m-rnn model. effectiveness model validated three benchmark datasets flickr flickr model outperforms state-of-the-art generative method. addition m-rnn model applied retrieval tasks retrieving images sentences achieves signiﬁcant performance improvement state-of-the-art methods directly optimize ranking objective function retrieval. obtaining sentence level descriptions images becoming important task many applications early childhood education image retrieval navigation blind. thanks rapid development computer vision natural language processing technologies recent works made signiﬁcant progress task many works treat retrieval task. extract features sentences images semantic embedding space. methods address tasks retrieving sentences given query image retrieving images given query sentences. label query image sentence annotations images already existing datasets thus lack ability describe images contain previously unseen combinations objects scenes. work propose multimodal recurrent neural networks model address task generating novel sentences descriptions images task image sentence retrieval. whole m-rnn architecture contains language model part image part multimodal part. language model part learns dense feature embedding word dictionary stores semantic temporal context recurrent layers. image part contains deep convulutional neural network extracts image features. multimodal part connects language model deep together one-layer representation. m-rnn model learned using perplexity based cost function errors backpropagated three parts m-rnn model update model parameters simultaneously. best knowledge ﬁrst work incorporates recurrent neural network deep multimodal architecture. experiments validate model three benchmark datasets iapr flickr flickr show method signiﬁcantly outperforms state-of-the-art methods task generating sentences task image sentence retrieval using image feature extraction networks. model extendable potential improved incorporating powerful deep networks image sentence. figure examples generated top-ranked retrieved sentences given query image iapr dataset. sentences well describe content images. show failure case fourth image model mistakenly treats lake sky. deep model computer vision natural language. deep neural network structure develops rapidly recent years ﬁeld computer vision natural language. computer vision krizhevsky proposed deep convolutional neural networks layers image classiﬁcation tasks outperformed previous methods large margin. recently girshick proposed object detection framework based alexnet. natural language recurrent neural network shows state-of-the-art performance many tasks speech recognition word embedding learning image-sentence retrieval. many works treat task describe images retrieval task formulate problem ranking embedding learning problem ﬁrst extract word sentence features uses dependency tree recursive neural network extract sentence features) well image features. optimize ranking cost learn embedding model maps language feature image feature common semantic feature space. directly calculate distance images sentences. recently karpathy et.al showed object level image features based object detection results generate better results image features extracted global level. generating novel sentence descriptions images. generally categories methods task. ﬁrst category assumes speciﬁc rule language grammar. parse sentence divide several parts part associated object attribute image uses conditional random field model uses markov random field model). kind method generates sentences syntactically correct. ancategory methods related method learns probability density space multimodal inputs using example deep boltzmann machines topic models generate sentences richer ﬂexible structure ﬁrst group. probability generating sentences given corresponding image serves afﬁnity metric retrieval. method falls category. close related tasks method work kiros built log-bilinear model needs ﬁxed length context whereas model temporal context stored recurrent architecture allows arbitrary context length. brieﬂy introduce simple recurrent neural network elman network widely used many natural language processing tasks speech recognition architecture shown figure three types layers time frame input word figure illustration simple recurrent neural network multimodal recurrent neural network architecture. simple rnn. m-rnn model. input model image corresponding sentences model estimate probability distribution next word given previous words image. architecture much deeper simple rnn. illustration unfolded m-rnn. model parameters shared temporal frame m-rnn model. layer recurrent layer output layer activation input recurrent output layers time denoted respectively. one-hot representation current word. representation binary dimension vocabulary size non-zero element. calculated follows size adaptive length input sequence recurrent layers connect sub-networks different time frames. accordingly backpropagation need propagate error recurrent connections back time structure multimodal recurrent neural network shown figure m-rnn model much deeper simple model. layers time frame input word layer word embedding layers recurrent layer multimodal layer softmax layer). word embedding layers embed one-hot input dense word representation. several advantages. firstly signiﬁcantly lower number parameters networks dense word vector much smaller one-hot word vector. secondly dense word embedding encodes semantic meanings words semantically relevant words found calculating euclidean distance dense word vectors embedding layers. sentence-image multimodal models pre-computed word embedding vectors initialization model. contrast randomly initialize word embedding layers learn training data. show random initialization sufﬁcient architecture generate state-of-the-art results. treat activation word embedding layer ﬁnal word representation directly inputs multimodal layer. word embedding layers recurrent layer dimensions. calculation recurrent layer slightly different calculation simple rnn. instead concatenating word representation time recurrent layer activation time ﬁrst vector space together rectiﬁed linear unit inspired recent success training deep structure computer vision ﬁeld differs simple sigmoid function adopted relu faster harder saturate overﬁt data non-linear functions like sigmoid. backpropagation time conducted sigmoid function vanishing gradient problem appears since even simplest model large temporal depth. previous methods used heuristics truncated bptt avoid problem. truncated bptt stops bptt time steps hand-deﬁned hyperparameter. good properties relu need stop bptt early stage leads better efﬁcient utilization data truncated bptt. recurrent layer dimensional multimodal layer connect language model part image part m-rnn model language model part includes word embedding layer recurrent layer image part contains image feature extraction network. connect seventh layer alexnet multimodal layer framework image features. feature vector layer feature space together obtain feature vector multimodal layer training m-rnn model adopt cost function based perplexity sentences training given corresponding images. perplexity standard measure evaluating language model. perplexity word sequence calculated follows length word sequences denotes perplexity sentence given image probability generating word given previous words wn−. corresponds feature vector softmax layer model. cost function model average log-likelihood words given context words corresponding images training sentences plus regularization term. calculated perplexity training objective minimize cost function equivalent maximize probability model generate sentences training given corresponding images. cost function differentiable backpropagation learn model parameters. language modeling part mentioned above randomly initialize language modeling layers learn parameters. image part connect seventh layer pre-trained convolutional neural network features extracted seventh layer alexnet widely used previous multimodal methods recent multimodal retrieval work showed using rcnn object detection framework combined decaf features signiﬁcantly improves performance. experiments show method performs much better image features used better comparable results even sophisticated features based object detection. update alexnet according gradient backpropagated multimodal layer. paper image features deep network training stage shortage data future work apply method large datasets ﬁnetune parameters deep network training stage. sentence generation process straightforward. start start sign start arbitrary number reference words model calculate probability distribution next word sample probability distribution pick next word. practice selecting word maximum probability performs slightly better sampling. that input picked word model continue process model outputs sign end. retrieval tasks model calculate perplexity generating sentence given image. perplexity treated afﬁnity measurement sentences images. image retrieval task rank images based perplexity query sentence output ranked ones. test method three benchmark datasets sentence level annotations iapr flickr flickr iapr benchmark. dataset consists around images taken locations around world. includes images different sports actions people animals cities landscapes image provide least sentence annotation. average sentences annotations image. adopt publicly available separation training testing previous works images training images testing. flickrk benchmark. dataset consists images extracted flickr. image provides sentences annotations. grammar annotations dataset simpler iapr dataset. adopt standard separation training validation testing provided dataset. images training images validation images testing. flickrk benchmark. dataset recent extension flickrk. image also provides sentences annotations. consists crowd-sourced captions describing images. grammar style annotations dataset similar flickrk. follow previous work used images testing. dataset well flickk dataset commonly used image-sentence retrieval tasks. sentence generation. following previous works adopt sentence perplexity bleu scores evaluation metrics. bleu scores originally designed automatic machine translation rate quality translated sentences given several references sentences. treat sentence generation task translation content images sentences. bleu remains standard evaluation metric sentence generation methods images though drawbacks. images reference sentences might contains possible descriptions image bleu might penalize correctly generated sentences. conduct fair comparison adopt sentence generation steps experiment settings generate many words reference sentences calculate bleu. note model need know length reference sentence sign every training sentences stop generation process model outputs sign. sentence retrieval image retrieval flickrk flickrk datasets adopted evaluation metrics previous works tasks sentences retrieval image retrieval. used measurements recall rates ﬁrst retrieved groundtruth sentences images higher usually mean better retrieval performance. since care top-ranked retrieved results small important. another score used median rank ﬁrst retrieved groundtruth sentences images. lower usually means better performance. iapr datasets adopt exactly evaluation metrics plot mean number matches retrieved groundtruth sentences images respect percentage retrieved sentences images testing set. sentences retrieval task used shortlist images nearest neighbors query image feature space. shortlist strategy makes task harder similar images might similar descriptions often harder subtle differences among sentences pick suitable one. although published scores score dataset available best knowledge also report scores method future comparison. results sentence generation task shown table back-off n-grams methods katz backoff good-turing discounting ours-rnn-base serves baseline method m-rnn model. architecture m-rnn except input image features network. conduct fair comparison followed experimental settings include context length calculate bleu scores perplexity. evaluation metrics necessarily correlated following reasons. mentioned section perplexity calculated according conditional probability word sentence given previous reference words. therefore strong language model successfully captures distributions words sentences perplexity without image content. content generated sentences might unrelated images. table although baseline method generates perplexity bleu score high indicating failed generate sentences high quality. show m-rnn model performs much better baseline model terms perplexity bleu score. also outperforms state-of-the-art methods terms perplexity comparable result retrieval tasks mentioned section draw recall accuracy curve respect percentage retrieved images sentences figure sentence retrieval task used shortlist images three comparing methods shown ﬁrst method bowdecaf strong image based bag-of-words baseline. second third models multimodal deep models. m-rnn model signiﬁcantly outperforms three methods task. since publicly available results median rank dataset report scores method table future comparisons. result shows topranked retrieved images top-ranked retrieved sentences groundtruth. dataset widely used benchmark dataset image sentence retrieval. different methods shown table model outperforms state-of-theart methods large margin using image features also list performance methods using sophisticated features table -avg-rcnn denotes methods features average activation objects detection conﬁdence threshold. deepfe-rcnn uses fragment mapping strategy better exploit object detection results. results show using features improve performance. even without help object detection methods however method performs better methods evaluation metrics. develop framework using better image features future work. report results generated sentences table publicly available algorithm reported results dataset. compared m-rnn model ours-rnn-base model. m-rnn model performs much better baseline terms perplexity bleu scores. dataset dataset methods report retrieval results far. ﬁrst show evaluation metric table method outperforms state-of-theart methods evaluation metrics. results sentence generation task comparison baseline shown table propose multimodal recurrent neural network framework performs state-of-the-art three tasks sentence generation sentence retrieval given query image image gupta mannem. image annotation image description. iconip gupta verma jawahar. choosing linguistics vision describe images. aaai hodosh young hockenmaier. framing image description ranking task data models kiros zemel salakhutdinov. multimodal neural language models. icml krizhevsky sutskever hinton. imagenet classiﬁcation deep convolutional neural mitchell dodge mensch goyal berg yamaguchi berg stratos daum´e iii. midge generating image descriptions computer vision detections. eacl mnih hinton. three graphical models statistical language modelling. icml pages", "year": 2014}