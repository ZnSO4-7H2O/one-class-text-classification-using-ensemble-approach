{"title": "Max-Margin Invariant Features from Transformed Unlabeled Data", "tag": ["cs.LG", "cs.AI", "cs.CV"], "abstract": "The study of representations invariant to common transformations of the data is important to learning. Most techniques have focused on local approximate invariance implemented within expensive optimization frameworks lacking explicit theoretical guarantees. In this paper, we study kernels that are invariant to a unitary group while having theoretical guarantees in addressing the important practical issue of unavailability of transformed versions of labelled data. A problem we call the Unlabeled Transformation Problem which is a special form of semi-supervised learning and one-shot learning. We present a theoretically motivated alternate approach to the invariant kernel SVM based on which we propose Max-Margin Invariant Features (MMIF) to solve this problem. As an illustration, we design an framework for face recognition and demonstrate the efficacy of our approach on a large scale semi-synthetic dataset with 153,000 images and a new challenging protocol on Labelled Faces in the Wild (LFW) while out-performing strong baselines.", "text": "study representations invariant common transformations data important learning. techniques focused local approximate invariance implemented within expensive optimization frameworks lacking explicit theoretical guarantees. paper study kernels invariant unitary group theoretical guarantees addressing important practical issue unavailability transformed versions labelled data. problem call unlabeled transformation problem special form semisupervised learning one-shot learning. present theoretically motivated alternate approach invariant kernel based propose maxmargin invariant features solve problem. illustration design framework face recognition demonstrate efﬁcacy approach large scale semi-synthetic dataset images challenging protocol labelled faces wild out-performing strong baselines. becoming increasingly important learn well generalizing representations invariant indeed invariant intra-class many common nuisance transformations data. transformations discriminative between-class transformations said fundamental problems pattern recognition. nuisance transformations give rise many ‘degrees freedom’ even constrained task face recognition explicitly factoring leads improvements recognition performance found also shown features explicitly invariant intra-class transformations allow sample complexity recognition problem reduced study invariant representations machinery built concept explicit invariance important. invariance data augmentation. many approaches past enforced invariance generating transformed labelled training samples form perhaps popular method incorporating invariances svms virtual support method used sequential runs svms order augment support vectors transformed versions themselves. indecipherable transformations data leads shortage transformed labelled samples. approaches however assume explicit knowledge transformation. strong assumption. indeed general machine learning applications transformation figure max-margin invariant features solve important problem call unlabeled transformation problem. ﬁgure traditional classiﬁer \"learns\" invariance nuisance transformations directly labeled dataset hand approach incorporate additional invariance learned unlabeled data undergoes nuisance transformation interest. present data clear cannot modelled easily e.g. transformations different views general object different sentences articulated person. methods work generating invariance explicitly transforming augmenting labelled training data cannot applied scenarios. further cases know transformations exist actually model them difﬁcult generate transformed versions large labelled datasets. hence arises important problem train models invariant transformations test data access transformed labelled training samples availability unlabeled transformed data. although difﬁcult obtain generate transformed labelled data unlabeled transformed data readily available. instance different views speciﬁc objects interest available simply collect views general objects. also different sentences spoken speciﬁc group people available simply collect spoken members general population. scenarios explicit knowledge model transformation needed thereby bypassing problem indecipherable transformations. situation common vision e.g. unlabeled transformed images observed mostly addressed community intense efforts large scale data collection. note transformed data collected required labelled. position state central problem paper addresses. unlabeled transformation problem access transformed versions training unlabeled data labelled data learn discriminative model labelled data invariant transformations present unlabeled data overall approach. approach presented paper however solve problem learn invariance transformations observed unlabeled samples need labelled training data augmentation. explicitly simultaneously address problems generating invariance intra-class transformation discriminative inter class transformations given test sample ﬁnal extracted feature invariant transformations observed unlabeled thereby generalizes using single example. example one-shot learning. prior invariant kernels. kernel methods machine learning long studied considerable depth. nonetheless study invariant kernels techniques extract invariant features received much less attention. invariant kernel allows kernel product remain invariant transformations inputs. instances incorporating invariances focused local invariances regularization optimization techniques jittering kernels tangent-distance kernels sacriﬁced positive semi-deﬁnite property kernels computationally expensive. though methods success still lack explicit theoretical guarantees towards invariance. proposed invariant kernel formulation hand develops valid kernel guaranteed invariant. used group integration arrive invariant kernels address unlabeled transformation problem proposed kernels address. further proposed kernels allow formulation invariant application large scale problems. recently presented work invariant kernels. however unlike non-parametric formulation learn group transformations data assume known parametric transformations ideas. ideas paper twofold. ﬁrst model transformations using unitary groups leading unitarygroup invariant kernels. unitary transforms allow product preserved allow interesting generalization properties leading sample complexity also allow learning transformation invariance unlabeled examples classes learning problems vision often transformations belonging unitary-group would like invariant towards practice however found invariance much general transformations captured model achieved. secondly combine max-margin classiﬁers invariant kernels leading non-linear max-margin unitary-group invariant classiﬁers. theoretically motivated invariant non-linear svms form foundation upon max-margin invariant features based. mmif features effectively solve important unlabeled transformation problem. best knowledge ﬁrst theoretically proven formulation nature. contributions. contrast many previous studies invariant kernels study non-linear positive semi-deﬁnite unitary-group invariant kernels guaranteeing invariance address problem. central theoretical results applies group integration rkhs. builds observation that unitary restrictions kernel group action input space reciprocated rkhs. using proposed invariant kernel present theoretically motivated approach towards non-linear invariant solve problem explicit invariance guarantees. main theoretical contribution showcase result generalization max-margin classiﬁers group-invariant subspaces. propose max-margin invariant features learn highly discriminative non-linear features also solve problem. practical side propose approach face recognition combine mmifs pre-trained deep learning feature extractor mmif features used deep learning whenever need focus particular transformation data improve performance. unitary-group invariant kernels premise consider dataset normalized samples along labels {xi}y {yi} ...n {+−}. introduce dataset number unitary transformations part locally compact unitary-group note transformations consideration need entire unitary group. could well subgroup. augmented normalized dataset becomes {gxi clarity denote action group element i.e. also deﬁne orbit {gx} clearly invariant function deﬁned follows. deﬁnition group deﬁne function g-invariant method generating invariant towards group group integration. group integration stemmed classical invariant theory shown projection onto g-invariant subspace vector spaces. space thus representation invariant transformation element group ideal recognition problems would want discriminative between-class transformations invariant within-class transformations transformations model within-class transformations would like invariant towards. invariant group generated following basic known property based group integration. lemma given vector afﬁne group ﬁxed enjoy global invariance group property allows generate g-invariant subspace inherent space group integration. practice integral corresponds summation transformed samples. projection operator. further unitary sample complexity generalization. applying operator dataset points point g-invariant subspace thereby reducing number distinct points factor theoretically would drastically reduce sample complexity preserving linear feasibility trivial observe perfect linear separator learned would also perfect separator thus theory achieving perfect generalization. generalization refers ability perform correct classiﬁcation even presence transformations prove similar result reproducing kernel hilbert spaces section property theoretically powerful since cardinality large. classiﬁer avoid observe transformed versions {gx} generalize perfectly. case face recognition. illustration group transformations considered represents pose invariant subspace. theory poses subject converge point subspace leading near perfect pose invariant recognition. leveraged power unitary structure groups also critical generalization test cases would later. present central result showcasing unitary kernels allow unitary group action reciprocate reproducing kernel hilbert space. critical foundation core method called max-margin invariant features. group integration provides exact invariance seen previous section. however requires group structure preserved i.e. group structure destroyed group integration provide invariant function. context kernels imperative group relation samples preserved kernel hilbert space corresponding kernel mapping kernel unitary following sense possible. deﬁnition kernel unitary kernel unitary group mapping satisﬁes unitary condition fairly general common class unitary kernels kernel. deﬁne transformation within rkhs unitary group. following result signiﬁcance. theorem unitary kernel sense deﬁnition unitary transformation unitary-group theorem shows unitary-group structure preserved rkhs. paves theoretically motivated approaches achieve invariance transformations rkhs. studies group invariant kernels however examine whether unitary group structure actually preserved rkhs critical. also dikf recently proposed method utilizing group structure unitary kernel result generalization theorems present. theorem shows since unitary group structure preserved rkhs method involving group integration would invariant original space. preservation group structure allows direct group invariance results applied rkhs. also directly allows formulate non-linear guaranteeing invariance theoretically leading max-margin invariant features. apply group integration approach kernel svm. decision function svms written general form bias kernel feature i.e. reviewing maximum margin separator found minimizing loss functions hinge loss along regularizer. order invoke invariance utilize group integration kernel space using theorem points mapped given input space group integration results g-invariant subspace within using lemma introducing lagrange multipliers separator given yiαiψhφ thereby existing gh-invariant subspace within effectively observes samples therefore enjoys exact global invariance further ψhω∗ maximum-margin separator shown following result. theorem unitary group unitary kernel dgh) perfect separator {ψhφ} {ψhφ ψhω∗ also perfect separator margin. further max-margin separator {ψhφ} also max-margin separator {φ}. invariant non-linear objective observes samples form obtains max-margin separator ψhω∗. allows generalization properties max-margin classiﬁers combined group invariant classiﬁers. invariant nuisance transformations max-margin classiﬁers lead highly discriminative features experiments) invariant within-class transformations. theorem shows margins {ψhφ} deeply related implies max-margin separator datasets. theoretically invariant non-linear able generalize observing utilizing prior information form unitary kernels true practice linear kernels. non-linear kernels practice invariant still needs observe integrate transformed training inputs. leveraging unitary group properties. test time achieve invariance would require observe integrate possible transformations test sample. huge computational design bottleneck. would ideally want achieve invariance generalize observing single test sample effect perform shot learning. would computationally much cheaper make classiﬁer powerful owing generalization full transformed orbits test samples observing single sample. unitarity helps leverage form following lemma. assuming learned classiﬁer lemma shows test invariant product involves observing transformations equivalent quantity involves observing transformation hence model entire orbit single sample particular transformation including identity. drastically reduces sample complexity vastly increases generalization capabilities classiﬁer since need observe test sample achieve invariance lemma also helps saving computation allowing apply computationally expensive operation classiﬁer test sample. thus kernel invariant formulation replaced form ψhφ. kernels general gh-invariant subspace cannot explicitly computed since lies φdgh. important figure mmif feature extraction. denotes invariant kernel feature invariant transformation invariance generated group integration invariant kernel feature learns invariance form unlabeled transformed template also faces depicted actual samples large-scale mugshots data invariant features extracted labelled non-transformed dataset svms learned feature extractors. binary class trained invariant kernel feature random subset random class assignments. ﬁnal mmif feature concatenation inner-products note testing however formulation invariant transformations test sample regardless linear non-linear kernel. positive semi-deﬁniteness. g-invariant kernel form φdgh. preserves positive semi-deﬁnite property kernel guaranteeing global invariance unitary transformations. unlike jittering kernels tangent-distance kernels wish include invariance scaling however would lose positive-semi-deﬁniteness nonetheless show conditionally positive deﬁnite kernels still exist transformations including scaling although focus unitary transformations paper. previous section utilized group integration approach arrive theoretically invariant non-linear svm. however address unlabeled transformation problem i.e. kernel φdgh still requires observing transformed versions labelled input sample namely present core approach called max-margin invariant features require observation transformed labelled training sample whatsoever. assume access unlabeled templates {ti}i={...m}. assume observe transformations unitary-group i.e. access {gti g}i={...m}. also assume access {xj}i={...d} labelled data classes transformed. extract m-dimensional invariant kernel feature follows. invariant kernel feature explicitly show dependence dimension particular computed ﬁrst equality utilizes lemma third equality uses theorem equivalent observing transformations since using lemma thereby constructed feature invariant without ever needing observe transformed versions labelled vector brieﬂy training mmif feature extractor. matching metrics study normalized cosine distance. training mmif svms. learn k-dimensional mmif feature learn independent binary-class linear svms. trains labelled dataset ...d}} sample label subset classes rest labelled leads classiﬁer form yjαjl. here label svm. important note unlabeled data used extract multiple classes randomly labelled positive allows extract feature common them. increases generalization forcing extracted feature general rather highly tuned single class. k-dimensional mmif feature trained technique leading higher dimensional feature vector useful case limited labelled samples classes feature extraction inner products test sample distinct binary-class svms provides k-dimensional mmif feature vector. feature vector highly discriminative max-margin nature svms invariant invariant kernels. mmif. given mmif feature deﬁned mmif) test yjαjl further dimension ψhφ. process illustrated fig. inheriting transformation invariance transformed unlabeled data special case semisupervised learning. mmif features learn invariant transformations observing transfer invariance knowledge unseen samples thereby becoming invariant despite never observed samples special case semi-supervised learning leverage speciﬁc transformations present unlabeled data. useful property mmifs allowing learn transformation invariance source sample points another source powerful discrimination generalization properties. property formally stated following theorem. theorem mmif) mmif) ∀x∀g observed {gti g}i={...m}. thus mmif solve unlabeled transformation problem. mmifs invariant discriminative component. invariant component mmif allows generalize transformations test sample whereas discriminative component allows robust classiﬁcation max-margin classiﬁers. properties allow mmifs useful experiments face recognition. mean pooling mmif. group integration practice directly results mean pooling. recent work however showed group integration treated subset i-theory tries measure moments distribution since distribution also invariant group integration seen measuring mean ﬁrst moment distribution. also characterize using inﬁnite moment distribution. experiments pooling outperforms mean pooling general. results paper however still hold i-theory framework. mmif external feature extractors mmif make assumptions regarding input hence apply features extracted feature extractor general. goal feature extractor invariant within-class transformation maximizing between-class discrimination. however feature extractors trained explicitly factor speciﬁc transformations. access even small dataset transformation would like invariant transfer invariance using mmifs modelling general non-unitary transformations. general non-linear transformations out-of-plane rotation pose variation challenging model. nonetheless small variation transformations approximated unitary assuming piece wise linearity transformation-dependent sub-manifold unfolding further found practice integrating general transformations produced approximate invariance figure pose-invariant face recognition results semi-synthetic large-scale mugshot database operating pixels mmif outperforms invariance based methods dikf invariant operating deep features mmif trained vgg-face features produces signiﬁcant improvement performance. numbers brackets represent far. face recognition results vgg-face features mmif trained vgg-face features. values bracket show far. illustration apply mmifs using modalities overall pixels deep features pre-trained vgg-face network provide implementation details results discussion supplementary. mmif large-scale semi-synthetic mugshot database utilize large-scale semi-synthetic face dataset generate sets mmif. dataset major transformations exist pose variation subject variation. transformations illumination translation rotation strictly synthetically controlled. provides good benchmark face recognition. want invariant pose variation discriminative subject variation. experiment follows exact protocol data described test subjects identities pose varied real-textured gray-scale image resulting billion pair-wise comparisons results reported curves along far. fig. shows curves experiment. mmif features out-performs baselines including vgg-face features dikf approaches thereby demonstrating superior discriminability able effectively capture pose-invariance transformed template mmif able solve unlabeled transformation problem extracting transformation information unlabeled mmif unseen subject protocol. order able effectively train scenario general transformations challenge algorithms deﬁne much harder protocol lfw. choose subjects total images training mmif vgg-face features test remaining subjects images. perform versus matching totalling upto million matches evaluation metric deﬁned standard curve veriﬁcation rate reported false accept rate. split subjects sets alignment experiment faces cropped according fig. shows results experiment. mmif features signiﬁcantly outperforms protocol boosting demonstrates mmif able generate invariance highly non-linear transformations well-deﬁned rendering useful real-world scenarios transformations unknown observable. provide details supplementary. also note need utilize identity information required fact pose varied images belong subject. data obtained temporal sampling. mmif large-scale semi-synthetic mugshot database mmif template utilize large-scale semi-synthetic face dataset generate sets mmif. face textures sampled real-faces although poses rendered using model face independently hence dataset semi-synthetic. semi-synthetic dataset helps evaluate algorithm clean setting exists challenging nuisance transformation therefore models pose variation faces. utilize pose variation dataset generation procedure described order fair comparison. poses rendered varying steps using d-gem total number images generate images. align faces eye-center locations crop. protocol. ﬁrst experiment direct comparison approaches similar spirit ours namely ∞-dikf -dikf ndp-∞ ndp- train subjects test method remaining subjects matching pose-varied images subject other. dikf follows protocol mmif utilize ﬁrst images next images total svms trained subsets note although case contains pose variation integrate generate invariance. explicit invariance properties generated integration testing compare images remaining unseen subjects algorithms therefore tested billion pair wise comparisons. results reported curves along far. experiment report results working pixels directly dimensional features pre-trained vgg-face network baseline also report results using vgg-face features directly. results. fig. shows curves experiment. mmif features out-perform dikf approaches thereby demonstrating superior discriminability able effectively capture pose-invariance transformed template vgg-face features suffer handicap images grayscale. nonetheless mmif able transfer pose-invariance onto features. signiﬁcantly boosts performance owing fact main nuisance transformation pose. mmif explicitly pose invariant along solving unlabeled transformation problem able help features preserving discriminability features. fact max-margin svms discriminability. illustrates clean setting mmif able work well conjunction deep learning features thereby rendering immediately usable realistic settings. next experiments focus exact aspect. mmif unseen subject protocol. received attention recent years algorithms approached near human accuracy original testing protocol. order able effectively train scenario general transformations challenge algorithms deﬁne much harder protocol lfw. instead evaluating pair wise matches pair wise match images subjects seen training. modelling subjects whatsoever making difﬁcult task. utilize subjects images training test remaining subjects images. maximum amount data training pick subjects number images available test data thus contains images. number test pairwise matches million four orders magnitude larger matches original testing protocol deﬁned. evaluation metric deﬁned standard curve veriﬁcation rate reported false accept rate. mmif template split subjects data parts subjects each. subjects number images transformed template rest subjects note experiment transformations considered generic highly non-linear making difﬁcult experiment. alignment experiment faces cropped according protocol. mmif process kernel features transformed template exactly previous experiment similarly learn total svms subsets following protocol previous experiment. results. fig. shows results experiment. mmif features signiﬁcantly outperforms protocol boosting suggests mmif used conjunction pre-trained deep features. experiment mmif capitalizes non-linear transformations exist whereas previous experiment semisynthetic dataset transformation well-deﬁned pose variation. demonstrates mmif able generate invariance highly non-linear transformations well-deﬁned rendering useful real-world scenarios transformations unknown observable. large-scale semi synthetic mugshot data motivation main paper transformations observed unlabeled meant provide labeled untransformed data. however expeirments main paper even though explicitly pool transformations utilize transformations training svms. order closer theoretical setting mmif pixels vgg-face features constraining number images svms train random images subject. mmif template utilize large scale semi-synthetic face dataset generate template mmif. face textures sampled real faces poses rendered using model face independently making dataset semisynthetic. semi-synthetic dataset helps evaluate algorithm clean setting exists challenging nuisance transformation therefore models pose variation faces. utilize pose variation dataset generation procedure described order fair comparison. poses rendered varying steps using d-gem total number images generate images. align faces eye-center locations crop. unlike experiment presented main paper dataset template constrained include randomly selected poses contained done better simulate real-world setting would observe faces random poses. protocol experiment direct comparison approaches similar spirit ours namely l∞-dikf l-dikf ndp-l∞ ndp-l call setting mmif mmif-cons reference. train subjects test method remaining subjects matching pose-varied images subject other. dikf follows protocol mmif utilize ﬁrst images template thus remains exactly protocol main paper. template generated choosing random poses next subjects. total svms trained random subset subjects labeled rest labeled figure pose-invariant face recognition results semi-synthetic large-scale mugshot database operating deep features mmif-cons-vgg trained vgg-face features produces signiﬁcant improvement performance pure features even though utilizes constrained set. interestingly mmif-cons-vgg almost matches performance mmif-vgg using less data. numbers brackets represent far. mmif-cons trained entire random transformations subject it’s important note since contain transformations observed entirety explicit invariance properties generated integration testing follow protocol main paper. compare images remaining unseen subjects algorithms therefore tested billion pair wise comparisons. results reported curves along far. experiment report results working pixels directly dimensional features pre-trained vgg-face network baseline also report results using vgg-face features directly. results fig. shows curves experiment. even though train svms mmif-cons-vgg constrained version outperforms features. although observe mmif-cons-raw outperforms methods thereby demonstrating superior discriminability fails match original mmif-raw method performance. interestingly however mmif-cons-vgg matches mmif-vgg features performance despite trained much lesser data thus mmif trained good feature extractor provide added beneﬁts discrimination despite lesser labeled samples train experiment explore number svms inﬂuences recognition performance large scale real-world dataset namely iarpa janus benchmark dataset. data work veriﬁcation protocol original dataset ijb-a janus. subset consists image templates distinct subjects template containing multiple images. images cropped respect bounding boxes speciﬁed dataset labeled images. cropped images re-sized pixels accordance requirements face model. explicit pose invariance applied general face descriptors. mmif template order effectively train scenario general transformations deﬁne protocol janus dataset similar protocol deﬁned main paper. protocol suited mmif since explicitly generate invariance transformations exist janus data. utilize ﬁrst subjects templates subjects training mmif test remaining subjects make maximum amount data training pick subjects number images rest utilized testing. training dataset split templates similar protocol main paper. ﬁrst subjects rest order maximize transformations generate invariance towards. showcase ability mmif used conjunction deep learning techniques similar experiment main paper train test vgg-face features janus data. protocol experiment split training data templates similarly mmif protocols paper train total svm’s subsets following protocol. perform pairwise comparisons entirety test data exceeds number comparisons deﬁned original testing protocol thereby making protocol much larger harder. recall throughout supplementary main paper always test completely unseen subjects. evaluation metric deﬁned standard curve using cosine distance. results fig. shows curves experiment much larger harder protocol. even svms max-margin feature extractors performance close feature extractors. suggests though svms provide enough discrimination invariant kernel provides bulk recognition performance explicitly invariant transformations hence proposed invariant kernel effective learning invariance towards transformations present unlabeled dataset. provide curves baselines future work focusing problem learning unlabeled transformations given dataset. proof theorem proof. since kernel unitary. deﬁne action thus mapping preserves dot-product reciprocating action requirements unitary operator however needs linear. note linearity derived linearity inner product preservation speciﬁcally arbitrary vector scalar ghφx) since therefore deﬁnition. also thus closure established. associativity identity inverse properties proved similarly. therefore unitary-group second equality group element since inner-product invariant using argument true using lemma fact unitary. further ﬁnal equality utilizes fact haar measure normalized. here line utilize closure property group line utilizes fact unitary ﬁnally line uses theorem hence every element invariant observed thus trivially mmif) mmifx) observed", "year": 2017}