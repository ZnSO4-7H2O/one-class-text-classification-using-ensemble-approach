{"title": "Efficient On-the-fly Category Retrieval using ConvNets and GPUs", "tag": ["cs.CV", "cs.LG", "cs.NE"], "abstract": "We investigate the gains in precision and speed, that can be obtained by using Convolutional Networks (ConvNets) for on-the-fly retrieval - where classifiers are learnt at run time for a textual query from downloaded images, and used to rank large image or video datasets.  We make three contributions: (i) we present an evaluation of state-of-the-art image representations for object category retrieval over standard benchmark datasets containing 1M+ images; (ii) we show that ConvNets can be used to obtain features which are incredibly performant, and yet much lower dimensional than previous state-of-the-art image representations, and that their dimensionality can be reduced further without loss in performance by compression using product quantization or binarization. Consequently, features with the state-of-the-art performance on large-scale datasets of millions of images can fit in the memory of even a commodity GPU card; (iii) we show that an SVM classifier can be learnt within a ConvNet framework on a GPU in parallel with downloading the new training images, allowing for a continuous refinement of the model as more images become available, and simultaneous training and ranking. The outcome is an on-the-fly system that significantly outperforms its predecessors in terms of: precision of retrieval, memory requirements, and speed, facilitating accurate on-the-fly learning and ranking in under a second on a single GPU.", "text": "abstract—we investigate gains precision speed obtained using convolutional networks on-the-ﬂy retrieval classiﬁers learnt time textual query downloaded images used rank large image video datasets. make three contributions present evaluation state-of-the-art image representations object category retrieval standard benchmark datasets containing images; show convnets used obtain features incredibly performant much lower dimensional previous state-of-the-art image representations dimensionality reduced without loss performance compression using product quantization binarization. consequently features state-of-the-art performance large-scale datasets millions images memory even commodity card; show classiﬁer learnt within convnet framework parallel downloading training images allowing continuous reﬁnement model images become available simultaneous training ranking. outcome on-the-ﬂy system signiﬁcantly outperforms predecessors terms precision retrieval memory requirements speed facilitating accurate on-the-ﬂy learning ranking second single gpu. ‘closed world’ problem computer vision object category recognition systems restricted pre-deﬁned classes occur carefully curated datasets available training example imagenet object categories ucf- human actions videos. more offers tantalising prospect developing large-scale general purpose object category retrieval systems operate millions images seconds possible speciﬁc instance retrieval systems reached point commercialisation products google goggles kooaba amazon’s snaptell. current on-the-ﬂy systems typically proceed three stages ﬁrst training data user query compiled commonly bootstrapping process text-to-image search using e.g. google image search source training images; second classiﬁer ranker learnt category; third images/videos dataset ranked order retrieve containing category. stages happen onlearning retrievalperformance/memory/speed off. particular high-dimensional feature vectors state-of-the-art classiﬁcation required performance incurred severe memory penalty also severe speed penalty training ranking. despite excellent progress compression methods nearest neighbour search using product quantization binary encoding compromises still made. paper show context onthe-ﬂy category retrieval convolutional networks training signiﬁcantly improve three retrieval precision memory requirements ranking speed. whole pipeline computing training image features learning model scoring ranking dataset images implemented runs highly-parallel online terms retrieval performance build recent research shows deep convnet features signiﬁcantly outperform shallow features fisher vectors image classiﬁcation task however contributions simply using convnet features on-the-ﬂy architecture take full advantage computation retrieval stages parallel downloading training images cpu. novel gpu-based architecture allows time budget trained available images within time limit used rank dataset images stage process architecture strong contrast standard on-the-ﬂy architectures training begins training images downloaded processed ranking follows that. start conducting comprehensive evaluation performance convnet-based image features category-based image retrieval. given lack evaluation data suitable assessment large-scale retrieval performance compose taking standard medium-scale object category recognition benchmark optionally adding large number distractor images take dataset size images. evaluate datasets variation training data either using training images using images google image search full details given section goal ranking millions images conventional gpu-equipped investigate section retrieval performance affected using low-dimensional features scenarios. low-dimensional features advantages less memory scalar products faster training ranking. cover spectrum methods achieving lowdimensional descriptor namely reducing dimensionality last convnet layer; product quantization convnet features binarization convnet features. shown combination low-dimensional ﬁnal convnet feature layer product quantization produces features highly-compact incredibly performant. finally based investigations propose architecture on-the-ﬂy object category retrieval section highly scalable capable adapting varying query complexity running single commodity gpu. section describes evaluation protocol used assess performance image representations described section onthe-ﬂy training architecture introduced section begin describing datasets used evaluation describe three different scenarios datasets used subsequent scenario moving closer modelling conditions experienced real-world large-scale object category retrieval system. difﬁculty evaluating large-scale object category retrieval system lack large-scale datasets sufﬁcient annotation assess retrieval performance fully particular measure recall. pascal dataset provides full annotation twenty common object classes facilitating evaluation using common ranking performance measures mean average precision much small evaluate performance real-world system. conversely ilsvrc dataset much larger complete annotation object categories image. therefore ranking performance cannot measured without annotation object category classiﬁcation metrics accurately reﬂect performance object category retrieval scenario used. additionally work imagenet ilsvrc- dataset pre-train convnet also assessing retrieval performance. result evaluation paper custom combination datasets carefully tailored representative data could expected typical collection web-based consumer photographs mirflickr-m used augment data pascal test later experiments comprises unannotated images dataset represents snapshot images taken popularity image sharing site flickr thus representative typical web-based consumer photography imagenet although also sourced flickr collected queries often speciﬁc terms wordnet. addition mirflickr-m conﬁrmed contain many images twenty pascal classes. evaluation protocol linear trained classes used rank images target dataset. interested evaluating performance within object category retrieval setting measuring ‘goodness’ ﬁrst pages retrieved results critical. therefore evaluate using precision basis larger proportion true positives given object category ranked list better perceived performance. adopting evaluation protocol also advantage able images mirflickr-m dataset despite fact full annotations provided. since need consider ranked list class evaluation take take ‘lazy’ approach annotating mirflickr-m dataset annotating class instances ranked list necessary generate complete annotation top-k results avoids generate full annotation images. fig. data subsets used evaluation. using example object category ‘dog’ ranked lists used evaluation scenarios compiled combining pascal data lazily annotated data mirflickr-m dataset. scenario test using images pascal test addition entirety mirflickr-m dataset. class remove positive class occurrences ranked list retrieved mirflickr-m dataset using lazy annotation described section purpose scenario test features perform attempting retrieve small known number class occurrences large number scenario time exclude images pascal dataset instead evaluate precision solely mirflickr-m dataset lazily annotating retrieved ranked lists case before. purpose scenario test features perform realworld dataset unknown statistics. practice easier scenario scenario since mirflickr-m dataset contains many instances pascal classes. scenario google training. testing scenario instead using pascal data training query issued google image search pascal classes images used case training data. scenario assesses tolerance training images prevalence pascal classes ‘people’ ‘cats’ ‘birds’ mirflickr-m data explains exclude them restricting annotation classes reasonable levels proved impossible. differ mirflickr-m test images google images noisy typically contain object centre. also mirrors closely real-world on-the-ﬂy object category retrieval setting queries practice need limited pascal classes. sub-scenarios different data used negative training samples case scenario images downloaded google image search classes except current class used negative training data scenario ﬁxed pool negative training images used. training images sourced issuing queries ﬁxed ‘negative’ query terms google bing image search attempting download ﬁrst results case. pool negative training data also used section dataset ground truth preparation described section combination pascal dataset mirflickrm dataset evaluation. mirflickrm come annotation apart noisy ﬂickr image tags annotations twenty pascal classes. despite dataset containing images away annotating less number given chosen evaluation metric precision requires ground truth ﬁrst items ranked list target class compute. therefore adopt ‘lazy’ approach annotation using result ranked lists starting point. miscellanea random selection photo random selection random objects random things nothing particular photos stuff random photos random stuff things annotations make particular method/scenario stored images need annotated different methods. developed web-based annotation tool facilitate processwhich allows positive annotations class shared across methods scenarios. total images mirflickrm dataset annotated average annotations class. annotations made publicly available. retrieval performance image representations section perform evaluation recent state-of-the-art image representations object category retrieval scenarios described section convnet-based features form basis on-the-ﬂy system described section shown perform excellently standard image classiﬁcation benchmarks pascal imagenet ilsvrc therefore focus evaluation features employing -dimensional ‘cnn image features baseline. compare traditional shallow feature encoding form improved fisher vector implementation details convnets given section explore effects reducing dimensionality features retrieval performance using following methods lower-dimensional convnet output layer reducing dimensionality convnet features consists retraining network last fully-connected layer lower dimensionality. following consider ‘cnn network conﬁguration -dimensional feature layer. using network place baseline ‘cnn seen discriminative dimensionality reduction factor product quantization widely used compression method image features works splitting original feature q-dimensional sub-blocks encoded using separate vocabulary cluster centres pre-learned training set. much higher dimensional taking much longer compute compared cnn- method nonetheless even challenging classes ‘sheep’ manages pull true positives ranked list. however relative performance drop rank much sharper convnetbased methods. bursty images comparing top-ranked negatives method ‘sheep’ cnn- method seen appears mistakenly rank highly ‘bursty’ images comprising repeating patterns textures. phenomenon particularly evident natural outdoor scenes explains performance drop particularly severe ‘sheep’ ‘cow’ ‘horses’ classes appears convnet-based features much robust textured images although heavy compression starts show deterioration consequence retrieval smaller number similarly ‘bursty’ images. diversity diversity retrieved results also much greater convnet-based representations indicating classiﬁer able make better generalisations using features. example seen figure whereas four retrieved results query ‘motorbike’ method show rider similar pose racing bike race track four retrieved results cnn- method depict variety different motorcycles several different angles. part compression convnet features appear reduce diversity appreciably top-ranked results convnet methods whether compressed appearing exhibit similar diversity results. compression mentioned above drop performance moving convnet-based features much greater incurred compression methods seems strongly connected robustness convnet-based features whether compressed kind ‘bursty’ textured images susceptible remarkable given comparing size largest uncompressed convnet representation cnn- smallest pq-compressed cnn--pq size difference. case binarization performed using tight frame expansion method recently successfully applied local patch face descriptors binarization zero-centred descriptors binary codes performed follows scenario pascal dataset pose major challenges features surprising given close decade research representations perform well dataset. even challenging classes produces fairly good results images true positives images true positives case -dimensional convnet features scenario adding mirflickr-m dataset signiﬁcant impact results task retrieve true positives constitute less dataset. challenging scenario setting superior performance convnet-based features compared state-of-the-art shallow representation much clearer see. sample precision-rank curves queries particularly challenging another less shown figure make following observations cnn--bin-k method mprec actually increases marginally compared non-compressed codes which visually inspecting rankings explained additional robustness brought compression. features also signiﬁcantly sped-up using hardware-accelerated hamming distance computation. nonetheless binary features requires different ranking model application left future work. fact convnet features sparse representation typically zeros reason amenable compression possible compression methods geared speciﬁcally capitalise scenario given mirflickr-m dataset contains many instances pascal classes moving testing solely mirflickr leads jump performance results across methods. nonetheless scenario provides closer representation performance real-world on-the-ﬂy object category retrieval system given scenario switching noisy training images google rather pre-curated pascal training images expected results small drop across board methods. however precision ranking remains subjectively good. nonetheless shown figure actual images returned dataset different reﬂects differences training data sourced google image search versus curated dataset. example query ‘chair’ returns predominantly indoor scenes regular dining-table chairs using training data avant-garde modern designs generally centred frame using google training data. scenario scenario switch using ﬁxed pool negative data sourced ‘negative’ queries seen improves results result larger negative training pool size given assumed lack coverage ﬁxed negative image pool suggests certain extent lack diversity made using larger number negative training images. convnet training computation framework based publicly available caffe toolbox convnet conﬁgurations considered paper pre-trained imagenet ilsvrc- dataset using conﬁgurations described namely contain convolutional fullyconnected layers interleaved rectiﬁcation nonlinearities max-pooling. stack layers followed -way soft-max classiﬁer removed pre-training ﬁnished difference convnets dimensionality second fully-connected layer ‘cnn ‘cnn order provide similar setup on-theﬂy architecture section uses linear predictor learnt using hinge loss quadratic regulariser learning stage standard linear support vector machine implementation. parameter determined using validation scenario ﬁxed experiments. implementation details implementation convnet image representations follows detail computation setting corresponds dense rootsift features spatial exten√ sion extracted pixel step scales scaling factor); improved fisher vector using codebook on-the-fly architecture evaluated various image representations sect. describe architecture object category retrieval system fully exploits advantages convnet image representations. user experience point view main requirement system instant response fig. architecture on-the-ﬂy object category retrieval system. entire framework aside image downloader resident data stored memory outlined green. operation split stages iterative training initiated user text query periodic model testing obtain ranking target dataset ﬁrst ranking repository images obtained immediately potential improvement time. dictates following design choice downloading training images internet carried parallel training model already downloaded images on-line fashion. result point time current model used perform ranking dataset images. approach work however image representation satisfy following requirements highly discriminative even handful training samples sufﬁcient learn linear ranking model; fast-to-compute maximise amount training data processed within allocated time budget; memory footprint allow storing large-scale datasets main memory ranking efﬁciently. demonstrated sect. convnet image representation perfect match requirements. indeed pre-training large image collection leads highly discriminative representation even training samples sufﬁcient training accurate linear model; convnet features computed quickly highly-parallel hardware; dimensionality instantly scored using linear model gpu. on-the-ﬂy architecture illustrated fig. divided cpu-based front-end gpu-based back-end continually trains ranking model downloaded images periodically applies repository. category retrieval carried follows. off-line allow fast processing convnet features target dataset images pre-computed off-line using architecture. also prepare ﬁxed negative image pool queries issuing negative pool queries bing google image search downloading returned urls. negative image feature features also pre-computed. memory requirements storing pre-computed features follows mirflickr-m dataset pool negative features. thus feasible permanently store features negative dataset images high-speed memory even without compression kind noted section convnet features compressed using product quantization without signiﬁcant degradation performance making datasets images storable memory setting aside storage model multiple gpus used. many recent laptops ﬁtted containing similar amounts memory making system theoretically runnable single laptop. furthermore whilst storing target repository preferable terms ranking time case datasets images placed memory typically larger capacity. on-line given textual query provided user front-end starts downloading relevant images used positive samples queried category back-end. regular time intervals front-end receives ranked list dataset images back-end displays user interface. on-line back-end runs parallel front-end responsible training ranking model applying dataset. training l-regularised linear model carried using mini-batch pegasos updates iteration learning rate l-norm regularisation constant experiments. batch contains equal amount positive negative samples; total batch size experiments. training commences soon ﬁrst positive image downloaded received front-end random crops taken iteration pool positive training images downloaded far. front-end meantime continue downloading images internet constantly increasing size positive image pool diversity extracted crops. note positive image features need computed on-the-ﬂy quick case convnets. ranking takes place using current model every seconds mentioned above pre-computed dataset features pre-stored scores images computed scores ranked list top-ranked images passed front-end displayed user. components back-end implemented within framework derived caffe system performance order evaluate real-world performance system queries several pascal classes tracked performance evolved time. simulate latency introduced downloading images internet limited rate positive images entering network images/second images sampled randomly top- image urls returned google image search. results experiments four classes shown figure even challenging pascal classes ‘sheep’ ‘softa’ performance converged ﬁnal value seconds seen evolving ranking time-step ordering ranking generally stabilizes within second showing good diversity results. easier classes ‘aeroplane’ convergence stabilization occurs even faster. real terms results typical query time on-the-ﬂy architecture entering text query viewing ranked retrieved images seconds often less complete convergence stabilization results. however advantages proposed architecture adaptable differing query complexity return good results early whilst still continuing train background necessary exposing classiﬁer expanding pool training data downloaded updating ranked list on-the-ﬂy. fig. precision training time four queries using on-the-ﬂy architecture. number images dynamically expanding positive image training pool time also marked plot. top- returned images ‘sheep’ query ﬁrst four time-steps shown right. false positives outlined images top- time step outlined blue. even moderately challenging query model settles second. images network supplement described challenging classes ‘sheep’ ‘sofa’. motivation determine role size positive training image pool performance system. note experimental setup slightly different previous section inputting training image system waited output classiﬁer stabilize. analyse impact class turn referring figure considering ﬁrst ‘sheep’ class single training image ﬁnal performance reached ranked list contains many sheep. however highly ranked images horned sheep suggestive bias introduced training single image. number training images increased topranked images become much diverse translating ﬁnal small jump performance third training image network. ‘sofa’ class provides example architecture deals challenging query larger degree intra-class appearance variation. case single training image clearly sufﬁce ranked list returned single training image performance close random sofas retrieved. however quickly changes second image network true positives entering following exposure retrieved images greatly improved mostly cases dataset true positives introduced introduction third fourth training images high initial position mean change ranking position suggesting coarse model trained relatively images improvements time predominantly effect tail ranked list. suggests even initially small number training images available user interface head ranked list presented user almost immediately whilst training continues background reﬁne tail ranked results possible. restriction apply case since mentioned section general training images available within seconds launching query. novel on-the-ﬂy queries although experimental results thusfar presented pascal classes advantage on-the-ﬂy architecture limitation imposed object categories queried classiﬁer trained demand present additional selected results on-the-ﬂy system figure using setup scenario fig. evolution performance increasing number positive training images. results presented queries presented section paper. shows performance number true positives entering ranking number training images increases shows minimum initial ranking position true positives shows head ranked list n=.. images added shows mean change ranking position images query terms disjunct twenty pascal classes test performance novel on-the-ﬂy queries. seen architecture much generalisable query terms outside pascal category hierarchy. queries ‘lion’ particularly challenging shallow feature representations fisher kernel repeating thick pattern bushes present many training images retrieving large number bursty images described section however convnet-based features appear much robust effect precision architecture also capable returning abstract concepts ‘cityscape’ ‘forest’ addition concrete objects ‘cake’ ‘truck’ finally even querying mirflickrm relatively obscure ‘capybara’ returned false positives within tight conﬁguration classes similar appearance course composition mirflickrm dataset unknown could images ‘capybara’ dataset. paper presented system on-the-ﬂy object category retrieval builds upon recent advances deep convolutional image representations. demonstrated representations efﬁciently compressed used novel incremental learning architecture capable retrieval across datasets images within seconds running entirely single gpu. larger datasets multiple cards could employed ranking classiﬁer learnt gpu. along investigation diversity ranked results changes time subject future work. zisserman pascal visual object classes challenge ijcv vol. huiskes ﬂickr retrieval evaluation proceedings international conference multimedia information retrieval huiskes thomee trends ideas visual concept detection ﬂickr retrieval evaluation initiative proceedings international conference multimedia information retrieval soomro zamir shah dataset human actions classes videos wild corr vol. abs/. sivic zisserman video google text retrieval approach object matching videos proc. iccv vol.", "year": 2014}