{"title": "A Multi-Modal Approach to Infer Image Affect", "tag": ["cs.CV", "cs.LG", "stat.ML"], "abstract": "The group affect or emotion in an image of people can be inferred by extracting features about both the people in the picture and the overall makeup of the scene. The state-of-the-art on this problem investigates a combination of facial features, scene extraction and even audio tonality. This paper combines three additional modalities, namely, human pose, text-based tagging and CNN extracted features / predictions. To the best of our knowledge, this is the first time all of the modalities were extracted using deep neural networks. We evaluate the performance of our approach against baselines and identify insights throughout this paper.", "text": "abstract group aect emotion image people inferred extracting features people picture overall makeup scene. state-of-the-art problem investigates combination facial features scene extraction even audio tonality. paper combines three additional modalities namely human pose text-based tagging extracted features predictions. best knowledge time modalities extracted using deep neural networks. evaluate performance approach baselines identify insights throughout paper. keywords group aect scene extraction pose extraction facial feature extraction centrist feature aggregation gaussian mixture model convolutional neural networks deep learning image captions introduction using machine learning infer emotion group people image video potential enhance understanding social interactions improve civil life. using modern computer vision techniques image retrieval made intuitive doctors able beer diagnose psychological disorders security able beer respond social unrest escalates violence. currently even highly skilled professionals dicult time recognizing categorizing exact emotional state group. consistent automatic categorization aect image achieved latest advances machine learning coupled precise feature extraction fusion. inferring overall emotion image elicits viewer requires understanding details vastly diering scales image. traditional approaches problem focused small-scale features namely investigating emotion individual faces however large-scale features additional action/scene recognition must represented description image emotion feature extraction methods modalities cannot capture full emotion image itself. previous research investigated combination facial features scene extraction even audio tonality paper combines three additional modalities commonly used facial scene modalities namely human pose text-based tagging extracted features predictions. best knowledge time modalities extracted using deep neural networks exception baseline census transform histogram model. approach combines top-down boom-up features. presence multiple subjects image problem needs resolved combine individual human emotions group level emotion. next step combine multiple group level modalities. address problem using bagof-visual-words based approach. based approach comprises developing code book using well known clustering algorithms k-means clustering gaussian mixture model based clustering. code books clustering algorithms used fuse individual subjects’ features group image level features evaluate performance individual features using different classication algorithms namely random forests extra trees gradient boosted trees svm. additionally predictions classiers used create ensemble classiers obtain classication results. developing ensemble model also employ predictions individually trained convolutional neural network model using group level images. modalities facial feature extraction facial features extracted individually isolated human images image-by-image basis. first faster r-cnn employed extract full human frames image. extracted frames used pose estimation facial feature extraction. face extracted aligned frontal view using deepface faces isolated pre-processed deep residual network employed extract facial features. human frame extraction. isolation signicant human frame performed image using faster r-cnn model trained pascal data using deep vgg- model procedure building training model presented original faster r-cnn manuscript detailed here. deepface. extracting aligning human faces images facebook’s deepface algorithm utilized. alignment performed using explicit facial modeling coupled -layer deep neural network. details implementation training model please validation set. face labeled following emotions anger disgust fear happiness sadness surprise neutral. balance training time ecacy resnet- topology implemented. resnet model trained scratch initial learning rate learning rate decay factor decays every epochs batch size network architecture able achieve top- accuracy validation predicting emotion image. lieu fully connected layer resnet- uses global average pooling penultimate layer. feature vector elements output global average pooling layer running inference isolated faces image. centrist census transform histogram visual descriptor predominantly used describe topological places scenes image census transform essence calculated comparing pixel’s gray-scale intensity eight neighboring pixels encoding results -bit binary codeword converting codeword decimal centrist turn histogram census transform calculated various rectangular sections image spatial pyramid techniques construction centrist expected capture high-level global features image background relative locations persons etc. centrist adopted challenge organizers baseline algorithm emotion detection. baseline accuracy provided organizers validation test set. achieve accuracies support vector regression model trained using features extracted centrist. work centrist scene-level descriptor build various modalities extract complementary features image. human pose intention including pose modality emotion detection task detect similar dissimilar poses individuals image capture eect poses towards group emotion. pose features expected work indirect complement features modalities. human pose estimation regression problem location specic points human body predicted. literature several neural network non-neural network methods used. state results pascal demonstrated gkioxari et.al. work utilize work presented based r-cnn. method obtained mean pascal validation dataset. method uses alexnet builds r-cnn region proposals generated tune imagenet pertained model classes. r-cnn work trained predict points within distance ground truth. test time embeddings used features combine modalities. clarifai. modalities used model generate captions images captions infer emotion. step towards that proceeded commercially available clarifai answer following preliminary questions whether reasonably accurate captions could generated whether captions descriptive underlying emotions fig. illustrates four tags generated clarifai images emotiw training dataset. results along generated several images dataset provide condence deep learning model reasonably accurate generating tags images thus answering question above. second question refer fig. here distribution tags generated clarifai across three emotion classes ploed. note that several tags ‘administration’ ‘election’ ‘competition’ notable difference prior probability occurrence given class. could translate discriminative probability classes given tags assuming uniform prior classes. observation even pronounced obvious tags ‘festival’ ‘bale’. answers second question above motivates explore further. imtxt. motivated image tags value inferring emotions group-level image turned aention general ‘image caption’ models. towards this focused imtxt tensorflow open-source model model combined techniques computer vision natural language processing form complete image captioning algorithm. specically machine translation languages recurrent neural network used transform sentence ‘source language’ vector representation vector second generates target sentence ‘target language’. authors derived approach replaced visual representation image using deep convolutional neural network pen-ultimate layer. originally trained detect objects pen-ultimate layer used feed second designed produce phrases original machine translation model. end-to-end system further trained directly images captions maximize likelihood description image best matches training descriptions image. open-source model imtxt implementation algorithm specically used dockerized version imtxt model available fig. illustrates captions generated imtxt images training dataset. approach captions encoded sparse bag-of-word vectors instance dictionary passed imtxt model made words wn}. image caption wwww bag-of-words representation image vector normalized concatenation stage eectively converting term frequency representation cnns proven technique image classication. complexity sparsity aection related features images suggest solution need deeper wider network large training dataset. however even relatively small training dataset cnns still used eective modality feature extraction. reduce overing resenet architecture employed models built training dataset trained original colored image trained grayscale images converted original ones. cross-validation color-model accuracy gray-model suggests color contains aection information. remaining paper refer color model model. feature aggregation previously discussed section given group level image methodology consists extracting scene related features using centrist facial features using resnet human pose features using pre-trained descriptors using imtxt neural network. section describe strategy combining features extracted group level images build training data classication. feature combination strategy involves concatenating features group level image. important note that problem group level emotion recognition feature concatenation straight-forward. feature vectors extracted centrist bag-of-words extracted imtxt already image basis.however case primary advantage vlad matrix discriminative property added feature vector taking dierence descriptor mean voronoi cell. order statistic adds information feature vector give beer discrimination classication. vlad encodings usually normalized usage. third feature vector resulting k-means clustering algorithm weighted average cluster centers visual word image. weights nothing normalized term frequencies corresponding visual word. based methodology addition k-means clustering method also perform dimensionality reduction visual codes using gmm. aggregation involves computing posterior probability component given visual word also dened responsibility particular component takes explaining visual word. responsibilities given component resulting faces given image averaged compute group level image responsibility component. performing computation components using visual words given image results image level aggregated feature vector. noted four feature vectors described above namely matrix vlad weighted average cluster centers based features dimensions either number clusters k-means algorithm number gaussians model. since features consistent terms dimensions groupimage level features easily concatenated. series described steps carried training validation image sets construct features classication. classification results given feature vectors group level images corresponding training validation next task build classication model assign given image three classes positive negative neutral. build classication model adopt tier approach tier- consisting learning multiple independent classiers tier- learning tier- classiers. ensemble approach previously used many data science competitions. inspired adopt bag-of-visual-words based approach construct image level aggregated feature vectors using facial pose features group level image evaluated using methods described section section. based feature transformation carried separately facial pose features. based approach feature vector corresponding face pose regarded visual word result number visual words equal total number humans extracted group level images. dened visual word based feature aggregation described follows. k-means based methodology visual words clustered using k-means algorithm reduce vocabulary consists cluster labels also referred visual codes. clusters resulting k-means clustering algorithm develop three group level feature vectors follows. term frequency matrix consists associating face group level image visual code counting occurrence visual code vocabulary. values also normalized dividing count total number faces image. denoting count visual code given image simply given well-known classiers considered namely random forest classier gradient boosted tree based classier support vector machine classier variant random forests called extra trees classiers considered inherently dierent sense learn dierent characteristics feature perform classication. example classier well suited particular group level emotion whereas performance classiers par. dierent scenario situation based classier beer suited. motivated possibility second tier model consists building ensemble mentioned classiers using technique referred stacking. also note input features classiers also made dierent modalities thereby providing diversity information second tier algorithm learn. logistic regression model used second tier classier. training dataset images human detection face detection pipeline extracted faces. validation extracted faces images. images vocabulary sizes compute derived features. performance classication best vocabulary size hence conciseness explain rest results based vocabulary size. list feature vectors used tier- along dimensions shown table observation noted work methodology able exploit pose based features optimal fashion. needs investigated further. also improvements could made methodology adopted image text based feature extraction. current method extracted image tags could limiting performance classier. weak supervision proven eective obtaining additional labeled data. future work planning google reverse-image search labeling function collect similar images training dataset. process context information human annotated tags summary information also gathered newly collected image. apply second based labeling function label images. initial experiment shows newly labeled images restnet model improvement terms accuracy. classication performance features apart pose meet exceed benchmark performance since pose based features poor include concatenated features. also interesting note performance concatenated features beer performance individual features. among individual modality features weighted average features face emotion modality using random forests achieves best validation accuracy observed concatenated features provide best classication accuracy validation hence basis stacking classier. probabilities predicted individual classiers concatenated feature input used train three class logistic regression classier perform stacking. classier improves validation accuracy resulting overall validation accuracy conclusions future directions problem determining aect group people considered paper. multi-modal approach consisting features extracted scene human face human pose image tags adopted. extract human face based features developed pipeline consists r-cnns extracting humans group level images crop faces conventional face alignment method uses regression trees. main contributions work training usage deep neural networks extract face pose features. furthermore dnns trained external datasets contained number images suitable learning large number parameters dnn. approach overcomes inadequacy current dataset sucient samples train dnn. additionally also employed bagof-visual-words based approach translate multiple human level features group level features. using combination group level features multiple modalities validation accuracy percent achieved. finally stacking methodology employed build ensemble classiers resulted validation accuracy references clarifai. hps//www.clarifai.com/. pablo arbel´aez jordi pont-tuset jonathan barron ferran marques jitendra malik. multiscale combinatorial grouping. proceedings ieee conference computer vision paern recognition. cheng liu. learning coarse-to-ne sparselets ecient object detection scene classication. ieee conference computer vision paern recognition doihp//dx.doi. org/./cvpr.. merrienboer gulcehre bougares schwenk bengio. learning phrase representations using encoder-decoder statistical machine translation. proc. empirical methods natural lang. process. tommy w.s. chow haijun zhang m.k.m. rahman. document representation using term frequency vectorized graph connectionists application document retrieval. expert systems applications costante ciarfuglia valigi ricci. transfer learning approach multi-cue semantic place recognition. ieee/rsj international conference intelligent robots systems. doihp//dx.doi.org/ ./iros.. abhinav dhall jyoti joshi karan sikka roland goecke nicu sebe. merrier analysing aect group people images. automatic face gesture recognition ieee international conference workshops vol. ieee ross girshick donahue trevor darrell jitendra malik. rich feature hierarchies accurate object detection semantic segmentation. proceedings ieee conference computer vision paern recognition. georgia gkioxari bharath hariharan ross girshick jitendra malik. using k-poselets detecting people localizing keypoints. proceedings ieee conference computer vision paern recognition. goodfellow dumitru erhan pierre-luc carrier aaron courville mehdi mirza hamner cukierski yichuan tang david aler dong-hyun yingbo zhou chetan ramaiah fangxiang feng ruifan xiaojie wang dimitris athanasakis john shawe-taylor maxim milakov john park radu ionescu marius popescu cristian grozea james bergstra jingjing lukasz romaszko bing zhang chuang yoshua bengio. challenges representation learning report three machine learning contests. neural networks doihp//dx.doi.org/./j.neunet... special issue deep learning representations. alex krizhevsky ilya sutskever georey hinton. imagenet classication deep convolutional neural networks. advances neural information processing systems. lazebnik schmid ponce. beyond bags features spatial pyramid matching recognizing natural scene categories. ieee computer society conference computer vision paern recognition vol. doihp//dx.doi.org/./cvpr.. jianshu sujoy jiashi feng terence sim. happiness level prediction sequential inputs multiple regressions. proceedings international conference multimodal interaction york doihp//dx.doi.org/./. alexander ratner stephen bach henry ehrenberg chris r´e. snorkel fast training generation information extraction. proceedings international conference management data york doihp//dx.doi.org/./. bhargava reddy ye-hoon sojung junik jang soonhyuk hong. deep learning single step real-time facial expression recognition. video analytics. face facial expression recognition audience measurement international workshop vaam second international workshop ffer cancun mexico december revised selected papers. doihp//dx.doi.org/./---- shaoqing kaiming ross girshick jian sun. faster r-cnn towards real-time object detection region proposal networks. advances neural information processing systems. sermanet eigen zhang mathieu fergus lecun. overfeat integrated recognition localization detection using convolutional networks. international conference learning representations karen simonyan andrew zisserman. deep convolutional networks large-scale image recognition. arxiv preprint arxiv. qinglan liandong qihua lejun lstm dynamic emotion group emotion recognition wild. proceedings international conference multimodal interaction. sutskever vinyals sequence sequence learning neural networks. proc. neural inf. process. syst. yaniv taigman ming yang marc’aurelio ranzato lior wolf. deepface closing human-level performance face verication. ieee conference computer vision paern recognition vinyals toshev bengio erhan. show tell lessons learned mscoco image captioning challenge. ieee transactions paern analysis machine intelligence hp//dx.doi.org/./tpami.. jianxin rehg. centrist visual descriptor scene categorization. ieee transactions paern analysis machine intelligence yang jiang. randomized spatial pooling deep convolutional networks scene recognition. ieee international conference image processing doihp//dx.doi.org/./icip. zhiding zhang. image based static facial expression recognition multiple deep network learning. proceedings international conference multimodal interaction york doihp//dx.doi.org/./. zhang rong zhi-hua zhou. understanding bag-of-words model statistical framework. international journal machine learning cybernetics doihp//dx.doi.org/./ s---", "year": 2018}