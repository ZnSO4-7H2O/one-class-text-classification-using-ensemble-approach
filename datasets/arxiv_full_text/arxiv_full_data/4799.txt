{"title": "Better Computer Go Player with Neural Network and Long-term Prediction", "tag": ["cs.LG", "cs.AI"], "abstract": "Competing with top human players in the ancient game of Go has been a long-term goal of artificial intelligence. Go's high branching factor makes traditional search techniques ineffective, even on leading-edge hardware, and Go's evaluation function could change drastically with one stone change. Recent works [Maddison et al. (2015); Clark & Storkey (2015)] show that search is not strictly necessary for machine Go players. A pure pattern-matching approach, based on a Deep Convolutional Neural Network (DCNN) that predicts the next move, can perform as well as Monte Carlo Tree Search (MCTS)-based open source Go engines such as Pachi [Baudis & Gailly (2012)] if its search budget is limited. We extend this idea in our bot named darkforest, which relies on a DCNN designed for long-term predictions. Darkforest substantially improves the win rate for pattern-matching approaches against MCTS-based approaches, even with looser search budgets. Against human players, the newest versions, darkfores2, achieve a stable 3d level on KGS Go Server as a ranked bot, a substantial improvement upon the estimated 4k-5k ranks for DCNN reported in Clark & Storkey (2015) based on games against other machine players. Adding MCTS to darkfores2 creates a much stronger player named darkfmcts3: with 5000 rollouts, it beats Pachi with 10k rollouts in all 250 games; with 75k rollouts it achieves a stable 5d level in KGS server, on par with state-of-the-art Go AIs (e.g., Zen, DolBaram, CrazyStone) except for AlphaGo [Silver et al. (2016)]; with 110k rollouts, it won the 3rd place in January KGS Go Tournament.", "text": "competing human players ancient game longterm goal artiﬁcial intelligence. go’s high branching factor makes traditional search techniques ineffective even leading-edge hardware go’s evaluation function could change drastically stone change. recent works clark storkey show search strictly necessary machine players. pure pattern-matching approach based deep convolutional neural network predicts next move perform well monte carlo tree search -based open source engines pachi search budget limited. extend idea named darkforest relies dcnn designed long-term predictions. darkforest substantially improves rate patternmatching approaches mcts-based approaches even looser search budgets. human players newest versions darkfores achieve stable level server ranked substantial improvement upon estimated ranks dcnn reported clark storkey based games machine players. adding mcts darkfores creates much stronger player named darkfmcts rollouts beats pachi rollouts games; rollouts achieves stable level server state-of-the-art except alphago rollouts place january tournament. long time computer considered grand challenge artiﬁcial intelligence. fig. shows simple illustration game players black white place stones intersections turn board black plays ﬁrst empty board. -connected component color called group. liberties group number neighboring empty intersections group captured liberties zero. goal game control territory opponent fig. shows rating system ranging level level professional levels difﬁcult high branching factors subtle board situations sensitive small changes combination implies solution massive search requires prohibitive amount resources attainable cutting-edge hardware. fortunately recent works clark storkey computer shown board situation could deciphered deep convolutional neural network predict next move human would play time. however whether accuracy leads strong well understood. possible dcnn correctly predicts regular plays looking correlation local patterns still fails predict critical moves loses game. indeed dcnn-based player still behind compared traditional open-source engines based monte-carlo tree search kocsis szepesv´ari alone commercial ones. figure special situations black captures white stone playing white prohibited capture back immediately playing prevent repetition game state. ﬁght. black captures white white cannot capture back. instead white plays threatening three black stones black plays connect white back ladder. black plays threatening capture white stone circle. white escapes eventually gets captured border. time black plays white’s liberties shrink images sensei’s library paper show dcnn-based move predictions indeed give strong properly trained. particular carefully design training process choose predict next moves rather immediate next move enrich gradient signal. despite prediction giving mere boost accuracy move predictions rate open-source engines heavy search scenarios times higher current state-of-the-art dcnn-based player addition search-less darkfores played ranked game server achieves stable level much better neural network based proposed clark storkey holds estimated games mcts-based engines. bots also share common weakness dcnn-based methods local tactics. combining dcnn mcts hybrid darkfmcts addresses issues. rollouts beats pachi rollouts games rollouts achieves stable level server state-of-the-art rollouts place january tournament. recently deepmind’s alphago defeated european champion showing strong power dcnn-based bot. using neural network function approximator pattern matcher predict next move long-standing idea richards schraudolph enzenberger recent progress clark storkey uses deep convolutional neural network move prediction shows substantial improvement shallow networks linear function approximators based manually designed features simple patterns extracted previous games paper train dcnn predicts next moves given current board situation input. treat board image multiple channels. channel encodes different aspect board information e.g. liberties compared previous works compact feature predict long-term moves show lead substantial performance boost terms rate open source engines. table features extracted current board situation input network. note extended feature also includes standard set. result standard channels extended channels. feature channels table shows features extracted current board situation. feature binary except history information position mask real numbers history encoded long stone placed. exponential temporal decay meant enable network focus recent battle. position mark deﬁned squared distance board center. used encode relative position intersection. differences features maddison first relative coding almost features. contrast features maddison largely player-agnostic. second feature simpler compact particular free step forward simulation. comparison maddison uses features like liberties move captures move etc. similar encode rank planes maddison kyu-players nine planes zero players ﬁrst plane all- players second plane all- etc. professional players planes ﬁlled fig. shows architecture network best model. -layered full convolutional network. convolution layer followed relu nonlinearity. except ﬁrst layer layers width weight sharing used. pooling since negatively affect performance. instead using softmax outputs predict black white moves softmax layer predict next move reducing number parameters. predicting immediate next move limits information received lower layers. instead predict next moves current board situation. move separate softmax output. motivation two-fold. first want network focus strategic plan rather immediate next move. second multiple softmax outputs expect supervisions train network. table computes ratio average gradient norm -step -step predictions convolutional layer. expected gradient magnitudes layers higher -step prediction. however gradient magnitudes lower layers approximately same showing lower gradients canceled -step prediction presumably leaving important gradient training. empirically dcnn trained steps gives high rate step. training threads prepare minibatch simulating random selected games dataset. minibatch thread randomly select game simulate step according game record extract features next moves input/output pair batch. game ended randomly pick training continue. batch size data augmentation rotation -degree intervals horizontal/vertical ﬂipping. board situation data augmentation could generate different situations. training randomly initialize games different stages. ensures batch contains situations corresponding different stages games. without this network quickly overﬁt trapped poor local minima. training style clear training thoroughly processed once. therefore deﬁne epoch mini-batches. unlike maddison uses asynchronous stochastic gradient descent vanilla nvidia gpus single machine train entire network epoch lasts hours. learning rate initially divided convergence stalls. typically model starts converge within epoch shows good performance epochs simplest dcnn model also tried training resnet recently gives state-of-the-art performance image classiﬁcation. also tried using additional targets predicting endgame territories given current board status. gives faster convergence. recurrent neural network also tried gives worse performance. experiments clearly show dcnn tactically weak lack search. search explore solution space conditioned current board situation build non-parametric local model game. local model ﬂexible global model learned massive training data adapted current situation. state-of-the-art approach computer monte-carlo tree search fig. shows basic principle. combining dcnn mcts requires nontrivial engineering efforts rollout mcts much faster dcnn evaluation. therefore must parallel frequent communications. basic implementation mcts gives rollouts second typically takes dcnn give board evaluations batch size gpus. ways address problem. asynchronized implementation used maddison mcts sends newly expanded node dcnn blocked dcnn evaluation. mcts tree policy dcnn evaluation arrives updates moves. gives high rollout rate time dcnn evaluation take effect clear many board situations evaluated given number mcts rollouts. synchronized implementation mcts wait dcnn evaluates board situation leaf node expands leaf. default policy before/after dcnn evaluation. much slower guarantees node expanded using dcnn’s high-quality suggestions. figure brief illustration mcts dcnn. game tree. node statistics indicates node games emulated black. root represents current game state. rollout starting root. picks move current state using tree policy advances next game state picks move expand leaf. leaf default policy game ends time leaf status sent dcnn server evaluation. synchronized implementation node available tree policy evaluation returned. statistics along trajectory tree policy updated accordingly. experiments evaluate synchronized case achieves rate dcnn player rollouts. note implementation directly comparable asynchronized version maddison achieving rollouts. recent alphago system fast cpu-based tree policy used dcnn evaluation arrives. combined default policy gives move suggestion accuracyon tygem dataset cpu-only system already achieves level. also implementing using similar local patterns achieves slight higher accuracy move. however combined system performance good pachi’s rule-based default policy showing top- accuracy sensitive metric use. indeed moves much critical others. setup public dataset used maddison games training games test set. leads games training games testing. also gogod dataset also used clark storkey games used training testing. table shows performance comparison move prediction. models predict next moves evaluate prediction accuracy immediate next move i.e. ﬁrst move model predicts. although improvement move prediction accuracy small improvement play strength terms rate much larger. fig. shows improvement rate time. dcnn trained steps better dcnn trained step. steps show diminishing returns. hand rate standard feature comparable extended one. table shows rate approach substantially higher previous works. also train smaller model whose number parameters comparable maddison smaller model achieves games pachi pachi’s pondering off. contrast maddison reports mention pondering status. darkforest bots. build three bots trained models. ﬁrst darkforest trained using standard features step prediction dataset. second darkfores trained using extended features step prediction gogod dataset. bots trained constant learning rate based darkfores ﬁne-tuned learning rate create even stronger dcnn player darkfores. note ﬁne-tuning model achieves comparable strength. table shows strengths open source engines. seems despite fact gogod smaller model trained faster better performance presumably gogod contains professional games games amateurs hence noisy. rates among three bots consistent performances open source engines. table rate comparison open source engines model previous works. setting groups games played. report average rate standard deviation computed group averages. game experiments mentioned paper komi chinese rules. pondering pachi fuego note clark storkey control time move sec/move cores instead ﬁxing rollout number. also compare darkforest public dcnn model. create diverse games moves sampled according dcnn softmax probability. played sets games rate. darkforest always wins sampling top-/top- moves. performance humans. bots onto server check performance humans months period. darkforest became publicly available since played games. recently also release improved version darkfores darkfores iclr deadline. bots become ranked since late november score endgame board situations randomly trials default policy dead stones followed standard tromp-taylor scoring. trials show losing points resign. three pure dcnn bots quite popular server playing around games day. ranked darkforest achieves darkfores strong level showing strength next predictions consistent estimations using free games played ﬁne-tuned version darkfores stable level impressive result pure dcnn models. even beats games row. notice open handicap games rates become higher. major improvement upon dcnn developed clark storkey holds level estimated playing engines. fig. shows example game darkfores human player. overall bots good understanding global board situations tend play good shapes occasionally fail local basic life/death situations e.g. making large connected group alive capturing race failing make eyes. rarely lost ladder capture special case keeps chasing opponent’s stones board’s border kill them. apparently network failed capture ladder pattern rarity actual games. handle this separate simple search module added. figure example game darkfores player gugun move shows understanding ﬁght darkfores. black react lower left corner reinforce group. trade white wins ﬁght right corner. result game white example game darkforest darkforest+mcts darkforest resigned. concise illustration truncated game estimated rate mcts exceeds build standard mcts framework study performance dcnn+mcts. tree policy moves ﬁrst sorted dcnn conﬁdences picked order accumulated probability exceeds maximum number moves reached. select moves tree expansion. note dcnn conﬁdences used uct. noise uniformly distributed added rate enforce search threads quickly diverge locked node waiting dcnn evaluation. speeds tree search tremendously default policy following pachi’s implementation patterns opponent atari points detection nakade points avoidance self-atari default policy. note pachi’s complete default policy yields slightly better performance. non-deterministic nature multi-threading game dcnn+mcts dcnn always different trial. versus pure dcnn. table darkforest+mcts gives highest performance boost darkforest boost darkfores darkfores smaller. indicates mcts mitigates weakness dcnn particular weaker engine. another interesting observation performance becomes higher consider fewer moves search. shows moves dcnn really high quality moves mcts works better digs deep promising paths. interestingly mcts top- gives even better performance pure dcnn performance worse version. finally setting minimal number choices hurts performance tremendously. versus pachi rollouts rate improvement pure dcnn model huge particular weak models. rollouts make performance even better. particular darkforest+mcts overwhelms pachi rate. note experiments pachi’s pondering turned comparison previous works. comparison asynchronized version used maddison achieves rollouts faster numbers directly comparable since asynchronized implementations number game states sent dcnn evaluation unknown rollouts table shows stronger dcnn model beneﬁts less combined mcts. section gives detailed comparison implementations. evaluation server. distributed version named darkfmcts server darkfores underlying dcnn model runs rollouts threads produces move every seconds intel xeon .ghz nvidia gpus. uses top- predictions ﬁrst moves switched top- afterwards mcts could choices. pondering used. dynamic komi used high handicap games darkfmcts holds stable level except alphago beaten hold win/lose korean professional player handicaps. version rollouts gpus place january computer tournament dolbaram took place abacus took rollouts single machine gpus move. weakness. despite involvement mcts weakness remains. top-/ moves dcnn might contain critical local move save/kill local self/enemy group local tactics remain weak. sometimes plays tenuki pointlessly tight local battle needed. dcnn tends give high conﬁdences moves even useless. enables dcnn play single ﬁghts decently following pattern playing playing threats playing again. also gets confused presence double losing plays moves like mcts bots loses more. paper substantially improved performance dcnn-based extensively evaluated open source engines strong amateur human players shown potentials combined monte-carlo tree search ideally want construct system combines pattern matching search trained jointly online fashion. pattern matching dcnn good global board reading might fail capture special local situations. hand search excellent modeling arbitrary situations building local non-parametric model current state computation cost affordable. paradigm update dcnn weights mcts completes chooses different best move dcnn’s proposal. increase signal bandwidth could also update weights using board situations along trajectory best move. alternatively could update weights mcts running. actor-critics algorithms also used train models simultaneously predict next move evaluate current board situation finally local tactics training focuses local board situation fewer variations dcnn approaches beneﬁt like human players. browne cameron powley edward whitehouse daniel lucas simon cowling peter rohlfshagen philipp tavener stephen perez diego samothrakis spyridon colton simon survey monte carlo tree search methods. computational intelligence games ieee transactions enzenberger markus m¨uller martin arneson broderick segal richard. fuegoan opensource framework board games engine based monte carlo tree search. computational intelligence games ieee transactions schraudolph nicol dayan peter sejnowski terrence temporal difference learning position evaluation game advances neural information processing systems silver david huang maddison chris guez arthur sifre laurent driessche george schrittwieser julian antonoglou ioannis panneershelvam veda lanctot marc dieleman sander grewe dominik nham john kalchbrenner sutskever ilya lillicrap timothy leach madeleine kavukcuoglu koray graepel thore hassabis demis. mastering game deep neural networks tree search. nature sutton richard mcallester david singh satinder mansour yishay policy gradient methods reinforcement learning function approximation. nips volume citeseer", "year": 2015}