{"title": "Real-Time Bidding with Multi-Agent Reinforcement Learning in Display  Advertising", "tag": ["stat.ML", "cs.AI", "cs.LG"], "abstract": "Real-time advertising allows advertisers to bid for each impression for a visiting user. To optimize a specific goal such as maximizing the revenue led by ad placements, advertisers not only need to estimate the relevance between the ads and user's interests, but most importantly require a strategic response with respect to other advertisers bidding in the market. In this paper, we formulate bidding optimization with multi-agent reinforcement learning. To deal with a large number of advertisers, we propose a clustering method and assign each cluster with a strategic bidding agent. A practical Distributed Coordinated Multi-Agent Bidding (DCMAB) has been proposed and implemented to balance the tradeoff between the competition and cooperation among advertisers. The empirical study on our industry-scaled real-world data has demonstrated the effectiveness of our modeling methods. Our results show that a cluster based bidding would largely outperform single-agent and bandit approaches, and the coordinated bidding achieves better overall objectives than the purely self-interested bidding agents.", "text": "auctions campaign bidders interact auction environment critically other. changes strategy bidder would aect strategies bidders vice versa addition existing computational bidding methods mainly concerned micro-level optimization party advertiser merchant)’s benet. given competition auction optimizing party’s benet ignore hurt parties’ benets. system’s viewpoint micro-level optimization fully utilize dynamics ecosystem order achieve beer social optimality paper address issue taking gametheoretical approach bidding solved multi-agent reinforcement learning bidding agents interactions modeled. signicant advantage previous methods proposed marl bidding strategy rational bidding agent motivated maximizing payo; also strategic bidding agent also provide best response strategic change bidders eventually reach equilibrium stage. study large-scale developed context realistic industry seing taobao largest e-commerce platform china. taobao serves four hundred million active users. best knowledge study employing marl large scale online advertising case evaluated real data. previous studies marl mostly theoretical nature majority experiments done simulated games bidding considered earliest realistic applications marl. modeling large scale bidding marl however dicult. taobao e-commerce platform large number consumers merchants. modeling merchant strategic agent computationally infeasible. tackle issue propose bidding agents operate clustering level. cluster consumers several groups considered super-consumer also cluster merchants groups represented common bidding agent. multi-agent formulation thus based interactions super-consumers cluster-level bidding agents well interactions among bidding agents. technical challenge convergence marl cluster bidding agents explore auction system simultaneously makes auction environment non-stationary noisy agent learn stable policy. inspired multi-agent deep deterministic policy gradient techniques propose distributed coordinated multi-agent bidding method stabilize convergence feeding agents’ bidding actions function. learning bidding agent’s function evaluates abstract real-time advertising allows advertisers impression visiting user. optimize specic goal maximizing revenue placements advertisers need estimate relevance user’s interests importantly require strategic response respect advertisers bidding market. paper formulate bidding optimization multi-agent reinforcement learning. deal large number advertisers propose clustering method assign cluster strategic bidding agent. practical distributed coordinated multi-agent bidding proposed implemented balance tradeo competition cooperation among advertisers. empirical study industry-scaled real-world data demonstrated eectiveness modeling methods. results show cluster based bidding would largely outperform single-agent bandit approaches coordinated bidding achieves beer overall objectives purely self-interested bidding agents. introduction online advertising marketing paradigm utilizing internet target audience drive conversions. real-time bidding allows advertisers every individual impression realtime generated. typical exchange employs second price sealed-bid auction theory second price auction would encourage truthful bidding. practice however optimal equilibrium bids largely unknown depending various factors including availability market prices existence budget constraints performance objectives rationality opponent bidders. such strategically optimize bidding becomes central question advertising research optimal bidding strategies focused largely statistical solutions making strong assumption market data stationary specially zhang shows budget-constrained optimal bidding achieved condition environment stationary. proposes two-stage bandit modeling bidding decision independent time. wang leverage reinforcement learning model optimization sequential decision procedure. nonetheless solution fully distributed integrated taobao’s distributed-worker system high-concurrency asynchronous requests consumers. experiments conducted real world industrial data. results demonstrate dcmab’s advantage several strong baselines including deployed baselines system. also bidding agents self-interested motivations equilibrium converged necessarily represent socially optimal solution thus develop fully coordinated bidding model learns strategy specifying common objective function whole. related work optimization rtb. bidding optimization concerned problems aims help advertiser right bidding price auctioned impression maximize campaign’s performance indicator click prot perlich introduced linear bidding strategy based impression evaluation widely used real-word applications since then. zhang went beyond linear formulation. found non-linear relationship between optimal impression evaluation derived eective non-linear bidding functions. methods regard bidding optimization static problem thus fail deal dynamic situations rationality bidding agents. intelligent bidding strategy manages optimize certain constraints make real-time adaption campaign’s lifetime reinforcement learning. formulated markov decision process bidding framework learn sequentially allocate campaign budget along impressions impression evaluation campaign’s real-time conditions state. tackled budget constraint means constrained mdp. wang utilized deep reinforcement learning specically optimize bidding strategy dsp. high-level semantic information state consider budget constraint. tasks share common task seing i.e. optimization serves single advertiser competitors part environment signicantly diers seings. another popular method budget allocation pacing algorithm smooths budget spending across time according trac intensity uctuation. compared method pacing considered single agent optimization method explicitly model inuence agents’ actions auction environment. addition pacing cannot coordinate agents cooperate beer equilibrium. like many exchanges taobao display advertising system treat advertisers equally. meanwhile need balance interests among consumers advertisers platform. erefore motivated construct framework simultaneously takes dierent interests consideration. advertisers compete high quality impressions cooperate sense providing beer user experience improving overall revenue platform. work adopt multi-agent reinforcement learning achieve goal. multi-agent reinforcement learning. multi-agent literature design mechanisms learning algorithms make agents well cooperate focus. compared cooperation independent q-learning drawing conclusion additional information agents used properly benecial collective reward. many studies aerwards focused eectively coordinate agents achieve common goal either means sharing parameters learning communication protocol studies adopted framework centralized training decentralized execution allowing involving extra information ease training. lowe studied direction proposed maddpg centralized critic augmented policies agents. however maddpg applied simulation environment states update transition tuple saving performed frequently. task serious challenge face huge number advertisers taobao display advertising exceeds processing capacity almost current multi-agent reinforcement learning methods. furthermore model advertiser individual agent reward would sparse agents. besides bidding system implemented distributed workers process requests parallel asynchronously. considering factors extend deterministic policy gradient algorithm solution improvements including clustering method model large number merchants multiple agents distributed architecture design enable framework process requests distributed workers parallel asynchronously. taobao display system taobao ecosystem advertisers mostly merchants advertise also sell products taobao’s e-commerce platform. remaining paper call merchants. taobao system divided three parts shown figure first matching stage user preferences obtained mining behavior data receiving user request matching part recalls candidate entire corpus real time based relevancy. dierent recommender systems recall also reect advertisers’ willingness join i.e. behavior targeting seings. second follow-up realtime prediction engine predicts click-through rate conversion rate eligible realtime bidding candidate received candidate ranked descending order called eective cost-per-mille sorting mechanism. finally ranked displayed. general auction seing refer stated above change bids inuence ranking candidate impact connections built consumers merchants. ideal mapping consumers ideal products merchants target right consumers intent advertised products. demands precisely supplies platform creates higher connection value society stochastic game formulate stochastic game a.k.a. markov game bidding agents behalf merchants impressions. markov game dened states describing possible status bidding agents actions represents action spaces agent action adjustment ratio. according t-th timestep state bidding agent uses policy determine action execution bidding agent transfers next state according state transition function indicates collection probability distributions state space. agent obtains reward based function state agents’ actions initial states determined predened distribution. agent aims maximize total expected return discount factor time horizon. describe details agents states actions rewards objective functions seing follows. agent clusters. system registered merchants denoted registered consumers denoted auction launched consumer feature describing consumer’s information auction. merchant’s product’s price denoted ideal formulate merchants model agent. however arrangement computationally expensive fact sparse interactions specic pair consumer merchant. also growth number agents exploration noise becomes dicult control. thus propose clustering method model involved entities. according cumulative revenue period merchants categorized clusters similarly consumers categorized clusters cluster consumers building agents’ states computation static features enable agents evaluate features auctions dierent consumers adjust bids accordingly. hereinaer subscript merchant cluster consumer cluster. normally shrink cluster size enlarge cluster number approximates ideal case. diagram modeling shown figure state. state design aims bidding agents optimize budgets allocation based impression’s value spending trends along time. denote cumulative cost revenue merchants consumers beginning episode decision moment general information state. vectors characterize important information budget spent status agent plan rest auctions; distribution consumers agent distinguish quality dierent consumer clusters; distribution figure overview taobao display advertising system. matching ranking modules sequentially process user requests nally return specied quantity ads. shown guess like taobao tagged surrounded recommendation results. meantime gets higher revenue facilitating matching. beer revenue optimization merchants also authorize platform adjust manually bids within acceptable range. summary bids control variables online advertising system adjusted well achieve win-win-win situation consumers merchants platform’s interest. e-commerce system large number registered merchants registered consumers. auction launched consumer. according information auction merchant budget constraint gives price. merchant auction corresponding would delivered consumer. consumer probability click enter detailed landing page product probability merchant’s product price forming merchants’ revenue. given predened budget achieve higher revenue general goal merchants. higher total revenue also consumers’ platform’s motivations consumers connected products want platform larger gross merchandise volume means larger long-term advertising revenue. whenever merchant’s clicked corresponding merchant unspent budget subtracted advertising cost according generalized second price auction mechanism merchant loses auction gets reward pays nothing. merchant’s budget runs merchant participate rest auctions. bidding display advertising regarded episodic process episode includes many auctions auction consumer’s page view specic context. sequentially sent bidding agents. merchant’s goal allocate budget right consumers right time maximize total revenue. merchants competing together forms multi-agent game. however budgets limited game merchants’ bidding result suboptimal equilibrium. example merchants compete severely early auctions many merchants quit early. competition depth late bidding results matching eciency consumers merchants. erefore merchants seing bids dierent consumers dierent time according dierent competition bidding multi-agent since output action continuous space adopt deterministic policy gradient learning bidding strategy. marl seing function agent given commonly called actor. marl goal learn optimal strategy agent dierent even conicted goal. notion nash equilibrium important represented policies satises compact notations joint policy agents except nash equilibrium agent acts best response others provided agents follow policy gives optimal action state agent leads equilibrium bidding strategy. using alternative gradient descent approach similar ones introduced xing gradient update agent’s agent’s parameters specically critic parameter figure merchants consumers grouped clusters separately. merchant cluster agent adjusts bids included merchants dierent consumer clusters. action iterates number merchant clusters consumer clusters. bratiok stands base adjustment ratio merchant agents agent evaluate competitive cooperative environment. besides consumer feature also added includes slowly-changed consumer features total status updated every period time. feature helps agents evaluate auction. concatenate form state suppose merchant’s budget predened therefore spent unspent budgets information also maintained state. diagram modeling shown figure action. every merchant manually dierent bids dierent consumer crowds dierent creatives. without loss generality denote bidk across auctions iterates merchants hereinaer. beer budget allocation platform authorized adjust scalar generate bidk ran❕e ran❕e experiment. stated above cluster merchants clusters dierent values dierent merchant clusters denoted exactly action agent however applying agent’s action included merchants lack exibility. hence actually conducted adjust ratio bratiok shown figure calculation bratiok predened would discuss detail section reward transition. reward dened agent level merchant level. merchant belonging agent executes wins auction delivering consumer reward agent increases revenue directly caused consumer. clicked budget merchant decreases cost rnext bidnext/pct according mechanism merchant next next ranked merchant merchant according maximum ecpm ranking score bid. state updated accumulating changes including consumer feature changing form transition states. merchant loses auction contribution agent’s reward. quality consumer request demonstrated seings factor applies coarse adjustment merchants within cluster factor bratiok discriminates among merchants within cluster reects value conversion real time. next focus learnable component i.e. computing every consumer computationally costly every time interval large numbers consumers. solution utilize consumer clusters. consumer clusters design cluster-specic versions features contains one-hot embedding consumer cluster dimension history design consumer cluster one-hot embedding enhance discriminative ability basis beginning compute every merchant cluster consumer cluster pair within interval candidate merchant select according merchant cluster consumer cluster pair multiplied bratiok clipped form adjusting ratio min{max{aij bratiok −ran❕e} ran❕e} bidk. worth mentioning that replaced extra dimensionality consumer cluster. aggregated actions. save transition tuples replay memory every time interval requires aggregate information propose aggregation method summarize executions within maintain discrete distribution aij/tot stands executed number executed number. concatenate save part tuple every critic function input augmented distributed gradient update aims agents optimize budgets allocation according consumer distributions consumer features every utilizing real-time feature every auction. call algorithm distributed coordinated multi-agent bidding critic actor update figure illustration dcmab. dcmab workow advertising system. state server maintains agents’ states including general information consumer distribution consumer static feature every states merged agents’ actors updated dcmab. that multiplied bratiok form adjustment ratio. dcmab network design. separate actor network agent. calculated using input. addition states actions consumer distribution collected input agents’ function. implementation distributed architecture typical method original saves transition tuple every state transition dicult implement real-world platform following reasons. operational system usually consists many distributed workers process consumers’ requests parallel asynchronously demands merge workers’ state transitions. states change frequently saving every request transition tuple would cost unnecessary computation. section extend original gradient updates adapted real-world distributed-worker platform. system transition update action execution maintained asynchronously. words transition tuples executing actions operated dierent frequencies states merge among workers tuples saved periodically every time many requests processed. every request according dierent request features actor generates dierent actions execution. method merge states transition updates every interval handled current industrial computation ability distributed workers. note although states updated every actions generated every auction real time. framework brings dierent frequencies critic updates actor executions. propose split consumer-based features aggregated actions make critic actor well organized explained next. split consumer-based features. stated state denition consumer feature consists static feature containing slowly changed information obtained starts. real-time feature acquired request comes worker also utilized. shown actor denition factorize adjust ratio bratiok. computed every static consumer feature. real-time part used bratiok calculation every auction. concrete formulation bratiok rk/pcv merchant level merchant historical average merchant rk/pcv provides auction level information enables merchant apply auction level adjustment high hundreds recommendation slots well organized. based data saved procedures consumers’ requests including pctr pcvr along requests used procedure replay form oine simulation platform. pctr pcvr used simulate consumers’ behaviors computing states rewards. uniformly sampled fraction three hours’ logged data date training data uniformly sampled fraction three hours’ logged data test data. training test algorithm based oine simulation system lack real consumer feedback data. results reported based test data. merchants budget unlimited merchant adjust price highest number solution trivial. test budget optimized allocation along time budget merchant large. similar work seing determine budget follows merchants human manually unlimited budgets accumulate total cost merchant’s budget fraction notion statistics data training impressions revenue revenue means seing merchants endowed unlimited budgets testing impressions revenue revenue evaluation metrics. evaluation based agents’ revenue total revenue predened budgets number auctions. agent’s objective maximize revenue given budget. experiments revenue primary evaluation measure. also analyze inuences agents’ rewards changes converged equilibrium. evaluation built oine simulation system close real online system distributed workers processing consumers’ requests. auction according maximum ecpm ranking top-ranked three merchants win. training model learns model’s dierent bids lead dierent ranking results. lack consumers’ real feedback dierent ranking results merchants expected bidnext/pct based mechanism) expected revenue oine simulation. system based -node computation cluster node intel xeon .ghz cores memory centos. model implemented distributed tensorflow python. oine platform consistent online platform future deployment need change reward expectation real feedback. episode length. simulate real online system simulation platform updates states every hour. three hours’ auctions evaluation. length episode includes three steps number state transitions. three-hour training data includes totally impressions number actor executions. experiment training takes hours distributed workers. experiments experiments conducted data sets collected taobao display system. data collected guess like column taobao homepage three display slots hundreds recommendation slots allocated. collected prices traded market well feedback conversions consumers placed would able replay data train test proposed marl bidding oine fashion. similar seings found research work data sets evaluation setup data sets. data sets used experiments come realworld production. display located guess like column taobao homepage three display slots compared methods evaluation following algorithms compared dcmab algorithm. except manually seing bids algorithms neural networks approximators. also build reward estimator contextual bandit method critic. algorithms’ critics include hidden layers neurons hidden layer neurons second hidden layer states inputs layer actions inputs hidden layer. algorithms’ actors include neurons hidden layer neurons second hidden layer states inputs actions outputs. activation function hidden layers relu output layer actors tanh output layer critics linear. manually bids. real bids manually contextual bandit. algorithm optimizes time step independently. impression’s adjusted according feature impression called contextual feature. compare dcmab also agents’ actions part contextual feature. dierence algorithm optimize budgets allocation along time. advantageous actor-critic method on-policy actor-critic algorithm utilize memory replay. critic function algorithm take agents’ actions input. ddpg. ddpg o-policy learning algorithm memory replay. critic function algorithm doesn’t take agents’ actions input. dcmab. algorithm. upgrade maddpg clustered agents modeling redesign actor critic structures adapt distributed workers’ platform. critic function algorithm takes agents’ actions input. clustering method. consumer request comes according requested merchant criteria system rstly selects candidates merchants registered merchants candidates aend bidding stage merchants ltered out. consider merchant present bidding stage presence. rank merchants according revenues training data group clusters clusters approximately equal presences respect consumer requests training data. clustering method makes competitions among agent clusters relatively balanced. example three clusters figure usually clusters higher revenues consist small numbers merchants contribute larger amount revenue. reason high-revenue merchants aend bidding stage frequently. consumers also ranked according revenues grouped clusters cluster equal proportion requests platform. number clusters. formulation theoretically clusters smaller cluster sizes provide possible adjusting ratios means beer possible solutions. tried dierent cluster numbers shown figure kinds rewards used. coord means clusters’ rewards total trac revenue. self-interest means figure horizontal axis number agent clusters vertical axis represents total trac revenues. draw mean episode reward blue curves corresponding colored area standard deviations. results best performance achieved number clusters cluster number increases performance increases shows benets shrinking cluster size adding clusters. increase cluster number performance drops. observe increased number agents agents’ policies learning easily converged worse equilibria many agents competed severely early stage high prices quited auctions earlier. exists beer strategies agents lowering bids early stage competing cheaper auctions late stage. cluster number tuning cluster number appears perform best following-up experiments shall number clusters budget search. three agent clusters measure total revenue performance dcmab manually bids shown figure ’coord’ means agents’ rewards total revenue. budget merchant searched one-third full amount unlimited budget. compared manually seing dcmab coordinated rewards consistently maintain higher revenue even budget beer budget allocation. manually seing bids acquires revenue budget increases higher budget makes merchants stay market deliver consumers. performance comparisons. performance test best hyperparameters tuned previous section. instance group merchants consumers clusters respectively. merchant’s budget agent table lists converged performances dierent algorithms shows algorithm’s results. columns represent results dierent agent clusters’ summed total revenue algorithm’s experiment. conducted times experiments algorithm gave average revenues standard deviations table pareto improvement cluster improve revenue without hurting clusters’ revenues. among algorithms dcmab pareto improvement algorithms except ddpg means clusters’ revenue total revenue improved. veries eectiveness algorithm. ddpg pareto improvement manual bandit. compared on-policy algorithm ddpg dcmab perform beer illustrating usefulness sample memory. compared bandit algorithms ddpg dcmab verify importance budget allocation among dierent hours points necessity reinforcement learning modeling rather bandit modeling. manually seing bids perform worst non-learning baseline. dcmab ddpg result dierent equilibria. agentc agentc revenue dcmab ddpg agentc gets revenue ddpg dcmab. comparing equilibria dcmab achieves higher total revenue ddpg perspective total matching eciency connecting consumers products dcmab gives beer result. moreover dcmab gives stable equilibrium agents’ revenues total revenue’s standard deviation lower ddpg veries merits modeling agents’ actions dcmab rather modeling action ddpg. learning illustrated figure dcmab converges stable ddpg verifying eectiveness modeling agents’ actions inputs action-value functions. dcmab ddpg learn faster bandit showing merits deterministic policy gradient memory replay. coordination self-interest. part study dierent reward seings inuence equilibrium reached. first compare kinds reward seings shown table figure self-interest stands agent reward revenue; coord stands agents’ rewards total trac revenue agents fully coordinated maximize goal. coord achieves beer total revenue self-interest. compared self-interest equilibrium coord’s equilibrium agent agent obtain less revenues agent’s revenue improved largely resulting total revenue improvement. total revenue improvement coord demonstrates ability dcmab coordinate agents achieve beer result overall social benets. table figure analyze performance gradually learned agents’ bids coordination reward keeping agents’ bids manually set. figure manual means agents self-interested manually bids; coord stands bids agent cluster learned total revenue reward agents’ bids manually set; coord stands agent agent’s bids learned rewards total revenue agent’s bids manually set; coord means agents’ bids learned rewards total revenue. compared manual total revenue coord seing improved improvement mainly comes agent agent agent contribute total improvement. illustrates exibility marl framework approach adjusting coordination level depending specic needs practice. coord seing total revenue improved coord mainly comes agent agent agent drops lile. merchants join cooperation total revenue improved coord coord comparing coord coord agent’s revenue increases largely agent’s revenue unfortunately drops shows coord rearranges trac allocation would inevitably harm performance agents achieve beer overall revenue. finally agents cooperate total revenue achieves highest total revenue. agents’ rewards total revenue agent agent reach compromise dropped revenue compared coord coord. coord rearranges trac unleash agent’s potential improve total revenue resulting larger improvement total revenue coord terms total revenue coord coord coord gradually added coordination veries dcmab’s ability reinforce agents cooperate predened global goal. system perspective higher total revenue means consumers’ beer experiences beer connections commodities like. long-term perspective maximizing total revenue also encourages merchants improve business operational eciency provide beer products consumers. benjamin edelman michael ostrovsky michael schwarz. internet advertising generalized second-price auction selling billions dollars worth keywords. american economic review arlington fink equilibrium stochastic n-person game. journal science hiroshima university series jakob foerster yannis assael nando freitas shimon whiteson. learning communicate deep multi-agent reinforcement learning. nips. obtrusiveness. marketing science jayesh gupta maxim egorov mykel kochenderfer. cooperative multi-agent control using deep reinforcement learning. aamas. springer. junling michael wellman. nash q-learning general-sum stochastic games. jmlr. junling michael wellman multiagent reinforcement learning theoretical framework algorithm.. icml vol. citeseer smooth budget delivery online advertising. adkdd. joel leibo vinicius zambaldi marc lanctot janusz marecki graepel. multi-agent reinforcement learning sequential social dilemmas. aamas. lihong john langford robert schapire. contextualbandit approach personalized news article recommendation. www. timothy lillicrap jonathan hunt alexander pritzel nicolas heess erez yuval tassa david silver daan wierstra. continuous control deep reinforcement learning. arxiv preprint arxiv. ryan lowe aviv tamar jean harb openai pieter abbeel igor mordatch. multi-agent actor-critic mixed cooperative-competitive environments. nips. volodymyr mnih adria puigdomenech badia mehdi mirza alex graves timothy lillicrap harley david silver koray kavukcuoglu. asynchronous methods deep reinforcement learning. icml. igor mordatch pieter abbeel. emergence grounded compositional language multi-agent populations. arxiv preprint arxiv. claudia perlich brian dalessandro hook stitelman troy raeder foster provost. optimizing inventory scoring targeted online advertising. sigkdd. satinder singh michael kearns yishay mansour. nash convergence gradient dynamics general-sum games. proceedings sixteenth conference uncertainty articial intelligence. morgan kaufmann publishers inc. conclusions paper proposed distributed cluster-based multi-agent bidding solution real-time bidding based display advertising. marl approach novel time takes interactions merchants bidding together optimize bidding strategies. utilizes rich information agents’ actions features historic auction user feedback budget constraints etc. dcmab exible adjust bidding fully self-interested fully coordinated. fully coordinated version great interest platform whole coordinate merchants reach beer socially-optimal equilibrium balancing benets consumers merchants platform together. realized model product scale distributed-worker system integrated process auctions parallel asynchronously. experimental results show dcmab outperforms state-of-the-art single agent reinforcement learning approaches. fully cooperative rewards dcmab demonstrates ability coordinating agents achieve global socially better objective. results oine evaluation promising process deploying online version. plan conduct live test taobao platform particular focus mobile display ads. jian kuang-chih wentong hang smart pacing eective online campaign optimization. sigkdd. shuai yuan wang bowei chen peter mason seljan. empirical study reserve price optimisation real-time bidding. sigkdd. shuai yuan wang xiaoxue zhao. real-time bidding online", "year": 2018}