{"title": "Reasoning about Bayesian Network Classifiers", "tag": ["cs.LG", "cs.AI", "stat.ML"], "abstract": "Bayesian network classifiers are used in many fields, and one common class of classifiers are naive Bayes classifiers. In this paper, we introduce an approach for reasoning about Bayesian network classifiers in which we explicitly convert them into Ordered Decision Diagrams (ODDs), which are then used to reason about the properties of these classifiers. Specifically, we present an algorithm for converting any naive Bayes classifier into an ODD, and we show theoretically and experimentally that this algorithm can give us an ODD that is tractable in size even given an intractable number of instances. Since ODDs are tractable representations of classifiers, our algorithm allows us to efficiently test the equivalence of two naive Bayes classifiers and characterize discrepancies between them. We also show a number of additional results including a count of distinct classifiers that can be induced by changing some CPT in a naive Bayes classifier, and the range of allowable changes to a CPT which keeps the current classifier unchanged.", "text": "bayesian fields naive bayes classifiers. paper introduce reasoning bayesian plicitly diagrams reason properties fiers. specifically converting show theoretically perimentally tractable size even intractable odds tractable sifiers algorithm test equivalence sifiers them. also show number additional results including classifiers induced naive bayes classifier allowable current classify number usually ability disease example variables network nario three different network pregnancy. test results pending results formal follows. fines probability able called known attributes. known instance. moreover stantiation probability bayesian inducing viewed instance follows otherwise. called classifier complexity. results real-world scalability applications odds mostly abled tractability plans extend discuss beyond proposed framework con­ sifiers. cluding remarks. proofs appendix simplest work classifiers induced contains network attributes nodes edges exist network. shown figure classify compute ever ease computations compute probability given pr/) given naive bayes network binary subset instantiation uninstantiated attribute questions instances proach often infeasible instances. logical answer questions size constructed specific ordered tractable; objective network plest induced specifically bayes classifiers question network classifier gorithm provide attributes net\\vork induced however functions rephrase equivalence given naive bayes network class. define contains tained changing classifiers test ffv. same. theorem allows verifying logo' theorem gives count number equiv­ alence close section crucial converts consider network would like change attribute without weights wu=-ve classifier still maximum number distinct fiers shown figure sents naive bayes classifier probability figure variable binary dered binary decision researched discuss representation posed earlier suppose fier induced {we}) threshold goal build represents respect order state algorithm plain observations first attributes path root root sub--odd nif> {we.}) obtained updating note output naive bayes classifier given instance tained f}.;¢ {we.}). cause differ prior log-odds theorem classifiers logo algorithm equivalence reached compute equivalence interval compute every node inductively identify caches algorithm k-th cache store nodes depth cache tervals. already logo built path also reaches algorithm returns sents naive bayes classifier attribute built recursively build-sub-odd shown algorithm procedure ffr� represents logo instantiation prior log-ndds next theorem upper bound gives theoretical number nodes time complexity algorithm theorem appendix therefore tributes space exponential significant compared nential handled experimental required theoretical sifiers finally depend attribute following heuristics show experimental results random real-world using algorithm first part experiment represent nary attributes prior log-ddds dence naive bayes network translated uniform probability meaning generate table second column results shows number instances i.e. third column shows theoretical upper bound number fourth nodes odds built using random attribute orders. two-thirds attributes evidence i.e. difference impact probabilities odds built using attribute orders ascending fifth sixth columns number nodes average bound improvement orders. second part experiment naive bayes represent real-world naive bayes networks constructed obtained learning also find intervals idence attribute unchanged intervals attribute child root node childe con­ tains allowable whi�h keep classifier therefore plicitly orems building using algorithm complexity number attributes actual operations supported decision diagram package vlsi. operations answer queries. number positive classifiers perform equivalence tant operations sifiers network sifying instances. helpful whether rounding instance. attribute classification ability figure network. test want know adding particular given beneficial current results applying tests test potentially support absence moreover classification outputs duced different learning non-binary made restriction able naive bayes network case non�binary mapping likely given extensions need multiple ferent values conceptually cardinality rithm building instead node compute gion whose dimension", "year": 2012}