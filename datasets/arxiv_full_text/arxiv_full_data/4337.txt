{"title": "The Approximation of the Dissimilarity Projection", "tag": ["stat.ML", "cs.CV"], "abstract": "Diffusion magnetic resonance imaging (dMRI) data allow to reconstruct the 3D pathways of axons within the white matter of the brain as a tractography. The analysis of tractographies has drawn attention from the machine learning and pattern recognition communities providing novel challenges such as finding an appropriate representation space for the data. Many of the current learning algorithms require the input to be from a vectorial space. This requirement contrasts with the intrinsic nature of the tractography because its basic elements, called streamlines or tracks, have different lengths and different number of points and for this reason they cannot be directly represented in a common vectorial space. In this work we propose the adoption of the dissimilarity representation which is an Euclidean embedding technique defined by selecting a set of streamlines called prototypes and then mapping any new streamline to the vector of distances from prototypes. We investigate the degree of approximation of this projection under different prototype selection policies and prototype set sizes in order to characterise its use on tractography data. Additionally we propose the use of a scalable approximation of the most effective prototype selection policy that provides fast and accurate dissimilarity approximations of complete tractographies.", "text": "diﬀusion magnetic resonance imaging data allow reconstruct pathways axons within white matter brain tractography. analysis tractographies drawn attention machine learning pattern recognition communities providing novel challenges ﬁnding appropriate representation space data. many current learning algorithms require input vectorial space. requirement contrasts intrinsic nature tractography basic elements called streamlines tracks diﬀerent lengths diﬀerent number points reason cannot directly represented common vectorial space. work propose adoption dissimilarity representation euclidean embedding technique deﬁned selecting streamlines called prototypes mapping streamline vector distances prototypes. investigate degree approximation projection diﬀerent prototype selection policies prototype sizes order characterise tractography data. additionally propose scalable approximation eﬀective prototype selection policy provides fast accurate dissimilarity approximations complete tractographies. deterministic tractography algorithms reconstruct white matter ﬁber tracts streamlines also known tracks diﬀusion magnetic resonance imaging data. streamline mathematical approximation thousands neuronal axons expressing anatomical connectivity different areas brain figure recently increase attention analysing dmri/tractography data means machine learning pattern recognition methods e.g. methods often require data vectorial space case streamlines. streamlines polylines space diﬀerent lengths numbers points. goal work investigate features limits speciﬁc euclidean embedding i.e. dissimilarity representation recently applied analysis tractography data dissimilarity representation euclidean embedding technique deﬁned selecting objects called prototypes mapping object vector distances prototypes. representation usually presented context classiﬁcation clustering problems. lossy transformation sense information lost projecting data dissimilarity space. best knowledge loss i.e. degree approximation received little attention literature. approximation studied decide among competing prototype selection policies classiﬁcation tasks. work interested assessing controlling loss without restriction classiﬁcation scenario. work motivated practical applications executing common algorithms like spatial queries clustering classiﬁcation large collections objects natural vectorial space representation. lack vectorial representation avoids algorithms computationally eﬃcient implementations. dissimilarity space representation could provide vectorial representation reason crucial assess degree approximation introduced. besides characterisation propose stochastic approximation optimal algorithm prototype selection scales well large datasets. scalability issue primary importance tractographies given full following present concise formal description dissimilarity projection together notion approximation quantify accurate representation additionally introduce three strategies prototype selection compared section dissimilarity projection space objects interest e.g. streamlines probability distribution distance function objects note assumed necessarily metric. ˜xp} ﬁnite. call objects corresponding distances dissimilarity representation space claim good dissimilarity representation must able accurately preserve partial order distances i.e. practical cases unknown ﬁnite sample available. approximate sample correlation accurate approximation relative distances objects results values zero close literature euclidean embeddings metric spaces term distortion used representing relation distances original space corresponding ones projected space. embedding interesting embedding metric spaces described based ideas similar dissimilarity representation advantage providing theoretical bound distortion. unfortunately embedding computationally expensive used practice. claim correlation distortion target slightly diﬀerent aspects embedding quality ﬁrst focussing averaged diﬀerences original projected space second worst case scenario. reason claim that context machine learning pattern recognition applications correlation appropriate measure. deﬁnition prototypes goal minimising loss dissimilarity projection open issue dissimilarity space representation literature. context classiﬁcation problems policy random selection prototypes proved useful certain assumptions following address issue choosing prototypes order achieve desired degree approximation restrict classiﬁcation case only. deﬁne discuss following policies prototype selection random selection farthest ﬁrst traversal subset farthest ﬁrst policies parametric respect i.e. number prototypes. note sampling without replacement identical prototypes provide redundant i.e. useless information. policy ﬁrst proposed seeding clustering algorithms. policy lowest computational complexity smallest \u0001-cover size k-center problem known np-hard i.e. eﬃcient algorithm devised always returns optimal answer. nevertheless known close optimal solution following sense solution returned optimal solution maxx∈s maxx∈s moreover metric spaces algorithm better ratio must np-hard complexity. unfortunately becomes large prototype selection policy becomes impractical. context radial basis function networks initialisation scalable approximation algorithm called subset farthest ﬁrst proposed approximation also claimed reduce chances select outliers lead poor representation large datasets. policy sample order select prototypes. proved hypothesis clusters probability representative clusters sample pe−m/p. computational complexity note large datasets small prototype selection policy much lower computational cost fft. following describe assessment degree approximation dissimilarity representation across diﬀerent prototype selection policies diﬀerent numbers prototypes. investigate trade-oﬀ accuracy computational cost. experiments carried simulated data real tractographies reconstructed dmri recordings human brain. selection prototypes according diﬀerent policies explained section chose order high probability accurately representing subset. dataset projected given metric space \u0001-cover deﬁned distance point dissimilarity space. correlation distances original space corresponding distances projected space estimated computing repetitions simulated dataset. average correlation standard deviation prototype selection strategy shown figure estimated dissimilarity representation tractography data dmri recordings facility cognition brain sciences unit cambridge dataset consisted healthy subjects; signiﬁcantly higher correlation random sampling numbers prototypes considered. conﬁrmed selection policy accurate approximation policy tractogracurrent dmri recording techniques. case impractical computed requires approximately minutes standard desktop computer single repetition cost computing instead case streamlines computational cost depends number prototypes. took seconds standard streamlines signiﬁcantly outperformed random policy reached highest correlation average note ﬁgures presented section refers data subject dmri dataset. conducted experiments subjects obtaining equivalent results. code reproduce experiments available https//github.com/emanuele/prni_dissimilarity open source license. document investigated degree approximation dissimilarity representation goal preserving relative distances streamlines within tractographies. empirical assessment conducted diﬀerent datasets various prototype selection methods. results simulated data real tractography data reached correlation comparing diﬀerent prototype selection policies found small advantage number prototypes always outperformed random policy. moreover since computational cost increase size dataset number prototypes observed policy easily computed standard computer even advocate dissimilarity approximation euclidean embedding tractography data machine learning pattern recognition applications. moreover strongly suggest policy obtain eﬃcient eﬀective selection prototypes.", "year": 2015}