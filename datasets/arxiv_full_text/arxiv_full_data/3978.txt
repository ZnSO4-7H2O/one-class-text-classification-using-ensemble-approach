{"title": "Using CODEQ to Train Feed-forward Neural Networks", "tag": ["cs.NE", "cs.AI"], "abstract": "CODEQ is a new, population-based meta-heuristic algorithm that is a hybrid of concepts from chaotic search, opposition-based learning, differential evolution and quantum mechanics. CODEQ has successfully been used to solve different types of problems (e.g. constrained, integer-programming, engineering) with excellent results. In this paper, CODEQ is used to train feed-forward neural networks. The proposed method is compared with particle swarm optimization and differential evolution algorithms on three data sets with encouraging results.", "text": "abstract. codeq population-based meta-heuristic algorithm hybrid concepts chaotic search opposition-based learning differential evolution quantum mechanics. codeq successfully used solve different types problems excellent results. paper codeq used train feed-forward neural networks. proposed method compared particle swarm optimization differential evolution algorithms three data sets encouraging results. artificial neural networks provide learn arbitrary mapping between data sets. neural network contains number adjustable parameters called weights biases. data sets consisting input patterns corresponding output values used train network. objective training neural network minimize mapping error difference output value specified data output network given corresponding input pattern. local global optimization methods used train anns. popular training methods variants gradient based back-propagation algorithms back propagation conjugate gradient etc) local methods. local search algorithms depend initial conditions prone trapped local optimum. address limitations local search methods global search approaches used train anns. global optimizers particle swarm optimization differential evolution successfully applied problem training anns motivated advantages population-based methods recently-proposed parameter-free populaton-based algorithm called codeq used train feed-forward anns. codeq metaheuristic approach built based concepts chaotic search opposition-based learning quantum mechanics. performance codeq already investigated compared well-known population-based optimization approaches applied eleven benchmark functions results show codeq provides excellent results added advantage parameter tuning. application codeq constrained problems investigated omran salman encouraging results. furthermore codeq successfully used solve integer programming problems reminder paper organized follows section provides overview codeq. proposed method presented section data sets measure performance different approaches provided section results experiments presented section finally section concludes paper. codeq floating-point encoded optimization algorithm global optimization continuous spaces. thus used within weight bias spaces feed-forward neural network. network training vector consists network weights biases wit… wnit bit…bbit objective function needs minimized training mean squared error feed-forward neural network. calculated follows estimated values actual value proposed method tested three different data sets model parameters optimized order find best solution. addition data divided training testing set. training data used train network optimize weights biases. testing data used test optimized parameters. data sets follow house data estimate median value owner occupied homes boston suburbs given neighborhoods attributes. samples divided samples used train model samples used validation. price price data consists west texas crude spot price terms different parameters include crude production crude supply crude demand refinery capacities throughput. data used study starts january- december-. order capture effect combined effects model built creating indices factor normalized production. demand supply level normalized average monthly production. data consists samples samples user training remaining used validate model. iris iris data classify iris flowers based four attributes output three different flower types. data consists samples used training remaining used validate model. section compares performance codeq particle swarm optimization self-adaptive differential evolution version control parameters self-adaptive results show generally outperformed evolutionary algorithms literature applied benchmark functions results reported section averages standard deviations simulations. simulation allowed evaluations objective function using population size individuals order make fair comparison initial population used algorithms. statistically significant best solutions shown bold table shows results data sets include training testing data sets. shown table clearly shown codeq algorithm best estimation weights biases result minimum values shown table training data testing data set. example data testing data gives best value using codeq algorithm compared algorithms. noted better check testing data since data used optimize weight biases values hence used prediction purposes. addition figure shows summary network training data sets data sets. clearly shown codeq algorithm outperform paper codeq used train feed-forward neural networks. proposed method compared three data sets. results showed codeq outperformed approaches. future work study effect using local search algorithm within codeq train anns. according preliminary results using back-propagation training method refine best vector iteration codeq yields promising results.", "year": 2010}