{"title": "Recurrent Instance Segmentation", "tag": ["cs.CV", "cs.AI"], "abstract": "Instance segmentation is the problem of detecting and delineating each distinct object of interest appearing in an image. Current instance segmentation approaches consist of ensembles of modules that are trained independently of each other, thus missing opportunities for joint learning. Here we propose a new instance segmentation paradigm consisting in an end-to-end method that learns how to segment instances sequentially. The model is based on a recurrent neural network that sequentially finds objects and their segmentations one at a time. This net is provided with a spatial memory that keeps track of what pixels have been explained and allows occlusion handling. In order to train the model we designed a principled loss function that accurately represents the properties of the instance segmentation problem. In the experiments carried out, we found that our method outperforms recent approaches on multiple person segmentation, and all state of the art approaches on the Plant Phenotyping dataset for leaf counting.", "text": "abstract. instance segmentation problem detecting delineating distinct object interest appearing image. current instance segmentation approaches consist ensembles modules trained independently other thus missing opportunities joint learning. propose instance segmentation paradigm consisting end-to-end method learns segment instances sequentially. model based recurrent neural network sequentially ﬁnds objects segmentations time. provided spatial memory keeps track pixels explained allows occlusion handling. order train model designed principled loss function accurately represents properties instance segmentation problem. experiments carried found method outperforms recent approaches multiple person segmentation state approaches plant phenotyping dataset leaf counting. instance segmentation automatic delineation different objects appearing image problem within computer vision attracted fair amount attention. interest motivated potential applicability whole range scenarios stimulating technical challenges poses. regarding former segmenting instance level useful many tasks ranging allowing robots segment particular object order grasp highlighting enhancing outline objects partially sighted wearing smart specs counting elements image interest right wide range applications. example industrial processes require number elements produced knowing number people attended demonstration counting number infected healthy blood cells blood sample required medical procedures malaria detection instance segmentation challenging pixel-level learning problems semantic segmentation deals classifying pixel image given classes. there pixel belong predeﬁned groups whereas instance segmentation number groups unknown priori. difference exacerbates problem semantic segmentation evaluate prediction pixel-wise instance segmentation requires clustering pixels evaluated loss function invariant permutation assignment leads complexities learning models. hence instance segmentation remained difﬁcult problem solve. approaches proposed instance level segmentation based pipeline modules whose learning process carried independent other. them rely module object proposal followed another implementing object recognition segmentation detected patches. common problem piecewise learning methods module learn accommodate outputs modules. another drawback cases often necessary deﬁne independent loss function module places burden practitioner decide convenient representations data intermediate stages pipeline. issues take different route develop fresh end-to-end model able learn whole instance-segmentation process. magnitude task study focus problem class-speciﬁc instance segmentation. assume model segments instances belong class excluding classiﬁcation stages. solution problem useful right example segment count people images consider also ﬁrst step towards general semantic learning systems segment classify different kinds instances. approach propose partially inspired humans count elements scene. known humans count sequentially using accurate spatial memory order keep track accounted locations. driven insight purpose build learning model capable segmenting instances object image sequentially keeping current state internal memory. order achieve this rely recurrent neural networks exhibit properties discussed ability produce sequential output ability keep state memory along sequence. based rnns containing convolutional layers derivation principled loss function problem. assess capabilities model conducting experiments; segmentation multiple people plant-leaves segmentation counting. instance segmentation formulated conjunction semantic segmentation object detection example authors proposed model integrates information obtained pixel segment object levels. instance segmentation requires capacity object detection approaches separate instances ability semantic segmentation methods produce pixel-wise predictions hence delineation shape objects. progress instance segmentation methods thus limited advances made object detection semantic segmentation. recent breakthrough object detection region-based approach consists using region proposal method produce large varied sized object proposals image extracting features means ﬁnally classifying resultant feature vectors. several approaches instance segmentation build method. multiscale combinatorial grouping region proposal method extract candidates followed region reﬁnement process. former work authors perform non-maximum suppression candidates order remove duplicates combine coarse information obtained superpixels extracted image order segment instances. latter work output reﬁned means exemplar-based shape prediction graph-cut. approaches produced state results instance segmentation. however suffer common drawback want avoid consist ensemble modules trained independently other. semantic segmentation methods seen signiﬁcant improvement recently based ﬁrst work proposed fully convolutional network produces pixel-wise predictions followed works improve delineation predicted objects using conditional random fields work builds instance segmentation model standing previous approaches. based predicting pixel-wise instances locations network applying clustering method post-processing step number clusters predicted another cnn. problem approach optimizing direct instance segmentation measure relies surrogate loss function based pixel distances object positions. problem associated instance segmentation related lack order among instances images several works overcome problem inferring exploiting depth information order instances. model means markov random field cnn. advantage approach occlusion objects explicitly modeled. disadvantage approach beneﬁcial instances appear similar depth example image containing sport team many players together. unlike previous approaches propose paradigm instance segmentation based learning segment instances sequentially letting model decide order instances image. recurrent neural networks powerful learning models. power resides capacity keep state memory model able store considers relevant events towards minimizing given loss function. also versatile applied arbitrary input output sequence sizes. properties successful application rnns wide range tasks machine translation handwriting recognition conversational models among others. rnns also useful obtaining variable length information static images. example draw variational auto-encoder learning generate images encoder decoder rnns image generation process sequential. image captioning another application beneﬁted rnns images. examples based using obtaining meaningful representation image introduced produces word iteration. another example involving biological images authors explore combination convolutional layers lstms order predict protein subcellular compartment belongs authors predict bounding delimiting human face iteration. approach shares motivations. main difference approaches consider regression problem producing iteration scalars specify bounding instance whereas consider pixel-wise classiﬁcation problem. authors present several recurrent structures track segment objects videos. finally worth mentioning approach despite consists greedy sequential algorithm learning several objects image. attention based approaches consist models capability deciding time part input look order perform task. recently shown impressive performance several tasks like image generation object recognition image caption generation approaches divided main categories hard soft attention mechanisms. hard attention mechanisms decide part instance process time totally ignoring remainder contrary soft attention mechanisms decide time probability distribution input indicating attention part must receive. latter wholly differentiable thus optimized backpropagation approach resembles attention models sense cases model selects different parts input successive iterations. attention based models different approach apply attention mechanisms means task whereas approach attention instance time target for. section describe inference process approach performs well structural elements compose process inference stage depicted described follows image height width rh×w×c taken input fully convolutional network described composed sequence convolutional max-pooling layers preserve spatial information inner representations image. output network rh×w×d represents d-dimensional features extracted pixel size smaller size input image subsampling effect described network. output input iterations sequence. beginning sequence initial inner state initialized ﬁrst iteration produces segmentation instances image together indicator informs conﬁdence prediction order stopping condition. simultaneously updates inner state account recent segmented instance. then inputs inner state model outputs another segmented instance conﬁdence score. process keeps iterating conﬁdence score drops certain level model stops ideally segmented instances image. sequential nature model allows deal common instance segmentation problems. particular implicitly model occlusion segment nonoccluded instances ﬁrst keep state regions image already segmented order detect occluded objects. another purpose state allow model consider potential relationships different instances image. example ﬁrst iteration instance person embracing something segmented information somehow kept state subsequent iterations might increase plausibility another person embraced ﬁrst one. structure approach composed fully convolutional network followed function transform state segmentation instance conﬁdence score ﬁnally loss function evaluates quality predictions optimize. ﬁrst components long short-term memory networks stood recurrent structures able prevent vanishing gradient problem. indeed chosen model works reviewed sec. achieved outstanding results. section build lstm unit perform changes structure adapt characteristics problem. problem described observe input model lattice output also lattice. problems characteristics semantic segmentation optical often tackled using structures based convolutions intermediate representations images preserve spatial information. problem inner state recurrent units preserves spatial information well. convolutional versions rnns particular convolutional long short-term memory units. represents element-wise product operator rh×w×d gates rh×w×d represents memory recurrent unit amount memory used pixel ﬁlter weights dimensionality size ﬁlter bias terms d-dimensional vector repeated across height width. refer diagrams deﬁnitions presented detailed explanation lstm update equations follows. also provide diagram illustrating appendix sec. note primary aspect keeping memory state allow model keep account pixels image already segmented previous iterations process. naturally done applying convolutions state. also stack convlstm units learning complex relationships. advantages convlstm respect regular lstm hand hand advantages convolutional layers respect linear layers suitable learning ﬁlters useful spatially invariant inputs images require less memory parameters. fact memory required independent size input. similar recurrent unit recently proposed context weather forecasting region. output indicates pixels compose object segmented current iteration. second output estimated probability current segmented candidate object. output stopping condition. following describe functions supporting presentation schematic view given fig. function produces ﬁrst output described sequence layers discriminating instance ﬁltering everything else. firstly convolutional layer maps channels hidden state output channel using ﬁlters. followed log-softmax layer normalizes input across pixels flsmi applies logarithm. result pixel value interval exponentiation values leads competing mechanism potential inhibiting pixels belong current instance segmented. following that layer adds learned bias term input data. purpose layer learn threshold ﬁlters pixels selected present instance. then sigmoid transformation applied pixelwise. hence resultant pixel values interval required. finally upsample resultant back original size input image order help understand effect layers visualize sec. appendix inner representations captured model different stages described pipeline. function encodes relationship current state conﬁdence predicted candidate consists simply max-pooling linear layer followed sigmoid function. choosing loss function accurately reﬂects objective want achieve model able learn given task. order present loss function ﬁrst notation. training stage provided training composed labeled images. denote image rh×w×c simplicity consider size images. annotation }h×w containing segmentation masks instance image. point note labels dimension last index depends image image different number instances. ˆni} conﬁdence score associated image inference time number elements masks predicted depends conﬁdence values network stops producing outputs time training time predeﬁne length predicted sequence. given know length i-th ground truth annotation length predicted sequence network learn stop. case number elements predicted sequence necessarily equal elements corresponding ground truth given model could underestimate overestimate number objects. represent scenario arrange elements bipartite graph edge ˆyˆt cost associated intersection union ˆyˆt. similarity measure deﬁned maximum intersection union correspondence elements elements ˆy+y−ˆyy used relaxed version intersection fiou union allows input take values continuous interval function accounts ﬁrst predicted masks ignoring remainder case model produces instances. elements determine optimal matching elements ˆyˆt assigned δˆtt constraint deﬁned impedes ground truth instance assigned predicted instances vice versa. case ground truth δˆtt optimal matching found efﬁciently means hungarian algorithm similar vein coverage loss described similar form predictions discrete problem posed integer program. end-to-end learning possible loss function point-wise minimum continuous functions thus direction decrease loss function point computed following steps figuring function achieves minimum point. computing gradient function. here hungarian algorithm employed described ﬁrst step function achieves minimum point. then gradient function computed. details process shown sec. appendix. need account conﬁdence scores predicted model. consider ideal output predict number instances segmented equal less total number instances otherwise taking account propose following loss function fbce log) binary cross entropy iverson bracket condition within brackets true otherwise. finally hyperparameter ponders importance second term respect ﬁrst one. perform kinds experiments study capabilities approach segment count instances. ﬁrst experiment focus multiinstance subject segmentation second focus segmenting counting leaves plants. presenting results ﬁrst describe implementations details common experiments. recurrent stage composed convlstm layers output ﬁrst convlstm acts input second one. stage followed spatial inhibition module produces conﬁdence score together instance segmentation mask. resultant prediction evaluated according loss function deﬁned training stage parameters recurrent structure learned backpropagation time. order prevent exploding gradient effect clipped gradients elements maximum absolute value adam optimization algorithm training whole network setting initial learning rate multiplying training error plateaus. neither dropout regularization observe overﬁtting preliminary experiments. used image batch. weights recurrent structure initialized random sampling uniformly interval exception bias terms forget gate initialized allowing default backpropagate error previous iterations sequence. perform curriculum learning gradually increasing number objects required segmented images. beginning recurrent iterations network expected learn extract objects image even more. training procedure converges increment number keep iterating process. inference time assign pixel instance predicted value higher nevertheless observe predicted pixels values usually saturated either close close although uncommon might happen pixel assigned instance sequence. whenever case assign pixel instance belonging earlier iteration. finally produced sequence terminates whenever conﬁdence score predicted network assess quality approach detecting segmenting individual subjects real images. multiple person segmentation extremely challenging people pictures present high variations different posture gender clothing location depth within scene among others. order learn task integrated model fcn-s network developed fcn-s network composed series layers adding skips produce result image representation whose size smaller original image. followed upsampling layer resizes representation back original image size. modify structure putting convlstm upsampling layer integrated subsequent spatial inhibition module shown fig. following works padding and/or resize input image resultant size consequence size input convlstm layers well hidden states dimensionality number features extracted pixel. gates convlstm layers convolutions. training used mscoco dataset training images pascal dataset. ﬁrst ﬁxed weights fcn-s except last layer learned parameters last layer together convlstm spatial inhibition module following procedure described sec. ﬁne-tuned whole network using learning rate convergence. observed predictions obtained recurrent instance segmentation promising coarse respect boundaries segmented subjects. expected convlstm operates resolution representation image. order amend this used post-processing method produced segments. call approach ris+crf. compare approaches recent instance segmentation methods presented already introduced sec. also compare baseline consisting performing proposal generation semantic segmentation result produced fcn-s used faster r-cnn proposal generation method. following previous works measure predictive performance methods respect pascal validation using standard metrics average precision predicted regions overlapping ground truth masks denoted averaging different degrees overlapping denoted rave. show results table observe achieves comparable results state approaches. using post-processing method results improve outperforming competing methods. also provide qualitative results fig. extensively sec. appendix. automatic leaf segmentation counting useful tasks plant phenotyping applications lead improvements seed production plant breeders processes. section computer vision problems plant phenotyping dataset particular utilize subset plants biggest subset available contains top-down view images size each shown fig. training composed images annotations available. remaining images left testing purposes. images challenging present high range variations occasional leaf occlusions varied backgrounds several slightly blurred images lack focus complex leaf shapes. limited number training images driven augment data considering valid transformations images. apply transformations rotating image random angle ﬂipping resultant image probability learn fully convolutional network scratch. structure composed sequence convolutional layers followed rectiﬁed linear unit. ﬁrst convolution learns ﬁlters following four learn ﬁlters each. sequence convolutions produces representation image input recurrent stage model. stack convlstms gates convolutional layers. gatersleben firstly segments foreground background using histograms supervised learning model. secondly identiﬁes leaves centre points leaves split points applying unsupervised learning methods segments individual leaves applying graph-based noise removal region growing techniques. nottingham firstly slic applied image order superpixels. plant extracted background. superpixels centroids leaf identiﬁed ﬁnding local maxima distance foreground. finally leaves segmented applying watershed transform. wageningen performs foreground segmentation using neural network followed series image processing transformations including inverse distance image transform detected foreground using watershed transform segment leaves individually. prian first features learned unsupervised log-polar representation image. then support vector regression model applied resultant features order predict number leaves. competing methods explicitly designed perform well particular plant leaf segmentation counting problems containing heuristics valid domain. contrary applicability model broad. table results obtained cvppp dataset according measures difference count absolute difference count symmetric best dice reported mean standard deviation results obtained shown table using measures reported cvppp organization order compare submitted solutions. difference count difference predicted number leaves ground truth |dic| absolute value averaged across images symmetric best dice deﬁned provides measure accuracy segmentation instances. regarding leaf counting observe approach signiﬁcantly outperforms competing methods designed particular problem. regard segmentation leaves approach obtains comparable results respect competitors outperform approach. hypothesize despite data augmentation process follow amount original images available training small learn segment wide variety leaf shapes scratch. scarcity training data smaller impact competing methods given contain heuristics prior information problem. also visualized fig. representation network keeps memory sequence produced. column denoted shows summary function hidden state second convlstm layer. summary function consists absolute values across channels pixel. column denoted corresponds output produced network. observe time advances state modiﬁed take account parts image visited. also inspected value cell observed clear clues. paper proposed instance segmentation paradigm characterized sequential nature. similarly human beings counting objects scene model proceeds sequentially segmenting instance scene time. resulting model integrates single pipeline required functions segment instances. functions deﬁned parameters jointly learned end-to-end. aspect model recurrent structure able track visited areas image well handle occlusion among instances. another aspect deﬁnition loss function accurately represents instance segmentation objective achieve. experiments carried multiple person segmentation leaf counting show approach outperforms state methods. qualitative results show state recurrent stage contains information regarding visited instances sequence. primary objective paper show learning end-to-end instance segmentation possible means recurrent neural network. nevertheless variations architectural choices could lead even better results. tried variety alternatives adding prediction masks extra input recurrent unit. also tried alternatives fiou log-likelihood. results obtained either case better ones achieved model described sec. analysis alternative architectures left future work. several extensions carried approach. allowing model classify segmented instance time. done generalizing loss function another extension consists integrating module layer end-to-end model another interesting line research investigating recurrent structures could good even better convlstms instance segmentation. finally extension model exploiting co-occurrence objects parts objects attributes could promising research direction.", "year": 2015}