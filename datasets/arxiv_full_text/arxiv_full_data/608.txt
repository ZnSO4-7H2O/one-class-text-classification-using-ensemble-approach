{"title": "Simplified End-to-End MMI Training and Voting for ASR", "tag": ["cs.LG", "cs.CL", "cs.NE"], "abstract": "A simplified speech recognition system that uses the maximum mutual information (MMI) criterion is considered. End-to-end training using gradient descent is suggested, similarly to the training of connectionist temporal classification (CTC). We use an MMI criterion with a simple language model in the training stage, and a standard HMM decoder. Our method compares favorably to CTC in terms of performance, robustness, decoding time, disk footprint and quality of alignments. The good alignments enable the use of a straightforward ensemble method, obtained by simply averaging the predictions of several neural network models, that were trained separately end-to-end. The ensemble method yields a considerable reduction in the word error rate.", "text": "simpliﬁed speech recognition system uses maximum mutual information criterion considered. end-to-end training using gradient descent suggested similarly training connectionist temporal classiﬁcation criterion simple language model training stage standard decoder. method compares favorably terms performance robustness decoding time disk footprint quality alignments. good alignments enable straightforward ensemble method obtained simply averaging predictions several neural network models trained separately end-to-end. ensemble method yields considerable reduction word error rate. index terms neural networks deep learning hidden markov models connectionist temporal classiﬁcation speech recognition hybrid approach hidden markov model deep neural network presents stateof-the-art results automatic speech recognition system highly complicated. connectionist temporal classiﬁcation hand suggests simple scalable training procedure. shown enough data achieve state-of-the-art results recently sequenceto-sequence models attention shown promising results without need external language model decoding minimizing disk footprint attention models still fail surpass phoneme-based models external applied methods also results). addition attention models impose long training times moreover since attention models massively prone overﬁtting several heuristics take place order obtain good results however issues ctc. first exact decoding computationally intractable needs approximation improve performance blank suppression method prior normalization usually applied datadependent addition excel providing good alignment input output sequences posing challenges ensemble applications lattice-free training using maximum mutual information criterion suggested. shown lattice-free training powerful technique. however training procedure still requires hmm-gmm systems decision trees uses multiple-states context dependent senones instead one-state characters context independent phonemes typically used systems. hence system much complicated compared larger disk footprint requirements. paper suggest simpliﬁed training method using criterion. similarly simple end-to-end training one-state context independent phonetic system. however unlike derivation formulated using approach simple training stage. resulting objective function similar diﬀerences. first present training method using criterion. second allow integration scalable objective function. decoding performed using standard decoder. weighted ﬁnite state transducer approach discuss implementation issues. speech recognition results wall street journal corpus compare favorably ctc. method presents faster decoding times reduction disk footprint decoder graph. another advantage model fact provides reliable alignment input output sequences. allows simple eﬀective voting method obtained simply averaging outputs several trained dnns. demonstrate relative reduction word error rate compared single model. training procedure train model using database pairs n-th observation sequence associated transcript. first values transition probabilities estimated training text using train remaining model parameters criterion. goal maximize loglikelihood transcript given observation sequence. estimate ψmmi parameter vector given consider phonetic hidden markov model word sentence represented left right whose states phonemes. blank state inserted words reserve states sentence start end. assume word contains consecutive identical phonemes blank state inserted in-between. {ot} sequence acoustic feature vectors representing sentence. deﬁne time-extended feature vector integer assume left right sequence {˜ot}. underlying hidden state sequence {st} total number possible states. joint probability {˜ot}t {st}t transcript sentence concatenated sequence word states. example consider sentence transcript {start blank blank blank end}. sentence transcript deﬁnes left right associated sentence. possible state phonetic model denotes self transition probability denotes probability transition next state transcript figure describes deﬁned sentence given sequence states associated sentence {st}t corresponding sentence transcript obtained erasing repeated states formulate criterion need deﬁne probabilistic model also deﬁnes distribution transcript random variable optimal solution would ground-truth used decoding stage would computationally infeasible. alternative solution degenerated model states n-grams given time process state remain probability make transition diﬀerent state probability multiplied transition probability n-grams states model. bi-grams model deﬁne probability later show bi-grams model already powerful. brevity describe standard decoder. integrate model wfst approach. wfst ﬁnite-state machine transition input symbol output symbol weight. wfst implemented library openfst based decoding method eesen ﬁrst build separate wfsts lexicon states. example grammar wfst possible sentences shown figure lexicon wfst encodes sequences lexicon units words. enforces occurrence blank state between words also identical phonemes. example shown figure wfst maps sequence frame-level states single lexicon unit. allows occurrences repetitive states proper weighting according trained transition probabilities. example shown figure finally compose graphs single graph refer hlg. inputs graph outputs neural network normalized priors. hmms calculations forward backward variables usually performed log-scale another possibility normalization technique implementation necessary combine approaches modiﬁcation method describe. time frame ﬁrst compute forward variables according original recursions log-scale subtract maximal value forward variables forward variable. simpler variant perform subtraction every certain time units. derivatives parameters easily obtained similarly. note values eytl constrained valid probabilities. satisfy constraint standard approach softmax layer output similar approach order constrain valid probablities. many disciplines ensemble methods proven highly eﬀective since acoustic inference decoding models little computation model combination attractive option voting scheme proposed ctc-based system using rover technique eﬀective voting scheme complicated requires full decoding pass model performing systems combination decoded hypothesis system. models provide good alignment input output sequences therefore simpler frame-level scores averaging would yield good results. since method provides good alignments propose simple voting scheme based averaging posteriors model. neither methods suggested worked well simple averaging. averaging transition probabilities priors yields little none gains therefore average posteriors. implemented model tensorﬂow loss function implemented samples mini-batch calculated parallel diﬀerent cores cpu. integrated feature extraction procedures eesen procedures tensorﬂow wfsts decoding procedures eesen. lattice-free training using criterion suggested. system uses multiple-states context dependent senones obtained using decision trees. suggested training procedure still incorporates hmm-gmm system order obtain alignments number reasons. first order split utterances chunks seconds training applied. second order constrain training model allowed predict state within small window around obtained alignment. -gram train used trained according alignments. system operates one-state context independent phonemes breaks free hmm-gmm systems. transition probabilities uniform whereas system learning provided gains performance. finally also train prior probabilities criterion also similar however derived estimate. also values transition probabilities states trained whereas here probabilities pre-trained states need trained acoustics. also allows convenient integration higher-level conducted experiments wall street journal corpus training data consists hours transcribed speech. almost training process architecture architecture layers bi-directional lstm cells without peephole connections training training cross validation. inputs -dimensional ﬁlterbank delta delta-delta coeﬃcients. features normalized mean variance speaker basis. operate phonemes-based system states. utterances training sorted lengths. mini-batch size adam optimizer initial learning rate gradient clipping value learning rate decay stopping criteria determined based validation test model eval test std. eesen std. std. eemmi bi-gram std. eemmi trigram ext. attention seqseq ext. ext. eemmi bi-gram ext. eemmi trigram ext. rover models ext. eemmi bi-grams eemmi bi-grams trigram ext. table various models corpus. baseline better eval used validation set. results table shows results eval sets. consider decoding lms. standard pruned trigram model extendedvocabulary pruned trigram model compare end-to-end model conditions. decoding performed using wfst prior normalization method model obtains comparable results ones reported consistent improvement eemmi using bi-grams train compared ctc. observed attention models inferior phonemes-based method. hybrid hmm-dnn model achieves wers .%/.% eval/dev sets using ﬁlterbank features. hybrid hmm-dnn model achieves wers .%/.% using enhanced speaker adaptation. latticefree approach achieves wers .%/.% also using enhanced speaker adaptation. epoch eemmi using diﬀerent train trigrams bi-grams uni-grams uniform. trigrams model achieves best results training process demanding bi-grams model figure shows obtained alignments utterance training set. demonstrates signiﬁcantly improved alignment eemmi compared peaky output distributions ctc. well established alignments enable simple voting scheme. models architecture described trained separately endto-end. best ensemble models yield considerable relative wers reduction eval test sets resulting wers reported table note simple posteriors averaging work well even using models identical architectures. werrs achieved using complicated voting scheme full decoding pass model. perform decoding once averaged outputs models. note eval used validation whereas eval sets test sets. figure shows posteriors segment utterance eval set. segment corresponds word dravo figure shows typical output distribution posteriors peaky time state axes. harms ability simple posteriors averaging several models. figure show posteriors single eemmi model ensemble models respectively. ensemble method substantially diminished variance states axis single model. decoder table shows comparison decoders eemmi standard demonstrate speedup decoding time. model’s decoder graph smaller ctc’s meaning model smaller disk footprint. shown graph size hybrid system operating senones decoding time times faster compared hybrid system. note parameters consume many diﬀerent approaches shrink number means decoder graph weakest link terms disk footprint. presented simpliﬁed end-to-end training method asr. method aligns general form training trained predict context independent phones. also system trained end-to-end without need pre-training hmm-gmm system. experimented several simple phonemes n-grams training shown bi-grams trigrams compare favorably corpus. moreover method presents better decoding times considerable reduction disk footprint compared hybrid systems. finally since method provides reliable alignments proposed simple voting method obtained simply averaging predictions several models. voting scheme provides considerable reduction wers. hybrid hmm-dnn speech recognizers outperform system terms wer. however lower implementation computational requirements proposed system considered applications. geoﬀrey hinton deng dong deep neural networks acoustic modeling speech recognition shared views four research groups ieee signal processing magazine vol. wayne xiong jasha droppo xuedong huang frank seide mike seltzer andreas stolcke dong geoﬀrey zweig achieving human parity conversational speech recognition arxiv preprint arxiv. alex graves santiago fern´andez faustino gomez j¨urgen schmidhuber connectionist temporal classiﬁcation labelling unsegmented sequence data recurrent neural networks proceedings international conference machine learning. awni hannun carl case jared casper bryan catanzaro greg diamos erich elsen ryan prenger sanjeev satheesh shubho sengupta deep speech scaling adam coates arxiv preprint end-to-end speech recognition arxiv. sundaram ananthanarayanan rishita anubhai deep speech end-toend speech recognition english mandarin international conference machine learning chorowski dmitriy serdyuk philemon brakel yoshua bengio end-to-end attention-based large vocabulary speech recognition acoustics speech signal processing ieee international conference ieee yonghui mike schuster zhifeng chen quoc mohammad norouzi wolfgang macherey maxim krikun yuan klaus macherey google’s neural machine translation system bridging huarxiv preprint machine translation arxiv. alex lamb anirudh goyal alias parth goyal ying zhang saizheng zhang aaron courville yoshua bengio professor forcing algorithm training recurrent networks advances neural information processing systems ha¸sim andrew senior kanishka ozan irsoy alex graves fran¸coise beaufays johan schalkwyk learning acoustic frame labeling speech recognition recurrent neural networks ieee international conference acoustics speech signal processing ieee yajie miao mohammad gowayyed florian metze eesen end-to-end speech recognition using deep models wfst-based decoding ieee workshop automatic speech recognition understanding december ha¸sim f´elix chaumont quitry tara acoustic modsainath kanishka elling cd-ctc-smbr lstm rnns automatic speech recognition understanding ieee workshop ieee lalit bahl peter brown peter souza robert mercer maximum mutual information estimation hidden markov model parameters speech recognition acoustics speech signal processing ieee international conference icassp’. ieee vol. ronan collobert christian puhrsch gabriel synnaeve wavletter end-to-end convnetbased speech recognition system neural information processing systems douglas paul janet baker design wall street journal-based corpus proceedings workshop speech natural language. association computational linguistics cyril allauzen michael riley johan schalkwyk wojciech skut mehryar mohri openfst general eﬃcient weighted ﬁnite-state transducer library. implementation application automata awni hannun carl case jared casper bryan catanzaro greg diamos erich elsen ryan prenger sanjeev satheesh shubho sengupta adam coates andrew deep speech scaling end-to-end speech recognition corr vol. abs/. jonathan fiscus post-processing system yield reduced word error rates recognizer output voting error reduction automatic speech recognition understanding proceedings. ieee workshop ieee cheng aur´elien bibaut mark laan relative performance ensemble methods deep convolutional neural netarxiv preprint works image classiﬁcation arxiv. daniel povey arnab ghoshal gilles boulianne kaldi speech recognition toolkit ieee workshop automatic speech recognition understanding. ieee signal processing society number epfl-conf-. mcgraw rohit prabhavalkar raziel alvarez personalized speech recognition mobile devices acoustics speech signal processing ieee international conference ieee", "year": 2017}