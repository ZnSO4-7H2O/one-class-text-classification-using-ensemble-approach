{"title": "Statistical modality tagging from rule-based annotations and  crowdsourcing", "tag": ["cs.CL", "cs.LG", "stat.ML", "I.2.7; I.2.6; I.5.1; I.5.4"], "abstract": "We explore training an automatic modality tagger. Modality is the attitude that a speaker might have toward an event or state. One of the main hurdles for training a linguistic tagger is gathering training data. This is particularly problematic for training a tagger for modality because modality triggers are sparse for the overwhelming majority of sentences. We investigate an approach to automatically training a modality tagger where we first gathered sentences based on a high-recall simple rule-based modality tagger and then provided these sentences to Mechanical Turk annotators for further annotation. We used the resulting set of training data to train a precise modality tagger using a multi-class SVM that delivers good performance.", "text": "explore training automatic modality tagger. modality attitude speaker might toward event state. main hurdles training linguistic tagger gathering training data. particularly problematic training tagger modality modality triggers sparse overwhelming majority sentences. investigate approach automatically training modality tagger ﬁrst gathered sentences based high-recall simple rule-based modality tagger provided sentences mechanical turk annotators annotation. used resulting training data train precise modality tagger using multi-class delivers good performance. deﬁne core cases modality john must john might john leave john leave many semanticists kratzer kaufmann deﬁne modality quantiﬁcation possible worlds. john might means exist possible worlds john goes. another view modality relates speaker’s attitude toward proposition modality might construed broadly include several types attitudes speaker wants express towards event state proposition. modality might indicate factivity evidentiality sentiment factivity related whether speaker wishes convey belief propositional content true i.e. whether actually obtains world not. distinguishes things happened things desires plans considers merely probable. evidentiality deals source information provide clues reliability information. speaker paper published within proceedings acl- workshop extra-propositional aspects meaning computational linguistics pages jeju republic korea july association computational linguistics ﬁrsthand knowledge reporting hearsay inferred indirect evidence? sentiment deals speaker’s positive negative feelings toward event state proposition. investigate automatically training modality tagger using multi-class support vector machines main hurdles training linguistic tagger gathering training data. particularly problematic training modality tagger modality triggers sparse overwhelming majority sentences. baker created modality tagger using semiautomatic approach creating rules rulebased tagger. pilot study revealed boost recall well naturally occurring proportion modality without annotated data precision. investigated approach ﬁrst gathered sentences based simple modality tagger provided sentences annotators annotation resulting annotated data also preserved level inter-annotator agreement example learning algorithms could take account training. finally resulting annotations used training modality tagger using svms gave high precision indicating success approach. section discusses related work. section discusses procedure gathering training data. section discusses machine learning setup features used train modality tagger presents experiments results. section concludes discusses future work. previous related work includes timeml involves modality annotation events factbank event mentions marked degree factuality. modality also important detection uncertainty hedging. conll shared task deals automatic detection uncertainty hedging wikipedia biomedical sentences. baker baker analyze eight modalities include belief require permit addition modalities focus paper. built rule-based modality tagger using semi-automatic approach create rules. earlier work differs work described paper emphasis creation automatic modality tagger using machine learning techniques. note annotation automatic tagging belief modality described detail considerable amount interest modality biomedical domain. negation uncertainty hedging annotated bioscope corpus along information words scope negation/uncertainty. shared task included track detecting assertion status medical problems clinical records. apostolova presents rule-based system detection negation speculation scopes using bioscope corpus. studies emphasize importance detecting uncertainty medical text summarization modality also received attention context certain applications. earlier work describing difﬁculty correctly translating modality using machine translation includes sigurd write rule based frameworks using alternate grammatical constructions passive improve rendering modal target language. murata analyze translation japanese english several systems showing often render present incorrectly progressive. authors trained support vector machine speciﬁcally handle modal constructions modal annotation approach part full translation system. textual entailment literature includes modalidentifying modalities annotation schemes. important determine whether text entails hypothesis. bar-haim include polarity based rules negation modality annotation rules. polarity rules based independent polarity lexicon annotation rules negation modality predicates based identifying modal verbs well conditional sentences modal adverbials. authors read modality parse trees directly using simple structural rules modiﬁers. section discuss procedure followed construct training data building automatic modality tagger. pilot study obtained modality tagger described english side urdu-english language pack. randomly selected sentences tagger labeled want modality posted amazon mechanical turk three different turkers marked sentences whether contained want modality. using majority rules turker judgment sentences marked want modality. also posted sentences tagger labeled want modality marked turkers want modality. therefore estimated precision type approach around hence able tagger gather training data. approach apply simple tagger ﬁrst pass positive examples subsequently handannotated using mturk. made sentence data enron email corpus derived construct simple tagger used lexicon modality trigger words constructed baker tagger essentially tags sentence word lexicon corresponding modality. wrote simple obvious ﬁlters handful exceptional cases arise fact sentences e-mail. example ﬁltered best wishes expressions otherwise would tagged want word wishes. words trigger modality occur different frequencies. training data dominated commonly occurring trigger words learned tagger would biased towards words. order ensure training data diverse examples containing many lexical triggers examples lexical trigger modality capped number sentences single trigger sentences selected simple tagger posted mturk annotation. turkers asked check indicating modality present sentence given modality expressed. check asked highlight target modality. table shows number sentences posted mturk modality. three turkers annotated sentence. restricted task turkers adults greater approval rating completed least hits mturk. paid sentences. since data annotated three turkers training data used examples least turkers agreed modality target modality. resulted examples. examples turkers agreeing unanimous agreement. kept track level agreement example http//bailando.sims.berkeley.edu/enron/enron.sql.gz data received personal communication more detailed statistics mturk annotations available section describe automatic modality tagger built using mturk annotations described section training data. section describes training evaluation data. section present machinery section describes features used train tagger. section present various experiments discuss results. section presents additional experiments using annotator conﬁdence. training used data presented section refer mturk data rest paper. evaluation selected part corpus expert annotated modality tags. ﬁrst used high-recall simple modality tagger described section select sentences modalities. sentences returned simple modality tagger expert removed ones fact modality. remaining sentences expert annotated target predicate. refer gold dataset paper. mturk gold datasets differ terms genres well annotators distribution modalities mturk gold annotations given table modalities context. tagging used yamcha sequence labeling system uses svmlight package classiﬁcation. used versus method multi-class classiﬁcation quadratic kernel value report recall precision word tokens corpus modality. also report -measure harmonic mean recision ecall. features used lexical features token level extracted without parsing relatively high accuracy. term context width denote window tokens whose features considered predicting given token. example context width means feature vector given token includes addition features tokens well prediction tokens experiments varying context width found context width gives optimal performance. results reported paper obtained context width token performed experiments using following lexical features wordstem word stem. wordlemma word lemma. word’s tag. isnumeric word numeric? verbtype modal/auxiliary/regular/nil whichmodal word modal verb used porter stemmer obtain stem word token. determine word lemma used in-house lemmatizer using dictionary morphological analysis obtain dictionary form word. obtained tags stanford tagger used tags determine verbtype whichmodal features. verbtype feature assigned value ‘nil’ word verb whichmodal feature assigned value ‘nil’ word modal verb. feature isnumeric binary feature denoting whether token contains digits not. experiments results section present experiments performed considering mturk annotations annotators agreed mturk annotations three annotators agreed equally correct annotations. present experiments applying differential weights annotations section performed -fold cross validation mturk data order select best feature conﬁguration best feature obtained wordstem whichm odal context width ﬁnding best performing feature context width conﬁguration exhaustive search feature space pruning away features proven useful results stages. table presents results obtained modality -fold cross validation. also trained model entire mturk data using best feature evaluated gold data. results obtained modality gold evaluation given table attribute lower performance gold dataset difference mturk data. mturk data entirely email threads whereas gold data contained sentences newswire letters blogs addition emails. furthermore annotation different finally distribution modalities datasets different. example ability modality merely mturk data compared gold data obtained reasonable performances effort want modalities performance modalities rather low. also gold dataset contained instances success none recognized tagger resulting recall precision success considered applicable assigned. annotation conﬁdence experiments mturk data contains sentence least three turkers agreed modality target modality. section investigate role annotation conﬁdence training automatic tagger. annotation conﬁdence denoted whether annotation agreed annotators unanimous. denote sentences annotators agreed three annotators agreed agr. present four training setups. ﬁrst setup train model using equal weights. setup used results presented section then train using respectively. then train model giving different cost values examples. svmlight package allows users input cost values training instance separately. tuned cost value examples found best value respectively. four setups used feature performed -fold cross validation mturk data ways tested combination tested agr. results experiments presented table also present results evaluating tagger trained whole mturk data setup gold annotation table tested presented table tested gold data presented table correspond results presented table table respectively. measure evaluations. also even evaluating high conﬁdent cases gave high gain recall percentage point loss precision. conjecture training instances quantity beats quality. another important observation increase performance using varied costs examples although dropped performance points cross-validation measure enron corpora gained points gold evaluation measure. results seem indicate differential weighting based annotator agreement might beneﬁcial impact training model applied wide range genres training model genre-speciﬁc data application data genre. differently using varied costs prevents genre over-ﬁtting. don’t full explanation difference behavior yet. plan explore future work. presented innovative combining high-recall simple tagger mechanical turk annotations produce training data modality tagger. show obtain good performance genre training corpus reasonable performance across genres also present experiments utilizing number agreeing turkers choose cost values training examples svm. future work plan work supported part johns hopkins human language technology center excellence. opinions ﬁndings conclusions recommendations expressed material authors necessarily reﬂect views sponsor. thank several anonymous reviewers constructive feedback.", "year": 2015}