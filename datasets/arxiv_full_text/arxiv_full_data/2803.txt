{"title": "Active Learning of Strict Partial Orders: A Case Study on Concept  Prerequisite Relations", "tag": ["cs.LG", "cs.AI", "stat.ML"], "abstract": "Strict partial order is a mathematical structure commonly seen in relational data. One obstacle to extracting such type of relations at scale is the lack of large-scale labels for building effective data-driven solutions. We develop an active learning framework for mining such relations subject to a strict order. Our approach incorporates relational reasoning not only in finding new unlabeled pairs whose labels can be deduced from an existing label set, but also in devising new query strategies that consider the relational structure of labels. Our experiments on concept prerequisite relations show our proposed framework can substantially improve the classification performance with the same query budget compared to other baseline approaches.", "text": "strict partial order mathematical structure commonly seen relational data. obstacle extracting type relations scale lack large scale labels building effective data-driven solutions. develop active learning framework mining relations subject strict order. approach incorporates relational reasoning ﬁnding unlabeled pairs whose labels deduced existing label also devising query strategies consider relational structure labels. experiments concept prerequisite relations show proposed framework substantially improve classiﬁcation performance query budget compared baseline approaches. pool-based active learning learning framework learning algorithm allowed access unlabeled examples labels examples goal learn good classiﬁer signiﬁcantly fewer labels actively directing queries valuable examples. typical setup active learning label dependency among labeled unlabeled examples considered. data knowledge real world often embodied prior relational structures. taking consideration structures building machine learning solutions necessary crucial goal paper investigate query strategies active learning strict partial order namely ground-truth labels examples constitute irreﬂexive transitive relation. paper develop efﬁcient effective algorithms extending popular query strategies used active learning work relational data. study following problem active learning context problem. given ﬁnite strict order type irreﬂexive transitive relation. strict order represented subset given unknown strict order oracle returns feature extractor hypothesis class predicts whether pair querying ﬁnite number pairs main focus develop reasonable query strategies active learning strict order exploiting knowledge classiﬁers trained limited number labeled examples deductive structures among pairwise relations. work also particular focus partial orders. strict order total large school called learning rank studied topic active learning setting learning rank relies binary classiﬁers probabilistic models consistent rule total order. approaches however limited sense principally modeling partial order classiﬁer consistent total order always non-zero lower bound error rate ground-truth partial order total order. active learning problem incorporating deductive relations strict order soliciting examples labeled non-trivial important. challenges motivating pursue direction explained three folds first example whose label deterministically reasoned labeled using properties strict orders need manual labeling statistical prediction. second probabilistic inference labels based independence hypothesis done conventional classiﬁer training proper deductive relations make labels examples dependent other. third order quantify valuable example querying combine uncertainty logic build proper representations. sound efﬁcient heuristics empirical success explored. related active learning work deals similar setting whereas equivalence relations considered instead. particularly made several crude approximations order expedite expected error calculation computational tractable level. approach design query strategies different perspective keeping efﬁciency central concerns. empirically study proposed active learning algorithm apply concept prerequisite learning problem goal predict whether concept prerequisite concept given pair although research efforts towards learning prerequisites mathematical nature prerequisite relation strict partial orders investigated. addition obstacle effective learning-based solutions problem lack large scale prerequisite labels. liang applied standard active learning problem without utilizing relation properties prerequisites. active learning methods tailored strict partial orders provide good opportunity tackle current challenges concept prerequisite learning. main contributions summarized follows first propose efﬁcient reasoning module monotonically calculating deductive closure assumption strict order. computational module useful general solutions need fast reasoning regard strict orders. second apply reasoning module extend popular active learning approaches handle relational data empirically achieve substantial improvements. ﬁrst attempt design active learning query strategies tailored strict partial orders. third proposed framework solve problem concept prerequisite learning approach appears successful data four educational domains whereas previous work exploited relational structure prerequisites strict partial orders principled way. preliminary deﬁnition given ﬁnite subset called strict order satisﬁes conditions deﬁnition subsets function denoted called g-oracle g-oracle returns label denoting whether transitivity restricted pairs deﬁnition given strict order closure deﬁned smallest g-oracle complete. proposition closure subject strict order unique. proposition strict order complete g-oracle also strict order deﬁnition given strict order ancestor subject please supplemental material proofs figure following notations theorem black lines pairs solid lines pairs dashed lines pairs pair cyan color pair labeled deduced. likewise s.t. figure provides informal explanation necessary condition mentioned theorem. positive example i.e. inferred positive examples transitivity; inferred negative examples irreﬂexivity; sets inferred negative examples transitivity; negative examples inferred negative example i.e. negative examples inferred transitivity. elaborate later computational hurdle active learning algorithm efﬁciently calculate closure given complete g-oracle particular among formula theorem found main bottleneck efﬁciently calculate whose worst time complexity others done proposition following notations theorem given worst time complexity calculate deﬁnitions previous section section proposes reasoning module designed monotonically calculate deductive closure strict orders. remark difference traditional transitive closure deﬁnition closure former focuses latter requires calculation context machine learning relations correspond positive examples negative examples respectively. since examples crucial training classiﬁers existing algorithms calculating transitive closure warshall algorithm applicable. thus propose following theorem monotonically computing closure. theorem strict order complete g-oracle pair deﬁne notation also conduct empirical studies examine growth rate calculating practice empirical growth rate closer linear rate means worst time complexity bound presented conservative. pool-based sampling typical active learning scenario maintains labeled unlabeled particular denote feature vector representing i-th instance denote groundtruth class label. round instances selected whose label requested labeled instance moved typically instances queried prioritized obtain good classiﬁers trained substantially smaller focus poolbased sampling setting queries selected serial i.e. time. query strategies component active learning design effective criterion selecting valuable instance query often referred query strategy. refer selected instance strategy. general different strategies follow greedy framework investigate commonly used query uncertainty sampling query-by-committee show binary classiﬁcation setting reformulated uncertainty sampling selects instance least certain label. choose study popular uncertainty-based sampling variant least conﬁdent. subject resulting approach query-by-committee maintains committee models trained labeled data aims reduce size version space. speciﬁcally selects unlabeled instance committee members disagree based predictions. subject resulting approach given strict order consider data similar pool-based active learning needs maintain labeled unlabeled require dl∪duand dl∩du given feature extractor build vector dataset ground-truth label active learning aims query subset limited budget construct label order train good classiﬁer predicts accurately whether unlabeled pair active learning strict orders differs traditional active learning unique aspects querying label single unlabeled instance obtain labeled examples help strict orders’ properties; relational information strict orders could also utilized query strategies. present efforts towards incorporating aspects active learning strict order. basic extension standard active learning strict order setting apply relational reasoning updating predicting labels. algorithm shows pseudocode pool-based active learning strict order. updating instance whose label acquired querying ﬁrst calculates i.e. closure using theorem sets respectively. therefore possible augment labeled pair stage even though single instance queried. furthermore following corollary shows given ﬁxed samples queried querying order affect ﬁnal labeled constructed. corollary straightforward result uniqueness closure also veriﬁed experiments. labeled contains kinds pairs based labels come from ﬁrst kind labels comes directly queries second kind comes relational reasoning explained theorem approach clear advantage standard active learning budget queries because labels part test pairs inferred deterministically result labeled data supervised training. setup active learning train classiﬁers predicting labels remaining relational active learning framework explained previous section however consider incorporating relational reasoning query strategy. develop systematic approach achieve this. argmax }\\dl) again scoring function. pairs whose labels originally unknown inferred assuming using theorem inferred label denoted sequel. formulation generalization proceed develop extensions query strategies model dependencies pairs imposed rule strict order. following notations described section difference numbering index replaced pairwise index propose query strategies tailored strict orders. uncertainty sampling reasoning. relational reasoning reduce uncertainty queried pair also reduce pairs deduced assuming y=y. modiﬁed scoring function reads bounds number queries note strict order described directed acyclic graph show lower upper bounds number queries needed learn consistent classiﬁer evaluation apply proposed active learning algorithms concept prerequisite learning problem given pair concepts predict whether prerequisite binary classiﬁcation problem. here cases prerequisite prerequisite relation exists considered negative. dataset wiki concept dataset collected textbooks different educational domains. domain dataset consists prerequisite pairs concept map. table summarizes statistics ﬁnal processed dataset. features concept pair calculate types features following popular practice information retrieval natural language processing graph-based features text-based features. please refer table detailed description. note trained topic model wiki corpus. also trained wordvec model corpus concept treated individual token. in/out degree a/b. common neighbors times links b/a. proportion pages link also link b/a. normalized google distance pointwise mutual information relatedness incoming links metric measure differently related concepts refer difference hub/authority scores. whether ﬁrst sentence b/a. whether appears title. jaccard similarity titles. words a/b’s content. times mentioned content b/a. noun phrases a/b’s content; common noun phrases. cosine similarity tf-idf vectors ﬁrst paragraphs. cosine similarity vectors trained wordvec. shannon entropy vector a/b. cross entropy vector experiment settings follow typical evaluation protocol poolbased active learning. ﬁrst randomly split dataset training test dtest ratio randomly select samples training initial query compute closure meanwhile d\\dl. iteration pick unlabeled instance query label update label re-train classiﬁcation model updated re-trained classiﬁcation model evaluated dtest. experiments random forests classiﬁer trees classiﬁcation model. area curve evaluation metric. taking account effects randomness subject different initializations continue experimental process method repeatedly preselected distinct random seeds. average scores conﬁdence intervals reported. compare four query strategies random randomly select instance query. least conﬁdent sampling widely used uncertainty sampling variant. logistic regression estimate posterior probabilities. simple baseline query strategy designed greedily select instance whose label potentially infer number unlabeled instances. following previous notations scoring function experiments test query strategy three settings traditional active learning relational information considered. query strategies setting denoted random qbc. relational active learning relation reasoning applied updating predicting labels dtest. query strategies setting denoted random-r lc-r qbc-r. besides applied updating relational reasoning also incorporated query strategies. query strategies setting baseline method proposed extensions strict partial orders denoted lc-r+ qbc-r+ respectively. table summarizes query strategies studied experiments. experiment results effectiveness study figure shows results different query strategies. case present average values c.i. repeated trials different train/test splits. addition figure compares relations number queries number labeled instances across different query strategies. note relational active learning setting querying single unlabeled instance result labeled instances. according figure figure following observations first comparing query strategies settings setting observe incorporating relational reasoning active learning substantially improves performance query strategy. addition query order supposed different strategy affect thus partly veriﬁes corollary second proposed lc-r+ qbcr+ signiﬁcantly outperform compared query strategies. speciﬁcally comparing lc-r qbc-r incorporating relational reasoning directing queries helps train better classiﬁer. figure shows lc-r+ qbc-r+ lead labeled instances using amount queries lc-r qbc-r. partly contributes performance gain. third lc-r+ qbc-r+ effective collecting larger labeled training better classiﬁers baseline. addition comparing lc-r qbc-r random-r observe larger size labeled always lead better performance. observations demonstrate necessity combining deterministic relational reasoning probabilistic machine learning designing query strategies. efﬁciency study proposed reasoning module designed plugged algorithm needs reasoning strict orders. thus besides verifying effectiveness also important investigate efﬁciency. conduct empirical studies runtime reasoning module. figure shows relation average runtime calculating closure using theorem size current labeled closure |h|. results lbc-r+ qbc-r+ presented. keeps increasing pool-based active learning process average runtime calculating increases almost linearly even decreases little end. although worst case time complexity calculating theorem runtime required directly related number ascendants descendants elements usually different four strict order datasets used. ascendants descendants effectively control size calculations observed runtime short regardless large |h|. figure average runtime calculating closure using theorem v.s. size current labeled closure |h|. might explain growth calculating near linear. also empirically evaluate effects using prop. efﬁciency include results supplemental material. conclusion propose active learning framework tailored relational data form strict partial orders. efﬁcient reasoning module proposed extend commonly used query strategies uncertainty sampling query committee. experiments concept prerequisite learning show incorporating relational reasoning selecting valuable examples label expanding training signiﬁcantly improves standard active learning approaches. future work could explore following apply reasoning module extend query strategies; active learning strict partial orders noisy oracle. steffen rendle lars schmidt-thieme. active learning equivalence relations minimizing expected loss using constraint inference. proc. icdm. ieee pages partha pratim talukdar william cohen. crowdsourced comprehension predicting prerequiproceedings site structure wikipedia. seventh workshop building educational applications using nlp. pages shuting wang alexander ororbia zhaohui kyle williams chen liang bart pursel giles. using prerequisites extract concept maps textbooks. proc. cikm. pages witten david milne. effective lowcost measure semantic relatedness obtained wikipedia links. proceeding aaai workshop wikipedia artiﬁcial intelligence evolving synergy. pages proof theorem well-deﬁniteness trivial complete also strict order. therefore well deﬁned necessity easily verify deﬁnition closure likewise another word also fig. explanation necessary condition mentioned. sufﬁciency ancestor ancestor also ancestor descendant descendant also descendant proceed prove complete using contradiction ﬁnalizes proof result complete deﬁnition four conditions deﬁnition must fail. deﬁnition fails must exist case complete contradicts assumption. hence least included deﬁnition pair belongs must come therefore implies cases however implies summary deﬁnition holds deﬁnition fails must exist case complete contradicts assumption. hence least included divide statement following cases discuss cases because therefore cases thus plies cases thus cases thus cases exists therefore hence cases thus directed acyclic graph shown transitive reduction unique subgraph simple directed acyclic graph compliance def. denote transitive closure deﬁne graphs every graph transitive closure i.e. proof simple contradiction based deﬁnition transitive reduction fact consistent learner. hand learning algorithm simply remembers queries positive labels predict inputs negative. algorithm sufﬁces make queries. experiment environment experiments conducted ubuntu server intel xeon .ghz processors. active learning query strategies implemented python.. code data publicly available. effectiveness proposition also empirically evaluate effects using proposition efﬁciency. speciﬁcally measure total runtime calculation theorem full round active learning without applying pruning rule induced proposition results shown table numbers average runtime different rounds active learning dataset. pruning lead speedup lc-r+", "year": 2018}