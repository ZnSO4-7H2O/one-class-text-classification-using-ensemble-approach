{"title": "Partitioning Large Scale Deep Belief Networks Using Dropout", "tag": ["stat.ML", "cs.LG", "cs.NE"], "abstract": "Deep learning methods have shown great promise in many practical applications, ranging from speech recognition, visual object recognition, to text processing. However, most of the current deep learning methods suffer from scalability problems for large-scale applications, forcing researchers or users to focus on small-scale problems with fewer parameters.  In this paper, we consider a well-known machine learning model, deep belief networks (DBNs) that have yielded impressive classification performance on a large number of benchmark machine learning tasks. To scale up DBN, we propose an approach that can use the computing clusters in a distributed environment to train large models, while the dense matrix computations within a single machine are sped up using graphics processors (GPU). When training a DBN, each machine randomly drops out a portion of neurons in each hidden layer, for each training case, making the remaining neurons only learn to detect features that are generally helpful for producing the correct answer. Within our approach, we have developed four methods to combine outcomes from each machine to form a unified model. Our preliminary experiment on the mnst handwritten digit database demonstrates that our approach outperforms the state of the art test error rate.", "text": "deep learning methods shown great promise many practical applications ranging speech recognition visual object recognition text processing. however current deep learning methods suffer scalability problems large-scale applications forcing researchers users focus smallscale problems fewer parameters. paper consider well-known machine learning model deep belief networks yielded impressive classiﬁcation performance large number benchmark machine learning tasks. scale propose approach computing clusters distributed environment train large models dense matrix computations within single machine sped using graphics processors training machine randomly drops portion neurons hidden layer training case making remaining neurons learn detect features generally helpful producing correct answer. within approach developed four methods combine outcomes machine form uniﬁed model. preliminary experiment mnist handwritten digit database demonstrates approach outperforms state test error rate. deep learning methods learn multilayer neural network extract feature hierarchies input data maximizing likelihood training data. promise largely lies potential vast amounts unlabeled data learn complex highly nonlinear models millions parameters. recent competitions deep learning methods shown adavantanges nearest-neighbor based methods kernel methods ensemble methods paper consider well-known machine learning model deep belief networks learn hierarchical representations inputs. applied number machine learning applications including speech recognition visual object recognition text processing among others. particular especially well-suited problems high-dimensional inputs infer rich models many hidden layers. example applied images easily tens millions free parameters ideally would want millions unlabeled training examples richly cover input space. demonstrated increasing scale deep learning respect number training examples number model parameters both drastically improve ultimate classiﬁcation accuracy unfortunately current algorithms even training moderate-sized take weeks using conventional implementation single primarily daunting computational requirements training large number parameters need trained available examples. address scalability problem paper proposes approach scale large-scale deep belief networks adapting idea random dropout. random dropout proposed hinton originally used prevent complex co-adaptations training data single processor. training case hidden unit randomly omitted network probability hidden unit cannot rely hidden units present. many separate dbns trained applied independently test data reduce predication bias single dbn. approach extends random dropout idea distributed parallel setting. rather omitting hidden unit probability approach randomly drops portion hidden units processor training case. combine dbns processor approach offers four different ways performing model averaging trained dbns. using majority vote predication result trained test case. synchronously updating parameters fetching needed paramevalidated preliminary evaluation using random dropout approach outperforms state-of-the-art algorithms data potential exhibit nearly linear speedup parallel implementation. recently many approaches developed scale machine learning algorithms within machine across machines much existing work focuses linear convex models takes distributed gradient computation ﬁrst step. approaches relax synchronization requirements exploring delayed gradient updates convex problems exploring lock-less asynchronous stochastic gradient descent shared-memory architectures another scale machine learning algorithms provide better abstractions wellencapsulated computation tools. mapreduce graphlab notable examples. however mapreduce originally designed parallel data processing number limitations training deep belief network hand graphlab designed general unstructured graph computations exploit computational effectiveness typical structured graph deep belief network. thus still unknown whether abstraction graphlab used training large-scale dbns. deep learning community work done train relatively small models single machine general training many-layer model computationally intensive. thus full model parallelism well smart distributed optimization techniques required. recent years surge interest scaling training inference algorithms used dbns improving applicable optimization procedures existing approaches primarily fall following categories. approaches ﬁrst category graphics processors achieve signiﬁcant speedup training moderate-sized dbns. gpus signiﬁcantly reduced computation time matrix operations dominate computation cost deep learning algorithms. however known limitation gpu-based approaches speedup small model memory thus effectively leverage researchers often reduce model size parameter number alleviate impact lacking enough memory. data parameter reduction work well small problems less attractive realistic problems large number examples dimensions approaches second category model parallelism achieve scalability. example distbelief notable framework enables model parallelism across machines details parallelism synchronization communication managed framework. model parallelism distbelief framework suffers large communication overhead dense connections layers neurons. data parallelism also supported distbelief using multiple replicas model optimize single objective. however pointed hinton large neural network trained distbelief still perform poorly held-out test data relationship input correct output complicated network enough hidden units model accurately. cases typically many different settings weights model training almost perfectly. weight vectors make different predictions held-out test data alworse test data training data feature detectors tuned work well together training data test data. approach inspired mentioned approaches aims address limitations. goal scaling deep learning techniques train large dbns approach combines intrinsic parallelism ensemble learning algorithms random dropout approach improve generalization results neural networks. using random dropout approach trains separate individual processor large cluster combines results using four proposed methods. compared existing approaches random dropout-based approach several noticeable beneﬁts. first becomes possible train huge number different networks reasonable time since number parameters trained single machine much smaller original dbn. second approach permits better modern memory reduced model size. third data transferring processors would incur less communication overhead. train large dbns propose approach supports distributed computation neural networks. high level approach consists steps model parallelism model combination ﬁrst model parallelism step approach automatically parallelizes computation machine using available resources manages communication synchronization data transfer machine. second step approach supports four different ways combine results machine form uniﬁed dbn. worthy noting computational needs training machine depends connectivity structure random dropout signiﬁcantly reduce complexity well number parameters dropping neurons layer lead reduction parameters general given dropout probability approach permits model parallelism among machines machine updating disjoint portion weight matrix. fundamentally different existing model parallelism approaches example distbelief framework user needs deﬁne computation takes place machine layer model approach distributes computation training fully automatically machine. addition framework like distbelief complexity reduced; rather partitioned available machines machine must communicate frequently updating weights. therefore large models high computational demands might benfigure example model parallelism -layer neural network machines. example machine randomly drops portion neurons trains separate independently. later approach combines trained dbns using four methods described section compute {calculate gradient} fetch weight queue push machines’ weight queues figure asynchronous parameter updating algorithm machine training data. machine weight queue receiving updated parameters machines. beginning machine replica parameters. access cpus memory beginning limited bottleneck communication costs dominate point. contrast approach dbns produced random dropout tend amenable extensive distribution fully-connected structures given less complex structures lower communication requirements. also help alleviate bottleneck many machines waiting single slowest machine ﬁnish given phase computation. figure sketches asynchronous parameter weight updating algorithm machine training data. lock-free asynchronous algorithm prevents machine waiting others ﬁnish proceeding next training data sacriﬁcing data consistency parameters possible machines updating parameters simultaneously without explicit ordering. consequence asynchronous algorithm introduce additional stochasticity training. compute {calculate gradient} fetch parameter server {wait machines ﬁnish updating update parameter server {wait machines ﬁnish updating figure sychronous parameter updating algorithm machine training data. parameter serve stores weights; machine fetches needed weights server updating. figure sketches synchronous parameter weight updating algorithm machine. algorithm central parameter server storing weights parameters. mini-batch machine sends request parameter server fetch needed parameter weights. machines updating requested parameters machine needs wait machines ﬁnish updates. comparing asynchronous algorithm algorithm eliminates possible data races improves data consistency parameters introduces higher overhead. implemented approach prototype using matlab python. prototype uses theano library deﬁne optimize evaluate mathematical expressions involving multidimensional arrays efﬁciently. speciﬁcally implementation uses theano achieve signiﬁcant speedup data-intensive calculations leveraging transparent gpu. combining trained dbns implementation uses inter-process communication exchange data among multiple threads processes. implementation publicly available http//deeplearning.googlecode.com. architectures deep network varies different benchmark tasks. ﬁrst step develop prototype evaluate effectiveness mnist handwritten digits dataset consists digit images training testing. objective classify digit images correct digit class. experimented neural network size –––– pretrained network layer-wise restricted boltzmann machine epochs. epoch means pass training data. pre-training phase employs greedy contrastive divergence– learning algorithm. learning rate exponentially decaying initial value decay rate epoch training. weights updated mini-batch size momentum also used initial value linear increasing rate ﬁrst epochs stays tuning using back-propagation dropout epochs employed stochastic gradient descent mini-batches size dropout rates hidden units dropout input pixels. constant learning rate used there’s constraints imposed norms weight vectors. original dropout article hinton claims better generalization performance achieved various dropout probabilities. implementation details shown section show test error rate varies function dropout probability. demonstrated ﬁgure dropout decrease test error rate contrary claim found generation performance dropout actually depends dropout probability. dropout probability greater test error rate increases signiﬁcantly. inconsistency might much smaller training epochs used implementation. figure test error rate mnist variety dropout probabilities. input visible neurons also dropout. best previous published results task using without dropout using epochs table test error rate using different algorithms epochs tuning. weight averaging majority vote algorithms collect ﬁnal weights independent runs standard dropout algorithms. synchronous update asynchronous update algorithms combine results processes input instance. dropout rate algorithms. weight averaging synchronous update algorithms achieved notable improvement generalization performance. surprisingly majority vote method didn’t reduce test error rate large margin. asynchronous update algorithm introduced additional noise weight updates lock free mechanism thus generalization performance relatively sequential dropout algorithm. however exhibited ﬁgure convergence rate synchronous asynchronous update algorithms faster sequential dropout algorithm. current evaluation performed desktop dual core intel processor nvidia graphics card. pretraining/ﬁne tuning generally time consumption machine. time constraints able evaluate proposed algorithm relatively small mnist dataset. however plan evaluate algorithm speech object recognition benchmark tasks timit acoustic-phonetic continuous speech corpus reuters corpus news article topic recognition imagenet dataset millions labeled images thousands categories paper proposes approach scale deep belief networks core approach random dropout prevent co-adaptions training data reduce overﬁtting enable training computational power clusters distributed environment. empirically implementation outperforms state-of-the-art approaches promising nearly linear speedups. furthermore approach allows parallel training even gradients computationally intensive. future work would interesting compare approach approaches using different abstractions example powergraph abstraction exploits internal structure graph programs address challenges computation natural graphs. thus possible adapt similar random dropout idea reduce memory consumption communications processors. investigation generalize approach structures problems would enable even faster computation machine learning problems.", "year": 2015}