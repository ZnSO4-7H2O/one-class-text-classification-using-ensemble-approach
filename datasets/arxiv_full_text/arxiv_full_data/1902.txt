{"title": "Learning like a Child: Fast Novel Visual Concept Learning from Sentence  Descriptions of Images", "tag": ["cs.CV", "cs.CL", "cs.LG", "I.2.6; I.2.7; I.2.10"], "abstract": "In this paper, we address the task of learning novel visual concepts, and their interactions with other concepts, from a few images with sentence descriptions. Using linguistic context and visual features, our method is able to efficiently hypothesize the semantic meaning of new words and add them to its word dictionary so that they can be used to describe images which contain these novel concepts. Our method has an image captioning module based on m-RNN with several improvements. In particular, we propose a transposed weight sharing scheme, which not only improves performance on image captioning, but also makes the model more suitable for the novel concept learning task. We propose methods to prevent overfitting the new concepts. In addition, three novel concept datasets are constructed for this new task. In the experiments, we show that our method effectively learns novel visual concepts from a few examples without disturbing the previously learned concepts. The project page is http://www.stat.ucla.edu/~junhua.mao/projects/child_learning.html", "text": "figure illustration novel visual concept learning sentences task. start model trained images contain concept quidditch using quidditch images sentence descriptions method able learn quidditch played people ball. categories objects handful examples. task important practice sometimes enough data novel concepts hence need transfer knowledge previously learned categories. moreover want retrain whole model every time images novel concepts especially amount data model parameters big. however previous methods concentrate learning classiﬁers mappings single words images. unaware computer vision studies task learning novel visual concepts sentences using concepts describe images task children seem effortlessly. call novel visual concept learning sentences task paper present novel framework address nvcs task. start model already trained large amount visual concepts. propose method allows model enlarge word dictionary describe novel concepts using examples without extensive retraining. particular need retrain models scratch data propose three datasets nvcs task validate paper address task learning novel visual concepts interactions concepts images sentence descriptions. using linguistic context visual features method able efﬁciently hypothesize semantic meaning words word dictionary used describe images contain novel concepts. method image captioning module based several improvements. particular propose transposed weight sharing scheme improves performance image captioning also makes model suitable novel concept learning task. propose methods prevent overﬁtting concepts. addition three novel concept datasets constructed task publicly available project page. experiments show method effectively learns novel visual concepts examples without disturbing previously learned concepts. project page www.stat.ucla.edu/˜junhua. mao/projects/child_learning.html. introduction recognizing learning using novel concepts important cognitive functions humans. young learned concepts observing visual world listening sentence descriptions parents. process slow beginning much faster accumulated enough learned concepts particular known children form quick rough hypotheses meaning words sentence based knowledge previous learned words associate words objects properties describe novel concepts using sentences words phenomenon researched years psychologists linguists study process word learning method requires base model image captioning adapted perform nvcs task. choose m-rnn model performs state base model. note could current image captioning models base model method. make several changes model structure m-rnn partly motivated desire avoid overﬁtting particular danger nvcs want learn images. note changes also improve performance original image captioning task although improvement main focus paper. particular introduce transposed weight sharing strategy reduces factor half number model parameters need learned. allows increase dimension word-embedding multimodal layers without overﬁtting data yielding richer word multimodal dense representation. train image captioning model large image dataset sentence descriptions. base model adapt nvcs task. address task learning concepts small data contains concepts. main difﬁculties. firstly weights previously learned concepts disturbed concepts. although solved ﬁxing weights. secondly learning concepts positive examples introduce bias. intuitively model assign baseline probability word roughly proportional frequency words sentences. train model data baseline probabilities words unreliably high. propose strategy addresses problem ﬁxing baseline probability words. construct three datasets validate method involves concepts man-made objects animals activities. ﬁrst datasets derived ms-coco dataset third dataset constructed adding three uncommon concepts occur ms-coco standard datasets. concepts quidditch t-rex samisen experiments show training method examples concepts gives good performance retraining entire model examples. related work deep neural network recently dramatic progress deep neural networks natural language available www.stat.ucla.edu/˜junhua. mao/projects/child_learning.html. adding novel concepts dataset. latest version dataset contains additional novel concepts tai-ji huangmei opera kiss rocket tempura waterfall wedding dress windmill. computer vision. natural language recurrent neural networks long-short term memories achieve state-of-the-art performance many tasks machine translation speech recognition computer vision deep convolutional neural networks outperform previous methods large margin tasks object classiﬁcation detection success methods language vision motivate multimodal learning tasks multimodal learning language vision methods image-sentence retrieval image description generation visual question-answering developed fast recent years. recent works image captioning includes many adopt rnn-cnn framework optimizes log-likelihood caption given image train networks end-to-end way. exception incorporates visual detectors language models multimodal similarity models high-performing pipeline. evaluation metrics image captioning task also discussed image captioning methods prespeciﬁed ﬁxed word dictionary train model large dataset. method directly applied captioning models adopt rnn-cnn framework strategy avoid overﬁtting useful models novel visual concept learning task. zero-shot one-shot learning zero-shot learning task associate dense word vectors attributes image features dense word vectors papers pre-trained large amount text corpus word semantic representation captured co-occurrence words developed idea showing novel words times. addition adopted auto-encoders attribute representations learn class labels proposed method scales large datasets using label embeddings. another related task one-shot learning task categories learn objects examples. however work consider words attributes instead sentences learning target different task paper. image captioning model need image captioning base model adapted nvcs task. base model based m-rnn model architecture shown figure make main modiﬁcations architecture make suitable nvcs task which side effect also improves performance original image captioning task. firstly importantly propose transposed weight sharing strategy sigfigure image captioning model. word sentence model takes current word index image inputs outputs next word index. weights shared across sub-models words sentence. number right layer denotes dimension. m-rnn model start sign wstart sign wend training sentence. transposed weight sharing niﬁcantly reduces number parameters model secondly replace recurrent layer long-short term memory layer lstm recurrent neural network designed solve gradient explosion vanishing problems. brieﬂy introduce framework model section describe details transposed weight sharing strategy section model architecture shown figure input model word sentence index current word word dictionary well image. represent index one-hot vector output index next word. model three components language component vision component multimodal component. language component contains word embedding layers lstm layer. maps index word dictionary semantic dense word embedding space stores word context information lstm layer. vision component contains -layer deep convolutional neural network pre-trained imagenet classiﬁcation task remove ﬁnal softmax layer deep connect fully connected layer model. activation dimensional layer treated image features contain rich visual attributes objects scenes. multimodal component contains one-layer representation information language part vision part merge together. build softmax layer multimodal layer predict index next word. weights shared across sub-models words sentence. m-rnn model start sign wstart sign wend training sentence. testing stage image captioning input start sign wstart element-wise non-linear function one-hot vector current word. note fast calculate equation non-zero element practice need calculate full matrix multiplication operation since column used word forward backward propagation. intuitively role weight matrix equation encode one-hot vector dense semantic vector role weight matrix equation decode dense semantic vector back pseudo one-hot vector help softmax function similar inverse operation equation difference dense multimodal semantic space dense word semantic space. solve problems propose following strategies learn concepts images without losing accuracy original concepts. fixing originally learned weights assumption learned weights original words large amount data amount data concepts relatively small straightforward originally learned weights model incremental training. speciﬁcally weight matrix separated parts associate original words words respectively. e.g. shown figure novel visual concept associated words kitten pawing. sub-matrix update submatrix illustrated figure fixing baseline probability equation bias term intuitively element represents tendency model output corresponding word. think term baseline probability word. similar separated parts associate original words words respectively. present data network estimation unreliable. network tend increase value causes overﬁtting data. easiest solve problem during training novel concepts. enough. average activation intermediate layer across training samples weight matrix plays similar role changing baseline probability. avoid problem centralize activation intermediate layer turn original bias term follows adaptive learning rate algorithm base model novel concept model. role language vision novel concept learning task sentences serve weak labeling image. language part model hypothesizes basic properties words whether words closely related content image. also hypothesizes reduce number parameters decompose parts. ﬁrst part maps multimodal layer activation vector intermediate vector word semantic space. second part maps intermediate vector pseudo one-hot word vector inverse operation equation sub-matrix second part able share parameters transposed manner motivated tied weights strategy autoencoders unsupervised learning tasks example linear decomposition equation accordingly changed element-wise function. identity mapping function equivalent linearly decomposing experiments setting scaled hyperbolic tangent function leads slightly better performance linear decomposition. strategy viewed adding intermediate layer dimension multimodal softmax layers shown figure weight matrix intermediate softmax layer shared transposed manner. transposed weight sharing strategy enables much larger dimensional word-embedding layer m-rnn model withincreasing number parameters. also beneﬁt strategy addressing novel concept learning task. novel concept learning task suppose trained model based large amount images sentences. meet images novel concepts whose sentence annotations contain words dictionary time-consuming unnecessary re-train whole model scratch using data. many cases cannot even access original training data model. ﬁne-tuning whole model using data causes severe overﬁtting concepts decrease performance model originally trained ones. words original dictionary semantically syntactically close words. example suppose model meets image sentence description woman playing cat. also suppose images original data containing sentence description playing dog. although model seen word before hypothesize word close other. vision part pre-trained imagenet classiﬁcation task million images categories. provides rich visual attributes objects scenes useful classiﬁcation task itself also vision tasks combining cues language vision model effectively learn concepts using examples demonstrated experiments. datasets strategies construct datasets annotations images coco construct novel concept learning datasets. current release coco contains training images validation images object instance annotations sentence descriptions image. construct dataset speciﬁc concept remove images containing object according object annotations. also check whether images left sentences descriptions containing related words. remaining images treated base train validate test base model. removed images used construct novel concept used train validate test model task novel concept learning. novel visual concepts datasets dataset datasets mentioned derived coco dataset. verify effectiveness method construct dataset contains three novel concepts quidditch t-rex samisen contains object concepts also activity concepts labeled images concept sentence annotations image. diversify labeled sentences different images category annotators instructed label images different sentences describing details image. leads different style annotation coco dataset. average length sentences also longer coco construct dataset reasons. firstly three concepts included categories imagenet classiﬁcation task pre-trained vision component model. secondly dataset richer diversiﬁed sentence descriptions compared newobj-cat newobjmotor. denote dataset novel concept- dataset samples images annotations shown figure randomly separate three datasets training testing validation sets. number images three datasets shown table investigate possible overﬁtting issues datasets testing stage randomly picked images testing base treated separate testing images. number added images equal size original test denote original concept testing images novel concept test added base testing images base test set. good novel visual concept learning method perform better base model test comparable base test set. organization datasets illustrated figure publicly available www.stat.ucla.edu/ ˜junhua.mao/projects/child_learning.html. actively expanding dataset. latest version contains novel concepts. evaluate output sentence descriptions novel visual concepts adopt evaluation metrics widely used recent image captioning work bleu scores meteor bleu scores meteor target evaluating overall quality generated sentences. nvcs task however focus accuracy words previously learned words sentences. therefore conduct comprehensive evaluation also calculate score words describe concepts. e.g. dataset words cats kitten pawing. precision recall word dictionary calculated follows sgen denotes generated sentence sref denotes reference sentences represents number testing images conform condition. note calculated combined testing test base test high indicates model overﬁts data high indicates underﬁting. p−+r− balanced measurement best score note either compared meteor bleu score show effectiveness model learn concepts explicitly. effectiveness test base model transposed weight sharing strategy original image captaining task coco compare m-rnn tws. model performs better m-rnn task shown table choose layer dimensions model number parameters matches models different hyperparameters features pipelines might lead better performance beyond scope paper. e.g. improve results submission draft achieve score respectively using e.g. ﬁne-tuned image features coco consensus reranking complementary tws. also validate effectiveness transposed weight sharing baseline probability fixation strategies novel concept learning task newobj-cat dataset. compare performance deep-nvcs models. properties performance terms score word summarized table biasfix means bias term equation centralize means centralize intermediate layer activation affect baseline probability. achieve increase performance terms using achieves increase using deep-nvcs represent deep-nvcs-bpf-tws short rest paper. results newobj-motor newobj-cat using training samples show performance deep-nvcs models compared strong baselines newobj-cat newobjmotor datasets table deep-nvcs training data novel concept set. deep-nvcsinc training data randomly sampled training base set. number added training images training images novel concepts. model-base stands model trained base implement baseline model model-wordvec weights words calculated using weighted weights similar concepts measured unsupervised learned word-embeddings wordvec also implement strong baseline model-retrain retraining whole model scratch combined training results show compared model-base trained base deep-nvcs models perform much better novel concept test reaching comparable performance base test set. deep-nvcs also performs better model-wordvec model. tried versions model without model multimodal layer directly connected softmax layer like model additional intermediate layer like share weights. experiments performs slightly better report performance here. table results newobj-cat newobj-motor dataset using training samples. deep nvcs models outperform simple baselines. achieve comparable performance strong baseline need time. model-base model-retrain stand model trained base model retrained combined data respectively. model-wordvec baseline model based wordvec deep-nvcs stands model trained concept data. deep-nvcs-inc stands deep-nvcs model trained adding equal number training images base set. figure performance comparison model different number training images newobj-cat newobj-motor datasets. blue magenta dashed line indicates performance deep-nvcs using training images base test test test respectively. green dashed line indicates performance modelbase. black dots stand performance model-retrain test. show model trained images achieves comparable performance model trained full training set. performance deep-nvcs models close strong baseline model-retrain needs less time. demonstrates effectiveness novel concept learning strategies. model learns words novel concepts without disturbing previous learned words. performance deep-nvcs also comparable with though slightly lower deep-nvcs-inc. intuitively image features successfully capture difference concepts existing ones sufﬁcient learn concept data. however concepts similar previously learned concepts helpful present data novel existing concepts make easier model difference. show performance model different number training images figure show results terms score meteor space limitation. results consistent shown metrics. performance model trained full training last section indicated blue magenta dashed lines figure lines represent experimental upper bounds model few-shot scenario. performance model-base shown green dashed line. serves experimental lower bound. also show results model-retrain test black dots figure trained novel concepts images. ages model achieves comparable performance deep-nvcs model trained full novel concept training set. addition using training images observe nontrivial increase performance compared base model. deep-nvcs also better handles case images runs much faster model-retrain. results dataset three main difﬁculties. firstly concepts similar counterparts original image samisen v.s. guitar quidditch v.s. football. secondly three concepts rarely appear daily life. included imagenet categories pre-trained vision deep cnn. thirdly describe three novel concepts somewhat different common objects included base set. requirement diversify annotated sentences makes difference style annotated sentences coco even larger. effect difference sentence style leads decreased performance base model compared newobj-cat newobj-motor dataset furthermore makes harder model hypothesize meanings words sentences. faced difﬁculties model still learns semantic meaning concepts quite well. scores model shown table indicate model successfully learns concepts high accuracy examples. five nearest neighbours kitten; tabby; puppy; calico; doll; motorbike; moped; vehicle; motor; motorbikes; soccer; football; softball; basketball; frisbees; giraffe’s; bull; pony; goat; burger; guitar; wii; toothbrushes; purse; contents; dataset. output word quidditch samisen generated sentences. bleu scores meteor also low. surprising since training examples three novel concepts easy overwhelmed concepts original coco dataset. qualitative results table show nearest neighbors concepts using activation word-embedding layer learned deep-nvcs model. shows learned novel word embedding vectors captures semantic information language vision. also show sample generated sentence descriptions base model deep-nvcs model figure conclusion paper propose novel visual concept learning sentences task. task methods need learn novel concepts sentence descriptions images. describe method allows train model small number images containing novel concepts. performs comparably model retrained scratch data number novel concept images large performs better training images novel concepts available. construct three novel concept datasets validate effectiveness method. datasets released encourage future research area.", "year": 2015}