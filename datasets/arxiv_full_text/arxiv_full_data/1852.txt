{"title": "One-shot and few-shot learning of word embeddings", "tag": ["cs.CL", "cs.LG", "stat.ML", "I.2.7"], "abstract": "Standard deep learning systems require thousands or millions of examples to learn a concept, and cannot integrate new concepts easily. By contrast, humans have an incredible ability to do one-shot or few-shot learning. For instance, from just hearing a word used in a sentence, humans can infer a great deal about it, by leveraging what the syntax and semantics of the surrounding words tells us. Here, we draw inspiration from this to highlight a simple technique by which deep recurrent networks can similarly exploit their prior knowledge to learn a useful representation for a new word from little data. This could make natural language processing systems much more flexible, by allowing them to learn continually from the new words they encounter.", "text": "standard deep learning systems require thousands millions examples learn concept cannot integrate concepts easily. contrast humans incredible ability one-shot few-shot learning. instance hearing word used sentence humans infer great deal leveraging syntax semantics surrounding words tells here draw inspiration highlight simple technique deep recurrent networks similarly exploit prior knowledge learn useful representation word little data. could make natural language processing systems much ﬂexible allowing learn continually words encounter. despite fact several nonsense words follow narrative poem understand approximately many words mean relate words. vital skill interacting world constantly need learn words ideas context. even beyond language humans often able adapt quickly gracefully accomodate situations differ radically seen before. complementary learning systems theory suggests interaction slow-learning system learns structural features world fast-learning system allows humans adapt rapidly experiences. comparison standard deep learning systems usually require much data learn concept task sometimes generalize poorly lake trained learn concept one-shot sole task limits types tasks performed. furthermore models typically discard information single use. order deep learning systems adaptible need build prior knowledge learn effectively pieces information. words need integrate learning experiences across different timescales complementary learning systems theory suggests humans animals paper explore broad issue speciﬁc context creating useful representation word based context. however word vectors typically trained large datasets surprisingly little prior work learn embeddings words system trained. cotterell proposed method incorporating morphological information word embeddings allows limited generalization words however general system learning representations words requires building rather strong structural assumptions language appropriately labelled data exploit them. recently lazaridou explored multi-modal word learning process suggested simple heuristic inferring word vector context simply average together surrounding word vectors. sensible since surrounding words likely occur similar contexts. however ignores syntactic information treating surrounding words identically relies semantic information linearly combinable different word embeddings. factors likely limit performance. better? deep learning system trained perform language task must learned great deal semantic syntactic structure would useful inferring representing meaning word. however knowledge opaquely encoded weights. exploit knowledge learning word? suggest already update representations network accounting current knowledge inferences precisely backpropagation invented course cannot simply train whole network accomodate word would lead catastrophic interference. however rumelhart todd showed simple network could taught input freezing weights except connecting input ﬁrst hidden layer optimizing gradient descent usual. showed resulted network making appropriate generalizations input design training procedure interfere network’s prior knowledge. used model human concept learning take inspiration work guide approach. learn sentence containing word freeze weights network except representing word stochastic gradient descent update weights word using epochs training sentence containing figure percent change perplexity test sentences containing word plotted number training sentences across four different words comparing optimizing three different starting points centroid training word baselines. averages across permutations shown dark lines individual results shown light lines. framework described updating embeddings could applied generally sake paper ground simple task predicting next word sentence based previous words penn treebank dataset speciﬁcally model architecture approach zaremba appendix details. course human language understanding much complex prediction grounding language situations goals likely important achieving deeper understanding language recent work begun it’s likely approach would effective settings like these. ability humans make rich inferences text stems richness knowledge. however simplicity chosen ﬁrst demonstrate prediction task. order test one-shot word-learning algorithm penn treebank chose word appeared times training set. removed sentences containing word trained model remaining sentences epochs using learning rate decay strategy zaremba dataset contains sentences missing ones essentially effect networks overall performance. split sentences containing word train test trained different permutations ensures sentence used one-shot learning once enforces diversity multi-shot examples). words performed training runs word training runs distinct single sentence distinct pair sentences etc. ﬁrst evaluated approach words bonuses explained marketers strategist either initializing never-seen embedding network optimized never produce zero vector centroid surrounding words compared baselines taking centroid surrounding words full training words fig. optimizing centroid outperforms approaches learning word datasets including centroid approach lazaridou even outperforms full training word three four cases optimizing approaches strongly affected embedding initialization training sentences sentences perform quite similarly. course learning might still cause interference networks prior knowledge. order evaluate this replicated ﬁndings four words also evaluated change perplexity test corpus indeed found centroid method substantially change test perplexity corpus optimizing method causes increasingly interference training sentences provided decline case training sentences. necessarily surprising base rate occurrence word training data artiﬁcially inﬂated relative true base rate probability. problem learning data locally highly correlated biased solved many recent domains replay buffers interleave learning especially reinforcement learning importance replay also highlighted complementary learning systems theory helped inspire work. therefore tested whether using replay buffer learning word would ameliorate interference. speciﬁcally sampled negative sentences without-word corpus network pre-trained interleaved random word training sentences indeed interleaving sentences without word substantially reduced interference caused word fig. maximum increase perplexity interleaving result somewhat less improvement new-word test sentences probably simply test sentences over-represent word network overﬁtting predicting word much warranted. optimizing approach still reduces perplexity dataset containing word model using distinct input output embeddings able evaluate distinct contributions learning word. speciﬁcally compared learning softmax weights bias learning input embedding well learning both oneten-shot learning. fig. results. found mostly output embeddings improving. one-shot learning changing input embedding alone causes almost improvement changing embeddings seem substantially different changing output embedding. however training sentences updated input embedding producing improvement alone trained together output embedding. even case however effect input embedding still much smaller effect output embedding. model mostly improving predicting word context rather predicting context based word. interesting note words appears test data appears once. full training word result lowered test perplexity test data three four cases? chance variation course general would expect learning word useful sake learning word word small piece signal network learns language generally. figure comparing full training word centroid optimizing centroid approaches word dataset full test corpus using negatively sampled sentences replay. using replay buffer learning words interfere substantially prior knowledge. figure comparing change perplexity word test optimizing input embedding output embedding either sentences containing word. light lines independent runs dark lines averages. unnatural situations human might experience word even pretraining network sentences presented without context surrounding sentences. means model less data learn word predicts surrounding context less information context predicts word. also explain full training word still produced better results cases updating finally efﬁciently passing information word model input might require adjustments intermediate weights frozen. table average log-probabilities word when word current target word current target appear current sentence word doesn’t appear sentence context. course results illustrate evaluating solely change perplexity limits insight. thus conducted detailed analyses model’s predictions. since know beneﬁt one-shot training model comes predicting word context evaluated well word predicted three cases actual target word current target appear sentence irrelevant sentences. allowed investigate whether model learning something useful simply overﬁtting data. compared average log-probability model assigned word cases full training word baseline centroid approach learning words approach relevant cases evaluated held-out test data word; irrelevant case evaluated ﬁrst sentences test corpus table results. model fully trained word shows clear distinctions three conditions word estimated times likely contexts appears irrelevant contexts estimated times likely actually appears. however model severely underestimates probability word appear; word would similar probability uniform distribution whole vocabulary. centroid method also issue addition even distinguish particularly well contexts. word estimated times likely target completely irrelevant contexts. contrast approach results good distinction contexts word predicted times likely contexts appears compared irrelevant context times likely word actually appears. relative probabilities quite similar exhibited model fully trained word. respects appears superior centroid approach. compared full training word however appears base rate estimates prevalence word inﬂated explains residual small increase test perplexity dataset containing word. possible could ameliorated either setting prior bias word norm distance bias values rare words) validation using negative samples training. case optimized embeddings capturing important features word appear effectively centroid approach. point presented results paper broken word rather averages large word-by-word differences almost every analysis evaluated relatively words. order establish generality ﬁndings large sample words additional experiment spans space words broadly. experiment selected words appear exactly times train corpus instead training separate models without word previously trained single model none words included train set. tested few-shot learning technique replay buffer centroid technique sentences compared results obtained full training words model trained entire train corpus including train sentences hundred words. notice comparison full training words precise previous experiments model receives training data overall few-shot learning models means linguistic structure learn words from well advantage interleaving them. however comparisons technique centroid technique still valid comparison full training words gives worst-case bound poorly one-shot methods compared full training. mind fig. results. before optimizing centroid performed much better simply using centroid average produced improvement centroid result none words perform worse centroid method. quantitatively optimizing method performed signiﬁcantly better furthermore despite disadvantage exposed less total data optimizing approach seems approximately well full training approach average although full training approach sometimes results much larger improvements results signiﬁcantly differ across wide variety words optimizing improves centroid approach performs comparably full training. figure percent change perplexity words applying centroid optimizing centroid full training words. sentences containing word used training used testing. large solid dots indicate change mean smaller dots indicate change individual words. overall using technique updating embedding vectors word training sentences containing negative sampled sentences networks past experience seems quite effective. allows substantial reductions perplexity text containing word without greatly interfering knowledge words. furthermore seems capturing useful structure word used context previous approaches performs close well full training word. results exciting beyond potential applications natural language processing technique could easily extended adapting systems types experiences example vision network agent could ﬁlters layer added trained accomodate type object. circumstances strategy fail? complementary learning systems theory drew inspiration suggests information schema-consistent integrated easily whereas schemainconsistent knowledge cause interference. similar principles apply here. approach work learning word topic already somewhat familiar would likely fail learn word context well understood. example would difﬁcult learn german word context model experienced english. hand perspective also provides promises. expect technique would perform even better system sophisticated understanding language would prior knowledge bootstrap understanding words. thus would interesting apply technique complicated tasks like question answering santoro grounded context hermann presented technique onefew-shot learning word embeddings text data freeze weights network except embeddings word optimize embeddings sentence interleaving negative examples network’s prior experience stopping early. results substantial improvement ability predict word context minimal impairment prediction words. technique could allow natural language processing systems adapt ﬂexibly changing world like humans generally could serve model integrate rapid adaptation deep learning systems. karl moritz hermann felix hill simon green fumin wang ryan faulkner hubert soyer david szepesvari wojciech marian czarnecki jaderberg denis teplyashin marcus wainwright chris apps demis hassabis. grounded language learning simulated world. arxiv dharshan kumaran demis hassabis james mcclelland. learning systems intelligent agents need complementary learning systems theory updated. trends cognitive sciences issn ./j.tics.... angeliki lazaridou marco marelli marco baroni. multimodal word meaning induction minimal exposure natural text. cognitive science issn ./cogs.. mitchell marcus beatrice santorini mary marcinkiewicz. building large annotated corpus english penn treebank. computational linguistics issn ./coli..... volodymyr mnih koray kavukcuoglu david silver andrei rusu joel veness marc bellemare alex graves martin riedmiller andreas fidjeland georg ostrovski stig petersen charles beattie amir sadik ioannis antonoglou helen king dharshan kumaran daan wierstra shane legg demis hassabis. human-level control deep reinforcement learning. nature issn ./nature. jeffrey pennington richard socher christopher manning. glove global vectors word representation. proceedings conference empirical methods natural language processing issn ./v/d-. david rumelhart peter todd. learning connectionist representations. attention performance synergies experimental psychology artiﬁcial intelligence cognitive neuroscience issn ---. adam santoro david raposo david g.t. barrett mateusz malinowski razvan pascanu peter battaglia timothy lillicrap. simple neural network module relational reasoning. arxiv yonghui mike schuster zhifeng chen quoc mohammad norouzi wolfgang macherey maxim krikun yuan klaus macherey jeff klingner apurva shah melvin johnson xiaobing łukasz kaiser stephan gouws yoshikiyo kato taku kudo hideto kazawa keith stevens george kurian nishant patil wang cliff young jason smith jason riesa alex rudnick oriol vinyals greg corrado macduff hughes jeffrey dean. google’s neural machine translation system bridging human machine translation. arxiv used large model described zaremba hyper-parameters pre-training. speciﬁcally model consists layers stacked lstms hidden size units recurrent steps dropout applied non-recurrent connections. gradients clipped global norm weights initialized uniformly loss function cross-entropy loss model predictions. model trained epochs stochastic gradient descent batch size learning rate ﬁrst epochs decayed multiplier epoch remainder training. centroid extracted input embeddings softmax weights softmax biases every word sentence except word. averaged together input embeddings produce input embedding word etc. optimizing initialized input embedding three ways centroid above vector zeros current embedding vector word starting point epochs batch gradient descent learning rate loss used cross entropy loss plus times norm embedding. borrow borrow borrow borrow borrow borrow borrow cowboys cowboys cowboys cowboys cowboys cowboys cowboys immune immune immune immune immune immune immune rice rice rice rice rice rice rice often noted relationships word embeddings capture semantic features words analogies words thus natural extent word vectors produced one-shot learning produce similarity structures close produced full training word. address question computed product word output embedding word output embeddings. vector dot-product results thought similarity word. compared similarity maps similarity maps produced full training word computing correlations similarity maps. different runs full training word produced correlated similarity structures thus appear consistent semantic structure embeddings capturing. however neither centroid optimizing one-shot learning methods seemed capturing structure. centroid method actually produced similarity structures negatively correlated full training similarity structures three four cases optimizing method produced slightly similar structures similarity structures effectively uncorrelated full training similarity structure. word methods produce similarity structure strongly positively correlated structure produced full training word. results difﬁcult interpret. hand consistency semantic knowledge produced network fully trained word suggests discovering important structure. hand later learning approaches actually produce even internally consistency least training several sentences. full training word produces average correlation different training runs whereas optimizing sentences produces average correlation furthermore results section suggest approach well distinguishing contexts word appear. optimizing runs extracting consistent structure well creating different representational structures full training runs. different representations explained removal contextual cues sentences presented isolation networks full training word able attention relationships across sentence boundaries give exposure word co-occurrences one-shot learning approach missing. including surrounding context sentences training might result similar representational structures. figure similarity representational similarity correlated similarity structures generated different methods similarity structure produced training word? commenter draft paper also noted herbelot baroni pursued related questions independently came conclusions reached. however believe results improve upon work several important ways. first able show beneﬁts training deﬁnitions word show beneﬁts learning word context. furthermore evaluated embedding similarity show behaviorally relevant improvements. important conclusion results embedding similarity analyses appendix show dissimilar embeddings nevertheless offer comparable performance. finally explore depth effects varying data parameters like number training sentences analyze improvements occurring perspectives parameters outputs.", "year": 2017}