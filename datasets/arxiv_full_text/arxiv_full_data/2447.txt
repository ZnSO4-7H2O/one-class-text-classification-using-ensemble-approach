{"title": "Data generator based on RBF network", "tag": ["stat.ML", "cs.AI", "cs.LG", "62-07, 62H30, 97N80, 65C10", "I.2.6; I.5.2; I.6.5; G.3; G.4"], "abstract": "There are plenty of problems where the data available is scarce and expensive. We propose a generator of semi-artificial data with similar properties to the original data which enables development and testing of different data mining algorithms and optimization of their parameters. The generated data allow a large scale experimentation and simulations without danger of overfitting. The proposed generator is based on RBF networks which learn sets of Gaussian kernels. Learned Gaussian kernels can be used in a generative mode to generate the data from the same distributions. To asses quality of the generated data we developed several workflows and used them to evaluate the statistical properties of the generated data, structural similarity, and predictive similarity using supervised and unsupervised learning techniques. To determine usability of the proposed generator we conducted a large scale evaluation using 51 UCI data sets. The results show a considerable similarity between the original and generated data and indicate that the method can be useful in several development and simulation scenarios.", "text": "plenty problems data available scarce expensive. propose generator semi-artiﬁcial data similar properties original data enables development testing different data mining algorithms optimization parameters. generated data allow large scale experimentation simulations without danger overﬁtting. proposed generator based networks learn sets gaussian kernels. learned gaussian kernels used generative mode generate data distributions. asses quality generated data developed several workﬂows used evaluate statistical properties generated data structural similarity predictive similarity using supervised unsupervised learning techniques. determine usability proposed generator conducted large scale evaluation using data sets. results show considerable similarity original generated data indicate method useful several development simulation scenarios. technological challenges data analytics facing enormous amount data. challenge well known recently term data coined purpose bring attention develop solutions. however many important application areas excess data problem quite opposite isn’t enough data available. several reasons this data inherently scarce difﬁcult obtain expensive distribution events interests highly imbalanced machine learning approaches lack data causes problems model selection reliable performance estimation development specialized algorithms tuning learning model parameters. certain problems caused scarce data inherent underrepresentation problem cannot solved aspects alleviated generating artiﬁcial data similar original one. example similar artiﬁcial data sets great help tuning parameters development specialized solutions simulations imbalanced problems prevent overﬁtting original data allow sound comparison different approaches. generating data similar general data easy task. background knowledge available problem precious scarce data posses extract properties generate semi-artiﬁcial data similar properties. weather acceptable context problem matter proposed approach assume afford aside least small part data purpose. data lost modeling shall aware extracted properties considering possibility overﬁtting. approaches used existing data generators limited dimensional data assume certain probability distribution mostly normal; review sect. approach limited classiﬁcation problems. ﬁrst construct network prediction model. networks consist gaussian kernels estimate probability density training instances. properties gaussian kernels learned kernels used generative mode produce data. overcome limitation dimensional spaces. show approach successfully used data sets several hundred attributes also mixed data paper organized follows. section review existing work generating semi-artiﬁcial data. section present neural networks properties allow generate data based them. section present actual implementation based rsnns package explain details handling nominal numeric data. section discuss evaluation generated data similarity original data. propose evaluation based statistical properties data well similarity original generated data estimated supervised unsupervised learning methods. section present quality generated data determine working conditions proposed method well suitable parameters. shortly present application generator benchmarking cloud bases data analytics tool. section conclude summary critical analysis ideas work. area data generators full interesting approaches. cover general approaches data generation cover methods speciﬁc certain problem class problems. distribution generated data shall drawn from. scientiﬁc computational engines tools contain random number generators univariate data drawn standard distributions. example system supports uniform normal log-normal student’s chi-squared poisson exponential beta binomial cauchy gamma geometric hypergeometric multinomial negative binomial weibull distribution. additional less-known univariate distribution-based random number generators accessible add-on packages. need univariate data distributions parameters distributions obtained parameters generate data. example package mass provides function ﬁtdistr obtain parameters several univariate distributions. random vector generators based multivariate probability distributions less common. effective random number generators exist multivariate normal distribution variables. simulating data multivariate normal distribution possible matrix decomposition given symmetric positive deﬁnite matrix containing variable covariances. using decomposed matrix sequence univariate normally distributed random variables generate data multivariate normal distribution discussed sect. approach proposed paper relies multivariate normal distribution data generator assume whole data normally distributed. instead ﬁnds subspaces successfully approximated gaussian kernels extracted distribution parameters generate data proportion requirements. generate data nonnormal multivariate distribution several transformational approaches proposed start generating data multivariate normal distribution transform desired ﬁnal distribution. example proposes iterative approximation scheme. iteration approach generates multivariate normal data subsequently replaced nonnormal data sampled speciﬁed target population. iteration discrepancies generated desired correlation matrices used update intermediate correlation matrix. similar approach ordinal data proposed transformational approaches limited dimensional spaces covariance matrix capturing data dependencies successfully estimated. contrast method limited speciﬁc data type. problem space split subspaces dependencies clearly expressed subsequently captured. kernel density estimation method estimate probability density function random variable kernel function. inferences population made based ﬁnite data sample. several approaches kernel basedparameter estimation exist. frequently used kernels gaussian kernels. methods intended dimensional spaces variables interesting approach data simulation copulas copula multivariate probability distribution marginal probability distribution variable uniform. copulas estimated empirical observations describe dependence random variables. based sklar’s theorem states multivariate joint distribution written univariate marginal distribution functions copula describes dependence structure variables. generate data ﬁrst select correct copula family estimate parameters copula generate data. process trivial requires in-depth knowledge data modeled. principle number variables used copula limited practice careful selection appropriate attributes copula family required copulas numeric categorical data exist mixed types whereas approach limited sense. networks proposed function approximation tool using locally tuned processing units mostly gaussian kernels development still continues network consists three layers figure example. input layer input units corresponding input features. hidden layer contains kernel functions. output layer consist single unit case regression many units output classes case classiﬁcations. assume classiﬁcation problem described pairs a−dimensional training instances class labels ...c. hidden units computations network estimate probability class vectors present centers widths kernels. centers kernel widths learned advance. kernel function applied euclidian distance center given instance kernel functions maximum zero distance center activation close zero instances away center. algorithms used train networks require ﬁxed architecture number units hidden layer must determined training starts. avoid manual setting parameter automatically learn kernel centers weights standard deviations several solutions proposed among dynamic decay adjustment work. builds network incrementally adding appropriate number units. unit encodes instances class. process adding units kernel widths dynamically adjusted based information neighbors. rbfs trained algorithm often achieve example rbf-dda network classiﬁcation problem features binary class presented fig. hidden layer rbf-dda network contains gaussian units added layer training. input layer fully connected hidden layer. output layer consists unit possible class. hidden unit encodes instances class therefore connected exactly output unit. classiﬁcation instance winner-takes-all approach used i.e. output unit highest activation determines class value. data generator uses function rbfdda implemented package rsnns port snns software implementation uses parameters positive threshold negative threshold illustrated fig. thresholds deﬁne upper lower bound activation training instances. default values thresholds thresholds deﬁne safety area center conﬂicting class allowed. good separability classes achieved. addition training instance inner circle least center correct class. idea proposed data generation scheme extract local gaussian kernels learned rbf-dda network generate data proportion desired class value distribution. class distribution different empirically observed desired distribution speciﬁed input parameter. notable property gaussian kernels ability used discriminative models also generative models. generate data multivariate normal distribution exploit following property multivariate gaussian distribution want simulate multidimensional given symmetric positive deﬁnite matrix ﬁrst construct sample dimensionality. easily constructed using independent variables next decompose obtained matrix pseudo code proposed generator given figure input generator available data parameters. parameter minw controls minimal acceptable kernel weight. weight kernel deﬁned number training instances achieve maximal activation kernel. learned kernels weight less minw discarded data generator prevent overﬁtting training data. boolean parameter nominalasbinary controls treatment nominal attributes described sect. speciﬁc demands rbf-dda algorithm data preprocessed ﬁrst preprocessing includes normalization attributes preparation nominal attributes function rbfpreparedata returns normalized data normalization parameters used later generating instances. learning algorithm takes preprocessed data returns classiﬁcation model form gaussian kernels store learned parameters gaussian kernels namely centers weights class values kernel weight equals proportion training instances activated k-th gaussian unit. class value unit corresponds output unit connected gaussian unit theoretically extracted information would sufﬁcient generate data however several practical considerations taken account generate data comparable original one. majority instances activated exactly kernel. widths learned kernels therefore prevent overlapping competing classes. purpose generating data kernel shall different would generate instances near proximity kernel centers i.e. existing training instances. approach adopted take training instances activate particular kernel estimate empirical variance dimension later generation phase used width gaussian kernel. matrix extracted network diagonal elements presenting spread training instances dimension. algorithm returns data generator consisting list kernel parameters normalization parameters rbfdda function accept missing values impute several advanced imputation strategies exist classiﬁcation accuracy uttermost importance case resorted median based imputation numeric attributes nominal attributes frequent category. gaussian kernels deﬁned numeric attributes rbfdda treats attributes including nominal numeric. nominal attribute converted numeric simply assigning category unique integer number categories problematic transformation established order categorical values converted attribute inexistent original attribute. example attribute color categories {red green blue} converted values respectively meaning category closer green blue. solve problem binary parameter nominalasbinary encode nominal attributes several binary attributes parameter true nominal attributes categories encoded number binary attributes equal number categories. category encoded binary attribute. value nominal attribute equals given category value corresponding binary attribute values encoding binary attributes equal e.g. color attribute three categories would encoded three binary attributes credcgreencblue. value attribute color green binary encoding value cred cgreen andcblue binary encoding required also class values rbfdda function expects data normalized want generate data original unnormalized form store computed normalization parameters together attribute encoding information pass back calling rbfgen function. generator generate instances. default method generates class values proportionally number class values training generator user specify desired class distribution parameter data generator consists list parameters describing gaussian kernels information attribute transformations recall information kernel contains location kernel’s center weight kernel class value estimated standard deviation input newdata function also parameters size specifying number instances generated desired distribution class values controlling width kernels aultspread width kernel estimated width function starts creating empty data generates instances kernels stored kernel list .the weight kernel desired class probability overall number instances generated size determine number instances generated kernel weight kernel normalized weights class kernels presents indicator function. width kernel normalization encoding size number instances generated vector desired class distribution parameter controlling width kernels aultspread width kernel estimated width else silverman heuristic rule mvrnorm generate data kernel makeconsistent check inconsistencies assign class value kernel append generated data decode nominal attributes spread estimated training data zeros individual dimensions optionally replaced value parameter aultspread. kernel width also possible generalization silverman’s rule thumb multivariate case case covariance matrix used diagonal i.e. diag kernel width dimension covariance matrix function exploits property gaussian kernels decomposes covariance matrix eigenvalue decomposition. generated data checked consistency i.e. generated attribute values interval nominal attributes rounded values encoding existing categories etc. instances rejected process practice generate instances mvrnorm retain desired number them. assign class value generated instances append data generated kernels transform generated instances original scale encodings. nominal attribute check encoding transform back original form numeric attributes denormalized transformed back original scale using minimums spans stored function returns generated data demonstration generator graphically present generated data simple data sets. ﬁrst data forms dimensional grid attributes generated three gaussian kernels centers group instances assigned unique class value illustrated generator based data consists eight gaussian kernels illustrate instances generated generator rbfdda learner exact locations original centers approximated data several kernels difference original generated data individual statistics close shown table four features measured sample length width sepals petals centimeters. scatter plots original data sets shown fig. class values marked different colors. generator based data consisting gaussian units generated instances shown fig. graphs show considerable similarity matching pairs scatter plots. aware data generator capable generating data similar existing data sets limitations number type attributes. quality existing data generators mostly evaluated comparing standard statistics mean median standard deviation skewness kurtosis. statistics important indicators quality generated data insufﬁcient data sets attributes computed attribute separately thereby presenting overall view data take possible interactions attributes account difﬁcult compare number attributes increases. statistics also convey information appropriate similar generated data machine learning data mining tasks. resolve difﬁculties quantify similarity original generated data developed several data quality measures described below. measures incorporating standard statistics measures based clustering measures based classiﬁcation performance. standard statistics numeric attributes mean standard deviation skewness kurtosis. compare also value distributions attributes original generated data. hellinger distance kolmogorov-smirnov test workﬂow whole process illustrated normalize numeric attribute make comparison attributes sensible. input comparison data sets comparison attributes’ statistics computed data sets tedious especially data sets large number attributes. therefore ﬁrst compute standard statistics attributes subtract statistics second data statistics ﬁrst data set. summarize results report average difference statistics. compare distributions attribute values hellinger distance discrete attributes test numerical attributes. hellinger distance discrete univariate distributions deﬁned overall picture report average hellinger distance discrete attributes percentage numeric attributes p-value test null hypothesis attributes’ values data sets drawn form distribution. averages strict statistical meaning illustrate similarity data sets. cluster information important introspection structure data. compare similarity clusterings obtained data sets estimate similarity based clusterings adjusted rand index starting data data points assume different clusterings namely ...uu} ...vv} u∩···∩uu ∪···∪uu ∩···∩vv ∪···∪vv information overlap clusters expressed contingency table shown table rand index lies takes value clusterings identical value pair points appear either cluster different clusters desirable similarity indicator would take value close zero random clusterings true adjusted rand index ﬁxes using generalized hypergeometric distribution model randomness computes expected number entries contingency table. deﬁned used compare different clusterings instances want compare similarity different sets instances. overcome obstacle cluster data sets separately extract medoids clusters clustering. medoid cluster existing instance cluster whose average similarity instances cluster maximal. instance ﬁrst data nearest medoid second clustering assign cluster thereby getting joint clustering data sets based cluster structure second data set. repeat analogous procedure second data joint clustering based ﬁrst data set. joint clusterings deﬁned instances therefore asses similarity clusterings compare structure data sets. workﬂow cluster based comparison data sets illustrated fig. need assign instances existing clustering selected partitioning medoids clustering algorithm which besides partitions outputs also medoids. distance medoids criterion assign instances existing clusters. clustering implemented package cluster method ﬁrst computed distances instances data using gower’s method method normalizes numeric attributes uses scoring number clusters estimated optimal value separately original generated data set. number clusters estimated optimum average silhouette width method computed package computed package mclust classiﬁcation probably important task machine learning data mining. judgment good substitute original data generated instances therefore largely dependent classiﬁcation similarity data sets. scenario propose measure similarity classiﬁcation performance shown fig. basic idea train models original data generated data. models tested unseen original generated data performances compared. performance model trained original data comparable original generated data indicator generated data within original distribution performance model trained generated data comparable original generated data shows generated data enables comparable learning good coverage original distribution therefore generator able produce good substitutes original data concerning machine learning data mining. additionally model trained original data achieves better performance generated data original data indicates generator oversimpliﬁed cover peculiarities original data. testing workﬂow start data sets split randomly stratiﬁed halves four splits used train classiﬁer name resulting models respectively. evaluate performance models data unseen training tested tested uses uses testing set. test produces performance score average -fold cross-validation following estimates estimates already convey important information discussed above subtract performances difference opinion important indicator suitable generated data development classiﬁcation methods. ideal case difference would close zero generated data would good substitute lack original data expect performance developed methods comparable used original data. want verify proposed generator produces data consistent original covers whole space original data does. determine working conditions generator data works fails sort problems veritably reproduces original less successful. ﬁrst describe evaluation scenario compare original generated data. afterwards examine parameters generator propose reasonable defaults. evaluate generator performed large scale empirical evaluation using data sets repository great variability number attributes types attributes number class values. used package readmldata provides uniform interface manipulation data sets. assuming would mostly desire generate semi-artiﬁcial data number original instances rather small keep computational load evaluation limited number original instances taking conditions account extracted classiﬁcation data sets collection data sets kindly provided author package readmldata. characteristics data sets presented table data generator based rbfdda learner constructed function rbfgen used value parameter minw data sets compared variants encoding nominal attributes. produced generator used generate number instances original data distribution classes using function newdata width kernels estimated training instances setting parameter var=estimated. table characteristics data sets used. column number instances number attributes numeric number numeric attributes discrete number discrete attributes average number values discrete attribute number class values majority proportion majority class percent missing percentage missing values. dataset annealing arrhythmia audiology automobile balance-scale breast-cancer breast-cancer-wdbc breast-cancer-wisconsin bridges.version bridges.version bupa credit-screening cylinder-bands dermatology ecoli ﬂags glass haberman heart-disease-cleveland heart-disease-hungarian hepatitis horse-colic house-votes- ionosphere iris labor-negotiations lymphography monks- monks- monks- pima-indians-diabetes post-operative primary-tumor promoters sonar.all soybean-large spect-spect spect-spectf spectrometer sponge statlog-australian statlog-german statlog-german-numeric statlog-heart statlog-vehicle thyroid-disease-new tic-tac-toe vowel-context wine skewness kurtosis difﬁcult relevant data attribute separately exclude skewness kurtosis summary comparisons section. numeric attributes computed p-values tests null hypothesis attribute values compared data sets drawn distribution. report percentage numeric attributes hypothesis rejected level discrete attributes compared similarity value distributions using hellinger distance. response variables excluded data sets comparison similarity distributions enforced generator. report average hellinger distance discrete attribute data results below. clustering structure original constructed data sets compared k-medoids clustering using presented workﬂow fig. response variables excluded data sets. data sets exhibits high variance report average repetitions generating data. classiﬁcation performance compared predictive similarity data sets using classiﬁcation accuracy random forests illustrated workﬂow fig. selected random forests robust performance learning algorithm various conditions implementation used comes package corelearn default parameters used built random trees number randomly selected attributes nodes square root number attributes. report cross-validated performances models trained tested data sets. results comparisons presented table integer encoding nominal attributes. column labeled present number gaussian kernels constructed generator. relatively large number units needed adequately represent training data. nevertheless generator construction time seconds seen column labeled measurements used single core intel running .ghz. time generate data instances cases report column labeled gives percentage generated instances exactly equal original instances. mostly happens data sets discrete attributes whole problem space small identical instances expected. exception datasets horse-colic primary-tumor breast-cancer generators contain majority gaussian units activation instance. reason large number attributes consequently poor generalization rbfdda algorithm table number gaussian units table table comparison original generated data sets. columns number gaussians generator construction time seconds proportion generated instances exactly equal original instances mean average difference means normalized numeric attributes average difference standard deviation normalized numeric attributes percentage p-values tests comparing matching numeric attributes average hellinger distance matching discrete attributes adjusted rand index mxdy classiﬁcation accuracy percents model trained data tested data dash means given comparison applicable data set. dataset annealing arrhythmia audiology automobile balance-scale breast-cancer breast-wdbc breast-wisconsin bridges.version bridges.version bupa credit-screening cylinder-bands dermatology ecoli ﬂags glass haberman heart-cleveland heart-hungarian hepatitis horse-colic house-votes- ionosphere iris labor-negotiations lymphography monks- monks- monks- pima-diabetes post-operative primary-tumor promoters sonar.all soybean-large spect-spect spect-spectf spectrometer sponge statlog-australian statlog-german statlog-german-n statlog-heart statlog-vehicle thyroid-new tic-tac-toe vowel-context wine cases shows moments distributions individual attributes close originals. distributions individual attributes compared test numeric attributes hellinger distance discrete attributes. column labeled gives percentage p-values tests comparing matching numeric attributes using null hypothesis original generated data drawn distribution. data sets attributes ks-test detects differences distributions. column labeled presents average hellinger distance matching discrete attributes. many data sets distances also data sets distances relatively high indicating distribution differences considerable discrete attributes. suitability generator development simulation benchmarking tools data mining evidenced comparing clustering classiﬁcation performance. column labeled presents adjusted rand index. observe clustering similarity considerable many data sets also data sets low. columns report cross-validated classiﬁcation accuracy random forest models trained either original generated data tested original generated data. general trend observed majority data sets model trained original data performs better generated data original data indicates complexity original data lost generated data. conﬁrmed also models built generated data mostly perform better generated original data nevertheless generated data satisfactory substitute data mining many cases namely models build generated data outperforms model built original data tested original data half cases overall conclusion therefore considerable number data sets proposed generator generate semi-artiﬁcial data reasonable substitute development data mining algorithms. discussed sect. encode nominal attribute binary attributes instead single integer attribute avoid making unjustiﬁed assumption order attribute’s values. report results tests using binary encoding table binary encoding nominal attributes used nominal non-binary attribute report results data sets include least attribute. number gaussian kernels mostly larger binary encoding attributes generator construction time differences relatively small which case zero estimated variance certain dimension replaces unrealistic value constant variance typically results default value defaultspread=. reported table table comparison original generated data sets using binary encoding nominal attributes value parameter defaultspread=.. meaning columns table dataset annealing arrhythmia audiology automobile balance-scale breast-cancer breast-cancer-wdbc reast-cancer-wisconsin bridges.version bridges.version bupa credit-screening cylinder-bands dermatology ecoli ﬂags glass haberman eart-disease-cleveland eart-disease-hungarian hepatitis horse-colic house-votes- ionosphere iris labor-negotiations lymphography monks- monks- monks- pima-indians-diabetes post-operative primary-tumor promoters sonar.all soybean-large spect-spect spect-spectf spectrometer sponge statlog-australian statlog-german statlog-german-numeric statlog-heart statlog-vehicle thyroid-disease-new tic-tac-toe vowel-context wine bined table data sets missing table wilcoxon paired rank test level shows setting produces signiﬁcantly lower proportion equal instances lower difference means numeric attributes lower difference differences signiﬁcant level. approximation original data nevertheless better recommend experimentation setting using safe default. tried determine conditions based data generation works well. ﬁrst hypothesis tested whether success classiﬁcation algorithm related success based data generation. compared classiﬁcation performance rbfdda performance random forests. selected random forests successful classiﬁers known robust performance using cross-validation compared classiﬁcation accuracy rbfdda algorithm rsnns package random forest implemented corelearn package using default parameters classiﬁers. unsurprisingly random forests produced signiﬁcantly higher accuracy auc. report results accuracy four left-hand side columns table results highly similar skip them. tried identify main factors affecting success proposed based data generator. measure success difference classiﬁcation accuracy models trained original data generated data tested original data difference labeled table factors possibly affecting indicator difference classiﬁcation accuracies number instances number attributes number instances attribute number gaussians generator average number instances gaussian kernel number attributes gaussian kernel. factors collected table table show correlation pearson’s correlation coefﬁcients indicate largest correlation performance difference classiﬁcation accuracy number attribute number gaussian kernels. factors indicators difﬁculty problem classiﬁer hinting usability proposed generator depends ability learning method capture structure problem. tried predict success data generator using stepwise linear model independent variables above turned difference classiﬁcation accuracy variable needed. prediction methods also successful. table different factors might inﬂuence quality rbf-based data generator. columns classiﬁcation accuracy rbfdda classiﬁer percents classiﬁcation accuracy random forests percents difference classiﬁcation accuracy percents difference classiﬁcation accuracy percents number instances number attributes number instances attribute number gaussian kernels generator average number instances gaussian unit number attributes gaussian unit. dataset annealing arrhythmia audiology automobile balance-scale breast-cancer breast-cancer-wdbc breast-cancer-wisconsin bridges.version bridges.version bupa credit-screening cylinder-bands dermatology ecoli ﬂags glass haberman heart-disease-cleveland heart-disease-hungarian hepatitis horse-colic house-votes- ionosphere iris labor-negotiations lymphography monks- monks- monks- pima-indians-diabetes post-operative primary-tumor promoters sonar.all soybean-large spect-spect spect-spectf spectrometer sponge statlog-australian statlog-german statlog-german-numeric statlog-heart statlog-vehicle thyroid-disease-new tic-tac-toe vowel-context wine development data cloud based framework clowdflows wanted test several classiﬁcation algorithms components framework also capabilities scalability framework. though several examples public data problems freely available requires preprocessing adaptations speciﬁcs problem. development already required signiﬁcant effort everyone involved additional effort undesired. rbfdatagen contained open-source package semiartiﬁcial turned require little additional work provided required testing data desired characteristics. generated several data sets different characteristics needed development evaluation framework. present original practically useful generator semi-artiﬁcial data successfully tested development data tools. generator captures structure problem using classiﬁer exploits properties gaussian kernel generate data similar original one. expect tool useful development adaptation data analytics tools speciﬁcs data sets. possible uses data randomization ensure privacy simulations requiring large amounts data testing data tools benchmarking scenarios huge amounts data. developed series evaluation tools provide estimate generator’s performance speciﬁc data sets. using large collection data sets able show generator cases successful generating artiﬁcial data similar original. success generator related success classiﬁer successfully capture properties original data generator based also successful vice versa. nevertheless unable create successful prediction model quality generator. user therefore advised provided evaluation tools speciﬁc data set. provided results shall provide good indication usability generated data intended use. proposed generator together statistical clustering classiﬁcation performance indicators turned open-source package semiartiﬁcial future plan extend generator modules using different learning algorithms capture data structure generate data. interesting approach would also rejection approach uses probability density estimates based various learning algorithms. many thanks petr savicky interesting discussions subject preparation data sets used paper. author supported slovenian research agency research programme", "year": 2014}