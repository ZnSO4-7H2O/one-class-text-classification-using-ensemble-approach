{"title": "Weighted Spectral Cluster Ensemble", "tag": ["cs.LG", "cs.AI", "stat.ML"], "abstract": "Clustering explores meaningful patterns in the non-labeled data sets. Cluster Ensemble Selection (CES) is a new approach, which can combine individual clustering results for increasing the performance of the final results. Although CES can achieve better final results in comparison with individual clustering algorithms and cluster ensemble methods, its performance can be dramatically affected by its consensus diversity metric and thresholding procedure. There are two problems in CES: 1) most of the diversity metrics is based on heuristic Shannon's entropy and 2) estimating threshold values are really hard in practice. The main goal of this paper is proposing a robust approach for solving the above mentioned problems. Accordingly, this paper develops a novel framework for clustering problems, which is called Weighted Spectral Cluster Ensemble (WSCE), by exploiting some concepts from community detection arena and graph based clustering. Under this framework, a new version of spectral clustering, which is called Two Kernels Spectral Clustering, is used for generating graphs based individual clustering results. Further, by using modularity, which is a famous metric in the community detection, on the transformed graph representation of individual clustering results, our approach provides an effective diversity estimation for individual clustering results. Moreover, this paper introduces a new approach for combining the evaluated individual clustering results without the procedure of thresholding. Experimental study on varied data sets demonstrates that the prosed approach achieves superior performance to state-of-the-art methods.", "text": "aggregation method important challenges selecting better partitions ensemble committee generating ﬁnal result. wide range ideas solving mentioned challenges although methods improve performance robustness ﬁnal results using wide range threshold values employing entropy based metric main weak points method. threshold values different data mentioned methods; really hard optimum values real-world applications. moreover real-world data sets logarithm behavior. prove entropy based methods estimate diversity based logarithm best choice evaluate diversity. paper proposes novel methodology solving clustering problems without mentioned weak points. mentioned before four stages cluster ensemble selection i.e. generating individual clustering results evaluating selecting combining ﬁnal clustering result. although achieve better result comparison individual clustering algorithms cluster ensemble methods accuracy fully sensitive process thresholding selecting individual clustering results consensus metric used diversity quality estimation results. unfortunately hard optimum threshold values practice; metrics used diversity quality estimation heuristic; especially based shannons entropy. main goal paper solving mentioned problems. paper proposes method estimating diversity generated individual clustering results using redeﬁned version modularity based expected value introduced community detections applications. further paper introduces novel approach combining evaluated individual clustering results without process thresholding. contribution paper summarized follows firstly study proposes greedy method based feedback mechanism employs idea bisecting k-means generating individual results. that paper introduces kernels spectral clustering generating individual clustering results. abstract—clustering explores meaningful patterns non-labeled data sets. cluster ensemble selection approach combine individual clustering results increasing performance ﬁnal results. although achieve better ﬁnal results comparison individual clustering algorithms cluster ensemble methods performance dramatically affected consensus diversity metric thresholding procedure. problems diversity metrics based heuristic shannon’s entropy estimating threshold values really hard practice. main goal paper proposing robust approach solving mentioned problems. accordingly paper develops novel framework clustering problems called weighted spectral cluster ensemble exploiting concepts community detection arena graph based clustering. framework version spectral clustering called kernels spectral clustering used generating graphs based individual clustering results. further using modularity famous metric community detection transformed graph representation individual clustering results approach provides effective diversity estimation individual clustering results. moreover paper introduces approach combining evaluated individual clustering results without procedure thresholding. experimental study varied data sets demonstrates prosed approach achieves superior performance state-of-the-art methods. clustering discovering meaningful patterns non-labeled data sets main tasks machine learning. generally individual clustering algorithms provide different accuracies complex data generate clustering results optimizing local global function instead natural relations data points data set. novel solution cluster ensemble combines different clustering results proposed achieving better ﬁnal result cluster ensemble selection solution combines selected group best individual clustering results according consensus metric ensemble committee order improve accuracy ﬁnal results evaluation metric thresholding selection strategy algorithm generates hybrid individual clustering results contains partitional results modular results. simple clustering problems method generates partitional results; also generates modular results represented graph alternative evaluating combining individual results. next satisfy diversity criterion study proposes normalized modularity redeﬁned version modularity criterion community detection evaluating diversity individual results general clustering problems. unlike diversity metrics based shannon’s entropy metric uses expected value probabilistic theory evaluating individual clustering results avoids undesired logarithm lastly paper proposed weighted evidence accumulation clustering obtain ﬁnal clustering weighted combination individual results. weight individual result weac estimated different metrics normalized modularity used paper. rest paper organized follows section study ﬁrst brieﬂy reviews related works cluster ensemble selection. then introduces proposed weighted spectral clustering ensemble framework section experimental results reported section ﬁnally paper presents conclusion pointed future works section unsupervised method clustering discovers meaningful patterns non-labeled data sets. wide range studies increase performance clustering algorithms. instance zhang introduced multi-manifold regularized nonnegative matrix factorization framework preserve locally geometrical structure manifolds multi-view clustering anyway individual clustering algorithms provide different accuracies complex data generate clustering results optimizing local global function instead natural relations data points data generally cluster ensemble important steps firstly generating individual clustering results using different algorithms changing number partitions. then combining primary results generating ﬁnal ensemble. step performed consensus functions idea partitions suitable cooperating generate ﬁnal clustering proposed instead combing achieved individual results combine selected group best individual results according consensus metric ensemble committee order improve accuracy ﬁnal results fern developed method effectively select individual clustering results ensemble ﬁnal decision azimi proved diversity maximization effective approach real-world applications. explored thresholding procedure must done based complexity quality data sets proposed diversity measurement works based normalized mutual information romano proposed standardized mutual information evaluating clustering results yousefnezhad introduced independency metric instead quality metric evaluating process solving problem alizadeh concluded disadvantages symmetric criterion. used apmm maximum metrics measure diversity stability respectively suggested method building co-association matrix subset base cluster results alizadeh introduced wisdom crowds cluster ensemble novel method base theory social science although method generate high performance stable results comparison methods using wide range thresholds employing different types clustering algorithms generating individual results main problems method. alizadeh used based shannon’s entropy diversity evaluation; basic parameter independency uses initialized values individual clustering algorithms random seeds ﬁrst iterative k-means independency evaluation. addition introduced feedback mechanism generating high-quality results graph based clustering methods spectral clustering generates high-performance results applied different applications; i.e. image segmentation community detection arena. introduced method automating process laplacian creation medical applications; especially fmri segmentation method used standard laplacians perform poorly chen proposed clustering algorithm based graph clustering optimizing appropriate weighted objective larger weights given observations lower uncertainty introduced graph-based consensus maximization method combining multiple supervised unsupervised models. method consolidated classiﬁcation solution maximizing consensus among supervised predictions unsupervised constraints generating individual clustering results proposed method partitions clusters denotes number clusters individual results individual result reference set. paper uses range generating individual results number clusters ﬁnal result. bisect k-means algorithms instead applying algorithm generated results iterative proposed method stores result ensemble committee; evaluates combines results. words reference denotes k+}. number instances denotes instance data points. beginning paper minimized correlation features. denotes follows data points denotes simple average calculated it’s clear zero-mean. words excepted value zero follows denotes index words correlation problem changed variance probe. maximizing based variance omitted correlation features. since scale data mapping must same assume following equation paper calculates non-symmetric distances matrix denoted rest paper proposed method applied matrix individual clustering results. moreover paper uses transform function converting distances matrix similarity matrix transformation optimize memory usage calculated euclidean distance. scaling parameter controls rapidly afﬁnity falls distance data points. paper uses method estimating value automatically paper introduces kernels spectral clustering algorithm generate individual results unlike normal clustering algorithms generate partition result tksc algorithm generates independent consequences called partitional result modular result individual clustering results using kernels partitional result partitioning data points result clustering methods; modular result network data points represented graph. paper uses modular result reference evaluating diversity generated partition using community detection methods furthermore kernel tksc refers laplacian equation spectral methods transforms data points environment especially linear environment non-linear data sets. shows i-th j-th column matrix used omitting effect zeros matrix paper uses generating experimental results. also denotes number instances data normalized matrix eigenvectors calculated follows calculated function ﬁnds biggest value matrix further values matrix called modular result zero one. algorithm shows pseudo code tksc method. tracing errors control similarity repetition speciﬁc answers clustering problems. wide range metrics based shannon’s entropy evaluating diversity individual results methods apmm shannon’s entropy uses logarithm probability individual results figure traditional represents number clusters shared objects indices number partitions pair instances simultaneously presented. method assumes weights individual clustering results same. paper proposes weighted optimizing method using weight individual clustering results instead counting shared clusters. weight different deﬁnitions applications paper uses average normalized modularity algorithms weight matrix. methods generate dendrogram based number clusters result recent years many papers used highperformance consensus function combining individual results uses number clusters shared objects number partitions selected pair objects simultaneously presented generating cell co-association matrix. figure illustrates effect equation shape dendrogram. represents number clusters shared objects indices number partitions pair instances simultaneously presented. matter fact; considers weights algorithms results same. instead counting indices paper uses following equation called weighted generating co-association matrix. equation; also weight combining instances. although weight different deﬁnitions applications paper uses average normalized modularity algorithms follows combining individual results generate similarity matrix using generate diagonal matrix using generate applying generate using generate matrix eigenvectors generate normalized using generate applying kmeans return evaluating diversity mathematical prove real-world data sets logarithmic behavior. community detection arena modularity based expected value proposed solving problem. recently many papers proved modularity estimate diversity graph data sets better entropy based methods. unfortunately modularity measure diversity graph data paper proposes tksc generate graph based result called modular result types data sets real-world application. since modularity deﬁned community detection arena paper introduces redeﬁned version modularity metric general clustering problems called normalized modularity used evaluating diversity individual results based modular result tksc follows calculated respecmij); cluster’s numbers i-th j-th instances partitional result also show degree i-th j-th nodes graph matrix addition calculated follows diversity evaluation rest section describe used evaluating individual clustering results. thresholding used selecting evaluated individual results ces. co-association matrix generated using consensus function selected results. lastly ﬁnal result generated applying linkage methods co-association high values; also effects individual results near zero algorithms small values metric. result paper omits effect quality individual results using mentioned mechanism instead selecting thresholding procedures. further ﬁnal co-association matrix symmetric matrix generated follows number data points; denotes ﬁnal aggregation instances. algorithm illustrates pseudo code proposed method. algorithm data set; number clusters ﬁnal result; ﬁnal result partition. distances also measured euclidean metric. tksc function builds partitions modules individual results; function evaluates results using then evaluated results added reference set. weac function generates co-association matrix according using normalized modularity values partitional results. average-linkage function creates ﬁnal ensemble according average linkage method data points number clusters number features output ﬁnal result method generate using algorithm generate matrix using based generate co-association matrix average linkage world application. since real dataset doesnt class labels direct evaluation method estimating performance unsupervised methods. like many pervious researches paper compares performance proposed method individual clustering methods cluster ensemble methods using standard datasets real classes. although evaluation cannot guarantee proposed method generate high performance datasets comparison methods considered example analyzing probability predicting good results wsce. results proposed method compared individual algorithms k-means maximum likelihood estimator well apmm wocce bgcm state-of-the-art cluster ensemble methods. paper reported empirical results k-means algorithm classical clustering methods. furthermore alternative clustering methods empirical results proposed method compared bgcm methods. also paper uses unsupervised version bgcm method representing effect uniformity performance ﬁnal results compares state-of-the-art metrics diversity evaluation last least experimental results paper compared wocce another method uses independency estimation. algorithms implemented matlab authors order generate experimental results. results reported averaging results independent runs algorithms used experiment. also number individual clustering results reference ensemble mentioned algorithms experiments certain speciﬁcations. paper uses three different groups data sets generating experimental results; i.e. image based data sets document based data sets others. table illustrates properties data sets. paper uses usps digits data collection gray-scale images natural handwritten digits available furthermore paper uses alzheimer’s diseases neuroimaging initiative data subjects another image based real-world data set. data contains images human brian categories recognizing alzheimer diseases. ﬁrst category data partitions subjects three groups health control mild cognitive impairment alzheimer’s diseases second category four groups partitioned high risk groups paper uses possible forms data using features features features categorize. information adni- available document based data newsgroups collection approximately newsgroup documents partitioned evenly across different newsgroups. newsgroups closely related other others highly unrelated. become popular data experiments text applications machine learning techniques text classiﬁcation text clustering. moreover reuters widely used test collections text classiﬁcation research. data collected labeled carnegie group inc. reuters ltd. largest classes data set. rest standard data sets chosen data sets diversity numbers clusters features samples. further features normalized mean variance i.e. section performance proposed method analyzed. words ﬁnal clustering performance evaluated re-labeling obtained clusters ground truth labels counting percentage correctly classiﬁed samples results proposed method compared individual algorithms spectral clustering well apmm wocce bgcm state-of-the-art cluster ensemble methods. main reason comparing proposed method spectral clustering show effect tksc framework performance ﬁnal results. furthermore alternative graph based clustering methods empirical results wsce compared bgcm methods. paper uses unsupervised version bgcm method representing effect normalized modularity performance ﬁnal results compares three state-of-theart metrics diversity evaluation based shannons entropy. paper doesn’t optional feature selection section experimental results given table table best result achieved data highlighted bold. depicted table although individual clustering algorithms shown acceptable performance data sets cannot recognize true patterns them. mentioned earlier paper order solve clustering problem individual algorithm considers special perspective data based objective function. achieved results individual clustering algorithms depicted table good evidence claim. furthermore results generated apmm wocce show effect aggregation method improving accuracy ﬁnal results. according table bgcm proposed algorithm generated better results comparison individual ensemble algorithms. even though proposed method outperformed number algorithms four data sets majority results demonstrate superior accuracy proposed method comparison algorithms. addition difference performance proposed method best result four data sets lower effect noise missed-values performance clustering algorithms discussed section. optional feature selection proposed method doesn’t section figure effect noise features data sets analyzed performance proposed method. ﬁgure represents performance wsce wocce bgcm apmm noisy data sets. experiment features arcene cnae- data sets randomly changed. ﬁgure shows proposed method generates stable results normalized modularity provides robust diversity evaluation selecting stable individual results. mentioned before shannon’s entropy uses logarithm probability individual results evaluating diversity mathematical prove realworld data sets logarithmic behavior. experiment best evidence claim. figure demonstrates analysis effect missed-values data sets performance clustering algorithms. ﬁgure illustrates performance wsce wocce bgcm apmm data sets missed-values. experiment values attributes arcene cnae- data sets randomly missed figure proposed method bgcm generate stable results. advantage proposed method comparison non-graph based methods. since proposed method uses tksc algorithms generating partitional modular results signiﬁcantly handle miss values. words local error individual results missed-value destroy edge modular result recognized comparing modular result partitional result diversity evaluation using metric. another reason exploiting proposed framework clustering problems. paper employs various data sets i.e. dimension data sets highdimension data sets middle-dimension also image based data sets analyzing performance proposed method. figure illustrates relationship performance proposed method based percentage selected features different data sets. vertical axis refers performance horizontal axis refers percentage selected feature data set. ﬁgure optional feature selection signiﬁcantly increase performance ﬁnal results high-dimensional data sets; also dramatically decrease performance low-dimensional data sets. further effective middle-dimension data sets. paper offers optional features selection used high-dimensional data sets handling features-sparsity. challenges cluster ensemble selection i.e. proposing robust consensus metric diversity evaluation estimating optimum parameters thresholding procedure selecting evaluated results. paper introduces novel solution solving mentioned challenges. employing concepts community detection arena graph based clustering paper proposes novel framework clustering problems called weighted spectral cluster ensemble framework version spectral clustering called kernels spectral clustering used generating graphs based individual clustering results; i.e. partitional result modular result. instead entropy based methods traditional paper introduces normalized modularity redeﬁned version modularity community detection arena general clustering problems. used transformed graph representation individual clustering results providing effective diversity estimation. moreover paper introduces solution combining evaluated individual clustering results without procedure thresholding called weighted evidence accumulation clustering weight individual result weac estimated different metrics used paper. validate effectiveness proposed approach extensive experimental study performed comparing individual clustering methods well cluster ensemble methods large number data sets. results clearly show superiority approach normal data sets noise missing values. future plan develop version normalized modularity estimating diversity partitional results directly. thank sheng-jun huang helpful suggestions anonymous reviewers comments. work supported part national natural science foundation china jiangsu natural science foundation distinguished young scholar nuaa fundamental research funds yousefnezhad alizadeh minaei-bidgoli cluster ensemble selection method based diversity independent metrics conference information knowledge technology zhang zhao zong multi-view clustering multi-manifold regularized nonnegative matrix factorization ieee international conference data mining series december romano bailey vinh verspoor standardized mutual information clustering comparisons step adjustment chance international conference machine learning june liang graph-based consensus maximization approach combining multiple supervised unsupervised models ieee transactions knowledge data engineering vol. zhang label-alignment-based multi-task feature selection multimodal classiﬁcation brain disease nips workshop machine learning interpretation neuroimaging december", "year": 2016}