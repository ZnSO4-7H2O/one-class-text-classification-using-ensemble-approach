{"title": "Open Vocabulary Scene Parsing", "tag": ["cs.CV", "cs.AI"], "abstract": "Recognizing arbitrary objects in the wild has been a challenging problem due to the limitations of existing classification models and datasets. In this paper, we propose a new task that aims at parsing scenes with a large and open vocabulary, and several evaluation metrics are explored for this problem. Our proposed approach to this problem is a joint image pixel and word concept embeddings framework, where word concepts are connected by semantic relations. We validate the open vocabulary prediction ability of our framework on ADE20K dataset which covers a wide variety of scenes and objects. We further explore the trained joint embedding space to show its interpretability.", "text": "figure propose open vocabulary framework given input image perform scene parsing concept retrieval concept synthesis arithmetic operations joint image-concept embedding space. solve problem propose framework able segment objects image using open vocabulary labels. particular method strives label pixel word used human annotator resorts taxonomy sure prediction. result model aims make plausible predictions even categories shown training e.g. model never seen tricycle still give conﬁdent guess vehicle performing like human. framework incorporates hypernym/hyponym relations wordnet help parsing. concretely word concepts image pixel features embedded joint high-dimentional vector space hypernym/hyponym relations preserved concepts image pixel embeddings close concepts related annotations according distance measures. framework offers three major advantages predictions made structured i.e. intermediate nodes wordnet thus yielding reasonable mistakes; end-to-end trainable system vocabrecognizing arbitrary objects wild challenging problem limitations existing classiﬁcation models datasets. paper propose task aims parsing scenes large open vocabulary several evaluation metrics explored problem. proposed approach problem joint image pixel word concept embeddings framework word concepts connected semantic relations. validate open vocabulary prediction ability framework adek dataset covers wide variety scenes objects. explore trained joint embedding space show interpretability. grand goals computer vision recognize segment arbitrary objects wild. recent efforts image classiﬁcation/detection/segmentation shown trend emerging image datasets enable recognition large-scale image captioning seen special instance task however nowadays recognition models still capable classifying objects level human particular taking account taxonomy object categories. ordinary people laymen classify things entry-levels experts give speciﬁc labels object single correct label prediction vocabulary inherently open-ended. furthermore widely-accepted evaluate open-ended recognition tasks also main reason direction pursued often. work pushing towards open vocabulary scene parsing model predictions limited ﬁxed categories also words larger dictionary even knowledge graph. considering existing image parsing datasets contain small number categories much model learn images given extra semantic knowledge like wordnet dictionary wordvec external corpus. ulary huge easily extensible; framework leaves freedom annotations inconsistent annotations workers different domain knowledge less affect performance model. additionally explored several evaluation metrics useful measures open vocabulary parsing tasks also large-scale recognition tasks confusions often exist. open vocabulary parsing ability proposed framework evaluated recent adek dataset explore properties embedding space concept retrieval classiﬁcation boundary loosing concept synthesis arithmetics. semantic segmentation scene parsing. astonishing performance deep learning particular cnns pixel-wise dense labeling received significant amount attention. existing work include fully convolutional neural network deconvolutional neural network encoder-decoder segnet dilated neural network etc. networks perform well datasets like pascal object categories cityscapes classes recently released benchmark sceneparse covering frequent daily objects. however models easily adaptable objects. paper going beyond limit make predictions wild. learning addresses knowledge transfer generalization models often evaluated unseen categories predictions made based knowledge extracted training categories. rohrbach introduced idea transfer large-scale linguistic knowledge vision tasks. socher frome directly embedded visual features word vector space visual similarities connected semantic similarities. norouzi used convex combination visual features training classes represent categories. attribute-based methods another major direction zero-shot learning maps object attribute labels language descriptions visual classiﬁers hierarchical classiﬁcations. hierarchical classiﬁcation addresses common circumstances candidate categories share hierarchical semantic relations. zweig combined classiﬁers different levels help improve classiﬁcation. deng achieved hierarchical imagelevel classiﬁcation trading accuracy gain optimization problem. ordonez hand proposed make entry-level predictions dealapproach hierarchical parsing inspired order-embeddings work attempt construct asymmetric embedding space image features hierarchical information knowledge graph effectively implicitly encoded deep neural networks. previous approaches combine deep neural networks optimization methods like conditional random ﬁelds semantic relatedness incorporated framework advantage approach makes end-to-end trainable network easily scalable dealing larger datasets practical applications. treat open-ended scene parsing retrieval problem pixel following ideas image-caption retrieval work goal embed image pixel features word concepts joint high-dimensional posi+ illustrated figure guidtive vector space principle constructing joint embedding space image features close concept labels word concepts preserve semantic hypernym/hyponym relations. embedding space vectors close origin general concepts vectors larger norms represent higher speciﬁcity; hypernym/hyponym relation deﬁned whether vector smaller/greater another vector dimensions. hypernym scoring function crucial building embedding space detailed section figure open vocabulary parsing network. concept stream encodes word concept hierarchy based dictionaries like wordnet. image stream parses images based learned hierarchy. image stream. concept stream tries encode predeﬁned semantics learns embedding function preserve hypermaps words nym/hyponym relationship word concepts. image stream embeds image pixels space pushing close labels describe streams details section embedding problem training performed pairs image-label pairs concept-concept pairs. either streams goal maximize scores matching pairs minimize scores non-matching pairs. choice scoring functions becomes important. symmetric scoring functions like distance cosine similarity widely used embedding tasks scos relations. consider vocabulary concepts form directed acyclic graph sharing common root entity node graph abstract concept unions children nodes speciﬁc class leaf. visualization part built based wordnet adek labels found supplementary materials. internally concept stream include parallel layers shared trainable lookup table mapping word concepts evaluated hypernym scores sconcept shyper tells conﬁdent hypernym maxmargin loss used learn embedding function lconcept otherwise note positive samples cases ancestor graph coordinates pushed towards values larger negative samples inverted pairs random pairs loss function pushes apart embedding space. training root entity anchor origin embedding space stays image stream image stream composed fully convolutional network commonly used image segmentation tasks lookup layer shared word concept stream. consider image pixel position label feature layer output convolutional network. mapping function embeds pixel features space label evaluate scoring function simage label retrieval inherently ranking problem negative labels introduced training. max-margin ranking loss commonly used encourage scores true labels larger negative labels margin limage choice scoring function ﬂexible either simply make image pixel features close embedding labels using symmetric scores scos asymmetric hypernym score shyper latter case treat images speciﬁc instances specializations label concepts labels general abstraction images. joint model combines streams joint loss function preserve concept hierarchy well visual feature similarities. particular simply weighted losses streams limage λlconcept training. embedding space dimension commonly used word embeddings. training model details described section working limited number classes four traditional criteria good measures scene parsing model performance pixel-wise accuracy proportion correctly classiﬁed pixels; mean accuracy proportion correctly classiﬁed pixels averaged classes; mean intersection-over-union between predictions ground-truth averaged classes; weighted weighted pixel ratio class. given nature open vocabulary recognition selecting good evaluation criteria non-trivial. firstly leverage graph structure concepts tell distance predicted class ground truth. secondly evaluation correctly represent highly unbalanced distribution dataset classes also common objects seen nature. given concepts deﬁne lowest common ancestor speciﬁc concept hypernym both. hierarchical precision recall deﬁned number common hypernyms prediction label vocabulary hierarchy formally prominent advantage hierarchical metrics penalize predictions speciﬁc. example guitar piano musical instrument guitar predicted piano guitar predicted musical instrument agrees human judgment prediction musical instrument accurate piano. mentioned before unbalanced distribution data points could make performance dominated frequent classes. information content ratio also used lexical search addresses problems effectively. frequency inherit idea preprocess image data pixel frequency concept speciﬁcally frequency concept frequency descendents’ frequencies image dataset. expected root entity frequency information content evaluations measure testing sample much information prediction gets total amount information label. ﬁnal score determined information ground truth predicted concepts. learn joint embedding associate class adek dataset synset wordnet representing unique concept. data association process requires semantic understanding resort amazon mechanical turk develop rigorous annotation protocol detailed supplementary materials. association classes dataset synset matches. unique synsets forming dag. matched synsets entity.n. hypernym average synsets between. depths adek dataset annotations range network implementations concept stream data layer concept stream feeds network positive negative vocabulary concept pairs. positive training pairs found traversing graph transitive closure hypernym pairs e.g. neckwear clothing entity tie; negative samples randomly generated training epoch excluding positive samples. using transitive closure pair greatly improves performance embedding providing training data. core image stream adapted vgg- taking away pool pool making following convolution layers dilated considering features image pixel last layer fully convolutional network dimension convolution layer weight dimension embed pixel feature. ensure positivity relu layer. technique improve training norms embeddings image pixelsto wide range values work. technique stabilizes training numerically speeds convergence. intuitively ﬁxing image large norm makes sense hierarchical embedding space image pixels speciﬁc descriptions concepts words general closer origin. inference stage cases testing training classes pixel embeddings compared embeddings candidate labels based scoring function class highest score taken prediction; zeroshot predictions hand threshold scores decide cutoff score concepts scores cutoff taken predictions. best threshold found testing validation images. section report performance model scene parsing task. training performed frequent classes stuffs objects adek dataset sceneparse class least total pixels dataset. trained models references several variants proposed model share architecture convolutional networks make fair comparisons. softmax baseline model classical multi-class classiﬁcation. conditional softmax hierarchical classiﬁcation model proposed builds tree based label relations softmax performed nodes common parent conditional probabilities node computed. absolute probabilities during testing conditional probabilities multiplied following paths root. wordvec model simply regresses image pixel features pre-trained word embeddings googlenews vectors. since dimensionality googlenews vectors weight dimension last convolution layer cosine similarity max-margin ranking loss negative samples used training. model direct counterpart devise scene parsing settings. margin loss softmax loss mentioned section augment googlenews vectors ﬁnetuning domain speciﬁc corpus. concretely collect scene descriptive sentences image adek training ﬁnetune pre-trained word vectors skip-gram model epochs word vectors ﬁnally ﬁxed regression like wordvec. variants proposed model. model names image-* refer cases image stream trained ﬁxing concept embeddings. models joint-* train streams together learn joint embedding space. three aforementioned scoring functions used image stream corresponding models marked *-cosine *-hyper. training classes evaluating training classes proposed models offer competitive results. baseline metrics used compare performance shown table without surprise best performance achieved softmax baseline agrees observation classiﬁcation formulations usually achieves higher accuracy regression formulations. time proposed models joint-cosine wordvec+ fall short softmax around affordable sacriﬁce given zero-shot prediction capability interpretability discussed later. visual results best proposed model joint-cosine shown figure move zero-shot prediction tasks fully leverage hierarchical prediction ability models. models evaluated less frequent object classes adek dataset. predictions classes hypernyms could compared based open vocabulary metrics. ples best model joint-hyper image show ground truth category make things clear different colors represent different predictions. though model always ground truth labels exactly correct gives reasonable predictions. another observation predictions sometimes noisy predictions single objects. inconsistencies plausible though e.g. ﬁrst upper part rocking chair predicted chair lower part predicted furniture. pixels upper segment closer ordinary chairs lower segment latter case model gives general prediction. open vocabulary recognition problem naturally raises question many training classes need generalize well zero-shot tasks? answer question diversity test section. different previous experiments take frequent classes training instead uniformly sample training testing classes histogram pixel numbers. better comparison number zero-shot test classes training classes range training process offset table shows results zero-shot predictions. terms hierarchical metrics joint-hyper gives best performance. proposed models general large margin baseline methods. conﬁrms modeling asymmetric relations data pairs better represents hierarchy. figure shows prediction samexperiment best model joint-hyper diversity test. results figure suggest performance could saturate training classes. conjecture training many classes instances could introduce sample noise. improve performance high quality data required. joint embedding space trained earlier features different properties known spaces like wordvec. section conduct three tests explore them. concept search. framework joint training require concepts corresponding image data semantics propagated. enables train wordnet synsets search concepts trained images. figure show pixel-level concept search results. heatmaps scores corresponding embedding spaces. search concepts become increasingly abstract model outperforms wordvec+ showing effective encoding hierarchical information embedding space. implicit attributes encoding. intriguing property feature embeddings continuous space classiﬁcation boundaries ﬂexible. explore vicinity concepts. figure show score maps searching concept chair. interestingly common phenomenon objects like bench ottoman hyponyms chair wordnet reasonable response. conjecture embedding space implicitly encodes abstract attributes clustering them e.g. sittable affordance attribute. simply loosing classiﬁcation threshold chair detect regions synthesized concepts arithmetics. wordvec joint embedding space concepts image detectors synthesized arithmetics. shown figure take elementwise operations word concepts search synthesized concepts images. found operation takes intersection concepts e.g. pool table common hyponym table game equipment; takes union e.g. cart composed attributes bicycle canopy. introduced challenging task open vocabulary scene parsing aims parsing images wild. proposed framework solve embedding concepts knowledge graph image pixel features joint vector space semantic hierarchy preserved. showed model performs well open vocabulary parsing explored semantics learned embedding space. references akata perronnin harchaoui schmid. labelieee conferembedding attribute-based classiﬁcation. ence computer vision pattern recognition june l.-c. chen papandreou kokkinos murphy yuille. deeplab semantic image segmentation deep convolutional nets atrous convolution fully connected crfs. arxiv. deng ding frome murphy bengio neven adam. large-scale object classiﬁcation using label relation graphs. european conference computer vision pages springer deng dong socher l.-j. fei-fei. imagenet large-scale hierarchical image database. computer vision pattern recognition cvpr ieee conference pages ieee deng krause berg fei-fei. hedging bets optimizing accuracy-speciﬁcity trade-offs large scale visual recognition. computer vision pattern recognition ieee conference pages ieee guillaumin ferrari. large-scale knowledge transfer object localization imagenet. computer vision pattern recognition ieee conference pages ieee karpathy fei-fei. deep visual-semantic alignments proceedings ieee congenerating image descriptions. ference computer vision pattern recognition pages lampert nickisch harmeling. attribute-based classiﬁcation zero-shot visual object categorization. ieee transactions pattern analysis machine intelligence swersky fidler predicting deep zero-shot proconvolutional neural networks using textual descriptions. ceedings ieee international conference computer vision pages mikolov sutskever chen corrado dean. distributed representations words phrases compositionality. advances neural information processing systems pages ordonez deng choi berg berg. prolarge scale image categorization entry-level categories. ceedings ieee international conference computer vision pages rohrbach stark schiele. evaluating knowledge transfer zero-shot learning large-scale setting. computer vision pattern recognition ieee conference pages ieee rohrbach stark szarvas gurevych schiele. helps where–and why? semantic relatedness knowledge transfer. computer vision pattern recognition ieee conference pages ieee vendrov kiros fidler urtasun. order-embeddings images language. arxiv preprint arxiv. proceedings annual meeting association computational linguistics pages association computational linguistics xiao hays ehinger oliva torralba. database large-scale scene recognition abbey zoo. computer vision pattern recognition ieee conference pages ieee zhou lapedriza xiao torralba oliva. learning deep features scene recognition using places database. advances neural information processing systems pages zweig weinshall. exploiting object hierarchy combining models different category levels. ieee international conference computer vision pages ieee model gives sample list predictions hierarchical order. page limitations full prediction lists shown main paper. figure give details zero-shot predictions ground truth prediction lists shown texts beneath images. correct predictions marked green inconsistent items marked orange. seen hard examples e.g. dome general conservative prediction made; test sample easy similar training samples e.g. wagon model gives speciﬁc aggressive predictions. learn joint embeddings images word concepts need augment adek dataset adding information label classes semantically related. associate class adek dataset synset wordnet representing unique concept. data association process requires semantic understanding resort amazon mechanical turk annotation protocol detailed follows screen shots interface shown figure search class dataset synsets name. different cases single synset found given class; multiple synsets found polysemy; sysnets found either correct synset different name concept wordnet. last case synset candidate found show image concept workers best matching synset looking wordnet online api. also option indicate synset match. data association getting classes dataset synset matches. unique synsets forming dag. matched synsets entity.n. hypernym average synsets between. depths adek dataset annotations range detailed visualization concept graph built shown figure node radii indicate class frequencies adek dataset. ﬁgure shows part full graph nodes descendents less hidden.", "year": 2017}