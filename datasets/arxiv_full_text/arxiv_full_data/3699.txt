{"title": "Active Ranking from Pairwise Comparisons and when Parametric Assumptions  Don't Help", "tag": ["cs.LG", "cs.AI", "cs.IT", "math.IT", "stat.ML"], "abstract": "We consider sequential or active ranking of a set of n items based on noisy pairwise comparisons. Items are ranked according to the probability that a given item beats a randomly chosen item, and ranking refers to partitioning the items into sets of pre-specified sizes according to their scores. This notion of ranking includes as special cases the identification of the top-k items and the total ordering of the items. We first analyze a sequential ranking algorithm that counts the number of comparisons won, and uses these counts to decide whether to stop, or to compare another pair of items, chosen based on confidence intervals specified by the data collected up to that point. We prove that this algorithm succeeds in recovering the ranking using a number of comparisons that is optimal up to logarithmic factors. This guarantee does not require any structural properties of the underlying pairwise probability matrix, unlike a significant body of past work on pairwise ranking based on parametric models such as the Thurstone or Bradley-Terry-Luce models. It has been a long-standing open question as to whether or not imposing these parametric assumptions allows for improved ranking algorithms. For stochastic comparison models, in which the pairwise probabilities are bounded away from zero, our second contribution is to resolve this issue by proving a lower bound for parametric models. This shows, perhaps surprisingly, that these popular parametric modeling choices offer at most logarithmic gains for stochastic comparisons.", "text": "consider sequential active ranking items based noisy pairwise comparisons. items ranked according probability given item beats randomly chosen item ranking refers partitioning items sets pre-speciﬁed sizes according scores. notion ranking includes special cases identiﬁcation top-k items total ordering items. ﬁrst analyze sequential ranking algorithm counts number comparisons uses counts decide whether stop compare another pair items chosen based conﬁdence intervals speciﬁed data collected point. prove algorithm succeeds recovering ranking using number comparisons optimal logarithmic factors. guarantee require structural properties underlying pairwise probability matrix unlike signiﬁcant body past work pairwise ranking based parametric models thurstone bradley-terry-luce models. long-standing open question whether imposing parametric assumptions allows improved ranking algorithms. stochastic comparison models pairwise probabilities bounded away zero second contribution resolve issue proving lower bound parametric models. shows perhaps surprisingly popular parametric modeling choices oﬀer logarithmic gains stochastic comparisons. given collection items frequently interest estimate ranking based noisy comparisons pairs items. rank aggregation problems arise across wide range applications. traditional examples sports include identifying best player tournament selecting teams playoﬀs ﬁnding full ranking players. recently internet variety applications involving pairwise comparison data including recommender systems rating movies books consumer items; peer grading ranking students massive open online courses; online sequential survey sampling assessing popularity proposals population voters. many applications possible make comparisons active adaptive manner—that based outcomes comparisons previously chosen pairs. motivated applications focus paper problem obtaining statistically sound rankings based sequence actively chosen pairwise comparisons. pairwise comparisons furthermore assumed statistically mutually independent. deﬁne ordering items terms scores score item deﬁned probability item beats item chosen uniformly random items context social choice theory sums also known borda scores counts items. apart intuitive appeal borda counts particular interest provide natural uniﬁcation assumed orderings several popular comparison models. speciﬁcally parametric bradley-terry-luce thurstone models well non-parametric strong stochastic transitivity model based assumed ordering items; models paper consider problem partitioning items sets pre-speciﬁed sizes according respective scores. notion ranking includes special cases identiﬁcation top-k items total ordering items. make primary contributions. begin presenting analyzing simple active ranking algorithm estimating partial total ranking items. round algorithm ﬁrst counts number comparisons computes conﬁdence bounds counts ﬁnally uses select subset pairs compared next time step. provide performance guarantees showing high probability algorithm recovers desired partial total ranking certain number comparisons refer sample complexity. show sample complexity function scores therefore distribution-dependent. conversely prove distribution-dependent lower bounds matching logarithmic factors thereby showing algorithm nearoptimal number comparisons. analysis leverages fact ranking terms related particular class multi-armed bandit problems connection observed past work context ﬁnding item. second main contribution relates popular parametric modeling choices made literature. hand algorithmic analysis paper impose assumptions pairwise comparison probabilities. hand much past work based speciﬁc parametric assumptions pairwise comparisons; instance papers well references therein. concrete examples parametric assumptions include bradley-terry-luce thurstone parametric models. long standing debate whether parametric assumptions reasonable—that situations hold fail parametric models suitable natural hope structure allows reduction sample complexity. fact essentially deterministic comparison models indeed signiﬁcant gains; discussion following theorem details. however show paper considers stochastic comparison models logarithmic gain sample complexity assuming parametric comparison model making structural assumption. logarithmic gain needs weighed potential lack robustness incurred using parametric model all) signiﬁcant shown numerical results section. related work vast literature ranking estimation pairwise comparison data. works assume probabilistic comparison outcomes; refer paper references therein ranking problems assuming deterministic comparison outcomes. several prior works consider settings pairs compared chosen priori. contrast consider settings pairs chosen active manner. recent work assumes bradley-terry-luce parametric model considers problem ﬁnding item full ranking active setup. stochastic regime certain underlying distributions corresponding results close general result implies. hand several problem instances performance guarantees theorem theorem work lead signiﬁcantly larger sample complexity. work thus oﬀers better guarantees model stochastic regime despite additional generality setting restrict model. however outside stochastic regime speciﬁcally models pairwise comparison probabilities close zero oﬀer gains results aﬀorded general model; discuss regime detail later. paper considers problem ﬁnding full ranking items pairwise comparison model provides performance analysis probabilistic model parameter vector. finally eriksson considers problem ﬁnding items using graph based techniques busa-fekete consider problem ﬁnding top-k items ailon considers problem linearly ordering items disagree pairwise preference labels possible. work also related literature multi-armed bandits revisit relations later paper. organization remainder paper organized follows. begin background problem formulation section present description sharp analysis ranking algorithm section section show parametric assumptions reduce sample complexity stochastic regime. section study numerically whether algorithms designed parametric models yield improvement outside stochastic regime study additional aspects proposed algorithm. provide proofs results section conclude discussion section section formally state ranking problem considered paper formalize notion active ranking algorithm. also formally introduce class parametric models section. item consider score given j∈\\{i} mij. note score corresponds probability item wins comparison item chosen uniformly random {i}. ranking corresponds permutation words denotes ranked item according scores. number ranking problems deﬁned terms extreme ﬁnding best item corresponds determining item whereas extreme ﬁnding complete ranking equivalent estimating active ranking algorithm acts pairwise comparison model consider speciﬁed values {k}l deﬁning partition form terms latent scores goal obtain partition items disjoints sets form active comparisons. time instant algorithm compare arbitrary items choice items compare based outcomes previous comparisons. result comparing items algorithm receives independent draw binary random variable success probability response. termination dictated associated worthwhile noting ranking problem studied related multi-armed bandits precisely multi-armed bandit model consists collection arms associated unknown stochastic reward function goal maximize reward obtained sequential choice arms. past work various researchers drawn links pairwise comparison ranking bandit problems. particular deﬁnition score comparing item distinct item chosen alternatives modeled drawing bernoulli random variable mean subsequent analysis section relies relation. cast multi-armed bandit setting setting pairwise comparisons often referred dueling bandits. prior works setting address problem ﬁnding single best arm— meaning item highest score—based noisy comparisons. contrast paper treats general problem ﬁnding partial total ordering items. despite similarities important distinction settings. view problem multi-armed bandit problem bernoulli random variables means {τi}n means actually coupled together sense information particular mean imposes constraints means. particular scores {τi}n must realized valid pairwise comparison probabilities {mij}ij∈. since pairwise comparison probabilities must obey constraint induced scores must satisfy certain constraints obvious. obvious constraint follows immediately condition necessary certainly suﬃcient seen studying simple cases. algorithm presented next section take coupling scores explicitly account. nevertheless algorithm shown optimal logarithmic factor stochastic regime. section introduce family parametric models form basis several prior works clear make modeling assumptions algorithm analysis section rather focus parametric models section show that perhaps surprisingly outside deterministic regime none parametric assumptions provide logarithmic gain sample complexity. member family deﬁned strictly increasing continuous function obeying function assumed known. pairwise comparison matrix family associated unknown vector entry represents quality strength corresponding item. parametric model cpar popular examples models family bradley-terry-luce model obtained setting equal sigmoid function +e−t thurstone model obtained setting equal gaussian cdf. note equivalent meaning ranking induced scores {τi}n equivalent section present algorithm obtaining desired partition items described earlier section sharp analysis algorithm proving optimality logarithmic factors. items total corresponding ﬁgure depicts estimates along corresponding conﬁdence intervals αtτi diﬀerent time steps either best second best item therefore algorithm assigns likewise assigns item time step algorithm assigns items part theorem follow prove upper bound involving algorithm part prove lower bound involving applies uniformly δ-accurate algorithm. might intuitively expect number comparisons required lower gaps underlying scores larger. figure illustration gaps part theorem proves algorithm δ-accurate characterizes number comparisons required ranking function gaps scores. contrast part shows that logarithmic factors algorithm optimal minimax sense fact acting given problem instance. proof part involves constructing pairs comparison matrices especially hard distinguish makes change measure lemma bandit literature. special case top- identiﬁcation jamieson urvoy observe using relation multi-armed bandits discussed section standard multi-armed bandit algorithm applied turn known achieve sample complexity special case top- identiﬁcation part theorem recovers theorem note negative result part pertains stochastic regime pairwise comparison probabilities bounded away zero therefore rule possibility regime pairwise comparison probabilities close improvements sample complexity possible. thus ranking problem reduces testing hypothesis verify hypothesis equivalent outcomes independent comparisons items natural test supposing without loss generality hoeﬀding’s inequality upper bound corresponding error probability order understood beneﬁts active strategy worthwhile compare performance active method guarantees obtainable passive comparison strategies. hasten gains seen surprising themselves since well-known active estimators often yield signiﬁcant improvements passive schemes. recent work subset current authors considers problem ranking items pairwise comparisons passive random design setup. hand shown simple passive scheme—namely ranks items according total number comparisons comparisons won—recovers items high probability using total; paper also establishes matching lower bound meaning passive scheme better constant factors. contrast theorem present paper shows active setting number comparisons necessary suﬃcient ﬁnding items order logarithmic factor. comparing guarantee passive sample complexity understand active strategies lead substantial gains. first note complexity non-active estimator always lower except scores satisfying linear constraints case estimators would similar performance. second diﬀerence sample complexity large factor figure estimated scores comparisons proposals planyc oecd surveys reported paper rated least times depicted). estimation proposals another ranking active scheme would require signiﬁcantly smaller number queries compared non-active estimator. case logarithmic factors sample complexity active passive schemes scale respectively. similar conclusion holds compare results paper present paper problem recovering full ranking. seen gains active estimation depend distribution scores natural wonder scores behave real-world settings. illustration figure shows real-world examples distribution data collected salganik levy left panel shows scores estimated paper collection environmental proposals york city whereas right panel shows collection educational proposals organisation economic co-operation development data collected asking interviewees corresponding online surveys preferences options. goal online surveys example identify proposals total ranking proposals. results show estimation proposals another ranking active scheme would require signiﬁcantly smaller number queries compared non-active estimator. active ranking algorithm described analyzed previous section applies comparison matrix —that neither assumes exploits particular structure imposed parametric models described section given algorithm imposes conditions model might suspect ranking data actually drawn parametric model—for example thurstone type—it could possible come another algorithm lower sample complexity. surprisingly show section intuition turns false following sense stochastic comparison models—in comparison probabilities bounded strictly away zero one—imposing parametric assumptions lead logarithmic reduction sample complexity. scores realizable pairwise comparison matrix cmmin mmin continuous strictly increasing exists pairwise comparison matrix cpar cmmin scores particular second turn implications theorem start noted lower bound least certain sense stronger lower bound theorem applies broader class algorithms—namely δ-accurate smaller class parametric models. side possible lower bound could weaker sense precisely could diﬃcult matrix cmmin supremum cpar cmmin much smaller matrix m—which need generated parametric model—there exists parametric model consequence theorem logarithmic factors algorithm optimal even restrict algorithms uniformly δ-accurate parametric subclass. thus stochastic comparison models imposing parametric assumptions limits ﬂexibility failing provide signiﬁcant reductions sample complexity ranking. worth commenting deterministic near-deterministic comparison models—in pairwise probabilities arbitrarily close zero one— constant cpar lower bound become small. reason lower bound contradict fact parametric assumptions might help -deterministic comparison models. example recalling model described section based parameter vector suppose tend inﬁnity. since model taking limit leads fully deterministic comparison model items beats probability limit pairwise ranking reduces deterministic sorting problem sorting-based algorithms used achieve item identiﬁcation comparisons. contrast deterministic setting algorithm requires comparisons guaranteed applying theorem associated score vector turn numerical comparisons active ranking algorithm algorithms designed parametric models. ﬁnding—consistent theory—is algorithm outperforms algorithms unless pairwise comparison probabilities close zero one. moreover algorithms designed parametric models start break even parametric modeling assumption slightly violated. finally experiment choice constants setting conﬁdence intervals algorithm choice given theory conservative. results section show stochastic comparison models algorithms exploit parametric structure sample complexities lower logarithmic factor. hand -deterministic comparison models gave example showing parametric structure allow signiﬁcant gains. section perform numerical experiments quantify understand diﬀerent regimes. consider problem item recovery known dueling bandit problem simply algorithms available special case general ranking problem considered paper. compare algorithm plackett-luce beat mean bandit algorithms. algorithms yield δ-accurate ranking provided modeling assumptions hold. choose plpac algorithm comparison based sorting problem pairwise comparison probabilities close zero clear example violate claimed results since lower bound theorem hence associated claim optimality applies case pairwise comparison probabilities bounded away constant mmin. standard deviation mean. algorithm even lower sample complexity plpac btmb algorithms regime mmax close plpac btmb perform better mmax close one. essence noisy sorting problem thus expect sorting based procedures work well here. btmb algorithm guaranteed succeed strong stochastic transitivity certain stochastic transitivity triangle inequality hold; assumptions satisﬁed model. regarding algorithms parameters; algorithm log/δ) algorithms choose consider diﬀerent models parameterized respectively denoted parameters determine close minimal maximal pairwise comparison probabilities larger closer. speciﬁcally parameters model given results pairwise comparison probabilities −i−j parameters second model implies probability item beats next best item +e−ξ thus item beats lower ranked ones probability +e−ξ results pairwise comparison probabilities skewed away least larger closer probabilities necessary suﬃcient condition matrix satisfy condition existence permutation items permuted pairwise comparison matrix non-decreasing across rows non-increasing across columns. stochastic transitivity inequality demands triplet figure relative sample complexity deﬁned number comparisons termination divided complexity parameter failure probability model fraction oﬀ-diagonals substituted random pairwise comparison probability. model transitions model random pairwise comparison matrix closer zero closer original model. results show that algorithm yields δ-accurate ranking comparisons irrespectively sample complexity importantly failure probability plpac btmb algorithms become large results show predicted theory sample complexity algorithm essentially constant times complexity parameter contrast sample complexity plpac btmb algorithms improves mmax relative complexity parameter note algorithm performs better plpac btmb mmax large plpac btmb lower sample complexity algorithm regime mmax close one. remark relative improvement determined solely mmax shown curves diﬀerently parameterized models diﬀering. substitute fraction oﬀ-diagonal elements number drawn uniformly thus model transitions model random pairwise comparison matrix small model close original model. results depicted figure show that algorithm succeeds values expected sample complexity importantly failure probability plpac btmb algorithms become large. hasten plpac btmb algorithm designed scenario; therefore might surprising fail. results show algorithms however robust violations assumed models. figure number comparisons required top- items items )/δ)/t. empirical error probability required top- items log/δ)/t theoretical items. particular choice constants results conservative sense obtaining δ-accurate ranking constants chosen smaller turn results fewer comparisons. sets suﬃciently large. main results show algorithm succeeds recovering ranking probability least provided length conﬁdence interval chosen result optimal log-factors particular choice constants might overly conservative improvements sample complexity might obtained choosing constants smaller show next. investigate claim generate pairwise comparison model scores algorithm items diﬀerent values desired accuracy results depicted figure show that even signiﬁcantly smaller constants algorithm δ-accurate. section provide proofs main theorems. order simplify notation take underlying permutation equal identity assumption entails loss generality since also satisﬁed re-indexing items necessary. order state second lemma require additional notation. τ{k} denote k-th largest score among latent scores note notation emphasize index necessarily equal index since latter corresponds k-th next step show that conditioned event algorithm tion carried out. since lemma event holds probability least concludes proof theorem dependence candidates explicit writing order show event occurs probability least ﬁrst recall comparing item item chosen uniformly random \\{i} equivalent taking independent draw bernoulli random variable mean verify recursion independent bernoulli random variables mean τi/t. order step follows inequality holds event inequality follows τ{k−} seen follows. shown above event algorithm never misclassiﬁes item therefore thek−-th largest score among items must turn proof lower bound theorem ﬁrst introduce notation required state useful lemma bandit literature. {νj}m collection probability distributions supported real line consider algorithm that times selects index receives independent draw distribution response. algorithm select based past observations measurable σ-algebra generated xit. algorithm stopping rule determines termination assume stopping time measurable respect obeying denote total number times index selected algorithm pair distributions denote kullback-leibler divergence denote kullback-leiber corresponds success algorithm recalling stopping rule algorithm guaranteed given linear relations pairwise comparison matrix determined entries {mij total number comparisons items made pairwise comparison matrix lemma ensures suppose obtained probabilities increasing probabilities surrounded rectangle decreasing probabilities surrounded circle others remain unchanged. figure illustration. follows that distribution score item among highest scoring items ensures moreover claim inclusion follows assumption implies consider parametric pairwise comparison matrix cpar cmmin. exists parameter vector assumption parameter vector obeys consider item notational convenience. construct alternative matrix cpar cmmin follows. consider scalar value lies interval wk−. deﬁne alternative matrix pairwise comparison probabilities deﬁnition ensures cpar cmmin. moreover deﬁnition item among items since algorithm uniformly δ-accurate cpar cmmin ensures inequality holds. denotes previously deﬁned event algorithm correctly recovers structure. similarly index deﬁne alternative matrix deﬁning corresponding parameters model speciﬁed item amongst items largest scores therefore line arguments yields theorem relies results established majorization orderings pairwise probability matrices. convenience deﬁne pairwise probability matrices scores given pairwise comparison matrices vectors entries corresponding oﬀ-diagonal elements respectively non-increasing order. majorizes shorthand denote relation. finally matrix minimal obeying satisﬁes relation order prove theorem show minimal cmmin. ﬁrst note observed argument minimizing schur convex function minimal construct function schur convex. particular ﬁrst deﬁne scalar function function well deﬁned since inverse exists assumption strictly increasing continuous. since strictly increasing follows strictly ij=i strictly schur convex result minimization performed variables next show optimal solution problem entries satisfying pairs therefore cmmin desired. interval inclusion indeed suppose optimal solution violated inclusion. assumption exists matrix cmmin. thus inclusion violated would index pair would imply strictly larger since exists solution convex optimization problem satisﬁes inequality constraints strictly slater’s conditions hold karushkuhn-tucker conditions necessary suﬃcient optimality thus primal dual optimal solutions paper considered problem ﬁnding partial complete ranking active pairwise comparisons. proved simple computationally eﬃcient algorithm succeeds recovering ranking sample complexity optimal logarithmic factors. furthermore proved algorithm remains optimal imposing common parametric assumptions popular thurstone models—provided pairwise comparison probabilities bounded away show that perhaps surprisingly imposing common parametric assumptions cannot reduce sample complexity ranking log-factor stochastic regime. said noted practice possibility gaining factor assuming parametric model overshadowed signiﬁcant additional robustness aﬀorded general model class. instance ballinger empirical evidence parametric models provide good many applications numerical results demonstrated algorithms relying parametric models quite sensitive violations modeling assumptions. number open practically relevant questions suggested work. theoretical perspective would interesting provide algorithm corresponding guarantees parametric models matches lower bound regime comparison probabilities bounded away zero time optimal regime pairwise comparison probabilities close zero one. ﬁnal interesting topic future work related approximate rankings. speciﬁcally practice might interested ﬁnding approximate ranking might able approximate ranking limited budget queries. work supported swiss national science foundation grant pezp work supported oﬃce naval research muri grant dod- force oﬃce scientiﬁc research grant afosr-fa--- oﬃce naval research grant onr-n well national science foundation grant cif--. work also supported part microsoft research fellowship.", "year": 2016}