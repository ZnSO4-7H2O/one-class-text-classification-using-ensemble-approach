{"title": "Graph Clustering Bandits for Recommendation", "tag": ["stat.ML", "cs.AI", "cs.IR", "cs.LG"], "abstract": "We investigate an efficient context-dependent clustering technique for recommender systems based on exploration-exploitation strategies through multi-armed bandits over multiple users. Our algorithm dynamically groups users based on their observed behavioral similarity during a sequence of logged activities. In doing so, the algorithm reacts to the currently served user by shaping clusters around him/her but, at the same time, it explores the generation of clusters over users which are not currently engaged. We motivate the effectiveness of this clustering policy, and provide an extensive empirical analysis on real-world datasets, showing scalability and improved prediction performance over state-of-the-art methods for sequential clustering of users in multi-armed bandit scenarios.", "text": "investigate efﬁcient context-dependent clustering technique recommender systems based exploration-exploitation strategies multi-armed bandits multiple users. algorithm dynamically groups users based observed behavioral similarity sequence logged activities. algorithm reacts currently served user shaping clusters around him/her time explores generation clusters users currently engaged. motivate effectiveness clustering policy provide extensive empirical analysis real-world datasets showing scalability improved prediction performance state-ofthe-art methods sequential clustering users multi-armed bandit scenarios. exploration-exploitation techniques a.k.a. bandits becoming essential tool modern recommenders systems recommendation setting involve ever changing dynamic items many domains news recommendation item changing rapidly impossible standard collaborative ﬁltering techniques. settings bandit algorithms contextual bandits proven work well since provide principled gauge appeal items. drawback contextual bandits mainly work content-dependent regime user item content features determine preference scores collaborative effects arise ignored. incorporating collaborative effects bandit algorithms lead dramatic increase quality recommendations. bandit algorithms mainly done clustering user. instance want serve content group users taking advantage underlying network preference relationships among them. preference relationships either explicitly encoded graph adjacent nodes/users deemed similar another implicitly contained data given outcome inference process recognizes similarities across users based past behavior. deal issue type bandit algorithms developed work assumption users grouped based selection items e.g. main assumption users form graph edges constructed based signals similar preference partitioning graphs coherent group users similar preference online behavior. algorithms proven perform signiﬁcantly better classical contextual bandits only provide exploration items. users users sparse activity difﬁcult accurate group assignment. particularly important issue since recommendation settings face unbalancedness user activity levels relatively users high activity vast majority users little practically activity work introduce bandit algorithm adds extra exploration component group users. addition standard exploration-exploitation strategy items algorithm explores different clustering assignments users users activity. experimental evaluation four real datasets baselines state-of-the-art methods conﬁrm additional dynamic paradigm tends translate solid performance beneﬁts. previous work literature assume user behavior similarity represented underlying clustering users. speciﬁcally users assume partitioned small number clusters expected much smaller meaning clustering users belonging cluster tend similar behavior users lying different clusters signiﬁcantly diverging behavior. partition common user behavior within cluster unknown learning system inferred based past user activity. inference procedure carried within sequential decision setting learning system continuously adapt newly received information provided users. effect learning process divided discrete sequence rounds round learner receives user index serve content notice user serve change every round though user recur many times. sequence {it} exogenously determined users interact system control. practice high unbalancedness levels user activity often observed. users active many others idle newly registered users preferences either extremely sporadic even exist along system receives round feature vectors xtct} representing content currently available recommendation user learner picks xtkt recommend observes it’s feedback form numerical payoff given number rounds. user feedback learner observes click/no-click behavior payoff naturally interpreted binary feedback quantity becomes click-through rate recommended item clicked user otherwise. experiments data disposal provide payoff associated item recommended logged policy measure prediction accuracy. hand data come payoffs possible items measure choice cumulative regret learner deﬁned follows. payoff associated data hand item cit. regret learner time extent payoff notice round-t regret refers behavior learner predicting preferences user thus cumulative regret takes duly account relative importance users quantiﬁed activity level. claim also holds measuring performance ctr. algorithm called graph cluster bandits variant cluster bandits algorithm originally introduced ﬁrst recall club works point weakness describe changes lead gclub algorithm. club algorithm maintains time partition users form connected components undirected graph whose nodes users whose edges encode current belief user similarity. club starts randomly sparsiﬁed version complete graph edges instead progressively deletes edges based feedback provided current user speciﬁcally node graph hosts linear function meant estimate payoff user would provide item recomwit mended him/her. hope estimates gets better better time. current user vector witt updated based it’s payoff signal similar standard linear bandit algorithm operating context vectors contained cit. every user hosts linear bandit algorithm. actual recommendation issued within computed follows. first connected component belongs singled figure then suitable aggregate prediction vector jtt− figure constructed collects information uses connected component. vector computed engaged standard upper conﬁdence-based exploration-exploitation tradeff select item recommend user it’s payoff received witt− gets updated witt turn change current cluster structure formerly connected node consequence update witt− witt vector witt longer close taken good indication cannot belong cluster edge gets deleted clusters users possibly obtained. main weakness club shaping clusters responding current user feedback algorithm operates locally advantageous computational standpoint long severe drawback overfocusing active users; algorithm responsive enough users enough information gathered either active simply newly registered users. words order make better recommendations it’s worthy discover capture niches user preferences well. since uneven activity levels among users standard pattern users many gclub complements club kind stochastic exploration level cluster shaping. every round gclub deletes edges ways independent algorithm picks connected component uniformly random among available ones time splits component subcomponents invoking fast graph clustering algorithm stochastic choice made initial stage learning think cold start regime users. graph clustering algorithm used experiments implemented graclus software package authors running single connected component initially sparsiﬁed graph tool turned quite fast experimentation. rationale behind gclub extra layer exploration-vs-exploitation tradeoff operates level clusters. level exploration corresponds picking cluster random among available ones exploitation corresponds working cluster current user belongs absence enough information current user his/her neighborhood exploring clusters intuitively beneﬁcial. next section indeed case. lastfm delicious yahoo datasets. sake fair comparison carefully followed implemented experimental setup described datasets refer reader paper details. yahoo dataset called yahoo therein. movielens dataset. freely available benchmark dataset movielens dataset ratings users movies user rated least movies. movie comes number features like movie title release date video release date genres. data cleaning extracted numerical features standard tf-idf procedure. applied resulting feature vectors retain least original variance giving rise item vectors dimension finally normalized features zero mean unit variance. payoffs generated binary payoffs mapping nonzero rating payoff zero rating payoff moreover timestamp dataset referring user generated random item sets size putting item provided payoff picking remaining vectors random available movies timestamp. hence likely contain movie payoff total number rounds took ﬁrst rounds parameter tuning rest testing. figure report activity level users yahoo movielens datasets. evinced plots levels quite diverse among users emerging pattern across datasets engaged users long tail unengaged ones. compared gclub three representative competitors linucb-one linucb-ind club. linucb-one linucb-ind members linucb family algorithms sense extreme solutions linucb-one allocates single instance linucb across users linucb-ind allocates independent instance linucb user provide personalized recommendations club online clustering technique yahoo dataset featureless version linucb-like algorithm i.e. version algorithm corresponding versions denoted ucb-one ucb-ind respectively. finally algorithms also compared trivial baseline selects item within fully random. tuned parameters algorithms training standard grid search used test evaluate predictive performance. training test datasets yahoo turned around experimental results reported averaged runs results summarized figure report test prediction performance. lastfm delicious movielens measured ratio cumulative regret algorithm cumulative regret random predictor yahoo dataset available payoffs associated items recommended logs measured instead ratio clickthrough rate algorithm whereas four datasets generated real online applications worth remarking datasets indeed quite different customers consume associated content. instance yahoo dataset derived consumption news often interesting large portions users hence strong polarization subcommunities thus unsurprising yahoo ucb-one already quite well. also explains ucb-ind poor extreme lies delicious derived social bookmarking service many niches scenario. linucb-one clearly underperforming. datasets club performs reasonably well cases improvement best performer ucb-one ucb-ind incremental. lastfm club even outperformed linucb-ind long run. finally gclub tends outperform competitors cases. though preliminary nature believe ﬁndings suggestive phenomena building clusters users solely based past user behavior beneﬁcial; settings highly diverse user engagement levels combining sequential clustering stochastic exploration mechanism operating level cluster formation enhance prediction performance even further.", "year": 2016}