{"title": "Learning to Transfer Privileged Information", "tag": ["cs.CV", "stat.ML"], "abstract": "We introduce a learning framework called learning using privileged information (LUPI) to the computer vision field. We focus on the prototypical computer vision problem of teaching computers to recognize objects in images. We want the computers to be able to learn faster at the expense of providing extra information during training time. As additional information about the image data, we look at several scenarios that have been studied in computer vision before: attributes, bounding boxes and image tags. The information is privileged as it is available at training time but not at test time. We explore two maximum-margin techniques that are able to make use of this additional source of information, for binary and multiclass object classification. We interpret these methods as learning easiness and hardness of the objects in the privileged space and then transferring this knowledge to train a better classifier in the original space. We provide a thorough analysis and comparison of information transfer from privileged to the original data spaces for both LUPI methods. Our experiments show that incorporating privileged information can improve the classification accuracy. Finally, we conduct user studies to understand which samples are easy and which are hard for human learning, and explore how this information is related to easy and hard samples when learning a classifier.", "text": "introduce learning framework called learning using privileged information computer vision ﬁeld. focus prototypical computer vision problem teaching computers recognize objects images. want computers able learn faster expense providing extra information training time. additional information image data look several scenarios studied computer vision before attributes bounding boxes image tags. information privileged available training time test time. explore maximum-margin techniques able make additional source information binary multiclass object classiﬁcation. interpret methods learning easiness hardness objects privileged space transferring knowledge train better classiﬁer original space. provide thorough analysis comparison information transfer privileged original data spaces lupi methods. experiments show incorporating privileged information improve classiﬁcation accuracy. finally conduct user studies understand samples easy hard human learning explore information related easy hard samples learning classiﬁer. framework called learning using privileged information introduced vapnik vashist recognized community recently. concept inspired human experience learning teacher learning access training examples additional source explanation teacher. example learning concept linear algebra faster teacher explains rather questions right answers only. course students able solve tasks rely teacher’s expertise anymore. training teacher signiﬁcantly improve learning process ability generalize humans machines introduces general framework lupi successfully applied variety tasks image classiﬁcation diﬀerent types privileged data attributes bounding annotation textual description handwritten digit images poetic descriptions privileged source data clustering task facial feature detection head pose gender privileged information facial expression recognition resolution images high resolution images privileged source metric learning counting backpropagation etc. figure three diﬀerent forms privileged information help learning better object recognition systems attributes object bounding boxes textual descriptions. standard learning setting given input–output training pairs task want learn example images category labels object classiﬁcation. lupi setting input–output training pairs plus additional information training pair available training. direct limitation form privileged information i.e. could another feature representation completely diﬀerent modality like text hand annotation addition image data speciﬁc training instance. lupi original formulation tell kind privileged information useful i.e. lead better performance measure quality work extends original publication examine three diﬀerent types privileged information context object classiﬁcation task attributes describe semantic properties object bounding boxes specify exact localization target object image image tags describe context image textual form. figure illustrates three modalities. approach contribution order lupi understand make data modality available test time. example training classiﬁer privileged data useless since evaluate resulting classiﬁer test data. core work lies insight privileged information allows distinguish easy hard examples training set. assuming examples easy hard respect privileged information also easy hard respect original data enable information transfer privileged original data modality. speciﬁcally ﬁrst deﬁne identify samples easy hard classiﬁcation task incorporate privileged information sample weights encodes easiness hardness. formalize observation section study compare maximum-margin learning techniques lupi. ﬁrst svm+ originally described vapnik second margin transfer contribution classiﬁcation setting adaptation rank transfer method proposed ranking. analyze core diﬀerence information transfer proposed methods kind knowledge learning problem guide training image-based predictor better solution. section report experiments three privileged information scenarios introduced earlier attributes bounding boxes image tags. demonstrate avoid handcrafted methods designed speciﬁc type additional information handle situations uniﬁed framework another contribution work. section show method naturally suitable multiclass classiﬁcation setting versus rest strategy. best knowledge ﬁrst time lupi methods examined setting classes. conduct user studies experiment identify easy hard samples human learning object categories. utilize data ground truth information analyze compare easy hard samples learned proposed lupi methods section ﬁrst attempt understand type privileged information could useful. computer vision problems common access multiple sources information. sometimes visual images represented color features well texture features. sometimes modalities mixed images text captions. modalities present training test time rather straight-forward combine better prediction performance. studied e.g. ﬁelds multi-modal multi-view learning. methods suggested range stacking simply concatenates feature vectors data modalities complex adaptive methods early late data fusions including multiple kernel learning lp-β situations asymmetric distribution information also explored. weakly supervised learning annotation available training time less detailed output wants predict. situation occurs e.g. trying learn image segmentation system using per-image bounding annotation multiple instance learning training labels given individual examples collectively groups examples inverse situation also occurs example pascal object recognition challenge become standard technique incorporate strong annotation form bounding boxes per-pixel segmentations even goal per-image object categorization similar strong weak supervision situations data representations diﬀer training testing phase distinguished whether less information available training time test time. ﬁrst situation occurs e.g. tracking temporal continuity used test time might available training time similarly shown image metadata auxiliary feature modality provide additional information test time compared image information available training time. situation interested occurs training time additional data representation compared test time. diﬀerent settings kind appeared computer vision literature studied separate way. example clustering multiple image modalities proposed learn shared representation computed either representations similarly shared representation also used cross-modal retrieval alternatively training data learn mapping image privileged modality predictor values missing test time feature vectors made semantic attributes used improve object categorization training examples available shown annotator rationales additional sources information training long rationales expressed data representation original data authors proposed explore privileged information measure uncertainty samples estimating noise term gaussian processes classiﬁcation privileged data i.e. privileged noise. work follows diﬀerent route approaches. looking task-speciﬁc solutions applicable speciﬁc form privileged information. instead generic method applicable form privileged information given additional representations training data. following formalize lupi setup task supervised binary classiﬁcation. describe simple extension lupi multiclass setting using one-versus-rest procedure section assume given training examples represented feature vectors label annotation {+−} additional information also form feature vectors x∗n} encodes additional information sample context computer vision consider examples images features extracted image content example form bag-ofvisual-words histograms make speciﬁc assumption privileged data space keep general notation feature vectors extracted visual verbal semantic form privileged information. refer original privileged data spaces accordingly. binary classiﬁcation task learn prediction function space learn better classiﬁer original data space would learn without since privileged data available training time comes diﬀerent domain original space possible e.g. apply functions deﬁned vice versa. work describe privileged data characterize training samples original data space easy hard cases. knowing help direct learning procedure towards better generalization learn function higher prediction quality. following explain maximum-margin methods learning privileged information interpretation. first method proposed vapnik second proposed alternative model solving lupi. simplicity notation write problems primal form. kernelizing dualizing possible using standard techniques ﬁrst model learning privileged information svm+ based direct observation non-linearly separable support vector machine turned linearly separable access so-called slack oracle. standard soft-margin classiﬁer trained based following constrained optimization problem note classiﬁer fully characterized weight vector bias parameter however training phase slack variables training sample also need estimated. number training examples increases soft-margin wonders whether possible soft-margin faster convergence rate ideally rate hard-margin svm. answer positive improved softmargin would require fewer training examples reach certain prediction accuracy inferred data instead unknowns include slack variables estimating unknowns actual object interest classifying hyperplane. interpretation slack variables tell training examples easy hard oraclesvm infer variables data given oracle. numerical optimization svm+ optimization problem convex solved dual representation using standard quadratic programming solver. medium size problem general purpose solver might suﬃce special purpose algorithms developed solve suitable sequential minimal optimization algorithms derived tackle problem. however problem size experimenting using general purpose provided cvxopt package faster specialized solver. therefore cvxopt-based solver experiments work propose second model called margin transfer that solved sequence standard solvers; explicitly enforces easy-hard interpretation transferring information privileged original space. method adaptation rank transfer method previously described ranking setup identify transfer information easy-to-separate hard-to-separate pairs examples. here propose follow similar strategy instead looking pairs examples check example whether easy-to-classify hard-to-classify based margin distance classifying hyperplane privileged space. subsequently transfer knowledge original space. hypothesize knowing priori examples easy classify hard learning improve prediction performance. consideration leads margin transfer method summarized algorithm first train ordinary resulting prediction function used compute margin distance training samples classifying hyperplane privileged space yif∗. examples large values considered easy classify whereas small even negative values indicate hard even impossible classify samples. train standard aiming datadependent margin transferred privileged space rather enforcing constant margin corresponding optimization problem examples small negative values limited inﬂuence comparing standard slacks easily compensate inequality constraint. threshold negative values margin certain tolerance value interpretation possible correctly classify sample privileged space also possible presumably weaker original space. forcing optimization solve hopeless tasks would lead overﬁtting reduced prediction accuracy. http//cvxopt.org note standard formulation would compute values slack variables know sample hyperplane. slack variables appear training phase deliberately evaluate prediction function data trained identify easy hard samples train time. numeric optimization learning steps margin transfer method convex optimization problems. furthermore contrast svm+ standard packages solve them including eﬃcient methods working primal representation solvers based stochastic gradient descent data-dependent margin following reparameterization divide constraint corresponding possible thresholding non-negative tolerance value. experiments threshold thereby preventing numeric instabilities increasing computational eﬃciency method. changing variables obtain equivalent optimization problem corresponds standard optimization training examples slack variable individual weight objective. many existing packages support per-sample weights experiments liblinear additionally would like position model support recent results svm+ classiﬁers reformulated special forms example-weighted binary svms suppose training samples oracles perceive samples. case svm+ back following answers oraclesvm+ oraclesvm+ means ﬁrst sample hard second easy encode optimization problem svm+ constraint second one. before optimization task would ignore constraints hard samples concentrate learning easy ones. despite fact svm+ oracle returns high value hard samples margin transfer oracle returns value hard samples vice versa easy ones. core svm+ lies idea imitating oracle learning non-negative linear regression slack function deﬁned privileged space. information labels come play modeling slack function sense never validate classiﬁcation performance privileged space. contrast margin transfer method performance privileged space explicitly guides training predictor original data space. samples easy hard classify privileged space directly deﬁne margin samples original data space. rank transfer method described observe another information transfer considering pairs samples. pair samples diﬀerent classes estimate whether easy-to-separate hard-to-separate pair based rank margin samples privileged space. transfer information ranking objective completely ignore pairs swapped. rank transfer framework deal pairs samples therefore suﬀer quadratic amount constraints satisﬁed every pair samples considered. experimental setting study three diﬀerent types privileged information showing handled uniﬁed framework previously hand crafted methods used. consider attribute annotation bounding annotation textual description sources privileged information present training time test time. modalities suitable transferring margin others. discuss following subsections. methods. analyze methods learning using privileged information proposed margin transfer method transferring margin svm+ method compare results ordinary learning original space directly. also provide reference performance privileged space access privileged information testing. model selection. lupi methods perform joint cross validation model selection approach choosing regularization parameters original privileged spaces. svm+ method margin transfer two-stage procedure methods privileged information regularization parameter cross validated. privileged experiments fold cross-validation scheme binary classiﬁcation fold cross-validation multiclass setting. best parameter found used retrain complete training set. based experience lupi methods require thorough model selection step. couple modalities privileged original data spaces properly grid search parameter spaces exploited. attribute annotation incorporates high-level description semantic properties diﬀerent objects like shape color habitation forms etc. concept attributes introduced attribute-based classiﬁcation object image classiﬁed based attributes has. animals attributes dataset focus default test classes attribute annotation provided together dataset. classes chimpanzee giant panda leopard persian hippopotamus humpback whale raccoon seal contain images total. attributes capture properties animals color texture shape body parts behavior among others. normalized dimensional surf descriptors original features dimensional predicted attributes privileged information. values predicted attributes obtained model correspond probability estimates binary attributes images. train binary classiﬁers pair classes images class training data. samples class testing. better statistics performance repeat procedure train/test split times. results. figure utilizing attributes privileged information object classiﬁcation task useful. margin transfer outperforms cases svm+ outperforms cases. noticeably margin transfer model able utilize privileged information better svm+. observe partial overlap cases margin transfer svm+ able utilize privileged information bars coincide mostly pairs giant panda leopard versus animals. full comparison accuracy methods shown table also notice gain margin transfer method higher regime problem hard i.e. accuracy analysis also check hypothetical performance privileged space privileged information consistently higher accuracy original space cases higher accuracy privileged space original space translates positive eﬀect margin transfer. credit fact margin transfer relies performance privileged space order explore easiness hardness samples. successful underlying assumption examples easy hard modalities fulﬁlled cases here. bounding annotation designed capture exact location object image. usually represented around object. performing image-level object recognition knowing exact location object training data privileged information. subset categories imagenet challenge chimpanzee versus giant panda chimpanzee versus leopard chimpanzee versus persian chimpanzee versus chimpanzee versus hippopotamus chimpanzee versus humpback whale chimpanzee versus raccoon chimpanzee versus chimpanzee versus seal giant panda versus leopard giant panda versus persian giant panda versus giant panda versus hippopotamus giant panda versus humpback whale giant panda versus raccoon giant panda versus giant panda versus seal leopard versus persian leopard versus leopard versus hippopotamus leopard versus humpback whale leopard versus raccoon leopard versus leopard versus seal persian versus persian versus hippopotamus persian versus humpback whale persian versus raccoon persian versus persian versus seal versus hippopotamus versus humpback whale versus raccoon versus versus seal hippopotamus versus humpback whale hippopotamus versus raccoon hippopotamus versus hippopotamus versus seal humpback whale versus raccoon humpback whale versus humpback whale versus seal raccoon versus raccoon versus seal versus seal table dataset numbers mean standard error accuracy runs. best result highlighted boldface total margin transfer svm+. highlighted blue indicates signiﬁcant improvement methods utilize privileged information methods used paired wilcoxon test conﬁdence level reference. additionally also provide performance figure dataset pairwise comparison methods utilize privileged information baseline counterpart shown diﬀerence accuracy performance. length bars corresponds relative improvement accuracy cases. bounding annotation available. deﬁne groups interest group variety snakes group balls diﬀerent sport activities. group snakes classes thunder snake ringneck snake hognose snake green snake king snake garter snake water snake vine snake night snake constrictor rock python indian cobra green mamba snake horned viper diamondback sidewinder images total average samples class. ignore images small bounding region images analysis. group balls classes soccer ball croquet ball golf ball ping-pong ball rugby ball tennis ball images total average samples class. here also ignore images uninformative bounding annotation images instead. consider one-versus-rest scenario group separately. normalized -dimensional fisher vectors extracted whole images well bounding regions former original data representation latter privileged information. train binary classiﬁer class ﬁrst group second group. training balance amount positive samples negative samples formed remaining classes i.e. groups accordingly. group snakes versus images randomly drawn desired class remaining classes used amount samples testing. group balls versus images training randomly drawn desired class remaining classes keep setting similar across datasets used double amount samples testing. better statistics performance repeat train/test split times. thunder snake ringneck snake hognose snake green snake king snake garter snake water snake vine snake night snake constrictor rock python indian cobra green mamba snake horned viper diamondback sidewinder table imagenet dataset group snakes numbers mean standard error accuracy runs. best result highlighted boldface. highlighted blue indicates signiﬁcant improvement methods utilize privileged information methods used paired wilcoxon test conﬁdence level reference. additionally also provide performance soccer ball croquet ball golf ball ping-pong ball rugby ball tennis ball table imagenet dataset group sport balls numbers mean standard error accuracy runs. best result highlighted boldface. highlighted blue indicates signiﬁcant improvement methods utilize privileged information methods used paired wilcoxon test conﬁdence level reference. additionally also provide performance results. table table utilizing bounding annotation privileged information ﬁne-grained classiﬁcation useful. tables lupi methods outperform non-lupi baseline case. group snakes svm+ clearly outperforms cases margin transfer outperforms cases experiment svm+ method able exploit privileged information much better margin transfer method group balls observe similar results clear advantage svm+ method methods. margin transform shows minor diﬀerence respect standard svm. noticeably performance privileged space superior original data space sometimes even worse especially group balls. since margin transfer method relies directly performance privileged space ability exploit easy hard samples limited scenario. hand modeling slacks form regression model svm+ does works well. suspect suitable privileged original spaces modality i.e. here privileged information obtained subset image features used original data representation. textual description provides complementary view visual representation object. used privileged information object classiﬁcation task. datasets explore textual description source privileged information describe turn. ﬁrst dataset israelimages introduced dataset classes images total textual description attached image. number samples class relatively small around samples varies samples. merge classes three groups nature religion urban perform binary classiﬁcation pairs groups. normalized -dimensional fisher vectors extracted images original data representation bagof-words representation text data privileged information. images group training group testing. repeat train/test split times. second dataset accessories dataset introduced dataset contains products taken variety e-commerce sources images textual descriptions. products grouped broad shopping categories bags earrings ties shoes. randomly select samples dataset experiments samples category. generated binary classiﬁcation tasks pair classes samples class training class testing. second dataset contains longer text descriptions israelimages dataset. longer texts allow advanced features introduced recently term word vectors instead simple term frequency features. extracted dimensional word vector using neural network skip-gram architecture constructed codebook word-vector convert word representation ﬁxed-length sentence representation apply normalization. normalized surf descriptors extracted images visual words codebook feature representation original space. non-lupi near equal performance signal privileged information utilized lupi methods. might seem contradictory high performance reference baseline text domain however high accuracy privileged space necessarily mean privileged information helpful. example assume used labels privileged modality classiﬁcation would trivial would provide additional information transfer. israelimages textual descriptions images sparse contain many duplicates accessories datasets texts easy. therefore margin distance privileged space capture easiness hardness diﬀerent samples mainly preserves class separation only. performance degrade nevertheless. also explore beneﬁts utilizing lupi methods multiclass setup one-versus-rest learning strategy. train binary classiﬁer class distinguish samples class versus samples remaining classes test point label assigned based class maximum prediction value binary classiﬁers. model selection fold cross-validation scheme search range regularization parameters before. order calibrate prediction scores diﬀerent classiﬁers parameter value train binary classiﬁers cross validate multiclass performance. best parameter used retrain classiﬁers. best knowledge ﬁrst time lupi methods studied classiﬁcation learning setting classes. multiclass setting datasets described previously binary classiﬁcation task. results summarized table table multiclass performance. numbers mean standard error accuracy runs. best result highlighted boldface. additionally reference also provide performance ticlass classiﬁcation. lupi methods outperform non-lupi baseline datasets. overall margin transfer superior svm+ case stable contrary performance drop svm+ accessories datasets; follows tendency outperform performance privileged space better original space experiment collect mechanical turk annotation images deﬁne easy hard samples human learning. analyze advantages information comparison lupi methods. managed collect reliable human annotation classes dataset chimpanzee giant panda leopard persian hippopotamus raccoon seal except class humpback whale. dataset many pictures class related food product rather animal itself create aesthetic issues user make objective judgment. images class humpback whale lack variability across samples makes diﬃcult distinguish easy hard ones. make analysis based annotation classes. user study participant shown images particular class asked select prominent images ﬁrst proceed less obvious diﬃcult samples left. aggregate ranking information across overlapping sets images compute global order images category. score range till observe time easiest instances clearly visible object interest center image hardest occluded objects small sized humans. evaluation. first analyze advantage transferring information human annotation looking accuracy performance. order easy-hard score margin distance linear scaling score interval values correspond hard samples values greater correspond easy samples. proceed directly second stage margin transfer method report results pairs classes table secondly study whether easy-hard score human understanding correlates easy hard samples identify learning privileged space attributes. kendall rank correlation analysis compute correlation coeﬃcient across learning tasks. task compute correlation margin distance training samples classifying hyperplane privileged correlation predicted values classiﬁers trained data original space privileged space attributes. complete analysis also look correlation user deﬁned easy-hard scores easy hard samples original space. visualization aggregate results symmetric table entry coeﬃcient computed corresponding pair classes binary learning task refer figure chimpanzee versus giant panda chimpanzee versus leopard chimpanzee versus persian chimpanzee versus hippopotamus chimpanzee versus raccoon chimpanzee versus chimpanzee versus seal giant panda versus leopard giant panda versus persian giant panda versus hippopotamus giant panda versus raccoon giant panda versus giant panda versus seal leopard versus persian leopard versus hippopotamus leopard versus raccoon leopard versus leopard versus seal persian versus hippopotamus persian versus raccoon persian versus persian versus seal hippopotamus versus raccoon hippopotamus versus hippopotamus versus seal raccoon versus raccoon versus seal versus seal table human annotation privileged information. incorporate human perception easiness hardness margin distance perform margin transfer human annotation numbers mean accuracy standard error runs. results. table collecting good quality human annotation help improve classiﬁcation performance however cannot solve problem negative transfer privileged space original space. cases clearly helps classify categories giant panda leopard versus others cases category chimpanzee. figure overall correlation easy-hard samples privileged original data spaces higher signal human annotation versus privileged data space versus original data space look closely case giant panda observe indeed correlation human annotation ranking original data expressed possibly explains performance gain using human annotation privileged information instead attribute description. always case leopard class example classiﬁcation figure human annotation privileged information. kendall rank correlation analysis used explore correlation easy-hard samples deﬁned human annotation easy hard samples identify learning privileged space analyze correlation easy hard samples privileged original data spaces human annotation samples original data space versus seal correlation considerably stronger also matches better performance gain utilizing attributes privileged information. class chimpanzee seems suitable explore privileged information based attribute description comparing human annotation classes right plot little signal correlation i.e. mostly blue color coincides rather disadvantageous performance margin transfer human annotation privileged information comparison margin transfer attributes privileged information. correlation like pairs versus persian also seal versus hippopotamus explained performance classiﬁers pairs. performance case means hard/misclassiﬁed samples wrong side classiﬁer hyperplane inﬂuences margin score. principle situation suitable ranking correlation analysis human deﬁned easy hard sample scores account misclassiﬁcations. studied setting learning using privileged information visual object classiﬁcation tasks. showed applied several situations previously handled hand-crafted separate methods. experiments show prediction performance often improves utilizing privileged information both binary multiclass learning settings. studied approaches solving lupi task svm+ proposed margin transfer method. margin transfer shows comparable performance svm+ algorithm easily applied using standard solvers. analysis main modeling assumptions lupi methods suggested privileged information utilized measure easiness hardness samples guide learning classiﬁer better generalization. also work made attempt understand essence easy hard samples learning process compared human labeled easy hard samples annotated user future interested exploring relatedness multiple tasks privileged space original space. another direction explore possibility predict priviledged data test time.", "year": 2014}