{"title": "Deep Exemplar 2D-3D Detection by Adapting from Real to Rendered Views", "tag": ["cs.CV", "cs.LG", "cs.NE"], "abstract": "This paper presents an end-to-end convolutional neural network (CNN) for 2D-3D exemplar detection. We demonstrate that the ability to adapt the features of natural images to better align with those of CAD rendered views is critical to the success of our technique. We show that the adaptation can be learned by compositing rendered views of textured object models on natural images. Our approach can be naturally incorporated into a CNN detection pipeline and extends the accuracy and speed benefits from recent advances in deep learning to 2D-3D exemplar detection. We applied our method to two tasks: instance detection, where we evaluated on the IKEA dataset, and object category detection, where we out-perform Aubry et al. for \"chair\" detection on a subset of the Pascal VOC dataset.", "text": "appearance across different domains encountered alignment unique problem found tasks e.g. learning dataset testing another bridge appearance gaps number cross-domain adaptation algorithms developed e.g. building successes methods present approach learns adapt natural image features task exemplar detection. hypothesize that given features natural image depicting object possible infer features corresponding rendered view object model similar style pose. note similar reasoning explored recent work predict object features different view achieve adaptation learning goal need large training aligned natural image rendered view pairs depicting similar object. existing datasets aligned pairs e.g. ikea pascald datasets either relatively small aligned models coarsely approximates object style. overcome challenges make ability render views models composite natural images allows create large training set. composite image rendered view pairs form training data learn feature adaptation similarly employed prior work train object detectors renders predict object pose learning adaptation adopt formulation similar lenc vedaldi studied equivariance image features geometric deformations image. work seen extension approach beyond geometric transformations. show adaptation incorporated module cnn-based object detection pipeline. furthermore show precomputed features rendered views added fully-connected layer brings beneﬁts accuracy speed recent advances deep learning exemplar detection. paper presents end-to-end convolutional neural network exemplar detection. demonstrate ability adapt features natural images better align rendered views critical success technique. show adaptation learned compositing rendered views textured object models natural images. approach naturally incorporated detection pipeline extends accuracy speed beneﬁts recent advances deep learning exemplar detection. applied method tasks instance detection evaluated ikea dataset object category detection out-perform aubry chair detection subset pascal dataset. recently aubry performed object category detection exemplar alignment large library object models. aligned models often approximately matched style depicted objects allowed information hidden object surfaces object pose propagated images. result useful scene reasoning potentially used applications object manipulation robotics model-based object image editing computer graphics despite recent progress matching retrieval detection alignment lags behind state-of-the-art object detection systems based annotated images e.g. r-cnn terms accuracy speed. primary reasons performance large appearance views rendered models real images; dbased object detection beneﬁted recent successes convolutional neural networks work ∗universit´e paris-est ligm enpc marne-la-valle. work carried imagine joint research project ecole ponts paristech centre scientiﬁque technique bˆatiment figure system overview. system takes input individual image object proposal windows generated selective search algorithm image window passed initial layers pre-trained caffenet model generate feature vector here visualize features using inversion network infers original image given layer’s response. ofﬂine step similarly pass rendered views library object models initial layers caffenet record responses. domain appearance natural images rendered views models learn adapt features natural image better align models compare features return view best matches style pose input image introduce cross-domain adaptation approach exemplar detection using generated pairs rendered views models composite views natural background. adaptation routine adapts features natural images depicting objects closely match features model rendered views. show adaptation routine incorporated cnn-based detection pipeline leads increase accuracy speed exemplar detection. evaluated method tasks instance retrieval ikea dataset object class detection pascal subset used aubry show state-of-the-art exemplar detection performance ikea instances out-perform discriminative element approach aubry terms accuracy speed. extended annotations ikea object dataset diverse dataset textured non-textured rendered views models used learn adaptation full code available http//imagine.enpc. fr/˜suzano-f/exemplar-cnn/. related work understanding natural images problem interest computer vision since beginning work line traditional geometrycentric approaches object recognition based alignment number successful approaches instance-level recognition e.g. typically based sift matching geometric constraints. recent approaches leveraged contourbased representation align skylines statues furthermore simpliﬁed parametric geometric models rendered views models used input training object class detector viewpoint prediction similar approaches align models directly images. examples include alignment ikea furniture models images exemplar-based object detection matching discriminative elements using hand-crafted features retrieving models depth prediction compositing multiple models also related approaches retrieval given rgb-d images recently work enrich feature representation matching alignment using cnns include retrieval based responses pool features) learning transformation features light-ﬁeld descriptors shapes training siamese network style retrieval building efﬁcient cnn-based object class detection e.g. r-cnn approach extends cnn-based approaches efﬁcient cad-exemplar detection. bridging different image modalities classic problem alignment past approaches addressed problem using main strategies. ﬁrst line work used manually-designed feature detectors adapted them example adding mask focus information available models real images another line work focused increasing realism rendered views e.g. extracting likely textures background annotated images domain adaptation approaches formulated cnns recently object detection tuning across tasks contemporary work transfer learning optical depth similar approach domain adaptation adapted hand-crafted features object detection. formulate generic domain adaptation approach image features applied hand-crafted features e.g. responses. figure shows exemplar detection pipeline. start computing features image corresponding selective search window along features rendered views models. large appearance across domains learn adapt features natural images better match features rendered views compare adapted features calibrated rendered view features obtain matching scores rendered view note detection pipeline implemented cnn. evaluation approach section section describe approach adapting features extracted real images better correspond features extracted rendered views models. approach general applied image feature e.g. cnn-based features adapt real images rendered views since likely difﬁcult hallucinate features corresponding missing image details surrounding context object texture remove them. formally seek learn transformation features real images. intuitively projection real image feature space space features rendered views. ideally property mapping given real image feature depicting object interest features rendered views object models geometry style pose. suppose input pairs features corresponding examples real images rendered views well-aligned models respectively. seek minimize following cost adaptation. simplest choice afﬁne transformation reference experiments also tested constrained complex transformations. focused transformations could formulated layers particular successions convolutional relu layers. note considering complex transformations also increases risk overﬁtting. similar lenc vedaldi attempted constrain structure transformation sparsity. easily done replacing fully-connected layer convolutional layer limited support implies translation invariance adaptation. found best-performing transformation slight modiﬁcation afﬁne transformation relu element-wise maximum zero. observed applying relu function consistently improved results agreement state-of-the-art architecture design choices object recognition. similarity. tried squared-cosine similarity measure similarity equation found leads better results. expected since cosine similarity known work better comparing features also later used cosine distance compare real synthetic features result also consistent observation importance task-speciﬁc similarities lenc vedaldi training data details. adaptation formulation requires large training well-aligned pairs images rendered views models matching style pose depicted objects. dataset difﬁcult acquire. existing datasets object models aligned images closely matching depicted object pose models often similar style. recent work accurate alignment models composition semi-automatic sweep modeling promising approaches obtaining accurate image-model alignments large-scale results available. models composite natural image backgrounds. gives access virtually unlimited training data. backgrounds provide natural-looking surrounding context encourages transformation learn subtract away background context. avoid color artifacts composite images used gray-scale image pairs also used gray-scale images test time. note contrary prior approaches using manually-annotated scenes increase realism composite directly object annotation background selection process. figure shows four representative image pairs adaptation data models found using diverse database comprising several object categories produced better results focusing target models detect. used reference experiments textureless rendered views aubry russell train adaptation. implementation details. used small regularization experiments found improved results despite large training sets. trained using stochastic gradient descent within torch framework used weight decay corresponding regularization momentum mini-batch size started learning rate reduced every epochs factor convergence. section show adaptation procedure section together feature computation exemplarbased retrieval incorporated efﬁcient cnnbased detection routine similar r-cnn exemplar detection. given input image seek detect bounding location object image return corresponding model similar style along pose depicted object. exemplar-detection pipeline. following initial part r-cnn object detection pipeline ﬁrst extract selective search windows compute responses intermediate layer window. apply adaptation features compare results features different model rendered views. similarity features rendered view. shown aubry calibration important step comparing similarity across different views models. starting initial similarity score apply afﬁne calibration routine compute calibrated similarity cisi scalar parameters selected using large random patches correspond random patch features mean .-percentile similarity scores respectively. take advantage fact exemplar-based detection setup expected aspect ratio alignments known. remove candidate rendered-view alignments aspect ratio difference selective search window rendered view. finally rank remaining alignments score perform non-maximum suppression obtain ﬁnal detections. implementation. figure shows exemplar detection. network starts layers corresponding trained different task trained imagenet classiﬁcation experiments) intermediate layer next resulting features pass adaptation layers corresponding implemented fully-connected layer followed relu. resulting adapted features compared exemplar rendered-view features. several standard similarity functions product cosine similarity implemented layers. example cosine similarity implemented feature-normalization layer followed fully-connected layer. weights fully-connected layer correspond matrix stacked unit-normalized features exemplar rendered views computed ofﬂine stage. afﬁne calibration could implemented independent layer incorporated directly fully-connected layer replacing matrix rows ciyi adding bias corresponding ﬁnal exemplar rendered-view scores given image features computed single forward pass cnn. section qualitatively quantitatively evaluate method analyze different design choices. first focus simpler retrieval task select features similarity function detection task then present main results object-instance object-class table instance detection performance ikea object dataset report average precision using bounding overlap threshold note categories reported annotated examples. report results classes include annotated instances. part table presents results original annotation bottom part extended annotations. evaluated detection outputs provided using extended annotations. dataset includes three different similar sizes bed. since able differentiate visually three kind beds annotated. select features similarity function comparing natural images rendered views consider retrieval task where given cropped image depicting query object seek return model corresponding object. consider ikea dataset models ikea object instances manually aligned location images depicting cluttered scenes. task allows compare performance different layer responses similarity functions. retrieval task difﬁcult variety object poses perspective effects ikea dataset. handle variation object pose perspective effects rendered azimuth elevation angles different distances object. note rendered views cover many possible viewpoints perspective effects cover cases. extracted features caffenet experiments. recent deeper networks yield better results illustrate basic design choices using shallower caffenet model. also expect better results using last layers network tuned object-class detection e.g. r-cnn tuned pascal detection chose consider network focus general case natural images related object classes annotated training. performed retrieval using features extracted conv layers caffenet relu applied max-pooling conv conv features keep dimensionality relatively small avoid memory issues detection pipeline. denote resulting features pooling pool pool. compared three similarity functions experiments distance dot-product similarity cosine distance. report retrieval accuracy table notice performance cosine distance best pool features decreases higher layers performance increases higher layers dot-product similarity. based results used cosine distance pool features experiments. moreover conv features known relatively generic features make little network knowledge gained speciﬁc objects chairs sofas beds imagenet classiﬁcation. section demonstrate feature-adaptation algorithm detection. consider tasks objectinstance object-category detection alignment. object-instance detection evaluated ikea dataset object-category detection evaluated subset pascal containing chairs used aubry show qualitative quantitative results benchmarks compare prior work. table average precision chair detection pascal subset best method outperforms baselines white column corresponds synthetic images white background. comp column corresponds synthetic images composited real-image backgrounds. matched exceeded baselines. inspecting bookcases missed algorithm available project webpage almost consist highly cluttered examples e.g. bookcases ﬁlled books different colors. veriﬁed extended annotations billy bookcases empty whereas billy billy non-cluttered examples dataset. looking false positives figure conﬁrms this since many parts empty bookcases bookcases categories. object-category detection alignment evaluated approach subset pascal dataset containing images non-difﬁcult non-occluded nontruncated chairs used aubry aligned chair rendered views. followed detection protocol report average precision detection task. compare performance baseline aubry also performs detection alignment. also report performance r-cnn without without bounding regression trained natural images object detection. another baseline report performance logistic regression classiﬁer trained using synthetic images similar spirit recent approaches trains object detector using synthetic training images order better situate work respect approaches train classiﬁer using synthetic images composite backgrounds also report results following baselines using synthetic images composited natural-image background positives without adaptation logistic regression figure detections billy ikea model. note ﬁrst good detection counted negative original annotation annotated dataset. detections different bookcases parts bookcases. object-instance detection alignment evaluated approach ikea dataset followed detection protocol outlined report average precision detection performance table along baselines task. seen clearly improve baselines several well-represented classes. however smaller baselines. show main effects chance factor classes objects annotated missing annotations failure algorithm bookcases analyze detail. dataset additional annotations. important issues using ikea object dataset evaluating instance detection relatively small size partial annotations made available maximum object image several often present. partly address issues annotated instances test images classes included three instances original dataset appear correspond different model). increases number annotated objects selected classes report results extended annotation table release annotation allow comparisons. extended annotations similar strong differences performance different objects. similar results clear improvements classes much lower performance bookcases figure top-ranked false positives without adaptation. since several false positives image without adaptation show best ranked image. false positives without adaptation occur uniform background patches. adaptation effect largely disappears false positives correspond patches look like chairs chair parts. inﬂuence adaptation alignment. figure show detections without adaptation. notice non-adapted features higher detection scores cad-like images darker chairs mostly white background adaptation allows detect chairs colors natural cluttered scenes similarly show false positives figure notice without adaptation false positives correspond regions uniform background adaptation chair-shaped false positives similar object detector trained natural images adaptation design. discussed section adaptation equation implemented fully-connected layer followed relu nonlinearity. seek study variants since pool caffenet features maintain spatial structure consider adaptations limited spatial support convolution kernels. also consider whether relu nonlinearity whether consider multiple convolutional layers adaptation. figure shows average precision different variants function aspect ratio threshold. notice adaptation variants tried performed better without adaptation imposing adaptations limited spatial support performed worse fully-connected layer. understood considering effect projection depends interpretation image foreground object background clutter task better performed globally. using layfigure detections without adaptation pascal chair subset notice alignments good without adaptation detection withadaptation returns dark chairs cad-like white backgrounds. detections adaptation include brighter objects cluttered backgrounds. report results table reference adaptation method outperforms baselines except rcnn svm. obtain average precision compared aubry peng also tried using method chairs resulted difference performance likely manual selection realistic viewpoints models w-ug set. detailed analysis reveals importance adaptation methods based features models. note beneﬁt using adaptation less important using layer logistic regression. shows unsurprisingly less sensitive type representation conv explain good results obtained using layers directly. interesting question whether adaptation could replaced synthetic images composited natural-image backgrounds. seen table even though composites help cases performance still lags behind performance obtained using adaptation. note used single background exemplar view. could include composites exemplar would increase memory requirements would need store additional exemplars. adaptation degraded performance. note observed validation loss better optimized using layers. believe effect synthetic nature training data approximates relation real synthetic images. finally found adding relu convolutional layer consistently increased performance. single fully-connected layer followed relu produced best performance. aspect ratio. figure shows evolution average precision function aspect ratio threshold different projections pascal subset detection experiment. expected increasing threshold ﬁrst improves results removes many false positives.the results relatively stable since positives negatives discarded. finally performance drops higher thresholds true positives discarded. experiments used aspect-ratio threshold evaluation retrieved pose. conducted experiment aubry evaluate quality retrieved poses. ground truth used pose annotations pascald figure shows histogram azimuth angle errors recall algorithm returns azimuth angle within ground truth examples compared aubry number rendered views. studied relative importance model dataset size ﬁnal detection performance conducting experiments renders aubry randomly selected increasing subsets rendered views randomly selected increasing numbers models used rendered views notice performance increases number renders expected. interestingly diversity models plays important role ﬁnal detection score. roughly number rendered views models performs considerably worse system runs computational time similar rcnn rendered views memory. excluding time compute bounding proposals align test image rendered views approximately seconds geforce graphics card. align views expense copying precomputed rendered view features memory. overcome larger-memory graphics cards running parallel cards. rendered views approach takes around seconds. similar recent fast detection pipelines timings could optimized reusing convolutional features bounding could potentially reduce computational time fraction second. filtering aspect ratio comparing features could also reduce number tests perform especially case large number views. note even without improvements computational times much faster presented aubry demonstrated end-to-end exemplar detection. showed adaptation image features closely match features rendered views models essential success. adaptation approach agnostic feature could potentially beneﬁt detection methods. thank joseph shared ikea detection outputs allowed compare approach using extended annotations. also wish thank alyosha efros renaud marlet fruitful discussions. work partly supported project semapolis anr--cord- intel gift adobe hardware donation nvidia.", "year": 2015}