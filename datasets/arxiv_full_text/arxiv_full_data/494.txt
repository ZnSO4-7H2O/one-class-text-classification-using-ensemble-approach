{"title": "A Survey of Voice Translation Methodologies - Acoustic Dialect Decoder", "tag": ["cs.CL", "cs.NE", "cs.SD", "stat.ML"], "abstract": "Speech Translation has always been about giving source text or audio input and waiting for system to give translated output in desired form. In this paper, we present the Acoustic Dialect Decoder (ADD) - a voice to voice ear-piece translation device. We introduce and survey the recent advances made in the field of Speech Engineering, to employ in the ADD, particularly focusing on the three major processing steps of Recognition, Translation and Synthesis. We tackle the problem of machine understanding of natural language by designing a recognition unit for source audio to text, a translation unit for source language text to target language text, and a synthesis unit for target language text to target language speech. Speech from the surroundings will be recorded by the recognition unit present on the ear-piece and translation will start as soon as one sentence is successfully read. This way, we hope to give translated output as and when input is being read. The recognition unit will use Hidden Markov Models (HMMs) Based Tool-Kit (HTK), hybrid RNN systems with gated memory cells, and the synthesis unit, HMM based speech synthesis system HTS. This system will initially be built as an English to Tamil translation device.", "text": "order make process communication amongst humans better easier efficient. however existing methods including google voice typically handle process translation non-automated manner. makes process translation word and/or sentences language another slower tedious. wish make process automatic device human translator does inside ears. speech translation process conversational spoken word and/or phrase translated result obtained either form words displayed screen output spoken aloud second language. make technology highly efficient automate process make inter-audio conversion produces simultaneous results without physically start process translation. enables people simply wear device hear native speech languages. everyone world equipped devices would total understanding harmony. technology tremendous importance enables speakers different languages communicate adds value humankind terms world peace science commerce cross-cultural exchange world politics global business. initially audio input system. audio subjected process feature extraction wherein noise surrounding disturbances removed produce feature vector. grammar files input sentence bstractâ€” speech translation always giving source text/audio input waiting system give translated output desired form. paper present acoustic dialect decoder voice voice ear-piece translation device. introduce survey recent advances made field speech engineering employ particularly focusing three major processing steps recognition translation synthesis. tackle problem machine understanding natural language designing recognition unit source audio text translation unit source language text target language text synthesis unit target language text target language speech. speech surroundings recorded recognition unit present ear-piece translation start soon sentence successfully read. hope give translated output input read. recognition unit hidden markov models based tool-kit hybrid systems gated memory cells synthesis unit based speech synthesis system hts. system initially built english tamil translation device. language thing world enable time completely shut human communication. language known take hardly seconds understand language understand cannot understood without using dictionaries manual parsers translators and/or various applications available translation. solutions disrupt flow conversation someone could another person different dialect pause required request translation time takes actual translation process. generated extended backus naur form vector trained using grammar files generate audio input's corresponding textual sentence. process explained modular fashion figure methods used including hmms neural networks deep neural networks. hmms used speech recognition speech signal visualised piecewise stationary signal short-time stationary signal. short time-scale speech approximated stationary process. speech thought markov model many stochastic purposes. another reason hmms popular trained automatically simple computationally feasible use. dynamic time warping used hmms long declared less successful used. neural networks used efficiently rarely successful continuous recognition tasks temporal dependencies .deep neural networks shown succeed system components recognition translation synthesis used hmms least time complexity. especially since based actual human auditory system perceptual frequency scale called frequency scale. combines advantage cepstral analysis perceptual frequency scale based critical bands making logarithmically spaced filter banks prior introduction mfccs lpcs lpccs used feature extraction process. stated obsolete since linear computation nature lack perceptual frequency scales even though efficient tuning environmental noise disturbances sampled speech signal further several researches based feature extraction various languages like english chinese japanese even indian languages like hindi proved experimentally mfccs produce least percent efficiency opposed percent lpcs lpccs available fairly popular widely accepted frameworks sphinx. based hidden markov model open source. frameworks used develop train test speech model existing corpus speech utterance data using hidden markov modeling techniques figure shows results achieved decoding test data corpus. achieved running windows cygwin .ghz pentium processor system divided word-based phrase-based phoneme-based mechanisms. excellent performance isolated word recognition word-based models fail comes continuous complexity. phoneme-based best approach employed system ability incorporate work large corpus ease addition words vocabulary main component feature extraction. uses maximum relevant information speech signal helps distinguish different linguistic units removes external noise disturbances emotions commonly used feature extraction techniques mfccs lpcs lpccs mfccs feature shall used process reason stated follows. mfccs ascertained state-of-the-art feature extraction decoder make deletions gave slight advantage overall word error rate. also hvite uses time difference running test significant seconds addition supports hcopy tools provide wealth input/output combinations model data front-end features couple present sphinx certain compatibility provided. however efficiency compatibility debatable slight advantages sphinx supported multiple sphinx largely supported linux platforms only. also uses first systems used involved takes source sentence input word word mutating input using hidden layer output function mapped encoded form input hidden layer back form used arrive target sentence using language translation modelling functions. beginning hidden layer used type rnns known shallow rnns. later layers hidden functions used instead system known deep drnns found much better encoding source sentence target sentence thus quickly replaced shallow rnns approach using single widely known phrase-based approach recent methods encoderdecoder approach. method shown figure involves rnns encoding decoding. encoder takes source sentence word word transforms vector contains properties sentence hidden layer function recursive previous function. decoder takes vector maps target sentence achine translation process converting source sentence sequence target sentence sequence same/different length. even though come long initial models nowhere near completely efficient. machine translation worked recent advancements using neural networks propelled field height. direct rule-based datadriven. achine translation implemented multitudes methodologies ranging decades research. machine translation advent direct translation system ways introduced like rule-based example-based machine translation systems. direct translation process conditional transcription source target words. rule-based systems operated rules translate sentences example-based system mapped examples. problems approaches lack interlingua database scalability naive nature translations tatistical machine translation source sentence encoded representation translated target language maximising probability closeness target sentence using bayes rule. faster systems used parallel processing various modules subsystems. scalable large scale memory performance bottlenecks previously used techniques still inherent complexity issue. importantly systems took space even translation engine small vocabularies. advent recurrent neural networks natural language processing field take turn unexpected advancement. rnns defined means hile system theoretically perfect retaining long range dependencies across input sentence practice falls short system unable maintain dependencies without memory units. made impossible system translate sentences bigger sentence length. popularly known vanishing gradient problem. problem various methods implemented smooth bounded function refers hidden layer function time epoch refers input received time output time known output function. usually input rnns encoded hidden layer using functions input onto continuous space like tanh sigmoid function etc. output function activation function common ones successfully store information sentence words them hidden layers built along gate-operated memory unit capable retaining encoding done state long time. solves problem lack long range dependencies system. ensure system errors algorithm like back propagation stochastic gradient descent linear gradient descent etc. used normalise values. main problem regular systems retain values algorithms applied. lstm neuron defined input forget cell output gates respectively. hidden layer depends output cell gates. output hidden layer function hidden layer time epoch logistic sigmoid utomatic segmentation first methods meaningful phrases translated together successful segmentation. issue sentence length occurs neural network fails recognize initial words input sentence vector sentence transcribed input sentence segmented cohesive phrases translated easily every segment source sentence translated target sentence target phrases concatenated together produce output. hile gets vanishing gradient problem poses difficulties. neural network work easy translate clauses clause division problem system cannot decide best cohesive phrases translate target language easily. also computational complexity increases parallel processing required reading input words translating previously read phrase time. also method concatenating translated phrases works languages long range dependencies words sentence source target language pairs similar grammar structures.. main problems rnns inability system maintain long range dependencies sentences words. main reasons input sequence scanned direction normally beginning sentence end. simultaneously model past future references bidirectional rnns used system composed independent recurrent layers layer processes input sentence forward time steps layer processes input sentence backward time steps bidirectional rnns defined output function hidden states forward time steps backward time steps hidden state functions simple sigmoid function complex lstm network brnns phrase-based implemented help n-best lists systems complementary. translation quality significantly better using unidirectional rnns particular brnn system come close current best translation quality. threshold amount. address problem hybrid encoder decoder system attention mechanism used algorithm proposed successfully manages keep computational complexity part vocabulary. system proposed bi-directional gated recurrent unit used encoder ensure encoding process efficient time faster conventional brnns gated unit skips time epochs. decoder computes context vector ierarchy classes approach target words clustered hierarchically multiple classes target probability based class probability inter-class probability. rare words model translation-specific solution problem. approach small subset target vocabulary used compute normalization constant training making complexity constant respect target vocabulary. also update complexity brought easiest select part vocabulary select frequent target words would ruin point large vocabulary. model creates dictionary based source target word alignment. using dictionary best choices chosen scrutinized final output. also obtained bleu score english french translation behind current best. also able perform really efficiently even target vocabulary. peech synthesis process generating computer simulation human speech. used translate written information/text aural information. counterpart speech recognition. significant improvements performance system compared traditional rnns. interestingly found performance increased sentence input reverse order structural similarities languages english french system implemented ated recurrent units variation well known lstm approach neuron gated mechanisms enable remember encodings like lstms unlike lstm memory unit own. grus shown figure defined element wise multiplication operator output function hidden state function update gate reset gate candidate activation function gated recurrent unit sigmoid function. grus proven terms performance lstm networks really nothing clearly better other. systems interchangeably used similar resulting translations. methods machine translation described various approaches fail acknowledge problem target vocabulary. presence target vocabulary makes computationally infeasible number words target language known system exceeds rticulatory synthesis tries model human speech production system articulatory processes directly. however difficult method implement lack knowledge complex human articulation organs. oncatenative synthesis based concatenation segments recorded speech. produces natural sounding synthesized speech. however serious drawbacks like audible glitches output sometimes memory requirement large store large amount speech corpus statistical parametric synthesis technique. used easily implementing prosody various voice characteristics basis probabilities without large databases. system frequency spectrum fundamental frequency prosody speech modeled simultaneously hmms speech waveforms generated hmms basis maximum likelihood criterion. approach speech utterances used extract spectral excitation parameters model context dependent phone models turn concatenated used synthesize speech waveform corresponding text input .hts technology preferred overcomes drawbacks formant articulatory synthesis based statistical approach. process translation. occurs mainly variation speech patterns accents intonations etc. make impossible detect even right sentence alone errors present modules employed. errors caused lack accuracy recognition. result input sentence well formed. even without recognition errors speech translation cannot rely conventional grammar models structures differ written language nature speech. ecently shown promise voice translation. smts need make syntactic assumptions statistical nature system. target sentence guaranteed output system regardless nature input. ensures even syntactic structural accuracy translation least meaning retained translation. said that structure recognition followed translation synthesis lacks coherent working style independent approach modules. also models like n-best lists n-gram model words model etc. used along textual input sentence first pre-processed process called normalization things like special characters date time numbers abbreviations turned words. next list phonemes taken list database phonemes used language used prosody generation speech sounds target speech sentences phonemes chosen based spectral parameter intonation based excitation parameter duration parameter. system shown figure important qualities speech synthesis system naturalnessclosely output sounds like human speech intelligibilityease output understood. appropriate prosody model essential ensure naturalness intelligibility serves backbone system. prosody means characteristics obtained speech like accent intonation rhythm. parameters information duration pitch intensity. earlier rule-based approach used deriving prosody modelling concatenative synthesis. today statistical approaches popularly adopted. also cues provided prosody listener help interpret speech correctly. factors like speaking regional effect various phonological factors affect prosody. ormants resonance frequencies vocal tract. formant synthesis models frequencies speech signal. human speech samples instead creates artificial speech using parameters fundamental frequency voicing noise levels varied time create waveform artificial speech results robotic sounding speech. huge scope improvement extension. made translate multiple languages using input structures. made much efficient using various efficiency enhancing algorithms like rare words model many others. also improved make target speech sound exactly like source speaker enhance comfort using device. system also incorporated hearing enable service people deaf well. mukundan shreshta bhasha malayalam speech recognition using vol. pokhariya mathur sanskrit speech recognition using hidden markov model toolkit vol. rabiner b.-h. juang fundamentals speech recognition. upper saddle river prentice-hall inc. bhutada georgila sagae artstein traum practical evaluation speech recognizers virtual human dialogue systems nair sreenivas multi pattern dynamic time warping automatic speech recognition tencon ieee region conference graves mohamed hinton speech recognition deep recurrent neural networks icassp dines magimai doss study phoneme grapheme based context-dependent systems lect. notes comput. sci. vol. lncs efficient mfcc extraction method speech recognition circuits systems iscas proceedings. ieee international symposium pp.â€“. bou-ghazale hansen comparative study traditional newly proposed features recognition speech stress ieee trans. speech audio process. vol. proposed system composed three processesrecognition translation synthesis. fig. describes processes involved. section begins describing working hmm-based recognition supports decision choosing methodology surveying tools methods available perform section contains survey various translation methodologies focus adaptation lstm addressing target vocabulary problem. helps make choice gated memory networks several variations optimality output. section explains hmm-based synthesis process supports decision survey available methodologies thus making perfect methodology task. further section mentions three independent modules voice translation. also talks complementary language models used enhance performance. survey concludes stating requirements expectations model. scope extension services provided described section found based speech recognition hybrid based machine translation based gated units approaches based speech synthesis respective paradigms. therefore objective build continuous speakerindependent english tamil voice translation system using based speech recognition hybrid system least lstm based machine translation system python based speech comput. vol. chung gÃ¼lÃ§ehre bengio empirical evaluation gated recurrent neural networks sequence modeling corr vol. abs/. chung gulcehre bengio empirical evaluation gated recurrent neural networks sequence modeling zaremba addressing rare word problem neural machine translation arxiv jean memisevic bengio using large target vocabulary neural machine translation vol. modification prosody conversion expressive marathi text-to-speech synthesis signal processing integrated networks international conference yamagishi kobayashi nakano ogata isogai analysis speaker adaptation algorithms hmm-based speech synthesis constrained smaplr adaptation algorithm ieee trans. audio speech lang. process. vol. tabet boughazi speech synthesis techniques. survey int. work. syst. signal process. appl. wosspa conference computing novel intonation model improve quality tamil text-to-speech synthesis system yamagishi oura speech synthesis based hidden markov models proc. ieee vol. improved statistical alignment models proceedings annual meeting association computational linguistics machine translation. springer london koehn statistical machine translation. cambridge university press hiregoudar manjunath patil survey research summary neural networks koehn marcu statistical phrase-based translation proc. conf. north chapter assoc. comput. linguist. hum. lang. technol. naacl vol. june bengio properties neural machine translation encoder-decoder approaches pouget-abadie bahdanau merrienboer bengio overcoming curse sentence length neural machine translation using automatic segmentation neural networks arxiv prepr. arxiv. sutskever vinyals sequence sequence learning neural networks adv. neural inf. process. syst. hochreiter hochreiter schmidhuber schmidhuber long short-term memory. neural", "year": 2016}