{"title": "Active Learning for Online Recognition of Human Activities from  Streaming Videos", "tag": ["stat.ML", "cs.CV", "cs.LG"], "abstract": "Recognising human activities from streaming videos poses unique challenges to learning algorithms: predictive models need to be scalable, incrementally trainable, and must remain bounded in size even when the data stream is arbitrarily long. Furthermore, as parameter tuning is problematic in a streaming setting, suitable approaches should be parameterless, and make no assumptions on what class labels may occur in the stream. We present here an approach to the recognition of human actions from streaming data which meets all these requirements by: (1) incrementally learning a model which adaptively covers the feature space with simple local classifiers; (2) employing an active learning strategy to reduce annotation requests; (3) achieving promising accuracy within a fixed model size. Extensive experiments on standard benchmarks show that our approach is competitive with state-of-the-art non-incremental methods, and outperforms the existing active incremental baselines.", "text": "recognising human activities streaming videos poses unique challenges learning algorithms predictive models need scalable incrementally trainable must remain bounded size even data stream arbitrarily long. furthermore parameter tuning problematic streaming setting suitable approaches parameterless make assumptions class labels occur stream. present approach recognition human actions streaming data meets requirements incrementally learning model adaptively covers feature space simple local classiﬁers; employing active learning strategy reduce annotation requests; achieving promising accuracy within ﬁxed model size. extensive experiments standard benchmarks show approach competitive state-of-the-art non-incremental methods outperforms existing active incremental baselines. introduction pervasive presence cameras everyday lives created strong demand automatic methods able analyse real time video streams. especially challenging videos depicting human activities case footages surveillance cameras human computer human robot interactions many applications. mainstream approaches action activity recognition typically based ofﬂine training phase setting leads several critical issues dealing streaming videos continuously learn activities incoming data? dynamic nature streaming video setting implies time instant data made available system needs continuously learn implies reﬁning model known human activities adding previously unseen activities minimise required annotation effort? strictly related ability learn issue many video fragments annotated. newly observed activities might assume video fragments manually annotated analysing footage known actions fraction video fragments likely bring information worthy annotation effort. context system automatically select fragments informative asks help human annotator cases. optimise algorithm’s heuristics dynamically? system’s components features chosen algorithm parameters crucial impact ﬁnal performance framework. learning continuously incoming data difﬁcult chose components optimally even properly. contribution paper algorithm human activity recognition streaming videos which best knowledge ﬁrst address challenges listed principled manner. starting point recently proposed local algorithm classiﬁcation data streams incrementally trainable nonparametric providing theoretical guarantees performance. leverage result extend active learning setting. leads framework matches requirements listed above incrementally learns incoming data stream respect known classes classes computationally efﬁcient; active learning component evaluates informative content incoming data respect level conﬁdence system allows decide cost manual annotation worthwhile; lastly nonparametric nature approach combined intrinsic locality allows fully data-driven learning. video associated arbitrary number feature vectors feature space; incoming training vectors used sequentially cover feature space balls; ball associated estimate conditional class probabilities obtained collecting statistics around centre estimates used make predictions unlabeled samples; radius ball adjusted accordingly well ball predict samples around centre; ball centres incrementally adjusted actual data distribution; balls organized tree structure predictions computed time logarithmic number balls. call algorithm fast active incremental visual covering extensive experiments several publicly available databases show approach outperforms existing algorithms activity recognition streaming data. furthermore show combining fiver roin nonparametric models model structure speciﬁed priori determined data. implication models completely lack parameters number value parameters ﬂexible ﬁxed advance. bust temporal segmentation algorithm presented obtain system able deal straightforward manner realistic continuous active recognition scenario. related work within vast literature related action recognition references therein) research focusing streaming setting gained momentum recently important features required context incremental updates large amount data generally presented sequentially stream desirable algorithms update model adaptively rather re-train incremental learning activiscratch. ties algorithms able accomodate upcoming classes. bounded size model stream could large models keep bounded memory footprint allowing real-time prediction avoiding storage issues. implies ability discard useless information critical tracking drifting concepts data-driven parameter tuning problematic streaming settings systems parameters preferable. nonparametric true structure data progressively revealed examples stream observed nonparametric algorithms committed speciﬁc family decision surfaces preferable. active learning streaming setting system needs learn incoming video stream. however training labels provided human annotators invoked system conﬁdence prediction current label. bounded request rate querying human annotators expensive practical active learning system streaming settings impose bound query rate. table lists previous efforts human activity recognition involving incremental and/or active learning components which features closest alternatives approach. feature tree-based incremental recognition approach proposed tree free grow without bounds examples learner. requires store presented instances figure approach bag-of-words. classical pipeline vocabulary size clustering method classiﬁer parameters result tuning cross-validation. contrast approach completely data-driven local balls cover feature space codewords number size location dynamically depend distribution feature vectors associated labels. rather global classiﬁer entire feature space cover local classiﬁers associated updated local class statistics incrementally built. active learning component based suitable conﬁdence measure makes possible perform active temporal segmentation leading continuous activity recognition table identiﬁed open challenges previous work human action recognition streaming data. best knowledge fiver algorithm equipped features crucial dealing streaming data. legend method infeasible continuous recognition streaming videos number activities large time. human tracking-based incremental activity learning framework brought forward nevertheless requires annotation location build. methods adopt nonparametric incremental ball covering feature space strategy. fiver however brings table crucial features makes uniquely suitable dealing streaming data. first rely input parameters inconvenient tune streaming settings. second limits model size thus allowing tracking drifting concepts number allocated balls exceeds given budget fiver discards probability proportional error rate. third dynamically adjusts ball centres thus yielding compact models improving performance. resulting covering resembles visual dictionary learned incrementally directly usable predictions balls play role visual code words. finally active learning module deﬁnes interaction learning system labeler agent limiting number annotations requested. incremental active learning activity recognition tasks recently investigated approach uses ensemble linear classiﬁers incrementally created sequence mini-batch learning phases. conﬁdence measure outputs deﬁned individual classiﬁer output weighted training error. user-deﬁned thresholds control query rate labeled videos. non-conﬁdent instances close class boundary forwarded annotator others discarded. notably ensemble classiﬁers become large arbitrary number svms added batch phase. furthermore method requires model initialisation several parameters tuned validation set; requirement makes approach unsuitable truly streaming context. method initially learns features unsupervised manner using deep neural network. then multinomial logistic regression classiﬁer learned incrementally. posterior class probability output used select videos need supervised information. method presents several parameters candeal classes requires initialisation. authors recently presented extension methods attempts mine information scene’s context. however core learning system suffers drawbacks discussed above. moreover active modules used cannot section describes fiver algorithm heart system activity recognition streaming videos. sec. describes incremental visual covering approach based sec. shows keep memory footprint bounded technique introduced never applied activity recognition. sec. introduce mechanism performs active learning stream. fiver algorithm ﬁnally summarized sec. assume learner trained stream labeled videos video associated local descriptors belongs d-dimensional feature space. video label denotes activity possible classes change time. classiﬁer trained incrementally small adjustments current model every time labeled video presented learner. follows drop superscript reindex local features thus assuming learner sequence labeled local feature space adaptively covered balls depending complexity classiﬁcation problem. unlike balls always centered input samples adapt auto-adj version abacoc described uses k-means-like update step centre ball shifted towards average training samples correctly predicted local classiﬁer; practise balls track feature clusters visual codewords. following initialize radius ball distance closest ball. resulting setting parameterless. incremental updates. sequence observed training examples used build balls cover region feature space span. ball empirical distribution classes kept. ball centre keep updated number data points class time belong ball. counts used compute class probability estimates ball centre follows speciﬁcally training algorithm operates follows —see alg. initially balls empty. training example efﬁciently compute nearest ball centre belong closest ball i.e. distance greater ball’s radius ball centre initial radius equal created added label used initialise empirical class distribution ball belong nearest ball label used update error count ball. local classiﬁer centred makes mistake argmaxy∈y whenever happens radius initial value scaled polynomial function current error count prediction correct ball centre average correctly classiﬁed instances within ball allowing move towards majority class centroid. finally class probability estimates local classiﬁer centred updated notably a-priori knowledge full classes needed incremental learning approach labels soon ﬁrst appear stream. unlike feature space intrinsic dimension parameter empirically found signiﬁcantly affect performance. example embeds tree nearest neighbour queries updates performed time —see also measuring prediction conﬁdence. shows class estimates associated ball centres near current input instance considered reliable associated faraway centres corresponding region feature space already explored thus adapt kernel scale ball estimates based distance input examples updating varunstr conﬁdence threshold triggers requests labels prediction conﬁdence current threshold duration last observed video decreased fraction order query uncertain instances ﬁrst. otherwise threshold increased avoid interruptions learning process algorithm asking labels. explained parameter default value experimental section follow suggestion thus algorithm remains parameterless. fiver algorithm combines elements described above. namely fiver trains model video stream alg. controlling memory footprint described sec. concurrently alg. represents active learning module asks informative instances exceeding budget rate. prediction. prediction phase proceed similarly associated unlabelled video nearest neighbour efﬁciently located. then assuming local features i.i.d. label test video predicted using following maximum likelihood estimate order curb system’s memory footprint adopt simple approach proposed based deleting existing balls whenever given budget parameter label query rate attained. crucial real-time applications search used training prediction logarithmic number balls. probability deleting given ball proportional number mistakes made associated classiﬁer. namely budget reached ball added existing ball deleted probability pdisc number mistakes made ball helps addressing concept drift ball classiﬁers accumulate many mistakes removed make room accurate description data. introduce active learning system streaming settings bounds rate queries human annotators. technique propose inspired whenever segmented video presented model system makes prediction invokes active learning module order determine whether label requested. particular conﬁdence prediction certain threshold i.e. prediction ambiguous query issued annotator unless query rate budget violated. label requested model updated. instead selecting ﬁxed conﬁdence threshold query instances so-called variable uncertainty strategy queries least certain instances within time interval. algorithm variable uncertainty strategy input incoming video classiﬁer model threshold output labeling {true alse} initialize conﬁdence threshold store settings. batch setting dataset followed standard evaluation protocol compared fiver’s results competing incremental ofﬂine methods. streaming setting instead assessed different variants fiver using online accuracy sequential risk evaluation measure. measure captures average error made sequence incrementally learned models procedure ﬁrst predict test item current model result adjust model itself. notably streaming setting used experiments strict seed training sets mini-batch training cross-validation sets assume preliminary knowledge number classes. incremental methods rely much richer sources information allowed streaming setting could evaluate batch setting. order focus truly real-time prediction. particular virat sequences computed improved dense trajectories outstanding performance action recognition tasks. video three types features extracted namely histogram oriented gradient histogram optical flow motion boundary histogram code published inria website keeping default parameters except trajectory length frames number descriptor bins every frames obtained variable number active trajectories. accumulated trajectories descriptor concatenated descriptors obtaining collection vectors dimensions video. setting vector summary three local descriptors extracted video frame. virat initialised improved trajectory algorithm using bounding boxes released along dataset. datasets rely initialisation. available extracted two-level pyramidal features using bins. experiments euclidean distance used metric pilot tests using norm varying show improvement. ﬁrst experiments batch setting i.e. running fiver random permutation given training applying resulting classiﬁer test set. compared fiver against incremental algorithms follow incremental learning approach similar ours. batch algorithms unrestricted access training data learning opposed incremental methods access data sequentially. notably performance incremental algorithms typically poorer obtained using corresponding batch versions used -fold cross-validation averaged runs virat like incremental competitors described sec. skig msrgestured carried -fold cross-validation available training test sets used japvow auslan. shown table fiver among best methods datasets matter whether batch incremental setting considered. demonstrates algorithm combined state-ofpure streaming setting data arrive sequentially number activities depicted video known priori. conducted extensive experiments exploring following scenarios correspond different variants fiver full. least realistic case assume incoming instances manually annotated memory requirements incoming training sample incrementally update model. varun. case active learning component described alg. used including varunstr strategy described alg. decide instances require manual annotation. query rate calculated fraction videos label requested among observed upper bounded input budget parameter rnd. random strategy queries labels incoming instances probability equal query rate budget varunfix. realistic scenario also assume limited memory space store labeled training instances. apply method sec. limit number balls stored model. tests model size instances. notably methods large amount codewords generally necessary successfully predict video labels —see instance authors four different visual vocabularies words built random permutations videos dataset. algorithm predict label incoming video. prediction active learning system requested true label video along label model training example. competing algorithms range budget values plotted resulting online accuracy averaged different streams average query rate. importantly budget upper figure plots show active online performance full varun varunfix variants fiver different benchmarks. x-axis percentage label requested active learning module y-axis plots average online accuracy random permutations videos. coloured boxes percentage input data selected centres varun varunfix budget shown. plot represents evolution accuracy model size sequentially videos dataset. curve shows fraction input data selected centres curve online accuracy. notably fraction centers added diminish time accuracy improves. figure left evolution action class probabilities time test sequence containing three actions. middle pink line plots standard deviation class probabilities frame sequence —the cyan curve average standard deviation computed short interval frames. segmented activity conﬁdence measure computed —the predicted activity label discarded conﬁdence adaptive threshold right examples three time series associated medium high conﬁdence respectively. note fiver need validation parameters tune. important streaming context non-adaptive methods tune parameters initial validation stage perform suboptimally future data. plots fig. represent recorded performance various benchmarks presented scenarios. ﬁgure shows varun performs well full datasets even though queries around labels. example varun achieves online accuracy accessing less labels. method performs typically worse needs labels reach performance full. varunfix works almost well varun simplest datasets slightly worse complex ones; ﬁxed budget control discard information order keep model size ﬁxed. example varun input data around query rate whereas varunfix data –this shown green boxes fig. respectively ﬁnal percentage input examples used model centres. therefore varunfix extremely good compressing data allows efﬁcient computation cost little performance degradation. although sec. assumed incoming videos pre-segmented whenever feature vectors extracted frame-by-frame basis exploit activity scores computed short temporal window perform automated temporal segmentation. segmentation procedure based evolution class probabilities time transitions action instances associated local minima standard deviation class scores temporal window addition unlike done conﬁdence measure discard send supervision detected activity conﬁdence certain threshold discussed sec. crucial applications humanrobot interaction preferable robot perform action prediction conﬁdence lead safety issues communication errors. tested active approach temporal segmentation dataset manipulative actions used action recorded times different illumination settings backgrounds dhof descriptors extracted frame. excluded four gestures learning phase evaluated algorithm sequences representing pick place activities formed grasping moving releasing actions. system evaluated ability predict correct class known gesture performed request supervision unknown gesture observed. compare estimated class sequence ground truth employed levenshtein distance case action originally used s+d+i treated symbol sequence represents number substitutions number deletions number insertions test sequences achieved levenshtein distance error compared reported presented incremental active human activity recognition framework well suited streaming recognition problems especially amount data process large. approach exhibits number desirable features deals sets local descriptors extracted videos learns incremental fashion embeds active learning module capable learning classes limits memory usage predicts data real-time. addition method nonparametric require expensive validation sessions training parameters tuned. results demonstrate competitiveness terms accuracy respect traditional batch approaches well promising performance truly streaming scenario. future research explore conﬁdence measures automatically discover activity classes associating conﬁdence trajectories", "year": 2016}