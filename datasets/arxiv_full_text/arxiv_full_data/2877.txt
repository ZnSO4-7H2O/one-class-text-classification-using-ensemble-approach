{"title": "Deep Transfer Learning: A new deep learning glitch classification method  for advanced LIGO", "tag": ["gr-qc", "astro-ph.IM", "cs.CV", "cs.LG", "cs.NE"], "abstract": "The exquisite sensitivity of the advanced LIGO detectors has enabled the detection of multiple gravitational wave signals. The sophisticated design of these detectors mitigates the effect of most types of noise. However, advanced LIGO data streams are contaminated by numerous artifacts known as glitches: non-Gaussian noise transients with complex morphologies. Given their high rate of occurrence, glitches can lead to false coincident detections, obscure and even mimic gravitational wave signals. Therefore, successfully characterizing and removing glitches from advanced LIGO data is of utmost importance. Here, we present the first application of Deep Transfer Learning for glitch classification, showing that knowledge from deep learning algorithms trained for real-world object recognition can be transferred for classifying glitches in time-series based on their spectrogram images. Using the Gravity Spy dataset, containing hand-labeled, multi-duration spectrograms obtained from real LIGO data, we demonstrate that this method enables optimal use of very deep convolutional neural networks for classification given small training datasets, significantly reduces the time for training the networks, and achieves state-of-the-art accuracy above 98.8%, with perfect precision-recall on 8 out of 22 classes. Furthermore, new types of glitches can be classified accurately given few labeled examples with this technique. Once trained via transfer learning, we show that the convolutional neural networks can be truncated and used as excellent feature extractors for unsupervised clustering methods to identify new classes based on their morphology, without any labeled examples. Therefore, this provides a new framework for dynamic glitch classification for gravitational wave detectors, which are expected to encounter new types of noise as they undergo gradual improvements to attain design sensitivity.", "text": "daniel george hongyu shen huerta ncsa university illinois urbana-champaign urbana illinois department astronomy university illinois urbana-champaign urbana illinois department statistics university illinois urbana-champaign urbana illinois exquisite sensitivity advanced ligo detectors enabled detection multiple gravitational wave signals thereby establishing gravitational wave astrophysics active ﬁeld research. sophisticated design detectors mitigates eﬀect types noise. however advanced ligo data streams contaminated numerous artifacts known glitches non-gaussian noise transients complex morphologies. given high rate occurrence glitches lead false coincident detections obscure even mimic true gravitational wave signals. therefore successfully characterizing removing glitches advanced ligo data utmost importance. article present ﬁrst application deep transfer learning glitch classiﬁcation showing knowledge deep learning algorithms trained real-world object recognition transferred classifying glitches time-series based spectrogram images. using gravity dataset containing hand-labeled multi-duration spectrograms obtained real ligo data demonstrate method enables optimal deep convolutional neural networks classiﬁcation given small training datasets signiﬁcantly reduces time training networks achieves state-of-the-art accuracy perfect precision-recall classes. furthermore types glitches classiﬁed accurately given labeled examples technique. trained transfer learning show convolutional neural networks truncated used excellent feature extractors unsupervised clustering methods identify classes based morphology without labeled examples. therefore provides framework dynamic glitch classiﬁcation gravitational wave detectors expected encounter types noises undergo gradual improvements attain design sensitivity. keywords deep learning machine learning ligo gravitational waves gravity glitch classiﬁcation detector characterization transfer learning convolutional neural network feature extraction unsupervised clustering advanced laser interferometer gravitational wave observatory detectors largest sensitive interferometric detectors ever built. cutting-edge design fabrication aligo’s subsystems enable sensing changes aligo’s arm-length thousands times smaller diameter proton instrument already detected multiple gravitational wave signals produced mergers black holes aligo gradually attains design sensitivity transition current discovery mode astronomical observatory routinely detect sources providing insights astrophysical objects processes cannot observed means study glitches paramount importance characterize detectors. aligo realize full potential necessary ensure sensing capabilities hindered unwanted noises contaminate data. nontrivial task requiring intelligent algorithms given noise transients vary widely duration frequency range morphology spanning wide parameter space challenging model accurately furthermore since aligo detectors undergoing commissioning observing expect types glitches identiﬁed aligo attains design sensitivity accurately characterizing glitches essential eliminate noise transients obscure signals accidentally lead coincident false detections mimic signals high occurrence rate. complex time-evolving nature glitches makes ideal case study apply machine learning algorithms methods learn examples rather explicitly programmed. machine learning divided supervised unsupervised learning depending whether labeled structured data used training algorithms deep learning machine learning based deep artiﬁcial neural networks fastest growing ﬁelds artiﬁcial intelligence research today outperformed competing methods many areas machine learning applications e.g. image classiﬁcation face recognition natural language understanding translation speech recognition synthesis game-playing self-driving vehicles. therefore deep learning algorithms also expected excellent performance characterization gravitational wave detectors. article focus deep learning convolutional neural networks leading approach computer visions tasks using spectrograms computed time-series glitches inputs. recent eﬀorts front include gravity innovative interdisciplinary project provides infrastructure citizen scientists label datasets glitches aligo crowd-sourcing supervised classiﬁcation algorithms based dataset presented ﬁrst gravity article discussed ref. latter study deep multi-view models introduced enhance classiﬁcation accuracy using multiple-duration spectrograms glitch stitchedtogether form larger input image. algorithms employed deep learning models layers deep achieved overall accuracies close glitch classiﬁcation. however found glitch classes labeled samples diﬃcult classify level accuracy. subtle features larger classes. considering issues interested exploring deep cnns designed harder task classifying thousands categories real-world objects. however small size gravity dataset compared datasets used train state-of-the-art cnns real-world object recognition would lead poor results immediate overﬁtting i.e. memorization features training data without generalizing testing data. therefore previous attempts glitch classiﬁcation spectrograms used relatively shallow cnns designed trained ground. approach lower input image resolution used keep model size manageable signiﬁcant time eﬀort needed optimize architecture cnns train scratch. directly employ deep models well-established architectures optimized computer vision glitch classiﬁcation problem diﬀerent approach necessary. article present deep transfer learning method glitch classiﬁcation leverages complex structure deep abstraction pre-trained state-of-the-art cnns used object recognition ﬁne-tunes throughout layers accurately classify glitches re-training small dataset aligo spectrograms. show technique achieves state-of-the-art results glitch classiﬁcation gravity dataset attaining overall accuracy perfect precision-recall classes signiﬁcantly reducing training time minutes. also demonstrate features learned real-world images deep cnns directly transferable classiﬁcation spectrograms timeseries data detectors possibly also spectrograms general although datasets dissimilar. cnns originally designed classes objects imagenet. therefore algorithm easily extended classify hundreds classes glitches future especially since transfer learning approach requires labeled examples class. furthermore outline classes glitches automatically found grouped together occur using trained cnns feature extractors unsupervised semisupervised clustering algorithms. article organized follows. section describes methods datasets used applying transfer learning develop accurate cnns glitch classiﬁcation. section summarizes results. discuss immediate applications method hyperparameters refer several quantities manually chosen determine extension ﬁnding classes glitches unsupervised manner section conclusions brief description future strategies assist ongoing eﬀorts aligo data analysis provided section section provide succinct description neural networks transfer learning. thereafter present methods procedure applying transfer learning context glitch classiﬁcation. cnns currently best performing method image classiﬁcation object recognition variety image processing tasks serve excellent feature extractors allowing end-to-end learning features representations image data classiﬁcation thus eliminating need feature engineering i.e. hand-extraction features representations human experts. cnn-based algorithms recently achieved super-human results imagenet large scale visual recognition competition outperforming methods since state-of-the-art cnns real-world object recognition extremely powerful thus training ground small dataset would lead poor performance. capacity model i.e. degrees freedom model would much larger necessary small data distribution thus resulting known overﬁtting) algorithm memorizes training samples without generalizing test set. symptoms overﬁtting alleviated using regularization techniques dropout limiting number training iterations however practice extremely large labeled dataset required train randomly initialized deep cnns optimal performance. gravity crowd-sourcing project mobilizes citizen scientists hand-label spectrograms obtained aligo time-series data. rationale approach humans capable distinguishing diﬀerent classes noise spectrograms shown examples indicates generic pattern recognizers developed humans real-world object recognition also useful distinguishing spectrograms glitches. therefore motivated apply similar approach ﬁrst trained large database labeled real-world objects knowledge subsequently transferred re-training dataset spectrograms. machine learning literature idea referred transfer learning describe following section. transfer learning essential ingredient artiﬁcial intelligence knowledge learned domain task transferred another domain diﬀerent task context deep learning transfer learning commonly implemented pre-training deep neural network e.g. large labeled dataset followed ﬁne-tuning diﬀerent dataset interest usually smaller. approach successfully applied many areas computer vision well known initial layers always learn extract simple generic features applicable types images whereas ﬁnal layers represent highly abstract data-speciﬁc features therefore using model optimally-trained large dataset ﬁne-tuning diﬀerent dataset expected result higher accuracy faster training process compared training cnns scratch shared features present initial layers. demonstrate power transfer learning classifying glitches compare performance popular models object recognition namely inception version resnet leading entries recent ilsvrc competitions. cnns optimally trained large dataset images i.e. imagenet contains million labeled images real-world objects belonging categories course weeks using multiple gpus research groups. obtained open-source weights models used initialize cnns ﬁne-tuning model dataset glitches. show transfer learning allows apply powerful cnns classifying glitches using small training dataset spectrograms obtain signiﬁcantly higher accuracies reduce training time several orders magnitude eliminate need optimizing hyper-parameters. furthermore show information multiple duration spectrograms eﬃciently encoded single image diﬀerent color channels enhance information provided models. gravity dataset ﬁrst observing ligo contains labeled spectrogram samples classes glitches shown figure within dataset sample contains images recorded durations images hand-labeled citizen scientists participating gravity project accuracy labeling greatly enhanced cross-validation techniques within gravity infrastructure. figure classes glitches gravity dataset ﬁrst observing aligo. glitch class omitted ﬁgure. glitch sample spectrograms durations available. objective predict classes given images. april slightly modiﬁed since previous publications additional classes namely lines ripples extra elements violin mode class. randomly split dataset containing elements parts approximately samples class training class testing set. separate validation since engage kind hyperparameter optimization could overﬁtting test set. allowed larger fraction data training testing. directly used hyperparameters pre-trained models. cross-veriﬁcation performance inception models trained independently rest models using diﬀerent deep learning software framework diﬀerent randomized test-train splits data. training resnet used spectrogram images duration since contained suﬃcient information resolve long short duration glitches. since dataset small image augmentation used artiﬁcially enhance size dataset input image subtracted mean training samples randomly shifted pixels horizontal vertical directions randomly color channels present maximum information cnns. duration spectrograms converted gray-scale merged produce images channel encoding diﬀerent durations. examples encoded images shown figure previous work used concatenated parallel-views multiple-duration spectrograms inputs specially designed cnns trained scratch encoding method advantage allowing direct pre-trained architectures designed imagenet classiﬁcation multiple-duration spectrograms. ﬁnal fully-connected layer model replaced another fullyconnected layer neurons corresponding glitch class. reduce overﬁtting added several dropout layers beginning network right output layers. apart this also added additional layer ﬁrst trainable convolutional layer resnet. details network structures listed table appendix softmax function used ﬁnal layer model provide probabilities class outputs. training model utilized standard cross entropy loss function good performance classiﬁcation problems combination softmax layer ﬁne-tuned across layers since dataset glitches diﬀerent objects imagenet data. model trained epochs usual iterative procedure check-pointed epoch. best performing check-points chosen subsequently. used standard adagrad adam optimizers learning algorithm training. speciﬁcally used adagrad resnet initial learning rate adam method parameters inception models. inception models implemented wolfram language internally uses open-source mxnet framework training. resnet models implemented trained independently diﬀerent randomized train-test split using tensorflow keras naive implementation logistic regression classiﬁer features extracted spectrograms using inception models pre-trained imagenet produced accuracy without ﬁne-tuning layers. strongly indicated features learned real-world object recognition also directly useful classiﬁcation spectrograms ligo noise transients thus oﬀered incentive train every layer. cnns implemented paper inceptionv inceptionv achieved accuracy fewer epochs training achieved accuracy within epochs training. however resnet took much longer converge. compare results cnns trained transfer learning method models trained scratch table found models consistently achieved accuracy many epochs thus indicating performance robust regardless stopping criteria therefore model overﬁtting test set. precision recall obtained model every class reported appendix inceptionv achieved perfect precision recall classes lines ripples compressor chirp helix paired doves power line scratchy. resnet achieved perfect precision recall classes lines ripples extremely loud helix paired doves scratchy violin mode. resnet inceptionv achieved highest accuracy test despite trained independently diﬀerent methods diﬀerent splits data scans encoded scans respectively. also obtained accuracy considering top- predictions implies given input true class narrowed within classes conﬁdence. particularly useful since true class glitch often ambiguous even human experts. shown confusion matrices resnet inceptionv figure figure respectively. confusion matrices remaining models included appendix accuracies models previously published models trained scratch dataset reported table note models consistently under-performed trained random initializations i.e. without applying transfer learning. therefore evident networks trained transfer learning approach achieve better results models trained ground dataset. results presented table indicate transfer learning state-of-the-art image classiﬁcation cnns achieves optimal performance signiﬁcantly reducing training time less hour eliminating diﬃculties associated hyperparameter tuning. employing models deep complex structures feasible approach small datasets since larger training used pre-training enables learning good feature extractors initial layers thus prevents overﬁtting learning good features. addition cnns able learn high level features speciﬁc small dataset glitches ﬁne-tuning process throughout layers improved classiﬁcation results. figure confusion matrix resnet ﬁne-tuning dataset glitches. accuracy note resnet current state-of-the-art model variety image processing tasks including object recognition. models image classiﬁcation transfer learning problem. furthermore demonstrated transfer learning always provides signiﬁcant improvements traditional approach used classifying spectrograms allows powerful cnns small datasets even dissimilar compared original data used pre-training. trained inference carried milliseconds using allowing real-time classiﬁcation glitches aligo. figure confusion matrix inceptionv. accuracy also seen diﬀerent errors made compared resnet. note chirp glitch class paired doves class identiﬁed perfect precision recall. table lists top- top- accuracies diﬀerent cnns testing set. top- accuracy classes also shown comparison previous publications. re-trained layer merged-view model described publications scratch train-test dataset fair comparison since gravity dataset recently updated. note inception resnet models capable narrowing input within classes accuracy. recall paired doves test even though smallest class elements training set. previous methods trained ground achieved sub-optimal results class analysis strongly suggests high accuracy transfer learning larger dataset since similar patterns could learned pre-trained imagenet data. therefore shown that although number samples vary greatly diﬀerent classes could obtain high precision recall even smallest classes without employing class balancing techniques training. best performing models imagenet currently based ensembles/committees diﬀerent cnns. since confusion matrices indicate diﬀerent strengths weaknesses many classes expect using ensemble diﬀerent models would boost accuracy glitch classiﬁcation. furthermore gravity dataset enlarged future hand-labeled glitches cnns re-trained largest available dataset improve accuracy. however upper bound error-rate humans providing labels. seen figure misclassiﬁcation made cnns either incorrect labeling superposition diﬀerent classes glitches inputs whose true class remain ambiguous. since method trained quickly used eﬃciently correct mislabeled elements original dataset training large number randomized train-test splits searching commonly mislabeled elements among test sets. cnns developed study immediately used ligo pipelines classifying known categories glitches high accuracy real-time. well-known ability deep neural networks generalize implies classiﬁcations would resilient changes background noise. therefore expect excellent performance achieved current data would translate future observing runs. nonetheless accuracy improved periodically re-training larger datasets containing available labeled examples glitches time. applying transfer learning i.e. ﬁne-tuning cnns small dataset glitches cnns also used good feature extractors ﬁnding categories glitches unlabeled data unsupervised semi-supervised manner. method combines supervised learning transfer learning unsupervised learning used identify many categories noise transients estimate times types glitches similar morphologies start occurring. also used correct mislabeled glitches original dataset used training/testing searching anomalies feature-space. instance consider inceptionv model removing ﬁnal softmax fullyconnected layer near output produces maps input image dimensional vector. high-dimensional space glitches similar morphology clustered together. anomalies mis-labeled examples appear isolated clusters. visualized reducing dimensions feature space using suitable dimension reduction algorithm shown figure figure classiﬁed none model mapped vectors using truncated feature extractors. then classes glitches identiﬁed applying standard unsupervised clustering algorithms automated clustering also used accelerate human labeling glitches semi-supervised manner presenting batches similar glitches citizen scientist. believe reason clustering technique works well used deep cnns capable extracting representing large number highly abstract features input images. therefore transfer learning enables cnns excellent feature extractors thus eﬀectively enabling unsupervised learning techniques ﬁnding classes glitches. performance diﬀerent clustering methods investigated detail subsequent study. article part program aims spread deep learning many related areas multimessenger astrophysics ranging detection characterization sources detector characterization. ﬁrst application deep transfer learning context aligo. using method developed state-of-the-art dnns aligo glitch classiﬁcation using gravity dataset. shown combining pre-trained weights state-ofthe-art cnns ﬁne-tuning across layers increase accuracy compared neural networks trained scratch using gravity dataset. furthermore shown training time signiﬁcantly reduced approach compared traditional methods eﬀort required design models optimize hyper-parameters eliminated. note even though gravity dataset spectrograms similar real-world objects found imagenet database demonstrated transfer learning approach works extremely well. therefore expect method useful time-series classiﬁcation general problem represented form images. furthermore developed novel method encode diﬀerent duration spectrograms diﬀerent color channels single image renders excellent results allows direct pre-trained state-of-the-art models. algorithms introduced article used classify time-series data gravity project well data future aligo observing runs data international partners virgo kagra ligo-india come online next years. would useful improving data quality detectors generating vetoes search pipelines. transfer learning method allows deep cnns well-known architectures capable extracting complex abstract features spectrogram images. classes glitches also found unsupervised manner labeled rapidly semi-supervised manner method truncating cnns using feature extractors clustering algorithms. employing transfer learning method glitch classiﬁcation create larger dataset labeled transients real aligo data corresponding timeseries fetched times produce labeled time-series inputs. dataset added training process deep filtering pipeline introduced unify detection classiﬁcation parameter estimation directly timeseries data streams detectors real-time. fully-trained cnns developed article made available community glitch classiﬁcation detector characterization pipelines. grateful nvidia supporting research hardware donations wolfram research oﬀering several mathematica licenses vlad kindratenko providing dedicated access machine innovative systems ncsa. acknowledge gravity project citizen scientists participated creating dataset used. thank gabrielle allen scott coughlin vicky kalogera joshua smith staats sara bahaadini michael zevin productive interactions. thank staats laura nuttall gravity team reviewing article providing feedback. also acknowledge ligo ligo scientiﬁc collaboration abbott arxiv e-prints goodfellow bengio courville deep learning lecun bengio hinton nature issn zevin coughlin bahaadini besler rohani allen cabero crowston katsaggelos larson lintott littenberg lundgren oesterlund smith trouille kalogera classical quantum gravity krizhevsky sutskever hinton imagenet classiﬁcation deep convolutional neural networks advances neural information processing systems pereira burges bottou weinberger yosinski clune bengio lipson transferable features deep neural networks? proceedings international conference neural information processing systems nips’ http//dl.acm.org/ citation.cfm?id=. kaiming xiangyu shaoqing jian arxiv e-prints karen andrew arxiv e-prints deng dong socher fei-fei cvrp srivastava hinton krizhevsky sutskever salakhutdinov journal machine john elad yoram journal machine learning research kingma corr abs/. http//arxiv.org/abs/. wolfram language system documentation center https//reference.wolfram.com/ abadi barham chen chen davis dean devin ghemawat irving isard kudlur levenberg monga moore murray steiner tucker vasudevan warden wicke zheng tensorﬂow system largescale machine learning proceedings usenix conference operating systems design implementation osdi’ isbn ---- http//dl.acm.org/citation.cfm?id=. chollet maaten hinton journal machine learning research george huerta arxiv e-prints acernese classical quantum gravity hirose sekiguchi kumar takahashi kagra collaboration classical section present supplementary information summarizing networks experimented classify spectrograms gravity dataset. figure figure present confusion matrices inceptionv models respectively. table presents recall precision deep transfer learning algorithm glitch classiﬁcation. results clearly exhibit power method especially rare classes labeled examples therefore transfer learning method oﬀers promising framework future development glitch classiﬁcation detectors. table lists recall precision diﬀerent models. last column compares results merged-view model described training testing scratch train-test split used models updated gravity dataset. figure misclassiﬁed elements test inceptionv model. spectrograms shown. seen cnns always outputs reasonable classiﬁcations many mistakes incorrect labels test glitches whose classes appear ambiguous even humans. therefore achieved close ideal accuracy bayes error rate. suggests mislabeled examples found corrected trying diﬀerent randomized test-train splits dataset inspecting mistakes made test set. resnet architectures shown. resnet model employs residual connections modules. ﬁnal layers networks replaced fully connected layer neurons followed softmax function. figure architecture inceptionv inceptionv models. parallel structure inception modules signiﬁcantly improves evaluation speed reduces total model size compared models. used inceptionv model currently imageidentify project pre-trained superset imagenet dataset publicly available figure random samples multi-duration spectrograms encoded single images. color channels correspond durations respectively. encoding used train test inception models. figure presents samples gravity glitches used train test inception models. figure presents gallery samples imagenet. database used ilsvrc competitions benchmark computer vision algorithms used pre-train models utilized glitch classiﬁcation article. figure random samples images imagenet database common benchmark used test computer vision algorithms. contains images real-world objects belonging diﬀerent classes. examples classes include hamster taxi stingray tricycle volleyball lamp mushroom restaurant water bottle hook ladle kite speedboat etc. dataset used pre-train models used article glitch classiﬁcation. figure location diﬀerent classes glitches test applying feature extractor. t-sne algorithm used reduce dimension vector vector visualization. note type glitch forms cluster relative positions depend morphology. outliers inspected closely verify whether labels accurate whether belong class. figure feature-space projected using t-sne. class called reverse chirp chirps reﬂected vertical axis added. seen feature-extractor maps class unique cluster. furthermore cluster located near chirp class none class indicates relative positions glitches feature-space meaningful depends morphology. figure unsupervised clustering glitches belonging none known classes. note glitches similar morphology located near other. trained cnns used feature extractors images -dimensional vectorspace turn mapped space shown using t-sne dimension reduction method. feature-extractor used group classes glitches morphology time occurrence future. figure clusters glitches none class automatically found unsupervised spectral clustering algorithm applied featurespace shown previous figure. represents cluster. diﬀerent clustering algorithms used parameters tuned vary sensitivity clustering enforce stricter similarity criteria.", "year": 2017}