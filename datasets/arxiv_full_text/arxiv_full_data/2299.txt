{"title": "Ordered Preference Elicitation Strategies for Supporting Multi-Objective  Decision Making", "tag": ["cs.LG", "cs.AI", "stat.ML"], "abstract": "In multi-objective decision planning and learning, much attention is paid to producing optimal solution sets that contain an optimal policy for every possible user preference profile. We argue that the step that follows, i.e, determining which policy to execute by maximising the user's intrinsic utility function over this (possibly infinite) set, is under-studied. This paper aims to fill this gap. We build on previous work on Gaussian processes and pairwise comparisons for preference modelling, extend it to the multi-objective decision support scenario, and propose new ordered preference elicitation strategies based on ranking and clustering. Our main contribution is an in-depth evaluation of these strategies using computer and human-based experiments. We show that our proposed elicitation strategies outperform the currently used pairwise methods, and found that users prefer ranking most. Our experiments further show that utilising monotonicity information in GPs by using a linear prior mean at the start and virtual comparisons to the nadir and ideal points, increases performance. We demonstrate our decision support framework in a real-world study on traffic regulation, conducted with the city of Amsterdam.", "text": "figure decision support scenario. planning learning phase coverage multi-objective decision problem produced. selection phase user selects policy maximises utility interacting algorithm preference elicitation. finally selected policy executed. paper focus selection phase. decision making option several attributes influence user’s preferences. subfield multiobjective decision theoretic planning learning studies complex multi-objective decision problems. studies typically focus producing so-called coverage sets i.e. contains optimal policy every possible user preference profile respect different objectives. commonly assumed user preferences modelled utility function monotonically increasing objectives leading possibly infinitely sized pareto front coverage set. however selection problem follows i.e. selecting policy user likes best typically left open. since direct access user’s intrinsic utility function step trivial. argue accordance utilitybased approach multi-objective decision making selection phase integral part solving multi-objective decision problem suboptimally detrimental user utility. therefore believe algorithms selection phase seen essential part multiobjective decision-theoretic planning learning. learn specific user’s utility respect objectives find single optimal policy terms user utility executed. paper propose analyse methods main considerations elicit user’s preferences model multi-objective setting. find policy user likes best take active learning approach alternate updating model user’s utility querying user feedback using relative feedback queries. relative comparisons natural humans express preferences model user’s preferences utilise gaussian processes abstract multi-objective decision planning learning much attention paid producing optimal solution sets contain optimal policy every possible user preference profile. argue step follows determining policy execute maximising user’s intrinsic utility function under-studied. paper aims fill gap. build previous work gaussian processes pairwise comparisons preference modelling extend multi-objective decision support scenario propose ordered preference elicitation strategies based ranking clustering. main contribution in-depth evaluation strategies using computer human-based experiments. show proposed elicitation strategies outperform currently used pairwise methods found users prefer ranking most. experiments show utilising monotonicity information using linear prior mean start virtual comparisons nadir ideal points increases performance. demonstrate decision support framework real-world study traffic regulation conducted city amsterdam. introduction understanding humans want integral part artificial intelligence central importance using assists humans making decisions. consider tasks like picking film watch deciding route road-trip europe amount options choose often large human iterate through making search best option possibly cumbersome process. case support accelerate user’s decision-making. system needs learn user’s preferences efficiently asking right questions guide search generalising options. proc. international conference autonomous agents multiagent systems dastani sukthankar andre koenig july stockholm sweden international foundation autonomous agents multiagent systems rights reserved. https//doi.org/doi since bayesian methods like work well little data build method uses novel likelihood pairwise comparisons inspired active learning setting brochu iterate asking user feedback pairwise comparison updating information selecting next query paper extend approach query types like asking user rank cluster items main contribution in-depth evaluation synthetic experiments user study results show ranking queries lead better utility models preferred humans pairwise clustering approach. propose utilise monotonicity assumption multi-objective decision problems using linear prior mean virtual comparisons show experimentally indeed improves performance also found using linear prior mean leads large performance increase beginning essential turn prior initial data collected restrict much. finally demonstrate implementation method real-world example; project collaboration municipality traffic regulations amsterdam background section introduce framework multi-objective decision making user utilities formalised within introduce gaussian processes pairwise comparative judgements active learning. multi-objective decision making much multi-objective decision making takes place context decision support scenario applies multiobjective decision-theoretic planning learning also multi-objective optimisation with e.g. evolutionary algorithms ultimate goal scenario maximise user utility executing policy specific user likes best. however users typically cannot express preferences directly thus priori scalarisation objectives possible. case need approach delivers coverage possibly optimal solutions. refer planning/learning phase. selection phase follows finding policy maximises specific user’s utility focus paper. call single solution multi-objective decision problem policy denote value number objectives possible policies. context multi-objective markov decision problems example policy’s value expected cumulative reward objective. following roijers assume user intrinsic utility function higher value higher user’s preference policy. since objectives desirable monotonically increasing objectives. given monotonicity property solution pareto coverage i.e. pareto front contains allowed policy value policy greater equal value objectives consequently contains optimal solution user preference profile infinite policies contain infinitely many policies. however result vamplew typically possible construct mixing policies much smaller solution alleviating necessity compute explicitly. precisely convex coverage contains non-dominated policies whose values satisfy non-negative weights insight important typically much smaller pcs. e.g. momdps finite number states actions finite deterministic stationary policies. momdps piecewise linear surface comprised mixture policies policies constituent policies. mixture policy stochastic mixture policies value policy linear combination adjacent policies decision support scenario want maximise utility function restricted mixtures policy values input. need elicit preference information user. preference elicitation distinguish ways querying user preferences scoring items comparisons items expressing preferences absolute terms difficult humans prone errors numbers unnatural express preferences values might change time users mood depend something seemingly trivial like weather. relative feedback easier humans express typically consistent time therefore focus relative feedback. user compares policies assume true utility values user cannot directly access uses indirectly compare items. since personal evaluations users likely always accurate vary depending different factors model outcome comparison based noisy utility values gaussian noise zero mean unknown variance observations user thus stem comparison true utility values contaminated noise denoted want relative preferences find policy whose value maximises user’s utility function next section introduce approximation method suitable task. gaussian processes pairwise feedback objective asking feedback bother user many queries otherwise user might quit using system goals achieved. therefore need methods work well little data take uncertainty user’s preferences account. bayesian optimisation techniques like gaussian processes particularly suited tasks little available data gaussian processes general introduction) used approximate functions seen infinitedimensional extension multivariate gaussian distribution. approximates function captures uncertainties assigning point domain normal distribution mean value reflecting expected value variance reflecting uncertainty function value point. gaussian process fully specified mean function kernel querying user information initialised defining prior mean function kernel function. common choices zero function prior mean squared exponential kernel also here; alternative prior mean function discussed section prior belief utility function updated light data likelihood using bayes’ rule posterior updated belief user’s utility current approximation utility function. data case given terms pairwise comparisons ghahramani introduce probit likelihood noisy pairwise comparisons. given likelihood gaussian process prior posterior analytically tractable approximated. following laplace approximation. approximate user’s utility take active learning approach meaning alternate updating querying user information next section describe select next question user. active learning ghahramani show defined pairwise likelihood work well fixed datasets learning done off-line influence information collected user. instead interested active learning setting queries information based current information belief user’s preferences. functions select next item given gaussian process called acquisition functions. typically balance exploration exploitation following expected improvement acquisition function step select item user queried next. optimising user utility multi-objective decision support restrict domain acquisition function utilise monotonicity information user’s preferences input domain input domain user’s utility function well approximate d-dimensional hypercube defined minimum maximum possible values objectives. multi-objective planning learning phase coverage produced contains optimal solution every possible user. typically infinite subset d-dimensional hypercube since trade-offs objectives constrain solution set. user’s utility function local maxima. since maximise user’s utility solution restrict acquisition function set. present achievable solutions user. otherwise could bias user give rise unrealistic expectations might waste time asking user items feasible. utilising monotonicity information multi-objective decision support scenario assume user’s utility function monotonically increasing objective. information used approximation. prior mean. information function approximated known priori commonly used prior mean zero function however monotonic utility function want better heuristic prior. propose linear prior mean function equal weights objectives heuristic. equal weights implies user would care equally objectives linearity means user’s utility increases linearly value objective. note linear prior mean function imply model linear functions; shape functions determined kernel. section show adding heuristic prior highly useful many queries posed user hinder data becomes available. hence propose remove heuristic initial number queries. virtual comparisons. optimise user’s utility achievable possibly optimal solutions i.e. pcs. around however virtual comparisons include items outside enforce monotonicity. propose compare item selected acquisition function minimal maximal item vectors contain minimal value objective independent objective values. hypothesise extra information enforces monotonicity lead better approximations. figure possible outcomes different query types items utilities arrows represent preference information expressed user different elicitation strategies lead different orderings full ranking returns total ordering query types typically lead partial orderings. order items swapped queries. handle apparent inconsistencies keeping contradicting pairwise comparisons dataset; experiments showed significant difference removing contradictory samples following sections evaluate different query types study effect utilising monotonicity information. first simulating user behaving according given utility function order access true utility values. present results user study humans answer queries different types multi-objective decision problem finally combine findings realworld application collaboration policy makers traffic regulation city amsterdam experiments optimisation quality section evaluate proposed strategies terms well optimise user’s utility i.e. close fast maximal achievable utility. need access ground truth utility function user. therefore virtual user whose utility function know assess utilising monotonicity information section different query types section following first describe experimental set-up defined virtual user’s utility function simulate decision making process. preference elicitation strategies section introduces query types study paper; pairwise comparisons ranking/clustering strategies. describe query types following show orderings result figure pairwise comparisons. brochu active learning approach pairwise comparisons step user compares items; winner compared item next query. thus queries user made comparisons used update typically leads partial ordering items extreme cases total ordering degenerate case first item better items subsequent queries. ranking. here user asked make full ranking inputs leading total ordering items user initially starts ranking items round item added sorted ranking. i.e. queries user evaluated items ordered sorted list. pairs successive items update note ranking approach leads number comparisons pairwise comparisons full ordering. words data quantity information quality higher ranking compared pairwise comparisons. clustering. instead requesting full ranking user pick best item items clusters decreasing utility items whose utility values close cluster. number clusters either pre-determined defined dynamically user. clusters user’s preferences would expressed form xbest single best item disjunct sets whose union contains remaining items. means items cluster better ones data gaussian process pairwise comparison likelihood comparing xbest every item every item every item giving |c|+|c|∗|c| pairwise comparisons. general number clusters least comparisons. top-rank. query type above user asked rank items remaining items cluster. gives pairwise comparisons qualitatively pairwise full ranking approach. test approach since information upper region user’s utility function might help find maximum faster. experiment starts asking user compare items independent query types. subsequent step item selected using acquisition function question asked user depend query type. ranking/clustering queries allow user re-order items time step merge items cluster. history previous queries kept dataset used update noise utility values since users allowed re-arrange items happen relative figure examples stacked sigmoids polynomials virtual user utility functions right used show slice utility function mapping first objective solution figure utilising monotonicity performance using different prior functions reference points switch linear zero prior queries stop adding virtual comparisons queries well. results averaged query types runs each. used objectives utility noise results utilising monotonicity within multi-decision making framework described section assume user’s utility function monotonic i.e. objectives desirable. section proposed strategies utilising information adding linear prior adding virtual comparison points. compare strategies looking reached utility query step. here interested fast good user utility reached final utility value. figure shows results adding information prior mean function adding virtual comparisons compared using prior information adding monotonicity information always gives performance boost. using linear prior mean function beginning helps acquisition function focus promising regions jump-starts reached utility. however using linear prior mean throughout queries performance point drops lower using zero prior mean start. hold reference points. linear prior mean function heuristic might hinder search process later virtual comparisons enforce monotonicity. plot right shows combination linear prior beginning virtual comparisons throughout queries works best. experiments consists number queries asked query updated item chosen acquisition function. first randomly choose utility functions well values randomly generate solution sets hold possibly optimal policies want maximise user utility. input space always normalise functions individually allow easy comparisons results. figure shows examples stacked sigmoids polynomials general utility functions. given utility function simulate users expressing preferences items. start selecting starting items using acquisition function alternate evaluating query updating selecting item acquisition function again. queries evaluated virtual utility function described following different query types. pairwise step winner previous query item xnew compared. evaluate utility function obtain noise εnew drawn i.i.d. normal distribution noisy utility values compared result added dataset winner comparison used next query ranking/clustering step items previous queries item xnew evaluate utility function obtain noise εnew drawn i.i.d. normal distribution produce ranking clustering based noisy utility values. note query draw noise values items. clustering simulate clustering k-means general agreement literature humans perform clustering especially since depends heavily task prior knowledge. like shape utility function itself using k-means therefore somewhat arbitrary choice based intuition authors. results query types section compare proposed elicitation strategies pairwise approach terms approximating utility function attaining high utility. figure shows time step utility currently highest rated item objectives different noise levels pairwise approach outperformed methods especially high noise utility function. full ranking generally performs best difference clustering top-rank significant noise utility function. plot number queries reached utility method time step datapoints available difference number comparisons datapoints lowest pairwise approach. note though better performance cannot solely higher number available comparisons ranking clustering methods reach higher utility faster also converge higher utility compared pairwise approach. believe superior performance ranking clustering queries stems better approximation utility function. interested finding maximum necessarily closely approximating user’s utility function whole better approximation helps acquisition function make informed decision item select next. figure show approximation different utility functions pairwise queries ranking queries. methods close maximum ranking queries give better overall approximation. pairwise method also found item near-optimal utility since know anything relationship remaining datapoints approximation quality areas poor variance high. might argue necessary finding maximum element since interested areas utility believe results give strong indication better overall approximation quality help solve optimisation problem faster better. figure utility graph shows reached utility query. used objectives different noise levels results averaged runs. shows performance without using prior information bottom shows performance using linear prior mean function beginning reference points throughout. pairwise comparisons outperformed query methods regarding convergence speed final reached utility. figure approximation graph shows approximation true utility function objectives plotting first objective utility pcs. show different random seeds pairwise ranking query queries. ranking query able approximate much better. different types orderings available given datapoints. hypothesise better approximation enables acquisition function suggest better points query explains superior performance ranking queries. experiments user study previous section used virtual user utility function defined ourselves found ranking queries lead best results. section investigate real users experience interact system. description user study assess query type humans prefer well work reality built web-interface multi-objective decision making including three query types pairwise ranking clustering chose test top-rank method since ranking clustering think might become relevant larger studies many items compared generated offers attributes. defined mathematical utility function offers selected three pairs jobs utility present initial query. used zero prior used acquisition function described section select offer step. user participated experiment asked answer queries offers query types according persona description described utility function jobs simple words. participants given minute answer queries type. user asked complete survey experience. collected responses user study amazon mechanical turk. running experiments randomised order user took different experiments well pair starting jobs. results participating experiment asked users perceived effort query whether think algorithm understood preferences query type prefer decision-making tool. results shown figures also logged user’s responses queries show average reached utility step figure results show majority participants found effort acceptable across queries ranking queries rated high effort slightly often. users felt algorithm understood preferences suggested better jobs time felt often pairwise query. despite results pairwise comparisons query type users prefer decision-making tool surprise ranking query rated often least often. surprised clustering consistently ranked lowest users seem like terms reached utility query types show similar performance. figure also shows average number queries answered minute experiment type users able answer average pairwise queries clustering/ranking. conclusion users prefer ranking query type oneminute experiment although requires slightly effort users felt less often understood method query types. hypothesise ranking gives control process items visually compared previous items. good intuition clustering unpopular. expected easiest popular method since jobs sorted three categories figure effort query type participant able choose options ’effort okay’ ’too much effort’. users typically found effort acceptable query types. figure utility graph shows reached utility time according utility function defined described participants words. query types similar performance. also average number answered queries pairwise setting clustering/ranking scenario within given minute. experiments application order test decision making tool real-world application worked project together municipality amsterdam. part daily work traffic control city complex real-world task many objectives. critical intersections city municipality utilises specialised simulation software test policies traffic regulation. however since many free parameters setting needs tested several times account variance simulation near impossible humans manually test settings. thus hypothesise policy makers benefit decision-making support system like ours. reflect delay duration queue length different directions different traffic participants. first removed paretodominated results leaving parameter settings possibly optimal value. experts municipality used web-interface tool find best outcome according intrinsic utilities. case access true utility values users. experiments therefore investigate whether experts think system useful used real-world problem preference elicitation strategy prefer. used pairwise ranking queries experiment since clustering performed poorly user study participant started query types switched other. instead time limit participants choice either requesting item finishing experiment saying satisfied current outcome. table shows results experiment. experts answered twice many queries pairwise comparisons ranking satisfied outcome spent time first experiment second regardless query type. experts preferred ranking query types. found item ranking query different ones pairwise comparison. received positive feedback experts found multi-objective decision support system useful tool. preferred ranking queries since makes easier compare items. related work paper model utility function using important advantages explicitly models uncertainty function enabling active learning contrast e.g. using pomdps predecessing methods handle continuum items. main framework relative preferences gaussian processes taken work ghahramani propose likelihood pairwise comparisons used preference learning. experiments done fixed datasets i.e. off-line instead active learning. extension relative preference active learning brochu asks user compare items query; winner last query item suggested acquisition function. ghahramani also propose active learning approach relative preference learning rank task. they step select pair items highest expected entropy term. objective learning rank approximate unknown function instead finding best item. jensen extend approach ghahramani user addition specify degree preference comparing items propose novel likelihood gaussian process. idea principle orthogonal ours intrinsically ordinal nature human preferences consider risk misspecification introducing ratio scale degrees preferences high attempt integrating method. pairwise preferences applied variety settings sound quality reduction mechanisms hearing aids material design learning predict emotions expressed music believe strategies could useful many these. conclusion paper proposed strategies elicit user preferences active learning setting gaussian processes asking user rank cluster items. showed compared previous work uses pairwise comparisons ranking clustering methods find better approximation utility function select items higher utility user fewer queries. furthermore showed obtain better results entering monotonicity information virtual comparisons. showed utilising heuristic linear prior mean function first queries leads increased performance heuristic turned later queries. user study showed ranking method popular although perceived effort slightly higher users felt less often understood method example pairwise comparisons. surprisingly clustering methods least popular. finally successfully used proposed decision-making tool real-world project traffic regulation together municipality amsterdam. showed human expertise successfully combined decision-making tools received positive feedback collaborators. hope work inspires real-world applications involving multiple objectives used multi-objective optimisation planning alike. future work perform extensive real-user experiments. extend approach multi-user settings like done houlsby pairwise feedback multiple users user informed prior inferred other. also study acquisition functions pick next item based look-ahead information gain furthermore interested investigating principled approach deciding disable linear prior mean function. acknowledgments authors would like thank municipality amsterdam time insights employees tested decision making tool. thank anonymous mturk workers participating study. research supported innoviris brussels institute research innovation brussels belgium. diederik roijers postdoctoral fellow research foundation flanders grant number simone parisi matteo pirotta marcello restelli. multi-objective reinforcement learning continuous pareto manifold approximation. journal artificial intelligence research alina pommeranz joost broekens pascal wiggers willem-paul brinkman catholijn jonker. designing interfaces explicit preference elicitation user-centered investigation preference representation elicitation process. user modeling user-adapted interaction marco wiering edwin jong. computing optimal stationary policies multi-objective markov decision processes. approximate dynamic programming reinforcement learning adprl ieee international symposium ieee peter auer chao-kai chiang ronald ortner madalina drugan. pareto front identification stochastic bandit feedback. artificial intelligence statistics. nawal benabbou patrice perny. adaptive elicitation preferences under uncertainty sequential decision making problems. international joint conference artificial intelligence. brochu cora freitas. tutorial bayesian optimization expensive cost functions application active user modeling hierarchical reinforcement learning. arxiv. kalyanmoy lothar thiele marco laumanns eckart zitzler. scalable test problems evolutionary multiobjective optimization. evolutionary multiobjective optimization. springer m.p. deisenroth c.e. rasmussen. gaussian processes dataefficient learning robotics control. ieee trans. pattern analysis machine intelligence groot heskes dijkstra kates. predicting preference judgments individual normal hearing-impaired listeners gaussian processes. ieee transactions audio speech language processing pascal halffmann stefan ruzika clemens thielen david willems. general approximation method bicriteria minimization problems. theoretical computer science arnaud liefooghe bilel derbel sébastien verel hernán aguirre kiyoshi tanaka. fitness landscape analysis pareto local search bi-objective permutation flowshop scheduling problems. international conference evolutionary multi-criterion optimization. lizotte. practical bayesian optimization. alberta. daniel lizotte michael bowling susan murphy. linear fitted-q iteration multiple reward functions. journal machine learning research", "year": 2018}