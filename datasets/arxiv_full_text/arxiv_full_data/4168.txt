{"title": "GuessWhat?! Visual object discovery through multi-modal dialogue", "tag": ["cs.AI", "cs.CV"], "abstract": "We introduce GuessWhat?!, a two-player guessing game as a testbed for research on the interplay of computer vision and dialogue systems. The goal of the game is to locate an unknown object in a rich image scene by asking a sequence of questions. Higher-level image understanding, like spatial reasoning and language grounding, is required to solve the proposed task. Our key contribution is the collection of a large-scale dataset consisting of 150K human-played games with a total of 800K visual question-answer pairs on 66K images. We explain our design decisions in collecting the dataset and introduce the oracle and questioner tasks that are associated with the two players of the game. We prototyped deep learning models to establish initial baselines of the introduced tasks.", "text": "introduce guesswhat? two-player guessing game testbed research interplay computer vision dialogue systems. goal game locate unknown object rich image scene asking sequence questions. higher-level image understanding like spatial reasoning language grounding required solve proposed task. contribution collection large-scale dataset consisting human-played games total visual question-answer pairs images. explain design decisions collecting dataset introduce oracle questioner tasks associated players game. prototyped deep learning models establish initial baselines introduced tasks. people natural language effective communicate including comes describe visual world around them. often need words refer speciﬁc object rich scene. whenever expressions unambiguously point object speak referring expression however uniquely identifying referred object always possible depends listener’s state mind context scene. many real life situations therefore require multiple exchanges clear object referred telligent scene understanding. systems would transparent interpretable humans naturally interact them example asking clarifying questions perceives. still fundamental challenge remains create models understand natural language descriptions ground visual world. last years seen increasing interest computer vision community tasks towards goal. thanks advances training deep neural networks availability large-scale classiﬁcation datasets automatic object recognition reached human-level performance result attention shifted toward tasks involving higher-level image understanding. prominent example image captioning task automatically producing natural lankey contribution paper introduction guesswhat? dataset contains dialogues composed question/answer pairs images extracted coco dataset deﬁne three sub-tasks based guesswhat? dataset prototype deep learning baselines establish difﬁculty. paper organized follows. first explain rules guesswhat? game sec. then sec. describes guesswhat? relates previous work. sec. highlight design decisions collecting dataset sec. analyses many aspects dataset. sec. introduces questioner oracle tasks baseline models. finally sec. provides ﬁnal discussion guesswhat? game. guesswhat? cooperative two-player game players picture rich visual scene several objects. player oracle randomly assigned object scene. object known player questioner whose goal locate hidden object. questioner series yes-no questions answered oracle shown note questioner aware list objects whole picture. questioner gathered enough evidence locate object notify oracle ready guess object. reveal list objects questioner picks right object consider game successful. otherwise game ends unsuccessfully. also include small penalty every question encourage questioner informative questions. appendix display full game perspective oracle questioner respectively. oracle role form visual question answering answers limited option included respond even question asked ambiguous answer simply cannot determined. instance cannot answer question wearing glasses? face selected person visible. role questioner much harder. need generate questions progressively narrow list possible objects. ideally would like minimize number questions necessary locate object. optimal policy involves binary search eliminate half remaining objects question. natural language often effective grouping objects image scene. strategies depend picture distinguish following types guage descriptions image. visual question answering another popular task involves answering single open-ended questions concerning image. closer work referit game aims generate single expression refers object image. hand renewed interest dialogue systems inspired success datadriven approaches areas natural language processing traditionally dialogue systems built heavy engineering hand-crafted expert knowledge despite machine learning attempts almost decades difﬁculties comes lack automatic evaluation contrary machine translation evaluation metric correlates well human evaluation promising alternative goal-directed dialogue tasks agents converse pursue goal rather casually chit-chat. agent’s success rate completing task used automatic evaluation metric. many tasks recently introduced including babi tasks testing agent’s ability answer questions short story movie dialog dataset assess agent’s capabilities regarding personal movie recommendation wizardof-oz framework evaluate agent’s performance assisting users ﬁnding restaurants. paper bring ﬁelds together propose novel goal-directed task multi-modal dialogue. two-player game called guesswhat? extends referit game dialogue setting. succeed players must understand relations objects expressed natural language. machine learning point view guesswhat? challenge following learn acquire natural language interaction visual task. previous attempts direction ground natural language immediate environment; instead rely external database conversational agent searches. goal guesswhat? task enable machines understand natural descriptions ground visual world. note higher-level reasoning occurs scene rich enough i.e. enough objects scene. people otherwise tend fall back linear search strategy simply enumerating objects guesswhat? game data collected present opportunities extension current research image captioning visual question answering dialogue systems. following describe previous work areas relate open challenges offered guesswhat?. also mention relevant work dataset collection. image captioning work builds coco dataset consists images object segmentations. addition dataset provides captions image initiated explosion interest research community generating natural language descriptions images. several methods proposed inspired encoder-decoder approach proven successful machine translation. image captioning research uncovered successful approaches automatically generate coherent factual statements images. modeling interactions guesswhat? requires instead model process asking useful questions images. datasets visual question answering tasks form another well known extension captioning task. instead require answering question given picture recently challenge provided dataset bigger previous attempts where much like guesswhat? questions free-form. extensive body work followed publication largely building image captioning literature unfortunately many advanced methods shown marginally improve simple baselines recent work also reports trained models often report answer question irrespective image suggesting largely exploit predictive correlations questions answers present dataset. guesswhat? game dataset attempt circumvent issues. questioner’s locate hidden object generated questions different nature naturally favour spatial understanding scene attributes objects within making valuable consult image. besides contains binary questions whose answers balanced twice questions average picture. goal-directed dialogue guesswhat? also relevant goal-directed dialogue research community. systems aimed collaboratively achieving goal user retrieving information solving problem. although goal-directed dialogue systems appealing remain hard design. thus usually restricted speciﬁc domains train ticket sales tourist information call routing besides existing dialogue datasets either limited fewer example dialogues unless generated template formats simulation case don’t reﬂect free-form natural conversations. finally recent work end-to-end dialogue systems fail handle dynamical contexts. instance intersects dialogue external database recommend restaurants. well-known game-based dialogue systems also rely static databases. contrast guesswhat? dialogues heavily grounded images. resulting dialogue highly contextual must based content current picture rather external database. thus best knowledge guesswhat? dataset marks important step dialogue research ﬁrst large scale dataset goaloriented multi-modal. human computation games guesswhat? line ahn’s seminal work human computation games showed games effective gather labeled data. ﬁrst game developed collect image tags later extended peekaboom gather object segmentations. games developed decade object recognition infancy served different purpose guesswhat?. referit probably closest work referit game game player observes annotated object scene need generate expression refers player receives expression subsequently clicks location object within image. original dataset uses imageclef dataset three recent extensions built coco. three databases select images objects category. contrast guesswhat? picks images objects without further restrictions object class thus contains three times images referit datasets. investigate difference referit guesswhat? compare three samples selected object appendix referit directly locates object single expression guesswhat? iteratively narrows object means positive negative feedback questions. also observe guesswhat? dialogues favor abstract concepts edible? oval plate? referit. images subset training validation images objects coco dataset ﬁrst discard objects small decently located human observer. then keep images containing three twenty objects avoid trivial overly complicated images. total keep images objects. veriﬁed selection signiﬁcantly alter original dataset distribution. amazon mechanical turk data collection crowd-sourced amazon mechanical turk created separate tasks known hits questioner oracle roles rewarded questioner slightly oracle. ensured quality data collection several means. first workers qualiﬁcation round consisted successfully completing games producing fewer mistakes disconnects. qualiﬁcation hits continue consist batch successful games. incentivize worker produce many successful dialogues providing bonuses making fewer mistakes. secondly players could report players banned certain number reports. thus players incentivized cooperate. kept dialogues qualiﬁed people successful dialogues qualiﬁcation round. contrast traditional dataset collection game requires interactive session players. fortunately found guesswhat? game highly engaging. total people participated hits participants played games each. since questions manually typed could contain spelling mistakes. thus retrieved questions containing words occur english dictionary manually corrected common words. remaining questions created hits correct spelling mistakes. figure appendix details. following explore properties data collected using guesswhat? game. provide global statistics examine vocabulary used questioners highlight relationship properties objects guess odds successful dialogue. dataset statistics guesswhat? composed dialogues containing question/answer pairs unique images unique objects. answers respectively n/a. average questions dialogue dialogues image. dialogues contain word tokens total making different words least occurrence words least occurrences. moreover dialogues successful unsuccessful completed thus different subsets co-exist guesswhat? dataset refer dataset full ﬁnished successful include dialogues ﬁnished dialogues successful dialogues respectively. details previous statistics broken dataset types question distributions better understanding guesswhat? games show number questions within dialogue average number questions given number objects within image first number questions within dialogue decreases exponentially players tend shorten dialogues speed game interestingly observe average number questions given number objects within image appears follow function grows rate logarithmically linearly. questioning strategy simply listing objects would imply linear growth number questions optimal binary search strategy would imply logarithmic growth. thus human questioners seem imply strategy somewhere between. conjecture three reasons humans achieve optimal search strategy. first questioner access ground truth list objects picture might therefore overestimate number objects. second humans tend favor linear search figure number questions dialogue number questions dialogue number objects within picture word cloud guesswhat? vocabulary word proportional frequency. words colored based hand-crafted clustering. uninformative words manually removed. vocabulary gain insight vocabulary used questioner compute frequency words guesswhat? corpus display frequent words word cloud several words clearly stand out. explained sec. words refer abstract object properties person object spatial locations right/left side visual features red/black/white. furthermore prepositions also heavily used express relationships objects. better understand sequential aspect questions study evolution vocabulary question round. observe questioners abstract object properties human/object/furniture beginning dialogues quickly switch either spatial visual terms left/right white/red tablechair. highlighted applying dynamic topic model study evolution topics course dialogue shown appendix elements success investigate whether certain object properties favour success compute success ratio dialogues relative size unknown objects number objects within images object category location objects within images size dialogues appendix respectively. expect complex scene lower success rate objects questioner success rate ratio drops around objects. similarly objects almost always found smallest found time. questioners easily objects middle picture difﬁculties border. finally objects categories often grouped together e.g. bananas books lower success rates. miscellaneous break ratio yesanswers within dialogues. ﬁrst yes-no answers balanced small dialogues often terminate ﬁnal yes. contrast long dialogues often start higher proportion negative answers slowly decrease exchange. split guesswhat? dataset randomly assigning images corresponding dialogues training validation test set. dividing data ensures evaluate performance images seen training. guesswhat? dataset available https//guesswhat.ai/download. formally guesswhat? game revolves around image rm×n containing segmented objects ok}. object assigned object category pixel-wise segmentation mask }m×n specify location size. game consists sequence questions answers produced questioner oracle. refer ﬁrst questions answers respectively. question contains sequence tokens i.e. wjnj} taken vocabulary represents token position question answer either i.e. {yes n/a}. finally oracle access identity correct object ocorrect prediction questioner denoted opredict. figure histogram absolute/relative successful dialogues respect number objects size objects respectively. evolution answer distribution clustered dialogue length follows. embed full image rescaled image passed pre-trained network obtain features. selected object ﬁrst cropped ﬁnding smallest rectangle encapsulates based segmentation mask. rescale crop square obtaining features pre-trained network. although could mask drop pixels around selected object keep crop since pre-trained networks exposed background noise training. also embed spatial information crop help locate cropped object within whole image. follow approach extract -dimensional vector location bounding wbox hbox denote width height bounding respectively. normalize image height width coordinates range place origin center image. object category convert one-hot class vector dense category embedding using learned look-up table. finally embedding current natural language question computed using long short-term memory network questions ﬁrst tokenized using word punct tokenizer python nltk toolkit simplicity decided ignore question-answer pairs history oracle baseline. training setting train oracle models full dataset. training keep parameters network ﬁxed optimize lstm object category/word look-up tables parameters minimizing negative log-likelihood correct answer. adam optimization train epochs. early stopping validation report train valid test error. results report results several oracle models using different inputs table name oracle task requires produce yes-no answer object within picture given natural language question. ﬁrst introduce model outline results better understanding guesswhat? dataset. model propose simple neural network based approach model illustrated speciﬁcally appropriate neural network architecture embed following information image cropped object spatial information category current question embeddings concatenated single vector input single hidden layer outputs ﬁnal answer distribution using softmax layer. finally minimize cross-entropy error training report classiﬁcation error evaluation time. model dominant class question image crop question crop question image question category question spatial question category spatial question category crop question spatial crop question category spatial crop question spatial crop image question category spatial image table classiﬁcation errors oracle baselines train valid test set. best performing model question category spatial refers takes question selected object class spatial features input. model input feed instance refers network question object category spatial features xspatial full image results subsets reported table appendix guesswhat? dataset fairly balanced simply outputting common answer training results high error rate. solely providing image crop features barely improves upon result. using question slightly improves error rate speculate small bias comes questioners refer objects never segmented overrepresented categories. hoped observe error rate signiﬁcantly drops ﬁnally feed information object guess model. crop category information redundant model achieve respectively error combined model achieves general expect object crop contain additional information color information beside object class. however object category outperforms object crop embedding. might partly imperfect feature extraction crops. finally best performing model combines object category spatial features along question. general also needs module determine start guessing object baseline bypass issue ﬁxing number questions question generator model. guesser role guesser model predict correct object. guesser access image dialogue list objects image. encode image extracting features network. dialogue guesswhat? game sequence different levels variable number question-answer pairs question turn consists variable-length sequence tokens. encoded ﬁxed size vector using either lstm encoder hred encoder lstm encoder considers dialogue sequence hred explicitly models hierarchy different recurrent neural networks first encoder creates ﬁxed-size representation question answer reading tokens taking last hidden state rnn. representation processed context obtain representation current dialogue state. models concatenate image dialogue features dot-product embedding objects image followed softmax obtain prediction distribution objects. given best performance question+category+spat oracle model respect described parameters. test time beam-search approximately probable question evaluating questioner model requires pretrained oracle pre-trained guesser model. questioner model ﬁrst generate question answered oracle model. repeat procedure times obtain dialogue. best performing guesser model predict object report error metric qgen model. since ground truth answers qgen training oracle answers test time mismatch training testing procedure. avoided using oracle answers also training time. call models qgen+gt qgen+oracle respectively. table shows results. guesser based human generated dialogues achieves error. question generator models achieve reasonable performance lies random performance performance guesser human dialogues. observe using oracle’s answers training question generator introduces additional errors signiﬁcantly deteriorates performance. example dialogues generated qgen+gt model shown fig. introduced guesswhat? game novel framework multi-modal dialogue. best knowledge present ﬁrst large-scale dataset involving images dialogue. wide range challenges arise union rely different ﬁelds machine learning natural language understanding generative models computer vision. guesswhat? turns engaging game greatly decreases cost collecfigure hred model conditioned features image. avoid clutter show part model deﬁnes distribution third question given ﬁrst questions answers image complete hred model models distribution questions. represent objects category spatial features. precisely concatenate -dimensional spatial representation object category look-up pass layer embedding object. note parameters shared handle variable number objects image. overview guesser hred lstm. table reports results guesser baselines using human-generated dialogues. ﬁrst baseline report performance random guesser dialogue information. split guesser results based whether features not. general including features improve performance lstm hred models. hypothesize features coarse representation image scene visual information already encoded question object features. surprisingly lstms perform slightly better sophisticated hred models. question generator question generation task hard several reasons. first requires high-level visual understanding meaningful questions. second generator able handle long-term context sequence relevant questions challenging problems dialogue systems. additionally evaluate question generator using imperfect oracle imperfect guesser introduces compounding errors. tion dataset required modern algorithms. second contribution introduced three tasks based questioner oracle role. case prototyped neural architecture ﬁrst baseline. analyzed results presented quantitative description guesswhat? dataset. believe guesswhat? could allow myriad applications either based game itself extending database tasks. instance interesting compute conﬁdence interval proceeding ﬁnal guess. differently guesswhat? could test one-shot learning guessing object categories transfer learning line-drawing images using questions another language. thus guesswhat? dataset offers opportunity develop original machine learning tasks upon acknowledgement authors would like acknowledge stimulating environment provided mila sequel labs. thank members mila participated trial data collection workers participated hits. thank jake snell mengye laurent dinh jeremie mary bilal piot helpful discussions. acknowledge following agencies research funding computing support nserc calcul qu´ebec compute canada canada research chairs cifar chistera iglu cper nord-pas calais/feder data advanced data science technologies supported fqrnt-pbeee scholarship.", "year": 2016}