{"title": "Locally Scale-Invariant Convolutional Neural Networks", "tag": ["cs.CV", "cs.LG", "cs.NE"], "abstract": "Convolutional Neural Networks (ConvNets) have shown excellent results on many visual classification tasks. With the exception of ImageNet, these datasets are carefully crafted such that objects are well-aligned at similar scales. Naturally, the feature learning problem gets more challenging as the amount of variation in the data increases, as the models have to learn to be invariant to certain changes in appearance. Recent results on the ImageNet dataset show that given enough data, ConvNets can learn such invariances producing very discriminative features [1]. But could we do more: use less parameters, less data, learn more discriminative features, if certain invariances were built into the learning process? In this paper we present a simple model that allows ConvNets to learn features in a locally scale-invariant manner without increasing the number of model parameters. We show on a modified MNIST dataset that when faced with scale variation, building in scale-invariance allows ConvNets to learn more discriminative features with reduced chances of over-fitting.", "text": "convolutional neural networks shown excellent results many visual classiﬁcation tasks. exception imagenet datasets carefully crafted objects well-aligned similar scales. naturally feature learning problem gets challenging amount variation data increases models learn invariant certain changes appearance. recent results imagenet dataset show given enough data convnets learn invariances producing discriminative features could more less parameters less data learn discriminative features certain invariances built learning process? paper present simple model allows convnets learn features locally scale-invariant manner without increasing number model parameters. show modiﬁed mnist dataset faced scale variation building scale-invariance allows convnets learn discriminative features reduced chances over-ﬁtting. convolutional neural networks achieved excellent results visual classiﬁcation tasks like handwritten digits toys trafﬁc signs recently -category imagenet classiﬁcation convnets’ success comes ability learn complex patterns building increasingly abstract representations layer layer much like deep neural networks. however convnets differ exploit dimensional structure images objects patterns appear arbitrary locations. convnets apply local ﬁlters every position image allowing network detect learn patterns regardless location. reality world three dimensional structure objects different distances appear image different scales well locations. convnets mechanism take advantage scale explicitly detect single pattern multiple scales must learn separate ﬁlters scale. unfortunately several major shortcomings. capturing patterns multiple scales uses resources could used learn wider variety feature detectors. requires increase number feature detectors means network harder train takes longer train likely overﬁt. learn multiple scales prevent overﬁtting would need training data even network respond scales seen training. also detectors capture pattern different scales learned independently without sharing training samples. finally multiple ﬁlters single pattern different scales burdens next layer increasing number conﬁgurations indicate presence absence pattern. paper present scale-invariant convolutional networks applies ﬁlters multiple scales layer single ﬁlter detect learn patterns multiple scales. max-pool responses scales obtain representations locally scale invariant dimensionality traditional convnet layer output. proposed architecture differs multi-scale approaches explored convnets since scale-invariance built layer level rather network level. also achieve locally scale-invariant representation require increase number parameters learned. show experiments sharing information multiple scales proposed model achieve better classiﬁcation performance convnets simultaneously requiring less training data. evaluate proposed model variation mnist dataset digits appear multiple scales demonstrate si-convnets robust scale variations training data unfamiliar scales test data convnets. model complementary convnet architectures easily incorporated existing variants make source code available online research community. several recent works addressed problem explicitly incorporating transformation invariance deep learning models. unsupervised feature learning domain sohn introduced transformation-invariant restricted boltzmann machines linear transformations ﬁlter applied input infer highest activation. models transformed ﬁlters applied center largest receptive ﬁeld size. model uses inverse transformation stage transformed ﬁlters applied densely still retain correspondence. work inspired success sohn goal incorporate scale-invariant feature learning extremely successful convnet models tiled convolutional neural networks learn invariances implicitly square-root pooling hidden units computed partially un-tied weights. comparison approach explicitly encodes scale invariance require increase number learned parameter required un-tying weights. fuses outputs multiple convnets applied multiple scales semantic segmentation convnet learned independently without weight-sharing. contrast jointly learn feature detectors shared multiple scales. proposes multi-scale convnet outputs convolutional layers classiﬁer. enables capture information different levels hierarchy scale invariance features learned layer layer applied original scale. another inﬂuential work farabet train convnets laplacian pyramid images tied weights scene parsing problems. model entire multi-layer forward propagation applied scale disjointly right fully-connected layers responses scales aligned up-sampling concatenated. keeping responses scale allows capture scale-level dependencies expense increasing number parameters required ﬁnal layer. restricts number scales applied; contrast model compact free restrictions. further approach motivated need large receptive ﬁeld sizes capture long-range contextual interactions necessary scene understanding. contrast interested capturing locally scale-invariant features useful image classiﬁcation; hence unlike approach pool responses scales spatial location layer. pooling responses scales layer opposed concatenating scales subtle different effects middle layers. example suppose image circles different sizes circle ﬁlter detect circles image. architecture farabet circle detected different scale never recognized together layer scales concatenated. architecture circles detected together second layer immediately make fact circles image. course circle ﬁlters different sizes farabet al.’s network also detect circles scale expense learning redundant ﬁlters. work demonstrates advantages applying convnets multiple scales scene parsing investigate effectiveness image classiﬁcation domain modular model explicitly incorporates scale-invariance layer. convolutional neural networks supervised feed-forward multi-layer architecture layer learns feature detectors increasing complexity. ﬁnal layer classiﬁer regressor cost function network trained supervised manner. entire network optimized jointly stochastic gradient descent gradients computed backpropagation single layer convnet usually composed feature extraction nonlinear activation stages optionally followed spatial pooling feature normalization. hallmark convnets idea convolving local feature detectors across image. idea motivated fact similar patterns appear anywhere layout pixels nearby values present strong dependencies natural images local feature detectors trainable ﬁlters spatial extent called receptive ﬁeld network represents much image network gets see. convolution operation effectively ties learned weights multiple locations radically reduces number trainable parameters compared different weights location output convolving kernel called feature sent nonlinear activation function feature layer computed trainable weights bias respectively. multiple feature maps network represent multiple concepts single layer. model summarize sub-region feature average pooling providing invariance small amounts image translation. feature detectors convnets ability detect features regardless spatial locations image cannot said features different scales. section describe scale-invariant convnet formulation also allows output convnets locally scale-invariant representation patterns different scales similar figure shows side side comparison overall structure layers. goal feature detector respond patterns multiple scales. convolve ﬁlters multiple resolutions pyramid. scale exact ﬁlters used convolve image since spatially transform image outputs convolution come different spatial sizes. order align feature maps apply inverse transformation feature finally max-pool responses scales spatial location. pooling responses multiple scales serves purposes. first allows obtain locally scale-invariant representation. second summarizes responses concise allows maintain output size standard convolution layer. speciﬁcally linear image transform operator applies spatial transformations input then transformation operators feature computed given patterns share center. center patterns shifted output when stride equal size kernel applying inverse transformation gives direct correspondence convolution outputs. it’s applying inverse transformation output either cropped padded properly aligned. figure side-by-side comparison structure convolution layer proposed scaleinvariant convolution layer. black bold feature detector kernel ﬁgures. ﬁrst image pyramid constructed scaling input second kernel convolved across input scale. third responses convolution scale normalized. finally responses pooled scale spatial location obtaining locally scale-invariant representation. note input output size same. note rhi×hi×m size output convolution i-th transformed input rh×h×m canonical output size responses aligned number feature maps used. always identity transformation framework equivalent traditional convnets. figure illustrates idea sample inputs pattern different scales. detector convnet learned. standard convolution layer activate whose pattern matches size however scale-invariant convolution layer undergo scale transformations matched scales allowing detect pattern responses aligned inverse transformation ﬁnal output maximum activation spatial location. path winning scale shown bold lines. since convolving pyramid images single ﬁlter analogous convolving single image ﬁlters different sizes using scales analogous increasing number feature maps times without actually paying price parameters. allows train expressive model without increasing chances over-ﬁtting. image transform operator parametrized single scale factor location transformed image computed linear interpolation original image around s−x. bilinear interpolation compute coefﬁcients. note focus scale invariance paper framework applicable linear transformations. transformation coefﬁcients precomputed applying transformation efﬁcient. however increase number convolution operations required since scaled input must convolved. increase dominated largest scale factor step sizes please scale. explicitly increase number convolutions layer refer supplementary material details. figure illustration showing single feature detector detect features images despite scale difference standard convolution layer highly respond scale difference however scale-invariant convolution layer respond well scaled twice original size. thus achieve similar feature representation. bold arrows indicate winning scale used ﬁnal representation. scales shown illustration purposes. since scale-invariant convolution layer consists linear operations gradients computed simple modiﬁcation back-propagation algorithm. backprop maxpooling scale implemented using argmax indices analogous backprop done spatial max-pooling. scale transformations error signal propagated bilinear coefﬁcients used compute transformation. please refer supplementary materials detailed derivations. ﬁrst compare performance proposed method referred si-convnet baseline methods including traditional convnets. experiments carried networks share exact hyper-parameters architecture except convolution layers replaced scale-invariant convolution layers. implement method using opensource caffe framework code available online. order evaluate effectiveness si-convnets must experiment dataset objects come variety scales since much gain obtained learning scale-invariant manner scale variation data. unfortunately benchmark datasets evaluating convnets category. therefore experiment modiﬁed mnist handwritten digit classiﬁcation dataset introduced called mnist-scale. consists gray-scale images digit randomly scaled factor without making truncation foreground pixels. unless otherwise noted architectures used experiment consist convolutional layers feature maps kernels respectively fully connected layer hidden nodes soft-max logistic regression layer. network architecture modeled convnets achieve state-of-the-art original mnist dataset pre-processing method hyper-parameters unless otherwise noted. don’t techniques data augmentation dropout model averaging simplify comparison convolution layer proposed scale-invariant convolution layer kernel size ﬁrst convolution layer weight decay parameter re-tuned mnist-scale dataset using subset training data convnet ﬁxed networks. networks trained epochs test error epochs reported. networks share random seed. scale-invariant convolution layer uses scales scale step i.e. scales details parameters used experiment provided supplementary materials. experiment compare proposed network convnets hierarchical convnets farabet restricted boltzmann machine scale-invariant version sohn following experimental protocol train test network images respectively. evaluate models train/test folds report average test error standard deviation. architecture scale parameters hierarchical convnets. results shown table si-convnet outperforms convnet hierarchical convnet hierarchical convnet slightly underperforms convnet possibly overﬁtting times parameters convnet/si-convnet. scene classiﬁcation context hierarchical convnet introduced pixel-level labels exist providing much training data compared image classiﬁcation settings. result emphasizes strength si-convnet achieves scale-invariant learning keeping number parameters ﬁxed. large models convnets fact rbms unsupervised models architecture shallow feature extraction layer. however relative error difference original scale-invariant version rbms convnets comparable respectively si-rbm si-convnet. shows si-convnet obtaining similar improvements scale-invariant good supervised counterpart scale-invariant models. investigate scale-invariance achieved model using invariance measure proposed goodfellow method neuron said ti|/n inputs greater transformations applied images activate hidden unit number times neuron ﬁres response transformed inputs recorded. proportion transformed inputs neuron ﬁres called local ﬁring rate measures robustness neuron high value indicates invariance unless neuron easily ﬁred arbitrary inputs. therefore invariance score neuron computed ratio invariance selectivity i.e. li/gi. report average highest scoring neurons please details. consists scaling images values step size figure shows invariance score convnet si-convnet measured layer. max-pooling responses multiple scales si-convnets produce features scale-invariant convnets. evaluate si-convnet varying number training samples feature maps ﬁrst layers. experiments report test error images. discussed subsection using scales scale-invariant convolution layer kernels resembles network kernels without actually increase number parameters times. biggest disadvantages convnets requires training data number parameters increase. keeping number parameters ﬁxed siconvnets train times wider thus powerful network less demanding amount training data. able share information patterns multiple scales allows si-convnets learn better features less data. contrast convnets learn multiple ﬁlters pattern independently learning ﬁlters well requires many examples pattern scale. figure plots test error number feature varied si-convnets consistently outperforms convnets. since given enough feature maps convnets learn feature detector scale observe decreases number feature maps increases. figure plots test error amount training data changes. again si-convnet consistently achieves lower error convnet decreases training data increases. shows si-convnets learn better model less training data. following experiments increase image sizes mnist-scale dataset experiment wider range scale variation. order account larger scale range change scales used si-convnet scales scales experiments. train test images. first evaluate ability correctly classify images less common training data. training data scaled factors sampled gaussian rather uniform distribution. digits test data scaled particular scale factor vary test scale factor correspond away mean. away test scale factor mean challenging problem gets since many training samples observed scale training. expect convnet siconvnet similarly around mean convnet progressively worse scale moves away mean cannot reuse ﬁlters learned inputs different scales. shown figure results verify trend si-convnet outperforms convnet even mean. average reduction relative error ends scales relative error reduction respectively. lack symmetry around mean possibly fact digit classiﬁcation becomes extremely difﬁcult even humans digits small. next evaluate robustness scale variation increasing range scale present training test data keeping number parameters training samples ﬁxed. scale factors sampled uniform distribution range results figure show siconvnets consistently outperform convnets error si-convnets increases lower rate convnets scale variation increases. shows weakness convnets learn redundant ﬁlters digits come wide variety scales si-convnets making efﬁcient resources terms number parameters training data. figure test error scale digits test time digits training data scaled factor sampled gaussian distribution centered extremes ends standard deviation away mean. classiﬁcation challenging away scales mean since less number training data available. large si-convnets convnets ends show si-convnets robust images unfamiliar scales. test error range uniform distribution used scale training data. lower growth error si-convnets shows learn better features given resources data complexity increases. introduced architecture allows locally scale-invariant feature learning representation convolutional neural nets. sharing weights across multiple scales locations single feature detector capture feature arbitrary scales locations. achieve locally scaleinvariant feature representation pooling detector responses multiple scales. architecture different previous approaches scale-invariance built convolution layer independently. maintain number parameters traditional convnets incorporating scale prior learn features efﬁciently reduced chances overﬁtting. experiments show si-convnets outperform convnets various aspects.", "year": 2014}