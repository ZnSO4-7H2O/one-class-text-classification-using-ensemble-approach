{"title": "Dimensionality Reduction and Reconstruction using Mirroring Neural  Networks and Object Recognition based on Reduced Dimension Characteristic  Vector", "tag": ["cs.CV", "cs.AI", "cs.NE"], "abstract": "In this paper, we present a Mirroring Neural Network architecture to perform non-linear dimensionality reduction and Object Recognition using a reduced lowdimensional characteristic vector. In addition to dimensionality reduction, the network also reconstructs (mirrors) the original high-dimensional input vector from the reduced low-dimensional data. The Mirroring Neural Network architecture has more number of processing elements (adalines) in the outer layers and the least number of elements in the central layer to form a converging-diverging shape in its configuration. Since this network is able to reconstruct the original image from the output of the innermost layer (which contains all the information about the input pattern), these outputs can be used as object signature to classify patterns. The network is trained to minimize the discrepancy between actual output and the input by back propagating the mean squared error from the output layer to the input layer. After successfully training the network, it can reduce the dimension of input vectors and mirror the patterns fed to it. The Mirroring Neural Network architecture gave very good results on various test patterns.", "text": "neural networks used mirror input image pattern reduce dimension input pattern. reduced pattern dimension vector considered signature pattern used classifying object. reduced pattern dimension vector mirroring neural network reconstructs original image pattern minimal distortion. approach different past work done recognition classification patterns discussed used different architecture coupled rescaled learning rate parameter also different activation function. mirroring neural networks used recognise type patterns object interest. many networks trained multitude patterns networks ability recognize patterns albeit network. networks connected framework architecture made pattern input networks architecture gives output network successfully mirrors pattern architecture could possible data structure simulated memory. detailed discussion architecture found proposed work developed mirroring neural network face patterns. present section explains architecture mirroring neural network reduce dimension mirror input patterns network used train single pattern. mirroring neural network upon successful training recognize image pattern trained. layered architecture learning rate parameter random weights configured neural network converge minimal loss information. coded form object least dimensional hidden layer called signature object used classify objects. mirroring neural network contains adalines outer layers least middle layer form converging-diverging shape shown fig.. abstract paper present mirroring neural network architecture perform non-linear dimensionality reduction object recognition using reduced lowdimensional characteristic vector. dimensionality reduction network also reconstructs original high-dimensional input vector reduced low-dimensional data. mirroring neural network architecture number processing elements outer layers least number elements form converging-diverging shape configuration. since network able reconstruct original image output innermost layer outputs used object signature classify patterns. network trained minimize discrepancy actual output input back propagating mean squared error output layer input layer. successfully training network reduce dimension input vectors mirror patterns mirroring neural network architecture gave good results various test patterns. paper proposes pattern recognition algorithm using neural network architecture called mirroring neural network. paper uses facial patterns example explain mirroring neural network architecture illustrate performance. facial pattern recognition broadly classified techniques viz. manually specifying facial features automatically extracting features. paper deals second technique neural network face patterns automatically. many problems resolved using neural networks face detection optical character recognition visual pattern recognition gender classification etc. mirroring adalines last layer. pattern reconstructed output original dimension units signature. input patterns dimensions thus represented code units hidden layer tried various architectures varying hidden layer dimensions. considerable experimentation found network hidden layer output layer suitable choice pattern. degree reduction input pattern plays important role reduced dimension vector number units least dimensional hidden layer must chosen careful experimentation. trying different dimensions hidden layers trail error method checking neural network’s performance found units hidden layer gave accurate results. designed mirroring neural network inputs hidden units output units inputs network grayscale images. converging part example network starts units input layer units hidden layer units hidden layer till reaches least dimensional hidden layer units. converging part condenses high dimensional pattern dimensional code format. diverging part network starts least dimensional central hidden layer ends output layer. units layer network layer units till reaches output layer ‘nl’ units number hidden layers values variables ‘n’… ‘nl’ selected input pattern mirrored output minimum distortion. training back propagating mirroring neural network used usual gradient descent minimize mean squared error input reconstruction output. activation function variable learning rate parameter reduce out-of-range values help faster convergence network. learning rate parameter incremented hidden layer compared output layer. mirroring neural network combination hyperbolic tangent function learnt input patterns rapidly reconstructed deformation. input grayscale intensities rescaled rescaled grayscale intensities mapped range initial weights chosen randomly range detailed discussion architecture defined following sections. nitially small random values chosen weights bias terms hidden layer output layer. used hyperbolic tangent function instead linear logistic functions used faster convergence network. differential nonlinear activation function implemented node hidden layer output layer. transfer function defined tested network face images algorithm classified face images correctly accuracy also tested images containing face non-face images. algorithm could correctly classify images sets test images entirely images none training set. architecture described paper simple approach object recognition applicable various image categories like faces furniture flowers trees tested slight changes network architecture hidden layer size threshold values. networks could used face detection incorporating application verify possible face candidates. networks parallelized recognition tasks pertaining different patterns. example input image pattern sent specialized mirroring neural networks parallel network gives least value thresholds would identify input pattern. overview multiple pattern mirroring architecture illustrated fig. fter successfully training neural network desired accuracy average feature vector input pattern computed averaging least dimensional hidden layer outputs input images. recognition object based threshold values. first threshold value euclidian distance† reduced dimension feature vector test image average feature vector computed training mirroring neural network. second threshold value euclidian distance output input mirroring neural network. values computed test image within accepted threshold categorized test image face pattern. threshold values fixed considerable experimentation order maximize success rate reduce false acceptance. training consisting facial images size mirroring neural network. sufficient training network could recognize faces reject non-face patterns. recognition based threshold values discussed typical sample input images training corresponding mirror images shown fig. test samples face nonface images given fig.", "year": 2007}