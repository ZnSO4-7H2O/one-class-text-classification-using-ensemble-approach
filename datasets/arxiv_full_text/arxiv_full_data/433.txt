{"title": "Surprising properties of dropout in deep networks", "tag": ["cs.LG", "cs.AI", "cs.NE", "math.ST", "stat.ML", "stat.TH"], "abstract": "We analyze dropout in deep networks with rectified linear units and the quadratic loss. Our results expose surprising differences between the behavior of dropout and more traditional regularizers like weight decay. For example, on some simple data sets dropout training produces negative weights even though the output is the sum of the inputs. This provides a counterpoint to the suggestion that dropout discourages co-adaptation of weights. We also show that the dropout penalty can grow exponentially in the depth of the network while the weight-decay penalty remains essentially linear, and that dropout is insensitive to various re-scalings of the input features, outputs, and network weights. This last insensitivity implies that there are no isolated local minima of the dropout training criterion. Our work uncovers new properties of dropout, extends our understanding of why dropout succeeds, and lays the foundation for further progress.", "text": "analyze dropout deep networks rectiﬁed linear units quadratic loss. results expose surprising diﬀerences behavior dropout traditional regularizers like weight decay. example simple data sets dropout training produces negative weights even though output inputs. provides counterpoint suggestion dropout discourages co-adaptation weights. also show dropout penalty grow exponentially depth network weight-decay penalty remains essentially linear dropout insensitive various re-scalings input features outputs network weights. last insensitivity implies isolated local minima dropout training criterion. work uncovers properties dropout extends understanding dropout succeeds lays foundation progress. imagenet large scale visual recognition challenge university toronto team surprisingly large margin. invited talk nips hinton credited dropout training technique much success. dropout training variant stochastic gradient descent where example processed network temporarily perturbed randomly dropping nodes network. gradient calculation weight updates performed reduced network dropped nodes restored next iteration. since imagenet competition dropout successfully applied variety domains widely used example incorporated popular packages torch caﬀe tensorflow intriguing crippling network training often leads dramatically improved results dropout also sparked substantial research related methods work examine eﬀect dropout inductive bias learning algorithm. match dropout’s inductive bias important applications could explain success dropout popularity also motivates study unusual properties. call penalty since diﬀerence training criterion evaluated empirical loss analogy deﬁne dropout penalty diﬀerence dropout training criterion empirical loss dropout penalties measure much dropout discriminates weight vectors understanding dropout’s inductive bias. even one-layer networks conclusions drawn approximations dropout penalty misleading therefore focus exact formal analysis dropout multi-layer networks. theoretical analysis deep networks notoriously diﬃcult might expect thorough understanding dropout deep networks must achieved stages. paper process exposing surprising ways inductive bias dropout diﬀers standard regularizers. include following input features largely insensitive rescaling outputs; play role dropout’s practical success. dropout also unaﬀected weights layer scaled constant weights another layer scaled implies dropout training isolated local minima. ticular dropout penalty weights negative; dropout penalty weights depends training instances labels; although dropout probability intuitively measures strength dropout regularization dropout penalties often non-monotonic dropout probability. contrast wager show dropout applied generalized linear models dropout penalty always non-negative depend labels. analysis multilayer neural networks square loss output node. hidden layers popular rectiﬁed linear units outputting node’s activation study minimizers criterion viewed objective function using dropout. abstracts away sampling optimization issues focus inductive bias section complete explanation. number possible explanations suggested dropout’s success. hinton suggest dropout controls network complexity restricting ability co-adapt weights illustrate appears learn simpler functions second layer. others view dropout ensemble method combining diﬀerent network topologies resulting random deletion nodes. wager observe -layer networks dropout essentially forces learning challenging distribution akin ‘altitude training’ athletes. formal analysis inductive bias dropout concentrated single-layer setting single neuron combines inputs. wager considered case distribution label given feature vector member exponential family log-loss used evaluate models. pointed that situation criterion optimized dropout decomposed original loss term depend labels. gave approximations dropout regularizer discussed relationship regularizers. seen many aspects behavior dropout relationship regularizers qualitatively diﬀerent hidden units. wager considered dropout learning topics modeled poisson generative process. exploited conditional independence assumptions generative process show excess risk dropout training training variation term decays rapidly straightforward empirical risk minimization also second additive term related document length. also discussed situations model learned dropout small bias. baldi sadowski analyzed dropout linear networks showed dropout approximated normalized geometric means subnetworks nonlinear case. ghahramani described interpretation dropout approximation deep gaussian process. on-line learning experts setting erven showed applying dropout on-line trials leads algorithms automatically adapt input sequence without requiring doubling parameter-tuning techniques. rest paper organized follows. section introduces notation formally deﬁnes dropout model. prove dropout enjoys several scaling invariances weight-decay doesn’t section dropout requires negative weights even simple situations section section uncovers various properties dropout penalty function. section describes simulation experiments. provide concluding remarks section throughout analyze fully connected layered networks inputs output layers nodes hidden layer. assume positive multiple even perfect square power avoid unilluminating ﬂoor/ceiling clutter analysis. call standard architecture. denote particular setting weights biases network denote network’s output input using hidden nodes relus output node linear. decomposed matrix weights connections hidden layer ||w||. throughout ||w|| denote squares strength weights denote minimizer criterion. penalty ||w|| non-negative. useful example bound risk minimizer since node always kept; dropping eﬀect cancelling training iteration.) node dropped node’s output compensate reduction values kept nodes multiplied compensation dropout viewed injecting zero-mean additive noise non-output node equation property dropout criterion. indicates something true dropout criterion family distributions concentrated single examples thing true mixture single-example distributions. consider example network figure weight parameters all-’s biases hidden node computes dropout pattern indicates subset four lower nodes kept subset equally likely kept. dropout pattern input dropped nodes kept network computes three dropout patterns produce non-zero output concentrated example variance output dropout causes network better data network’s non-dropout evaluation. section give necessary condition variance beneﬁcial. dropout criterion dropout penalty decomposes expectation penalties single examples theorem example distribution diagonal full-rank matrix dropout aversion equals dropout aversion proof choose network undoes eﬀect gets rest network unchanged. furthermore dropout pattern undoes eﬀects kept nodes rest network modiﬁed manner paralleling thus bijection networks networks yielding theorem. theorem indicates common normalizations input features aﬀect quality dropout criterion minimizers normalization might change speed convergence minimizer reached. centering features slightly diﬀerent properties. although easy biases deﬁne undoes centering non-dropout computation diﬀerent appear required diﬀerent dropout patterns breaking bijection exploited theorem implies dropout criterion never isolated minimizers since continuously up-scale weights layer compensating down-scaling another layer contiguous family networks computing function dropout criterion. possible exploit parameterization equivalence theorem training using canonical forms equivalent networks switching equivalent networks whose gradients better properties. leave question future work. proof network minimizes dropout criterion network obtained scaling weights bias output unit minimizes dropout criterion dropout pattern cy)/c. analyze criterion depth- networks appendix resulting following theorem. proof shows that despite non-convexity criterion still possible identify closed form optimizers. weight setting weights zero bias output node. means weight-decay -layer networks completely regularize away signiﬁcant signal sample even ﬁnite contrasting starkly weight-decay’s behavior -layer networks. vertical ﬂexibility rescale weights layers enjoyed dropout hold always drive penalty inﬁnity scaling layer large enough positive even scaling another hand proof theorem shows criterion alternative horizontal ﬂexibility involving rescaling weights across nodes hidden layer lemma shows optimizers hidden node’s contributions output constant times contribution penalty. shifting magnitudes contributions hidden nodes leads alternative weights since output node puts weight hidden node biases unregularized optimum actually represents class networks diﬀering irrelevant biases hidden nodes. easily construct cases weightdecay isolated minima sense example equal probability label compute value weight decay penalty. general observation permutation symmetry hidden nodes portion hidden node’s contribution shifted another hidden node. weights unit non-negative unit computes monotone function sense increasing input keeping others ﬁxed increases output. bias aﬀect node’s monotonicity. network monotone units also monotone. section analyze simple distribution assigns probability example probability example arguably simplest monotone function. nevertheless prove dropout uses negative weights data. intuition optimizing dropout criterion requires controlling variance. negative weights hidden nodes used control variance dropout input layer. enough hidden nodes becomes beneﬁcial every minimizer dropout criterion uses negative weights. biases wneg building block deﬁnition wneg block hidden units call ﬁrst-one gadget. block hidden nodes takes input input nodes. hidden node block takes value input node inputs accomplished weight vector ﬁrst hidden layer wneg comprises copies ﬁrst-one gadget. informally construction removes variance number input recorded approaches case. lemma gives larger lower bound network positive weights. concrete case lemma implies consider computation wneg dropout output. number input nodes kept number nodes hidden layer kept. call node ﬁrst-one gadget computes node node gadget computes input dropped arbitrarily make gadget’s ﬁrst hidden node node. ensures exactly node gadget every non-key node computes number kept nodes ﬁrst hidden layer. output always holds. furthermore uniformly distributed among vectors ones uniformly distributed among vectors ones uniformly distributed among vectors ones. true also true network obtained dropping hidden nodes thus theorem standard architecture ﬁxed large enough every optimizer dropout criterion uses negative weights. proof deﬁne wneg proof lemma except output layer bias taken respect dropout patterns hidden nodes since dropout pattern hidden nodes deﬁnes particular network lemma holds them relationships also hold expectations previous sub-section analyzed distribution -feature examples however examples embedded larger feature space using ﬁxed vector additional feature values creating instance distribution results section still apply distribution extended examples deﬁning wneg network zero weight additional features noticing weight additional features positive-weight network simulated using biases every network non-negative weights zero-embeddings hand single wneg network copies k-input ﬁrst-one gadget source distribution puts probability example embeddings thus mixture optimizing analysis negative weights used dropout counterintuitive ﬁtting monotone behavior needed control variance dropout. suggests dropout less eﬀective layers sparse activation patterns wider layers dropout training hijack part expressiveness wide layer control artiﬁcial variance dropout rather ﬁtting underlying patterns data. weight-decay penalizes large weights theorem shows compensating rescaling weights aﬀect dropout penalty criterion. hand dropout sensitive calculation large outputs weight decay large outputs produced deep networks using small weights. make observation concrete exhibiting family networks depth desired output linked size individual weights remains constant. family dropout penalty grows exponentially depth suggesting dropout training less willing data kind situation. proof network whose weights /dn/d biases penalty number weights times λc/. simple induction show that weights input value computed hidden node level cjknj− network outputs cdknd− zero square loss cdknd− consider dropout network. equivalent changing weights independently probability replacing value node ﬁxed dropout pattern node given layer weights receives inputs. thus value computed every node layer same. value computed units hidden layer. dropout penalty non-negative. since calculations averaging multiple examples dropout penalty always non-negative networks linear nodes. weights biases inputs network rectiﬁed linear units positive rectiﬁed linear units behave linear units dropout penalty non-negative. contrast behavior variety linear models including logistic regression dropout penalty depend value response variable deep networks relus quadratic loss. thus fundamental important respect dropout diﬀers traditional regularizers like weightdecay penalty. input dropout pattern values presented output node dropout. before weights connections directly output node bias output node. indicator variables whether various nodes nodes weights connections output node. value hidden nodes without dropout dropout hidden nodes never negative computes positive values negative input dropped expectation positive. trained networks standard architecture inputs depth width training data studied section input input used nn.stochasticgradient function torch maximum iterations learning rate initialize parameters network clone network produce copy initialization. train dropout probability nodes train without dropout despite fact consistent monotone function. experiment shows even optimization done standard using dropout tends create models negative weights attribute variance reduction eﬀects associated theorem experiment also indicates training dropout sometimes produces fewer negative weights. random initialization hidden relu unit negative weights evaluate inputs weights never updated without dropout. hand extra variance dropout could cause updates negative weights. another non-dropout training could produce negative weights hidden node whose output large many small weights turn negative standard gradient descent step. however dropout half small weights updated. theorem focusses eﬀect dropout global minimum abstracts away kinds initialization optimization eﬀects. experiments regarding sensitivity respect scale input used standard architecture used stochastic gradient using optim package torch learning rate winit cloned three times produce wnone identical starting parameters. trained dropout probability weight decay. trained weight decay dropout. wnone trained without regularization. scale inputs also aﬀects dynamics stochastic gradient descent. small inputs convergence slow large inputs unstable. eﬀects scale inputs inductive bias analyzed paper visible scales optimization done eﬀectively. reasons behind dropout’s surprisingly good performance training deep networks across variety applications somewhat mysterious relatively little existing formal analysis. variety dropout criterion expected loss dropout patterns variance output values dropout patterns contributes expected loss. therefore dropout co-adapt weights order reduce variance. prove happens even simple situations nothing training data justiﬁes negative weights indicates relationship dropout co-adaption simple one. eﬀects dropout deep neural networks rather complicated approximations misleading since dropout penalty non-convex even -layer networks section show dropout enjoy several scale-invariance properties shared weight-decay. perhaps surprising consequence invariances never isolated local minima learning deep network dropout. exploration scale invariance properties warranted contributor dropout’s empirical success exploited facilitate training. contrasting dropout weight-decay simple situations found degenerate all-zero network results regularization parameter threshold. dramatic contrast previous intuition -layer case. dropout viewed regularization method adding data dependent penalty empirical loss undesirable solutions. section shows that unlike generalized linear models case analyzed there dropout penalty deeper networks negative depends labels training data thus behaves unlike regularizers. hand dropout penalty grow exponentially depth network thus better reﬂect complexity underlying model space regularization. paper uncovers number dropout’s interesting fundamental properties using formal analysis simple cases. however eﬀects using dropout training deep networks subtle complex hope paper lays foundation promote formal analysis dropout’s properties behavior.", "year": 2016}