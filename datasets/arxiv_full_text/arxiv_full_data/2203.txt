{"title": "Emergence of Invariance and Disentangling in Deep Representations", "tag": ["cs.LG", "cs.AI", "stat.ML"], "abstract": "Using established principles from Information Theory and Statistics, we show that in a deep neural network invariance to nuisance factors is equivalent to information minimality of the learned representation, and that stacking layers and injecting noise during training naturally bias the network towards learning invariant representations. We then show that, in order to avoid memorization, we need to limit the quantity of information stored in the weights, which leads to a novel usage of the Information Bottleneck Lagrangian on the weights as a learning criterion. This also has an alternative interpretation as minimizing a PAC-Bayesian bound on the test error. Finally, we exploit a duality between weights and activations induced by the architecture, to show that the information in the weights bounds the minimality and Total Correlation of the layers, therefore showing that regularizing the weights explicitly or implicitly, using SGD, not only helps avoid overfitting, but also fosters invariance and disentangling of the learned representation. The theory also enables predicting sharp phase transitions between underfitting and overfitting random labels at precise information values, and sheds light on the relation between the geometry of the loss function, in particular so-called \"flat minima,\" and generalization.", "text": "using established principles information theory statistics show deep neural network invariance nuisance factors equivalent information minimality learned representation stacking layers injecting noise training naturally bias network towards learning invariant representations. show that order avoid memorization need limit quantity information stored weights leads novel usage information bottleneck lagrangian weights learning criterion. also alternative interpretation minimizing pac-bayesian bound test error. finally exploit duality weights activations induced architecture show information weights bounds minimality total correlation layers therefore showing regularizing weights explicitly implicitly using helps avoid overﬁtting also fosters invariance disentangling learned representation. theory also enables predicting sharp phase transitions underﬁtting overﬁtting random labels precise information values sheds light relation geometry loss function particular so-called minima generalization. keywords deep learning; neural network; representation; minima; information bottleneck; overﬁtting; generalization; suﬃciency; minimality; sensitivity; information complexity; stochastic gradient descent; regularization; total correlation; pac-bayes eﬀorts understand empirical success deep learning followed main lines representation learning optimization. optimization deep network treated black-box family functions want parameters yield good generalization. aside diﬃculties non-convexity loss function fact deep networks heavily over-parametrized presents theoretical challenge bias-variance tradeoﬀ suggests overﬁt; even without explicit regularization perform remarkably well practice. recent work suggests related figure alexnet model zhang achieves high accuracy even trained random labels cifar-. using lagrangian limit information weights leads sharp transition underﬁtting predicted theory overﬁt network needs memorize dataset information needed grows linearly. real labels information suﬃcient data without overﬁtting saturates value depends dataset somewhat independent number samples. representation learning hand focuses properties representation learned layers network remaining largely agnostic particular optimization process used. fact eﬀectiveness deep learning often ascribed ability deep networks learn representations insensitive nuisances translations rotations occlusions also disentangled separating factors high-dimensional space data careful engineering architecture plays important role achieving insensitivity simple geometric nuisance transformations like translations small deformations; however complex dataset-speciﬁc nuisances still need learned. poses riddle neither architecture loss function explicitly enforce invariance disentangling properties emerge consistently deep networks trained simple generic optimization? work address questions establishing information theoretic connections concepts. particular show that suﬃcient representation data invariant minimal i.e. contains smallest amount information; information representation along total correlation tightly bounded information weights retain dataset; information weights related overﬁtting minima pac-bayes upper-bound test error controlled implicit explicit regularfinally perform several experiments realistic architectures datasets validate assumptions underlying claims. particular show using information weights measure complexity deep neural network rather number parameters leads sharp theoretically predicted transition overﬁtting underﬁtting regimes random labels shedding light questions zhang information bottleneck introduced tishby generalization minimal suﬃcient statistics allows trading ﬁdelity complexity representation. particular introduction lagrangian reduces ﬁnding minimal suﬃcient representation data variational optimization problem. later tishby zaslavsky shwartz-ziv tishby advocated using information bottleneck test data activations deep neural network study suﬃciency minimality resulting representation. parallel developments lagrangian used regularized loss function learning representation leading information theoretic regularizers paper introduce lagrangian weights network training data opposed traditional activations test datum. show seen generalization variational inference related hinton camp special case general pac-bayes framework used compute high-probability upper-bounds test error network. main contributions show that particular duality induced architecture deep networks minimality weights learned representation connected particular show networks regularized either explicitly implicitly biased toward learning invariant disentangled representations. theory develop could used explain phenomena described small-scale experiments shwartz-ziv tishby whereby initial fast convergence related suﬃciency representation later asymptotic phase related compression activations seemingly agnostic property learned representation show minimize information weights compression activations follows corollary bounds. practical implementation theory real large scale problems made possible advances stochastic gradient variational bayes representations learned deep networks observed insensitive complex nuisance transformations data. certain extent attributed architecture. instance convolutional layers max-pooling shown yield insensitivity local group transformations complex dataset-speciﬁc particular non-local non-group transformations insensitivity must acquired part learning process rather coded architecture. show suﬃcient representation maximally insensitive nuisances minimal allowing prove regularized network naturally biased toward learning invariant representations data. eﬀorts develop theoretical framework representation learning include tishby zaslavsky shwartz-ziv tishby consider representations stochastic functions approximate minimal suﬃcient statistics diﬀerent bruna mallat construct representations operators invertible limit exhibiting reduced sensitivity small perturbations data. deterministic constructions based assumption underlying data spatially stationary therefore work best textures visual data subject occlusions scaling nuisances. anselmi develop theory invariance locally compact groups construct maximal invariants like sundaramoorthi that however assume nuisances inﬁnitedimensional groups eﬀorts limited assumption nuisances group structure. assumptions relaxed soatto chiuso advocate seeking suﬃcient invariants rather maximal ones. advance approach unlike prior work suﬃcient dimensionality reduction seek minimize dimension representation rather information content prescribed theory. recent advances deep learning provide computationally viable methods train high-dimensional models predict quantify observed phenomena convergence minima transitions overﬁtting underﬁtting random labels thus bringing theory fruition. theoretical eﬀorts focus complexity considerations explain success deep networks ways statistical computational eﬃciency disentanglement often-cited property deep networks seldom formalized studied analytically although steeg galstyan suggested studying using total correlation representation also known multi-variate mutual information also use. following suggestions david mcallester also explored relations theory pac-bayes framework show theory also derived pac-bayes framework without resorting information quantities information bottleneck thus providing independent alternative derivation theoretically rigorous computationally easy upper-bound optimal loss function. preliminaries training dataset comprised independent identically distributed samples unknown distribution parametrized following bayesian approach also consider random variable sampled unknown measured labels associated data; test marginal distribution components recall divergence distribution always non-negative zero equal. particular zero components independent case disentangled. often following identity equivalently minimal smallest among suﬃcient representations. study trade-oﬀ suﬃciency minimality tishby introduces information bottleneck lagrangian nuisance random variable aﬀects observed data informative task trying solve. formally random variable nuisance task equivalently similarly representation invariant nuisance strictly invariant minimizes among suﬃcient representations representation maximally insensitive simplify inference process instead working directly observed high dimensional data want representation captures exposes relevant information task ideally representation suﬃcient task i.e. information lost; among suﬃcient representations minimal i.e. minimized retains little possible simplifying role classiﬁer; ﬁnally invariant eﬀect nuisances ﬁnal classiﬁer overﬁt spurious correlations present training dataset nuisances labels representation exists would unique since bijective mapping preserves properties. advantage make representation maximally disentangled i.e. minimal. simpliﬁes classiﬁer rule since information present higher-order correlations components inferring representation satisﬁes properties seem daunting. however section show need enforce suﬃciency minimality invariance disentanglement follow naturally thanks stacking noisy layers computation deep networks. show suﬃciency minimality learned representation also promoted easily implicit explicit regularization training process. amount need task provides network automatically learn invariance complex nuisances complementary invariance imposed architecture. speciﬁcally enforcing minimality explicitly hence invariance lagrangian. remarkably lagrangian seen standard cross-entropy loss plus regularizer promotes invariance. fact without proof implicitly used achille soatto also provides eﬃcient algorithm perform optimization. alemi also propose related algorithm shows improved resistance adversarial nuisances. addition modifying cost function invariance also fostered choice architecture notice however corollary simply imply layers merrier assumes successfully trained network becomes increasingly diﬃcult size grows. also note architectures resnets layers necessarily form markov chain skip connections; however blocks still section data distribution randomly sample dataset parameter distribution also assumed random variable prior distribution example fairly general generative model natural images parameters model generated dataset. consider deep neural network implements input class distribution full generality following main problems optimizing cross-entropy loss notoriously prone overﬁtting. fact easily minimize even completely random labels figure fact that somehow highly overparametrized functions manage generalize trained real labels puzzled theoreticians prompted wonder whether inconsistent intuitive interpretation bias-variance tradeoﬀ theorem whereby unregularized complex models overﬁt wildly. however show next inconsistency measures complexity information content dimensionality weights. ﬁrst term right-hand side relates intrinsic error would commit predicting labels even knew underlying data distribution second term measures much information dataset parameter captured weights third term relates eﬃciency model class functions respect loss optimized. last negative term relates much information labels uninformative underlying data distribution memorized weights. unfortunately without implicit explicit note that somewhat related denote output distribution weights training choice algorithm dataset bayesian posterior weights given dataset would denoted dirac delta point regularization network minimize cross-entropy loss maximizing last term i.e. memorizing dataset yields poor generalization. prevent network this neutralize eﬀect negative particular explore alternate paths lead equivalent conclusions diﬀerent premises assumptions case pac-bayes upper-bound other lagrangian upper-bound latter approach notice successfully learn distribution need memorize information latent parameters need bounded constant. hand overﬁt term needs grow linearly number training samples exploit fact prevent overﬁtting adding lagrange multiplier make amount information constant respect leading regularized loss function remarkably lagrangian interpreted function rather lagrangian best knowledge novel role information bottleneck thus conﬁned characterizing activations network learning criterion. equation seen generalization suggestions literature also seen generalization variational learning. particular case studied kingma ﬁrst showed generalization dropout called variational dropout could used conjunction reparametrization trick kingma welling minimize loss eﬃciently. measure eﬀective complexity network rather number parameters merely upper bound complexity. show experiments allows recover version bias-variance tradeoﬀ networks lower information complexity underﬁt data networks higher complexity overﬁt. contrast clear relationship number parameters overﬁtting moreover random labels information complexity allows precisely predict overﬁtting underﬁtting behavior network ﬁxed distribution approximates real marginal distribution lagrangian weights seen generally intractable special case gives sharpest upper-bound desired loss family losses. modeling assumptions. denote vector containing parameters network denote weight matrix layer assume improper loguniform prior c/|wi|. notice scale-invariant prior trained network. then parametrize weight distribution training remark simplify exposition since optimization unaﬀected additive constant following abuse notation neklyudov also suggest principled dealing arbitrary constant using proper log-uniform prior. network memorizing dataset thus avoid overﬁtting also conﬁrm empirically section however real networks commonly trained regularizer thus seemingly undermining theory. however claim that even hochreiter schmidhuber intuitively since loss landscape locally weights stored lower precision without incurring excessive inference error. consequence previous claims minima better generalization properties section associated representation data invariant disentangled. completeness derive precise relationship ﬂatness information content based model. next section prove main results networks information weights realize invariant disentangled representations. therefore invariance disentanglement emerge naturally training network implicit explicit regularization related minima. theorems tells whenever decrease information weights either explicit regularization implicit regularization automatically improve minimality hence theorem invariance disentanglement learner representation. particular obtain corollary biased toward learning invariant disentangled representations data. using markov property layers easily extend bound multiple layers remark bound theorem tight bound multilayer case needs expected reducing information weights creates bottleneck know much information actually bottleneck. often ﬁnal layers information through initial layers drop most. section show using pac-bayes bound arrive regularized loss function obtained using information bottleneck without need approximation. theorem mcallester ﬁxed sharpest pac-bayes upper-bound test error obtained case reduces lagrangian weights. lagrangian weights considered special case pac-bayes giving sharpest bound. unfortunately noticed section joint marginal weights tractable. circumvent problem instead consider sharpest pac-bayes upper-bound obtained using tractable factorized prior obtained product marginals leading last note recall modeling assumptions marginal assumed improper log-uniform distribution. advantage noninformative prior closely matches real marginal weights network also disadvantage deﬁned modulo additive constant therefore making bound test error vacuous model. problem computing vacuous bounds real deep neural networks addressed dziugaite figure measure quantity information weights necessary overﬁt vary percentage corrupted labels settings figure increasingly random labels network needs memorize information weights; increase needed entirely random labels magnitude size label pointed zhang standard convolutional neural network trained cifar- random labels network able perfectly. easily explained framework simply means network complex enough overﬁt show here steep price terms information complexity weights hand information regularization prevents overﬁtting exactly predicted theory. regardless dataset size completely prevent memorization hence overﬁtting overﬁtting possible. empirical behavior network shown figure closely follows prediction. real labels model still able overﬁt importantly large interval model trained real data real labels without excessive overﬁtting figure measure quantity information weights diﬀerent levels corruption labels. this network able overﬁt figure training samples generated adding nuisance clutter mnist dataset. reducing information weights makes representation learned digit classiﬁer increasingly invariant nuisances decreases) suﬃciency retained constant). expected smaller similar behavior theoretical bound theorem generate samples distributions generate data train discriminator. intuitively discriminator able classify means insensitive changes precisely since optimal discriminator test algorithm random occlusion nuisances mnist digits case nuisance occlusion pattern observed data occluded digit. various values train classiﬁer data order learn representation representation obtained train discriminator described compute resulting approximation results figure show decreasing information weights makes representation increasingly insensitive even cannot generate data aﬀected nuisances like previous section still visualize information content learn nuisances discarded representation. given representation want learn sample test algorithm train representation classify binary attributes celeba face dataset yang loss function train network reconstruct input image representation results generates samples increasingly random backgrounds hair style retaining facial features. words representation increasingly insensitive nuisances aﬀecting data information pertaining task retained reconstruction work presented bounds tight connect amount information weights amount information activations invariance property network geometry residual loss. results leverage structure deep networks particular multiplicative action weights markov property layers. leads surprising result reducing information information regarding thus reconstructed image close background included. increasing decreases information weighs thus representation becomes invariant nuisances reconstructed image matches important details preserved background hair style nuisances generated anew. notion representation intrinsically stochastic. simpliﬁes computation well derivation information-based relations. however note even start deterministic representation theorem gives converting stochastic representation whose quality depends ﬂatness minimum. theory leverages heavily information bottleneck principle dates back decades recently under-utilized lack tools eﬃciently approximate optimize information bottleneck lagrangian. work focuses inference learning optimal representations seek data speciﬁc task. guarantee good outcome since data processing inequality representation easier ultimately informative data themselves. orthogonal equally interesting issue informative data possible subject active learning experiment design perceptual exploration. labels. dataset normalized using global channel-wise mean variance additional data augmentation performed. exact structure network table common practice batch normalization relu nonlinearities except ﬁrst layer. train learning rates pick best performing network two. generally found higher learning rate needed overﬁt number training samples small lower learning rate needed larger train momentum epochs reducing learning rate factor every epochs. large batch-size minimize noise coming sgd. weight decay regularization methods used. ﬁnal plot obtained triangulating convex envelope data points interpolating value resulting simplexes. outside convex envelope value obtained inpainting. digits mnist dataset level train classiﬁer table dataset. weights layers excluding ﬁrst last threated random variable multiplicative gaussian noise optimized using local reparameterization trick kingma last convolutional layer classiﬁcation representation lows inputs nuisance pattern image containing random occluding squares representation obtained classiﬁer. first preprocess using following network conv conv conv conv conv conv conv block convolution followed batch normalization relu. then concatenate result along recover binary attributes associated image. classiﬁer network table following modiﬁcations exponential linear units activations instead relu since invertible activations generally perform better training divide number ﬁlters experiment gaussian multiplicative noise slightly stable training stabilize training found useful scale reconstruction error term loss function slowly increase weight reconstruction error desired value training. expressed closed form arbitrary constant matter optimization process principled approach problem uses proper log-uniform prior). another possibility suggested kingma gaussian multiplicative noise mean unfortunately struction claim notice that since exists measurable isomorphism assume withloss generality case deﬁnition take cumulative distribution function composed i.i.d. samples unknown distribution output training algorithm dataset distribution weights. putting everything together well-deﬁned joint distribution ppq. random variable tuple random variables. speciﬁed assumed cross-entropy computed respect unknown underlying data distribution similarly conditional cross-entropy deﬁned conclude want approximate expectation logarithm using taylor expansion ﬁrst need check variance term inside logarithm need bound kurtosis. fact since kurtosis bounded constant well-known overﬁtting relates eﬀective number degrees freedom measured number ways information weights? information weights indeed particular choice measure complexity. nice aspect plays central role many diﬀerent frameworks correlates well performance real network. compute nuclear norm hessian? sounds expensive need show that optimization algorithm happens minima automatically limits information weights promotes good generalization. however wanted approximate trace hessian could done linear time dataset random variable realization theory almost identical case ﬁxed dataset randomly sampled dataset. consider case randomly sampled dataset develop theory since expressions simplify slightly easier interpret practical applications assume ﬁxed training given. algorithm returns log-uniform prior basic pacbayes bound that however gives vacuous generalization bound improper prior. generalization bound could stated terms length ﬁnite interval approximation log-uniform prior. indeed case. however limit interval length going inﬁnity divergence would still inﬁnite optimization would slightly complex. simpler option generalization-bound would gaussian prior posterior dziugaite however computing good pac-bayes upper-bound outside scope paper non-informative scale invariant prior matches empirical behaviour networks simpliﬁes theoretical analysis. course minimal representation invariant nuisance variation since that’s means minimal task. result intuitive some compression invariance thing unaware existing proof claim special tasks like clustering small perturbations.", "year": 2017}