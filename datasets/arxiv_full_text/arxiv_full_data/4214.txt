{"title": "CLAD: A Complex and Long Activities Dataset with Rich Crowdsourced  Annotations", "tag": ["cs.CV", "cs.AI"], "abstract": "This paper introduces a novel activity dataset which exhibits real-life and diverse scenarios of complex, temporally-extended human activities and actions. The dataset presents a set of videos of actors performing everyday activities in a natural and unscripted manner. The dataset was recorded using a static Kinect 2 sensor which is commonly used on many robotic platforms. The dataset comprises of RGB-D images, point cloud data, automatically generated skeleton tracks in addition to crowdsourced annotations. Furthermore, we also describe the methodology used to acquire annotations through crowdsourcing. Finally some activity recognition benchmarks are presented using current state-of-the-art techniques. We believe that this dataset is particularly suitable as a testbed for activity recognition research but it can also be applicable for other common tasks in robotics/computer vision research such as object detection and human skeleton tracking.", "text": "abstract paper introduces novel activity dataset exhibits real-life diverse scenarios complex temporallyextended human activities actions. dataset presents videos actors performing everyday activities natural unscripted manner. dataset recorded using static kinect sensor commonly used many robotic platforms. dataset comprises rgb-d images point cloud data automatically generated skeleton tracks addition crowdsourced annotations. furthermore also describe methodology used acquire annotations crowdsourcing. finally activity recognition benchmarks presented using current state-of-the-art techniques. believe dataset particularly suitable testbed activity recognition research also applicable common tasks robotics/computer vision research object detection human skeleton tracking. artiﬁcial intelligence system embedded human environment robot required perform activity recognition order fully comprehend environment could take appropriate steps make decisions gain utility. recognisable/human activities largely vary complexity length expressiveness short primitive actions lasting seconds ‘pick’ ‘wave’ ‘approach’ etc. longer activities lasting minutes hours days ‘dinner restaurant’ ‘surgery hospital’ ‘studying exams’ etc. currently research human activity recognition focused recognising relatively short activities. though steady shift towards slightly longer activity recognition still need standardised datasets present longer complex activities. service robotics domain requirement become imperative tackle. fully autonomous system capable autonomously running days months amongst humans example strands project hawes needs equipped capability recognising long-term activities last hours days using embedded sensors. however popular activity datasets e.g. opportunity activity dataset roggen offer sensor data multitude inertial sensors either body worn installed perspective point ceiling corners rooms whose outputs normally available embedded robot general environments. natural assume robot rely primarily video data onboard cameras activity analysis recognition settings. dataset recorded perspective mobile robot using video rgbd camera commonly found sensor robot aimed promote research long-term complex activities span longer periods time previous datasets. biggest challenges gathering datasets consisting long activity videos comes challenge accurate annotation timely cost effective manner. therefore provide mechanism obtaining annotations effectively crowdsourcing. crowdsourced annotations achieved worldwide pool non-expert users independently annotate samples videos objective unbiased manner. generates annotations reﬂect aspects true human understanding activities within video adds complexity unconstrained natural language annotations exhibit large variability describing videos. remainder paper organised follows section describe related datasets presently available. then section provide detailed description presented clad dataset. section describe ground-truth collection process ﬁnally conclude section figure sample images dataset. column shows different recordings single high-level activity seen high variability performance high-level activities instances. activity recognition popular research direction robotics. many activity datasets openly available activity recognition research ranging datasets consisting simple repetitive action jumping walking etc. complex activities cooking food cleaning microwave etc. available datasets categorised three categories heterogeneous actions speciﬁc actions others chaquet dataset falls ’activities daily living’ subcategory ’speciﬁc actions category’. early activity datasets weizmann datasets zelnik-manor irani blank captured many instances various activities scripted recorded controlled environment would rarely observed naturally. natural environment presented dataset schuldt caviar dataset activities presented datasets limited heterogeneous repetitive motion walking jumping running etc. aiming model repetitive nature short activities. datasets soomro hollywood- dataset marszałek ﬁrst datasets aimed model everyday activities natural setting eating hugging kissing etc. large number naturally recorded instances. datasets mostly generated movies youtube videos. however videos datasets though longer previous datasets still short activities video comprised basic activity thus temporal segmentation assumed. duckworth collected dataset comprising long videos human activities recorded mobile robot kitchen setting. videos continuous comprised multiple activities. however annotations dataset segmented short actions pick down pour etc. cornell activity datasets koppula sung presented challenging datasets consisting longer videos complex activities stacking boxes taking medicine etc. though benchmarking dataset shortcomings. videos dataset consisted single actor annotations provided limited levels granularity highlevel activities video sub-level actions within high-level activity video. mentioned datasets annotations activity labels consistent extracted pre-set label lists collected welldeﬁned rules place. clad dataset presented paper created particular focus address shortcomings. dataset presented consists much longer activities example service restaurant consisting multiple actors contains deep hierarchy activities crowd-sourced freely descriptive annotation i.e. annotators given freedom describe activities using words. given advancement towards long-running autonomous robots gathering longer videos activity data using crowdsourcing elicit annotations becoming popular therefore annotations included dataset. knowledge dataset presents multiple challenges research community namely modelling longer naturally occurring variable activities many levels granularity well semantic analysis extraction information crowdsourced annotations. recording setup dataset comprises videos recorded high resolution pixels using microsoft kinect sensor. sensor installed height approximately feet ground. view point simulate commonly used robot tiago scitos etc. would normally patrolling environment. approximately objects relevant activity available subjects use. five subjects employed scenes. subjects told top-level activity free objects available task. subjects involved scene. subjects carefully selected outside faculty computer science research experience order capture natural acting activities unbiased research knowledge. minimal instructions given subjects requested scenes; fact encouraged variable random performing task different recordings. allowed natural unbiased data capture activities exhibiting high variation. natural setting actual restaurant variety practical ethical reasons videos recorded research lab; short coming dataset otherwise tries capture activities natural possible. every effort made minimise inﬂuence environment actors clearing neutralising irrelevant items possible. dataset content dataset comprises videos everyday activities ranging minutes length. toplevel activity occurs within full videos however numerous sub-level activities occur entire video. top-level activities comprise three natural scenes breakfast lunch restaurant working ofﬁce. scenarios chosen normally occurring home restaurant ofﬁce locations likely robot deployed sample images dataset shown ﬁgure recordings consists following data meta-data video low-resolution compressed video recording. images uncompressed high deﬁnition images recording image labelled kinect {frame number}.{format} resolution pixels. denotes wildcard variables names. images provided .png .jpg formats. skeletons state-of-the-art skeleton trackers used generate skeleton tracks subjects recording provided skeletons ﬁles recording. skeleton contains ﬁles corresponding different skeleton trackers used namely aachen. skeleton tracker consists ﬁles labelled person {person’s id}. depending number subjects video person would dedicated skeleton tracks identiﬁed person’s person {person ﬁles labelled frame {frame number}.txt. ﬁles generated frame contain list coordinates deﬁne location joints skeleton onto image frame following order head neck r-shoulder r-elbow rhand l-shoulder l-elbow l-hand r-hip r-knee r-foot l-hip l-knee l-foot torso refer right left. point cloud folder consists point cloud ﬁles labelled {frame number}. available on-line acquired upon request. uploaded large sizes. annotations folder contains annotations recording acquired crowdsourcing. since multiple annotators employed video annotation ﬁles split annotator annotations folder therefore contains ﬁles labelled annot{annotator’s id}. ﬁles contains list annotations corresponds format {subject performing activity} {activity label/description} {starting frame} {ending frame}. ﬁles simple ﬁles easy quick parse use. details annotations gathered provided section moreover involved subjects.txt speciﬁes unique actors performing activity scene. list unique numbers corresponding actor dataset. dataset annotations annotation videos involves identiﬁcation activities occurring within video along temporal boundary traditionally task performed manually usually experts hold domain knowledge. task expensive timeconsuming case domain knowledgeable experts result biased annotations order reduce cost time taken annotate activities crowdsourcing platforms increasingly gaining popularity. crowdsourcing platform offer large pool world-wide workers able perform human intelligent task annotation video small ﬁnancial incentive. large datasets long videos case dataset suitable option attain annotations cost-effective efﬁcient manner. furthermore since many annotators employed annotate single video helped ensure rich varied perspective latent activities reﬂected annotations. single person usually tends annotate videos sequentially activity temporal sequence. multiple annotators increased degree obtained annotations multiple level temporal granualirty. combining annotations different workers provides richer annotation video. however many challenges design decisions taken developing system elicit annotations using crowdsourcing deciding payment amount making clear interface workers perform task detection removal spam non-diligent workers etc. overcoming challenges factors greatly affects ability obtain accurate annotations shown nguyendinh describe design process next. interface design success crowd-sourced annotation system crucial easy-to-use interface provided workers submit annotations through. image interface shown ﬁgure interface divided following parts ease description instructions part simply provides instructions worker required interface. instructions provided interface simply worded since annotators native english speakers. also top-level scenario activity video mentioned instructions given worker order obtain maximally unbiased annotations. video player easy video player frame skipping control provided along current frame number display. allows worker tune temporal boundaries identiﬁed activities. veriﬁcation questions important aspect interface qualiﬁcation questions. order ﬁlter workers inputting spam data tend form random character inputs included veriﬁcation questions. questions objective randomly placed preanswered. boolean question numeric question used. questions enforce user watch entire video answering. example sample boolean question ’did subject teapot?’ sample numeric question ’how many times subject newspaper pages?’. numeric question answers within range pre-speciﬁed? worker failed answer correctly would disqualiﬁed continuing task. experimenting found inclusion veriﬁcation questions helped discouraging non-diligent user trying cheat task. annotation submission form section allows user input start frames activity activity label actor/s performing activity. workers allowed type frame numbers rather button automatically insert ﬁelds. done minimise erroneous input frame number’s numeric ﬁelds. important design decision made allow user freely enter activity label input minor restrictions alphabetical words maximum activity label disallow long essay-like descriptions sentences produce concise short labels activities. example ’consuming coffee’ instead ’the subject drinking coffee’. common preset list labels workers choose avoid ambiguity variability natural language time limits descriptive power worker. chosen allow workers full control choice words describe identiﬁed activity ensure annotations captured expressive maximum time minutes following linear relationship. ’reward’ amount computed maximum task frames. amount split three parts passing veriﬁcation test submitting minimum number required annotations quality labels start times accuracy manually checked randomly selected labels iii) identiﬁcation parallel overlapping activities. furthermore bonuses frame long video awarded exceptional work additional motivation workers perform well. similar assignment duration reward linearly adjusted depending length video frames. given price model ensured workers sufﬁciently motivated perform task effectively within reasonable amount time. conclusion paper presented activity dataset naturally occurring daily activities might observed mobile robots. dataset accessed https// doi.org/./. presented activity annotations gathered crowdsourcing. believe dataset useful robotics computer vision research. dataset presents challenges long-term autonomous robots systems comprehend activities observe. future plan augment dataset object tracks well activities involve subjects interacting boasts higher complexity. also plan record videos real-life setting real restaurant real ofﬁce. acknowledge colleagues school computing robotics schools university strands project consortium contributions. acknowledge ﬁnancial support provided project", "year": 2017}