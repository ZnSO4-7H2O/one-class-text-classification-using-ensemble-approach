{"title": "An Online Learning-based Framework for Tracking", "tag": ["cs.LG", "cs.AI", "stat.ML"], "abstract": "We study the tracking problem, namely, estimating the hidden state of an object over time, from unreliable and noisy measurements. The standard framework for the tracking problem is the generative framework, which is the basis of solutions such as the Bayesian algorithm and its approximation, the particle filters. However, these solutions can be very sensitive to model mismatches. In this paper, motivated by online learning, we introduce a new framework for tracking. We provide an efficient tracking algorithm for this framework. We provide experimental results comparing our algorithm to the Bayesian algorithm on simulated data. Our experiments show that when there are slight model mismatches, our algorithm outperforms the Bayesian algorithm.", "text": "study tracking problem namely estimating hidden state object time unreliable noisy measurements. standard framework tracking problem generative framework basis solutions bayesian algorithm approximation particle ﬁlters. however solutions sensitive model mismatches. paper motivated online learning introduce framework tracking. provide eﬃcient tracking algorithm framework. provide experimental results comparing algorithm bayesian algorithm simulated data. experiments show slight model mismatches algorithm outperforms bayesian algorithm. study tracking problem numerous applications control ﬁnance. tracking given noisy measurements time problem estimate hidden state object. challenge reliably combining measurements multiple time steps prior knowledge state dynamics goal tracking produce estimates close true states possible. popular solutions tracking problem kalman ﬁlter particle ﬁlter numerous extensions variations based generative framework tracking problem. suppose want track state object time given measurement vectors times generative approach think state measurements random variables. represent knowledge regarding dynamics states using transition process pr|x) knowledge regarding relationship states observations measurement process pr|x). then given observations goal tracking estimate hidden state sequence done calculating likelihood state sequence using estimate either sequence highest posterior probability expected value state respect posterior distribution practice uses particle ﬁlters approximation bayesian algorithm. problem generative framework practice diﬃcult precisely determine distributions measurements. bayesian algorithm sensitive model mismatches using model diﬀerent generating measurements lead large divergence estimated states true states. address this introduce online learning-based framework tracking. framework given state sequences paths state space; instead assuming observations generated measurement model path think path mechanism explaining observations. emphasize done regardless observations generated. suppose path proposed explanation observations measure quality path using predeﬁned loss function depends measurements tracking algorithm selects path taking weighted average best paths according past observations. theoretical guarantee provide loss path selected algorithm online tracking algorithm close path minimum loss; here loss measured according loss function supplied algorithm. guarantees analogous competitive analysis used online learning important note guarantees hold uniformly sequence observations regardless probabilistic assumptions. next contribution provide online learningbased algorithm tracking framework. algorithm based normalhedge general online learning algorithm. normalhedge instantiated loss function. supplied bounded loss function guaranteed produce path loss close path minimum loss candidate paths. computationally ineﬃcient directly apply normalhedge tracking derive sequential monte carlo approximation normalhedge show approximation eﬃcient. demonstrate robustness tracking algorithm perform simulations simple onedimensional tracking problem. evaluate tracking performance measuring average distance between states estimated algorithms true hidden states. instantiate algorithm simple clipped loss function. simulations show algorithm consistently outperforms bayesian algorithm high measurement noise wide range levels model mismatch. ﬁnally note bayesian algorithm also interpreted online learning-based framework. particular loss path negative log-likelihood measurement model then bayesian algorithm shown produce path log-loss close path minimum log-loss. tempted think tracking solution follows approach; however point paper loss functions diﬀerent log-loss particular show scenario using loss functions produces better tracking performance bayesian algorithm rest paper organized follows. section explain detail explanatory model tracking. section present normalhedge tracking algorithm based. section provide tracking algorithm. section presents experimental comparison algorithm bayesian algorithm simulated data. finally discuss related work section section describe detail setup tracking problem online learning-based framework tracking. tracking time given input measurements goal estimate hidden state object using measurements knowledge state dynamics. path words dynamics loss time depends states time common express knowledge dynamics terms dynamics function deﬁned paths small dynamics loss. example consider object moving constant velocity. here state position velocity would interested paths cases dynamics loss typically growing function distance second component loss function observation loss given path measurements observation loss function quantiﬁes well path explains measurements. again simplicity restrict loss functions written words observation loss path time depends state time measurements time total loss path dynamics observation losses. note loss path depends particular path measurements true hidden state. result loss path always computed algorithm given time. normalhedge algorithm action time denote normalhedge weight assigned action time time deﬁne regret algorithm action diﬀerence cumulative loss algorithm cumulative loss action. also real number notation denote max. normalhedge algorithm presented below. performance guarantees normalhedge algorithm stated follows. signiﬁcant advantage using normalhedge online learning algorithms parameters tune achieves performance comparable best performance previous online learning algorithms optimally tuned parameters. discussion section another advantage actions total loss greater total loss algorithm assigned zero weight. since algorithm performs almost well best action scenario actions signiﬁcantly better rest algorithm assign zero weight actions. words support normalhedge weights small property makes easier design approximation schapire cesa-bianchi lugosi time path algorithm assigns weight estimated state time weighted mean states weight state total weight paths state. loss algorithm time weighted loss paths theoretical guarantee look loss algorithm close loss best path hindsight thus small fraction paths loss loss functions successfully capture tracking performance then sequence states estimated algorithm good tracking performance. section describe normalhedge algorithm forms basis tracking algorithm. present normalhedge full generality ﬁrst need describe decision-theoretic framework online learning. problem decision-theoretic online learning follows. round learner access actions; purposes action method provides prediction round. learner maintains distribution actions time time period action suﬀers loss lies bounded range loss witit. note framework general assumption made nature actions distribution losses. goal learner maintain distribution actions cumulative loss time compared cumulative loss action lowest cumulative loss. cases particularly number actions large interested achieving cumulative loss compared \u0001-quantile actions. here \u0001-quantile actions fraction actions lowest cumulative loss. starting seminal work littlestone warmuth problem decision-theoretic online learning well-studied literature common algorithm problem hedge exponential weights assigns action weight exponentially small total loss. paper however consider diﬀerent algorithm normalhedge problem algorithm forms basis tracking algorithm. bayesian averaging algorithm shown variant hedge tracking algorithm speciﬁed algorithm action algorithm path state space however maintain entire path explicitly action; rather state update step algorithm computes xit+ using dynamics function need maintain current state action. recall applying dynamics function ensure path incurs little dynamics loss start actions initially positioned states uniformly distributed uniform weighting actions. round like normalhedge action incurs loss determined current state tracker incurs expected loss determined current weighting actions. using losses update cumulative regrets action. however unlike normalhedge delete actions zero negative regret replace using re-sampling procedure. procedure replaces poorly performing actions actions currently high density regions thereby providing better approximation normalhedge weights. apply normalhedge directly tracking action path state space loss action time loss corresponding path time make normalhedge robust practical setting make small change algorithm instead using cumulative loss discounted cumulative loss. discount parameter discounted cumulative loss action t=t−tit. discounted losses used reinforcement learning well online learning intuitively makes tracking algorithm ﬂexible allows easily recover past mistakes. however direct application normalhedge prohibitively expensive terms computation. consider paths discretization state space cardinality then time actions. take advantage structure loss function formulate weight updates dynamic program; however still expensive update takes time. therefore sequel show derive sequential monte-carlo based approximation normalhedge approximation experiments. observation behind approximation weights actions generated normalhedge algorithm induce distribution states time therefore random sample states round approximate distribution. thus particle ﬁlters approximate posterior density states induced bayesian algorithm tracking algorithm approximates distribution induced states normalhedge tracking. main diﬀerence normalhedge approximation normalhedge always maintains weights actions delete action action list weight falls replace action re-sampling procedure chooses another action currently region state space actions losses. thus spend resources maintaining updating weights actions perform well. another diﬀerence normalhedge tracking algorithm approximation explicitly impose dynamics loss actions. instead re-sampling procedure considers actions dynamics loss. also avoids spending resources actions high dynamics loss anyway. note changes tracking algorithm sampling action proportional weight previous round. choose state randomly ellipsoid around current state selected action; action inherits history selected action current state diﬀerent selected action. latter step makes state distribution smoother previous round supported states actions losses. note resampling procedure samples actions dynamics loss thus algorithm explicitly compute dynamics loss action. simulations consider task tracking object simple one-dimensional state space. evaluate algorithm measure distance between estimated states true states object. experimental setup inspired application tracking faces videos using standard face detector case state location face measurement corresponds score output face detector region current video frame. goal predict location face across several video frames using scores produced detector. detector typically returns high scores several regions around true location face also erroneously produce high scores elsewhere. though cases detection score probabilistic interpretation often diﬃcult accurately characterize distribution noise. parameter represents noisy measurements relative signal parameter represents fraction outliers. experiments vary total number time steps track generative framework dynamics object represented transition model observations represented measurement process thus observations generated according measurement process supplied given observation vectors three different methods estimate true underlying state sequence ﬁrst bayesian algorithm recursively applies bayes’ rule update posterior distribution using transition observation model. posterior distribution maintained location discretization bayesian algorithm actual value used generate observations value obtained tuning measurement vectors generated true state sequence independently generated noise values. prior distribution states assigns probability true value zero elsewhere. second algorithm algorithm described section algorithm parameters parameters also obtained tuning range values also compare algorithm particle ﬁlter uses parameters bayesian algorithm predicts using expected state posterior distribution. algorithm actions particle ﬁlter particles. experiments implementation particle ﬁlter figures show true state states predicted algorithm bayesian algorithm diﬀerent values independent simulations. table summarizes performance algorithms diﬀerent values parameter diﬀerent values noise parameter report average standard deviation rmse true state predicted state. rmse computed state predictions single simulation rmse values averaged independent simulations. experiments show bayesian algorithm performs well supplied correct noise model; however performance degrades rapidly increases becomes poor even hand performance algorithm suﬀer appreciably increases. degradation performance bayesian algorithm even pronounced noise high respect signal particle ﬁlter suﬀers even higher degradation performance poor performance even results indicate bayesian algorithm sensitive model mismatches. hand algorithm equipped clipped-loss function robust model mismatches. particular algorithm provides rmse value even high noise high note degradation performance bayesian algorithm solely model mismatch experiments repeated bayesian algorithm supplied correct likelihood model performs least well better algorithm. moreover bayesian algorithm supplied likelihood model correct distribution correct fraction outliers diﬀerent outlier variance performance bayesian algorithm improves signiﬁcantly incorrect distribution performed additional experiments algorithm understand eﬀect varying parameters details omitted lack space. results indicate performance algorithm depends value high enough actions drawn regions state-space object tracked makes diﬃcult track granularity. actions concentrated current actions were explore enough state space. hand level outliers algorithm appears less performance wide range values. table experimental results. root-mean-squarederrors predicted positions time steps algorithm bayesian algorithm particle ﬁlter reported values averages standard deviations simulations. sub-optimality bayesian algorithm model mismatch investigated contexts classiﬁcation view bayesian algorithm online learning algorithm log-loss well-known various communities including information theory computational kakade work look beyond bayesian algorithm log-loss consider loss functions algorithms appropriate task. also work tracking online learning literature method uses diﬀerent class actions tracking framework works. algorithm considers class actions paths switch states ﬁxed number figure predicted paths simulations blue lines correspond algorithm lines correspond bayesian algorithm dashed black line represents true states. times. moreover algorithm treats switches states equally therefore fails take advantage prior knowledge state dynamics. contrast take account prior knowledge using dynamics loss sequences approximately following expected dynamics lower loss result work sophisticated state transition dynamics methods. paper introduce framework tracking based online learning. propose algorithm tracking framework deviates signiﬁcantly bayesian approach. experimental results show algorithm signiﬁcantly outperforms bayesian algorithm observations generated distribution deviating slightly model supplied bayesian algorithm. work reveals interesting connection decision theoretic online learning bayesian ﬁltering. authors would like thank nando freitas helpful comments. part work done part center ucsd. research support work provided grants iis- would like thank calit- support. experimental results made possible support ucsd fwgrid project research infrastructure grant number eia-.", "year": 2012}