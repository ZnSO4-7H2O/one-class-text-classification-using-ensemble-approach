{"title": "Learning deep representation of multityped objects and tasks", "tag": ["stat.ML", "cs.CV", "cs.LG"], "abstract": "We introduce a deep multitask architecture to integrate multityped representations of multimodal objects. This multitype exposition is less abstract than the multimodal characterization, but more machine-friendly, and thus is more precise to model. For example, an image can be described by multiple visual views, which can be in the forms of bag-of-words (counts) or color/texture histograms (real-valued). At the same time, the image may have several social tags, which are best described using a sparse binary vector. Our deep model takes as input multiple type-specific features, narrows the cross-modality semantic gaps, learns cross-type correlation, and produces a high-level homogeneous representation. At the same time, the model supports heterogeneously typed tasks. We demonstrate the capacity of the model on two applications: social image retrieval and multiple concept prediction. The deep architecture produces more compact representation, naturally integrates multiviews and multimodalities, exploits better side information, and most importantly, performs competitively against baselines.", "text": "introduce deep multitask architecture integrate multityped representations multimodal objects. multitype exposition less abstract multimodal characterization machine-friendly thus precise model. example image described multiple visual views forms bag-of-words color/texture histograms time image several social tags best described using sparse binary vector. deep model takes input multiple type-speciﬁc features narrows cross-modality semantic gaps learns cross-type correlation produces high-level homogeneous representation. time model supports heterogeneously typed tasks. demonstrate capacity model applications social image retrieval multiple concept prediction. deep architecture produces compact representation naturally integrates multiviews multimodalities exploits better side information importantly performs competitively baselines. multimedia objects instantly command attention. notoriously difﬁcult model. multimedia objects require fusing multiple modalities distinct characteristics wide semantic gaps. online image example could associated human-level semantics captions tags comments sentiments surrounding context. image itself however pixels colors arranged grid machine-level representation construct meaningful abstraction visual image represented multiple ways including several histograms color edge texture; visual words common approach learning multiple representations concatenate features form long vector assuming representations equally informative. likely cause problems several reasons. first high variation dimensionality scales types second modalities different correlation structures warrant separate modeling single modality tags leaves snail slow evening movement animal crust nikon srilanka beautiful asiasociety image photo interesting green mail wait ambition colour depth bokeh bird nikon srilanka beautiful asiasociety image photo interesting photography sunbird purplerumpedsunbird branch stance wild garden sunrise newyear nikon srilanka beautiful asiasociety morning leave leaves horizon hospital sunspots badulla year rise rising figure flickr images captions tags comments groups. visual modality multiple representations including variety histograms visual words. photos uditha wickramanayaka. also admit multiviews hence multiple types. visual modality histogram real-valued vector visual words discrete word counts. thus effective modeling also account type-speciﬁc properties. type modeling however largely missing prior multimodal research better address multimodal differences correlation structures necessary recognize intra-mode correlation often much higher inter-mode correlation suggests step fusion. translated typed representations need ﬁrst decorrelate intratype data capture inter-type inter-dependencies. modeling multityped multimodality essential capture intra/inter-type correlation structure care must paid tasks hand. representations handcrafted independent future tasks likely suboptimal. suggests task-informed representation learning. putting together argue successful approach work across tasks modalities semantic levels coding types. paper introduces bottom-up deep learning approach tackle challenges. deep architectures offer natural solution decoupling intra-type correlation inter-type correlation multiple layers starting bottom machinefriendly representations object characterized collection type-speciﬁc feature vectors type homogeneous numerical qualitative representation real-valued binary count. primitive representations enable modality expressed belong type. example visual modality image represented real-valued color histograms word counts social tags considered sparse binary vector. intra-type correlation handled type-speciﬁc lower models. moving hierarchy inter-type correlation captured higher layer. ﬁnally tasks deﬁned higher layer. realization deep learning scheme two-phase procedure based stack restricted boltzmann machines depicted fig. ﬁrst learning phase unsupervised. discovers data regularities shared structures modalities types without labels. learning starts lowest level array rbms type-speciﬁc inputs intermediate representations. middle-level representations integrated another binary high-level features. stack forms multityped deep belief network second learning phase auxiliary typed tasks introduced highest feature layer essentially forming multityped deep neural network. tasks learnt simultaneously previously learnt representations reﬁned process. creates predictive deep representation shared among tasks approach appears resemble recent multimodal multitask learning frameworks however differ signiﬁcantly modeling types input task levels previous work often assumes homogeneous representations. summarize paper makes following contributions introduction deep multityped architecture integrate multiviews multimodalities. introducing concept multityped multitask learning tasks heterogeneous figure -step training procedure first type-speciﬁc rbms trained; posteriors previous layers used input next layer; ﬁnally auxiliary tasks learnt reﬁning previously discovered latent representation. steps unsupervised step supervised. next section reviews related background. section presents building blocks proposed architecture restricted boltzmann machines. deep architecture multityped inputs tasks described section section demonstrates applicability proposed deep architecture applications image retrieval multilabel learning. finally section concludes paper. learning multimodal data recently attracted increasing attention however fusion multiple data types sparsely studied. early attempts include work joint probabilistic model correspondence latent dirichlet allocation proposed. model explicitly assumes direct correspondence data recent work uses model text image features. modalities treated separate sources lately fused using canonical correlation analysis. however clear systematically handle different data types sources. work extends rich class undirected graphical models known restricted boltzmann machines capable encoding arbitrary types side information existing work rbms limited single types example binary real-valued count joint modelling visual features tags ﬁrst introduced line work extended richer types. works however assume shallow architecture ideal multimedia objects modalities differ substantially correlation structures semantic levels recently deep architectures suggested overcome difﬁculties associated shallow models multimodal learning. deep canonical correlation analysis example potentially help narrow semantic gaps. multimodal stacked autoencoders shown effective integrating speech vision efforts however address multiple data types. closer architecture perhaps work deep boltzmann machine used multimodal data. differences work assumes modality view model purely generative. work hand extends multiple views multiple types modality generative discriminative components. multiple views visual modality studied limited hashing consider multityped tasks. neural networks multitask learning ﬁrst introduced exploiting auxiliary tasks shared latent representation improve main task previously proposed multimodal multitask learning studied however differ signiﬁcantly modeling heterogeneous types input task levels previous work often assumes homogeneous representations. ﬁrst present building blocks deep architecture restricted boltzmann machine generalizations. restricted boltzmann machine stochastic undirected neural network without outputs graphical depict). given binary inputs hidden units deﬁnes following energy function serves representation data. factorizations enable efﬁcient layerwise mcmc sampling alternating parameters {aibkwik} typically estimated maximizing data likelihood encourage sparse representation probability hidden unit activated augment data log-likelihood regularization term desired activation probability k-th hidden unit regularization factor. learning realized fast stochastic gradient ascent procedure known contrastive divergence major limitation model binary inputs. next subsections present extensions real-valued inputs gaussian-bernoulli count inputs constrained poisson gaussian–bernoulli rbms model real–valued inputs pixel intensities histograms graphical structure exactly standard rbms except input type energy replaced document length given special mean–rate ensures i.e. bounded above. addition model rate equals empirical rate average leading stable learning. rbms extended types including multinomial ordinal rank beta mixture real-valued count types extensions maintain bipartite structure rbms differ type-speciﬁc generative distributions recent ﬂexible framework claimed represent known types using truncated gaussian–bernoulli rbms. hidden layers rather real-valued layer constrained type-speciﬁc inequalities. present deep architecture multityped objects multityped tasks. learning -step procedure spanning unsupervised learning phase supervised phase depicted figs. respectively. ideas two-fold separation modeling intra-type correlation inter-type correlation using multiple layers using predictive tasks reﬁne learnt representation. derive -phase learning procedure. ﬁrst phase unsupervised representations learnt data without guidance labels. second phase supervised tasks used ﬁne-tune previously learnt model. step learning type-speciﬁc representations ﬁrst ignore inter-type correlation feature modeled separately using type-speciﬁc rbm. assume object represented ways corresponds feature ..s. step learning joint representation model inter-type correlation posteriors type-speciﬁc rbms object concatenated posterior second stage expected abstract ﬁrst stage. step shown improve lower-bound data log-likelihood step learning tasks-informed representations layers steps connected joining output ﬁrst layer input second layer depicted fig. essentially joint model becomes generalization deep belief network input multityped. further hidden layer connected tasks interest. whole model complex deep neural network supports multiple input types well multiple output tasks. finally parameters reﬁned discriminative training tasks back-propagation. elaborate step following subsection. multityped multitask learning denote parameters associated s-th feature bottom layer parameters second layer. step k-th higher feature computed feedforward procedure however learning point aimed approximately optimize lower-bound data likelihood since data likelihood well connected tasks perform using discovered representation second stage suboptimal. informative guide learning process learned representation become predictive respect future tasks. beside main tasks interest argue auxiliary tasks helpful shape representations. provides realization vapnik’s idea learning privileged information teacher knows extra information available training time. example main task content-based retrieval concept labeling ranking social tags associated images used auxiliary task. absence well-deﬁned extra tasks input reconstruction auxiliary tasks. note auxiliary tasks needed training time. major distinctive aspect multitask setting tasks multityped tasks assume functional form. example task histogram reconstructions regression tagging label ranking. tasks however share latent data representation along line model deep neural network standard back-propagation applies. major difference parameters learnt unsupervised phase serve initialization supervised phase. numerous evidences literature suggest initialization sensible parameter region enabling exploitation good local minima time implicitly provides regularization consider three cases namely multiclass prediction label ranking multilabel learning. label ranking refers ordering labels according relevance respect object. example image ranking groups image belong {birds close-up outdoor indoor}. partial label ranking rank given incomplete e.g. {birds close-up others} given. label known reduces multiclass problem. multilabel prediction assign label object. image tagged {bird morning branch wild garden} example. {ytyt ...yttt} labels given object t-th task. employ simple multiclass prediction class labels label ranking consists labels deﬁned recursively follows j−\\yt essentially reduces plackett-luce model complete ranking available prediction simple need rank labels according multilabel learning contains labels ..tt. prediction adapt strategy labels satisfying selected. threshold estimated training data table type deﬁnitions retrieval. means auxiliary tasks used ﬁnetune model given features. d-ch means color histogram d-visual means visual features combined. evaluate learning method nus-wide dataset consists flickr images equipped visual feature representations tags drawn kword vocabulary manually labelled concepts. randomly pick images training model testing. dimensionality social tags limited bows instead count. real-valued histograms ﬁrst normalize histogram unit vector normalize across train data obtain zero mean unit variance. model architecture hidden units type bottom layer hidden units layer. mapping parameters randomly initialized small normally distributed numbers bias parameters zeros. posterior sparsity learning rates binary real-valued count types. difference learning rate scales fact real-valued gaussian means unbounded poisson mean–rates although bounded larger parameters unsupervised phase updated every training images. discriminative training supervised phase based back-propagation conjugate gradients. task test image used query test objects. retrieval based cosine similarity representations query objects. deep architecture top-level representation used unit create baseline representation ﬁrst normalize feature unit vector concatenating them. eliminates difference dimensionality scales views. retrieved image considered relevant shares least manually labelled concept query. performance measures reported mean average precision retrieved images normalized discounted cumulative gain images. reli denote whether i-th retrieved image relevant query. precision rank precision table reports results. clear multiple visual representations needed good contentbased retrieval quality. baseline improves representation visual features combined. similarly method improves alone visual feature types textual tags particularly useful boost performance perhaps tags closer concepts term abstraction level. believe reﬂected deep model tagging auxiliary task consistent improvement baseline achieved regardless visual representations. hypothesize representation predict tags well likely semantically closer concept. table image retrieval results nus-wide. retrieved image considered relevant shares least concept query. test query matched test images. means auxiliary tasks used ﬁne-tune model given features. d-ch means color histogram d-visual means visual features combined. ndcg evaluated results. symbol denotes increase performance compared baseline. tags available retrieval stage large boost performance baseline method tags) reconﬁrming multimodal fusion required. difference method baseline improvement wider e.g. improvement method versus baseline. mance. speciﬁcally increases tagging alone tagging visual reconstruction surprising visual information low-level compared tags concepts. support stronger hypothesis representation predictive many auxiliary tasks could suitable retrieval. note passing deep architecture produce compact representation typical multimodal representation. example visual features tags combined generate dimensions order magnitude larger size deep representation problem predict high-level concepts images. concepts total image typically assigned concepts. cast multilabel prediction problem create baseline k-nearest neighbor classiﬁer first normalize multityped visual features section prediction retrieve similar training images test image estimate label probabilities. labels higher probability estimated threshold selected. whenever possible ranking auxiliary task addition main concept labeling task training. figs. plot prediction results test three performance metrics recall precision macro-f. results largely reﬂect ﬁndings retrieval experiments multiviews work better single view tags informative thus exploited sensibly deep architecture outperforms shallow one. particular fusing visual views leads figure multiple concept labeling results. ranking used auxiliary task. macro-f mean f-measure labels. bag-of-words color histogram visual visual views combined visual tags improvements macro-f single view color histogram. tags integrated inputs improvement higher using deep architecture baseline. macro-f better baseline alone better fusion types modalities. introduced deep architecture learning procedure discover joint homogeneous representation multityped multimedia objects. also presented concept multityped tasks deviate common single-type multitask setting. deep learning procedure phases unsupervised supervised. unsupervised phase starts bottom layer type-speciﬁc features modeled using separate rbms creating mid-level representations. representations aggregated second level rbm. supervised phase layers fused deep neural network whose layer connected tasks interest. whole network discriminatively trained obtain predictive representation starting parameters estimated unsupervised phase. summary architecture seamlessly supports compact feature discovery multimodal multityped data multityped multitask settings. capacity demonstrated tasks image retrieval multiple concept prediction showing promising results. emphasized proposed architecture modular. types complex objects tasks integrated easily. word counts example modeled replicated softmax extension multinomial model paper limited -layer deep architecture extended straightforwardly layers step.", "year": 2016}