{"title": "Concept of E-machine: How does a \"dynamical\" brain learn to process  \"symbolic\" information? Part I", "tag": ["cs.AI", "cs.LG", "I.2.0"], "abstract": "The human brain has many remarkable information processing characteristics that deeply puzzle scientists and engineers. Among the most important and the most intriguing of these characteristics are the brain's broad universality as a learning system and its mysterious ability to dynamically change (reconfigure) its behavior depending on a combinatorial number of different contexts.  This paper discusses a class of hypothetically brain-like dynamically reconfigurable associative learning systems that shed light on the possible nature of these brain's properties. The systems are arranged on the general principle referred to as the concept of E-machine.  The paper addresses the following questions:  1. How can \"dynamical\" neural networks function as universal programmable \"symbolic\" machines?  2. What kind of a universal programmable symbolic machine can form arbitrarily complex software in the process of programming similar to the process of biological associative learning?  3. How can a universal learning machine dynamically reconfigure its software depending on a combinatorial number of possible contexts?", "text": "human brain many remarkable information processing characteristics deeply puzzle scientists engineers. among important intriguing characteristics brain’s broad universality learning system mysterious ability dynamically change behavior depending combinatorial number diﬀerent contexts. paper discusses class hypothetically brain-like dynamically reconﬁgurable associative learning systems shed light possible nature brain’s properties. systems arranged general principle referred concept e-machine. kind universal programmable symbolic machine form arbitrarily complex software process programming similar process biological associative learning? paper explains concept e-machine outlines broad range potential applications. applications include context-sensitive associative memory context-dependent pattern classiﬁcation context-dependent motor control imitation simulation complex informal environments natural language. observed from outside human brain seems behave sequential symbolic machine. else explain clearly symbolic phenomena mental computations natural language? observed from inside however neural networks brain evoke idea noisy dynamical system distributed parameters rather image logic circuitry digital computer gradually changing potentials decaying residual excitation high level ﬂuctuations. neurons produce spikes reminiscent pulses digital computer. widely believed however frequency pulses rather presence absence carry important information. kind universal programmable symbolic machine form arbitrarily complex software process programming similar process biological associative learning? metaphor brain e-machine sheds light questions. metaphor suggests brain neither traditional symbolic system traditional dynamical system. non-classical symbolic system probabilities sequential discrete processes controlled massively parallel continuous processes. note. general idea brain employs combination symbolic dynamical computational mechanisms entertained diﬀerent forms different researchers concept e-machine attempt provide neurobiologically consistent formalization general idea. requirement neurobiological consistency makes diﬀerence whole human brain universal learning computer. section takes broader look problem information processing whole human brain. argues exists relatively short formal representation universal learning computer similar untrained human brain. associative neural networks e-machines. section establishes link associative neural networks e-machines. connects eﬀects dynamic reconﬁguration neural networks hypothetical states dynamical memory available individual neurons. states residual-excitation-like memory referred e-states. chines statistical mixed-signal computers. section addresses problem neurobiological implementation e-sates next e-state procedures. describes formalism connects dynamics macroscopic e-states statistical conformational dynamics ensembles protein molecules embedded neural membranes. single protein molecule treated probabilistic nanomachine e-states interpreted average numbers nanomachines diﬀerent states average occupation numbers. formalism suggests statistical conformational dynamics protein molecules individual neurons rather collective statistical dynamics neural networks performs main volume brain hardware computations. enough neurons whole human brain implement required amount computations networks built simple neurons. computing e-states. section tackles question massively parallel transformations e-states allow slow brain eﬃciently process large arrays symbolic data stored long-term memory without moving data read/write memory buﬀer. hierarchical structure sparse-recoding data compression statistical ﬁltering. section explains e-machines hierarchical structure associative memory perform eﬃcient data compression context-dependent statistical ﬁltering context-dependent generalization. section takes broader look problem information processing whole human brain. argues exists relatively short formal representation universal learning computer similar untrained human brain. consider cognitive system schematically shown figure external world human-like sensory motor devices hypothetical computing system simulating work human nervous system. think system human-like robot. systemtheoretical viewpoint useful divide system subsystems external world appears brain devices representation subsystems treated abstract machines inputs outputs vice versa. sake simplicity refer brain. general level rest nervous system treated part block denote state time corresponds beginning learning. argue following general propositions true special mathematical formalism needed describe work given powerful enough hardware relatively small program would able simulate work time step msec. program would suﬃcient adequately represent important psychological characteristics complex still rather small program would able simulate work time step µsec. program would suﬃcient adequately represent important psychological characteristics many neurobiological characteristics. exists relatively short formal representation sensorimotor devices since representation encoded human genome. metaphorical ﬂoppy disk mentioned item enough room know well diﬀerent kinds artiﬁcial devices main secret rather general case exists ﬁnite formal representation system system inﬁnitely complex. doesn’t prevent simulating behavior system robot ﬁnite formal representation external world always there experiment with. formal representation must long representation must include form representation brain’s individual experience resulted interaction whatever language used representation main part representation representation knowledge accumulated course learning. figuratively speaking human brain works complexity sucker gets complexity system knowledge represented rather form brain’s learning algorithm close memorizing sensory-motor-emotional experience. special data structures needed. instead pre-processing data putting memory brain uses powerful massively parallel decision-making procedure capable processing experience depending context. practically impossible formally represent simulate nontrivial parts behavior system without adequate formal representation adequate cognitive theory cannot separated theory brain. main goal brain modelling must reverse engineering clearly deﬁned practically achievable goal. advance toward goal concentrate analysis basic psychological neurobiological observations rather mimicking parts brain’s behavior. latter strategy leads new-eﬀect-new-model pitfall cursed combinatorial explosion number partial models needed represent whole behavior. role cognitive science meaningfully compared role maxwell equations classical electrodynamics. maxwell equations coupled inﬁnite variety speciﬁc external constraints allow simulate inﬁnite variety speciﬁc classical electromagnetic phenomena. similarly interacting diﬀerent external systems would allow simulate principle inﬁnite variety arbitrarily complex cognitive phenomena. example physics warns underestimate power simple basic mechanisms mother nature. argue warning relevant problem reverse engineering physical system brain designed mother nature human system engineers. makes diﬀerence world. design artiﬁcial information processing systems make easier understand test debug. costs extra resources. contrast mother nature tends solve natural design problems minimum resources. makes designs look clever. also makes diﬃcult understand. minimum-resource designs diﬀerent functions necessarily strongly integrated cannot easily structured independent blocks. integration simple physical principles produce critical mass eﬀect. introduction so-called displacement current maxwell equations gives classical example interesting phenomenon. sudden simple addition known basic laws electricity argue something similar happened case human brain. much needed transform brains simple animals human brain. clever integration relatively small powerful basic mechanisms produced critical mass eﬀect. understand pitfall pure phenomenology consider following metaphor. imagine physicist wants simulate behavior electromagnetic ﬁeld complex microwave device e.g. stanford linear accelerator assume physicist doesn’t know existence maxwell equations even importantly doesn’t believe complex behavior observes something simple equations. scruﬀy physicist sets purely phenomenological computer simulation observed complex behavior anyone involved computer simulation behavior electromagnetic ﬁeld linear accelerator easily predict results gedanken experiment. best case scenario mentioned scruﬀy physicist comes computer program capable simulating behavior electromagnetic ﬁeld narrow range. computer program extrapolating power accepted slac community theory linear accelerator. note would impossible reverse engineer maxwell equations analysis behavior electromagnetic ﬁeld complex external world slac. argue that similarly impossible reverse engineer analysis complex cognitive phenomena system playing chess solving complex mathematical problems story telling etc. observation person suﬃciently large external memory perform principle eﬀective computational procedure. formalization observation lead famous english mathematician alan turing invention celebrated machine corresponding formalization intuitive notion algorithm. observation born knowledge possible algorithms. learn however perform principle given algorithm simulating work turing machine representing algorithm. observation person good visual memory performing computations external memory learns perform similar mental computations using corresponding imaginary memory aid. chess player learns move chess pieces imaginary chess board. abacus user learns operate imaginary abacus principle person learn perform mental computations mentally simulating process writing symbols sheet paper. ignoring severe theoretically unimportant limitations size working space available mechanism mental imagery observation suggests human brain person external memory must treated system theorist universal learning system. note. adequate model must highest general level computing power. attempting simulate work human brain using learning system general level computing power lower brain compared attempt design perpetual motion machine violation energy conservation law. matter sophisticated learning process might system learn cannot principle. observation imagine sensory events synthesize motor reactions. time remember recall real sequence events example experienced chess player mentally play chess party. time he/she recall real parties he/she played. similarly generate combinatorial number sentences. time read heart speciﬁc text we’ve learned. area. example easily remember long sentences language know. next impossible remember long sentences language don’t know. also diﬃcult second language speaker accent he/she tends build words second language syllables ﬁrst language. observation ability retain information short-term memory increases similar information present ltm. repeat sentence language know. cannot repeat sentence language don’t know. imitate reactions people ourselves. true perception. diﬃculties recognizing words foreign language cannot pronounce ourselves. observation imagine diﬀerent sensory events need mental motor reactions would cause similar events. need mentally sing melody imagine another person singing melody. need mentally sentence imagine another person saying sentence. etc. observation diﬀerent sub-pictures picture depending expect see. necker cube example. hear diﬀerent tunes sequence sounds depending expect hear. observation short-term memory retain limited number items magical number miller however eﬀect chunking size single item signiﬁcantly increased. also report raises questions observation observation brain slow noisy system. cannot process symbolic information traditional moving symbols read/write memory buﬀer. nevertheless learn mentally simulate diﬀerent external systems properties read/write memory. computational universality turing’s sense achieved without moving symbols read/write memory? neural networks learn simulate symbolic read/write memory? note. problem brain learn simulate external system properties read/write memory must confused problem neural network implement read/write memory. latter problem trivial. former problem nontrivial critically important. traditional neural network models cannot learn simulate external systems properties read/write memory therefore cannot serve models brain’s systems responsible mental imagery. observation recognize certain object statistically strongly correlated another object also produce reaction statistically well correlated certain stimulus importantly statistical relationship depends context. objects strongly correlated context correlated diﬀerent context. language words usual unusual common uncommon etc. reﬂect ability recognize statistical relationships. observation wait certain object appears recognize object waiting for. expect certain object appear instead unexpected object appears recognize unexpected object. answer questions what waiting for? expect? sider question what context question person behaves pattern classiﬁer. he/she answer example book. person’s brain able distinguish book objects disk drive etc. consider instruction take this. context longer important object name book. important object’s size weight position etc. experience acquired taking book applicable taking taking disk drive. object treated member diﬀerent classes depending context. observation recognize emotional states. remember emotional experience. experience evaluate events. concepts good important unimportant etc. formed process learning. observation recognize internal states internal reactions people. example know feel. know another person thinking waiting etc. learn imitating another person imitating person black box. means problem learning cannot formalized automata theory problem machine deciphering structure another machine observed black box. observation much memory. example driving familiar environment need glance scene update visual picture expect. close eyes room live mentally moving eyes mentally turning head. expand structure system figure shown figure brain divided blocks associative learning system forms sensorymotor motor associations motor centers. diagram also depicts block teacher. case teacher acts idealized neurophysiologists produce desired output centers clamping centers. system receives sensory signals system motor signals output centers approach teaching learning similar so-called supervised learning except that case learning system receives sensory input external system rather teacher. compared so-called instrumental conditioning. make expansion structure system shown figure brain divided four blocks blocks figure sensory centers associative learning system forms motorsensory sensory associations. goal system simulate block teacher. goal system simulate external system easy system plays role system block teacher view systems systems responsible motor control mental imagery respectively. view sets associations brain’s software associated functions. speciﬁc example system shown figure gives simpliﬁed general explanation phenomenon mental computations. model implemented educational program called erobot microsoft windows. explicit description model given eliashberg figure utter symbol kept mind cycle one-cycle memory provided delayed feedback motor signal utter symbol speech organ proprioceptive signal symbol uttered organ. case ﬁnite tape suﬃcient number training examples system learns simulate external system accordingly robot learns perform demonstrated algorithm imaginary memory aid. main part today’s research learning devoted development study referred smart learning algorithms. algorithms attempt create optimal representations learner’s experience learner’s memory. argue general approach cannot employed universal learning system similar human brain. catch smart learning algorithm aimed single-context optimization universal. optimizing performance selected context throws away information needed variety contexts. consider example observation form section observation suggests that case human brain thing optimal context-independent classiﬁcation. main issue pre-process information course learning store pre-processed information memory what information learn. human concepts good important unimportant change experience. therefore smart learning algorithm ﬁxed criterion optimality criterion aﬀected contents data cannot serve adequate metaphor human learning. seems unimportant today become important tomorrow information acquired. argue really smart universal learning system must dumb universal learning algorithm. instead much pre-processing data placing memory system must eﬃcient decisionmaking procedure process experience dynamically depending context. theoretically powerful enough interpretation procedure always make dumb learning algorithm long algorithm doesn’t lose data. contrast decision making procedure make smart learning algorithm throws away information. loss data irremediable. section introduces concept primitive e-machine natural information processing extension notion homogeneous associative neural network. complex e-machine system built several primitive e-machines. complex e-machines discussed part paper. figure large circles incoming outgoing lines represent neurons dendrites axons respectively. small white black circles represent excitatory inhibitory synapses respectively. network three layers neurons input neurons intermediate neurons output neurons neurons global inhibitory feedback neuron local excitatory feedbacks. shown network neurons compete reciprocal inhibition winner–take–all fashion. similar eﬀect obtained network lateral inhibitory feedbacks. figure uses following notation following functional model network figure studied eliashberg model neuron treated linear threshold element zero threshold time constant spite simplicity model signiﬁcant educational value allows explicitly bridge neurobiological psychological theories show kind mathematics involved bridging. learning algorithm described assumed model preprogrammed beginning experiment. according expression neurons increase potentials neurons decrease potentials switch reduces increases making additional neurons eventually neurons shown equilibrium unstable therefore presence noise transient response winner randomly selected neurons maximum level assume states iltm oltm speciﬁed beginning experiment model don’t change experiment also assume parameters model experiments. describe psychological properties model ann- need following system theoretical concepts. combinatorial machine system ﬁnite sets symbols called input output respectively; output function machine works follows input output symbols ν-th cycle. probabilistic combinatorial machine system above; function output conditional probabilities machine works follows conditional probability given psychological properties model ann- described algorithmic terms. description presented gives example trivial primitive e-machine primitive e-machine without e-states. model referred model long similarity function allowable inputs satisfy correct decoding condition similarity) model system universal respect class combinatorial machines. psychological model much simpler neurobiological model ann-. model doesn’t neural-implementationparameters model ann-. also doesn’t fast changing state introducing e-state arrays next e-state procedure structural transform model nontrivial primitive e-machine capable producing interesting eﬀects working memory temporal context definition ﬁnite–state machine system ﬁnite sets external symbols called input output sets respectively ﬁnite internal symbols called state function called output function function called next-state function work machine described note. diﬀerent equivalent formalizations concept ﬁnite– state machine. formalization described known mealy machine. another popular formalization moore machine. moore machine output described function next–state. practical electronic designers usually term state machine instead term ﬁnite–state machine. ﬁnite–state machine implemented combinatorial machine cycle delayed feedback using trick easy show model delayed feedback simulate ﬁnite–state machine. return system shown figure simple model enough computing power serve motor control system because one-cycle delayed feedback utter-symbol→ symbol-uttered transforms block system universal respect class ﬁnite machines gives system power universal turing machine. provides functionality tape head machine.) easy show simplest algorithm satisfying requirement taperecording xsequence y-sequence input output respectively. case deterministic combinatorial machine algorithm improved recording associations. case probabilistic combinatorial machine associations need recorded several times accumulate statistics. interesting mention famous psychiatrists advocating concept tape-recording-learning. quotation meynert each impression meets still vacant cell. existence vast number vacant cells impressions arriving succession carriers remain forever close order. mentioned concept smart learning algorithm creates methodological pitfall. catch human concept important information changes experience learning algorithm ﬁxed criterion optimality smart enough know advance information important store not. seems unimportant today become important tomorrow information acquired. neurons layer compete winner-take-all fashion model ann- thought neural counterpart programmable logic array shown figure input synaptic matrix similar programmable and–array output synaptic matrix similar programmable array. goes direction gets neural extras reduces competition neurons layer enters realm connectionist neural networks. also replace linear threshold output function sigmoid function. model ann- becomes typical parallel distributed processing system. traditional connectionist graphical representation system looks like shown figure selects nonsymbolic path inspired view neural networks analog computational devices implementing multidimensional mappings real numbers. seldom possible weights corresponding nontrivial multidimensional mappings analytically. therefore development study learning algorithms automatically adjusting weights becomes main thrust research. traditional models don’t suﬃcient general level computing power adequately address critically important symbolic problems problem natural language. discussion issue.) traditional models room accommodate known complexity biological neurons. whole vision brain collectivedistributed-dynamical system built simple atomic neurons inconsistent modern neurobiological data single neuron complex integrated computing element. brain many diﬀerent types neurons tailored diﬀerent tasks. basic architecture model shown figure compared model model additional procedures bias next state procedure. procedures included block excitation. ote. similarity equal number non-zero matches divided number non-zero components input vector many similarity functions satisfying correct decoding condition section expression would work well. proof. program contain least pair subset locations containing commands combinatorial machine class. otherwise. model program e-state simulate machine result illustrates importance e-states. model program length simulate single combinatorial machine simulate diﬀerent machine model must reprogrammed. model program length simulate machine class without reprogramming. section presents formalism oﬀers answer questions. formalism viewed system theoretical extrapolation main idea hodgkin huxley theory sodium potassium channels embedded axon membrane work stochastic switches several internal states formalism discussed eliashberg function describing input-dependent conditional probability densities state transitions conditional probability transfer state state time interval value input non-negative real numbers. components called generalized potentials. interpreted membrane potential concentrations diﬀerent neurotransmitters. condition holds internal structure shown figure dpij probability transition state state time interval output function input current state. probability transition state state channels studied many diﬀerent disciplines biophysics protein chemistry molecular genetics cell biology others concerned information processing possibilities channels. postulate that information processing level channels treated pmms. level exact biophysical biochemical mechanisms important. important properties channels abstract machines. situation meaningfully compared general relationship between statistical physics thermodynamics. properties molecules important level thermodynamics. similarly properties protein molecules important level statistical computations implemented ensembles molecules. general structure voltage-gated channel shown schematically figure figures show channel represented pmm. example states single input single output make diﬀerent assumptions function describing conditional probability densities state transitions. convenient represent function matrix voltage dependent coeﬃcients aij. model spike generation discussed eliashberg sodium potassium channels treated pmms states shown figure coeﬃcients assumed sigmoid functions membrane potential coeﬃcients constant. case sodium channel used high permeability state used inactive state. case potassium channel assumed high permeability states. definition. ensemble protein molecule machines identical independent pmms input vector output vector equal output vectors individual pmms. structure epmm shown figure total number pmms output vector k-th output vector epmm. figure illustrates implementation e-states relative occupation numbers states pmm. maximum number independent e-state variables equal number reduced additional equation change sharply functions inputs epmm better characterized mixed-signal computer. statistical molecular implementation computer extremely robust since characteristics whole computer determined properties single pmm. interesting emphasize matrix input dependent coeﬃcients implemented matrix input dependent probabilities external connections needed. would diﬃcult reach level microminiaturization level reliability using traditional vlsi techniques. neural modeler needs simulate diﬀerent eﬀects cellular he/she usually assumes eﬀects associated chemical kinetics and/or accumulation diﬀerent neurotransmitters and/or ions diﬀerent cellular compartments. approach cellular encounters serious problems important avoid common misunderstanding want emphasize conformational dynamics nothing traditional chemical kinetics. conformational dynamics determined biophysical properties protein molecules. chemistry involved example case voltage controlled channels. even case ligand controlled channels enzymes inadequate think interaction neurotransmitter molecule protein molecule chemical reaction. protein molecules whereas neurotransmitter molecules tiny tiny molecule changes conformation molecule latter temporarily open pore become catalyst producing second messenger. little known properties diﬀerent membrane proteins represent abstract probabilistic nanomachines. best studied sodium potassium channels used classical hodgkin huxley model generation nerve spike. believed protein molecules close diﬀerent states each. speciﬁc case eppm formalism gives good approximation available experimental data therefore seems reasonable believe formalism work well many less studied cases. single neuron several diﬀerent epmms interacting electrical messages chemical messages mentioned section hodgkin-huxley model naturally expressed terms epmms interacting common membrane potential figure shows epmms interacting second messenger. example epmm primary transmitter receptor epmm second messenger receptor. popular notion brain implements multidimensional real mapping fallacy. whole concept learning algorithm optimizes synaptic weights create mappings largely irrelevant problem human learning. main data storage procedure human brain must universal close memorizing experience. instead processing data placing memory brain must process data dynamically depending context. context-dependent statistics precalculated advance principle number possible contexts explodes combinatorially. biological neural networks right computational resources implement dynamic approach. main computational engine brain statistical mechanics protein nanomachines rather statistical mechanics neural networks. notion neuron simple atomic computing element employed latter approach inconsistent available neurobiological data eliashberg context-sensitive associative memory residual excitation neural networks mechanism mental set. proceedings ijcnn- june washington d.c. vol. eliashberg universal learning neurocomputers. proceeding fourth annual parallel processing symposium. california state university fullerton. april", "year": 2004}