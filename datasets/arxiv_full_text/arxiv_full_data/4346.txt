{"title": "Fast clustering for scalable statistical analysis on structured images", "tag": ["stat.ML", "cs.CV"], "abstract": "The use of brain images as markers for diseases or behavioral differences is challenged by the small effects size and the ensuing lack of power, an issue that has incited researchers to rely more systematically on large cohorts. Coupled with resolution increases, this leads to very large datasets. A striking example in the case of brain imaging is that of the Human Connectome Project: 20 Terabytes of data and growing. The resulting data deluge poses severe challenges regarding the tractability of some processing steps (discriminant analysis, multivariate models) due to the memory demands posed by these data. In this work, we revisit dimension reduction approaches, such as random projections, with the aim of replacing costly function evaluations by cheaper ones while decreasing the memory requirements. Specifically, we investigate the use of alternate schemes, based on fast clustering, that are well suited for signals exhibiting a strong spatial structure, such as anatomical and functional brain images. Our contribution is twofold: i) we propose a linear-time clustering scheme that bypasses the percolation issues inherent in these algorithms and thus provides compressions nearly as good as traditional quadratic-complexity variance-minimizing clustering schemes, ii) we show that cluster-based compression can have the virtuous effect of removing high-frequency noise, actually improving subsequent estimations steps. As a consequence, the proposed approach yields very accurate models on several large-scale problems yet with impressive gains in computational efficiency, making it possible to analyze large datasets.", "text": "brain images markers diseases behavioral differences challenged small effects size ensuing lack power issue incited researchers rely systematically large cohorts. coupled resolution increases leads large datasets. striking example case brain imaging human connectome project terabytes data growing. resulting data deluge poses severe challenges regarding tractability processing steps memory demands posed data. work revisit dimension reduction approaches random projections replacing costly function evaluations cheaper ones decreasing memory requirements. speciﬁcally investigate alternate schemes based fast clustering well suited signals exhibiting strong spatial structure anatomical functional brain images. contribution two-fold propose linear-time clustering scheme bypasses percolation issues inherent algorithms thus provides compressions nearly good traditional quadratic-complexity variance-minimizing clustering schemes; show cluster-based compression virtuous effect removing high-frequency noise actually improving subsequent estimations steps. consequence proposed approach yields accurate models several large-scale problems impressive gains computational efﬁciency making possible analyze large datasets. introduction data brain imaging. medical images increasingly used markers predict diagnostic behavioral outcome. corresponding biomarkers tenuous researchers come rely systematically larger cohorts increase power reliability group studies case neuroimaging). addition typical resolution images steadily increasing datasets become larger feature sample dimensions. striking example brain imaging case human connectome project terabytes data growing. whole ﬁeld thus presently situation large datasets assembled. computational bottlenecks. data deluge poses severe challenges regarding tractability statistical processing steps memory demands posed data representations involved. instance given problem samples dimensions classical linear algorithms complexity becomes exorbitant large. medical imaging would number voxels number samples e.g. order brain images resolution becoming larger impact computational cost actually worse simple linear effect datasets longer cache power standard computational architectures longer leveraged resulting extremely inefﬁcient resources. result practitioners left alternative simplifying analysis framework working sub-samples data lossy compression random projections clustering. part solution issue reduce dimensionality data. principal components analysis even randomized counterpart longer option procedures become inefﬁcient cache size effects. non-linear data representations suffer issue. however aggressive reductions obtained random projections i.e. construction random representations dataset k−dimensional space essential virtue random projections come guarantees reconstruction accuracy important drawback projected data longer embedded back native observation space. moreover random projections generic approach take account relevant information problem hand instance ignore spatially continuous structure signals medical images. contrast spatiallycontrast-aware compression schemes probably better suited medical images. propose investigate adapted clustering procedures respect anatomical outline image structures. practice however standard data-based clustering yield computationally expensive estimation procedures. alternatively fast clustering procedures suffer percolation contribution propose novel approach fast image compression based spatial clustering data. approach designed solve percolation issues encountered settings order guarantee good enough clustering quality. contributions theory accuracy random projections. important characteristic random projections existence theorems guarantee accuracy projection particular johnson-lindenstrauss lemma variants given points number linear simply taken projection random k-dimensional subspace rescaling. interpretation that given large enough number random projections given dataset obtain faithful representation explicit control error. accurate representation norm) used analyses kernel methods consider between-sample similarities addition number necessary projections lowered data actually sampled sub-manifold practice sparse random projections used reduce memory requirements increase efﬁciency important limitations approach random mapping cannot inverted general high dimensionality; means ensuing inference steps cannot made explicit original data space; approach ignores structure data spatial continuity medical images. signal versus noise. contrast clustering techniques used quite frequently medical imaging means compress information empirical success absence formal guarantees super-voxel approaches explanation medical images typically composed signal noise high-frequency noise reduced withincluster averaging low-frequency signal interest preserved. denote image associated signal noise projectors clusters pressed representation problem boils deﬁning suitable partition image volume equivalently associated projectors large. data-unaware clustering partitions obviously sub-optimal respect underlying structures lead signal loss. data-driven clustering performed various approaches k-means agglomerative clustering tend expensive kmeans complexity agglomerative clustering also expensive single linkage clustering fast suffers percolation issues. percolation major issue decompositions giant cluster singletons quasi-singletons obviously suboptimal represent input signals. fast clustering percolation lattices. voxel clustering take account lattice structure medical images based local image statistics order obtain linear-time algorithms. given dataset thus represented graph lattice topology edges neighboring voxels indexed associated distance measures similarity features. common observation random graphs lattices display percolation soon edge density reaches critical density meaning huge cluster group voxels leaving small islands apart single linkage clustering suffers percolation simple variant alleviates problem strategy called rand single linkage simply rand single paper. sophisticated strategies proposed framework computer vision designed avoid percolation make possible control number clusters. order obtain better clustering designed linear-time clustering algorithm described alg. illustrated brain image fig. algorithm recursive nearest-neighbor agglomeration merges clusters nearest neighbor step. since number vertices divided least step number iterations i.e. less practice typically algorithm fast clustering recursive nearest neighbor agglomeration require input image shape associated topological graph nearest neighbor extraction function connected components extraction function desired number clusters. since operations involved linear number vertices procedure actually linear predicted theory –namely fact one-nearest neighbor graph point exhibit percolation– cluster sizes even. procedure yields even cluster sizes agglomerative procedures performs well k-means purpose call fast clustering henceforth. compare performance various compression single average complete linkage ward schemes fast clustering sparse random projections series tasks involving public neuroimaging datasets study kmeans estimation overly expensive large regime interest. accuracy compressed representation first study accuracy isometry simply check empirically evaluating ratio pairs samples simulated real data. random projections come precise guarantees variance function figure principle fast clustering procedure illustrated real brain image nearest neighbor graph computed origin data recursively. last iteration closest neighbors associated yield exactly desired number components. figure percolation behavior various clustering methods observed cluster size histogram ﬁxed number clusters obtained averaging across subjects dataset. k-means fast clustering best avoid percolation display neither singletons large clusters. traditional agglomerative clustering methods hand exhibit giant small components. similar results obtained values datasets. result exists cluster-based representations. simulated data simply cube shape contains signal consisting smooth random signal additional white noise; samples drawn. experimental data sample individuals taken test-retest resting-state functional magnetic resonance imaging dataset preprocessing standard pipeline sampled resolution space avoid bias inherent learning clusters measuring accuracy representation data perform cross-validation loop clusters learned training dataset accuracy measured independent dataset. importantly observed clustering actually systematically compressive. hence base conclusions variance across pairs samples i.e. stability ratio distances. sidered activation maps. speciﬁcally relied motor activation dataset taken subjects dataset considered activation maps related different contrasts left hand versus average right hand average left foot average right foot average tongue average. activation maps obtained general linear model application upon preprocessed data resampled resolution space. sets maps voxel computed ratio between-condition variance between-subject variance fast cluster-based representation. quotient values equal whenever signals identical. values greater indicate denoising effect between-condition variance reﬂects signal interest between-subject variance expected reﬂect noise plus between-subject variability. simply consider boxplot ratio function number components. fast logistic regression performed discriminative analysis oasis dataset used anatomical images processed software obtain modulated grey matter density maps sampled space resolution. used maps predict gender subject. achieve this images masked approximate average mask grey matter leaving voxels. voxel density values analyzed -logistic classiﬁer regularization parameter cross-validation. performed following methods non-reduced data fast clustering ward random projection reduction either components. accuracy procedure assessed -fold cross validation loop. measured computation time taken reach stable solution varying convergence control parameter. note estimation problem rotationally invariant i.e. objective function unchanged rotation feature space– makes well suited projectionbased dimension reductions. indeed interpreted kernel. fast independent components analysis performed independent components analysis resting state fmri dataset task performed routinely dataset. speciﬁcally used separate functional connectivity signal noise obtain spatial model functional connectome present experiment analyzed independently data subjects. data consist resting-state sessions scans. relied preprocessed data resampled resolution space. image represents data converted data matrix performed analysis dataset three settings data data compressed fast clustering iii) data compressed sparse random projections extracted independent components standard number literature. based analyses investigated whether components obtained dataset similar clustering; similar components session session type processing. done matching components across sessions hungarian algorithm using absolute value pairwise correlation betweencomponents similarity; iii) computation time decomposition. implementation aspects data used publicly available test-retest oasis datasets used data preprocessing steps provided release -subjects release. relied scikit-learn library machine learning tasks ward clustering. relied scipy library agglomerative clustering methods sparse matrices. results computational cost. computational cost different compression schemes displayed fig. sparse random projections obviously faster require training fast clustering outperforms ward clustering much faster average complete linkage procedures. clustering relatively large image obtained second cost actually much smaller standard linear algebra computations dataset furthermore cost reduced learning clustering subset images accuracy compressed representation quality distance preservation summarized fig. random projections accuracy improves predicted theory. among clustering algorithms ward clustering performs best terms distance preservation. fast clustering performs slightly worse though better random projections. hand average complete linkage perform poorly task –which expected tendency toward percolation. next experinoise reduction differential effect spatial compression signal noise displayed fig. shows that spite large between-voxel variability clear trend toward higher signal-tonoise ratio lower values means spatial compressions like clustering impose low-pass ﬁltering data better preserves important discriminative features variability components part simply noise. fast logistic regression. results application logistic regression oasis dataset displayed fig. shows compressed datasets achieve least level accuracy uncompressed version drastic time savings. result straightforward consequence approximate isometry property compressed representations. accuracy achieved actually higher cluster-based compressions original data random projections illustrates denoising effect spatial compression. side note achieving full convergence improve classiﬁer performance. qualitatively similar results obtained rotationally invariant methods svms ridge regression). carry kernel machine. fast independent components analysis results experiment summarized fig. found ﬁrst components highly similar fast clustering average absolute correlation components random projections recover components across sessions components obtained clustering actually similar clustering before showing denoising effect clustering. effect observed subjects hence extremely signiﬁcant opposite random projections yielded degradation similarity random projections perturb statistical structure data particular deviations normality used ica. consequence cannot recover sources derived original data. contrast statistical structure mostly preserved clustering. finally computation time reduced factor thus improving drastically tractability procedure. faster convergence obtained fast-clustering random projections. summary fast clustering helped make faster also improved stability results. random projections cannot used purpose. figure evaluation computation time clustering algorithms tested images taken oasis dataset. proposed fast clustering outperforms alternatives except random projections. figure evaluation metric accuracy compressed representations obtained various compression techniques different numbers components. experiments based simulated oasis dataset respectively. compression ratio figure denoising effect cluster-based compression ratio between-contrasts subject variance increased lower number regions used data compression scheme. based motor contrasts fmri dataset fast clustering procedure. figure quality logistic regression oasis dataset function computation time. cluster-based methods obtain signiﬁcantly higher scores regression whole dataset much smaller computation time note time displayed include cluster computation costly case ward clustering figure results experiments accuracy fast clustering respect non-compressed components high. across sessions fast clustering yields components consistent data random projections fail regarding computation time fast clustering yields gain factor actually larger p/k. boxplots represent distributions across subjects. experiments shown moderate size datasets fast clustering technique yield impressive gains computation speed minimal overhead build spatiallycontrast-aware data compression schemes. importantly gain found linear various applications. comes good news even absence theoretical result found spatial compression schemes perform well state-of-the-art approach data compression machine learning namely random projections. holds thanks structure medical images noise often observed higher frequency components relevant information. finally found spatial compression schemes presented actually denoising effect yielding possibly accurate predictors uncompressed version random projections. lation super-voxels. difference lies interpretation view spatial compression meaningful model reduce data dimensionality without losing much information. typically number necessarily trade-off between computational efﬁciency data ﬁdelity. note regime ward clustering slightly powerful terms representation accuracy much slower hence cannot considered practical solution. shown experiment clustering-based compression used even tasks norm preservation alone guarantee good representation. combination clustering randomization sparsity also proved extremely effective tool ill-posed multivariate estimation problems hence fast clustering seems particularly well-suited problems. order magnitude real-world multivariate statistic problems. moreover supervised problem improve prediction performance using data compression scheme captures better signal noise. proposed strategy thus extremely promising regarding statistical analysis medical image datasets perfectly compatible efﬁcient online estimation methods acknowledgment. data provided part human connectome project wu-minn consortium funded institutes centers support blueprint neuroscience research; mcdonnell center systems neuroscience washington university. barch deanna burgess gregory harms michael petersen steven schlaggar bradley corbetta maurizio glasser matthew curtiss sandra dixit sachin feldt cindy nolan bryant edward hartley tucker footer owen bjork james poldrack russ smith steve johansen-berg heidi snyder abraham essen david consortium uminn hcp. function human connectome taskfmri individual differences behavior. neuroimage button katherine ioannidis john mokrysz claire nosek brian flint jonathan robinson emma munaf marcus power failure small sample size undermines reliability neuroscience. neurosci halko martinsson p.-g. tropp finding structure randomness probabilistic algorithms constructing approximate matrix decompositions. arxiv e-prints september johnson william lindenstrauss joram. extensions lipschitz mappings hilbert space. conference modern analysis probability volume contemporary mathematics american mathematical society marcus daniel wang tracy parker jamie csernansky john morris john buckner randy open access series imaging studies crosssectional data young middle aged nondemented cogn neurosci demented older adults. pedregosa varoquaux gramfort michel thirion grisel blondel prettenhofer weiss dubourg vanderplas passos cournapeau brucher perrot duchesnay scikit-learn machine learning python. journal machine learning research smith stephen beckmann christian andersson jesper auerbach edward bijsterbosch janine douaud gwenalle duff eugene feinberg david griffanti ludovica harms michael kelly michael laumann timothy miller karla moeller steen petersen steve power jonathan salimi-khorshidi gholamreza snyder abraham woolrich mark junqian yacoub essa uurbil kamil essen david glasser matthew consortium uminn hcp. resting-state fmri human connectome project. neuroimage varoquaux ga¨el gramfort alexandre thirion bertrand. small-sample brain mapping sparse recovery spatially correlated designs randomization clustering. icml", "year": 2015}