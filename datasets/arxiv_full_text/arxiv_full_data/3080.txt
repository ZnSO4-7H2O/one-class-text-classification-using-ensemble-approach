{"title": "Hierarchical Clustering for Finding Symmetries and Other Patterns in  Massive, High Dimensional Datasets", "tag": ["stat.ML", "cs.CV", "cs.LG", "62H30, 68P01", "G.3; H.2.8; H.3.3"], "abstract": "Data analysis and data mining are concerned with unsupervised pattern finding and structure determination in data sets. \"Structure\" can be understood as symmetry and a range of symmetries are expressed by hierarchy. Such symmetries directly point to invariants, that pinpoint intrinsic properties of the data and of the background empirical domain of interest. We review many aspects of hierarchy here, including ultrametric topology, generalized ultrametric, linkages with lattices and other discrete algebraic structures and with p-adic number representations. By focusing on symmetries in data we have a powerful means of structuring and analyzing massive, high dimensional data stores. We illustrate the powerfulness of hierarchical clustering in case studies in chemistry and finance, and we provide pointers to other published case studies.", "text": "data analysis data mining concerned unsupervised pattern ﬁnding structure determination data sets. structure understood symmetry range symmetries expressed hierarchy. symmetries directly point invariants pinpoint intrinsic properties data background empirical domain interest. review many aspects hierarchy here including ultrametric topology generalized ultrametric linkages lattices discrete algebraic structures p-adic number representations. focusing symmetries data powerful means structuring analyzing massive high dimensional data stores. illustrate powerfulness hierarchical clustering case studies chemistry ﬁnance provide pointers published case studies. keywords data analytics multivariate data analysis pattern recognition information storage retrieval clustering hierarchy p-adic ultrametric topology complexity social sciences following quotation shows central theme complexity frequently takes form hierarchy hierarchic systems common properties independent speciﬁc content. hierarchy shall argue central structural schemes architect complexity uses. partitioning observations leads simple symmetries. approach clustering data mining. approaches often based optimization direct interest here. instead pursue theme pointed simon namely notion hierarchy fundamental interpreting data complex reality data expresses. work diﬀerent marvelous view development mathematical group theory viewed right complex evolving system presented foote weyl makes case fundamental importance symmetry science engineering architecture areas. guiding principle whenever structure-endowed entity determine group automorphisms group element-wise transformations leave structural relations undisturbed. expect gain deep insight constitution way. start investigate symmetric conﬁgurations elements i.e. conﬁgurations invariant certain subgroup group automorphisms; section describe ultrametric topology expression hierarchy. provides comprehensive background commonly used quadratic computational time number observations) agglomerative hierarchical clustering algorithms. section look generalized ultrametric context. closely linked analysis based lattices. case study chemical database matching illustrate algorithms area. section p-adic encoding providing number theory vantage point ultrametric topology gives rise additional symmetries ways capture invariants data. section deals symmetries part parcel tree representing partial order data equally subsets data embedded. application symmetry targets dendrogram expressing hierarchical embedding provided haar wavelet transform dendrogram wavelet ﬁltering based transform. section deals recent results relating remarkable symmetries massive especially high dimensional data sets. example discussed segmenting ﬁnancial forex trading signal. reader analysis data short introduction provided hierarchical clustering. along families algorithm objective automatic classiﬁcation purposes data mining knowledge discovery. classiﬁcation fundamental human thinking machine-based decision making. draw attention fact objective unsupervised opposed supervised classiﬁcation also known discriminant analysis machine learning. concerned generalizing decision making capability training data concerned ﬁtting statistical models data models play role generalizing predicting. instead concerned data speak themselves. unsupervised objective classifying data huge task society unquestionably true. think situations precedents limited instance. among families clustering unsupervised classiﬁcation algorithms distinguish following array permuting visualization approaches; partitioning form clusters optimization including graph-based approaches; interest article embedded clusters interrelated tree-based way. last-mentioned family algorithm agglomerative building hierarchy consideration object pairwise distances common approach adopted. comprehensive background texts whether deal euclidean non-euclidean geometry always dealing reals. reals start natural numbers associating observational facts details numbers begin process measurement. natural numbers proceed rationals allowing fractions taken consideration. following view science carry quantitative study proposed volovich also surveys always rationals make measurements. approximate general. better therefore allow observables continuous i.e. endow topology. therefore need completion ﬁeld rationals. complete ﬁeld rationals need cauchy sequences requires norm archimedean norm that exists integer |y|. convenience here write |x|∞ norm. alternatives? remarkably norms known. besides norm inﬁnity norms |x|p labeled primes ostrowski’s theorem possible norms unambiguous labeling inﬁnite non-archimedean completions ﬁeld endowed topology. cases obtain locally compact completions ﬁelds p-adic numbers. continua. locally compact additive multiplicative haar measures. integrate them reals. denote prime denote non-zero positive integer. p-adic number integers distinct residue classes modulo used p-adic digits. makes point opens range alternative notation options practice.) recall ring allow division ﬁeld does. m-adic numbers form ring; p-adic numbers form ﬁeld. priori -adic numbers form ring. provides reason preferring p-adic m-adic numbers. choice practical issue. indeed adelic numbers possible values extensive discussion adelic number framework). consider encoded using four nucleotides adenine; guanine; cytosine; thymine. replaced uracil. -adic encoding used since prime thereby oﬀers uniqueness. -adic encoding used -adic encoding latter based -digit boolean expressions four nucleotides default norm used based longest common preﬁx p-adic digits start left sequence consider figures illustrating ultrametric distance role deﬁning hierarchy. early inﬂuential paper johnson important survey rammal discussion hierarchy expresses semantics change distinction found ultrametric topology introduced marc krasner ultrametric inequality formulated hausdorﬀ essential motivation study area provided follows. real complex ﬁelds gave rise idea studying ﬁeld complete valuation comparable absolute value function. ﬁelds satisfy strong triangle inequality max. given valued ﬁeld deﬁning to|x− various terms used interchangeably analysis ﬁelds p-adic ultrametric non-archimedean isosceles. natural geometric ordering metric valuations real line whereas ultrametric case natural ordering hierarchical tree. ultrametric space triangles either isosceles small base equilateral. clear symmetries shape ultrametric topology. symmetry patterns used ﬁngerprint data data sets time series many examples this. properties studied every point circle ultrametric space center circle. ultrametric topology every ball open closed ultrametric space -dimensional clear ultrametric topology diﬀerent intuitive euclidean notions. important point keep mind ultrametric space everything lives hierarchy expressed tree. diagonal matrix distances associated ultrametric distance suﬃcient necessary condition permutation rows columns satisﬁes following form matrix illustrate ultrametric matrix format consider small data shown table dendrogram produced figure ultrametric matrix read dendrogram shown table finally visualization matrix illustrating ultrametric matrix properties discussed above figure figure metric data approximate ultrametric made approximate ultrametric case stepwise agglomerative algorithm. query right. easily determine closest target closest really much diﬀerent alternatives? question motivates ultrametric view metric relationships shown. function cartesian product could order. ultrametric matrix properties establish possible distance ultrametric one. matrix involves mode clear rows columns permuted yield order property form matrix small values near principal diagonal. sets here term real-valued. also generalize principle permuting small values near principal diagonal instead allow similar values near another thereby facilitate visualization. optimized pursued comprehensive surveys clustering algorithms area including objective functions visualization schemes optimization approaches presence constraints applications found examples various local symmetries worthy consideration data sets consider subsets data comprising clusters reciprocal nearest neighbor pairs. figure hierarchical clustering iris ﬂowers using data table data normalization used. agglomerative clustering criterion minimum variance ward one. index function stronger condition partial order required subset relation. index function represented ordinate figure bijection exists hierarchy ultrametric space. usually constructive approach used induce eﬃcient algorithms based nearest neighbor chains deﬁnition pair agglomerable reciprocal nearest neighbors. information found subsection consider ultrametric deﬁned power join semilattice. comprehensive background ordered sets lattices found review generalized distances ultrametrics found example consider objects characterized boolean attributes shown figure deﬁne dissimilarity pair objects table components corresponding attributes components either component components simple matching coeﬃcient could e.g. euclidean distance values sought; prefer treat values components signaling contribution. call then call etc. latter create lattice nodes shown middle part figure formal concept analysis lattice primary interest. discussion range examples close relationship traditional hierarchical cluster analysis based theory reasoning monotonic operator rigorous application succession conditionals however negation multiple valued logic require support non-monotonic reasoning. thus once introduces negation certain important operators monotonic consequence knaster-tarski theorem longer applicable them. various ways proposed overcome problem. syntactic conditions programs another consider diﬀerent operators third main solution introduce techniques topology analysis augment arguments based order methods based metrics quasi-metrics ﬁnally ultrametric spaces. convergence ﬁxed points based generalized ultrametric system precisely study spherically complete systems expansive automorphisms discussed section below. expansive automorphisms example symmetry work. ward minimum variance hierarchical clustering method became method choice chemoinformatics community hierarchical nature quality clusters produced. unfortunately method reached limits pharmaceutical companies tried processing datasets compounds processing requirements reciprocal nearest neighbor algorithm; requirement hold chemical structure ﬁngerprints memory enable random access; requirement parallel implementation shared-memory architecture. look alternative hierarchical clustering algorithm bypasses computational diﬃculties. allows hierarchy read directly input data bypasses consideration pairwise distances agglomerative hierarchical clustering. study application chemoinformatics. proximity best match ﬁnding essential operation ﬁeld. typically million chemicals upwards characterized approximate -valued attribute encoding. baire space consists countably inﬁnite sequences metric deﬁned terms longest common preﬁx longer common preﬁx closer pair sequences. baire metric simultaneously ultrametric deﬁned deﬁnition next subsection. interest longest common preﬁx metric additionally ultrametric. longest common preﬁxes issue precision value consider values which context easily allows call precision take integer write numbers ordered. cardinality place; precision number measured. without loss generality normalization take also consider decimal numbers only article distance deﬁned common n-length preﬁx left substring words. words preﬁx tree built expedite word matching baire distance derived tree. equal −|k|. baire distance -bounded ultrametric. tiway tree numbers xik. number indexed precision |k|. actually simple determine hierarchy. partition |k|. strictly ﬁner identical partition found successive level identical numbers level distance identical numbers level distance identical numbers level distance level distance −|k|. rather separate tests equality suﬃcient wjxijk weights helps making suﬃcient condition equality work well practice many xijk values approximate matrix occupancy rate holds table shows immediate succession results three data sets. normalizing column sums calculated applied independently three data sets. insofar directly proportional whether calculated chemical structures million leads constant proportionality random projection ﬁnding dimensional embedding point dimension equals line axis work distortion pair points bounded function lower dimensionality burgeoning literature area e.g. random projection guarantee bijection best match original lower dimensional spaces projection eﬀectively hashing method uses nearest neighbor search) order deliberately hash collisions thereby providing suﬃcient condition mapped vectors identical. prove result require assumption distribution original data follow. general class referred stable distribution distribution limited number weighted sums variables also distribution. examples include gaussian longtailed power distributions. interestingly however high dimensional data sets virtue high relative dimensionality alone points mostly lying vertices regular simplex polygon intriguing aspect reason perhaps found random projection work well. another reason following work normalized data values attributes small. hence small. random weight attribute random projections terms dominated random weights. expect near equal terms work required conﬁrm hypotheses viz. high dimensional data highly regular structured way; that consequence hashing particularly well-behaved sense non-identical vectors nearly always collision-free. discussion remark preﬁx tree trie well-known searching sorting literature used expedite ﬁnding longest common preﬁxes. level nodes associated ﬁrst digit. level nodes associated second digit deeper levels tree. cals denoted |i|; number attributes |j|; total number digits precision |k|. consider particular number digits precision |k|. random projection takes opdendrogram widely used hierarchical agglomerative clustering induced observed data. article important goals show lays bare many diverse symmetries observed phenomenon represented data. expressing dendrogram p-adic terms open wide range possibilities seeing symmetries attendant invariants. introduce one-to-one mapping clusters dendrogram p-adically expressed integers ﬁeld p-adic numbers important example ultrametric spaces. addition multiplication p-adic integers well-deﬁned. inverses exist zero-divisors exist. follows. path given object specifying given terminal embedded classes along path specifying nodes dendrogram. root node speciﬁed class comprising objects. level rank object index. example used left branch right branch node path matrix form encoding follows {·}t denotes transpose column vector xn}t. column vector pn−}t. consider objects dealing equivalent integer values. show that must work decimal equivalents p-adic expressions used noted equivalence between p-adic number; p-adic expansion; element coeﬃcients used specify p-adic number notes must taken representatives class modulo numbers obvious choice note matrix used somewhat trivial view hierarchical trees perfectly scaled dimension p-adic numbering feasible hence dimensional representation terminal nodes easily arranged expressing p-adic number real number equivalent. term looking term looking term looking found value distance deﬁned longest common preﬁx metric also known baire distance discussed section topology baire metric deﬁned inﬁnite strings distance ultrametric bounded inﬁmum relevant long sequences limit inﬁnite-length sequences. baire metric pursued based random projections providing computational beneﬁts classical hierarchical clustering based pairwise distances. scale-related symmetry important practice. subsection introduce operator provides symmetry. also term dilation operator role wavelet transform trees discussion examples). operator p-adic multiplication lost. subject lowest level tree lost form tree remains same. carrying multiplication-by-/p operation objects seen eﬀect rise hierarchy level. implies subset relationship clusters result applying {aq}. repeated application operator gives starting singleton gives path terminal root node benedetto benedetto discuss expansive automorphism i.e. form-preserving locally expansive. implications expansive automorphism follow. take sequence path deﬁned application expansive automorphism deﬁnes spherically complete system formalization well-deﬁned subset embeddedness. methodological framework ﬁnds application multi-valued non-monotonic reasoning noted section section wreath product group used literature framework tree structuring image signal data used -way tree dendrogram data structure. example wreath product invariance provided wavelet transform tree. dendrogram like shown figure invariant representation structuring data relative rotation left right child nodes. rotation symmetries deﬁned wreath product group introduction applications signal image processing) used m-ary tree although treat binary -way case here. view clear represents simply agglomeration clusters called term term replacing cluster term spaces functions constant subsets corresponding cluster agglomerands denoted clusters disjoint initially motivates taking spaces couple exemplify case satisﬁes deﬁned context wreath product invariance targeting. algorithm discussed depth take constant function take constant function deﬁne constant function scaling function next deﬁne zero mean function wavelet function follows discrete wavelet transform decomposition data spatial frequency components. terms dendrogram components respect respectively within clusters successive partitions. show works taking data table inverse transform determined figure following way. consider observation vector vector reconstructed exactly reading tree root similarly path root figure dendrogram terminal nodes constructed ﬁrst values fisher iris data. detail wavelet coeﬃcients denoted data smooths denoted observation vectors denoted associated terminal nodes. signal smooth vector. detail signals also vectors. vectors dimensionality. table hierarchical haar wavelet transform resulting ﬁrst observations fisher’s iris data shown table wavelet coeﬃcient levels denoted continuum smooth component denoted early work p-adic ultrametric wavelets found kozyrev treated case wavelet transform particular graph tree recent applications wavelets general graphs representing graph matrix work shown ambient dimensionality increased distances became ultrametric. hierarchical embedding becomes immediate direct dimensionality increases. better quantifying phenomenon developed means inherent hierarchical structure high dimensional data spaces. shown experimentally points high dimensional spaces become increasingly equidistant increase dimensionality. study gaussian clouds high dimensions. latter ﬁnds points convex hull reasonable-sized subsets span faces convex hull. wildly diﬀerent behavior would expected traditional low-dimensional thinking. simple structures come high dimensions trivial might appear ﬁrst sight. firstly even simple structures used support fast perhaps even constant time worst case proximity search secondly shown machine learning framework important implications ensuing simple high dimensional structures. thirdly shows high dimensional clustered data contain symmetries fact exploited read clusters computationally eﬃcient way. fourthly following might want look contexts considerable symmetry impurities small irregularities detract overall dominant picture. gaussian dimension data mean variance dimen. ambient dimensionality. isosc. number isosceles triangles small base proportion triangles sampled. equil. number equilateral triangles proportion triangles sampled. proportion ultrametricity-respecting triangles ﬁnancial futures circa march denominated euros exchange. data stream millisecond rate comprises records. record includes asking prices together asking sizes cases action. extracted symbol single values report results. figure note -length window case results points strongly fact values window overlapping. overlapping next window. notwithstanding major overlapping regard clusters involved pairwise distances still clusters data versatile tackling clustering objective. greater cluster concentration expect greater embedding dimension points -dimensional space notwithstanding fact points overlapping clusters. distances histogram figure bottom carry gaussian mixture modeling followed bayesian information criterion approximate bayes factor determine best number clusters gaussian mixture model data shown bottom histogram figure derive appropriate number histogram peaks gaussians bayesian information criterion approximate bayes factor model selection figure shows succession outcomes indicates best -gaussian result means gaussians follows corresponding standard deviations respective cardinalities histogram peaks note relates histogram pairwise distances. want determine corresponding clusters input data. ﬁnancial signal could expect peaks distances histogram clusters original ﬁnancial signal could expect peaks distances histogram information consistent asserting evidence figure points histogram peaks approximately co-located conclude clusters original ﬁnancial signal consistent number clusters. determine these. metric multidimensional scaling) pairwise distances. fact -dimensional mapping furnishes similar pairwise distance histogram seen using full dimensionality. ﬁrst axis figure accounts variance second note therefore scales planar representation figure point linear. benz´ecri chapter section discusses guttman eﬀect guttman scale factors mutually correlated nonetheless functionally related. fundamentally unidimensional underlying phenomenon factors functions legendre polynomials. view figure consisting multiple horseshoe shapes. simple explanation shapes terms constraints imposed another view embedded data capable well mapped unidimensional curve critchley heiser critchley heiser show approach mapping ultrametric linearly totally ordered metric. asserted established hierarchy form relevant high dimensional data spaces; linear projection figure consequence note critchley heiser result especially relevant high dimensional data analysis. adjacency-constrained agglomerative hierarchical clustering algorithm clusters figure contiguity-constrained complete link criterion choice sure inversions come hierarchy explained input coordinates figure -dimensional figure representation relates variance. complete basis dimensionality checked results -dimensionality embedding which noted below gave similar results. reading -cluster memberships figure gives signal actually used cluster corresponds signal values cluster corresponds signal values cluster corresponds signal values allows segment original time series figure either original high dimensional data principal coordinates analysis embedding used input sequence-constrained clustering method order determine clusters case clusters deﬁned using complete link criterion implying three clusters determined minimizing maximum internal pairwise distance. provides strong measure signal volatility explanation clusters addition average value. figure interesting representation type return found using principal coordinates analysis successive -dimensional points. demonstration high dimensional structures simple structure. planar projection seen represents information content data ﬁrst axis accounts variance second accounts figure hierarchical clustering points. sequence respected. agglomerative criterion contiguity-constrained complete link method. details including proof inversion dendrogram. among themes covered article data stream clustering. provide background motivaton discuss permutation representations data stream. since hierarchies also represented permutations ready associate data streams hierarchies. fact early computational work hierarchical clustering used permutation representation great eﬀect analyze data streams develop approach ultrametric embedding time-varying signals including biomedical meteorological ﬁnancial other. work pursued physics khrennikov. wrap exciting perspectives opened work theme symmetry-ﬁnding hierarchy large data collections. thesis path construction nontrivial theory complex systems theory hierarchy. thus simon noted symmetry many guises representations used transformations applied transformed outputs. symmetries non-trivial would case simply look classes partition claim cluster members mutually similar way. seen p-adic ultrametric framework provides signiﬁcant focus commonality viewpoint. algorithms. fully capable addressing data information deluge face providing best interpretative decisionmaking tools. full elaboration last point sought every application domain face face problems. seeking determining structure regularity massive data stores that line insights achievements klein weyl wigner data mining data analysis seek determine symmetries data express observed measured reality.", "year": 2010}