{"title": "Studying Very Low Resolution Recognition Using Deep Networks", "tag": ["cs.CV", "cs.AI", "cs.LG"], "abstract": "Visual recognition research often assumes a sufficient resolution of the region of interest (ROI). That is usually violated in practice, inspiring us to explore the Very Low Resolution Recognition (VLRR) problem. Typically, the ROI in a VLRR problem can be smaller than $16 \\times 16$ pixels, and is challenging to be recognized even by human experts. We attempt to solve the VLRR problem using deep learning methods. Taking advantage of techniques primarily in super resolution, domain adaptation and robust regression, we formulate a dedicated deep learning method and demonstrate how these techniques are incorporated step by step. Any extra complexity, when introduced, is fully justified by both analysis and simulation results. The resulting \\textit{Robust Partially Coupled Networks} achieves feature enhancement and recognition simultaneously. It allows for both the flexibility to combat the LR-HR domain mismatch, and the robustness to outliers. Finally, the effectiveness of the proposed models is evaluated on three different VLRR tasks, including face identification, digit recognition and font recognition, all of which obtain very impressive performances.", "text": "regrettably general resolution recognition problem largely overlooked except certain existing efforts face recognition empirical studies face recognition proved minimum face resolution required stand-alone recognition algorithms. even lower resolution results much degraded recognition performance conventional recognition models. severe information loss makes unlikely extract recover sufﬁcient recognizable features directly subjects typically vlrr problem smaller pixels even difﬁcult recognized human viewers. paper make ﬁrst attempt solve vlrr problem using deep learning methods starting simplest baseline perform step-by-step model evolution gradually obtaining sophisticated powerful models. extra complexity introduced fully justiﬁed analysis simulation results. ﬁnal outcome named robust partially coupled networks achieves feature enhancement recognition simultaneously. equipped ﬂexibility combat cross-resolution domain mismatch robustness outliers. proposed models applied resolving real vlrr problems three different tasks including face identiﬁcation digit recognition font recognition obtain impressive performances. real-world settings vlrr directly recognizes visual subjects low-resolution images without predeﬁned high-resolution image. here introduce images auxiliary variables model training assuming training image versions available. veriﬁed following experiments images help discover discriminative features prone overlooked images. testing images available vlrr visual recognition research often assumes sufﬁcient resolution region interest usually violated practice inspiring explore resolution recognition problem. typically vlrr problem smaller pixels challenging recognized even human experts. attempt solve vlrr problem using deep learning methods. taking advantage techniques primarily super resolution domain adaptation robust regression formulate dedicated deep learning method demonstrate techniques incorporated step step. extra complexity introduced fully justiﬁed analysis simulation results. resulting robust partially coupled networks achieves feature enhancement recognition simultaneously. allows ﬂexibility combat lr-hr domain mismatch robustness outliers. finally effectiveness proposed models evaluated three different vlrr tasks including face identiﬁcation digit recognition font recognition obtain impressive performances. object recognition research witnessed substantial achievements often assumed region interest large enough contains sufﬁcient information recognition. however assumption usually hold practice. typical example face recognition video surveillance prohibitive costs installing high-deﬁnition cameras around surveillance systems rely cameras limited deﬁnitions. besides wide-angle cameras normally used viewing area maximized. turn face region scene extremely small low-quality. text recognition system cheap versatile cameras make possible quickly scan documents deﬁnitions also present challenges ∗zhangyang wang thomas huang’s research works supported indeed absolute boundary images. however literature object scene recognition observed signiﬁcant performance drop image resolution decreased pixels authors also reported degradation recognition performance face regions became smaller pixels. follow choose image resolution less paper treat original training images images unless otherwise speciﬁed. generate images training downsample original images factor upscale back original resolution nearest neighbor interpolation. upscaling operation intended ensure sufﬁciently large spatial supports hierarchal convolutions well facilitate feature transfer. since interpolation bring information upscaled images treated default images hereinafter. deep convolutional neural networks recently shown explosive popularity partially prevailing success image recognition tasks various subjects faces digits texts fonts however models assume reasonable resolutions rois popular datasets imagenet mostly come moderate high image resolutions remains unexplored whether performances conventional cnns still reasonable vlrr tasks. thus start investigating basic single vlrr simplest baseline. fig. illustrates model similar popular imagenet structure convolutional layers fully-connected layers. since images vlrr problems much information extracted hierarchically refer deeper architectures. i-th convolutional layer assume channels ﬁlter sizes stride note image vlrr problems contains little self-similarity utilized often corrupted. therefore veriﬁed experiments applying large convolutional ﬁlter sizes extract patches etc.) brings little beneﬁts. fully-connected layers dimensionality respectively. network trained suggested many others. simulation popular cifar- cifar- datasets simulation subjects. cifar- dataset consists color images classes images class. class images training testing. cifar- dataset like cifar- total volume except classes containing images each. experiments convert images gray scale model simplicity. original images ﬁrst downscaled upscaled back interpolation images. image subtract mean normalize magnitude later back recovered image. small additive gaussian noise added default data augmentation training. implement models using cuda-convnet package relu adopted neuron. batch size learning rate starts divided training curve reaches plateau. dropout also applied. also compare vlrr models trained inputs trained original images. size last fully-connected layer always chosen number classes e.g. cifar- cifar-. ﬁxed default. vary network conﬁgurations examine baseline performances affected outlined table following important insights readily concluded performances vlrr models input images largely degraded compared obtained images. experiments adding ﬁlter channels generally helps hurt vlrr performances. likely result model overﬁtting since subjects contain scarce visual features. addition increasing size marginally rises performance bringing signiﬁcant complexity. also tried repeat conv. layer deeper architectures ending observation increasing depth contribute visibly vlrr since images rich visual semantic information. ﬁndings demonstrate distinct characteristics vlrr vlrr problems beneﬁt much larger ﬁlter sizes ﬁlter channels deeper models conventional visual recognition problems therefore adopt following moderate conﬁguration default table reminds directly classifying visual objects unreliable prone overﬁtting since visual features scarce highly degraded. hand noteworthy although images available real testing could still utilized training auxiliary information obtained enhanced features. classical paradigms ﬁrst apply super-resolution algorithm image classify result recently performance noticeably improved deep network models however recovered images still suffer inevitable oversmoothness detail loss also various artifacts introduced reconstruction process undermine subsequent recognition performance. authors incorporated discriminative constraints learn relationship face images recognition. class-speciﬁc facial features included prior. close loop apfigure super resolution sub-network pretraining part model note contain fullyconnected recognition sub-network fig. conv. layer channel discarded pre-training. model decomposed version model sub-networks super resolution sub-network unsupervised pre-training recognition sub-network supervised ﬁne-tuning. outlined fig. sub-network consists four convolutional layers takes images inputs outputs. trained unsupervised predict nonlinear mapping images. compared convolutional parts fig. easy notice newly added conv. layer channel. revealed layer acts linear ﬁlter averages input feature maps produce ﬁnal reconstruction. sub-network trained conv. layer discarded fully-connected layers well softmax classiﬁer added top. entire network exactly topology model jointly tuned supervised manner. earlier multi-layer feature learning methods auto-encoder denoising auto-encoder perform pre-training weights using unlabeled data alone reconstruction followed supervised ﬁne-tuning previous work showed unsupervised pre-training appeared play regularization role predominantly. model shares similar idea targets unsupervised part instead reconstruction. ﬁnal supervised ﬁne-tuning correlate unsupervised features class labels. resulting network aims achieve resolution enhancement recognition simultaneously. simulation classiﬁcation error rate cifar- error rate reduced decrease remark since one-to-many problem many plausible solution impossible ensure added details authentic original image. contrast object recognition tries identify many. then concern reasoning pre-training could possibly improve visual recognition performance? explanation guaranteed faithful hallucinated details pre-training help discover subtle discriminative features beneﬁt recognition. otherwise prone overlooked images. though limited improvements obtained introducing pre-training large performance around cifar-/ still exists models trained inputs. performance gap? hypothesis pre-training process bring enough discriminative ability recognition purposes hypothesis evidenced look visualizations ﬁlters learned either inputs. clearly visible edges curves ﬁlters ﬁlters learn much fewer recognizable patterns suffer dead ﬁlters. idea discover discriminative features blending images training data. domain adaptation viewpoint. goal equivalent learning transferable features resembles domain adaption scenarios. images constitute source domain images target domain. hypothesized intermediate representations could shared across variants input distribution. model learned cross-domain feature extraction using unlabeled data domains. classiﬁer trained transformed labeled data source domain tested target domain. data augmentation viewpoint. since model images already training look questionable inputs still help information would added. explanation blending images original training data could treated problem-speciﬁc data augmentation approach pre-training. common data augmentations would corrupt modify training images many ways. similarly introduction images alternatively viewed augment original images transforming versions. difference enhances figure super resolution sub-network enhanced lrhr feature transfer pre-training part model iii. note contain fully-connected recognition sub-network fig. super resolution sub-network model shown fig. related domain adaption techniques context domain adaption treat images related non-overlapping domains. sub-network could viewed fully-coupled channels. lr-hr channel reconstructs domain samples domain samples essentially equivalent sub-network model hr-hr channel reconstructs domain samples themselves supposed learn discriminative features former one. enforcing channels fully-shared hidden layers model aims learn cross-domain transferable features. shared ﬁlters hr-hr channel lr-hr channel also expected obtain enhanced features pre-training task. simulation ﬁrst pre-train unsupervised model enhanced feature transfer fig. followed supervised tuning. experiment settings follow previous ones except training hybrid model choosing smaller learning rates helps faster steady convergence. practice start learning rate anneal training. cifar- error rate reduced cifar- error rate goes fully shared feature representation across domains. since lr-hr pair indicates scene object reasonable assume exists hidden space approximately shared features however assumption data strictly equal feature representations coupled subspace appears overly strong. explored previously mappings spaces complex spatial-variant nonlinear. taking face recognition example empirically showed similarity measures spaces identical direct matching probe image within gallery performed poorly. domain mismatch images further enlarged noise blur corruptions generating images. make bold hypothesis image features fully overlap even highly sophisticated transforms. therefore attempt relax model order certain ﬂexibility cope feature variances mismatches domains. fig. depicts partially coupled networks pre-training part model pcsrn built unsupervised channels fig. major difference pcsrn subnetwork model lies former loosely coupled sharing convolutional ﬁlters layer tend capture commonality feature patterns across domains based hypothesis pcsrn also allows single channel learn domain-speciﬁc features unshared ﬁlters complement shared features handle mismatches. fig. could also viewed special case fig. pcsrn pre-trained follow routine replace conv. layer fully-connected layers followed softmax classiﬁer independently top. channel exactly topology model iii. whole two-channel model ﬁne-tuned supervised manner. either channel classiﬁes input parts still interact taking advantage shared ﬁlters. testing decouple model left lr-hr channel fig. including shared ﬁlters. these shared features usually basic correspondences mostly persists resolution changes pixel intensity histogram strong edges speciﬁc structural layouts make foundation cross-resolution recognition figure partially coupled networks pre-training part model note contain fullyconnected recognition sub-networks. channel recognition sub-network fig. channels share convolutional ﬁlters i-th layer. learned transforms. gives rise important extra ﬂexibility transfer knowledge across domains. despite looking like reckless idea beneﬁts validated next. fig. outlines general idea still unclear whether much performance gains could obtained complicated architecture. addition many ﬁlters coupled? answer them conduct quantitative research cifar-/ cases. numbers ﬁlters vary numbers shared ﬁlters deﬁne coupled ratio layer ki/ni note model splits uncorrected parts equivalent model contrary leads fully-coupled model iii. identify best conﬁguration perform course grid search step size even brutal-force search leads training models least conﬁgurations. avoid exhaustive effort develop strategy referring common belief domain adaptation discrepancy domains expected gradually reduced layers goes deeper hence always give priority increasing deeper layers error rate tends rise roll back last change instead increase coupled ratio immediate lower layer. summarized table results strongly support previous non-overlapping hypothesis. fact partially coupled models tried table obtain better performances model superior model well. moreover observed higher layers sensitive overregularization lower layers. example simply increasing ﬁxed raise error rate cifat- result choose default conﬁguration hereinafter. resulting model gradually narrows domains increasing number layers still allows certain ﬂexibility channel domain-speciﬁc features. veriﬁed partially coupled architecture could lead additional gains compared fully-coupled model. however remains unresolved adaptively choose best speciﬁc cases instead ad-hoc trials. potential solution learn mapping function regularizes intrinsic relationship domain-speciﬁc representations beyond vlrr partially coupled architecture could potentially applied many cross-domain recognition problems. leave future work. help pre-training well ﬂexible partially-coupled domain adaptation obtain satisfactory results cifar-/ data artiﬁcially downsampled clear groundtruth. however typical real data low-resolution sources video surveillance usually accompanied sensor noise impulsive outliers. even high-resolution cases outlier factors destroy manifold structure badly. example could found face recognition since faces neither perfectly convex lambertian face images taken directional illumination often suffer self-shadowing specularity saturations brightness. pose expression changes also introduce spatially localized artifacts makes fraction data grossly corrupted. adopt mean-square error loss function pre-training could rather sensitive outliers. argue works widely well unsupervised deep learning models e.g. burger showed plain multi-layer perceptrons produce decent results handle different types noise. fact observed learning ability deep systems could weakened outliers pervasive real-world data robust learning methods proposed immunize harmful inﬂuences caused outliers. correntropy-induced loss function proposed combat outliers authors concatenated another speciﬁc denoising handle complex signal-dependent outliers cost growing parameter volume merge. replace loss model convex continuous huber loss function pretraining. name robust partially coupled networks model huber loss widely used robust regression lower sensitivity outliers. comprises parts corresponding losses formally deﬁned vlrr outliers possess much stronger negative impact conventional recognition since images supply sufﬁciently representative feature distribution sketch correct data manifold. huber loss greatly alleviates problem. adopt clean cifar-/ data creating corrupted versions adding salt-and-pepper impulse noise randomly selected pixels before downsampling. test model datasets whose difference lies choice huber loss pre-training. dropout applied models. empirical value suggested many others. pre-training observe huber loss appears accelerate model convergence bit. table performances huber loss almost identical outlier-free cases becomes superior presence outliers ﬁnally gains remarkable margin outliers. compare models table evaluate whether bring extra complexity. general methodology design evolve models focus adapting model speciﬁc task speciﬁc data domains apply proposed models solve three vlrr applications. model conﬁgurations parameters training details similar cifar-/ simulation cases unless otherwise speciﬁed. here refer parameter complexity. example training data doubles model amount free model parameters keeps unchanged. therefore parameter complexity same training time deﬁnitely increases. vlrr face identiﬁcation dataset although many face image datasets scface cmu-pie developed collected controlled indoor environments limited variability. uccs dataset recently proposed larger challenging benchmark unconstrained face recognition. authors reported baseline face identiﬁcation result around top- accuracy -subject subset original-resolution images extracting face attributes using classiﬁcation. normalize cropped face regions downsample factor images perform evaluations -subject subset subject images. images training remaining testing. performance considering training data sufﬁcient perform layer-by-layer greedy unsupervised training models. fig. performances consistently improve model evolves ﬁnally reaching .%top- .%top- signiﬁcant margin around %top- simplest baseline. model correctly classiﬁes testing samples top- results top-. model reaches improvement model model improves identiﬁes role hallucinated features task pre-training lr-hr transfer. besides free model parameters partially-coupled architecture contributes performance rise .%top-. finally utility huber loss brings extra gain .%top-. vlrr digit recognition dataset svhn real-world massive digit image dataset highly complex scenes. note median digit height pixels images original heights less pixels validates svhn proper research object vlrr. utilize images training testing covering classes. images resized images obtained downsampling training images available testing sees images. note preprocessing svhn introduces distracting digits sides digits interest strong outliers could largely confuse models considering highly noise-sensitive nature resolution images performance calculate top- top- error rates models. fig. model still achieves lowest error rates impressive records .%to- .%top-. note human top- accuracy original svhn images heights less pixels around also special attention model obtains .%top- margin model showing great beneﬁts robust huber loss especially existence strong outliers another performance .%top- between model proves lr-hr transfer enhances feature learning. addition fullycoupled partially-coupled architecture demonstrate .%top- difference. pixels) majority vlrr images fail recognized even latest model heavy detail loss compression artifacts normalization. overcome explicitly taking resolution-enhancement account training formulating vlrr problem. training images downsampled random factor obtain images heights pixels intention make learnt model robust wide range resolutions testing. performance identical training testing sets fulﬁlls task emphasis improving recognition ability vlrr subjects. follow data augmentations train models. pretraining lr-hr transfer partially-coupled networks still lead visible gains interesting notice model hardly beneﬁts huber loss. might part small sample size; importantly training contains rendered synthetic data without outliers makes robust loss unnecessary unsupervised training. proposed model reaches error rates .%top- .%top-. outperforms best accuracy numbers reported before .%top- .%top- closer inspection reveals model correctly classify vlrr images top- results. dataset dataset used includes font classes. class synthetic text images rendered training normalized height testing collected real-world images classes various dimensions. statistics show approximately testing images fall vlrr cases (e.g character heights less paper study challenging vlrr problem using tool deep networks. starting simplest baseline gradually evolve models step well motivated justiﬁed. addition large learning capacity ﬁnal model also beneﬁts pre-training domain adaptation partial ﬂexibility robust loss. effectiveness proposed models evaluated three different vlrr tasks outstanding performances obtained.", "year": 2016}