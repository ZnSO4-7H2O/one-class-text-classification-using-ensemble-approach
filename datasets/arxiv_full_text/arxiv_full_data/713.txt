{"title": "Evolving Spatially Aggregated Features from Satellite Imagery for  Regional Modeling", "tag": ["stat.ML", "cs.CV", "cs.NE"], "abstract": "Satellite imagery and remote sensing provide explanatory variables at relatively high resolutions for modeling geospatial phenomena, yet regional summaries are often desirable for analysis and actionable insight. In this paper, we propose a novel method of inducing spatial aggregations as a component of the machine learning process, yielding regional model features whose construction is driven by model prediction performance rather than prior assumptions. Our results demonstrate that Genetic Programming is particularly well suited to this type of feature construction because it can automatically synthesize appropriate aggregations, as well as better incorporate them into predictive models compared to other regression methods we tested. In our experiments we consider a specific problem instance and real-world dataset relevant to predicting snow properties in high-mountain Asia.", "text": "abstract. satellite imagery remote sensing provide explanatory variables relatively high resolutions modeling geospatial phenomena regional summaries often desirable analysis actionable insight. paper propose novel method inducing spatial aggregations component machine learning process yielding regional model features whose construction driven model prediction performance rather prior assumptions. results demonstrate genetic programming particularly well suited type feature construction automatically synthesize appropriate aggregations well better incorporate predictive models compared regression methods tested. experiments consider speciﬁc problem instance real-world dataset relevant predicting snow properties high-mountain asia. regional modeling focuses explaining phenomena occurring regional opposed site-speciﬁc global scales regional models interest many remote sensing applications provide meaningful units analysis actionable insight policymakers. satellite imagery remote sensing provide variables relatively high resolutions. consequently studies often involve decisions concerning integrate information order model regional processes. considering measurements individual spatial unit separate model feature result high dimensional problem high variance overﬁtting major concerns. reason spatial aggregation often applied setting uniformly up-sample variables consistent response. although averaging variables across spatial units region discard information could turn diminish prediction accuracy understanding underlying phenomena. rather strictly incorporating individual spatial units uniformly upsampling might instead beneﬁcial construct features regional model using particularly important subsets geographical space. paper move away uniform up-sampling aggregations towards ﬂexible interesting aggregation operations predicated subsequent features regional model. propose novel method inducing spatial aggregations component machine learning process yielding features whose construction driven model performance rather prior assumptions. experiments designed explore techniques consider speciﬁc problem real dataset estimating regional snow water equivalent high-mountain asia satellite imagery. improved estimation mountainous regions critical diﬃcult part complex characteristics snow distribution take comparative approach problem considering ridge regression lasso gp-based symbolic regression. regression model consider ﬁlter-based method feature construction addition second dynamic method. linear regression incorporate wrapper approach constructed features regression model induced separate learning processes feedback two. symbolic regression embedded approach constructed features regression model induced simultaneously course evolutionary run. dataset. dataset derived data collected nasa’s advanced microwave scanning radiometer moderate resolution imaging spectroradiometer march september area spans high mountain asia. three explanatory variables measured daily across regular grid days mean standard deviation sub-pixel snow covered area well estimate derived passive microwaves response variable regional attribute entire study region represented single value days. response reconstructed combining snow cover depletion record calculation melt rate retroactively estimate much snow existed region ridge regression similar ordinary least squares subject bound l-norm coeﬃcients. nature quadratic constraint ridge regression cannot produce coeﬃcients exactly equal zero keeps features model. lasso modiﬁes ridge penalty subject bound l-norm coeﬃcients. geometry l-penalty strong tendency produce sparse solutions coeﬃcients exactly equal zero. many high dimensional settings lasso state-of-the-art regression method given ability produce parsimonious models excellent generalization performance. lasso ridge regression parameter constraining coeﬃcients cross-validation. genetic programming ﬂexible heuristic technique conveniently represent free-form mathematical equations parse trees. gp’s inherent ﬂexibility well-suited particular problem eﬃciently express spatial aggregations seamlessly combine learning process minimal assumptions. furthermore white nature provide physical insights complex problem currently lacking domains search space possible trees variant age-fitness pareto optimization afpo multiobjective method relies concept genotypic attribute intended preserve diversity. extend afpo include additional objective model size deﬁned syntactic length individual tree. size attribute protects parsimonious models less prone overﬁtting training data. algorithm therefore identiﬁes pareto front using three objectives error size. ﬁtness objective correlation-based function rather pure error deﬁne fcor denotes pearson correlation model predictions actual values response regional swe. correlation recently shown outperform error-based search drivers given model makes systematic error could easily eliminated linearly scaling output therefore protected accordingly implementations apply linear transformation fcor -driven evolution concluded using individual program output single input training data. implemented experiments used ramped half-and-half initialization height range instruction including unary binary functions thousand individuals population subject crossover mutation course generations. static limit tree height well tree size experiment consists evolutionary runs best model selected. selected model transformed using subsequently validated using unseen test data. standard methods. ridge regression lasso performed data using variable individual spatial unit separate feature. denote methods standard ridge standard lasso standard access features observations fold data. feature construction well studied problem utility genetic programming feature construction recognized many previous studies diﬀerence work past work nature data modeled. presume exist spatial autocorrelations varying size shape that aggregated improve signal noise ratio yield features supporting accurate predictions. regional model construct features aggregating higher dimensional variables across space. however entirely clear kind aggregations useful features predictive model. grouping variables based similarity dissimilarity necessarily produce useful regional features. paper make assumption importance distance continuity eﬀective spatial aggregations based tobler’s ﬁrst geography states everything related everything else near things related distant things. accordingly limit space possible spatial aggregations average values within circular spatial area deﬁned centerpoint radius. however aggregate many aggregations perform combine aggregates must still determined manually decided model optimization. view ﬁlters wrappers intermediary steps relaxing assumptions towards embedded approach automates three aspects. filter method. filter-based feature construction methods transform ﬁlter original variables preprocessing step prior modeling. ﬁlter problem represents static up-sampling transformation original variables. variable decomposed space grid overlapping circles equal radii centered square lattice pattern points constructed feature corresponds average particular variable sampled within particular circle space. units reside overlapping region separate circles included calculation features. since three explanatory variables dataset grid corresponds constructed features. constructed features used inputs ridge regression lasso refer filtered ridge filtered lasso filtered also specify value used particular model instance subscript e.g. denotes filtered ridge consider ﬁlters however note standard methods essentially ﬁlters albeit non-overlapping square pixels. ridge regression lasso order enable circular sampling regions deﬁne center radius. circles longer ﬁxed grid predetermined size. instead constructed feature uniquely parameterized coordinates center unit latitude longitude tuple radius single value ﬂoating point number center spatial unit region including edge raster. radius restricted within ﬂexible enough contain single unit span entire region wrapped ridge wrapped lasso separately ridge/lassodriven hill climbing algorithm construct features minimize mean absolute actual value response error i.e. output predicted model observations. algorithm uses number circles three variables initializing parameters randomly. iterations single constructed feature randomly selected subject gaussian mutation parameters standard deviation equal radius centered zero. ridge/lasso model reﬁt mutated features using random subset data sampled without replacement. mutation lowered model error complementing training data left change accepted. otherwise mutation undone. proposed mutation radius would take outside restricted range bounced-back distance would exceeded boundary. example random mutation would result radius becomes thirty restarts used best model based training data selected. consider wrappers corresponding features really means modiﬁable parameters. embedded method. using allow ﬂexibility respect placement number aggregations well combined form model. however stochastic optimization methods like cannot easily reﬁt manner deterministic algorithms like ridge regression lasso. therefore using wrapper approach computationally infeasible. instead modiﬁcations aggregated features implemented mutation-based operators. genetic programming embedded spatial aggregation introduced here constructed features represented parameterized tree terminals parameters constructed features randomly initialized manner wrapper method separately terminal individual population. greedy gaussian mutations parameters randomly selected constructed feature occur population probability generation. mutations mean zero standard deviation subject bounce-back rule. similarly mutations mean distance zero standard deviation iterations greedy mutations modify parameterized terminals within particular tree. modiﬁcation accepted successfully reduces average error random subsets training data sampled replacement. aside stochastic application another diﬀerence wrapper method’s hill climbing algorithm gpesa’s greedy mutations overall regression model stays mutations rather reﬁt mutation. validation. order validate generalization models partition dataset nine overlapping folds. fold corresponds leaving year testing training remaining eight unseen test data metric assess model performance. account diﬀerence scale across features input model features standardized time removing mean scaling unit variance. means wrapper embedded methods construct aggregations sampled data scaled time prior averaged space. since goal near-real-time estimation future training values feature’s mean variance reapplied scaling feature validation. fig. gpesa standard terminals replaced specialized aggregation operators allow automation number location size aggregations combined form predictive model. here aggregations taken evolved cyan magenta regions combined adjusted scalar value. table displays test error valid regression feature construction method combination. ﬁlters wrappers best performing model displayed indicate particular value parameter subscript. since ultimate goal paper synthesize method better existing approaches must statistically compare gpesa state-ofthe-art linear regression variable selection algorithm. null hypothesis interest diﬀerence gpesa therefore perform yearly wilcoxon signed rank tests comparing gpesa bonferroni correction across nine years. nine test years gpesa signiﬁcantly better four years signiﬁcant diﬀerence table median mean-absolute error corresponding standard errors parentheses. best testing ﬁlterwrapper-based results displayed. explicitly compare gpesa state-of-art bold values indicate signiﬁcance wilcoxon singed rank test null hypothesis asserts distribution diﬀerences gpesa symmetrically distributed displaying best testing ﬁlters wrappers focus speculation gpesa performance conservative lens. ultimately view ﬁlters wrappers intermediary steps working gpesa. accordingly best test error better represents bound potential performance particular intermediary method even though possible achieve performance parameter sweep based training data. indeed across methods tested gpesa reported lowest recorded median mean-absolute error within years second lowest. results show incorporating dynamic aggregations higher resolution variables regional model beneﬁcial particular problem setting compared uniform up-sampling variables state-of-the-art linear regression technique incorporates individual spatial units. achieves competitive prediction performance sparse linear combination individual spatial units linearly constrained. ultimately gpesa performed signiﬁcantly better majority cross validation folds. moreover whenever gpesa signiﬁcantly better signiﬁcantly worse. main reason gpesa advantage application difﬁculty knowing priori important spatial datapoints best aggregate them. additionally structure model unknown depends resulting aggregations. therefore ﬁxed length optimization problem makes well-suited gpesa search diﬀerent numbers non-linear combinations spatial aggregations. theoretically perform aggregation gpesa terminal restricted single linear solution gpesa not. however it’s important emphasize computational cost gpesa higher traditional much higher linear regression. particular expensive operation aggregation component gpesa makes ﬁtness evaluation require time sgp. part incurred cost ineﬃciencies implementation necessitated copy spatial aggregation operations. future work look reducing overhead eﬃcient data structures importance spatial data. better understand relevance particular spatial locations deﬁne importance spatial unit linear symbolic methods separately. ridge regression lasso deﬁne importance exploiting disposition coeﬃcients larger variables stronger correlation response relative particular feature set. deﬁne linear regression importance particular spatial unit average absolute coeﬃcient features incorporate unit regression model. cannot easily determine relative importance within nonlinear models instead deﬁne importance exploiting multiple candidate solutions provided stochastic multiobjective optimization. deﬁne importance particular spatial unit average absolute correlation nondominated solutions incorporate unit. visualize importance spatial information generated series heatmaps figures show regional importance values ﬁlter methods relevant value annotated upper left corner box. note lassogpbased approaches variables unused ridge cannot perform variable selection uses all. figures plot finally figures plot importance spatial information sense gpesa respectively. overall visualization indicates agreement among methods relatively higher importance information lower center/right region image. work developed novel method address problem modeling regional response high resolution satellite imagery. moved away uniform up-sampling aggregations towards ﬂexible interesting aggregation operations predicated subsequent features regional model. proposed technique gpesa general intended apply variety modeling problems spatially organized data. application example setting evaluate techniques considered problem estimating snow water equivalent high mountain asia using satellite imagery. results showed using evolve spatial aggregations outperforms lasso state-of-the-art method directly incorporating individual spatial units sparse linear model.", "year": 2017}