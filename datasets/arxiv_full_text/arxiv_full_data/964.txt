{"title": "End-to-end Continuous Speech Recognition using Attention-based Recurrent  NN: First Results", "tag": ["cs.NE", "cs.LG", "stat.ML"], "abstract": "We replace the Hidden Markov Model (HMM) which is traditionally used in in continuous speech recognition with a bi-directional recurrent neural network encoder coupled to a recurrent neural network decoder that directly emits a stream of phonemes. The alignment between the input and output sequences is established using an attention mechanism: the decoder emits each symbol based on a context created with a subset of input symbols elected by the attention mechanism. We report initial results demonstrating that this new approach achieves phoneme error rates that are comparable to the state-of-the-art HMM-based decoders, on the TIMIT dataset.", "text": "replace hidden markov model traditionally used continuous speech recognition bi-directional recurrent neural network encoder coupled recurrent neural network decoder directly emits stream phonemes. alignment input output sequences established using attention mechanism decoder emits symbol based context created subset input symbols selected attention mechanism. report initial results demonstrating approach achieves phoneme error rates comparable state-of-the-art hmm-based decoders timit dataset. speech recognition challenging transform long sequence acoustic features shorter sequence discrete symbols words phonemes. problem difﬁcult sequences unequal length also precise location output symbol input sequence often known advance. therefore straightforward building classiﬁer predicts target frame input signal. speech recognition model must instead learn align output sequence input sequence recognize content utterance. model investigated work recurrent neural network trained without explicit alignment input output sequences. decoding model keeps track position input sequence attention mechanism. step decoding model ﬁrst scores input frames hidden state soft-select relevant input frames. next summarizes selection context vector uses update hidden state generate next output symbol. model achieves phoneme error rate timit dataset comparable state-of-the dnn-hmm systems slightly worse best reported error rates obtained using rnns. however noted model easy apply requires narrow beam search found accuracy deteriorates slightly greedy search used recognition. also easy implement tune possible obtain training target frame acoustic input coupling neural network hidden markov model hybrid system neural network acts acoustic model predicting state corresponding input frame. since target provided input frame train neural network usual minimizing classiﬁcation error. per-frame classiﬁer trained whole system including acoustic model tuned jointly full sentences minimize decoding error hybrid approach recently made important progress adopting accoustic model deep neural networks fully-connected feedforward neural networks convolutional networks recurrent networks hybrid architecture however rather complicated requires controlling relative contribution part model decoding error. moreover training needs performed multiple stages beginning hybrid architecture gaussian mixture model used generate per-frame target states followed iteratively training acoustic model re-estimating transition probabilities hmm. furthermore reported instance graves improvements per-frame classiﬁcation necessarily translate decoding accuracy. contrast earlier works proposed minimize ﬁnal decoding error directly optimizing costs along paths alignment/decision graph along line research graves proposed recently alternative approach called connectionist temporal classiﬁer used without explicit input-output alignment. ctc-based model per-frame prediction either desired outputs special separator symbol. ﬁnal sequence obtained removing separators merging blocks consecutive identical output symbols. forward-backward algorithm used exactly compute probability desired output sequence given per-frame predictions. extension graves proposed transducer. unlike seen acoustic-only model transducer another acts language model. transducer composed parts transcription network produces frame input sequence either target symbol separator prediction network generates ﬁnal sequence outputs without separators repeated symbols. components allow transducer model probability observing next output symbol given position input output sequences. similarly probability observing output sequence given input computed using forward-backward algorithm. transducer computes score possible output token based position input output sequences. originally score obtained multiplying separate scores transcription prediction networks. graves hand used separate multi-layer perceptron combine scores transcription prediction networks achieved state-of-the-art performance timit dataset. attention mechanism respect ﬁrst used graves build neural network generates convincing handwriting given text. step network predicts window input sequence corresponds character currently written. similar approach attention used recently so-called neural machine translation model case generating target word network computes score matching hidden state output location input sequence attention mechanism decides look input sequence provide context emitting next output generative output iteratively predicts next phoneme conditioned state context. visual simplicity shown context computation. unlike handwriting generation network attention mechanism neural translation model assign high scores non-adjacent locations input sequence allows perform long-distance word reordering. addition uses features input sequence extracted bidirectional recurrent neural network output state order predict alignment probabilities. paper propose model based neural translation model suited speech recognition. allow learned soft alignment procedure take relative position account penalty helping attention mechanism choose single narrow mode encourage mode attention move forward. helps model search nearby potentially near-future input frames given current belief/state output symbols generated. learned dependency relative position successive points attention further used speed decoding ﬁnal model consider tiny section input sequence generating output symbol. word decoder used sense comes auto-encoder analogy encoder producing internal representation input sequence decoder mapping output sequence distribution. different usual word decoder speech recognition systems talk figure alignments produced model alignment successfully encouraged monotonic model free select frame input sequence. plot contains scores computed attention mechanism previous hidden state input annotations. observe absence learned preference monotonicity makes model confused repeated occurrence phonemes lesser degree repetition previous current state vectors prediction next output. recurrent state update computed using afﬁne layer reset-update gate used activation function keep track long-term dependencies. next output prediction realized composed maxout softmax layers. search algorithm approximately looks probable conﬁguration latent output variables e.g. using beam-search. also approximate search mechanism look probable output sequence given input sequence. normalized weight annotation effectively means decoder selects annotation certainty αoi. selection performed steps. first scores computed match previous state decoder annotations. scores penalized based relative position current previous selection normalized proposed addition gating procedure understood follows. attention mechanism searches input sequence frames match current state decoder. however utterance repeated phonemes similar annotations consequently result matching similarly sounding locations shown fig. gating procedure prevents behavior conﬁning search locations near inputs relevant previously generated symbol. however important notice shape gating function deﬁned priori learned. fig. show shape learned gating function. directly encodes preference input frames steps away previously searched input location eαo−. clearly model automatically learned prefer approximately frames future strongly inhibit selection past frames mass concentrated would like constrain selection frames consecutive outputs advance monotonically time. motivate network monotonic alignments design penalty added optimization cost. penalize alignment maps inputs already considered output emission. since selection weights normalized cumulative input sequence monotonically increasing bounded range encourage monotonicity alignment time optimization cost differences cumulative example penalty term shown fig. ﬁgure shows alignment weights cdfs computed along penalty cost intuitively proposed penalty encourages attention mechanism select nearby locations input sequence future rather past respect previously selected location. effect proposed penalty term together gating procedure clearly observed fig. fig. gating procedure penalty term used alignment time step conﬁned small subset consecutive locations monotonic. hand alignment without proposed penalty shown fig. clearly show properties. although regularization term could hyper-parameter coefﬁcient multiplying preliminary experiments suggested value worked well optimize further. encoder implemented using cascade multilayer maxout network whose last layer bi-directional chosen hybrid architecture combine ability maxout network nonlinearly transform speech features efﬁcient summarization nearby preceding following input frames provided birnn. birnn uses reset-update gate account long-term dependencies model trained minimize negative log-likelihood observing correct phoneme sequences conditioned recorded utterances extra penalty terms added promote alignment monotonicity weight decay applied weights output evaluated model timit dataset. baseline score established using recipe kaldi toolkit using score basic.sh scoring script. results gathered table models trained recognize phonemes predictions converted phoneme scoring. sentences removed training testing sets. models evaluated speaker core test auxiliary speaker development used select best network. gmm-hmm dnn-hmm hybrids used phoneme bi-grams language model used decoding. attention-based recurrent network used language model. similarly kaldi’s recipe kept training data validation resulted ﬁnal -way split data testing development validation training sets. networks trained speaker adapted fmllr features obtained using gmm-hmm built stage recipe provided kaldi. acoustic frame described using features however network access segments frames totaling features frame. furthermore used triphone gmm-hmm model force-align data obtain per-frame training targets. scoring scripts provided differing errors silence phone counted. basic scoring script treats error sclite scorer conﬁgured disregard errors related recognizing silence phones.", "year": 2014}