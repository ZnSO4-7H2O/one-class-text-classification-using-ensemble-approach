{"title": "Visualizing Deep Neural Network Decisions: Prediction Difference  Analysis", "tag": ["cs.CV", "cs.AI"], "abstract": "This article presents the prediction difference analysis method for visualizing the response of a deep neural network to a specific input. When classifying images, the method highlights areas in a given input image that provide evidence for or against a certain class. It overcomes several shortcoming of previous methods and provides great additional insight into the decision making process of classifiers. Making neural network decisions interpretable through visualization is important both to improve models and to accelerate the adoption of black-box classifiers in application areas such as medicine. We illustrate the method in experiments on natural images (ImageNet data), as well as medical images (MRI brain scans).", "text": "luisa zintgraf taco cohen tameem adel welling university amsterdam canadian institute advanced research vrije universiteit brussel {lmzintgraftameem.hesham}gmail.com {t.s.cohen m.welling}uva.nl article presents prediction difference analysis method visualizing response deep neural network speciﬁc input. classifying images method highlights areas given input image provide evidence certain class. overcomes several shortcoming previous methods provides great additional insight decision making process classiﬁers. making neural network decisions interpretable visualization important improve models accelerate adoption black-box classiﬁers application areas medicine. illustrate method experiments natural images well medical images last years deep neural networks emerged method choice perceptual tasks speech recognition image classiﬁcation. essence highly complex non-linear function makes hard understand particular classiﬁcation comes about. lack transparency signiﬁcant impediment adoption deep learning areas industry government healthcare cost errors high. order realize societal promise deep learning e.g. self-driving cars personalized medicine imperative classiﬁers learn explain decisions whether clinic courtroom. scientiﬁc applications better understanding complex dependencies learned deep networks could lead insights theories poorly understood domains. paper present probabilistically sound methodology explaining classiﬁcation decisions made deep neural networks. method used produce saliency pair highlights parts input constitute evidence activation given node. ﬁgure example. following sections review related work present approach. section provide several demonstrations technique deep convolutional neural networks trained imagenet data method applied classifying brain scans patients neurodegenerative disease. figure example visualization method explains dcnn predicts \"cockatoo\". shown evidence prediction. facial features cockatoo supportive decision parts body seem constitute evidence fact classiﬁer likely considers evidence second-highest scoring class white wolf. broadly speaking approaches understanding dcnns visualization investigated literature input image maximally activates given unit class score visualize network looking visualize network responds speciﬁc input image order explain particular classiﬁcation made network. latter subject paper. instance-speciﬁc method class saliency visualization proposed simonyan measure sensitive classiﬁcation score small changes pixel values computing partial derivative class score respect input features using standard backpropagation. also show close connection using deconvolutional networks visualization proposed zeiler fergus methods include shrikumar compare activation unit speciﬁc input forward reference activation unit. zhou bach also generate interesting visualization results individual inputs closely related method papers mentioned above. idea method similar another analysis zeiler fergus make estimate importance input pixels visualizing probability class function gray patch occluding parts image. paper take rigorous approach removing information image evaluating effect this. ﬁeld medical image classiﬁcation speciﬁcally widely used method visualizing feature importances simply plot weights linear classiﬁer p-values weights independent input image argued gaonkar davatzikos haufe interpreting weights misleading general. work presented paper based instance-speciﬁc method robnik-šikonja kononenko prediction difference analysis reviewed next section. main contributions three substantial improvements method conditional sampling multivariate analysis deep visualization method based technique presented robnik-šikonja kononenko review. given prediction method assigns relevance value input feature respect class basic idea relevance feature estimated measuring prediction changes feature unknown i.e. difference denotes input features except i.e. evaluate prediction feature unknown authors propose three strategies. ﬁrst label feature unknown second re-train classiﬁer feature left third approach simulate absence feature marginalizing feature however modeling easily become infeasible large number features. therefore authors approximate equation assuming feature independent features prior probability usually approximated empirical distribution feature. class probability estimated compared stick evaluation proposed authors referred weight evidence given figure simple illustration sampling procedure algorithm given input image select every possible patch size place larger patch size around conditionally sample conditioning surrounding patch ˆxw. input classiﬁer outputs input image size inner patch size outer patch size class interest probabilistic model patches size number samples initialization zeros counts zeros every patch size odds p/). avoid problems zero probabilities laplace correction used number training instances number classes. method produces relevance vector i=...m size input reﬂects relative importance features. large prediction difference means feature contributed substantially classiﬁcation whereas small difference indicates feature important decision. positive value means feature contributed evidence class interest removing would decrease conﬁdence classiﬁer given class. negative value hand indicates feature displays evidence class removing also removes potentially conﬂicting irritating information classiﬁer becomes certain investigated class. conditional sampling equation conditional probability feature approximated using marginal distribution crude approximation. images example pixel’s value highly dependent pixels. propose much accurate approximation based following observations pixel depends strongly small neighborhood around conditional pixel given neighborhood depend position pixel image. pixel therefore patch size contains condition remaining pixels patch feature become relevant using conditional sampling satisfy conditions relevant predict class interest hard predict neighboring pixels. relative marginal method therefore downweight pixels easily predicted thus redundant sense. robnik-šikonja kononenko take univariate approach feature time removed. however would expect neural network relatively robust feature high-dimensional input unknown like pixel image. therefore remove several features making knowledge images strategically choosing feature sets patches connected pixels. instead going individual pixels patches size image implemented sliding window fashion. patches overlapping ultimately individual pixel’s relevance obtained taking average relevance obtained different patches trying understand neural networks make decisions interesting analyze input-output relation classiﬁer also look going inside hidden layers network. adapt method units layer network inﬂuence node deeper layer. mathematically formulate follows. vector representation values layer network further value node depends i.e. node subsequent layer. analog equation given expectation expresses distribution unit layer unobserved. equation works arbitrary layer/unit combinations evaluates equation input-output relation analyzed. evaluate difference general activation difference case dealing probabilities applicable). section illustrate proposed visualization method applied imagenet dataset natural images using dcnns medical imaging dataset scans using logistic regression classiﬁer marginal sampling always empirical distribution i.e. replace feature samples taken directly images location. conditional sampling multivariate normal distribution. sampling methods samples estimate note images best viewed digital color. images ilsvrc challenge three dcnns alexnet googlenet network used publicly available pre-trained models implemented using deep learning framework caffe analyzing image took average minutes respective classiﬁers alexnet googlenet results shown chosen among small images order show range behavior algorithm. shown images quite representative performance method general. examples randomly selected images including comparison sensitivity analysis simonyan seen appendix figure visualization effects marginal versus conditional sampling using googlenet classiﬁer. classiﬁer makes correct predictions show evidence decision output layer. conditional sampling gives targeted explanations compared marginal sampling. also marginal sampling assigns much importance pixels easily predictable conditioned neighboring pixels. figure visualization different window sizes inﬂuence visualization result. used conditional sampling method alexnet classiﬁer varying even removing single pixels noticeable effect classiﬁer important pixels higher score. increasing window size easily interpretable smooth result image gets blurry large window sizes. figure shows visualizations spatial support highest scoring class using marginal conditional sampling conditional sampling leads results reﬁned sense concentrate around object. also marginal sampling leads pixels declared important easily predictable conditioned neighboring pixels throughout experiments found conditional sampling tends give speciﬁc ﬁne-grained results marginal sampling. rest experiments therefore show results using conditional sampling only. imagenet data observed setting gives good trade-off sharp results smooth appearance. figure shows different window sizes inﬂuence resolution visualization. surprisingly removing pixel measurable effect prediction largest effect comes sensitive pixels. expected removing pixel effect classiﬁcation outcome apparently classiﬁer sensitive even small changes. however using small window size difﬁcult make sense sign information visualization. want good impression parts image evidence for/against class therefore better larger windows. chosen large however results tend blurry. note results simple averages another multivariate approach indeed necessary observe presented results. third main contribution extension method neural networks; understand role hidden layers dnn. figure shows different feature maps three different layers googlenet react input tabby feature convolutional layer ﬁrst compute relevance input image hidden unit map. estimate feature whole doing show average relevance vectors units feature map. ﬁrst convolutional layer works different types simple image ﬁlters parts input image respond figure visualization feature maps thee different layers googlenet using conditional sampling patch sizes feature convolutional layer ﬁrst evaluate relevance every single unit average results units feature sense unit whole. pixels activate unit blue pixels decreased activation. figure visualization three different feature maps taken inception_a/output layer googlenet shown average relevance input features activations feature map. used patch sizes pixels activate unit blue pixels decreased activation. positively negatively ﬁlters. layer picked somewhere middle network specialized higher level features activations last convolutional layer sparse across feature channels indicating units highly specialized. sense single feature maps convolutional layers doing look visualization different input images look patterns behavior. figure shows four different feature maps layer middle googlenet network. directly kind features model learned stage network. example feature mostly activated eyes animals another looking mostly background visualize inﬂuence input features penultimate layer show evidence for/against particular class without taking classes consideration. softmax operation however values nodes interdependent drop probability class could less evidence different class becomes likely. figure compares visualizations last layers. looking three scoring classes visualizations penultimate layer look similar classes similar looking output layer however look rather different. consider case elephants three classes different elephant subspecies visualizations penultimate layer look similar since every subspecies identiﬁed similar characteristics. output layer classiﬁer decides three types elephants others ears case crucial difference. figure visualization support top-three scoring classes penultimateoutput layer. next input image ﬁrst shows results respect penultimate layer; second respect output layer. image additionally report values units. used alexnet conditional sampling patch sizes pixels evidence class blue figure comparison prediction visualization different dcnn architectures. input images show results prediction difference analysis using different neural networks alexnet googlenet network. analyzing neural networks make decisions also compare different network architectures inﬂuence visualization. here tested method alexnet googlenet network. figure shows results three different networks input images. alexnet seems contextual information could attributed least complex architecture compared networks. also interesting network deems basket balloon important compared pixels. second highest scoring class case parachute presumably network learned confuse balloon parachute detecting square basket illustrate visualization method also useful medical domain show experimental results dataset healthy patients. settings crucial practitioner insight algorithm’s decision classifying patient weigh information incorporate overall diagnosis process. dataset used referred cobra dataset. contains mris patients healthy individuals included academic medical center amsterdam netherlands. subjects diffusion weighted data acquired. preprocessing data performed software developed in-house using hpcn-uva neuroscience gateway using resources dutch e-science grid shahand result fractional anisotropy maps computed. sensitive microstructural damage therefore expected average decreased patients. subjects scanned tesla scanner systems subjects philips intera system philips ingenia system. patients controls evenly distributed. images spatially normalized standard space andersson resulting volumes voxels. trained l-regularized logistic regression classiﬁer subset slices balanced version dataset achieve accuracy -fold cross-validation test. analyzing image took around half hour conditional sampling also tried adding location information equation i.e. split image grid also condition index grid. found slightly improved interpretability results since pixel values special case scans depend spacial location well. figure shows prediction difference results could presented physician sample. overlapping prediction difference image exact regions pointed evidence classiﬁer’s decision. second shows results using weights logistic regression classiﬁer commonly used method neuroscientiﬁc literature. considerably noisier also speciﬁc given image. figure shows visualization results four healthy four samples. clearly patterns classes distinct pattern decision classiﬁer still speciﬁc input image. figure shows sample ﬁgure along different axes ﬁgure shows visualization changes different patch sizes. believe varying slice patch size give different insights clinician clinical practice animation parameters adjusted would useful analyzing visualization result. general assume better classiﬁer closer explanations decisions true class difference. clinical practice therefore crucial good classiﬁers. increase computation time many medical settings longer waiting times test results common worth wait patient acute life threatening condition presented results demonstration purposes visualization method claim medical validity. thorough qualitative analysis incorporating expert knowledge outside scope paper. experiments used simple multivariate normal distribution conditional sampling. imagine using sophisticated generative models lead better results pixels easily predictable surrounding downweighted even more. however also signiﬁcantly increase computational resources needed produce explanations. similarly could modify equation even better approximation using conditional distribution takes information whole image account make method applicable clinical analysis practice better classiﬁcation algorithm required. also software visualizes results interactive model improve usability system. presented method visualizing deep neural networks improves previous methods using powerful conditional multivariate model. visualization method shows pixels speciﬁc input image evidence node network. signed information offers insights research networks well acceptance usability domains like healthcare. method requires signiﬁcant computational resources real-time visualization possible visualizations pre-computed. optimization powerful gpus pre-computation time reduced further. experiments presented several ways visualization method analyzing dcnns make decisions. figure visualization support correct classiﬁcation using prediction difference method logistic regression weights. sample show results prediction difference using weights logistic regression classiﬁer slices positive values blue negative. slice left image shows original image overlaid relevance values. right image shows original image reversed colors relevance values. relevance values shown voxels relevance value maximum value. figure prediction difference visualization different samples. ﬁrst four samples class healthy; last four class hiv. images show slice samples correctly classiﬁed results show evidence decision. prediction differences shown voxels relevance value maximum value. figure visualization results across different slices image using input image shown prediction differences shown voxels relevance value maximum value. figure patch size inﬂuences visualization. input image show visualization different patch sizes prediction differences shown voxels relevance value maximum work also part supported innoviris brussels institute research innovation brussels belgium; nuts-ohra foundation amsterdam netherlands; netherlands organization health research development together aids fonds additional unrestricted scientiﬁc grants received gilead sciences viiv healthcare janssen pharmaceutica n.v. bristol-myers squibb boehringer ingelheim merck&co. thank barbara elsenga jane berkel sandra moll maja totté marjolein martens running agehiv study program capturing data care passion. thank yolanda ruijs-tiggelman veenenberg-benschop sima zaheri mariska hillebregt monitoring foundation contributions data management. thank aaﬁen henderiks hans-erik nobel advice logistics organization academic medical center. thank hiv-physicians hiv-nurses academic medical center efforts include hiv-infected participants agehiv cohort study municipal health service amsterdam personnel efforts include hiv-uninfected participants agehiv cohort study. thank study participants without research would possible. agehiv cohort study group. scientiﬁc oversight coordination reiss f.w.n.m. valk schouten k.w. kooij r.a. zoest verheij b.c. elsenga department global health amsterdam institute global health development prins m.f. schim loeff martens moll berkel totté g.r. visser kovalev newsum dijkstra datamanagement zaheri m.m.j. hillebregt y.m.c. ruijs d.p. benschop berkaoui central laboratory support n.a. kootstra a.m. harskamp-holwerda maurer booiman m.m. mangas ruiz a.f. girigorie boeser-nunnink project management administrative support zikkenheiner f.r. janssen participating physicians nurses s.e. geerlings m.h. godfried goorhuis j.w.r. hovius j.t.m. meer f.j.b. nellen poll j.m. prins reiss valk w.j. wiersinga vugt bree f.w.n.m. wit; eden a.m.h. mutschelknauss h.e. nobel f.j.j. pijnappel bijsterveld weijsenfeld smalhout collaborators jong p.g. postema p.h.l.t. bisschop m.j.m. serlie lips dekker velde j.m.r. willemsen vogt schouten portegies b.a. schmand g.j. geurtsen f.d. verbraak demirkaya visser schadé p.t. nieuwkerk langebeek r.p. steenwijk dijkers c.b.l.m. majoie m.w.a. caan h.w. lunsen m.a.f. nievaard b.j.h. born e.s.g. stroes w.m.c. mulder sebastian bach alexander binder grégoire montavon frederick klauschen klaus-robert müller wojciech samek. pixel-wise explanations non-linear classiﬁer decisions layer-wise relevance propagation. plos christine ecker andre marquand janaina mourão-miranda patrick johnston eileen daly michael brammer stefanos maltezos clodagh murphy dene robertson steven williams describing brain autism dimensions—magnetic resonance imaging-assisted diagnosis autism spectrum disorder using multiparameter classiﬁcation approach. journal neuroscience stefan haufe frank meinecke görgen sven dähne john-dylan haynes benjamin blankertz felix bießmann. interpretation weight vectors linear models multivariate neuroimaging. neuroimage yangqing evan shelhamer jeff donahue sergey karayev jonathan long ross girshick sergio guadarrama trevor darrell. caffe convolutional architecture fast feature embedding. arxiv preprint arxiv. stefan klöppel cynthia stonnington carlton bogdan draganski rachael scahill jonathan rohrer nick clifford jack john ashburner richard frackowiak. automatic classiﬁcation scans alzheimer’s disease. brain janaina mourao-miranda arun bokde christine born harald hampel martin stetter. classifying brain states determining discriminating activation patterns support vector machine functional data. neuroimage olga russakovsky deng jonathan krause sanjeev satheesh sean zhiheng huang andrej karpathy aditya khosla michael bernstein alexander berg fei-fei. imagenet large scale visual recognition challenge. international journal computer vision ./s---y. shayan shahand ammar benabdelkader mohammad mahdi jaghoori mostapha mourabit jordi huguet matthan caan antoine kampen sílvia olabarriaga. data-centric neuroscience gateway design implementation experiences. concurrency computation practice experience christian szegedy yangqing pierre sermanet scott reed dragomir anguelov dumitru erhan vincent vanhoucke andrew rabinovich. going deeper convolutions. proceedings ieee conference computer vision pattern recognition bolei zhou aditya khosla agata lapedriza aude oliva antonio torralba. learning deep features discriminative localization. proceedings ieee conference computer vision pattern recognition figure results randomly chosen imagenet images. middle columns original image; left columns sensitivity maps pixels indicate high sensitivity white pixels mean sensitivity right columns results method. methods visualize results respect correct class given image. brackets classiﬁer ranks class i.e. means correctly classiﬁed whereas means misclassiﬁed correct class ranked fourth. method areas show evidence correct class blue areas show evidence class", "year": 2017}