{"title": "Video In Sentences Out", "tag": ["cs.CV", "cs.AI"], "abstract": "We present a system that produces sentential descriptions of video: who did what to whom, and where and how they did it. Action class is rendered as a verb, participant objects as noun phrases, properties of those objects as adjectival modifiers in those noun phrases,spatial relations between those participants as prepositional phrases, and characteristics of the event as prepositional-phrase adjuncts and adverbial modifiers. Extracting the information needed to render these linguistic entities requires an approach to event recognition that recovers object tracks, the track-to-role assignments, and changing body posture.", "text": "sanja fidlerb aaron michauxa mussmana siddharth narayanaswamya dhaval salvic lara schmidta jiangnan shangguana jeffrey mark siskinda jarrell waggonerc song wangc aschool electrical computer engineering purdue university west lafayette bdepartment computer science university toronto toronto cdepartment computer science engineering university south carolina columbia present system produces sentential descriptions video whom action class rendered verb participant objects noun phrases properties objects adjectival modiﬁers noun phrases spatial relations participants prepositional phrases characteristics event prepositional-phrase adjuncts adverbial modiﬁers. extracting information needed render linguistic entities requires approach event recognition recovers object tracks track-to-role assignments changing body posture. present system produces sentential descriptions short video clips. sentences describe whom system describes observed action verb also describes participant objects noun phrases properties objects adjectival modiﬁers noun phrases spatial relations participants approached arrived attached bounced buried carried caught chased closed collided digging dropped entered exchanged exited fell followed gave handed hauled held jumped kicked left lifted moved opened passed picked pushed raised received replaced snatched stopped threw took touched turned walked went ball bench bicycle cage cart chair door ladder left mailbox microwave motorcycle object person right skateboard table tripod truck black blue cardboard crouched green narrow other pink prone short small tall teal upright white wide yellow prepositional phrases characteristics event prepositional-phrase adjuncts adverbial modiﬁers. incorporates vocabulary words coordination verbs nouns adjectives prepositions lexical prepositional phrases determiners particles pronouns adverbs auxiliary illustrated table production sentential descriptions requires recognizing primary action performed actions rendered verbs verbs serve central scaffolding sentences. however event recognition alone insufﬁcient generate remaining sentential components. must recognize object classes order render nouns. even object recognition alone insufﬁcient generate meaningful sentences. must determine roles objects play event. agent i.e. doer action typically rendered sentential subject patient i.e. affected object typically rendered direct object. detected objects play role observed event matter prominent incorporated description. means cannot common approaches event recognition spatiotemporal bags words spatiotemporal volumes tracked feature points determine class participant objects roles play. even combining approaches object detector would likely detect objects don’t participate event wouldn’t able determine roles detected objects play. producing elaborate sentential descriptions requires event recognition object detection. generating noun phrase embedded prepositional phrase person left bicycle requires determining spatial relations detected objects well knowing detected objects plays role overall event serves generation referring expression help identify event participant. generating noun phrase adjectival modiﬁers ball requires determining properties color shape size observed objects also requires determining whether descriptions necessary help disambiguate referent noun phrase. would awkward generate noun phrase tall wide cardboard trash trash would sufﬁce. moreover must track participants determine speed direction motion generate adverbs slowly prepositional phrases leftward. further must track identity multiple instances object class appropriately generate distinction between person person person themselves. common assumption linguistics verbs typically characterize interaction event participants terms gross changing motion participants. object class image characteristics participants believed largely irrelevant determining appropriate verb label action class. participants simply roles spatiotemporal structure action class described verb. example event participant picks another participant consists sequence sub-events ﬁrst subevent agent moves towards patient patient rest second sub-event agent moves together patient away original location patient. determining whether agent person whether patient ball necessary generate noun phrases incorporated sentential description information largely irrelevant determining verb describing action. similarly determining shapes sizes colors textures etc. participants necessary generate adjectival modiﬁers information also largely irrelevant determining verb. common approaches event recognition spatiotemporal bags words spatiotemporal volumes tracked feature points often achieve high accuracy correlation image video properties exhibited particular corpus. often artefactual deﬁning properties verb meaning confusing basketball volleyball ‘because time sports similar courts’ many existing video corpora used evaluate event recognition ill-suited evaluating sentential descriptions. example weizmann dataset dataset depict events single human participant ones people interact people objects. sentential descriptions would contain information verb e.g. person jumped. moreover datasets well sports actions dataset youtube dataset often make action-class distinctions irrelevant choice verb e.g. wave wave jump pjump golf-swing-front golf-swing-back kicking-front swing-sideangle tennis swing swing datasets ballet dataset dataset depict larger-scale activities bear activity-class names well suited sentential description e.g. basketball billiards breaststroke horserace hulahoop militaryparade taichi yoyo. year-one corpus produced darpa mind’s program however speciﬁcally designed evaluate sentential description. corpus contains parts development corpus solely training evaluation corpus solely testing. divided four sections support four task goals mind’s program namely recognition description ﬁlling anomaly detection. paper recognition description portions apply entire sentential-description pipeline combination portions. portions overlap paper train methods solely test methods solely portion overlap c-d. moreover portion corpus synthetically generated variety means computer graphics driven motion capture pasting foregrounds extracted green screening onto different backgrounds intensity varipaper ation introduced postprocessing. exclude synthetic video test corpus. training contains videos test videos. videos provided pfps range frames length average frames. videos nominally depict distinct verbs listed table however mapping videos verbs one-to-one. polysemy verb describe action class e.g. leaving object table leaving scene. synonymy action class described verb e.g. lift raise. event described verb contain component action described different verb e.g. picking object touching object. many events described combination verb constituents e.g. conversation heart attack. many videos depict metaphoric extensions verbs e.g. take puff cigarette. mapping videos verbs subjective corpus comes labeled darpa-collected human judgments form single present/absent label associated video paired verbs gathered using amazon mechanical turk. labels training testing described later. overall architecture system depicted fig. ﬁrst apply detectors object class frame video. detectors biased yield many false positives false negatives. kanade-lucas-tomasi feature tracker used project detection frames forward augment detections compensate false negatives detector output. dynamicprogramming algorithm used select optimal detections temporally coherent optical yielding object tracks video. tracks smoothed used compute time-series feature vectors video describe relative absolute motion event participants. person detections clustered based part displacements derive coarse measure human body posture form body-posture codebook. codebook indices person detections added feature vector. hidden markov models employed time-series classiﬁers yield verb labels video together object tracks participants action described verb along roles play. tracks processed produce nouns object classes adjectives object properties prepositional phrases spatial relations adverbs prepositional-phrase adjuncts track properties. together verbs woven grammatical sentences. describe components system detail below object detector tracker section body-posture clustering codebook section event classiﬁer section sentential-description component section employ detection-based tracking described section parallel submission detection-based tracking object detector applied frame video yield candidate detections composed tracks selecting single candidate detection frame maximizes temporal coherency track. felzenszwalb detectors used purpose. detection-based tracking requires biasing detector high recall expense precision allow tracker select boxes yield temporally coherent track. done depressing acceptance thresholds. prevent massive over-generation false positives would severely impact time limit number detections produced per-frame practical issues arise depressing acceptance thresholds. first necessary reduce degree non-maximal suppression incorporated felzenszwalb detectors. second star detector simply decrease single trained acceptance threshold yield detections increase computational complexity. however prefer star cascade detector faster. star cascade detector though must also decrease trained rootpart-ﬁlter thresholds detections. doing however defeats computational advantage cascade signiﬁcantly increases detection time. thus train model star detector using standard procedure human-annotated training data sample detections produced model decreased acceptance threshold train model star cascade detector samples. yields model almost fast trained star cascade detector original training samples desired bias acceptance threshold. corpus contains approximately different object classes play role depicted events. many these however cannot reliably detected felzenszwalb detectors use. trained models object classes reliably detected listed table object classes account event participants. person models trained approximately human-annotated positive samples nonperson models trained approximately samples. positive training sample negative training samples randomly generated frame constrained overlap substantially positive samples. trained three distinct person models account body-posture variation pool constructing person tracks. detection scores normalized pooled detections per-model offset computed follows histogram computed scores detection frame video. offset taken minimum value maximizes between-class variance bipartitioning histogram trained acceptance threshold offset ﬁxed small amount large number tracks thus produced discard tracks corresponding certain object models per-video basis exhibit high detection-score variance frames video well whose detectionscore distributions neither unimodal bimodal. parameters governing pruning determined solely training set. tracks remain pruning still account event participants. recognize events using combination motion event participants changing body posture human participants. body-posture information derived using part structure produced by-product felzenszwalb detectors. information noisier less accurate ﬁtting precise articulated models appears unintelligible human shown section sufﬁces improve event-recognition accuracy. information extracted large unannotated corpus robustly possible precise articulated models. body-posture information derived part structure ways. first compute vector part displacements displacement vector detection center part center normalizing vectors unit detection-box area. time-series feature vectors augmented includes part displacements ﬁnite-difference approximation temporal derivatives continuous features person detections. second vector-quantize part-displacement vector include codebook index discrete feature person detections. pose features included timeseries per-frame basis. codebook trained running pose-speciﬁc person detector positive human-annotated samples used train detector extract resulting part-displacement vectors. pool part-displacement vectors three posespeciﬁc person models employ hierarchical k-means clustering using euclidean distance derive codebook clusters. fig. shows sample clusters codebook. codebook indices derived using euclidean distance means clusters. tracker produces tracks object class video. convert tracks time-series feature vectors. video track taken designate agent another track taken designate patient. training manually specify track-to-role mapping. testing automatically determine track-to-role mapping examining car→car bag→bag cardboard-box→box bench→bench bicycle→bicycle cart→cart chair→chair big-ball→ball cage→cage dog→dog cardboard-box→cardboard big-ball→big feature vector encodes motion event participants changing body posture human participants. event participant isolation incorporate following single-track features hmms assume independent output distributions feature. discrete features modeled discrete output distributions. continuous features denoting linear quantities modeled univariate gaussian output distributions denoting angular quantities modeled mises output distributions. taining single-track features single participant containing single-track features participants along track-pair features. training videos selected manually hmms positive examples depicting action classes. given video could potentially included training sets onetrack two-track hmms action class even hmms different action classes video deemed depict action classes. testing generate present/absent judgments video test paired action classes. thresholding likelihoods produced hmms. varying thresholds produce curve action class comparing resulting machine-generated present/absent judgments amazon mechanical turk judgments. doing test videos tracker produces tracks two-track hmms test ones tracker produces single track one-track hmms. performed three experiments training different state hmms each. experiment omitted discrete features body-posture related features. experiment omitted discrete features. experiment omitted continuous body-posture related features. curves experiment shown fig. fig. fig. note incorporation body-posture information either form continuous normalized part displacements discrete codebook indices improves event-recognition accuracy despite fact part displacements produced felzenszwalb detectors noisy appear unintelligible human eye. produce sentence detected action class together associated tracks using templates table templates words italics denote ﬁxed strings words bold indicate action class denote subject object noun phrases categories ppendo ppexo denote adverbs prepositionalphrase adjuncts describe subject motion. processes generating noun phrases adverbs prepositional-phrase adjuncts described below. onetrack hmms take track agent thus subject. two-track hmms choose mapping tracks roles yields higher likelihood take agent track subject patient track object except action class either approached agent stationary patient moves agent. brackets templates denote optional entities. optional entities containing generated twotrack hmms. criteria generating optional adverbs prepositional phrases described below. optional entity received generated patient track whose category mailbox person person-crouch person-down. adverbs describe velocity subject. verbs velocity adverb would awkward verb-phrase templates thus indicate whether adverb allowed whether occurs preferentially preverbally postverbally. adverbs chosen subject three thresholds vaction class determined empirically per-action-class basis select frames subject track magnitude velocity box-detection center vaction class optional adverb generated comparing magnitude average velocity subject track boxdetection centers frames per-action-class thresholds verb-phrase templates thus indicate whether adjunct allowed whether preferentially endogenous exogenous. choice adjunct determined orientation computed depicted fig. omit adjunct vaction class instantiating sentential template required object noun-phrase one-track generate pronoun. pronoun also generated action class entered exited patient class door truck. anaphor generated action class attached raised anaphor action class moved something otherwise. described below generate optional prepositional phrase subject noun phrase describe spatial relation subject object. choose determiner handle coreference generating noun phrase unambiguously refers agent patient combination head noun adjectives generate head noun noun phrase object class using mapping table four different kinds adjectives generated color shape size restrictive modiﬁers. optional color adjective generated based average values eroded detection boxes track black white blue green yellow teal pink based optional size adjective generated ways object class using mapping table based per-object-class image statistics. object class mean object size figure endogenous exogenous prepositional-phrase adjuncts describe subject motion direction. prepositional phrases incorporated subject noun phrases describing viewer-relative spatial relations subject reference object aobject class determined averaging detected-box tracks object class training used train hmms. optional size adjective track generated comparing average detected-box area track ¯aobject class per-object-class cutoff ratios αobject class βobject class computed equally tripartition distribution perobject-class mean object sizes training set. optional shape adjectives generated similar fashion. per-object-class mean aspect ratios ¯robject class determined addition per-object-class mean object sizes aobject class. optional shape adjectives track gener¯ ated comparing average detected-box aspect ratio area track means .¯robject class βobject class¯aobject class tall .¯robject class αobject class¯aobject class short narrow .¯robject class αobject class¯aobject class .¯robject class βobject class¯aobject class wide avoid generating shape size adjectives unstable tracks generated detection-score variance detected aspect-ratio variance track speciﬁed thresholds. optional restrictive modiﬁers generated object class using mapping table person-pose adjectives generated aggregate body-posture information track object class normalized part displacements body-posture codebook indices. generate applicable adjectives except color person pose. following gricean maxim quantity generate color person-pose adjectives needed prevent coreference nonhuman event participants. finally generate initial adjective other needed prevent coreference. generating allow generation determiner place some. order adjectives generated comes ﬁrst followed size shape color restrictive modiﬁers order. two-track hmms neither participant moves prepositional phrase generated subject noun phrases describe static spatial relation subject reference object perspective viewer shown fig. used hmms generated experiment compute likelihoods video test paired action classes. video generated sentences corresponding three most-likely action classes. fig. shows frames four videos test along sentence generated most-likely action class. human judges rated videosentence pair assess whether sentence true video whether described salient event depicted video. video-sentence pairs deemed true videosentence pairs deemed salient. restricting consideration sentence corresponding single most-likely action class video video-sentence pairs deemed true video-sentence pairs deemed salient. finally videos least three generated sentences deemed true videos least three generated sentences deemed salient. integration language vision recognition action video considerable interest long time. also work generating sentential descriptions static images unaware prior work generates rich sentential video descriptions describe here. producing rich descriptions requires determining event participants mapping participants roles event motion properties. incompatible common approaches event recognition spatiotemporal bags words spatiotemporal volumes tracked feature points cannot determine information. approach presented recovers information needed generate rich sentential descriptions using detectionbased tracking body-posture codebook. demonstrated efﬁcacy approach corpus videos. work supported part grant naval research laboratory contract number n---g army research laboratory accomplished cooperative agreement number wnf--- computational resources provided information technology purdue rosen center advanced computing. views opinions ﬁndings conclusions recommendations contained expressed document material author necessarily reﬂect represent views ofﬁcial policies either expressed implied naval research laboratory ofﬁce naval research army research laboratory u.s. government. u.s. government authorized reproduce distribute reprints government purposes notwithstanding copyright notation herein. references aloimonos fadiga metta pastra editors. aaai workshop language-action tools cognitive artiﬁcial agents integrating vision action language girish kulkarni visruth premraj sagnik dhar siming yejin choi alexander berg tamara berg. baby talk understanding generating simple image descriptions. cvpr pages viterbi. convolutional codes performance communication systems. ieee trans. communication wang mori. human action recognition semilatent topic models. pami issn", "year": 2012}