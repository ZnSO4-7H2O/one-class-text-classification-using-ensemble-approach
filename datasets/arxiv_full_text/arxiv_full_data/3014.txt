{"title": "Recurrent Topic-Transition GAN for Visual Paragraph Generation", "tag": ["cs.CV", "cs.AI", "cs.LG"], "abstract": "A natural image usually conveys rich semantic content and can be viewed from different angles. Existing image description methods are largely restricted by small sets of biased visual paragraph annotations, and fail to cover rich underlying semantics. In this paper, we investigate a semi-supervised paragraph generative framework that is able to synthesize diverse and semantically coherent paragraph descriptions by reasoning over local semantic regions and exploiting linguistic knowledge. The proposed Recurrent Topic-Transition Generative Adversarial Network (RTT-GAN) builds an adversarial framework between a structured paragraph generator and multi-level paragraph discriminators. The paragraph generator generates sentences recurrently by incorporating region-based visual and language attention mechanisms at each step. The quality of generated paragraph sentences is assessed by multi-level adversarial discriminators from two aspects, namely, plausibility at sentence level and topic-transition coherence at paragraph level. The joint adversarial training of RTT-GAN drives the model to generate realistic paragraphs with smooth logical transition between sentence topics. Extensive quantitative experiments on image and video paragraph datasets demonstrate the effectiveness of our RTT-GAN in both supervised and semi-supervised settings. Qualitative results on telling diverse stories for an image also verify the interpretability of RTT-GAN.", "text": "natural image usually conveys rich semantic content viewed different angles. existing image description methods largely restricted small sets biased visual paragraph annotations fail cover rich underlying semantics. paper investigate semi-supervised paragraph generative framework able synthesize diverse semantically coherent paragraph descriptions reasoning local semantic regions exploiting linguistic knowledge. proposed recurrent topic-transition generative adversarial network builds adversarial framework between structured paragraph generator multi-level paragraph discriminators. paragraph generator generates sentences recurrently incorporating region-based visual language attention mechanisms step. quality generated paragraph sentences assessed multi-level adversarial discriminators aspects namely plausibility sentence level topic-transition coherence paragraph level. joint adversarial training rtt-gan drives model generate realistic paragraphs smooth logical transition sentence topics. extensive quantitative experiments image video paragraph datasets demonstrate effectiveness rtt-gan supervised semi-supervised settings. qualitative results telling diverse stories image also verify interpretability rtt-gan. describing visual content natural language emerging interdisciplinary problem intersection computer vision natural language processing artiﬁcial intelligence. recently great advances achieved describing images videos using single high-level sentence owing advent large datasets pairing images natural language descriptions. despite encouraging progress image captioning current systems tend capture scene-level gist rather ﬁne-grained entities largely undermines applications realworld scenarios blind navigation video retrieval automatic video subtitling. recent alternatives sentence-level captioning visual paragraph generation aims provide coherent detailed description like telling stories images/videos. generating full paragraph description image/video challenging. first paragraph descriptions tend diverse like different individuals tell stories personalized perspectives. illustrated figure users describe image starting different viewpoints objects. existing methods deterministically optimizing single annotated paragraph thus suffer losing massive information expressed image. desirable enable diverse generation simple manipulations. second annotating images/videos long paragraphs labor-expensive leading small scale image-paragraph pairs limits model generalization. finally different single-sentence captioning visual paragraphing requires capture detailed richer semantic content. necessary perform long-term visual language reasoning incorporate ﬁne-grained cues ensuring coherent paragraphs. overcome challenges propose semisupervised visual paragraph generative model recurrent topic-transition generates diverse semantically coherent paragraphs reasoning local semantic regions global paragraph context. inspired generative adversarial networks establish adversarial training mechanism structured paragraph generator multi-level paragraph discriminators discriminators learn distinguish real synthesized paragraphs generator aims fool discriminators generating diverse realistic paragraphs. paragraph generator built upon dense semantic regions image selectively attends regional content details construct meaningful coherent paragraphs. enable long-term visual language reasoning spanning multiple sentences generator recurrently maintains context states different granularities ranging paragraph sentences words. conditioned current state spatial visual attention mechanism selectively incorporates visual cues local semantic regions manifest topic vector next sentence language attention mechanism incorporates linguistic information regional phrases generate precise text descriptions. pair generator rival discriminators assess synthesized paragraphs terms plausibility sentence level well topic-transition coherence paragraph level. model allows diverse descriptions single image manipulating ﬁrst sentence guides topic whole paragraph. semi-supervised learning enabled sense single-sentence caption annotation required model training linguistic knowledge constructing long paragraphs transfered standalone text paragraphs without paired images. compare rtt-gan state-of-the-art methods image-paragraph video-paragraph datasets verify superiority method supervised semi-supervised settings. using single-sentence coco captioning dataset model generates highly plausible multi-sentence paragraphs. given synthesized paragraphs coco image considerably enlarge existing small paragraph dataset improve paragraph generation capability rtt-gan. qualitative results personalized paragraph generation also shows ﬂexibility applicability model. image captioning posed longstanding holy-grail goal computer vision targeting bridging visual linguistic domain. early works posed problem ranking template retrieval tasks performed poorly since hard enumerate possibilities collected dataset compositional nature language. therefore recent works focus directly generating captions modeling semantic mapping visual cues language descriptions. among research lines advanced methods train recurrent neural network language models conditioned image features achieve great success taking advantages large-scale image captioning dataset. similar success already seen video captioning ﬁelds though generating high-level sentences images encouraging massive underlying information relationships objects attributes entangled geometric structures conveyed image would missed summarizing coarse sentence. dense captioning recently proposed describe region interest short phrase considering details standard image captioning. however local phrases provide comprehensive logical description entire image. visual paragraph generation. paragraph generation overcomes shortcomings standard captioning dense captioning producing coherent ﬁne-grained natural language description. reason long-term linguistic structures multiple sentences hierarchical recurrent network widely used directly simulate hierarchy language. example generate multi-sentence video descriptions cooking videos capture strong temporal dependencies. krause combine semantics regions interest produce generic paragraph image. however methods suffer overﬁtting problem lack sufﬁcient paragraph descriptions. contrast propose generative model automatically synthesize large amount diverse reasonable paragraph descriptions learning implicit linguistic interplay sentences. rtt-gan better interpretability imposing sentence plausibility topic-transition coherence generator adversarial discriminators. generator selectively incorporates visual language cues semantic regions produce sentence. figure rtt-gan alternatively optimizes structured paragraph generator discriminators following adversarial training scheme. generator recurrently produces sentence reasoning local semantic regions preceding paragraph state. synthesized sentence sentence discriminator recurrent topic-transition discriminator assessing sentence plausibility topic coherence respectively. paragraph description corpus adopted provide linguistic knowledge paragraph generation depicts true data distribution discriminators provides overview framework. given input image ﬁrst detect semantic regions using dense captioning method semantic region represented visual feature vector short text phrase paragraph generator sequentially generates meaningful sentences incorporating ﬁne-grained visual textual cues selective way. ensure high-quality individual sentences coherent whole paragraph apply sentence discriminator topic-transition discriminator generated sentence respectively measure plausibility smoothness semantic transition preceding sentences. generator multi-level discriminators learned jointly within adversarial framework. rtt-gan supports supervised setting annotated image-paragraph pairs also semi-supervised setting single sentence caption provided image knowledge long paragraph construction learned standalone paragraph corpus. next sections ﬁrst derive adversarial framework rtt-gan describe detailed model design paragraph generator multi-level discriminators respectively. time step conditioned preceding sentences local semantic regions image generator recurrently produces single sentence sentence {wti} consists sequence words discriminators learn differentiate real sentences within true paragraph synthesized ones generator tries generate realistic visual paragraph minimizing discriminators’ chance correctly telling apart sample source. original optimizes binary probability distance suffers mode collapse instable convergence follow wasserstein method theoretically remedies minimizing approximated wasserstein distance. objective adversarial framework thus written construct adversarial game generator discriminators drive model learning. speciﬁcally sentence topic-transition discriminators learn critic real generated samples generator attempts confuse discriminators generating realistic paragraphs satisfy linguistic characteristics generative neural architecture ensures paragraph captures adequate semantic content image describe detail next sections. formally denote paragraph generator denote sentence topic-transition discriminators respectively. pdata pdata denote true data distributions sentences paragraphs respectively empirically constructed paragraph description corpus. second line equation objective sentence discriminator optimizes critic real/fake sentences third line objective topictransition discriminator indicates distribution generated sentences generator leverage existing image-paragraph pair dataset supervised setting image captioning dataset semisupervised setting also incorporate traditional word reconstruction loss generator optimization defigure illustration paragraph generator. given visual features local phrases semantic regions paragraph generator ﬁrst updated embedding performed steps sequentially generate sentence. t-th step paragraph states preceding sentences paragraph rnn. then visual attention takes features semantic regions current paragraph states sentence obtain encoded topic previous hidden states vector note reconstruction loss used supervised examples paragraph annotations semi-supervised examples single-sentence caption combining eqs.- joint objective generator thus balancing parameter ﬁxed implementation. optimization generator discriminators respectively) performed alternating min-max manner. describe training details section discrete nature text samples hinders gradient back-propagation discriminators generator address issue following seqgan state current produced words sentences action next word select. apply monte carlo search roll-out policy sample remaining words sees token sentence maximal number sentences. roll-out policy generator elaborated section discriminator trained providing true paragraphs text corpus synthetic ones generator. generator updated employing policy gradient based expected reward received discriminator reconstruction loss fully-supervised semi-supervised settings deﬁned reduce variance action values roll-out policy starting current state till paragraph times batch output samples. signals come word prediction labeled sentences regarded intermediate reward. gradients passed back intermediate action value monte carlo search paragraph generator figure shows architecture generator recurrently retains different levels context states hierarchy constructed paragraph sentence word attention modules. first paragraph encodes current paragraph state based preceding sentences. second spatial visual attention module selectively focuses semantic regions guidance current paragraph state produce visual representation sentence. sentence thus able encode topic vector sentence. third language attention module learns incorporate linguistic knowledge embedded local phrases focused semantic regions facilitate word generation word rnn. given input image adopt dense captioning model detect semantic regions image generate local phrases. region visual feature vector local text phrase consisting words. practice regions. paragraph rnn. paragraph keeps track paragraph state summarizing preceding sentences. t-th step paragraph takes embedding generated sentence previous step input turn produces paragraph hidden state input i-th given language representation step word computes hidden states used predict distribution words vocabulary. obtaining words sentence sentences ﬁnally concatenated form generated paragraph. paragraph discriminators distinguish real paragraphs synthesized ones based linguistic characteristics natural paragraph description. particular sentence discriminator evaluates plausibility individual sentences topic-transition discriminator evaluates topic coherence sentences generated far. multi-level assessment model able generate long realistic descriptions. speciﬁcally sentence discriminator lstm recurrently takes word embedding within sentence input produces realvalue plausibility score synthesized sentence. topic-transition discriminator another lstm recurrently takes sentence embeddings preceding sentences inputs computes topic smoothness value current constructed paragraph description recurrent step. discriminators implemented single-layer lstm hidden dimension generator paragraph single-layer lstm hidden size initial hidden memory cells zero. similarly sentence word single-layer lstms hidden dimension respectively. input word encoded embedding vector dimension. visual feature vector semantic region dimension adversarial framework trained following wasserstein alternate between optimization optimization eq.. particular perform gradient descent step every time gradient steps dr}. minibatch apply rmsprop solver initial learning rate stable training apply batch normalization sentence embedding obtained simply averaging embedding vectors words sentence. strategy enables model support manipulation ﬁrst sentence initialize paragraph generate personalized follow-up descriptions. visual attentive sentence controls topic next sentence selectively focusing relevant regions image. speciﬁcally given paragraph states paragraph previous hidden states sentence apply attention mechanism visual features semantic regions construct visual context vector represents next sentence t-th step linear layer transforms conβ compute weight region implemented single linear layer. notational simplicity denote normalized attentive weight region sentence responsible determining number sentences paragraph producing topic vector sentence. speciﬁcally hidden state ﬁrst passed linear layer produce probability states {continue= stop=} determine whether t-th sentence last sentence. updated treated topic vector sentence. word language attention. generate meaningful paragraphs relevant image model desired recognize describe substantial details objects attributes relationships. text phrases semantic regions express local semantics leveraged language attention module help recurrent word generation. example word conveniently copy precise concepts local phrases. following copy mechanism ﬁrstly proposed natural language processing selectively incorporate embeddings local phrases based topic vector preceding word state word generate next word representation semantically relates respective visual feature thus reuse visual attentive weights {aj}m enhance language attention. representing word embedset batch size order make parameters compact space clamp weights ﬁxed gradient update. semi-supervised setting single-sentence captioning images standalone paragraph corpus available maximal number sentences generated paragraph images. fully-supervised setting groundtruth sentence number visual paragraph used train sentence-rnn learning many sentences needed. train models converge epochs. implementations based public torch platform single nvidia geforce generate paragraph image paragraph generator forward stop sentence state predicted smax sentences whichever comes ﬁrst. word recurrently forwarded sample likely word time step stops after choosing stop token nmax words. beam search beam size generating paragraph descriptions. training details presented section models implemented torch platform. terms fully-supervised setting make fair comparison state-of-the-art methods experiments conducted public image paragraph dataset image-paragraph pairs used training validation testing. terms semi-supervised setting rtt-gan trained single sentence annotations provided mscoco image captioning dataset contains images. image-paragraph validation used validating semi-supervised paragraph generation. paragraph generation performance also evaluated paragraph testing samples. fully-supervised semi-supervised settings word vocabulary image-paragraph dataset paragraph descriptions public image paragraph dataset adopted standalone paragraph corpus training discriminators. report widely used automatic evaluation metrics bleu- bleu- bleu- bleu- meteor cider. model checkpoint selection based best combined meteor cider score validation set. table reports performance baselines models. figure visualization region-based attention mechanism. sentence generation rtt-gan selectively focuses semantic regions interest spatial visual attention attentively leverage word embeddings local phrases enhance word prediction. illustrate regions highest attention conﬁdences spatial visual attention corresponding words highest attention conﬁdences language attention step. obtain results four baselines speciﬁcally sentence-concat samples concatenates sentence captions model trained coco captions ﬁrst sentence uses beam search rest samples. image-flat directly decodes image paragraph token token. template predicts text handful manually speciﬁed templates. region-hierarchical uses hierarchical recurrent neural network decompose paragraphs corresponding sentences. baselines adopt vgg- encode visual representation image. note rtt-gan regionhierarchical dense captioning model extract semantic regions. human shows results collecting additional paragraph randomly chosen images expected humans produce superior descriptions automatic method large gaps cider meteor verify cider meteor metrics align better human judgment bleu scores. fully-supervised setting. rttgan model signiﬁcantly outperforms baselines metrics; particularly regionhierarchical image-flat terms cider. clearly demonstrates effectiveness region-based attention mechanism selectively incorporate visual language cues adversarial multi-level discriminators provide better holistic semantic regularization generated sentences paragraph. inferiority image-flat compared hierarchical networks rttgan region-hierarchical demonstrates advantage performing hierarchical sentence predictions long paragraph description. table performance comparisons four state-of-the-arts variants rtt-gan paragraph generation terms language metrics. human performance included providing better understanding metrics. semi-supervised setting. main advantage rtt-gan compared prior works capability generating realistic paragraph descriptions coordinating natural linguistic properties given singe sentence annotations. demonstrated effectiveness semi-supervised model rtt-gan uses single sentence annotations mscoco captions imposes linguistic characteristics rest sentence predictions using adversarial discriminators trained standalone paragraph corpus. speciﬁcally rtt-gan achieves comparable performance fully-supervised regions-hierarchical without using groundtruth image-paragraph pairs. augmenting image paragraph dataset synthesized paragraph descriptions rtt-gan rtt-gan dramatically outperforms rtt-gan baselines e.g. increase regionshierarchical cider. also show qualitative results generated paragraphs rtt-gan figure promising results verify capability rtt-gan reasoning long description coherent topics plausible sentences without presence ground-truth image paragraph pairs. eliminating discriminators model optimization fullysemi-supervised settings rtt-gan observe consistent performance drops metrics compared full models i.e. cider respectively. rtt-gan regarded image captioning model lack adversarial loss similar sentence-concat. justiﬁes sentence plausibility topic coherences preceding sentences critical generating long convincing stories. moreover pure word prediction loss largely hinders model’s extension unsupervised semi-supervised generative modeling. training adversarial discriminators explicitly enforce linguistic characteristics good description effectively impose high-level semantic constraints sentence predictions generator. furthermore break design discriminators order compare effect sentence discriminator recurrent topic-transition discriminator rttgan rtt-gan respectively. observed although discriminators help bring signiﬁcant improvement sentence discriminator seems play critical role addressing plausibility sentence. also evaluate effectiveness spatial visual attention language attention mechanisms facilitate paragraph prediction reported table rtt-gan directly pools visual features regions compact representation sequential sentence prediction like region-hierarchical. rtt-gan represents variant removes language attention module. observed attention mechanism effectively facilitates prediction rtt-gan selectively incorporating appropriate visual language cues. particularly advantages explicitly leveraging words local phrases suggest transferring visual-language knowledges fundamental tasks beneﬁcial generating highlevel holistic descriptions. exploratory experiment investigate generating paragraphs smaller number regions used previous models denoted rtt-gan rtt-gan although results worse full model performance using regions still reasonably good. figure gives visualization results region-based attention mechanism. generating sentence step model selectively focuses distinct regions distinct corresponding words local phrases facilitate sentence prediction. different prior works model supports personalized paragraph generation produces diverse descriptions manipulating ﬁrst sentences. conveniently achieved initializing paragraph sentence embedding predeﬁned ﬁrst sentence. generator sequentially output diverse topic-coherent sentences form personalized paragraph image. present qualitative results model figure interesting properties predictions include usage coreference ﬁrst sentence ability capture topic relationships preceding sentences. given ﬁrst sentences subsequent sentences give details scene elements mentioned earlier description also connect related content. also report human evaluation results table randomly chosen testing images three model variants compared i.e. rtt-gan rtt-gan rtt-gan image given ﬁrst sentences distinct topics model produces personalized paragraphs accordingly. regarding ﬁrst sentence image present three paragraphs three models random order judges select convincing ones. results table indicate judges think paragraphs generated models rtt-gan incorporate adversarial discriminators look convincing rtt-gan table also extend rtt-gan task video paragraph generation evaluate tacosmultilevel dataset contains long videos ﬁlmed indoor environment following model spatial appearance also extract semantic regions frames every second. capture motion patterns enhance feature representation motion features. similar pre-trained model sportm dataset outputs ﬁxed-length feature vector every frames. perform mean pooling features generate compact motion reprefigure personalized paragraph generations model manipulating ﬁrst sentence. different ﬁrst sentences image model effectively generate distinct paragraphs different topics. sentation used additional inputs every visual attention step. model signiﬁcantly outperforms state-of-the-arts demonstrating good generalization capability video domain. paper propose recurrent topic-transition visual paragraph generation. thanks adversarial generative modeling rtt-gan capable generating diverse paragraphs ﬁrst sentence annotations given training. generator incorporates visual attention language attention mechanisms recurrently reason ﬁne-grained semantic regions. discriminators assess quality generated paragraphs aspects sentence plausibility topic-transition coherence. extensive experiments show effectiveness model fully-supervised semi-supervised settings. future extend generative model vision tasks require jointly visual language modeling.", "year": 2017}