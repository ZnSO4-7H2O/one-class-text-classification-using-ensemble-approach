{"title": "Punny Captions: Witty Wordplay in Image Descriptions", "tag": ["cs.CL", "cs.AI", "cs.CV"], "abstract": "Wit is a quintessential form of rich inter-human interaction, and is often grounded in a specific situation (e.g., a comment in response to an event). In this work, we attempt to build computational models that can produce witty descriptions for a given image. Inspired by a cognitive account of humor appreciation, we employ linguistic wordplay, specifically puns. We compare our approach against meaningful baseline approaches via human studies. In a Turing test style evaluation, people find our model's description for an image to be wittier than a human's witty description 55% of the time!", "text": "figure sample images witty descriptions generation model retrieval model human. word parenthesis associated image. provided reference source unexpected used caption producing witty remark given image. approach inspired suls two-stage cognitive account humor appreciation. according suls perceiver experiences humor stimulus causes incongruity followed resolution. attempt introduce incongruity using unexpected word description image. consider words used descriptions fig. expectations perceiver regarding image disconﬁrmed description mentions poll city street’. incongruity resolved perceiver reinterprets image description original word associated image incongruity followed resoluwit quintessential form rich interhuman interaction often grounded speciﬁc situation work attempt build computational models produce witty descriptions given image. inspired cognitive account humor appreciation employ linguistic wordplay speciﬁcally puns. compare approach meaningful baseline approaches human studies. turing test style evaluation people model’s description image wittier human’s witty description time mark twain inter-human interactions. witty remarks often contextual i.e. grounded speciﬁc situation. developing computational models understand emulate subtleties human expression contextual humor important step towards making human-ai interaction natural engaging instance witty chatbots could help relieve stress increase user engagement being personable human-like trustworthy. bots could automatically post witty comments response friend’s post social media chat messaging. work attempt tackle challenging task ∗part work done intern build computational models based approach produce witty descriptions image. ﬁrst model generates witty descriptions image modifying image captioning model include speciﬁed word description inference. second model retrieves sentences relevant image also contain large corpus stories evaluate wittiness image descriptions human studies. compare top-ranked captions models meaningful qualitatively different baselines. turing-test style evaluation compare head-to-head top-ranked generated description image humanwritten witty description also uses puns. paper makes following contributions best knowledge ﬁrst work tackles challenging problem producing witty natural language remark everyday context. present novel models produce witty captions novel image. models rely linguistic wordplay. unexpected image description inference/retrieval. thus require trained witty captions. humans vote descriptions top-ranked generated captions ‘wittier’ description decoded regular inference humanwitty caption mismatched given image ‘punny’ description ambiguous plausibly witty turing teststyle evaluation model’s best description image found wittier witty humanwritten caption time. theories verbal humor. general theory verbal humor characterizes linguistic stimuli induce humor. binsted notes however implementing computational models theory requires severely restricting assumptions. puns. works studied mechanisms puns induce humor. pepicello green categorize riddles based type linguistic ambiguity exploit phonological morphological syntactic. zwicky zwicky detail difference perfect imperfect puns i.e. words pronounced exactly pronounced differently miller gurevych miller develop methods better detect identify puns. generating textual humor. jape pun-based riddle generating program. leverage phonological ambiguity. task involves producing free-form responses novel stimulus jape produces stand-alone canned jokes. also similar work hahacronym generates funny expansion given stimulus unlike work hahacronym constrained single modality limited producing sets words. comparison approach applicable situational humor real world human interactions since generate free form naturallanguage sentences response visual stimuli. petrovic matthews develop unsupervised model produces like like like jokes. generating multi-modal humor. wang predict meme’s text based given funny image. similarly shahaf radev learn rank cartoon captions based funniness. unlike typically boring context task memes cartoons involve context already funny atypical. chandrasekaran modify abstract scene make funny. task restricted altering input modality task generate witty natural language remarks novel image. lack large corpora witty remarks relationship surprise challenge learning witty purely data driven methods. approach employs linguistic wordplay overcome challenges. describe pipeline models detail. tags. ﬁrst step towards producing contextually witty remark identify concepts relevant context cases image directly associated relevant concepts e.g. tags posted social media. consider general case tags unavailable automatically extract tags associated image. first recognize objects image using image classiﬁer. utilize predictions state-of-theart inception-resnet-v model trained image classiﬁcation imagenet second consider words description image generated show-and-tell image captioning model. architecture uses inceptionv encoder lstm decoder trained coco dataset shown fig. combine object labels classiﬁer words caption produce tags associated image. puns. construct list heterographic homopohones mining web. increase coverage model automatic speech recognition research predicts edit distance words based articulatory features. consider pairs words edit distance manually eliminate false positives. list puns total unique words vocabulary. utilize list ﬁlter puns given image i.e. identify words associated image phonologically identical counterparts. result vocabulary image generating punny image captions. based image vocabulary generate witty descriptions show-and-tell architecture decodes words caption conditioned image. speciﬁc time-steps inference force model produce phonological counterpart word associated image achieve limiting vocabulary decoder contain counterparts image-puns time-step. time-steps follow decoder produces word conditioned previously decoded words. thus decoder attempts produce sentences well based previously uttered words. downside introducing puns later time-steps results less grammatical sentences. overcome training models decode image description forward reverse directions depicted ‘frnn’ ‘rrnn’ fig. respectively. forward reverse generate sentences appears ﬁrst last positions respectively. results pool candidate witty captions. fig. chosen decoded time-steps inference forward reverse respectively. retrieving punny image captions. attempt leverage usage natural human-written sentences relevant given context. concretely attempt retrieve natural language sentences combination book corpus corpora nltk toolkit constraints retrieved sentence. first introduce incongruity retrieved sentence must contain counterpart word associated image. second ensure contextual relevance retrieved sentence must support image i.e. must contain least image tag. results pool candidate captions perfectly grammatical little unexpected relevant given context ranking. rank captions pools candidates models according log-probability score image captioning model. results top-ranked descriptions relevant image grammatically correct. perform nonmaximal suppression i.e. eliminate captions similar higher-ranked caption reduce pool smaller diverse set. ranked captions model ‘best’ captions. generation model produces better descriptions among models. data. produce witty descriptions images validation coco puns associated them. evaluate human studies random subset images. baselines. compare wittiness descriptions generated model qualitatively different baselines. regular inference generates ﬂuent caption relevant image attempting witty. witty mismatch human-written witty caption different image evaluated. baseline results witty caption attempt relevant image. ambiguous ‘punny’ caption word boring caption replaced counterpart. caption likely contain content relevant image also contains relevant image rest caption. annotations. asked people vote wittier among given pair descriptions image. compared head-tohead output captions models baseline captions. choose majority among votes relative choice. metric. fig. report performance model using recallk metric. compute percentage images least ‘best’ descriptions model outperformed baseline. described earlier ‘best’ captions captions sorted log. probability according image captioning model. quantitative results. fig. image descriptions generation approach voted wittier baselines even increases recall steadily increases. indicates generated captions witty context image wittier naive approach introduces ambiguity. retrieved captions hand neither witty relevant image less witty regular inference ambiguous descriptions. further head-to-head comparison generated captions wittier retrieved captions also validate choice ranking captions based image captioning model score. observe ‘bad’ caption i.e. ranked lower model signiﬁcantly less witty output captions. human-written witty captions. people write witty description image figure sample images witty descriptions generation model retrieval model human. word parenthesis associated image. provided reference source unexpected used caption respectively). duce witty captions. instance fig. employs alliteration using original counterpart another example caption makes sense original associated image phonological counterpart cases fig. model naively replaces associated image counterpart description. retrieved sentence often contains words phrases irrelevant context image fig. likely reason retrieved sentence containing perceived less witty compared witty descriptions generated image. since involves unexpectedness objective describing image witty manner often results trade-off description witty description relevant image. interesting study perceived wittiness image description varies includes creative elements becomes less relevant image. another interesting factor inﬂuence perceived humor presentation. instance text cartoons memes funny characteristic informal font seem boring other serious font. producing description image perceived witty challenging description must achieve balance lending easy resolution perceiver impossible trivial. challenges however. instance automatic image recognition captioning models despite great strides advancement recent times still imperfect. approach cascading sources error could adversely affect perceived wittiness image description. presented novel computational models address challenging task producing contextually witty descriptions given image. leverage linguistic wordplay speciﬁcally puns retrieval generation style models. evaluate models meaningful baseline approaches human studies. turing test style evaluation annotators image descriptions generation model wittier human’s witty description time thank shubham toshniwal help automatic speech recognition model. work supported part career google gfra grant wnf-- grant n--- paul allen family foundation award sloan fellowship nvidia donations google gfra faculty award bloomberg data science research grant references salvatore attardo victor raskin. script theory revis joke similarity joke representation model. humor-international journal humor research arjun chandrasekaran ashwin kalyan stanislaw antol mohit bansal dhruv batra lawrence zitnick devi parikh. humor beings understanding predicting visual humor. cvpr. deng dong richard socher li-jia fei-fei. imagenet large-scale hierarchical image database. computer vision pattern recognition cvpr ieee conference ieee pages tsung-yi michael maire serge belongie james hays pietro perona deva ramanan piotr doll´ar lawrence zitnick. microsoft coco european confercommon objects context. ence computer vision. springer pages zhou leah nicolich-henkin alan black alex rudnicky. wizard-of-oz study non-task-oriented dialog systems reacts user engagement. annual meeting special interest group discourse dialogue. page yukun ryan kiros rich zemel ruslan salakhutdinov raquel urtasun antonio torralba sanja fidler. aligning books movies towards story-like visual explanations watching movies reading books. proceedings ieee international conference computer vision. pages edward loper steven bird. nltk natural language toolkit. proceedings acl- workshop effective tools methodologies teaching natural language processing computational linguistics volume association computational linguistics etmtnlp tomas mikolov ilya sutskever chen greg corrado jeff dean. distributed representations words phrases compositionaladvances neural information processing ity. systems. dragomir radev amanda stent joel tetreault aasish pappu aikaterini iliakopoulou agustin chanfreau paloma juan jordi vallmitjana alejandro jaimes rahul humor collective discourse unsupervised funniness detection yorker cartoon caption contest. arxiv preprint arxiv. dafna shahaf eric horvitz robert mankoff. inside jokes identifying humorous cartoon captions. proceedings sigkdd international conference knowledge discovery data mining. pages jerry suls. two-stage model appreciation jokes cartoons informationprocessing analysis. psychology humor theoretical perspectives empirical issues christian szegedy vincent vanhoucke sergey ioffe shlens zbigniew wojna. rethinking inception architecture computer vision. proceedings ieee conference computer vision pattern recognition. pages oriol vinyals alexander toshev samy bengio dumitru erhan. show tell lessons learned mscoco image captioning ieee transactions pattern analysis challenge. machine intelligence", "year": 2017}