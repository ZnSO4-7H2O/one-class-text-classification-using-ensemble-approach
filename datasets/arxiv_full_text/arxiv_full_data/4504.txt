{"title": "A Foundation to Perception Computing, Logic and Automata", "tag": ["cs.AI", "cs.LG", "I.2.0; I.2.6"], "abstract": "In this report, a novel approach to intelligence and learning is introduced, this approach is based on what we call 'perception logic'. Based on this logic, a computing mechanism and automata are introduced. Multi-resolution analysis of perceptual information is given, in which learning is accomplished in at most O(log(N))epochs, where N is the number of samples, and the convergence is guarnteed. This approach combines the favors of computational modeles in the sense that they are structured and mathematically well-defined, and the adaptivity of soft computing approaches, in addition to the continuity and real-time response of dynamical systems.", "text": "report novel approach intelligence learning introduced; approach based upon called perception logic. call ‘perception automata’ introduced learning accomplished different perception resolution. learning automata heuristic rather guarantees convergence approximated function whatever precision required. furthermore learning process take place on-line epochs number samples. perception automata based hierarchal levels resolution level adds details constructed function till final level successfully reconstruct whole function. approach combines favors computational approach sense precise structural rigorous features distributed processing adaptivity soft computing well continuity real-time response dynamical systems. general traditional a.i. techniques significantly better understanding perception process pattern recognition. till unified approach tackle problem intelligence engineering luger asked possible give formal computational account process enable intelligence?. intelligence viewed scientists abstract immeasurable quantity. main purpose artificial intelligence find organizing knowledge helps decision making take place rapidly efficiently; means learning happen optimal speed compact storage. learning also able discover relations symbols represent abstract concepts outer world. fundamentally intelligence knowing rather knowing levesque brachman argued intelligence needs less expressive representation efficient response ‘computation’. others intelligent action requires physical embodiment integration agent world human brain cope surrounding world imprecise uncertain adaptive coping done searching exact mathematical model represent nature rather based learning adaptation. therefore soft computing principles guided facts. theories interpret intelligence ability respond rather trying explains actions husserl stated intelligence knowing true rather knowing cope world constantly changing evolving example animals recognize patterns without ability define them. hence recognition without definition characterizes much intelligent behavior enables systems generalize. therefore information processing human brain expected measurable quantitative computational rather main function brain ensure survival adaptive time varying environment ctually real world problems brain required perceive high dimensional non-linear non-parametric unknown dependency variables world binary world; many states zero black white gradual change extremes mathematical model computation i.e. turing machine based symbols hence deals precise well-defined symbols order start processing human brain structure resemble model; seems hard convert every sensory information distinct symbol however impressive ability sense responding outer world ability enforces think nervous system perform accurate precise sort computation neither symbol-based even fuzzy-logic based spite impression measure computational systems numbers symbols formal logic yields computation processes; computer performs arithmetic operations actually performs logical operations. however biological neural networks actually compute similar way? boolean logic completely defines computable function design computer system called logic design means computation described terms solid formal well-defined logic. hand need another logic describe perception process also formal well-defined unambiguous contradict physical symbol system hypothesis newel simon consider analog nature sensory signals. uzziness human brain comes inability give exact word symbol observe measure. example assume looking analog device pointing position distinct positions actual value asked exact measurement; able give accurate answer; conclude fuzziness comes ability measure sensory signal itself. fuzzy logic based systems approach function approximation soft computing drawbacks firstly structured human solution problem beginning secondly ability learn adapt difficult weak lastly number rules increases exponentially increase number inputs however favor fuzzy logic approach leads reduction complexity knowledge applying fewer rules compared classical approach. reduction comes capability fuzzy system performing interpolation rules property still reserved approach. hybrid models fuzzy neural networks though combines structural knowledge representation fuzzy systems learning ability neural networks lacking ability self-adaptation structure besides heuristic nature learning process guarantee convergence. agree zadeh’s analysis perception universe divided information granules every object degree belonging information granule differ point argue construction granules dynamic based another logic call perception logic explain interaction granules leads precise accurate computation human brain. differentiate ability human brain produce accurate response outer stimuli apparently based accurate computation inability bring symbol stimuli faces; explained naming stimuli consumes cognitive space whereas required stimuli proper response without trying name give symbol. report argue existence fuzziness human perception result incomplete symbolizing event; inability give exact measure phenomena fuzzy signal inside human brain degree perception certain event. however human focuses distinguish separate event granular able describe exact word. therefore need mathematical model express phenomenon; call multi-resolution perception analysis. fuzzy logic prerequisite existence ‘symbols’ inherited fuzzy model; symbols fuzzy sets themselves. proposed perception logic terms symbols bases functions fixed subject topology re-ordering confine flexibility learning automata. objective report propose perception model acts rationally instead computational model appear intelligent. work argue biological neural network alternative even based formal logic approach rather based logic call ‘perception logic’. specifically research deal problems common sense reasoning could contribute significantly solution real world problems robotics computer vision machine learning speech recognition. study intended theoretical; rather presented engineering perspective. motivations work human living organisms respond similarly similar stimulus leads assume existence functional dependency natural behavior. people living organisms learns events repeat similarly. random events could never lead learning. similarity continuity enables generalize predict learn. meaning word ‘perception’ includes construction knowledge sensory information discovery associations level knowledge organization knowledge adaptation recall feasible reliable. odeling perception generally cognition classified traditional symbolic approach dynamical approach soft computing approach. qualitative structure newell simon holds cognition kind turing-machine computations however illsuited certain important applications called ‘natural computing’ bviously human brain another version universal turing machine cognitivism ‘good fashion artificial intelligence’ gofai assumed cognition form computation furthermore clear soft computing general still replicating neural system tasks simply like seeing hearing recognizing actions still difficult replicate simply them soft computing ognition seen scientists like newell simon computational process computation here mean symbolic logical manipulations turing machine perform. others dynamical system dominance traditional a.i. made approach considered much however recently dynamical approach restored attention work thelen smith argued symbolic processing computation correct approach understand cognition. moreover freeman skarda symbols representation harmful understand cognition. gelder port showed computational view cognition transformation static symbol another wrong right view dynamic system theory reason computation approach dominating good fashioned artificial intelligence provides notation mechanism terms computation notations; computation form machines provides mechanism capable processing symbols. similar concepts applied understanding self-production biological cells broadband definition mechanism could help explaining complex system like brain works main features computation approach provides abstract specification casual organization system .the gofai scientists took computers model cognition. since computers assume problems solved formal symbolic cognition would assumed modeled similarly example brooks called smpa sense model plan action approach. computational approach cognition focuses structure illustrate process information processing explain dynamic change mental process. computational approach explains manipulation explicit static symbols. real situation emergent active symbols interact change time hand dynamical approach focuses change cognition systems contributes describe coupling among brain body environment many reasons argue cognition form computation neumann architecture quite different form architecture brain. brain central control random access memory serial processing ecently dynamical approach cognition retained attention believed sufficient power scope cohesion count strong approach understanding cognition dynamical modeling based upon dynamical system theory includes terms attractors transients stability coupling bifurcations chaos forth hence dynamical system quantitative variables changing time accordance dynamical laws described equations representation dynamical approach seen transient changing rather static context free permanent units dynamical models treat process decision making variables evolve interactively time provide better understanding cognitive process dealing real time control dynamical approaches explain behavior system geometrically terms trajectories\" attractors\" bifurcations\" dynamical systems useful analyzing self-organization emergent behavior\" relative stability component coupling fact picture human brain gives rise dynamical system numerous variables changing time continuously coupling interaction other. structure could described differential equations sensory signals inputs motor neurons outputs internal neurons internal states dynamical approach cognition guided fact natural cognition dynamical phenomena better understand dynamical terms dynamical theories cognition languages describing continual temporal change complex systems owever problem dynamical system approach cognition yield concise single formation share characteristic continual coupling brain body environment real time hence dynamical approach focuses change whereas computational approach focuses internal structure problem dynamical approach pointed clark folds scaling style explanation scaling meant dynamical system general extremely hard analyzed high dimensional style explanation mean dynamical system analysis provide means answer behavior given system appears like this compare conclude results expect dynamical approach catch aspects cognition suitable computational approach story comprehension seems suitable significant range cognitive phenomena dynamical classical approach opposed other. since dynamical systems could perform computations real numbers analog computers hand classical approach effectively simulate dynamical systems computational approach cognition considered happen time. hand dynamical approach cognition happens time classic cognitive science symbols manipulations basic building blocks. dynamical approach dynamical entities system states trajectories shaped attractors positions therefore need theory combines structure change unified formation. soft computing approach provides another means model perception cognition favors classical hard computing approach artificial intelligence precise certain rigorous however obstacle faces symbolic computation dynamical; symbols derivatives smooth functions hand soft computing approach promising since real world live explicitly measured even certain precision certainty carry cost contract hard computing soft computing approximate heuristic informal qualitative solution however spite success soft computing methods formal models still advantages quantitative precise mathematically well defined. however hard computing always stuck problems complex high dimensional complete. therefore advances soft computing hold potential revolutionizing field a.i. atural computing suggested defined maclennan computation occurs nature inspired nature. examples natural computation include information processing brain immune system evolution nature examples computation inspired nature include artificial neural nets genetic algorithms simulated immune systems colony optimization particle swarm optimization simulated annealing applications autonomous robotics real-time control systems distributed intelligent systems relevant natural computing understood terms computation computational model used mimic behavior biological systems. however natural computation real-time flexible adaptive robust continuous natural computing computations allows smoothness time considers small changes natural computation neural networks requires non-turing models computation natural computing discrete continuous continuous computation could serve alternative model relevant natural computation brain. also related massively parallel analog machines order mimic natural cognition need generalized model analogical reduced digital model extremes considered. popular suggestion model dynamical system discrete attractors natural biological cognition based simply propositional logic actually neurons much like sophisticated analog components moreover sense organs like effectors analogical however mean brain deal boolean logic easily distinguish pairs opposites black white sweet bitter extended computation theory could expected provides means understand complex systems like brain biological systems what need rapprochement computation dynamics provide both. finally instead arguing whether brain computer brain able implement various complex computations dynamics computation adaptation come unified approach? question asked michel basically nervous system seems balance continuous analog perception-based computation discrete logic based computation hybrid computation presented model consists logic based associative computing. architecture combine best properties classic logic-based digital computer associative perceptuallybased neural computer informative physical biological computes whether underlying technology digital analog even biological maclennan argued computation broader definition include digital analog computation practical success digital computers confined meaning turing machine-computation computation. argument based primarily existence differential analyzer analog computers modern analog vlsi devices hence turing machine represent kinds computations defined maclennan example analog computers represents another alternative computation. broadened definition computation needed order include discrete continuous computation. obviously continuous computation contradicts many assumption model computation suitable addressing issues natural computing instead trying find model nature computation better introduce term natural computing broader definition understand computation nature earning modeled traditional methods statistical fuzzy approximation methods. however learning experimental data still needs mathematical analytical model perfect intelligent system completely said ‘learn’ luger declared there limited results programs interesting sense said learn even fundamental issues organizing knowledge require research. learning process general faces critical problems determining sufficiency cleanness data generalization universal approximation neural network fuzzy logic matrix support vector machine interesting property used model highly nonlinear partially known complex system always fundamental problem prerequisites computational techniques used order approximate multi-variate function. support vector machine based statistical theory learning; probabilistic models always formalize problem randomness data whereas backpropagation networks based parameters estimation approximation methods fuzzy systems based fuzzy logic; models imprecision vagueness data. radial bases neural networks fuzzy logic approach though represent different techniques shown kecman mathematically similar. real learning systems must satisfy epistemological commitment order ‘intelligent’ current learning systems actual limiting problems generalization problem problem learning problem inductive bias learning thirdly empiricist dilemma understanding constraint-free evolution introduced learning models usually constrained structure represents approximation; could know given structure suitable larger smaller certain application? another problem ‘quality quantity’ training data example could know training data sufficient fully represent whole problem domain? another problem training lead problem over-fitting over-training trivial know stop training order prevent problem problem using neural networks general cannot prove reaches optimal approximation required function every time train second problem inductive bias rationalist’s priori reflects bias creator learning model world expects example neural networks learning behavior also assumes inductive bias. example limitation perceptron introduction hidden nodes third problem empiricist’s dilemma discusses problem convergence unsupervised learning models; actually know going. unsupervised learning models also problem inductive bias appears design nodes selection operators search techniques. earning engineering terms defined function approximation. general function means dependency variables; casual relation variables also known function makes function approximation difficult theoretical background determining best form approximate actual function. function approximation error function depend linearly weights hence convex property always satisfied convergence approximations always guaranteed engineering problem function approximation approximate interpolate sparse noisy training data points. models used functions approximation known networks machines function approximation basic problems choosing form norm form mean function approximate actual unknown function norm mean distance function measures goodness approximation function. traditional functions used functions approximation tangent hyperbolic radial basis function polynomial functions fuzzy membership function bases activation truncated fourier series historical approximations algebraic trigonometric polynomial defined whole domain limited capabilities taking sharp bends followed flat ones. piecewise functions divide region several intervals joints. positions joints subject learning learning process complex requires nonlinear optimization. approximation methods polynomials splines number parameters give approximation. problem vandernonde matrix singular ill-conditioned using linear-in-parameter approximation function resulted error function convex norm used implies guaranteed global minimum. order approximated function increases better approximation introduced. however higher degree lead over-fitting problem. degree approximated model represented degree polynomial number nodes hidden layer neural networks number fuzzy rules fuzzy model. over-fitting avoided relaxing interpolation requirements. problem choosing form much important choosing norm since function approximation compatible underlying function none norms improve approximation choice norm depends practical application hand. difficult problem function approximation determining number parameters number neurons neural networks. number neurons hidden layer determines capacity networks ability approximate certain function. furthermore error functions soft models convex quadratic error function depends nonlinearly upon weights hence search minimum hard uncertain task. summarize function approximation always extremes avoided filtering relations hence eliminating characteristics extreme following noise overfitting training data. approach learning computational process defined predefined mathematical model rather based local interactions local decomposition signal effects described later. perceive daily life boolean approximation pair opposites extremes continuous concurrent perception extremes. analysis real number represents continuous quantity world perceived pair ‘observables’ quantities; represents degree belonging either extremes. main difference call perception logic existing logics view extremes example view white black good etc. existing logics express logical values argue part truth whole picture could clear express object logical value respect extreme words white take perception value black take perception value perception value range degree belonging extremes fully represent position perception space. known humans self ability measure anything accurately similar metric device tend give fuzzy words express measurable quantity imply signals brain based fuzzy logic rather argue perception signal inside brain fully represents actual signal association exact word symbol even number. therefore fuzziness comes result inability associate symbolic number observed stimulus. however planning phase cognition decision required taken based incomplete information knowledge expect that phase something similar fuzzy inference engine exists. easuring viewed terms perception cognition terms mapping natural quantity symbol; mapping quantity symbol represented dedicating certain neuron hence costs delay perception propagation time. since shortened cognition cycles performed real time expect intermediate measuring step along cycle know activities responses done without thinking observing give person gray paper white? answer answer idea. answer mean answer ambiguous even fuzzy instead gave exact answer based knowledge white black colors appear make confused actually know thing colors says idea. should herein noted switching logic design order illustrate idea give following example hypothetical machine modeled based certain logic question weather hot? response machine depends type logic based upon illustrated table types logic certainly simulated electronic computers. noted basically boolean logic contain third state tells answer ‘ideal’ comments’ however actual digital computer architecture incorporates state design circuits could motivates think digital computers computational power turing machine has. three valued logic ambiguity defining operations multi-valued logic argued many authors generalized version boolean logic fuzzy logic irrespective success still ambiguity ambiguity implies machine exact measure result incomplete knowledge. perception logic incorporate truth values extremes time complement time reason behind interpolated shown later order approximate function behavior moreover includes null state well. noted ideal passive much similar engineering third state high impedance digital circuit design example regular expressions represents string length zero means string logic circuit design engineers enforced third state called ‘high impedance’ order solve problem switching sharing etc. herefore might helpful assume that architecture biological neurons neuron either excited level excitation excited implies taking part perception process. logic truth falseness dual other duality implies existence truth falseness time concurrently. interested manage behavior order reach point learning means could used base developing automata could model perception process; relate perceptual events associate stimulus responses cognitive structure like brain. imilar quantum perception observable viewed object discrete continuous aspects like qubit c-bit viewed quantum two-state system. bases logic opposite value rather traditional orthogonal bases. traditional boolean logic separate states conversely c-bit perceptual observable holds states simultaneously perception value superposition states. l¬x. represents degree belonging perceptual signal positive opposite whereas represents degree belonging negative opposite general perception belonging function lx=bx need transformation transform linear belonging function analysis transformation covered report perception observable cbit formulated logical function represents logical dependencies independent cbit dependent cbit. association dependent observable independent observable given logical space belongs range decomposed logical space namely practical view analysis observations given x=-+ respectively i.e. boundaries mid-point relation logical spaces follows states decomposition space neighbors sub-spaces brings three bases span space shown figure result formulates composition process subspaces order realize function space based observations mid-point result constructs basic milestone multi-resolution analysis perceptual observables. hierarchal decomposition logical spaces construction discussed later section erception defined process organizing information acquired real world construct knowledge representation enables rational actions. process includes learning process main part. order model perception need non-turing machine model based different kind logic perception logic. luger emphasized that possible universal machine turing post general. paradoxically intelligence require less powerful computational mechanism focused control. human beings even animals learn based assigning symbols sense even giving measure actually perceive without ability measure sensing data. hand misleading assume natural neural networks deal numbers represented symbols digital computers turing machine assumes. sensory systems receive various kinds signals; convert symbolic numbers daily computers rather signal converted information-observable observable fully represents original signal without loss information. that neural network decompose signal certain enables discriminate signal multi-levels resolutions natural network capacity. decomposed features associated others based learning mechanism; finally related desired action responds rationally outer world. hence neural networks seen mechanisms mirroring outer world inside brain hence reacting spite outer world recast explicit symbols could expect neurons self-organized; selforganization could represent meaningful symbols patterns human used recognize. analysis assume sensory signal vary actually nervous system positive voltage neuron +mv. value perceptual value extreme opposite like sweet black soft whereas value perceptual value extreme opposite bitter white hard. important note perceptual value zero corresponds neutral equilibrium state nervous signal means neither sweet bitter cold black white addition spaces also third space logical belonging space perceptual value mapped separately onto logical values l¬x. represents degree belonging perceptual signal positive opposite whereas represents degree belonging negative opposite clear hand shown figure imilar multi-resolution analysis wavelets function decomposed several level perception lover level gives better image function full function image perceived. contrast analysis father mother basis functions namely shown figure imilar wavelet analysis percept-lets formed recursively level higher level. wavelets done means scaling shifting; operations difference analysis parents functions order construct bases shown need types shifting; shift right shift left efer logical spaces section based equation describes relation logical space sub-spaces bases second level perception basic daughter percept-let virtual bases ourier transform well wavelets transform originally transform signals time domain frequency domain signal special type function independent variable time computations transformations depends assumption samples given equal interval time case transformation. difference require existence samples hand transformation begins whereas transformation therefore perception transformation learn line sample data provided. additionally perception transformation viewed top-down approach function decomposition i.e. starts perceiving whole linear term function frequency part continues realize high order parts. earning process includes models knowledge acquisition unknown system concept defined approach estimate parameters model based using training data engineering terms called parameter estimation weights updating identification self-tuning process learning experimental data viewed statistical learning earning viewed process building model describe certain phenomena seeking function sample data proves efficient general coming data. enables estimate anticipate predict behavior phenomena. learning finding suitable function reduce huge volume sample data meaningful rules relations like searching general mapping function coincides training pairs values approximates actual function values outside training data range. earning trivial simple task; still difficult parts a.i. model. however learning considered important parts intelligent behavior moreover algorithm learn data said intelligent problem learning still addressed many fields biology neuroscience psyclogy philosophy till automation knowledge acquisition using machine learning methods still active area research main objective learning model models capable thinking acting rationally; rational system acquire knowledge respond rationally right times. soft computing techniques able learn including fuzzy models neural networks support vector machines recognized alternatives standard hard computing approach efficiency learning procedure depends upon ability abstract summarize create compact storage learnt functions i.e. remember long list if-then rules memorize huge amount pairs data learning automata also depends also structure means samples provided completely change reinvent structure rather adds without changing structure re-initializing learning process. approximation function relates perceptions depends directly required level perception perception resolution. perception resolution could defined maximum attained level perception. approach fastest learning process occur samples provided sequence corresponds hierarchal structure perception levels i.e. data level data level specifically sequence given follows {+}{-½+½ {-¼¾+¼+¾ data given order need scan data learn bases first level till maximum number perception therefore need number epochs order volume input data shown equation first level perception mapping represented points boundaries simply represented bases boundaries multiplied weights equals values boundaries. general level resolution weights equal samples represented bases level values given since representation replaced bases perception resolution shown equation consequently representation level replaced bases perception resolution till level shown equation conclude function decomposition transformation represent function. view function transformation follows first level perception extracts linear part function second level perception extracts deviation approximation mid-point provides better approximation adds first term non-linearity first resolution. consequently higher level perception compensates deviation previous approximation function fully represented decomposition process. short last level resolution output fully representing function whereas lower resolution output approximates function. term automata emphasize learning process proposed model achieved motive power within itself. obviously important feature intelligent system have. automata learning process achieved locally within node neuron expansion structure organization nodes neurons autonomous need external centralized guide. igure shows layout proposed automata inputs automaton i=..m shown three phases decomposition phase learning phase realization phase. decomposition phase generates bases learning phase updates weights bases level ascending phase i.e. weights first level namely updated first difference sample value function resolution first level calculated difference input second level learning. consequently second level resolution weights updated difference also generated process repeated last level resolution difference expected negligible igure represent learning step details shows nodes decomposition phase level resolution example first level transfer function respectively synapses similarly details second third levels perception presented. figure represents realization step details also shows nodes decomposition phase level resolution step update occurred weight learning step already final value weight. ognitive timing complexity automata studied terms size input requirements assumptions automata could better described assumptions requirements natural computing described maclennan first requirement natural computing real-time response animals respond fraction second outer stimulus takes place real-time therefore speed basic operation critical issue. intermediate results important; progressive approximation gets closer answer useful especially could anticipate response starting analysis computational model terms space time complexity less relevant context natural computation since size input generally fixed comparison natural computation models based criteria speed response generality response another criteria flexibility response novelty measures ability respond correctly novel input another criteria adaptability since natural environment unpredictable time-changing important issue whether natural system adapt changing environment fast accomplish gradual adaptation generally preferred abrupt change criterion stability learning another criteria tolerance noise error faults damage since natural environment noisy natural devices suffer internal disturbance well. atural computation model certain assumptions must fulfilled first physically realizable i.e. matter energy finite second assumption physical aspects representations implies syntactic formality natural computing reduced mechanical process intelligence defined terms specific process order deny ghost machine assumption important assumption real-time response. another assumption ‘abstract formality’ dependence abstract forms representations formal relationships. assumption input output information processing assumed continuous. another assumption non-terminating property natural computation; natural computation continuous interaction environment. better think natural computing real-time control system rather computing function case computation.an important assumption continual presence noise uncertainty error indeterminacy information representation processing final assumption input output assumed fixed size. opposed unbounded representation computation ssume function maps perception logical value another perception given disc-shaped dots figures samples given boundaries i.e. values -/....+/+ simulation used percept-let. function figure nearly linear function figure nonlinearity function figure nonlinear. figures perception resolution level shown figure. function approximated rather exactly represented output maximum resolution level esults third function compared feedforward neural network feedforward neural network simulated using matlab using levenberg-marquardt optimization method updating weights neuron tansig activation function. performance network depends initial setting weights average reached mean squared error epochs importance viewing logic continuous form continuous logic variable theoretically represented infinite zeros ones sequence hence infinite amount information. therefore expect neuron logicprocessing unit property infinite information-carrying capacity. logic ambiguity assumed; universe discourse mapped onto perception space inversed without loss generality. introduced model perception represents lower level mental process i.e. knowledge acquisition perception model higher level thinking planning perception automata based approach dynamical system consists hyper-graph processing elements; element either excited quiet isolation null state similar high impedance third state logic design. ased view perception automata measure sensory signals directly rather organizes components certain signal potential distinguished topological nodes discriminate them. learning accomplished re-organization nodes adjusting local weights based local interaction therefore perception automata could seen geometrize computation. symbols represented internally nodes signals decomposition aggregation features based output. model equilibrium state automata distributed nodes nodes either excited excited advantage approach symbols ability change adapt exist model luger mentioned theory symbols reduce patterns network turn influence adaptation network extraordinary contribution. support number developments integrating network-based perceptual knowledge intensive reasoning facilities single intelligence. perception automata produces approximation exact representation perception space viewed transformation samples another space. transformation used directly data compression similarities wavelet transform multi-resolution analysis note differences them example learning automata decomposing function based approach whereas multi-resolution analysis bottom approach secondly wavelets assumes existence samples starting decompose whereas perception automata requires condition thirdly equal intervals samples required; addition training data function approximator simply captures information modifies structure different level resolution approximation. proposed learning automata ad-hoc solution approaches soft computing rather proved approximate converge. therefore given training data samples represents relation relation function approximated perception automata different levels perception resolution. approximation expressed rigorous mathematical form enables designer take decision level required approximation precision. difference approach approaches clearly wide; problem rules-based systems difficult adaptive deal uncertainty mathematical foundations also knowledge acquisition representation. fuzzy logic tool representing imprecise ambiguous vague information. power lies ability perform meaningful reasonable operations based concepts outside definitions conventional boolean crisp logic. introducing elasticity numbers symbols natural inability provide exact measurements. therefore although fuzzy logic elasticity gradual degree belonging symbols represented fuzzy sets limited ability lean adapt. hand current artificial neural networks considered physical realization actual neural networks help uncover internal structure structure real neural networks suffer long learning time tendency overfitting generalization guaranteed convergence. although symbolic computation neural networks approaches intelligence seem different approaches share common properties firstly encode intelligence computation secondly offer formal model thirdly seek physical realization intelligence. reliable neural network model cannot assume model internally calculate i.e. subtract perform arithmetic operation explicitly unless dynamics model assumed certain functionality approximated operations. also assume exists centralized learning algorithm adjusts weights based objective function optimization. enerally drawback neural networks fuzzy systems seen models techniques. neural networks fuzzy systems model free estimators; guess output functionally depends input. traditional a.i. methods also model free estimators since conditions actions without declaring mathematical transfer function maps condition space action space. hand favor neural networks fuzzy systems numerical estimators dynamical systems report innovative approach model perception introduced logic model perceptual information proposed. multi-perceptual resolution analysis based logic given. proposed automata based analysis introduced learning mechanism could converge whatever required accuracy provided. simulation results showed ability automata learn different perceptual levels convergence speed compared neural network training process. report play role understanding human cognition ability build machines successfully simulate human behavior. approach combines advantages soft computing formal mathematical modeling sense shares soft computing approach features model-free approximator adaptive. mean time considered solid mathematical model since converges whatever accuracy want; secondly offers precise description approximation level. brooks intelligence without reason. steels brooks artificial life route artificial intelligence building embodied situated agents hillsdale lawrence erlbaum associates. bruce maclennan natural computation non-turing models computation technical report cs--. preprint article theoretical computer science based invited presentation american mathematical society meeting husserl crises european sciences transcendental phenomenology introduction phenomenotogical philosophy evanston iii. northwestern university press. harvey vaughan paolo time motion studies dynamics cognition computation humanoid walking hart fourth intl. symp. human artificial intelligence systems control autonomy. december japan. james anderson arithmetic parallel computer perception versus logic brain mind kluwer academic publishers proceedings first ieee international conference cognitive informatics alamitos kecman pfeiffer exploiting structural equivalence learning fuzzy systems radial basis function neural networks proceeding second european congress intelligent techniques soft computing vol. melanie mitchell complex-systems perspective computation dynamics\" debate cognitive science. proceedings annual conference cognitive science society", "year": 2006}