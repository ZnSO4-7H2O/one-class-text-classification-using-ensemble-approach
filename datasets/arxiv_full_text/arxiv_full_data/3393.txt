{"title": "Change-point Detection Methods for Body-Worn Video", "tag": ["cs.CV", "cs.LG", "stat.ML"], "abstract": "Body-worn video (BWV) cameras are increasingly utilized by police departments to provide a record of police-public interactions. However, large-scale BWV deployment produces terabytes of data per week, necessitating the development of effective computational methods to identify salient changes in video. In work carried out at the 2016 RIPS program at IPAM, UCLA, we present a novel two-stage framework for video change-point detection. First, we employ state-of-the-art machine learning methods including convolutional neural networks and support vector machines for scene classification. We then develop and compare change-point detection algorithms utilizing mean squared-error minimization, forecasting methods, hidden Markov models, and maximum likelihood estimation to identify noteworthy changes. We test our framework on detection of vehicle exits and entrances in a BWV data set provided by the Los Angeles Police Department and achieve over 90% recall and nearly 70% precision -- demonstrating robustness to rapid scene changes, extreme luminance differences, and frequent camera occlusions.", "text": "body-worn video cameras increasingly utilized police departments provide record police-public interactions. however large-scale deployment produces terabytes data week necessitating development eﬀective computational methods identify salient changes video. work carried rips program ipam ucla present novel two-stage framework video change-point detection. first employ state-of-the-art machine learning methods including convolutional neural networks support vector machines scene classiﬁcation. develop compare change-point detection algorithms utilizing mean squared-error minimization forecasting methods hidden markov models maximum likelihood estimation identify noteworthy changes. test framework detection vehicle exits entrances data provided angeles police department achieve recall nearly precision demonstrating robustness rapid scene changes extreme luminance diﬀerences frequent camera occlusions. body-worn video cameras becoming increasingly popular tools police departments used provide record police-public interactions shown increase accountability among oﬃcers furthermore recently become topic widespread interest among general public especially given recent controversies regarding police-public relations policy. produce video police oﬃcers wear specially designed cameras chests record interactions public. however large-scale deployment produces terabytes data week much complete review humans. necessitates development eﬀective computational methods identify salient changes video various states building interacting interacting public car. early architectures literature changes videos detected using variety statistical image processing techniques based computing diﬀerences image feature representations methods extend basic spatiotemporal models interesting ways produce video-speciﬁc changepoint detection algorithms. example authors introduce bayesian method segment videos containing speciﬁc scenes clusters online unsupervised accompanied conﬁdence probabilities. method applied robotics. authors extend statistical change-point detection algorithm video order track objects. recent deep learning literature authors propose convolutional network sliding frame window input capable creating spatiotemporal features classify videos. change-point detection literature informs part approach well. classic statistical methods range simple summean-based thresholding algorithms single change-point detection oﬄine †department mathematics state university york geneseo ‡department computer science university toronto §department mathematics university california angeles ¶department mathematics/computer science depaul university ∗names ordered alphabetically signify equal contribution work authors. data nonparametric tests changes distributions statistical methods bayesian priors incorporate time-dependent information probability change-point occurring paper present novel two-stage framework video change-point detection draws methods machine learning computer vision change-point detection. begin video data ground truths time changes predeﬁned states occur. states mutually exclusive collectively exhaustive refer positive negative states. then selectively extract frames video create time series frames. ﬁrst stage utilize feature extraction image representation methods generate compact representation frame label representation classiﬁers support vector machine convolutional neural network ultimately construct time series scores. scores measure conﬁdence classiﬁer whether video frame corresponds positive state. addition setting threshold able convert scores binary labels corresponding positive negative states. finally change-point detection algorithms analyze scores labels identify salient changes states interest thereby locating times change-points occur. modular format enables generalization variety change-point classes. paper organized follows. section presents construction video representation classiﬁcation approaches turning computer vision literature using feature detection methods svms cnns change-point detection methods presented section utilizing mean squared-error minimization forecasting methods hidden markov models maximum likelihood estimation. finally perform experiment body-worn video data provided angeles police department parameterized framework detect changes in-car scenes out-of-car scenes achieve promising results presented sections video regarded sequence frames. preprocessing step sample frames videos save jpeg images. goal classify frames either states states wish identify change-points. frame problem scene classiﬁcation. scene classiﬁcation extensively studied computer vision community; consequently methods computer vision classify scenes. current state approaches either keypoint detection bag-of-visual-words technique classiﬁer capable comparing histograms produces convolutional neural network pixel values extend propose novel technique soft histogramming improves classiﬁcation accuracy. also modify architecture pre-trained create capable two-state video frame classiﬁcation. details described following sections. intuitively keypoints distinctive image features. keypoint located keypoint detector image features keypoint’s neighborhood described keypoint descriptor. scale-invariant feature transform keypoint detection description sift features shown invariant image scale rotation partially invariant changes illumination. major steps constructing sift summarized using approach frame represented sift matrix dimenional sift descriptor. however since number sift descriptors extracted varies among frames requires inputs dimension bovw additional step construct image representations. extracting sift features video frames interest took frames states training applied -means clustering separately feature vectors state clusters. centroids clusters computed assign feature vector frames testing remaining part training closet centroids based euclidean distance. general technique called bovw number clusters often referred size vocabulary. bovw example vector quantization computer vision. feature vector represented indices clusters assigned general distinct forms hard soft hard feature vector assigned exactly cluster corresponds closest centroid; whereas soft feature vector assigned clusters work feature vector’s membership cluster depends feature vector’s distance corresponding centroid. propose following technique perform soft centroids computed clustering stage total number centroids {fi}f denote sift feature vectors extracted frame. goal construct measures eﬀective number feature vectors assigned cluster feature vector compute euclidean distance centroids centroid closest relative distance whereas farthest centroid gets relative distance control contribution clusters whose corresponding centroids closest parameter introduced. deﬁne exponentially decayed relative distance essentially recover hard approaches positive inﬁnity. contribution note idea closely related histogramming assigning vector clusters essentially achieves eﬀect incrementing counts corresponding histogram bins except later case counts discrete. notational convenience refer soft soft histogramming interchangeably called bovw histogram subsequent sections. note conventional bovw consider spatial information keypoints. words locations objects within images taken consideration. previous literature suggests small size visual vocabulary including spatial information improve classiﬁers’ performances signiﬁcantly large size visual vocabulary improvements substantial. evaluate eﬀect including spatial information keypoints experiment pyramid match kernel partitions input image increasingly spatial bins. level cells placed side image spatial bins equal size. partition occurs level setting parameter maximum number levels able control much detailed spatial information included. example spatial information keypoints considered. represent feature vector histogram cluster membership histogram measures similarity feature vector corresponding centroid. spatial create aggregated histogram summing histograms corresponding feature vectors falling bin. aggregated histograms weighted according level spatial located. matches features ﬁner spatial resolutions expected yield information similarity images histograms ﬁner grids weighted heavily. follow practice give weights levels respectively. ﬁnal step concatenate weighted aggregated histograms spatial bins input image represented vector ﬁxed length. vector later input svm. two-class works ﬁnding optimal hyperplane gives maximum separation training examples classes. goal achieved solving optimization problem maximizes two-class separation penalizing training examples lying wrong sides margins. apply kernel ﬁrst maps training examples higher dimensional feature space optimizing maximum separation. kernel function takes training examples measures similarity. project kernel function corresponds pyramid match kernel sums intersections histogram created using method described above. second classiﬁcation approach deep neural networks. deep neural networks machine learning algorithms jointly learn feature representation discriminative classiﬁer data nonlinear computational nodes called neurons stacked another layers form complex richly informative sets features highly discriminative characteristics. neural networks trained changing weights thresholds parameters generally iterative optimization algorithm like stochastic gradient descent overview historical development neural networks deep learning found ized although earlier forerunners contributed development. convnets extract information input data using overlapping convolutions. convolution operation consists sliding feature detector input data generates output similar dimensionality. feature detector looks speciﬁc feature made number trainable weights. features dependent data; example image features include edges color blobs simple shapes. multiple convolutions performed single convolutional layer output convolutional layer transformed nonlinear activation functions. convolutional layers stacked interspersed pooling layers subsample input produce output lower dimension. convolutional layer made several diﬀerent feature maps take form tensors sense multi-dimensional arrays numbers. feature maps require deﬁnition two-dimensional input image requires ﬁrst convolutional layer contain twodimensional feature maps. multiple feature maps ﬁrst layer output matrices concatenated form output tensors—three-dimensional arrays convolved feature maps next convolutional layers. structure means convolutional networks pass tensors intermediate layers. last pooling convolutional layer produced activation tensor generally ﬂattened single vector connected fully connected layer. fully connected layer followed fully connected layers output layer. case binary classiﬁcation measure error output layer activation using hinge loss function. hinge loss deﬁned convolutional layers create high-quality deep feature representations images fully connected neural networks excellent classiﬁers make convolutional neural networks eﬀective computer vision tasks. unfortunately deep neural networks negative feature take large amounts time computational power train. bypass problem re-use popular well-known network conﬁguration trained weights already exist. pre-trained neural networks created neural network researchers consist known architecture containing numbers weight network. pre-trained networks released ilsvrc competition participants classify images classes. found weights structure networks provide excellent starting points classifying images diﬀerent classes. example reported simply removing output layer popular pre-trained convnet replacing output layer trained detect diﬀerent classes provides state accuracy several computer vision problems. pre-trained vgg- network initially conceived publicly released top-performing model ilsvrc used widely literature achieve excellent results image classiﬁcation problems. original training process vgg- network found main reason vgg- convolutional network deep architecture allowed perform well ilsvrc competition. although vgg- ends -dimensional output layer layer removed replaced layer made binary classiﬁcation task detecting whether scene classiﬁed state another. facilitate this weights downloaded authors’ website network implemented using machine learning software libraries. weights last fully connected layer often tuned task next layer removed layer well output layer. replaced layers single output layer uses hinge loss function. layer weights trained produces univariate scalar score frame conveys positive/negative state label frame. hinge loss function reported produce excellent results diﬀerent classiﬁcation problems. addition using hinge loss regularize weights output layer using elastic regularization deﬁned adding penalty term loss function train network ﬁrst froze weights non-modiﬁed layers would changed. training proceeded using mini-batch stochastic gradient descent. detailed information training results discussed section recap framework sample every n-th frame video apply classiﬁer frame distinguish states. gives series conﬁdence scores. seek changepoints series points frames switch states interest. modular nature framework able explore several approaches problem change-point detection. section discuss variety approaches change-point detection. mean squared-error minimization derive distribution central statistic forecasting methods easily adapted online change-point detection hidden markov models maximum likelihood estimation provide state labels frame single change-point sequence attempt optimally describe sequence using constant functions. optimal point split sequence halves sequence cluster closely around sample means. formally wish create hypothesis test determine measurement given signiﬁcantly small enough represent change-point. change-point. reject null hypothesis declare true p-value signiﬁcance threshold p-value calculations given below. assume independently identically distributed according distribution central limit theorem take sample means normally distributed large enough sample size i.e. properties gamma therefore recursively extend method multiple change-points sequence exist. ﬁrst single change-point described above. change-point deemed signiﬁcant recursively test intervals side change-point another change-point. interval deemed signiﬁcant change-point algorithm stops. forecasting methods allow model data predict future observations using model. take advantage power forecasting change-point detection setting develop call future window technique combine univariate multivariate modeling methods detect change-points time series frames. employ future window technique establish initial model based number observations beginning time series assuming change occur within ﬁrst observations time series. potential changes baseline model predict next observation series compare prediction number future observations call future window. comparing prediction multiple observations future allows series deviates established model signiﬁcant amount time reduces instances false positives created outliers. number observations window changed depending upon desire user either minimize false positives false negatives. diﬀerences prediction observed value window greater threshold whose determination diﬀers method method call value beginning window observations change-point. change-point established reestimate baseline model using observations future window process outlined repeats every point time series except last would impossible take full future window account. methodology estimating future observations based current model lines framing change-point problem assumes shift model change-point methodology enables handling cases multiple change-points cases change-points. furthermore minor modiﬁcations future window technique could handle situations where-in-which user entire data instead receives pieces data over-time. following univariate methods assume change-points frames close temporally related thus output frames stationary furthermore utilize future window technique conjunction univariate models; values future window used re-estimate model change-point found. ﬁrst utilize one-lag autoregressive model accounts correlation values time series predicting next value series basis previous observation. threshold future window technique standard deviation entire time series next combine future window technique mean model computes mean number observations compares values future window mean. standard deviation time series threshold future window technique finally develop call sign-change ﬁlter. potential change-point identiﬁed univariate algorithm ﬁlter computes average scores ﬁnds sign average. sign average change potential change-point eliminate change-point ﬁnal output. ﬁlter signiﬁcantly increases methods’ precision. bovw histograms provide succinct representation frame counting number key-points associated visual word. apply methods directly time series unsupervised approaching change-point detection problem. utilize histogram comparison methods conjunction future window technique accomplish goal. apply methodology bovw histograms condensed representations. produce condensed representations employing agglomerate clustering algorithm group bovw centroids within close proximity speciﬁc application apply algorithm ﬁrst one-hundred centroids represent features corresponding negative state separately second one-hundred represent features corresponding positive state. constructing cluster tree choose clusters visual words simplify histograms without signiﬁcantly reducing informational content achieve choosing inconsistency coeﬃcient cutoﬀ. histogram chosen clusters aggregate points bins handle multivariate representations utilize chi-squared goodness-of-ﬁt test match distance conjunction future window technique. histogram comparison methods ﬁrst observation series baseline model change-point baseline model histogram beginning future window. p-value computed resulting chi-squared value compared alpha value null hypothesis stating histograms similar rejection null hypothesis indicating not. expected histogram baseline histogram observed histograms histograms future window. threshold future window technique alpha level test p-values associated chi-squared values histograms future window less alpha declare change-point beginning window denotes number bins cumulative elements including match distance baseline histogram histograms future window. threshold future window technique feature/bin mean diﬀerences successive observations series; means multiply value constant. histogram methods applied histograms condensed histograms. hidden markov model system modeled sequence discrete latent states which project ground truths whether frames corresponds positive state. sequence modeled using markov chain conditional probability future state depends present state. type state associated emission probability according output assumed generated. latent state directly observable associated output observable. goal construct probable sequence latent states given sequence frame associated sequence estimates parameters computed applying expectation-maximization algorithm baum-welch algorithm step likely sequence latent states inferred using viterbi algorithm sequence scores. project however interested evaluating well trained generalize video. training testing data sets designed following way. videos least exit entrance folds split folds. model trained four folds apply savitzky-golay ﬁlter sequences scores corresponding videos remaining folds. ﬁltered sequences scores input trained model. declare change-point occurs adjacent latent variables inferred diﬀerent states. process repeated times fold testing exactly once. another experiment goal estimate precision videos including without exit entrance. test videos without actual change-points apply trained videos contain least actual change point. results presented table solving problems maximum likelihood estimation common technique machine learning literature. goal maximum likelihood estimation values parameters likely given data available. here develop maximum likelihood formulation change-point using integer programming maximize quantity. essential addition formulation constraint number change-points allowable; otherwise algorithm robust sort noise. optimizes values follows present results applying framework data provided lapd. deﬁne change-points data places oﬃcer exited entered vehicle. states interest inside outside vehicle outside corresponds positive state framework. change-points important police-public interactions often occur oﬃcers outside vehicles. data provided lapd pilot program angeles’ central division body-worn videos recorded using cameras roughly ﬁeld-of-view resolution ﬁsheye lens. videos oﬃcer’s point-of-view body cameras mounted oﬃcers’ chests. videos data average length minutes. videos contain least change-point interest maximum videos begin driver’s side nighttime them vehicle moving point video. addition videos contain occasional camera ﬁeld-of-view occlusions oﬃcers’ hands arms clothing. overall eﬀect data highly varied presents many challenges might expect real-world video data unclear images rapid camera movement extreme luminance contrast diﬀerences etc. since sensitive redundancy training prepare diﬀerent training testing sets cnn. sensitive redundancy training learned decision boundary shifted response aggregated penalties imposed repeated examples wrong side margin. poses challenge project content consecutive video frames often highly correlated frames’ representations expected quite similar. therefore manually select video frames data training testing reduce impact redundancy video data. videos contain least entrance exit take randomly assign videos folds. selected videos select ‘in-car out-car frames resulting data in-car frames out-car frames. trial trained using nine folds tested remaining fold. process repeated times fold used testing fold exactly once. testing accuracy trials averaged give estimate. training proceeds -fold cross-validation entire data videos. first videos split diﬀerent folds. then videos frames extracted every second form data approximately frames. deletions selections made frames retained. training process fold held trained nine folds. performance statistics computed folds averaged. averaging valid combine performance statistics case number frames in-car/out-of-car percentages roughly equal across folds. section presents performance evaluations classiﬁers cnn. figure plots classiﬁcation accuracy spatial pyramid match kernel hard histogram conﬁguration versus number clusters. choice determines total number levels signiﬁcant impact classiﬁer’s performance. increases implies spatial information keypoint taken account classiﬁer’s performance improves greatly. increases frame partitioned figure classiﬁcation accuracy support vector machine spatial pyramid match kernel using hard histogram diﬀerent number levels using soft hard histogram diﬀerent values parameter ﬁner cells extra spatial information also contributes improvements classiﬁcation accuracy. results also show size vocabulary increases spatial information becomes less important. observation consistent results figure compares performance hard soft histogram conﬁgurations. obtain results parameter ﬁxed parameter vary. shown ﬁgure soft technique generally improve classiﬁcation accuracy. soft histogram outperform hard histogram every size visual vocabulary. vgg- convolutional network architecture modiﬁed generalization hinge loss function described section modiﬁcation weights layers except last layer frozen weight updates computed them. preprocessing frames resized mean pixel value reported vgg- authors subtracted color channel. network trained stochastic gradient descent mini-batch size equal size training set. elastic weight regularization described section used penalty coeﬃcient learning rate initialized scheduled according adaptive scheme decreases every epoch. network trained epochs. results shown table implementation carried using tensorflow keras scikit-learn software libraries convolutional network results show large improvement performance statistics gained using deep feature represenations frame opposed shallow feature representations believe sophisticated training methods unfreezing weights adapted vgg- network able produce accurate scene classiﬁcations. section discuss results change-point detection methods. stated beginning section identify points vehicle entry exit. video data apply classiﬁer either bovw-svm every frame classiﬁers detection methods; sequence identify number change-points. also sequences multivariate unsupervised frame representations multivariate change-point detection algorithms sequence identify number change-points. evaluate performance change-point detection algorithms data compare algorithms’ predicted change-points true change-points videos ten-second window error predicted change-point true change-point considered equivalent within seconds other. accounts fact take several seconds exit enter vehicle. calculate precision recall method evaluate performance recall percentage actual change-points within seconds predicted change-point precision percentage predicted change-points within seconds actual change-point. aggregate measurements videos meaning count total number actual change-points predicted change-points across videos. section organized follows. first apply methods videos contain least actual change-point using outputs cnn. algorithms tested full data contains videos without actual change points results jointly presented. discuss results running change-point detection algorithms outputs. finally present results change-point detection methods multivariate unsupervised representations. mentioned section undertake cross-validation produce scores videos using along traditional neural classiﬁer. table shows results applying change-point detection algorithms output videos contain least exit entrance. methods discussed section give comparable recall precision produces highest recall gives highest precision test change-point detection methods scores full data containing videos total contain entry exit car. shown table recall calculations remain presented table videos contribute total number actual change-points. precision calculations however decrease false alarms. methods adjust parameters. uses median ﬁlter window size p-value cutoﬀ bonferroni correction maximum recursive depth acts binary labels. autoregressive mean model forecasting methods sample standard deviation series future window threshold future window ﬁrst observations establish baseline model sign-change ﬁlter; scores. uses parameter classiﬁer accuracy constraint number allowable change-points acts binary labels. size polynomial order savitzky-golay ﬁlter respectively; method acts scores. table presents results applying change-point detection methods scores. comparing table table conclude precision measurements calculate running change-point algorithms scores signiﬁcantly lower precision measurements calculate running algorithms scores. recall measurements however generally comparable except whose recall decreases piece empirical evidence conclude performance classiﬁers signiﬁcant impact precision change-point detection results. again parameter values adjust. output autoregressive forecasting method uses sample standard deviation series future window threshold future window ﬁrst observations establish baseline model; acts scores. mean model forecasting method uses sample standard deviation series future window threshold future window seven ﬁrst observations establish baseline model simple rounding ﬁlter acts scores. parameters described above scores. finally table presents results change-point detection using multivariate data primarily comes bovw histograms. multivariate histograms represent frames entirety classify frames states unlike scores labels cnn. therefore methods detecting change-points video apart exits entrances vehicles. consequently methods fairly precision values detecting changes besides exits entrances precision measurements concerned exit entrance change-points. also worth noting that condensed histogram representations yield similar results full histogram results recorded table table results slightly better results obtained using condensed representations nevertheless realize histograms simpliﬁed without large losses recall precision. univariate methods multivariate methods parameter values adjust. uses parameters outlined univariate results section. chi-squared test uses alpha level future window seven baseline comparison ﬁrst histogram. match distance uses constant times threshold discussed section future window ﬁrst histogram baseline simple rounding ﬁlter above show precision recall methods. tuning parameters prioritize recall precision because enforcement application want ensure best ability miss important events. methods mostly achieve recall methods scores yield precision methods scores yield precision. interesting note large discrepancy change-point detection results diﬀerent classiﬁcation methods despite relatively small discrepancy classiﬁcation accuracy. seems small improvement classiﬁcation performance cause large increase precision change-point detection. finally results particular many methods yield quite similar recall precision values. suggests multiple ways approaching change-point detection problem enabling user choose method based additional considerations algorithmic speed. paper present novel framework change-point detection video using concepts machine learning image recognition change-point detection. outline methods classiﬁcation frame level including cnns feature extraction techniques. describe methods four approaches change-point detection mean square error minimization forecasting hidden markov models maximum likelihood estimation. present performance methods classiﬁer output bovw histogram representations. multivariate methods discuss challenges applying change-point detection methods ﬂexible unsupervised multivariate representations. testing speciﬁcally identiﬁcation vehicle entrances exits methods succeed recall nearly precision highly complex realistic data provided lapd. however believe framework highly adaptable diﬀerent change-point classes within domain enforcement outside instance appropriately re-labeled data believe framework would succeed comparably identiﬁcation video segments oﬃcer speaking member public handcuﬃng suspect engaging foot chase. mind framework presented paper represents promising step toward enforcement’s long-term goal automatic video tagging important segments. would make large-scale deployment much feasible. first would like thank academic mentor giang tran guidance continuous support. suggestions helped tremendously throughout research. would also like thank sgt. javier macias brantingham industry mentors; provided important context project. work completed part research industrial projects students program institute pure applied mathematics supported grants lapd nsf.", "year": 2016}