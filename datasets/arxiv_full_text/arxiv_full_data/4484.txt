{"title": "Reinforcement Learning with Linear Function Approximation and LQ control  Converges", "tag": ["cs.LG", "cs.AI", "I.2.6; I.2.8"], "abstract": "Reinforcement learning is commonly used with function approximation. However, very few positive results are known about the convergence of function approximation based RL control algorithms. In this paper we show that TD(0) and Sarsa(0) with linear function approximation is convergent for a simple class of problems, where the system is linear and the costs are quadratic (the LQ control problem). Furthermore, we show that for systems with Gaussian noise and non-completely observable states (the LQG problem), the mentioned RL algorithms are still convergent, if they are combined with Kalman filtering.", "text": "abstract. reinforcement learning commonly used function approximation. however positive results known convergence function approximation based control algorithms. paper show sarsa linear function approximation convergent simple class problems system linear costs quadratic furthermore show systems gaussian noise non-completely observable states mentioned algorithms still convergent combined kalman ﬁltering. reinforcement learning commonly used function approximation. however technique little theoretical performance guarantees example shown even linear function approximators diverge often used algorithms q-learning value iteration positive results well shown sarsa importance-sampled q-learning convergent policy remains constant however best knowledge result control problem gordon’s proved sarsa diverge paper show control linear function approximation convergent applied linear system quadratic cost functions using techniques gordon prove appropriate conditions sarsa converge optimal value function. consequence kalman ﬁltering convergent observable systems too. although control task seem simple numerous methods solving think technical report signiﬁcance best knowledge ﬁrst paper showing convergence control algorithm using lfa. many problems translated form first slightly modify problem time controller ﬁxed number instead time step process stopped ﬁxed probability modiﬁcation commonly used literature; makes problem amenable mathematical treatments. show separation principle holds problem i.e. control state ﬁltering computed independently other. hand state estimation independent control selection method i.e. estimate state system standard kalman ﬁltering equations hand easy show optimal control expressed function ˆxt. proof based fact noise error terms appearing expressions either linear zero mean quadratic independent cases omitted. precisely denote sequence ˆxt. equation ﬁltered case i.e. computation greedy control action according estimated state instead exact one. proof separation principle sarsa quite similar therefore omitted here. work supported hungarian national science foundation would like thank l´aszl´o gerencs´er calling attention mistake previous version convergence proof. need several technical lemmas show kxtk remains bounded linear-quadratic case also remains bounded kalman ﬁlter case. latter result implies case kxtk remains bounded", "year": 2003}