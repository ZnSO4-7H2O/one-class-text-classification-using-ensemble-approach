{"title": "Finer Grained Entity Typing with TypeNet", "tag": ["cs.CL", "cs.NE"], "abstract": "We consider the challenging problem of entity typing over an extremely fine grained set of types, wherein a single mention or entity can have many simultaneous and often hierarchically-structured types. Despite the importance of the problem, there is a relative lack of resources in the form of fine-grained, deep type hierarchies aligned to existing knowledge bases. In response, we introduce TypeNet, a dataset of entity types consisting of over 1941 types organized in a hierarchy, obtained by manually annotating a mapping from 1081 Freebase types to WordNet. We also experiment with several models comparable to state-of-the-art systems and explore techniques to incorporate a structure loss on the hierarchy with the standard mention typing loss, as a first step towards future research on this dataset.", "text": "consider challenging problem entity typing extremely grained types wherein single mention entity many simultaneous often hierarchically-structured types. despite importance problem relative lack resources form ﬁne-grained deep type hierarchies aligned existing knowledge bases. response introduce typenet dataset entity types consisting types organized hierarchy obtained manually annotating mapping freebase types wordnet. also experiment several models comparable state-of-the-art systems explore techniques incorporate structure loss hierarchy standard mention typing loss ﬁrst step towards future research dataset. recognizing entities types core problem natural language processing underlying complex natural language understanding problems relation extraction knowledge base construction question answering query comprehension early attempts entity recognition focused coarse grained types recently growing interest models explicitly focused entity typing ﬁner grained typesets e.g. figer increasingly sophisticated natural language understanding tasks undertaken machine learning community often require commensurately sophisticated world knowledge. world knowledge often organized hierarchically ontologies motivates creation ﬁne-grained deep high-quality dataset hierarchical types. despite increasing focus ﬁne-grained typing existing typesets still contain order different types. further typesets either endowed shallow hierarchy typically order levels deep don’t links existing work advocate larger deeper typesets models exploit inherently hierarchical nature types. present typenet expert-annotated type hierarchy containing individual types average depth also evaluate several models ﬁne-grained entity typing establish strong baseline conll-yago dataset best model. entity order types clearly exciting opportunities improvement future research. additionally investigate multi-task models explicitly incorporate hierarchical relations types learning objective. discuss typenet dataset entity types extremely grained entity typing. typenet created manually aligning freebase types noun synsets wordnet hierarchy naturally producing hierarchical type set. done ﬁrst ﬁltering freebase types linked entities ﬁltering freebase types. freebase types ﬁltered domain \"/freebase\"\"/dataworld\"\"/schema\" \"/atom\" \"/scheme\" \"/topics\". freebase type ﬁltered generate list candidate wordnet synsets substring match. annotator attempted freebase type synset candidate list parent-of child-of equivalence link examining deﬁnitions synset example entities freebase type. match found annotator queried online wordnet appropriate synset found. procedure carried separate annotators independently conﬂicts discussed resolved. annotators conservative assigning equivalence links resulting greater number child-of links. ﬁnal dataset contained parent-of child-of equivalence links. note freebase types multiple child-of links wordnet. finally ancestors freeebase types added construct dataset. also carried procedure additional links. done computing conditional probabilities freebase types given freebase types collection million randomly chosen freebase entities. threshold probabilities manually ﬁlter resulting links. describe various neural models experiments. input layer represent mention sequence word vectors vector ﬁxed dimension obtain mention vector representation convolutional neural network based architecture. learns mention representations table statistics various type sets. typenet largest type hierarchy gold mapping entities. *the entire wordnet could added typenet increasing total size types. ﬁlter size bias vector size concatenate mcnn another vector msfm obtained averaging surface form entity mention links. provide model explicit signal entity present mention. concatenation passed series afﬁne relu afﬁne transforms obtain ﬁnal mention representation loss function like prior work model entity typing multi-label problem given mention produce vector scores corresponding type. optimize mention-typing loss minibatch pairs {ti} gold types annotated mention score function indicating compatibility score mention type using interpretation type deﬁned unary predicate work also introduce structure loss among types incorporate hierarchy. this separate minibatch pairs {ta} ancestor types type exact scoring functions used different models summarized table either variations binary cross entropy order embedding loss. experiment models whose loss either ltyping alone weighted combination ltyping lstructure. hyperparameters pretrained dimensional case sensitive glove vectors pennington ﬁlter width type vectors dimensional initialized using glorot initialization dropout described fig- optimize using adam tune hyperparameters grid search early stopping development set. dataset evaluation metrics perform experiments conll-yago dev/test split subsampled version wikipedia training. obtain labels mentions distant supervision assuming positive types typenet types entity linked mention. perform heuristic pruning/denoising types even though relevant mention. pruning methods literature either harsh extremely types give increase performance however plan improving future work release gold test data set. obtain typenet types entity ﬁlter freebase types present typenet ﬁnally every type ﬁltered ancestors typenet giving average types mention much greater earlier datasets figer average types mention. since average types entities mean average precision measure performance unlike prior work grained entity typing results summarized table discussion observe encoder model works best multitasking mention typing structure decreases performance structure modeled using product. expected since hypernymy asymmetric relation. furthermore modeling structure bilinear objective improves performance product objective fails perform better regular model. believe nature test data made mostly leaf type predictions non-diverse types diverse dataset requiring predictions different depths hierarchy could structure effectively since posit without using structure model incorrectly predict leaf types parent types true. interestingly observe order embeddings model vendrov poor performance task. attribute fact loss function poorly suited table mean average precision various models typenet. \"mention\" refers simply averaging words entity mention surface form. concatenates mention representations sentence representation. scores +structure additionally multi-task structure loss training objective. problem since uses unrelated concepts negative examples traditional order embedding model actually implies reversal parent-child relation rather simply forcing types unrelated. example consider hypernym link person organism negative example person stadium. loss function vendrov attempts increase order violation person stadium making stadium hyponym person. also observe particularly poor performance combining order embeddings encoder. table- summarizes existing hierarchical type systems including popular data sets figer gillick corro considered task extremely grained entity typing. manually crafted rules patterns hearst extract candidate entity types match wordnet synsets. apply optional type ﬁltering step entity matching candidate type types string match hypernym hyponym. instead manually annotated exact mapping freebase types speciﬁc wordnet synset sense allowing leverage distant supervision trained supervised classiﬁers. knowledge base yago includes integration wordnet type hierarchies derived type system however links entity types wordnet types performed heuristically whereas typenet contains gold links freebase wordnet. growing interest learning representations hierarchically organized objects. vilnis mccallum proposed gaussian embeddings learn containment properties words approximating gaussian distributions. vendrov introduced order embeddings minimizing order violation loss. recently nickel kiela proposed poincaré embeddings. introduced typenet human labeled alignment freebase entity types wordnet synsets. used typeset distantly label conll-yago entity linking dataset reported initial results several models comparable state-of-the-art models previously used pre-existing datasets e.g. shimaoka additionally present results models incorporating structure loss type hierarchy appear required conll-yago dataset helpful diverse datasets different domains e.g. clueweb explore future work encourage community same. exploring sophisticated methods incorporating type hierarchy typing loss well joint models related tasks simultaneous typing entity linking. excited community typenet largest deepest entity type hierarchy manual alignment freebase. hope spur improvements ﬁne-grained entity mention typing linking associated downstream tasks. references jeffrey dalton laura dietz james allan. entity query feature expansion using knowledge proceedings international sigir conference research luciano corro abdalghani abujabal rainer gemulla gerhard weikum. finet proceedings conference context-aware ﬁne-grained named entity typing. empirical methods natural language processing. association computational linguistics lisbon portugal pages http//aclweb.org/anthology/d-. gillick nevena lazic kuzman ganchev jesse kirchner david huynh. contextdependent ﬁne-grained entity type tagging. corr abs/.. http//arxiv.org/abs/.. xavier glorot antoine bordes yoshua bengio. deep sparse rectiﬁer neural networks. proceedings fourteenth international conference artiﬁcial intelligence statistics. pages marti hearst. automatic acquisition hyponyms large text corpora. proceedings conference computational linguistics-volume association computational linguistics pages johannes hoffart mohamed amir yosef ilaria bordino hagen fürstenau manfred pinkal marc spaniol bilyana taneva stefan thater gerhard weikum. robust disambiguation named entities text. proceedings conference empirical methods natural language processing. association computational linguistics pages eduard hovy mitchell marcus martha palmer lance ramshaw ralph weischedel. ontonotes solution. proceedings human language technology conference naacl companion volume short papers. association computational linguistics pages changki yi-gyu hwang hyo-jung soojong jeong chung-hee hyeon-jin ji-hyun wang myung-gil jang. fine-grained named entity recognition using conditional random ﬁelds question answering. asia information retrieval symposium. springer pages jeffrey pennington richard socher christopher manning. glove global vectors word representation. proceedings conference empirical methods natural language processing emnlp october doha qatar meeting sigdat special interest group acl. pages http//aclweb.org/anthology/d/d/d.pdf. sonse shimaoka pontus stenetorp kentaro inui sebastian riedel. neural architectures ﬁne-grained entity type classiﬁcation. proceedings conference european chapter association computational linguistics volume long papers. association computational linguistics valencia spain pages http//www.aclweb.org/anthology/e. nitish srivastava geoffrey hinton alex krizhevsky ilya sutskever ruslan salakhutdinov. dropout simple prevent neural networks overﬁtting. journal machine learning research http//dl.acm.org/citation.cfm?id=. erik tjong sang fien meulder. introduction conll- shared task proceedings seventh conference language-independent named entity recognition. natural language learning hlt-naacl -volume association computational linguistics pages yadollah yaghoobzadeh heike adel hinrich schütze. noise mitigation neural entity typing relation extraction. proceedings conference european chapter association computational linguistics volume long papers. association computational linguistics valencia spain pages http//www.aclweb.org/anthology/e-. mohamed amir yosef sandro bauer johannes hoffart marc spaniol gerhard weikum. hyena hierarchical type classiﬁcation entity names. proceedings coling posters pages", "year": 2017}