{"title": "Learning to Identify Regular Expressions that Describe Email Campaigns", "tag": ["cs.LG", "cs.CL", "stat.ML"], "abstract": "This paper addresses the problem of inferring a regular expression from a given set of strings that resembles, as closely as possible, the regular expression that a human expert would have written to identify the language. This is motivated by our goal of automating the task of postmasters of an email service who use regular expressions to describe and blacklist email spam campaigns. Training data contains batches of messages and corresponding regular expressions that an expert postmaster feels confident to blacklist. We model this task as a learning problem with structured output spaces and an appropriate loss function, derive a decoder and the resulting optimization problem, and a report on a case study conducted with an email service.", "text": "paper addresses problem inferring regular expression given strings resembles closely possible regular expression human expert would written identify language. motivated goal automating task postmasters email service regular expressions describe blacklist email spam campaigns. training data contains batches messages corresponding regular expressions expert postmaster feels conﬁdent blacklist. model task learning problem structured output spaces appropriate loss function derive decoder resulting optimization problem report case study conducted email service. popular spam dissemination tools allow users implement mailing campaigns specifying simple grammars serve message templates. grammar disseminated nodes nodes create messages instantiating grammar random. email service providers easily sample elements mailing campaigns collecting messages spam traps tapping known nets. messages multiple campaigns collected joint spam trap clustering tools separate campaigns reliably however probabilistic cluster descriptions bag-of-words representation incur risk false positives regular expressions standard tool specifying simple grammars. widely available tools match strings regular expressions eﬃciently used conveniently scripting languages. regular expression translated ﬁnite state machine accepts language execution time linear length input string. speciﬁc comprehensible regular expression covers observed instances written expert postmaster used blacklist bulk emails campaign virtually risk covering messages. language identiﬁcation rich history algorithmic learning theory community problem setting diﬀers problem language identiﬁcation learner’s exact goal available training data. batches strings corresponding regular expressions observable training data. learner’s goal produce predictive model maps batches strings regular expressions resemble closely possible regular expressions postmaster would written feels conﬁdent blacklist rest paper structured follows. section reviews regular expressions section states problem setting. section introduces feature representation derives decoder optimization problem. section discuss ﬁndings case study email service. section discusses related work; section concludes. catenation disjunction kleene star written postﬁx notation accepts number repetitions preceding argument expression. parentheses deﬁne syntactic structure expression. several shorthands improve readability regular expressions deﬁned terms basic operators. instance character symbol abbreviates disjunction characters square brackets accept disjunction characters ranges included. postﬁx operator accepts arbitrary positive number reiterations preceding expression accepts reiterations include popular macros—for instance digit. formal deﬁnition regular expressions found online appendix. expressyn sion deﬁnition online appendix assigns tree regular expression. node tree tagged labeling function subexpression indicate node represents argument expression time linear trace veriﬁcation typically represented parse tree par) describing string derived regular expression least parse tree exists string element language case syntax node syntax tree spawn none several nodes parse tree. analogy syntax trees labeling function sion node relation reading left right gives generated string non-terminal nodes correspond subexpressions generate substrings compare diﬀerent regular expressions respect given string deﬁne labels nodes visited path root i-th character parse tree since true distribution unknown risk cannot calculated. state learning problem problem minimizing regularized empirical counterpart risk parameters regularizer structural properties regular expression captured features indicate speciﬁc nesting regular expression operators—for instance whether concatenation occurs within disjunction. formally ﬁrst deﬁne binary vector syntax tree generates substring generates node parse tree path parse tree every character substring example strings bca} matching list node represents subexpression deﬁnition online apelements language motivating application strings emails sampled regular expressions expert postmaster believes identify campaign template feels conﬁdent blacklist. cepts batch strings conjectures regular expression deﬁne loss captures deviation conjecture batch application postmasters expression blacklist campaign unless consider comprehensibly neatly written believe accurately identify campaign. parse trees string similar tree parse tree exists summand deﬁned similarly loss function hierarchical classiﬁcation diﬀerence parse trees string quantiﬁed comparison paths lead characters string; paths compared means intersection nodes deﬁnition loss function bounded zero one; attains zero expressions equal. expressions ranges a-z\\s\\e\\w\\d nodes syntax tree connected edge—indicating syn) argument subexpression syn)—the tensor product deﬁnes binary vector encodes speciﬁc nesting operators node feature vector aggregate vectors pairs adjacent nodes syntax tree joint properties input batch regular expression encoded follows. recall node syntax tree denotes substrings generated subexpression syn) labeled with. deﬁne vector attributes set. property accounted for; application include average string length inclusion empty string proportion capital letters many attributes. full list attributes used experiments included online appendix. joint encoding properties subexpression substrings generated given tensor product joint feature vector obtained aggregating operator-nesting information edges syntax tree joint properties subexpressions substrings generate nodes syntax tree alignment maximal alignment contains constant symbols. maximal alignment strings determined eﬃciently using hirschberg’s algorithm instance dynamic programming. contrast ﬁnding maximal alignment strings np-hard known algorithms strings adds number syntactic variants subexpressions constants replaced match elements matching list node belongs j-th wildcard symbol. lines hence search space possible substitutions wildcard symbols linear number subexpressions occur training sample. turn towards problem determining highest-scoring regular expression maximization regular expressions approximated maximization space deﬁned equation constrained search space initially contains alignment strings alignment regular expression contains constants—which occur strings batch—and wildcard symbol initial alignment thought most-general bound space. deﬁnition alignments batch strings contains concatenations strings wildcard symbol alternate generate elements argue maximization problem decomposed independent maximization problems replaces j-th wildcard alignment simple syntactic structure alignment deﬁnition feature vector decomposes linearly nodes pairs adjacent nodes syntax tree instantiation ynan alignment consists root node labeled alternating concatenation constant strings subexpressions root node connected layer address process minimizing regularized empirical risk deﬁned equation regularizer c||w||. loss function deﬁned equation convex. obtain convex optimization problem upper-bound loss hinged version following margin-rescaling approach rex-svm trained data contains batches total emails corresponding regular expressions collected email service provider. model deployed; user interface presents newly detected batches spam emails together regular expression conjectured rex-svm postmaster regular operations service. postmaster charged blacklisting campaigns suitable regular expressions. study postmasters created regular expressions. these created expressions copying substring automatically generated expression. observe postmasters prefer describe part message feel characteristic campaign whereas rex-svm describes entirety messages. cases postmasters edited string cases wrote expression scratch. illustrate diﬀerent cases figure compares excerpts expressions created rexrex/svm expressions postmaster. ﬁrst example shows perfect agreement rex-svm postmaster. second example expressions close distinct. third example svms produce expressions generate overly general urls lead otherwise-case equation never applies within search space. without case equations decompose linearly nodes parse tree therefore wildcards. hence identiﬁed maximizing variables independently step algorithm algorithm ﬁnds constraint violated strongly within constrained investigate whether postmasters accept output rex-svm blacklist mailing campaigns regular operations commercial email service. also evaluate accurately rex-svm reference methods identify extensions mailing campaigns. right diagram figure shows average loss rexrex/-svm measured cross validation batch held out. postmasters show tendency write expressions characterize message rex-svm evaluate ability rex-svm baselines identify exact extension email campaigns. alignment strings baseline. addition relie searches regular expression matches emails input batch match additional negative examples applying transformation rules; alignment input batch starting point. relie receives additional emails part batch negative data. additional content-based ﬁlter employed provider trained several million spam non-spam emails. order able measure false-positive rates combine data additional non-spam emails also provider. additionally public data consists batches emails extracted bruce guenther archive containing total emails. measure false-positive rates combine collection spam batches outer loop leave-one-out cross validation batch held back evaluate true-positive rate inner loop -fold cross validation regularization parameter tuned. figure shows true false positive rates methods data sets. horizontal axis displays number emails input batch error bars indicate standard error. alignment exhibits highest true-positive rate high falsepositive rate most-general bound decoder’s search space. relie needs zero replacement steps negative examples covered. consequently similarly high truefalse-positive rates. rex-svm attains slightly lower true positive rate substantially lower false-positive rate. false-positive rates rex/ order magnitude rate commercial content-based spam ﬁlter employed email service provider. zero-one loss leads comparable false-positive lower true-positive rates rendering loss funcgold shows impossible exactly identify regular language ﬁnitely many positive examples. notion minimizing expected diﬀerence conjecture target language distribution input strings reﬂects statistically-inspired notion learning. also problem setting learner access pairs sets strings corresponding regular expressions. work identiﬁcation regular languages focuses learning automata problems identical theory transforming generated automata regular expressions lead lengthy terms lend human comprehension work focuses restricted classes expressions symbol occurs times disjunction-free expressions disjunctions left-aligned disjunction-free expressions regular expressions detect urls spam batches develop spam ﬁlter false positive rate. relie-algorithm learns regular expressions positive negative examples given initial expression applying transformation rules long improves separation positive negative examples. complementing language-identiﬁcation paradigm pose problem learning strings target regular expression. training data consists batches strings corresponding expressions. phrase problem learning problem structured output spaces engineer appropriately loss function. derive resulting optimization problem devise decoder searches space specializations maximal alignment. case study conclude rex-svm gives high true positive rate false positive rate order magnitude lower commercial content-based ﬁlter. system used commercial email service provider complements content-based ip-address based ﬁltering.", "year": 2012}