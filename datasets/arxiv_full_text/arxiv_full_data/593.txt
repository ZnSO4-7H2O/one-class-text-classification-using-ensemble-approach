{"title": "Does Multimodality Help Human and Machine for Translation and Image  Captioning?", "tag": ["cs.CL", "cs.LG", "cs.NE"], "abstract": "This paper presents the systems developed by LIUM and CVC for the WMT16 Multimodal Machine Translation challenge. We explored various comparative methods, namely phrase-based systems and attentional recurrent neural networks models trained using monomodal or multimodal data. We also performed a human evaluation in order to estimate the usefulness of multimodal data for human machine translation and image description generation. Our systems obtained the best results for both tasks according to the automatic evaluation metrics BLEU and METEOR.", "text": "paper presents systems developed lium multimodal machine translation challenge. explored various comparative methods namely phrase-based systems attentional recurrent neural networks models trained using monomodal multimodal data. also performed human evaluation order estimate usefulness multimodal data human machine translation image description generation. systems obtained best results tasks according automatic evaluation metrics bleu meteor. recently deep learning greatly impacted natural language processing ﬁeld well computer vision. machine translation deep neural networks proposed competed successfully last year’s evaluation campaign trend generating descriptions images using dnns proposed several attempts made incorporate features different modalities order help automatic system better model task hand paper describes systems developed lium participated proposed tasks multimodal machine translation evaluation campaign multimodal machine translation multimodal image description remainder paper structured parts ﬁrst part describes architecture four systems submitted task standard phrase-based systems based moses described section neural systems described section section second part contains description systems submitted task ﬁrst monomodal neural system similar presented section second multimodal neural machine translation shared attention mechanism. order evaluate feasibility multimodal approach also asked humans perform tasks evaluation campaign. results show additional english description sentences improved performance straightforward translation sentence without image provide good results. results experiments presented section baseline system task developed following standard phrase-based moses pipeline described srilm kenlm giza++ system trained using data provided organizers tuned using mert maximize bleu meteor scores validation set. also used continuous space language model auxiliary features support proposed cslm architecture allows sentence-level features line training data means better context speciﬁc estimations obtained. used four additional scores rerank best outputs baseline system ﬁrst scores obtained separate cslm trained target side parallel training corpus following auxiliary features vgg-fc image features auxiliary feature used ﬁrst cslm image features provided organizers extracted layer vgg- network allows train multimodal cslm uses additional context learned image features. source side sentence representation vectors used method described compute continuous space representation vector source sentence provided second cslm auxiliary feature. idea behind condition target language model source side additional context. scores used n-best reranking probability computed system described following section score obtained recurrent neural network language model weights original moses features additional features optimized maximize bleu score validation set. neural system fundamental model experimented attention based encoder-decoder approach except notable changes recurrent decoder called conditional gru. bidirectional recurrent encoder reads input sequence forwards backwards produce sets hidden states based current input previous hidden state. annotation vector position obtained concatenating produced hidden states. attention mechanism implemented simple fully-connected feed-forward neural network accepts hidden state decoder’s recurrent layer input annotation time produce attention coefﬁcients. softmax activation applied attention coefﬁcients obtain attention weights used generate weighted annotation vector time initial hidden state decoder determined feed-forward layer receiving mean annotation vector. training picked following hyperparameters systems task task embedding recurrent layers dimensionality respectively. used adam stochastic optimizer minibatch size xavier weight initialization regularization except monomodal task system choices adadelta sampling regularization respectively. performance network evaluated validation split using bleu minibatch updates training stopped bleu improve evaluation periods. training times hours respectively monomodal multimodal systems tesla gpu. phrase-based systems task trained using dataset provided organizers described table dataset consists parallel sentences training validation ﬁnally test set. preprocessed dataset using punctuation normalization tokenization lowercasing scripts moses. order generalize better compound structs german trained applied compound splitter german vocabulary training validation sets. reduces target vocabulary unique tokens. translation generation splitted compounds stitched back together. results phrase-based baseline four submitted systems presented table bl+features system rescoring baseline -best output using features described bl+features excluding image features. overall able improve test scores around meteor bleu respectively strong phrase-based baseline using auxiliary features. regarding systems monomodal achieved comparative bleu score test compared phrase-based baseline. multimodal system described section obtained relatively lower scores trained using task data. describe image content make convolutional neural networks breakthrough work krizhevsky convincingly show cnns yield superior image representation compared previously used hand-crafted image features. based success intensiﬁed research effort started improve representations based cnns. work simonyan zisserman improved network breaking large convolutional features multiple layers small convolutional features allowed train much deeper network. organizers provide features participants. precisely provide features ﬁfth convolutional layer features second fully connected layer vgg-. recently residual networks proposed networks learn residual functions constructed adding skip layers network. skip layers prevent vanishing gradient problem allow much deeper networks trained. select optimal layer image representation performed image classiﬁcation task subsection images scenes extract features various layers resnet- evaluate classiﬁcation performance results increase ﬁrst layers stabilize block- based results considering higher spatial resolution better selected layer ’resf relu’ experiments multimodal also compared features different networks task image description generation system results generating english descriptions show clear performance improvement vgg- resnet- comparable results obtained going resnet-. therefore given increase computational cost decided resnet- features submission. figure architecture multimodal system. boxes refers linear transformation means tanh applied inputs. ﬁgure depicts running instance network single example. generation since provided source descriptions image order generate single german description generate german description source pick highest probability preferably without token. data organizers provided extended version flickrk entities dataset contains independently crowd-sourced german descriptions image addition english descriptions originally found dataset. possible dataset either considering cross product source target descriptions taking pairwise descriptions leading training pairs respectively. decided smaller subset sentences. table multimodal system surpass monomodal system. several explanations clarify behavior. first architecture well suited integrating image text representations. possible explore possibilities beneﬁt modalities. another explanation image context contain much irrelevant information cannot discriminated lone attention mechanism. would need deeper analysis attention weights order answered. computer algorithm human participants. modalities english description sentences image. output single description sentence german. experiment asks participants following tasks experiment performed native german speakers proﬁcient english ranging experiment performed ﬁrst sentences validation set. participants performed repetitions task repeating image across tasks. results experiments presented table humans english description sentences help obtain better performance. removing image altogether providing single english description sentence results signiﬁcant drop. surprised observe drop whereas expected good translations obtain competitive results. addition provided results submission subset images; humans clearly obtain better performance using meteor metrics approach clearly outperforming bleu metrics. participants trained train performing tasks could reasons difference. furthermore given lower performance translating english description sentences metrics could possibly caused existing biases data set. chine translation challenge. results show integrating image features multimodal neural system shared attention mechanism surpass performance obtained monomodal system using text input. however multimodal systems improve upon image captioning system phrase-based system beneﬁt rescoring multimodal neural language model well rescoring neural system. references walid aransa holger schwenk loic barrault. improving continuous space language models using auxiliary features. proceedings international workshop spoken language translation pages nang vietnam december. ondˇrej bojar rajen chatterjee christian federmann barry haddow matthias huck chris hokamp philipp koehn varvara logacheva christof monz matteo negri matt post carolina scarton lucia specia marco turchi. findings workshop statistical machine translation. proceedings tenth workshop statistical machine translation pages lisbon portugal september. association computational linguistics. xavier glorot yoshua bengio. understanding difﬁculty training deep feedforward neural networks. proceedings international conference artiﬁcial intelligence statistics society artiﬁcial intelligence statistics. kenneth heaﬁeld. kenlm faster smaller proceedings language model queries. emnlp sixth workshop statistical machine translation pages edinburgh scotland united kingdom july. ryan kiros ruslan salakhutdinov rich zemel. multimodal neural language models. tony jebara eric xing editors proceedings international conference machine learning pages jmlr workshop conference proceedings. philipp koehn hieu hoang alexandra birch chris callison-burch marcello federico nicola bertoldi brooke cowan wade shen christine moran richard zens chris dyer ondrej bojar alexandra constantin evan herbst. moses open source toolkit statistical machine translation. meeting association computational linguistics pages alex krizhevsky ilya sutskever geoffrey hinton. imagenet classiﬁcation deep convolutional neural networks. advances neural information processing systems pages alon lavie abhaya agarwal. meteor automatic metric evaluation high levels correlation human judgments. proceedings second workshop statistical machine translation statmt pages stroudsburg usa. association computational linguistics. tomas mikolov martin karaﬁ´at lukas burget cernock`y sanjeev khudanpur. recurrent neural network based language model. interspeech volume page franz josef och. minimum error rate training statistical machine translation. proceedings annual meeting association computational linguistics volume pages stroudsburg usa. association computational linguistics. kishore papineni salim roukos todd ward weijing zhu. bleu method automatic evalproceedings uation machine translation. annual meeting association computational linguistics pages stroudsburg usa. joint dependency model morphological syntactic structure statistical machine translation. proceedings conference empirical methods natural language processing pages association computational linguistics. jianxiong xiao james hays krista ehinger aude oliva antonio torralba. database large-scale scene recognition abbey zoo. computer vision pattern recognition ieee conference pages ieee. kelvin jimmy ryan kiros kyunghyun aaron courville ruslan salakhudinov rich zemel yoshua bengio. show attend tell neural image caption generation visual attention. proceedings international conference machine learning pages", "year": 2016}