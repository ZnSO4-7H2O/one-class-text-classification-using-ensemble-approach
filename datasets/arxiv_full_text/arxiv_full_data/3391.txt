{"title": "Automatic Construction of a Recurrent Neural Network based Classifier  for Vehicle Passage Detection", "tag": ["cs.CV", "cs.LG", "stat.ML"], "abstract": "Recurrent Neural Networks (RNNs) are extensively used for time-series modeling and prediction. We propose an approach for automatic construction of a binary classifier based on Long Short-Term Memory RNNs (LSTM-RNNs) for detection of a vehicle passage through a checkpoint. As an input to the classifier we use multidimensional signals of various sensors that are installed on the checkpoint. Obtained results demonstrate that the previous approach to handcrafting a classifier, consisting of a set of deterministic rules, can be successfully replaced by an automatic RNN training on an appropriately labelled data.", "text": "recurrent neural networks extensively used time-series modeling prediction. propose approach automatic construction binary classiﬁer based long short-term memory rnns detection vehicle passage checkpoint. input classiﬁer multidimensional signals various sensors installed checkpoint. obtained results demonstrate previous approach handcrafting classiﬁer consisting deterministic rules successfully replaced automatic training appropriately labelled data. keywords recurrent neural networks classiﬁcation time-series paper describes automatic vehicle classiﬁer toll roads based video classiﬁcation installed russian toll roads. vehicle passage detector important parts system. uses input several binary signals subsystems makes decisions vehicle passage based voting scheme vehicle passage detected binary detectors provide positive answer. logic augmented empirical rules provided human expert quantify take account time delays switches binary signals properties sequence switches information. rules extended modiﬁed test deployment based analysis encountered errors. previous paper devoted states accuracy since test dataset extended detection classiﬁcation error cases. noted current paper tests disabled trailer coupler detector. version described previous paper provides accuracy dataset coupler detector disabled. time current classiﬁer version provides accuracy without coupler detector comparing previous version classiﬁer optimized algorithms shield trailer couplers detection correlational detector updated fusion method binary detectors aggregation. would interesting develop automatic method machine learning algorithm could replace human expert. approach potentially could also produce higher classiﬁcation quality. therefore paper solve problem creating method automating synthesis minimizing human involvement. input data consists records. contains several vehicles passages. numerical experiments conducted dataset consisting ﬁles. system ﬁlled three-dimensional signal samples component binarized produced following sensors correlational detector induction loop shield detector also records contain frame sequence number manually created reference signal predictions basic classiﬁer based human tweaked rules record created saved database least input signals changed. problem speciﬁcs dictates special quality passage evaluation metric used equal standard pointwise two-class classiﬁcation metric accuracy extreme cases. reason standard metrics using pointwise difference reference signal predicted signal able estimate passage classiﬁcation quality physically sensible viewpoint. metric used paper pass quality r+∑err number correctly detected passages ∑err classiﬁcation error costs whole test dataset. calculation ∑err various error types complicated procedure described also table denotes true number passages analysed test signal denotes number detected passages quality metric take account detected passage shifted ideal one. however conducted experiments show needed applications since sequence correct passages intersections real passages least instant important delays themselves. section compare results obtained various machine learning methods gradient tree boosting implementation used) logistic regression scikit-learn package fully connected neural network hidden layer consisting neurons simple recurrent neural network simplernn keras package results training source signal without accounting past values provided table lines obtained results imply autocorrelation classiﬁcation using standard methods without taking account dependency .xt−k provides values. situation values comparable easily explained fact moment time three-dimensional vector take eight distinct values thus considered case methods easily provide similar decision rules. ﬁrst idea increase classiﬁcation quality w.r.t. metric extend feature space using previous values {xt− xt−w}. results experiments provided table lines optimal window size classiﬁer type selected using cross-validation procedure. threshold producing binary signal classiﬁer output probability selected maximizing objective function training set. extension provides signiﬁcant increase quality. gives best result. result however better basic classiﬁer. second natural idea recurrent neural networks proved productive labelling sequences time series classiﬁcation. standard recurrent network simplernn recurrent layer hidden layer turns model allows obtain higher quality pretty close basic classiﬁer. note basic classiﬁer uses additional feature trailer coupler detector. feature allows distinguish vehicles moving close distance vehicles trailers thus increasing basic method accuracy experiments feature although additional information could potentially increase classiﬁcation quality. primary reason prediction accuracy algorithms optimize target quality metric different value mean squared prediction error good correspondence target metric hereinafter error mean results section notice model provides results accuracy comparable baseline classiﬁer constructed manually collecting ensembling rules distributed time. thus rnns promising approach automate construction classiﬁers improve accuracy vpd. architecture original recurrent neural network model simplernn contains hidden layer; output signal neuron used input neuron next moment time. case input signal long duration exploding vanishing gradient problem appears training model calculating gradients neural network performance function details. effect stems fact gradients rnn’s performance function depend product gradients neurons hidden layer calculated successive values training signal fig. consequence product take absolute values well tends zero. principles lstm uses economical parametrization fewer operations compute output signal. extensive overviews architectures found selection architecture practice necessary search optimal architecture. section describes results matter. experiments following types lstm simplernn. experiments performed using keras framework wrapper python-libraries theano tensorflow types conduct series experiments play network hyper-parameters activation function types window length since training time several layers rather number hidden layers equal number neurons layer limited eight maximum number learning epochs limited table provide results optimal architecture selection type. selection hyper-parameters even limited space signiﬁcantly improves quality simplernn model ﬁrst experiments presented table according results decide continue architecture containing lstm layers since provides highest performance. since training neural network optimize mean square point-wise error appropriate considered problem section consider various additional approaches improve detection accuracy evaluated value. particular consider following tweaks weighting mean square error used performance function training neural network; smoothing input signal morphological ﬁlter adding penalty derivative neural network output used calculating performance function; optimization threshold value used binarize output signal according target quality criterion training set; applying morphological ﬁlter neural network output signal. turned improvement detection accuracy obtained expanding signiﬁcantly structure lstm neural network. provide modiﬁed architecture input lstm-layer hidden dense layers. however dropout transformation despite fact standard error decreases validation sample target error increases test set. turn dropout transformation dense layer increases time target error decreases also achieve additional signiﬁcant improvement detection accuracy selecting threshold value output signal cross-validation procedure training subsequent application morphological ﬁlter neural network output binarized using selected threshold value. also evaluate importance input signal component estimating inﬂuence accuracy ﬁnal model. table provide values performance criterion models constructed using possible combinations input features. best features pair achieve signiﬁcantly better quality classiﬁcation equal using input features whereas order achieve detection performance equal original classiﬁer takes input additional fourth feature trailer coupler detector without performance drops thus study developed automated approach constructing training classiﬁer superior terms performance previously constructed classiﬁers. stage research possible several directions. first increase classiﬁcation accuracy direct optimization criterion training neural network. implementation learning algorithm possible gradient-free optimization algorithms. ﬁnally implement integrated solution order eliminate initial input data pre-processing provided classical image recognition methods additional steps data processing happen event vehicle shot camera event binarized input signal produced. words propose following neural network structure realizes subsystems single stack convolutional neural networks rnns finally type model structure similar shown fig. used passage detection. acknowledgements work ﬁrst author supported rfbr grants oﬁ_m. work authors conducted iitp supported solely russian science foundation grant khanipov koptelov grigoryev kuznetsova nikolaev. vision-based industrial automatic vehicle classiﬁer seventh international conference machine vision proc. spie vol. yigitbasi gallet kondo iosup epema. analysis modeling time-correlated failures largescale distributed systems seventh international conference machine vision proc. spie vol. grihon burnaev belyaev prikhodko. surrogate modeling stability constraints optimization composite structures surrogate-based modeling optimization. engineering applications. eds. koziel leifsson. springer haykin. neural networks learning machines prentice hall rafal jozefowicz wojciech zaremba ilya sutskever. empirical exploration recurrent network architectures", "year": 2016}