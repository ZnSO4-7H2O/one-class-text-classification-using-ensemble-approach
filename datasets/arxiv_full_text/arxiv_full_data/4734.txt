{"title": "A Base Camp for Scaling AI", "tag": ["cs.AI", "cs.LG"], "abstract": "Modern statistical machine learning (SML) methods share a major limitation with the early approaches to AI: there is no scalable way to adapt them to new domains. Human learning solves this in part by leveraging a rich, shared, updateable world model. Such scalability requires modularity: updating part of the world model should not impact unrelated parts. We have argued that such modularity will require both \"correctability\" (so that errors can be corrected without introducing new errors) and \"interpretability\" (so that we can understand what components need correcting).  To achieve this, one could attempt to adapt state of the art SML systems to be interpretable and correctable; or one could see how far the simplest possible interpretable, correctable learning methods can take us, and try to control the limitations of SML methods by applying them only where needed. Here we focus on the latter approach and we investigate two main ideas: \"Teacher Assisted Learning\", which leverages crowd sourcing to learn language; and \"Factored Dialog Learning\", which factors the process of application development into roles where the language competencies needed are isolated, enabling non-experts to quickly create new applications.  We test these ideas in an \"Automated Personal Assistant\" (APA) setting, with two scenarios: that of detecting user intent from a user-APA dialog; and that of creating a class of event reminder applications, where a non-expert \"teacher\" can then create specific apps. For the intent detection task, we use a dataset of a thousand labeled utterances from user dialogs with Cortana, and we show that our approach matches state of the art SML methods, but in addition provides full transparency: the whole (editable) model can be summarized on one human-readable page. For the reminder app task, we ran small user studies to verify the efficacy of the approach.", "text": "modern statistical machine learning methods share major limitation early approaches scalable adapt domains. human learning solves part leveraging rich shared updateable world model. scalability requires modularity updating part world model impact unrelated parts. argued modularity require correctability interpretability achieve this could attempt adapt state systems interpretable correctable; could simplest possible interpretable correctable learning methods take control limitations methods applying needed. focus latter approach investigate main ideas teacher assisted learning leverages crowd sourcing learn language; factored dialog learning factors process application development roles language competencies needed isolated enabling non-experts quickly create applications. test ideas automated personal assistant setting scenarios detecting user intent user-apa dialog; creating class event reminder applications non-expert teacher create speciﬁc apps. intent detection task dataset thousand labeled utterances user dialogs cortana show approach matches state methods addition provides full transparency whole model summarized human-readable page. reminder task small user studies verify efﬁcacy approach. templates predicates text preprocessing parsed components list template matching process training process editing model testing experiments learning curves data luis learning curve experiments experiments full training luis baseline results results comparison complete intent detection classiﬁer ask-how-to-say dialog structure train-predicate dialog structure overview module speciﬁcation language turn detail turn types case study adapting event reminder module teacher task description teacher task results teacher task summary wake phase error correction dream phase error correction template error correction using unlabeled data template uniﬁcation multiple languages tal’s world model extending large numbers templates predicates extending beneﬁts model transparency machine comprehension language parameter names references special parameter names parameter types conditional operations parameters arithmetic operations parameters prompt paramvalueturn trainpredicateturn testpredicateturn niterations removeparamvalues scriptconditionalactions userconditionalactions paramvalueorconstantturn setconstantvalues enditerationaction endscriptaction noaction finding user wants long difﬁcult childhood nine winters varying degrees commonly identiﬁed technical roadblock seems problem scale terms tasks complexity reliance statistical methods particular statistical machine learning tasks essentially deﬁned labels large datasets models carefully constructed solve tasks. recent impressive successes fact major inroads made ﬁrst three winters listed statistical machine learning methods date share critical limitations comes scalability procedure make machine-learned model maximally leverage another learned different task. different models solve different problems built take advantage other’s world model shared basic concepts like space time number? system take advantage natural language learning another performed achieve desideratum every teacher beneﬁts teacher teaches? world transfer learning variants proposed attack problem. transfer learning takes form models sharing features parameters data close backbone; problem viewed mismatch data distributions one’s model sees rather lack shared fundamental growable world model. scalable world model modularity. argued modularity turn requires correctability system correctable errors corrected generalization performance improved errors introduced. also argued interpretability mean ability designer easily understand system makes assertions does desirable stepping stone towards correctability although perhaps necessary one. vast majority current statistical models complex unseen essentially uncontrollable decision surfaces make full correctability interpretability beyond reach. circumstances simplest option available error correction labeled training data either continue training starting current model re-train. clumsy tool delicate task previously correct predictions become errors training data expensive gather little control whether model actually solves errors question. certainly take nuanced approach balance robustness improved generalization example interesting application ideas ranking. currently tide ﬂowing opposite direction. large neural network models powerful becoming increasingly complex. furthermore worrying deep nets vision tasks generate highest conﬁdence outputs presented inputs human looks like noise almost imperceptible changes added input image previously classiﬁed correctly deep neural causing make error striking departures understand human visual system work would seem another barrier interpretability correctability. machine comprehension text presents particularly stark challenges statistical methods. effective automated open domain dialog system likely require rich world model ability perform commonsense reasoning possible purely statistical methods needed work extending lstm dialog models model individual speakers using cnns rnns dialog topic tracking). performance machines currently lags behind humans comprehending even language familiar typical ﬁrst second grader. dataset multiple choice format presented state results data approximately accuracy compared humans easily achieve. much larger question answering dataset provided paints similar picture scores achieved strong machine learning baseline compared humans. vast majority approaches proposed general algorithmic modeling various aspects human intelligence statistical nature appealing research strategy several well-known reasons. comes building interpretable correctable methods natural question arises methods interpretability correctability built ground resorting statistical machine learning methods? speciﬁcally problems associated controlled carefully compartmentalizing role system? work paper investigates question. adopt machine teaching approach speciﬁcally much progress made interpretable correctable rule-based system taught using crowd-sourcing? goal answer whether system could help address core scalability issues facing today work simply searching hard limitations simplest possible methods into; particular points methods become clearly required points exist. view exercise constructing base camp expedition initial results surprising crowd-sourced rule-based system generalization built using taxonomy perform well state machine learning system correctably interpretably task. bottom-up approach reminiscent early work perhaps closest work particular scenarios encapsulated scripts recent work knowlege graph learned conversational dialogs similar spirit ours there human knowledge leveraged deeply extracting labels editable ontology used representing world knowledge. however focus different investigate construction knowledge base support question answering given background true/false statements world gather user input dialogs structured around multiple choice questions. contrast focus methods achieve scalability general modeling language directly support this general development apps apas rather question answering. base camp built foundations teacher assisted learning factored dialog learning describe. since uses vice versa describe ﬁrst. traditionally developing machine learning models required expertise machine learning programming. however recent research focused help someone domain expert knows little machine learning quickly build machine learned models luis provides user-friendly interfaces available portal allow user perform necessary machine learning steps deﬁning labels adding examples training evaluating models interactive fashion. luis also provides visualizations show prediction performance integrates active learning component allow users label most uncertain utterances. however non-expert’s knowledge intuition problem domain highly valuable resource fully leveraged traditional machine learning techniques beyond asking labels. example predicting speaker intent dialog utterances non-expert easily interpret meaning utterance also explain believe interpretation utterances ambiguous utterances don’t make sense forth. current approaches including machine teaching methods ignore extra rich information. hypothesize learning task beneﬁt teachers experts domain machine learning important steps learning representation learning model generalization. core idea language-based templates predicates teacher tune solve problem hand using examples training resources guidance. construction interpretable correctable. setting address following fundamental questions shares objective traditional machine learning namely maximizing generalization performance. make maximal teacher’s language skills domain expertise achieve this? build interpretability correctability model ground assume teachers usually technical experts design simple natural-language-based dialogs teacher teaching process work language modeling task thus taking step towards addressing scale problem described above? representation interpretable highly modular language-based teacher adjust desired giving much control system detects meaning compared approaches. teaching iterative process where teacher taught pattern labeled data looking false positives negatives guide teacher tune pattern. approach thus leverages deeper language skills mentioned above point teacher reason pattern fails take steps correct work presented focuses ﬁrst three items above. fourth interesting open problem; discussion offered section present details below. case study task detect user intent make purchase demonstrate english speaker using instance integrates wordnet semantic taxonomy train intent prediction model dialog utterances correctably interpretably attain results comparable luis automated personal assistants long history modern apas siri cortana perform various useful tasks conversational dialogs users example detect user wants make phone call address item calendar take appropriate action. however scaling apas large numbers different kinds tasks eventually anticipate user’s needs natural engaging dialog still beyond traditional software development process well suited problem. typically support task designers developers must ﬁrst write review design requirements must make necessary changes implementation ﬁnally system must undergo suite unit system wide tests require beta testing users. dialog apps changes include redesigning turn-taking structure dialog implementing extra needed underlying logic. moreover language skills crucial good user experience intent detection task completion. process thus usually requires developers teach languages agent needs application form continue training understand user says even domain ﬁxed. investigate addressing scalability issue leveraging ideas ﬁrst factoring development entire language learning part problem performed non-experts; second developing shared world model re-used widely different classes applications. goal achieve scalability opening possibility using crowd sourcing application development call approach factored dialog learning uses language learning component also introduces additional roles found traditional development process teacher designer deals different aspect scalability issue. deﬁne teacher person teaches language skills required engage user dialog particular application. deﬁne designer person identiﬁes class tasks want handle designs abstract dialog every application domain within class opposed complex skillset required developer traditional development process here teacher need familiar application want build addition ﬂuent native language. framework requires designer designer must learn simple high level scripting language call module speciﬁcation language designer uses specify teacher create designer’s class applications. although simple scripting language support basic programming concepts loops conditionals. describe detail below. paper order contrast different roles played choose development example fdl’s dependence light implement class event reminder applications demonstrate create reminder scheduling apps tracking consumption medications visits birthdays reminder tasks. factors language development overall development process thus assign language development tasks designer teacher. however course developer still plays crucial role overall process. example event reminder class seven quantities must extract user given user wants create reminder strings numbers explained below point developer must write code appropriate thing user running data received however notice apa’s actions triggered seven quantities independent particular reminder run. thus developer’s role identify classes applications actions taken given class need coded once. figure summarizes development process diagram framework. concept underlying predicate. predicate thought boolean function text function ’state’. state modeled data structure contains slots handler functions. predicate ﬁres slots populated handler functions tell thus example predicate concept collocated might contain slot entities deemed collocated whenever predicate returns true. constraints imposed text particular require presence verb. distinguishes kinds predicates parsed predicates learned predicates. parsed predicates currently form tal’s world model; encapsulate notions time space number currently hardwired. parsed predicates thus easily shared across classes applications. example building event reminder class applications described paper developer create parsed predicates time frequency period duration earlier work predicates associated verbs theories syntax grammar however queries submitted intelligent agents often lack verbs nonetheless convey intent. could used designer creation different class applications. seems reasonable allow world model least level physics mathematics warrants special development effort since physics mathematics form succinct powerful world model. learned predicates hand used model forms meaning language. thus expect learned predicates greatly outnumber parsed predicates grows. learned predicates hard-coded instead learned entirely using human teachers. learned predicates divide problem introduce templates used detect patterns language. learned predicate declared true containing template ﬁres templates also entirely taught language-based leverage semantic taxonomy well teacher input achieve generalization. study wordnet semantic taxonomy teachers also remove items taxonomy needed. thus given template associated learned predicates whenever template matches piece text predicates declared true text. example text jesse sandwich might collocated predicate also consumes predicate. addition given predicate ﬁred several different templates example jesse sandwich sponge absorbed liquid might entity consumes another predicate alternative comes mind learn laws govern physical world labeled examples. core modeling functions don’t know describe closed mathematical form case here. even though templates predicate different. since learned predicates containing templates learned teachers attacks scalability problem leveraging expertise crowd-sourced teachers need experts native language. factoring problem pool available teachers becomes large. contrast fdl’s main task factor language needed application development process designer create script could used hundreds teachers turn create apps support millions users. thus attacks scalability problem factoring language modeling problem available expertise matches subtask well. event reminder class apps described below system relies almost entirely parsed predicates learn extra learned predicate however study learning user intent relies entirely learned predicates. chose examples little overlap predicate types need possible clearly test contrast ideas approach. following succinctness replace phrase correctable interpretable deﬁned above transparent. main design goal teacher assisted learning resulting models fully transparent tal’s behaviour always fully explicitly attributable underlying data rules data rules input teacher. earlier versions system used dependency consituency tree parsing semantic role labeling constructs using splat tool stanford package tools culmination decades development effort seemed wise rather reinvent wheel. using revealed four signiﬁcant drawbacks brittle slow transparent solve harder problem need solve. brittleness lack transparency unavoidable consequences statistical models underlying tools; could investigate building shims around tools correct errors retrain underlying models enough data gathered overhead would high retraining guarantee errors resolved. speed issues harder address would likely proven show stopper shipping time hunch systems also solve harder problem really needed solve indeed turned case. section describe detail current processing uses. template data structure consists ordered list items used pattern matching together pointer predicates. item roughly thought either string synset synsets efﬁciency templates indexed ﬁrst synset occuring list thus rather scanning templates piece text detect patterns templates indexed possible synsets correspoding current token text tested possible matches subsequent tokens. template said match sequence tokens text found matches template’s list order. matching process tokens could nouns verbs adjectives adverbs pronouns negation terms considered. template ﬁres asserts predicates associated template true piece text. mentioned above template/predicate many-to-many given predicate also pointed template. template’s list ﬁxed length different templates different length lists. limit possible length template’s list typically list four elements table histogram lengths list classiﬁer trained paper concretely item template’s list three types string; noun synsets; pair consisting single verb synset together simpliﬁed form verb’s tense. currently supports simple tense types past present future catchall pastorpresentorfuture. element template matches token text following three conditions holds reserve string matching parts speech small number possible instantiations currently allows question adverbs listed table note needed specialized parts speech could also used decided make question adverbs ﬁrst direct match type give rudimentary question detection abilities. processing template matching done text list parsed components. construction described below. note templates currently model nouns verbs question adverbs parsed components addition model adjectives general adverbs prepositions pronouns negation. take part current matching process others included facilitate extension template data structure desired. mentioned introduction distinguished kinds predicates learned predicates teacher constructs interacting natural language only parsed predicates form backbone tal’s world model currently hardwired. learned predicates learned predicate data structure consists predicate’s name names components slot optional notes handlers specifying scripts actions launched predicate ﬁres example predicate modeling entity ingests something might component names ingester ingested. important note mapping text component names straightforward since teacher mapping template trained. thus eaten would different template ﬁred slots time would ﬁlled automatically based mapping speciﬁed teacher train time. important advantage using teachers solve semantic role labeling problem compute mapping. table shows properties learnedpredicate. last item learnedsynsetmap added purely lower cognitive load teacher chances good synset found word used train previous templates given predicate also correct synset word different template trained predicate. description name predicate. mapping matching template relevant item predicate value would retrieved application receives notice predicate ﬁred. additional information predicate. action names script executed implement action predicate ﬁred. section detailed description. learnedsynsetmap mapping word last synset selected word predicate. used eliminate duplicate questions teacher predicate training presents conﬁrmation previous selection teacher override. parsed predicates written built-in parsed predicates support notions time parsed predicate name properties. table gives brief description built-in parsedpredicates currently implemented fdl; table section detailed description script usage. description properties period time number events period starting time ﬁrst occurrence period. duration sequence reminders duration single event date sequence reminders start parsed predicates templates; ﬁred pattern detectors. chose hard-wire several pattern detectors since patterns likely shared across many different applications since quantities represent modeled extremely succinctly mathematical notions time number line. wrote patterns model date time duration frequency. example table shows pattern detectors used detect frequencies english text. pattern detector written active pattern; found language particularly well-suited kind modeling. active pattern’s name encapsulates possible patterns captures facilitate code readability thus example oncepersecond active pattern models text snippets once second twice three times every week. order scans since sophisticated standard processing lemmatization basic part speech tagging describe process full here. first user’s input broken sentences. then terminators removed sentence leading trailing space removed. text lower-cased tokens appear slang replaced apostrophes removed. mappings corresponding tal’s internal model time intervals performed ﬁrst strings matching pattern represent integer mapped then strings matching pattern integer hardwired time intervals expanded form times expect mappings shared across applications tal’s world model hardwired. finally tokens mapped lemmas follows ﬁles lists verbs declinations lists nouns plurals. token appears declination verb declination appear noun list token declared type verb. otherwise gather possible parts speech token. cases tokens replaced lemmas verbs declination mapped past presentorfuture pastpresentorfuture. throughout processing original tokens lemmas kept. construct parsed components list sentence. amounts mapping token compound phrase possible parts speech keeping track negations; handling modal verbs. parts speech track shown table reserve ’unkown’ model tokens whose listed. note code implements processing described section language-speciﬁc currently would rewritten handle languages although amount code small. compound phrases teach phase known compound phrases shown teacher conﬁrmation teacher either conﬁrm declare found compound phrase non-compound teacher given option adding compound phrases missed compound phrases thus formed added taxonomy. test phase currently assumes compound phrases ﬁnds correct negation simply track negation negation tracked part speech immediately following negator. turns every part speech track negated; table gives example each. modal verbs distinguish semi-modal verbs pure modal ones. modal semi standalone verb modal verb have did. modal pure cannot occur standalone verb. list pure modals can; could; may; might; must; shall; should; will; would. include modals like must since although occur sentence always refer action. also cast modals past tense ’present future’ tense update verb’s tense based modal one. finally also distinguish modals possible noun meanings processing modals occurs follows. mentioned negation detected attached following verb tense detected attached following verb. pure modal also noun declared noun preceded determiner possessive pronoun otherwise pure modals kept processing. semi modals modify verb verb’s tense kept modal skipped; kept ’stand alone’ verbs finally parsed components could possibly noun verb pronoun directly matchable token dropped; remaining noun verb meanings mapped sets possible synsets certain pronouns mapped special purpose synsets personal pronouns mapped synset person.n.). done mainly make patterns containing pronouns clearly readable. template matching phrase straightforward. first phrase mapped parsed component list above. template matching done ordered comparison template’s list phrase’s parsed component list. greatly reduce computational overhead templates stored dictionary also ﬁrst synset occurring template’s list. order search match given position text templates whose hypernym equal synset current position parsed component list examined. done constructing hypernyms current token using key. positions template list must match match declared. text’s parsed component list longer template’s list subsequence matches attempted template item ﬁxed token token must match exactly. template item verb synset together tense synsets corresponding position text must contain least synset hyponym tenses must match. finally template item noun synsets match occur least member must hypernym synsets synsets corresponding position text. allowance also made skippable items parsed components whose contains example token’s parsed component contains adjective noun token skipped search match next noun examined match. likes blue cheese token blue taken alone could noun adjective matching process attempt make part match skip match fails. train phase conﬁrmed teacher teacher asked identify single best matching synset noun verb thus identiﬁed. described above lighten cognitive load teacher guesses correct synset conﬁrm teacher based previous teacher inputs. also mentioned teacher conﬁrms compound phrases found asked identify compound phrases missed; phrases added taxonomy teacher’s guidance. training done either batch mode free form mode asks wish train example. positive examples training complete. asks enter phrase inspired input text captures predicate trained. allows teacher zero part text predicate enter related text also predicate desired. runs template negatively labeled training samples. results false positives shows teacher asks still want keep template. loop continues above; else continues also gives teacher opportunity move next training sample found last step editing templates simple useful exercise note done transparent system. also allowed teacher edit templates described next section. thus teaching process result synsets added deleted from taxonomy. examples given section below. training tal’s transparency allows manually edit model. process efﬁcient especially number templates small compared adding labeled data retraining model. followed following procedure extended template’s sets noun synsets based noun synsets occuring templates. thus example template allowed get.v. followed currency.n. another allowed verb synset missing following currency.n. added over-generalization checked. example intent model trained below noticed teaching process suggested get.v. general version buy.v.. found replacing latter former indeed improve performance training templates others many false positives generated. test phase simpler involves teacher interaction. text normalized compound phrases identiﬁed using wordnet templates matched text using template matching logic described section template ﬁres asserts associated predicates true. experiments described below predicate; test example declared positive predicate true example. generated training test data cortana logs follows searched user inputs containing strings shown table note lack space tokens purchas acquir resulting matches user inputs containing strings stems. addition adder ﬁlters restrict user inputs either speech texts; inputs issued windows devices inputs issued cortana running queries days logs resulted records. uniquing data resulted records. also took recent queries logs unbiased background data. shufﬂed records took ﬁrst labeled resulting combined sentences indicating user’s intent not. remaining records kept luis active learning experiments. sample sets small split individual dataset create train test sets. resulted totals shown table mentioned above used luis system state machine learning baseline. luis uses logistic regression model words features number tokens inputs. luis also gives ability domain-speciﬁc dictionaries; experimented improved performance task. internally luis performs fold cross validation choose optimal model parameters trains training data using found parameter values. since constructing learning curves required training models luis order make comparisons feasible fair possible experiments used systems maximally automated mode. luis simply meant active learning used used simpliﬁed version full system user allowed delete items ontology; given option editing learned templates; templates used simpliﬁed version synset constrained singleton. full training resulted total templates figure shows training curves accuracy precision recall sample test function training size. luis experiments training sizes increased luis supports active learning ’suggest’ option. user upload unlabeled samples enter suggest mode. luis present unlabeled samples decides beneﬁt model verify along current prediction them. user changes prediction necessary accepts current label. samples labeled luis retrains model presents next unlabeled samples. training luis initially full -sample test full test performed active learning using unlabled samples. three runs active learning creating newly labeled samples test again. table shows results along tal’s scores test set. note luis team made signiﬁcant improvements intent prediction classiﬁer performand learning-curve experiments above. resulted pre-al baseline signiﬁcantly higher recall somewhat less precision before. adding active learning luis increased precision change recall. training ﬁrst sentences manual editing process described resulted reducing number templates seven. template collapse pattern repeated training data arrived templates. templates found fully trained user intent model shown below table addition since model fully transparent could also check user-entered data shown also noticed templates could easily reduced verb synsets combined sets possible. section table details. compared luis active learning signiﬁcantly higher precision lower recall marginal increase overall accuracy. natural next step would tune luis precision measure recall compare again. however results alone demonstrate comparable performance achieved fully transparant succinct editable model. advantages believe could take advantage training data increase accuracy arbitrarily present entire classiﬁer learned detect intent buy. first teacher removed single synset wordnet taxonomy. uses yaml track removals case contains single mapping get.v. meaning verb synset listed token removed graph. done remove loop wordnet causes generalize incorrectly. table shows teacher-taught extensions wordnet tokens left mappings right. table distinguishes concepts instances mappings denoted string instanceof concepts. table shows noun referred many templates referred finally table shows templates used. there example cost.v. denotes ﬁrst verb synset listed wordnet token cost; shorthand past present future tense present future tense. recall pronoun mapped special synset tal_narrator_i.n. mapped special synset tal_audience_you.n. finally sets noun synsets denoted curly braces. templates intent predicate therefore shown. striking fact entire classiﬁer written complete transparency page. table templates used classiﬁer. left right forms single template. note quite general; speciﬁc training data language teaching stage teacher teaches system language need converse user throughout rest section event reminders example class applications. ask-how-to-say dialog system teacher intended develop system’s language generation skills. system asks teacher explicitly something pertaining given general scenario uses teacher’s response later interacting user. however system limited simply parroting teacher’s phrases. example event reminders class system extracts verb phrase teacher throughout dialog user verb phrase would used system multiple different interactions user. another designer reduce cognitive load teacher making judicious defaults. continuing meds tracking example might like this dialog would trigger event user’s calendar labeled take aspirin. module speciﬁcation language described below make connection pointing yaml actually appears follows confirm user provide name reminder saying loopback okentersentence param ask_event_name type string default would like name particular reminder? system asks teacher whether default language acceptable asks sentence would like instead. sentence stored system variable <ask_event_name>. note system also variables parsed predicates patterns coded developer parse text extract quantities. make concrete brieﬂy describe structures built-in parsed predicates. example tal’s code contains frequency module collects several active patterns; called oncepersecond models frequencies written form once second twice times hour etc. call collections active patterns designed detect particular pattern language microgrammars. time microgrammars scanned across text particular order thus important keep active patterns independent contains another call speciﬁc version ﬁrst. example current code active pattern hourly matches hourly daily annually etc. called active pattern oncehourly detects once hourly twice daily etc. however dependencies rare active patterns similar still independent. example active pattern everysecond matches every morning etc. similar speciﬁc pattern everyntomseconds matches every seconds every minutes etc. patterns independent used scan either order. parsed predicates scan microgrammar active patterns text slots. example built-in parsed predicate frequency slots period numberofeventsperperiod thus tal’s built-in parsed predicates form rudimentary world model. hard-wiring raises concern would limit scalability. however concepts modeled fundamental shared across apps argue makes sense allow limited hardwiring take advantage extreme succinctness basic physical models touch issue section factored dialog learning centered around factoring language problem using built-in parsed predicates still need teacher assisted learning learn predicates needs covered built-ins. running example events reminders place learned predicates used detect user wants run. general apps need learned predicates minimized dependence learned predicates simplify exploration fdl. here learn user wants app. important practice reasons primary interface expected speech only; number apps likely become large listing practical example module speciﬁcation event reminder class apps designer introduce train predicate dialog user wants type phrase describes want apps match intent. need teach recognize user wants entering example phrases user might type this; example \"feed ﬁsh\" create ﬁsh-feeding reminder. sentence retrieve display existing templates match sentence verb positions. allow merge synsets template existing template remove synsets existing templates remove existing templates. note advantageous teacher zero phrases since detected longer sentences also contain irrelevant details. process described section teacher specify meaning noun verb according ontology example system generalize medication drug teacher chooses system recognize user input speciﬁed detail appendix speciﬁcation module speciﬁcation language. here give overview main ideas behind msl. order extend support application domain designer must create module speciﬁcation script supports class applications. module speciﬁcation script consists four sections blocks listed below. describe notion turn detail below high level series system-user interactions together acquire single piece information user deliver single piece information user. teach block teach blocks consist series kinds turn predicate detecting turns parameter value turns. high level teach block turn-taking structure designer designs series questions intended leverage teacher’s language skills teach application language comprehension generation skills used user mode. block turn-taking structure obtains parses free user input order create actual entity. events reminder example predicate detecting turn used parse free user input describing reminders series parameter value turns conﬁrms values found user missing values turn atomic building block module speciﬁcation. depending type information gathered delivered four core turn types used prompt paramvalueturn trainpredicateturn testpredicateturn. paramvalueturn system teacher/user question obtain answer and/or conﬁrm teacher/user value correct. parameter value thus obtained referenced subsequent turns figure shows example asks conﬁrms start date reminder app. trainpredicateturn used train templates needed form learned predicate detector teacher supplies example phrases train desired predicate. teacher types example phrase predicate system engages dialog teacher select correct parse synsets generalizations identiﬁed terms compound terms. system uses information create template associates predicate. testpredicateturn system displays question prompt user provide needed information example medications tracker event reminder class user might prompted input prescription. system parses user’s input detect matches parsed learned predicates. components matching predicates mapped parameters deﬁned predicateparammappings ﬁeld referenced subsequent turns. values present used populate conﬁrmation question missing values require user enter value conﬁrming addition four core turn types provides composite turn types deﬁne iteration conditional execution auxiliary turn types support these turn types explicitly control parameter values. brieﬂy describe here; appendix speciﬁcation module speciﬁcation language complete details. scriptconditionalactions equivalent if-else-then dialog based boolean value condition written simple conditional grammar allows testing whether script parameter inﬁnite value comparing numeric values parentheses precedence. userconditionalactions like scriptconditionalactions condition boolean result question presented user. example reminder application necessary slots ﬁlled user presented single sentence conﬁrm; returned script presents series paramvalueturns. paramvalueorconstantturn like paramvalueturn allows teacher enter constant value appropriate creating. example teacher creating birthday reminder would want user often reminder ﬁre. evaluate generalizability framework performed small user study determine whether ordinary english speakers easily effectively function teachers creating reminder applications based event reminder application class teacher participant participant operated users testing whether applications could used easily intuitively create reminders domains. using event reminder module assigned participants create reminder applications yearly reminder regular reminder provided informational document described role teacher general form prompts would receive answers supply. information contained prompts themselves many showed examples taken prototype medication tracker application. subject linguistic background created birthday reminder application early version system; feedback session incorporated version. second version subject re-did birthday reminder application created reminder application. subject linguistic background reminder application ﬁrst birthday reminder application. neither subject programming application-development experience. subject software developer signiﬁcant linguistic background used third version modiﬁed based upon feedback subjects creating ﬁrst regular call friend’ reminder application wedding anniversary reminder application. additionally subject medication tracker’ examples prompts largely replaced feed imaginary application additional features added system observed teachers performed tasks asked provide feedback complete. particular asked whether felt system expressive enough create desired application whether task harder easier expected whether parts task particularly difﬁcult confusing easy. distinction teacher creating application user application create actual instances focus fdl. subject initial system incorrectly started user perspective example using actual reminder description instead reminder creation action application activity documentation prompts modiﬁed clarify distinction issue subject subsequent pass. subject still exhibited confusion this although much less subject initially. subject minor confusion this. detailed tutorial combined experience using sufﬁcient clarify important distinction. subject provided additional valuable feedback streamline clarify system ﬁrst iterations particular generalizing medication reminder examples different reminder topic clarifying multiple reminders detected clarifying response \"yes/no\" sentence phrase improving speciﬁc generalized synset selection merging omitting steps. iteration user feedback system revisions ﬁrst-use experience subjects much straightforward. building upon feedback subjects additional features added address speciﬁc pain-points improved ﬁrst-use experience subject subjects found reminder much easier understand create following reasons reminder shares schedule structure example medication reminder; reminder like medication reminder refers speciﬁc concrete event; birthday reminder ambiguous sending email card buying gift planning attending party taking trip visit simply indeﬁnite reminder \"remember birthday.\" questions applicable value reminder domain \"how often want reminder sent?\" birthday reminder. subjects suggested allow teacher constant value \"annually\" present question user. system allows teacher provide multiple example sentences learned predicate. subjects required teacher explicitly create predicate application create different meaning changed. neither subject understood clearly prompts. subject lacking linguistic background found concept predicates confusing explanation provided also initially realize example sentences supplied user would enter them. additionally subject felt instructions unnecessarily restrictive. feedback make following changes subject session ability specify constant values added. subject happily used specify application deﬁne single function small closely related functions creation selection learned predicates removed favor single predicate application reducing complexity teacher. additional explanation added prompts. example address subject feeling requiring verb start phrase referring application restrictive additional text added explain used subsequent prompts. changes resulted much less confusion streamlined experience subject however subject still puzzled couple areas knowing deﬁnition compound seeing name script variable. subsequently modiﬁed clarity. subject also mentioned prompts long enough difﬁcult read. moving much material prompts tutorial includes detailed walk-through teaching application parallel demonstration application action phase would improve ﬁrst-use reducing clutter subsequent uses teacher. subjects felt turn-by-turn dialog helpful building much comfortable process conclusion tasks. however teacher rather command-line interface would reduce clutter could support undo functionality would reduce need multiple conﬁrmations. initial mistakes subjects system’s evolution much better experience testing proceeded. subjects became comfortable developed experience using system. better tutorial providing detailed walk-through teacher phases reduces screen clutter supports undo believe teachers solid english skills programming application-development experience able quickly learn system create applications especially linguistic background. subject went ﬁrst created reminders prescriptions. operated twice previously teacher subject familiar goals process. confusion asked specify single value range dialog clear context clear error message retried out-of-range values. also missing recognitions abbreviations intervals. encountered understood process proceeded quickly last reminders completed easily. subject used system subject feedback incorporated. subject entered single prescription found process quite straightforward; negative feedback number conﬁrmations slowed process down. subjects felt turn-taking process made easy provide necessary information create reminder. subjects felt conﬁrmations could streamlined make process smoothly. section look back assess things went; next look ahead possibe routes upward newly established base camp developing fully transparent scalable approaches main result that tools we’ve developed it’s straightforward build user-intent detector fully transparent editable succinct performs well state machine learning approach. furthermore tools rely sophisticated methods semantic role labeling consituency dependency parsing; employ statistical methods yet. thus results transparent tools used achieve them. finally ideas apply equally well detecting meanings text. however found initial hope teacher would need clear understanding wish build native language partially fulﬁlled; it’s certainly possible restrict teacher’s role found allowing edit text ﬁles contain templates extensions deletions taxonomy useful. requires extra level training teachers. hope designers feeding hundreds teachers support millions users comes pass perhaps it’s much little teacher role. serious issue made little headway towards every teacher beneﬁts teacher teaches north star. built-in parsed predicates shared certainly teachers reuse predicate detectors others built. true reusability likely employ hierarchical structures predicates. discuss ideas next section. earlier version used gazetteers identify cities retailers. found need gazeteers least intent detection task. later versions need them. however compound phrase handling need improved. found allowing paths introduced training errors treating possibly compound phrases deﬁnitely compound. seems solve robustly need context; phrase could compound noun check noun phrase possible part speech given surrounding tokens; similarly verbs; employ ’try paths’ trick compoundness truly ambiguous. note still require full parse text. finally ideas outlined paper need checked tasks datasets. hope beneﬁts resulting fully transparent approach warrant explorations. discussion section helpful name phases learning wake phase learns directly human dream phase human involved. dream phase example could learn either leveraging large unlabeled datasets directly making sense already learned. describe ideas error correction using large unlabeled datasets below also teacher conﬁrmation consequences choices thay anticipated. teacher arrived template using labeled data could real time large unlabeled dataset show resulting matches teacher allow modify template accordingly. false positives thus easy control. false negatives pose harder challenge. these perhaps simplest approach would unlabeled data statistical system luis teacher manually inspect samples systems disagree update templates needed. suppose teacher taught overly general template intended predicate person ingests food. suppose template illustrated table synsets template ﬁrst column corresponding roles deﬁned teacher right column. template overgeneralizes because example phrase building eats person. leverage large ofﬂine unlabeled dataset check template overgeneralize follows. first template dataset making record matches. match increment counter node wordnet-based taxonomy counter labeled component name corresponding predicate taxonomy hypernym tree thus represented heat map. template general heat contain cold spots close leaves. computation gives distribution nodes subtree taxonomy predicate component root subtree component’s synset. extend reasoning handle templates sets synsets clarity consider components correspond single synset template tested. concreteness consider ﬁrst component call tree subtree nodes sufﬁciently cold could subtree maximizes number nodes minimizes number cold nodes. necessary could split original template more nodes nodes covered process necessarily statistical since rare phrases occur interesting line future work take brakes process simply given large unlabeled text dataset choose templates amount matching text maximized amount text pairs templates match minimized? presumably template could chosen cover most data. templates compete explain data. might approach fully ofﬂine learning templates. using taxonomy large unlabeled datasets way? could predicates arise naturally resulting templates? could templates help inform build suitable hierarchy predicates? similarly large unlabeled dataset used identify templates essentially same even sets synsets differ similarity heat maps. first templates candidates uniﬁcation could found automatically comparing pairs heat maps. templates might uniﬁed template could found maximally agrees combined heat maps individual templates. process like likely needed identify similar templates proposed different teachers automated checking process used training fails. similar ideas applied identify predicate trained likely already learned. note ideas already instantiated extent phrase input teacher tested existing predicates teacher alerted match; similarly currently allows uniﬁcation parts templates templates share verb synset. tal’s language dependence currently resides wordnet taxonomy; microgrammars instantiates built-in parsed predicates; english lists parts speech occur small numbers tokens function maps text lemmas tense using slang map; function maps annotated lemmas ’parsed components list’; supporting ﬁles verb declinations nouns plurals. clearly adherence transparency comes development cost comes adding languages. wordnet supported languages english certainly envision using other similar taxonomies. extending templates predicates language another requires mapping synsets available since different languages express concept different ways. even possible machine translation systems accomplish automatically. large database paired phrases languages templates language could learned automatically predicates’ component names could translated similarly. idea combined given mapping synsets language other could also used learn mapping predicate components corresponding template components language. think built-in parsed predicates e.g. detecting properties time space number forming basis tal’s world model. currently structure containing predicates it’s clear hiearchy needed velocity needs concepts space time acceleration needs velocity time etc. seems likely hierarchy would also required make learned predicates scalable. entity other entities must colocated. people married must know other must made joint commitment etc. encode logical relationships directed graph whose nodes negatable predicates predicate set). node true children true logical connectives form functionally complete however convenient explicitly model connective instead directed bigraph nodes either predicates connectives every node attached boolean variable. example several predicate nodes connected node latter true predicates true. graph implementing logical inference hierarchy would also help interpretability overall model. apply similar ideas above detect logical relations predicates automatically. thus templates predicates large dataset predicate always found true whenever predicate holds relation could added graph. likely however probabilistic modeling logic markov logic networks would required. scalability parsed predicate must added deﬁned terms existing parsed predicates ideally would already uses simple mechanism limit search roughly speaking templates indexed token currently examined tested match following tokens. search limited partitioning templates using context. example awaiting user input determine knows it’s particular state safely templates would overgeneralize situations example template containing single verb exercise used select reminder used elsewhere. generally represent inner state using ﬁnite state automaton subsets templates available state. could extended interactions user could model user’s state using markov chain state links limited templates templates corresponding states whose probabiliy exceeds threshold would tested matches. currently deﬁne number turn types intended generic ﬂexible enough accommodate necessary question-answering control-ﬂow operations needed designer. supporting domain-speciﬁc turn types would require plug-in model understand actions take questions. consider supporting module reuse form module inheritance allowing module extend base module. base module might include required metadata-collecting operations initialize block derived modules need repeat them. similar superclass constructor execution constructing subclass instances object-oriented programming. similarly might extend script blocks allow base module deﬁne turns could called derived module. suppose several statistical models trained task. best combine them? model averaging often works well. that’s hack requires running models. fully transparent model models directly combined resulting model beneﬁts trained models compact efﬁcient using models independently. another transparency contribute scalability. multiple teachers thing data training predicate results combined. able handle inputs many teachers requirement scalability. machine comprehends passage text every assertion made text identiﬁed majority native speakers machine asserts corresponding predicate true assert predicates true. note ’false negatives’ easy detect automatically predicate ﬁres passage know passage meaning detected machine necessarily comprehend text. deﬁnition gives measure well system comprehends dataset text samples. could ﬁrst crowd source labeling asking workers write assertions made sample text determine overlap human generated predicates predicates declared true system text. errors introduced labeling could controlled using multiple workers sample asking workers verify outlier claims. might test system’s world model distinguishing predicates follow directly text implied indirectly measurement strategy would course work system makes assertions predicates giant black-box neural nets included. however argued above believe fully transparent interpretable correctable predicate-based approach presented paper least provides good starting point base camp investigations scaling thank jason williams paul bennett richard hughes many valuable discussions support work. also thank vishal thakkar stargate support team hisami suzuki help guidance generating cortana dataset. work culmination several years explorations. thank erin renshaw steadfast help earlier work. thank john platt vision supporting big-bet long-term research freed fail. additionally thank eric horvitz jeannette wing harry shum leadership vision supporting long term research general work particular. yaml serialized data representation format edited easily humans parsed program. module speciﬁcation language uses yaml representation medium. section discuss elements yaml used example medication reminder module script. scalar basic data type represent single value e.g. number string. type inference automatically done time yaml; table contains examples. mapping sequence basic ways composite scalars. mapping similar dictionary data structures programming languages; values referenced unique keys key/value pairs unordered. value separated colon space example mapping. yaml indentation really matters; entries mapping must indentation. sequence similar list data structure programming languages means values ordered referenced index entry begins hyphen space. example again note hyphens indented level hyphen start instance structure. default yaml concatenates lines together single value. special sequence starting preserve linebreaks whitespace; ‘|-’ suppresses ﬁnal linebreak. module speciﬁcation script partitions speciﬁcation four sections blocks listed below. describe notion turn detail below high level series system-user interactions together acquire single piece information user deliver single piece information user. initialize block app-independent constants used streamline interactions teacher example event reminders module deﬁnes okentersentence string constant value please enter sentence would like here. it’s used times teach block. initialize block also used teacher questions needed acquire metadata application; data saved using reserved keys. structure designer designs series questions intended leverage teacher’s language skills teach application language comprehension generation skills used user mode. turn types also embedded conditional blocks. events reminder example predicate turn used elicit teacher sentences exemplify language user likely input order identify application pool apps available user; lets know user wants run. parameter value turns teacher speciﬁes example language used elicit name series reminders user creating. designer also elicit teacher language likely repeated example designer might want extract general verb phrase teacher refer type reminders created verb phrase referred throughout remainder script block contains sub-blocks named action performed instance. event reminder module action deﬁned create creating reminder. could extended with example edit reads existing reminder allows user edit sub-block turn-taking structure obtains parses free user input order execute action entity; create action create entity. events reminder example testpredicateturn parses free user input describing reminders obtains parsed predicates series parameter value turns conﬁrms values found asks user missing values thus individual reminder ideally single predicate detecting turn receives sentence user contains information needed create reminder system conﬁrms information single turn. user chooses change information necessary information missing parameter value turns gather needed data. parameter named using underscore period case sensitive. special name formats underscore reserved speciﬁc purpose; section following discussion subsections occasionally example parameter named par. parameter value referenced subsequent turns using syntax {par}. process converting name representation value referred expansion. depending context parameter reference parameter value converted various types parameter names built parameters composite name. example {frequency.{i}.period} ﬁrst obtains value example forms name {frequency..period} looked directly. bracketing required expansion done otherwise present. particular parameter’s name used rather value expansion done entire name done embedded names parameter composite. discussed detail below. suggest reserving names begin underscore parameters special meaning. particular names using uppercase letters underscores beginning indicate external values state script parameters special meaning value application look for. example section section describes special parameters used application user wants run. table shows current special names fdl. meaning name application. another application look this. indicates script edited rather newly created script. means parameter values already present script designer present relevant dialog. __action_description__ base name collection parameters type string action block used give user friendly description action does. example __action_description__.create provides description create action block create reminder gym. __action_confirmation__ base name collection parameters type string action block used user question conﬁrm script action really user intends exam__action_confirmation__.create provides conﬁrmation question create action block want create reminder gym?. indicates parameter intended hold value internal setparamvalues turn reducing duplicate strings rather obtained user. description user’s answer saved without language understanding information extraction. extracts number expression user’s input saves ﬂoat value. supports digit expressions english format english cardinals integers only. user’s input starts don’t know\" \"forever infinity value assigned. numbers compared numbers infinity; section numbervaluerange number range \"-\". created user entering string testpredicateturn; script turns require single value. extracts date user’s input. supports .net datetime.parse compatible strings special days days week next week \"next tuesday\". extracts time user’s input. supports .net datetime.parse compatible strings time expressed using english words offset hours \"pm\" \"p.m.\" \"evening\" \"afternoon\" present. extracts time interval user’s input. supported units include \"second\" \"minute\" \"hour\" \"day\" \"week\" \"month\" \"year\" value either digits english words also support \"half\" interval expressions stored .net timespan object. number \"months\" \"years\" converted \"days\" depending current month year i.e. \"one month\" converted days\" days\". also supports don’t know\" \"forever\" answer user case timespan.maxvalue used. intervals compared infinity; section intervalvaluerange interval range hours\". created user entering string testpredicateturn; script turns require single value. expect user answer either \"yes\" \"no\" could parameter type. list valid answer strings could specify parameter type ‘nominal‘ list valid strings answer. supports conditional comparisons provide if-then-else logic selecting turns execute. table lists conditional operations currently supported fdl; ones useful developing medication reminder module added future. comparisons done scriptconditionalactions turn. supported number number interval boolean result indicating whether named parameter’s value inﬁnity. parameter exception thrown; check ﬁrst. boolean result indicating whether named parameter assigned value. parameter removed removeparametervalues turn set. boolean result indicating whether named parameter number. boolean result indicating whether named parameter interval. present expression separated operator. currently support binary operators ‘date‘ ‘interval‘ parameter ‘number‘ parameter ﬂoat value. illustrated table example assuming date parameter date value july interval parameter interval value days {date+interval} results date value july assuming number parameter value {i-} results float value handler combines script name action name means system determines scripts apply user’s intended action. discussion example handlers used section table describes handler properties. turn context series interactions together acquire single piece information user deliver single piece information user. atomic building block interactive application. presents question teacher user obtains result value. numerous possible interaction ﬂows depending upon presence absence referenced parameter properties. provides description shown execution step name parameter asked conﬁrmed. type tion default value assign parameter set. question teacher user request parameter value. conﬁrmation message parameter set. user conﬁrm asked prompt used repeat request parameter value. present question property used. value entered user cannot parsed value type custom message display; present general message shown. simplest paramvalueturn consists param type question properties system asks user question deﬁned question property converts answer type speciﬁed type property assigns result parameter named param property. example teacher user without asking initial question. case paramvalueturn would default confirm loopback properties. system ﬁrst assigns value default property parameter named param property conﬁrms user using question confirm property. user says \"no\" confirm question loopback question asked user asked confirm again. usually param referenced confirm. example default days loopback please tell duration you’d like reminders set? confirm would like take medication {duration}. correct? param duration type interval single paramvalueturn contain question confirm. case system ﬁrst asks user question saves value param confirming user. user denies conﬁrmation user asked loopback question exists; otherwise question asked again. either confirm asked process continues. specify particular type system couldn’t recognize instance type user’s input could also deﬁne mistypefollowup property give user hints expect user input. example question going start taking medication? confirm would like start {start_date}. correct? mistypefollowup date that? could enter \"today\" \"tomorrow\" specific date \"july param start_date type date another important feature paramvalueturn param initialized previous turns current turn skipped unless existing value type doesn’t match required param type case system forces type mapping user’s help. example deﬁne parameter duration type interval expected value type intervalvalue; value parameter value type intervalvaluerange system asks user select intervalvalue intervalvaluerange assigns updated value parameter duration. similar dialog occurs number parameter value numbervaluerange. summarize value assigned parameter following order trainpredicateturn leverages teacher’s language skills train templates needed form learnedpredicate detector. system enters trainpredicateturn asks teacher type example phrase learnedpredicate associated application created. system engages dialog teacher select correct parse synsets generalizations identiﬁed terms compound terms creates template associates predicate template. process supplying example sentences continues teacher phrases wish use; example every phrase teacher enters matched existing template. trainpredicateturn following properties names learnedpredicate associated application. predicatename property usually named application currently support learnedpredicate fdl. additional free-form information associated learnedpredicate. structure containing mapping action names names scripts implement actions. section action performed predicate ﬁres. name script execute actionname predicate ﬁres. testpredicateturn used user mode determine predicates match input user. system displays question prompt user provide needed information example medications tracker event reminder class user might prompted input prescription. system parses user’s input detect matches parsed learned predicates. components matching predicates mapped parameters deﬁned predicateparammappings ﬁeld. example built-in parsed predicates currently identify frequency time event duration start date duration reminder sequence predicates user’s input slots assigned corresponding script parameters referenced subsequent turns; script populate conﬁrmation question without requiring user ﬁrst enter value must done slot ﬁlled. testpredicateturn following properties prompts user enter sentence describing event. name parameter store answer question. name parameter store number phrases entered user structure containing names parsed predicates applicable application each name parameter store value parsed predicate. examples below. name parameter receive number parsed predicates found. example user input sentence response question. first system splits sentence phrases splitting \"then keyword; extended keywords syntactic structures. number clauses found stored parameter named countparam property. system parses clause extract parsed predicates system creates parameters clause regardless whether phrase contained parsed predicate not. clause numbered value countparam parameter system creates parameter parsed predicate ordinal clause appended parameter name speciﬁed testpredicateturn. example user’s sentence contained clauses system would create following parameters frequency. frequency. frequency. similar parameters parsed predicates found clause. parameters used subsequent niterations turn engage dialog user clause. currently supports built-in parsed predicate types table description frequency \"every day\" \"daily\" \"twice day\" times day\" etc. single value intervalvalue created; otherwise intervalvaluerange created user prompted select single value range. pred_freq following three properties. period quency e.g. daily. would two. starting time period; \"daily might duration entire sequence; event reminder long reminder remain calendar. duration single event; event reminder might long single appointment would take. e.g. event reminder date ﬁrst reminder. table built-in parsed predicates; name column shows quotes name parameter given predicate value medication reminder example propertyname column shows names system assigns properties. testpredicateturn complete subsequent series turns usually within niterations turn presents conﬁrmation parsed predicate detected clause well asking user’s sentence fully speciﬁes necessary information single conﬁrmation sentence presented; case would necessary conﬁrm individual value user rejects initial conﬁrmation. present iteration number user-friendly system provides special parameter {ordinal} maps itervar value corresponding ordinal word example iteration {ordinal} value \"ﬁrst\". niterations loops nested; turns list contain inner niterations turn. case {ordinal} special parameter scoped inner iteration’s itervar. often possible parameter reference previously assigned numbervalue. example prevous example deﬁne parameter count number clauses sentence; iterate clauses parameter would {count}. example niterations step allows date-sequencing logic. ﬁrst iteration frequency start_date user. subsequent iterations start_date date previous iteration tracked script parameter using setparamvalues turn. example setparamvalues turn allows designer parameter values directly script. setparamvalues turn list structures specify parameters set; following properties scriptconditionalactions equivalent if-else-then dialog based boolean value condition written simple conditional grammar allows testing whether script parameter inﬁnite value comparing numeric values parentheses precedence. scriptconditionalactions turn list following property userconditionalactions turn allows designer remove parameter values directly script. userconditionalactions turn similar scriptconditionalactions condition boolean result question presented user. example reminder application necessary slots ﬁlled user presented single sentence conﬁrm; returned script presents series paramvalueturns. paramvalueorconstantturn similar paramvalueturn also allows teacher enter constant value appropriate creating. example teacher creating birthday reminder would want user often reminder ﬁre. system teacher select three options provides description shown execution step text shown ﬁrst option above; presents question user would asked. text shown second option above allowing teacher specify different question. text shown third option above allowing teacher specify constant value. sentence system teacher enter question user. sentence system teacher conﬁrm question user. name parameter store question user. default question user. sentence system teacher enter constant value. sentence system teacher conﬁrm constant value. name parameter store constant value. type parameter section description user long keep reminder calendar. askquestionconfirm user \"{ask_sequence_duration_language}\". askdifferentquestion user different question. askspecifyconstant user; instead specify constant value. questionloopback please enter question user. questionconfirm want user \"{ask_sequence_duration_language}\". questionparam ask_sequence_duration_language questiondefault please tell long keep reminder calendar. constantloopback please enter constant value would like here. constantconfirm would like stop reminders constant period setconstantvalues turn sets script variables constant values already setconstantvalues turn list structures specify parameters set; following properties user wants perform action system sentence describes action parse action matching learnedpredicates handler action. following steps taken system user wants perform create action; example using medication reminder create reminder take medication. system asks user enter sentence describing activity create reminder for. parses sentence determines templates match forms learnedpredicates ﬁred templates entry handlers actionname create. matching learnedpredicate system presents list available apps learnedpredicates handler create actionname. apps identiﬁed scripts’ __action_description__s. user asked select app. matching learnedpredicate matching learnedpredicates handler create actionname system presents list matching apps identiﬁed scripts’ __action_description__s. user asked select app. user selects system asks user conﬁrm action presenting app’s __action_confirmation__ question. user says system loads script begins app’s dialog user.", "year": 2016}