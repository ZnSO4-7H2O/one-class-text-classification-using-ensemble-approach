{"title": "Generalized Convolutional Neural Networks for Point Cloud Data", "tag": ["cs.CV", "stat.ML"], "abstract": "The introduction of cheap RGB-D cameras, stereo cameras, and LIDAR devices has given the computer vision community 3D information that conventional RGB cameras cannot provide. This data is often stored as a point cloud. In this paper, we present a novel method to apply the concept of convolutional neural networks to this type of data. By creating a mapping of nearest neighbors in a dataset, and individually applying weights to spatial relationships between points, we achieve an architecture that works directly with point clouds, but closely resembles a convolutional neural net in both design and behavior. Such a method bypasses the need for extensive feature engineering, while proving to be computationally efficient and requiring few parameters.", "text": "abstract—the introduction cheap rgb-d cameras stereo cameras lidar devices given computer vision community information conventional cameras cannot provide. data often stored point cloud. paper present novel method apply concept convolutional neural networks type data. creating mapping nearest neighbors dataset individually applying weights spatial relationships points achieve architecture works directly point clouds closely resembles convolutional neural design behavior. method bypasses need extensive feature engineering proving computationally efﬁcient requiring parameters. recent work demonstrated strong results without requiring conversion deal data natively. pointnets calculate features individual points kdnetworks split point clouds kd-trees layer working features nodes method falls category however still based concept convolution. introduction past half decade sensors capable precisely measuring distances dropped price dramatically. rgb-d cameras microsoft kinect able assign distances individual pixels lidar scanners effective affordable. combination advances hardware research slam allowed robots self driving cars stitch together individual images maps environment. whereas image based object detection segmentation seen plenty advancement processing point cloud data still slightly lagging. attributed partly ubiquity images relative scarcity point cloud data also partly convenient nature images spatial relationships pixels encoded structure image indices pixels matrix. cnns exploit efﬁciently individual pixels matched individual weights resulting computationally cheap operation. point cloud however individual points exist location array spatial information encoded explicitly alongside information. generated rgb-d camera would consist points would structured such related work current leading solutions generally involve different classes involve converting point cloud format convenient conventional cnns. involves converting point cloud three dimensional grid value grid represents presence number points volume applying -dimensional convolution works reasonably well downside densifying sparse data. addition size input grows cube granularity required network. dominant design project model multiple views object ensembles former architecture architecture presented consumes point clouds natively also produces point clouds format making useful exact ways circumstances conventional cnns. layer also closely mirrors conventional layers involves shared ﬁlter applied locally. ﬁlters visualized bear resemblance ﬁlters learned cnns ﬁrst layer commonly performing tasks edge detection. sake illustration demonstrate network generalized convolution fully connected layer simpliﬁed dimensional problem example. given task classifying point clouds squares circles. problem trivial gives understanding behavior architecture. present results modelnet dataset later line compute indices nearest neighbors point. next line calculate spatial relationships query point neighbors. currently extract differences scenarios values. also euclidean distance already calculated nearest neighbor calculation. network learns complex features own. noted apply small neural network relationship. works effectively convolution except effect spatial relationships determined function approximation neural network instead explicitly encoded matrix. output features summed along neighbor dimension activation function choice giving tensor shape concatenate absolute values point corresponding activations next layer spatial feature extraction giving ﬁnal tensor shaped dimensionality original point cloud simplest implementation point cloud points original locations storing data. point cloud kind layer extract abstract features. fig. ﬁlters data represent corners. corroborated activations shown fig. activations corners squares differ signiﬁcantly nearby edges. graph convolutions mostly conﬁgured emulate concept. points query candidate neighbor extractions would effectively create directed graph nearest neighbors. applying generalized convolution graph would cause node store vector representing features relationship nodes connected order apply genconv layers actual graphs needs omit nearest neighbor step data already present graph. things stand limit model graph representation however omit arbitrary points introduce points every layer. integral part process fact viewed form striding. ﬁnal conﬁguration model sample half candidate points query points every layer resulting input sizes points layer. complexity analysis primary motivation behind creation layer inefﬁciency applying conventional architectures point cloud problem. conventional convolution complexity represents input dimensions represents ﬁlter dimensions. makes conventional convolutions look respect size input however situation much complex point clouds involved size individual dimensions space rigidly correlated size input point cloud. issue hand sparsity/density. conventional matrix oriented deﬁnition sparsity apply continuous spaces deﬁne sparsity volume point. assume sparsity constant sizes inputs complexity class conventional convolution actually number points. number points octuple input maintain sparsity product would also octuple. assumption sparsity remains make however sparsity depends level detail wishes ﬁlters learn. means complexity class actually represents function best approximates sparsity. don’t deﬁne function situational likely approximate well common functions many cases. howeverif level detail remains same scale problem grows sparsity grows. also issue level detail real world scans varies across image varying distances sensor. requires conventional convolutions work smaller blocks unit volumes increasing sparsity further. applying conventional convolution sparsely combat fact challenging convolution dilatory effect tensors sparse tensors quickly become dense convolutions. means converting point clouds occupation grids needs keep sparsity thus resolution maintain input reasonable size losing information process. applied ﬁnally apply more query point nearest neighbors points penultimate layer. conventional convolutional analog would fully connected layer thought convolution taken single pixel ﬁlter size input image. alternatively looking segment image semantically label point apply ﬁnal layer every point exact fully convolutional neural networks fig. shows full algorithm intuitive computation graph form takes built computation. includes features discussed detail next section notably form striding. analogies already existing systems claim technique generalized convolution thus must able represent conventional convolution. take image split points integer grid fig. apply types convolutions data. conventional convolution outputs point function applied point within receptive ﬁeld. function deﬁned piecewise possible spatial relationship point receptive ﬁeld might point convolution evaluated. a∆x∆y θ∆x∆y. reasonable even efﬁcient case normal image point guaranteed integer away point convolution evaluated. however assumption cannot made learnable piecewise function must replaced continuous function. deﬁne small neural network. evaluating function slower simply fetching weight values allows apply model point clouds directly. type convolution visualized different ways. ﬁrst sparse convolution continuous rather discrete space. consider point cloud stored inﬁnitely sparse grid ﬂoating point values represent indices. convolutional ﬁlter deﬁned continuous function ∆x∆y∆z instead looktable weights conventional convolutional layer. continuous ﬁlters visualized similarly conventional counterparts arbitrary levels granularity. weights deﬁned continuous function visualize ﬁlter passing unit sample point wish visualize. fig. illustrates ﬁlters network sampled resolution fig. visualizes ﬁlters ﬁrst convolution modelnet set. sparsity. results complexity class number points number parameters layer. component arises need search nearest neighbors kd-tree practice noticeable large size models. complexity comes cost requiring ﬁlter regard spatial features calculated neighbor separately whereas conventional model essentially lookup table weights spatial relationship possible. means method efﬁcient conventional convolution sparsity certain threshold log. show empirically case modelnet dataset. space complexity generalized convolutions also favorable conventional convolutions grow resolution generalized convolutions bound complexity feature need represent number points wishes include thusoparameters oneighbors) size convolution ﬁnely tuned independently resolution. practice yields noticeable gains seen table using type layer able achieve classiﬁcation accuracy modelnet competitive single model implementations parameters training epochs conﬁguration general convolution layers shown fig.c. leaky relu activations used everywhere except ﬁnal softmax activation. architecture implemented tensorﬂow. code available https//github.com/thahypnotoad/generalconvolution. note diagram currently fully connected table comparison relevant performance parameter counts various architectures modelnet datasets. blank spaces signify data could found. indicates based voxnet structure. indicates based vgg-m structure. future work notably absent architecture form pooling. plenty algorithms downsampling point clouds immediately necessary implement pooling explicitly shown conventional convolutional neural networks pooling replaced convolutions greater stride applied resources elsewhere. currently architecture utilizes ﬁxed-sized nearest neighbor search instead variable sized neighborhood search. design decision avoid non-uniformly sized arrays difﬁcult express matrix-matrix operations. addition nearest neighbor search allows model apply appropriate radii areas varying sparsity. look implications changing behavior feature extraction way. current implementation technique also omits many standard machine learning techniques data augmentation ensembling batching thus batch normalization. suspect properly re-implementing techniques type model yield similar beneﬁts conventional deep models experienced. previously mentioned working continuous space possible original point cloud query select entirely points original input. however instead constructing query cloud sample input layer. develop computationally cheap algorithm selecting generating salient points could signiﬁcantly increase extent apply striding thus speed. plan look algorithms future. finally type model applicable classes machine learning problems relationships data points relevant individual data points themselves. graphs example class intend test generalized convolutions future. fewer parameters scale well case sparse point clouds. also advantage voxel based methods natively work point clouds requiring voxellization real time applications. garcia-garcia gomez-donoso garcia-rodriguez orts-escolano cazorla azorin-lopez pointnet convolutional neural network real-time object class recognition international joint conference neural networks july maturana scherer voxnet convolutional neural network real-time object recognition ieee/rsj international conference intelligent robots systems sept lightnet lightweight convolutional neural network real-time object recognition eurographics workshop object retrieval pratikakis dupont ovsjanikov eds. eurographics association johns leutenegger davison pairwise decomposition image sequences active multi-view recognition corr vol. abs/. available http//arxiv.org/abs/.", "year": 2017}