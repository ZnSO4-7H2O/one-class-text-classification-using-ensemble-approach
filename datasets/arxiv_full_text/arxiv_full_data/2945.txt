{"title": "Towards Universal Representation for Unseen Action Recognition", "tag": ["cs.CV", "cs.AI", "cs.LG", "cs.MM"], "abstract": "Unseen Action Recognition (UAR) aims to recognise novel action categories without training examples. While previous methods focus on inner-dataset seen/unseen splits, this paper proposes a pipeline using a large-scale training source to achieve a Universal Representation (UR) that can generalise to a more realistic Cross-Dataset UAR (CD-UAR) scenario. We first address UAR as a Generalised Multiple-Instance Learning (GMIL) problem and discover 'building-blocks' from the large-scale ActivityNet dataset using distribution kernels. Essential visual and semantic components are preserved in a shared space to achieve the UR that can efficiently generalise to new datasets. Predicted UR exemplars can be improved by a simple semantic adaptation, and then an unseen action can be directly recognised using UR during the test. Without further training, extensive experiments manifest significant improvements over the UCF101 and HMDB51 benchmarks.", "text": "unseen action recognition aims recognise novel action categories without training examples. previous methods focus inner-dataset seen/unseen splits paper proposes pipeline using large-scale training source achieve universal representation generalise realistic cross-dataset scenario. ﬁrst address generalised multiple-instance learning problem discover ‘building-blocks’ large-scale activitynet dataset using distribution kernels. essential visual semantic components preserved shared space achieve efﬁciently generalise datasets. predicted exemplars improved simple semantic adaptation unseen action directly recognised using test. without further training extensive experiments manifest signiﬁcant improvements hmdb benchmarks. ﬁeld human action recognition advanced rapidly past years. moved manually designed features learned convolutional neural network features encoding appearance information encoding motion information learning local features learning global video features performance continued soar higher incorporate steps end-to-end learning framework however robust accurate action classiﬁers often rely large-scale training video datasets using deep neural networks require large numbers expensive annotated samples action class. although several large-scale video datasets proposed like sports-m activizero-shot action recognition recently drawn considerable attention ability recognize unseen action categories without labelled examples. idea make trained model generalise unseen categories shared semantic representation. popular side information used attributes word vectors visual-semantic embeddings. zero-shot learning frameworks effectively bypass data collection limitations traditional supervised learning approaches makes promising paradigms uar. extensive work zero-shot action recognition done past years. considered using attributes classiﬁcations. attribute-based methods easy understand implement hard deﬁne scale large-scale scenario. semantic representations like word vectors thus preferred since category names required constructing label embeddings. also much recent work using visual-semantic embeddings extracted pre-trained deep networks superior performance single view word vectors attributes. however whichever side information adopt generalisation capability approaches promising referred domain shift problem. previous work thus still focuses inner-dataset seen/unseen splits. practical since dataset category require re-training. motivated fact propose utilise large-scale training source achieve universal representation automatically generalise realistic cross-dataset scenario. unseen actions datasets directly recognised without training ﬁne-tuning target dataset. figure proposed cd-uar pipeline extract deep features frame summarise video essential components kernelised gmil; preserve shared components label embedding achieve using jsd; concepts represented adjusted domain adaptation. test unseen actions encoded gmil using essential components activitynet achieve matching using sual features results generative multiple instance learning problem. namely visual features video share label small portion determinative. compared conventional global summaries visual features using bag-of-visualword fisher vector encoding gmil aims discover essential building-blocks represent actions source target domains suppress ambiguous instances. introduce novel universal representation learning algorithm composed non-negative matrix factorisation jensen-shannon divergence constraint. non-negativity property allows learn part-based representation serves bases visual semantic modalities. symmetrised bounded version kullback-leibler divergence make balanced generalisation distributions visual semantic features. representation generalise visual semantic views source target domains referred insighs discussed experiments. main contributions summarised follows paper extends conventional tasks realistic cd-uar scenarios. unseen actions datasets directly recognised without training ﬁne-tuning target dataset. extensive experiments manifest effectively generalise across different datasets outperform state-of-the-art approaches inductive scenarios using either low-level deep features. zero-shot human action recognition advanced rapidly importance necessity aforementioned. common practice zero-shot learning transfer action knowledge semantic embedding space attributes word vectors visual features. initial work considered manually deﬁned attributes describe spatial-temporal evolution action video. investigated problem accurately robustly detect attributes images videos learned high-quality attribute detectors shown generalize well across different categories. however attribute-based methods suffer several drawbacks actions complex compositions including various human motions human-object interaction. extremely hard determine attributes describing actions; attribute-based approaches applicable large-scale settings since always require re-training model adding attributes; despite fact attributes data-driven learned semi-automatically deﬁned semantic meanings unknown inappropriate. hence word vectors preferred zero-shot action recognition since category names required constructing label embeddings. among ﬁrst works adopt semantic word vector spaces intermediate-level embedding zero-shot action recognition. following alexiou proposed explore broader semantic contextual information text domain enrich word vector representation action classes. however word vectors alone deﬁcient discriminating various classes semantic visual textual information. thus large number recent works exploit large object/scene recognition datasets object/scene scores videos actions. makes sense since objects scenes could serve basis construct arbitrary action videos semantic representation alleviate visual gaps. motivation also ascribed success cnns help off-the-shelf object detectors methods could even perform zero-shot spatio-temporal action localization. also alternatives solve zero-shot action recognition. leveraged semantic inter-class relationships known unknown actions followed label transfer learning. similarity mapping doesn’t require attributes. formulated zero-shot learning designing error-correcting output codes bypass drawbacks using attributes word vectors. domain shift problem several works extended methods using either transductive learning domain adaptation however previous methods focus inner-dataset seen/unseen splits extend problem cduar. scenario realistic practical; example directly recognise unseen categories datasets without training ﬁne-tuning. though promising cd-uar much challenging compared conventional uar. contend considered severe domain shift exceeds generalization capability existing approaches. hence propose algorithm obtain robust universal representation. novel cd-uar pipeline dramatically outperforms conventional benchmarks stateof-the-art approaches inductive scenarios using low-level features cd-uar using deep features respectively. related work also applies zero-shot image classiﬁcation despite fact promising generalisation reported supports insights still focuses inner-class splits without considering cd-uar. also sparsity constrained completely different goals methods jsd. section ﬁrst formalise problem clarify step below. introduce cd-uar pipeline detail includes genearalised multipleinstance learning universal representation learning semantic adaptation. training denote training actions class labels pairs source domain training sample size; action frames d-dimensional visual fea) rd×li; {··· ture space label embedding subscript denote information unseen classes. inference achieved learning visual-semantic compatibility function minl generalise test using learned unseen action recognised conventional summary achieved bagof-visual-words fisher vectors gmil assumed instances class drawn different distributions. denote space borel probability measures argument known bag. conventionally assumed instances attractive others repulsive paper argues many instances exist neutral bags. fig. show example visual feature distributions ‘long-jump’ ‘triple-jump’. point denotes frame. frames fall neutral bags frames attractive class repulsive others. neutral bags contain many basic action bases shared classes background noise. conventional maximum mean discrepancy well represent distributions. instead paper adopts odds ratio embedding aims discover attractive bases class suppress neutral ones. simply implemented kernelised representation odds ratio applies speciﬁc implementation details found supplemenway discover bases tary material. ‘building-blocks’ represent actions source target domains. universal representation learning clarity deﬁne visual semantic embeddings source domain towards universal representation shared space well preserve bases visual semantic modalities; generalise distributions unseen datasets. former rm×ns employed rm×ns nonnegative matrices rm×d rd×ns nonnegative matrices rm×d full rank whose product approximately represent original matrix i.e. practice min. constrain shared coefﬁcient matrix rd×ns latter introduce preserve generative components gmil essential ‘building-blocks’ generalise unseen datasets. hence overall objective function given converged need projection matrices project however since algorithm nmf-based direct projection shared space exist. inspired learn rotations protect data originality projecting universal space known orthogonal procrustes problem identity matrix. according orthogonal projection following advantages preserve data structure; redistribute variance evenly maximally decorrelates dimensions. optimisation simple. ﬁrst singular value decomposition algorithm decompose matrix sλqt connection matrix rd×m indicates zeros matrix. achieved way. given dataset semantic embeddings projected class-level prototypes unseen action gallery pbbu. test example simply predicted nearest neighbour search optimisation itsists three parts. eration takes comparison basic algorithm applied separately complexity respectively. words algorithm complex basic nmf. second regression requires decomposition complexity therefore total computational complexity w.r.t. number iterations since make generalise datasets domain shift unknown. improved performance semantic information target domain approximate shift. insight measure unseen class labels using discovered ‘building blocks’. learnt reliably associate visual semantic modalities i.e. could approximate seen-unseen discrepˆ ancy ˆvb. employ transfer joint matching achieves feature matching instance reweighing uniﬁed framework. ﬁrst projected semantic embeddings unseen classes training samples space paa. provide adaptive matrix kernel matrix unseen action recognition given test action ﬁrst convert kernelised representation using trained gmil kernel embedding similar make prediction using adapted unseen prototypes perform large-scale activitynet dataset. cross-dataset experiments conducted widely-used benchmarks hmdb hmdb contain trimmed videos activitynet contains untrimmed ones. ﬁrst compare approach state-of-the-art methods using either low-level deep features. understand contribution component method also provide detailed analysis possible alternative baselines. setting hmdb table comparison state-of-the-art methods using standard low-level features. last sets results reference. transductive; inductive; results datasets activitynet consists training validation test videos activity classes. class least videos. since videos untrimmed large proportion videos duration between minutes. composed realistic action videos youtube. contains video clips distributed among action classes. class least video clips clip lasts average duration hmdb includes videos action classes extracted wide range sources videos movies. class least video clips clip lasts average duration visual semantic representation three datasets single model obtain video features. model resnet- initially trained imagenet ﬁne-tuned activitynet dataset. overlapping classes activitynet used ﬁne-tuning. adopt good practices temporal segment networks state-of-the-art action classiﬁcation frameworks. extract feature last average pooling layer frame-level representation. note features extracted single frame. believe better performance could achieved considering motion information e.g. features extracted multiple frames consecutive optical however primary demonstrate ability universal representations. without loss generality widelyused skip-gram neural network model trained google news dataset represent category name l-normalized word vector. multi-word names accumulated word vectors implementation details gmil estimate pooled local nbnn kernel using estimate odds-ratio best hyper-parameter achieved cross-validation. order enhance robustness propose leave-onehop-away cross validation. speciﬁcally training activitynet evenly divided hops according ontological structure. iteration validation furthest hops used training. except feature extraction whole experiment conducted intel quad-core .ghz memory. comparison state-of-the-art methods comparison using low-level features since existing methods based low-level features observe signiﬁcant performance gap. fair comparison ﬁrst follow conduct experiments conventional inductive scenario. seen/unseen splits hmdb respectively. visual features fisher vectors improved dense trajectory provided semantic features wordvec model. without local features frame training starts url. note methods also based transductive assumption. method simply address scenario incorporating domain adaptation. report results table accuracy averaged random splits. method outperforms compared state-ofthe-art methods inductive scenario. although transductive setting extent violates ‘unseen’ action recognition constraint domain adaptation method shows signiﬁcant improvements. however none compared methods competitive proposed pipeline even though completely inductive plus crossdataset challenge. comparison using deep features table follow recent work provides comparisons related zero-shot approaches. many different data splits evaluation metrics comparison divided three common settings i.e. using standard supervised test splits; using randomly selected actions testing; using actions randomly testing. lows. first also deep-feature based approach employs googlenet network pre-trained -category shufﬂe imagenet. addition adopts faster r-cnn pre-trained ms-coco dataset. secondly also need training ﬁne-tuning test datasets. words shares spirit cross-dataset scenario object detection perspective. contrast cd-uar achieved pure representation learning. overall fair comparison worthy thorough discussion. method consistently outperforms compared approaches minimum margins respectively. note that also deep-model-based competitive results. ﬁnding suggests future research focus deep features instead. besides visual features similar skip-gram model wordvec label embeddings.therefore credit performance improvements given method itself. in-depth analysis since method outperforms compared benchmarks understand success method conduct baselines alternatives main approach. results summarised table convergence analysis analysing baselines ﬁrst show examples convergence curves fig. optimisation. seen overall loss reliably converges approximately iterations. constraint gradually resolves decomposition losses tend competing other. ascribed difference ranks instance-level kernelised features classlevel wordvec much lower rank alternation iteration reweighs turn despite overall converged loss. tjm. result beneﬁt domain adaptation large basis space size propose sets size according original sizes namely dlow high dhigh shown table higher dimension gives better results cases. note performance difference signiﬁcant. thus conclude method sensitive basis space size. paper studied challenging cross-dataset unseen action recognition problem. proposed pipeline consisting deep feature extraction generative multipleinstance learning universal representation learning domain adaptation. novel algorithm proposed incorporate non-negative matrix factorisation jensen-shannon divergence constraint. shown advantageous ﬁnding shared bases visual semantic spaces remarkable improvement empirically demonstrated distributive basis preserving unseen dataset generalisation. resulting universal representation effectively generalises unseen actions without training ﬁne-tuning dataset. experimental results exceeded stateof-the-art methods using conventional deep features. detailed evaluation manifests contribution credited approach. leave several interesting open questions. methodology examined variations divergences. gmil problem proposed without indepth discussion although simple trial using pooled localnbnn kernel showed promising progress. addition improvement signiﬁcant inductive cduar. uniﬁed framework gmil domain adaptation could better solution future. acknowledgements work supported part career grant iis-. gratefully acknowledge support nvidia corporation donation titan gpus used work. pipeline validation power deep features demonstrated comparison intuitive assumption cd-uar easily resolved deep features. thus gmil features followed state-of-the-art eszsl using kernels. performance table improved marginal surprise. results shows difﬁculty cd-uar conﬁrms contribution proposed pipeline. gmil stated earlier frame-based action features viewed gmil problem. therefore change encoding conventional keep rest pipeline. seen average performance drop high transductive scenario ucf. separated contribution algorithm arguably main contribution paper. progress conventional remove constraint. shown table performance severely degraded. shared bases regardless data structural change. gnmf address problem well need preserve distributions generative bases rather data structures. generative bases ‘building blocks’ actions data structure completely change datasets. however better preserving bases canonical correlation analysis purely based mutual-information maximisation. therefore signiﬁcant performance observed results nmf. without domain adaptation pipeline used adjust inferred unseen prototypes wordvec. insight align inferred bases gmil source domain also used represent unseen actions. visual semantic connected ˆva. without scheme however observe marginal performance degradation cd-uar scenario probably activitynet rich concepts hmdb distinctive. investigate transductive scenario assumes observed", "year": 2018}