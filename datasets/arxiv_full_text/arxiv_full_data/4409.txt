{"title": "Multispectral and Hyperspectral Image Fusion Using a 3-D-Convolutional  Neural Network", "tag": ["cs.CV", "stat.ML"], "abstract": "In this paper, we propose a method using a three dimensional convolutional neural network (3-D-CNN) to fuse together multispectral (MS) and hyperspectral (HS) images to obtain a high resolution hyperspectral image. Dimensionality reduction of the hyperspectral image is performed prior to fusion in order to significantly reduce the computational time and make the method more robust to noise. Experiments are performed on a data set simulated using a real hyperspectral image. The results obtained show that the proposed approach is very promising when compared to conventional methods. This is especially true when the hyperspectral image is corrupted by additive noise.", "text": "past decade methods based deep learning many cases outperformed traditional signal processing approaches areas speech pattern recognition main component artiﬁcial neural network speciﬁcally so-called convolutional neural network shown effective pattern recognition related areas method based training d-cnn learning ﬁlters used fuse images. since method based supervised learning requires target image available. therefore input data need spatially decimated order observed image target image. assumption made relationship input target data learned d-cnn lower resolution scale also applies higher resolution scale. make fusion problem computationally efﬁcient dimensionality image reduced prior fusion stage using principal component analysis important step proposed method depends assumption spectral singular vectors lower resolution image identical higher resolution image want estimate. comparing approach conventional methods given demonstrated proposed method gives better results according three quantitative quality metrics. another advantage proposed method dcnn learns decimation ﬁlter automatic manner. words method relatively insensitive choice decimation ﬁlter used prepare training samples d-cnn. also produces images free artifacts halos ringing artifacts often seen using conventional methods. outline paper follows. next section brieﬂy discuss cnns. section proposed method described detail. section present experimental results ﬁnally section conclusion drawn. abstract—in paper propose method using three dimensional convolutional neural network fuse together multispectral hyperspectral images obtain high resolution hyperspectral image. dimensionality reduction hyperspectral image performed prior fusion order signiﬁcantly reduce computational time make method robust noise. experiments performed data simulated using real hyperspectral image. results obtained show proposed approach promising compared conventional methods. especially true hyperspectral image corrupted additive noise. pansharpening fusion multispectral image wide-band panchromatic image important fused image contain spectral information image spatial details image. advances sensor development fusion high spatial resolution image spatial resolution hyperspectral image becoming relevant many applications. typical image contains hundreds spectral reﬂectance bands making spectral information content high. allows identiﬁcation different materials based spectral signature useful applications classiﬁcation land cover types. numerous pansharpening methods proposed recent years often categorized either component substitution multi-resolution analysis methods. methods generally described using simple detail injection framework apart methods model based methods methods based statistical inference although ms/hs fusion relatively topic remote sensing several publications topic including used sparse coding spectral unmixing. method using coupled non-negative matrix factorization spectral unmixing given method based d-wavelet transform proposed. common approach ms/hs fusion problem view number fig. general outline estimation part algorithm. trained entire input data full resolution yields high resolution spatial loadings used reconstruct estimated high resolution image inverse transform. number neurons. main idea behind cnns concept local receptive ﬁeld associated neuron hidden layer. input convolutional layer image channels. neuron hidden layer receives input rectangular subset input image neuron’s receptive ﬁeld. sliding receptive ﬁeld input image shift connecting neuron hidden layer neurons hidden layer provide complete tiling input image. neurons hidden layer share weights bias therefore detect feature different locations input image. output hidden layer called feature shared weights called ﬁlter. single convolutional layer many feature maps hence learn several different ﬁlters detect different distinct features. convolutional layers so-called pooling layers sub-sample feature maps according function e.g. maximum value simpliﬁes feature maps greatly reduces number parameters network number convolutional layers grows. main beneﬁt architecture much fewer parameters need learned conventional fully connected shiftinvariance i.e. shared weights locally connected neurons hidden layers enables construction deeper networks learn much faster without sacriﬁcing performance. simplify notation symbols d-matrices i.e. images normal matrices. implicit reshaping image matrix vectorized images columns assumed. tilde symbol denotes interpolation symbol denotes estimate concatenation/stacking matrices/images denoted square brackets e.g. image spatially decimated resolution factor images using bicubic dimension m×n×p decimation ﬁlter yield similarly spatially decimated interpolated dimension yielding stacked obtain input image target data ﬁrst bands i.e. randomly divided number matching patches size pixels depth inputs targets respectively. fusion part method depicted fig. trained d-cnn accept entire input data once without break patches since learned ﬁlters. input trained d-cnn consists stacked image ﬁrst spatial loadings interpolated size i.e. output d-cnn estimated high resolution loadings options reconstruction estimated fused image. ﬁrst option described above ﬁrst loadings replaced high resolution estimate image noisy second option retain ﬁrst i.e. performing inverse transform using reduced matrices yielding hrur denotes reduced matrix work decided d-cnn architecture since image spatial dimensions spectral dimension d-cnn learns spectral-spatial features. input convolutional layer image ﬁlter size resulting feature size preserve size input image layers d-cnn avoid boundary artifacts convolution operations input convolutional layer ﬁlter size needs zero-padded zeros ﬁrst dimension second dimension third dimension. d-cnn used experiments convolutional layers ﬁlters respectively number spatial loadings sharpen. ﬁlter sizes ﬁrst convolutional layers chosen equal last convolutional layer. convolutional layer preceded zero-padding layer followed gaussian noise regularization layer adds zero-mean gaussian noise output previous layer. helps reduce overﬁtting network form random data augmentation ﬁrst convolutional layers rectiﬁed linear unit activation functions i.e. output layer linear activation. input shape convolutional layers ﬂexible. words d-cnn trained using speciﬁc patch size trained entire input estimated once. memory consuming input image large therefore dimensionality reduction helps signiﬁcantly reduce memory overhead fusion process. layers summarized table convolutiond indicate number filters filter size dimension. indicates number pcs. finally number following gaussian noise denotes noise variance. fig. performance terms ergas proposed methods function number pcs. trials performed dcnn method. mean shown standard deviation displayed using errorbars. spectral bands. however blank strip along left side thus pixels along dimension. image simulated image averaging bands image according spectral response proﬁles bands ikonos sensor. spatially decimate observed image factor using bicubic decimation ﬁlter obtain lower spatial resolution image. yields images fused i.e. image dimension pixels spectral bands image dimension pixels spectral bands. original image used reference image quantitative quality evaluation. method implemented python programming language using keras library runs theano backend computations performed using intel cpu. ram. described section iii-a simulated image spatial loadings spatially decimated used input d-cnn. target data ﬁrst spatial loadings image. training data consist randomly chosen matched patches spatial size pixels input target data. network objective function mean squared error target patch estimated patch. adaptive moment estimation optimizer values optimizer parameters given number training epochs equal assured objective function fully converged training. finally batch size equal variance gaussian noise regularization layer equal batch size number samples propagated time. found small batch size gives better results faster convergence. proposed method compared method extended version method refer methods respectively. comparison methods based maximum posteriori estimation wavelet coefﬁcients method identical except dimensionality reduction similar manner proposed method. begin investigating effect number sharpened performance proposed methods terms ergas metric. following number considered results experiment shown fig. according ﬁgure give optimal results methods. following experiments used methods. next experiment evaluation fusion performance methods terms ergas ssim quantitative quality metrics without additive zero-mean gaussian noise results quantitative quality evaluation summarized table upper half table gives results without added noise. shown there proposed method signiﬁcantly outperforms methods according three quality metrics. comparison methods performs much better map. obviously proposed method costly comparison methods terms computation time. using powerful graphical processing unit training time could reduced order magnitude making proposed method competitive terms computation time. fig. depicts small portion band interpolated reference estimated image methods. visual inspection shows proposed method gives best results. lower half table summarizes results obtained zero-mean gaussian noise added image. again proposed method performs signiﬁcantly better terms quality metrics. however noise tolerance similar slightly less method. method prior fusion performs signiﬁcantly worse methods presence noise. terms ergas metric compared varies additive gaussian noise increments result experiment shown fig. plot clearly emphasizes observed previous experiment. proposed method performs best finally sensitivity methods w.r.t. decimation ﬁlter used investigated. three types decimation ﬁlters considered i.e. bicubic bilinear nearest neighbor. results methods measured ergas metrics summarized table iii. according table bicubic decimation gives best results methods. using bilinear decimation degrades performance methods terms ergas metrics however proposed method less affected method. finally nearest neighbor decimation degrades performance signiﬁcantly methods proposed method compared results obtained using bicubic decimation. performance methods w.r.t. interpolation filter used. bicubic bilinear nearest neighbor interpolation considered. trial performed proposed method. fig. subset band image shown. shows interpolated image band reference band shows image obtained using method shows image obtained using method shows image obtained using proposed method. paper proposed method fusion images using d-cnn. important component method dimensionality reduction prior fusion. decreases computational cost signiﬁcantly impact quality fused image. presence noise dimensionality reduction improve result. proposed method compared methods based estimation. experiments using simulated dataset demonstrated proposed method gives good results also tolerant noise image. vivone alparone chanussot dalla mura garzelli licciardi restaino wald critical comparison among pansharpening algorithms ieee transactions geoscience remote sensing vol. zhang backer scheunders noise-resistant wavelet-based bayesian fusion multispectral hyperspectral images ieee transactions geoscience remote sensing vol. nov. palsson sveinsson ulfarsson benediktsson model-based fusion multihyperspectral images using wavelets ieee transactions geoscience remote sensing vol. nezhad karami heylen scheunders fusion hyperspectral multispectral images using spectral unmixing sparse coding ieee journal selected topics applied earth observations remote sensing vol. june zhang wang zhang hyperspectral multispectral image fusion using cnmf minimum endmember simplex volume abundance sparsity constraints ieee international geoscience remote sensing symposium july sylla minghelli-roman blanc mangin d’andon fusion multispectral images extension pan-sharpening arsis method ieee journal selected topics applied earth observations remote sensing vol. chen wang jiang fusion hyperspectral multispectral images novel framework based generalization pan-sharpening methods ieee geoscience remote sensing letters vol. szegedy sermanet reed anguelov erhan vanhoucke rabinovich going deeper convolutions proceedings ieee conference computer vision pattern recognition lecun boser denker henderson howard hubbard jackel handwritten digit recognition back-propagation network neural networks current applications. chappman hall hubel wiesel receptive ﬁelds binocular interaction functional architecture cat’s visual cortex journal physiology vol. graves mohamed hinton speech recognition deep recurrent neural networks ieee international conference acoustics speech signal processing wald quality high resolution synthesized images simple criterion? proceedings third conference fusion earth data merging point measurements raster maps remotely sensed images. see/urisca yuhas goetz boardman discrimination among semi-arid landscape endmembers using spectral angle mapper algorithm summaries annual airborne geoscience workshop vol.", "year": 2017}