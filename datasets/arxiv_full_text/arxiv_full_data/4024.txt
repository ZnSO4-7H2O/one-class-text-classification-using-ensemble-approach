{"title": "Lattice Particle Filters", "tag": ["cs.AI", "cs.CV"], "abstract": "A standard approach to approximate inference in state-space models isto apply a particle filter, e.g., the Condensation Algorithm.However, the performance of particle filters often varies significantlydue to their stochastic nature.We present a class of algorithms, called lattice particle filters, thatcircumvent this difficulty by placing the particles deterministicallyaccording to a Quasi-Monte Carlo integration rule.We describe a practical realization of this idea, discuss itstheoretical properties, and its efficiency.Experimental results with a synthetic 2D tracking problem show that thelattice particle filter is equivalent to a conventional particle filterthat has between 10 and 60% more particles, depending ontheir \"sparsity\" in the state-space.We also present results on inferring 3D human motion frommoving light displays.", "text": "paper proposes lattice particle filter alternative particles placed deter­ ministically lattice rule. lattice rules approximate infer­ promising quasi-monte carlo meth­ subclass models particle filter­ ence state-space used successfully high­ performance ing. however dimensional graphics integration computer significantl filters often varies advan­ nance important present class stochastic nature. samples tage methods error filters particle gorithms called lattice rate converges placing circumvent par­ difficulty versus conven­ state space dimension deterministically ticles according quasi­ monte carlo practical tional viewpoint monte carlo integration rule. describe randomized methods idea discuss realization practical unbiased variance properties theoretical efficiency. estimators. track­ synthetic perimental results problem show lattice particle fil­ brief introduction introduce equivalent conventional particle fil­ describe methods lattice particle filter. show quantitative results problems depending \"sparsity\" ticles namely image patterns tracking inference state-space. human pose binocular human motion moving light ferring projected limb positions. previous work displays. introduction bayesian probability distribution unknown state vari­ particle able time conditioned inference approximate denoted tory distribution applications called filtering distribution. approximates robot localization method approximating unknown state distribution marginal thereby variables particle recursively updated time step next dealing approach multi­ provides observations gordon become available. modal distributions dynamics nonlinear method provide clear description servation suc­ despite call bootstrap algorithm. computer vision statistically unstable. cesses speak­ condensation often called algorithm even though produces method descriptions predictions samples random variation based given doucet generalizations therefore samples excessive pre­ pitt shepard visual unreliable. tracking dictions fil­ goal particle object location; poor estimates results tering distribution situations causes algorithm lose track many applications altogether. object instead fact assumption product proportional summa­ prediction filtering rizes information simplest random proposals evaluates bution normalized proposal; account tance weights proposal filtering sampled. states many applications dominates function rithm. consequence kept relatively small. example useful human motion dimensional subspaces filtering body's dynamics. tions performance particles mcmc sampling paper examines method general reduce num­ samples. recently similar non­ suggested filtering method applied locally randomized time step form stratified sampling flavor used; however method applied randomized method. allows used con­ properly struct unbiased does therefore statistical performed. bayesian filtering describing particle lattice filter filtering particle denote unknown state variable denote image observation sition model characterizes first-order observation model specifies tion likelihood practice direct cause involves integral whose dimension grows hence advisable solve recursively using prediction filtering equations -t)dxt- linear observation models using kalman filter other­ also gaussian computation case approach weighted integrable properly weighted paths exploration described multinomial index sequence step specifies generated \"surviving\" particles step propagated particles forward step specifies weights associated particle. independent function maps transformation vector uniform state xt-; transforma onto sample tion component computer simulation since ran­ distribu­ variate generation tions based transformations uniform random case univariate numbers standard nor­ model transition normal distribution standard function. provides filtering lattice rule instead explain next section. lattice particle filter weighted properly sec. produces described samples distribution approximate pf's performance however random nature sampling. practice figure left rectangle context sometimes particularly harmful rule projection even though approximation because filtering points axis results errors error sampling step small manner. accumulate this consider simple sition independent binary otherwise. dependently states trigger suppose fur­ thermore true state trajectory happened entirely evolve assume particles recover trajectory. particles within distributed parameters hence probability particles steps ponentially long time occurs almost certainly time completely. example alternative strategy would random choose particle particles time place remaining equidis­ particles deterministic place­ ment particles low-discrepancy according special next provide general lattice rules quasi-monte consider generic several ways approach tion averages values uniform convergen many practical slow. deterministic cartesian product shown figure ministic approach constant preserve fast dimension exponentially related behavior tions low-dimensional example points; points points project components integrate form create methods contrast point sets projections onto coordinate whose different subspaces overview points. always contain ran­ distinct number generation methods given book niederreiter example rule shown point called korobov lattice figure second goal methods create point sets close possible distri­ based bution. methods so-called point sets give conver­ gence rates integration method prac­ contrast intimately tice performance integration related effective dimension integration problem approximate integrand ability i.e. inte­ functions low-dimensional dimension inte­ grands small effective point sets good grated accurately subspaces dimension. projections demonstrated performance applications numerous special case methods rules comparison sequences niederreiter easy implement erator required built projections subspaces equivalent also randomized domain respect problem task. integra­ integrand random independent error points rate independent problems rate convergence alternative might one-dimensional point sets deter­ number points needed logn logn logn state-space table generators problems generators generator shifted orobov lattice build special lattice points called component-wise. integer crucial generator rule; choice depending values performance. sample size state dimension given vector table details). distributed shift uniformly implies also uniform depen­ dent. shift important means obtaining error estimates simulations multiple necessary approxima­ resulting tions unbiased. algorithm particles algorithm propagates rules however uniform num­ bers forward become com­ ponents rule precisely dimension number time steps. decompose ponents note that computed explicitly. ward propagation assignment uniform assigning depend outcome troducing serious dimensions lattice rule time com­ form time without components recursively storing next for­ issue step important particular number variables dan­ might particles components resampling hence gener­ note point {utl vtn} form lattice rule would necessary rate globally. how­ convergence ever point used time forms lat­ tice rule. addition shown point sets used time step differ implementation ran­ shift. remains sampling throughout time generally case types point sets used implementation summary differs points num­ state generator generates point generate theoretical section outline ordinary view ordinary different search expanded truncated versely algorithm. istic search heuristic function branch filtering transition sion. expansion state space evenly possible. mathematical perspective samples generated weighted fact updating pling replacement difference independent. formalize intuition special theorem particle generated point uniform distribution resampling independent properly weighted sample wti}� {xti proof omitted space limitations; dis­ proceeds showing follows then tribution function yields applying there ergodic theorem sult. hence least asymptotical produces distribution filtering correct approximation quantity furthermore unbiased note random shift essential result principal previous gen­ samples work qmc-based filtering erated e.g. experiments conventional test compare sampling filters uses residual observations temporal dynamics likelihood function. goal compare well approximate filters different quality distribution filtering imation measured computing ation estimation distribution numbers varying filters plying relationship also analyze errors time required computation gorithms. rithms scale similarly disk tracking first experiment involves random walk image sequence. position model setting misspecified larger standard \"true\" model model parameters typically unknown prac­ tice hence relatively large value must chosen search sufficiently large neighborhood frames image sequences created applied simulating initialized sequence setting true disk location time disk weighted taking cation estimated mean particles error time step euclidean distance summary statistic true disk location. compute root mean-squared trials time step. rmse results shown figure function particles difference ll'?o efficiency gain disk tracking table experimental task cles represents rmse ordinary performance curves represent pares identical particles. different com­ numbers figure numbers error bars showing rmse particles standard confidence measure provide expected pro­ true disk location. deviation approximately duces location errors less number samples. deterministic place­ hypothesis supports average improves ment particles although addition estimate. error bars plot standard also smaller. shows rmse results figure rmse results compared allows particles. different numbers gains lpf. assess computational number parti­ need increase cles hence computation time approximately errors small order produce obtained individual trial particles still error bars. results hold wide range particle figure shows experiments sizes. particles. particles experimental setup figure note average prediction error methods well vari­ predictions ability increasing summary results number particles. given table complete experiments note consistently outperform margin least performance improve­ ment seems less pronounced cases relatively many particles expected optimized parti­ case placement seems particularly relevant regarding relatively particles. percentage match performance third table occurs sample size particles overall lpf. again difference increases. human motion tracking second experiments apply using residual human task recover motion tracking lower portion rather using camera images observations body markers used projections system. motion capture obtained challenging lower filtering space. body described space without first tracking occurs directly algorithms dimensionality reduction like applying component analysis principal labeled cor­ positions image observations human subject markers responding found commercial locations system. tion capture markers used track­ lower body shown fig. observa­ projection tion model involves perspective onto image plane plus additive points gaus­ sian noise. given camera center optical axis parallel marker point produces isotropic true sure performance mean filtering provided using approximations computed true mean obtain ground truth measure filtering input distribution times number samples sequences used experiments. mean sample mean large run. times random seeds input every run. means computed according markers locations figure figure summarizes results individual state left articulated linkage. body modeled left namely variables angles angular lower body model state vector left knee. notice pelvis freedom degrees mean estimates average obtained knee. given state trials close true mean known spine kinematic traverse since cases. surprising marker locations. tree spine pelvis produced estimates. error generate bars fig. show standard deviation locations image �enerate ensemble means runs model. marker predicted predicted observations expect show smaller lity variabi location true mean. like disk tracker estimates function state likelihood state results standard usually deviation efficiency. observations filter particle similar gains computational dif­ shows expected figure ference variance error bars obtained larger instead fig. experiments simulate lattice trials. lower errors views person approximately clear nonetheless. eyes. assuming conclusions image views individual state variables called presented sumption reliability filter improve condi­ particular specifically visual gaussian tioned deterministically according particles here radians. variance rule. reduces shifted lattice note impose limits approximation. particle-based joints practical strate pro­ rotate. amounts savings impossible con­ posals anatomically also limb lengths sistent observations. \"sparsity\" human sub­ determined pronounced begins fixed ject tracking typical particles tracking. source error real joints complicated involving experiments model causing parts pelvis filter also similar lattice particle vary width time. variance. comparing performance work plan alternative future versions difficult case. particular mean based global always equal filtering distribution lattice global believe mensions. true state. filters approx­ attempting central obtain exact convergence rates imate filtering distribution appropriate mea-", "year": 2013}