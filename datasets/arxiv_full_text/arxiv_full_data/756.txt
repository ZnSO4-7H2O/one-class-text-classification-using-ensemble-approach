{"title": "Discrete Dynamical Genetic Programming in XCS", "tag": ["cs.AI", "cs.LG", "cs.NE", "cs.SY", "I.2.6"], "abstract": "A number of representation schemes have been presented for use within Learning Classifier Systems, ranging from binary encodings to neural networks. This paper presents results from an investigation into using a discrete dynamical system representation within the XCS Learning Classifier System. In particular, asynchronous random Boolean networks are used to represent the traditional condition-action production system rules. It is shown possible to use self-adaptive, open-ended evolution to design an ensemble of such discrete dynamical systems within XCS to solve a number of well-known test problems.", "text": "abstract number representation schemes presented within learning classiﬁer systems ranging binary encodings neural networks. paper presents results investigation using discrete dynamical system representation within learning classiﬁer system. particular asynchronous random boolean networks used represent traditional condition-action production system rules. shown possible self-adaptive open-ended evolution design ensemble discrete dynamical systems within solve number wellknown test problems. traditionally learning classiﬁer systems ternary encoding generalise environmental inputs associate appropriate actions. number representations previously presented beyond scheme however including real numbers lisp s-expressions fuzzy logic neural networks date temporally dynamic representation schemes used potentially important approach since temporal behaviour kinds viewed signiﬁcant aspect cognition general. paper explore dynamical system representation within —what herein termed dynamical genetic programming traditional tree-based genetic programming used within calculate action represent condition uses graph-based representation node constantly updated asynchronous parallelism evolved using open-ended self-adaptive scheme. discrete case node boolean function therefore equivalent form random boolean network show able solve number well-known immediate delayed reward tasks using temporally dynamic knowledge representation scheme. number representations presented enable evolution computer programs common tree-based lisp s-expressions forms include machine code instructions ﬁnite state machines relevant form used paper small amount prior work graph-based representations. teller veloso’s neural programming uses directed graph connected nodes functionality deﬁned standard recursive connections included. signiﬁcantly node executed synchronous parallelism number cycles output node’s value taken. poli presented similar scheme wherein graph placed grid executes nodes synchronously parallel. examples graph-based typically contain sequentially updating nodes schmidt lipson recently demonstrated number beneﬁts graph encodings traditional trees reduced bloat increased computational eﬃciency. noted above tree-based s-expressions used within lcs. recently wilson explored form gene expression programming within lcs. rules represented expression trees evaluated assigning environmental inputs tree’s terminals evaluating tree comparing result predetermined threshold. whenever threshold value exceeded rule added match set. common form discrete dynamical system cellular automaton consists array cells cells exist states ﬁnite update states synchronous parallelism discrete time. traditionally cell calculates next state depending upon current state states closest neighbours. seen graph restricted topology. packard ﬁrst evolutionary computing techniques design exhibit given emergent global behaviour. following packard mitchell investigated genetic algorithm learn rules uniform binary cas. packard’s work produces entries update table used cell candidate solutions evaluated regard degree success given task. andre repeated mitchell al.’s work whilst using traditional evolve update rules. report similar results. sipper presented non-uniform heterogeneous approach evolving cas. cell also viewed population member mating lattice neighbours receiving individual ﬁtness. shows increase performance mitchell al.’s work exploiting potential spatial heterogeneity tasks. sipper ruppin extended approach enable heterogeneity node connectivity along node function; evolved form random boolean networks. discrete dynamical systems known random boolean networks originally introduced kauﬀman explore aspects biological genetic regulatory networks. since used tool wide range areas self-organisation computation typically consists network nodes performing boolean function inputs nodes network updating synchronously such viewed generalisation binary cas. since ﬁnite number possible states deterministic boolean functions dynamics eventually fall basin attraction. well-established value aﬀects emergent behaviour wherein attractors typically contain increasing number states increasing phases behaviour suggested ordered attractors consisting states; chaotic large number states attractor; critical regime around similar states trajectories tend neither diverge converge nodes change state attractor cycle discussions critical regime e.g. respect perturbations). analytical methods presented determine typical time taken reach basin attraction number states within basins given degree connectivity closely akin work described here kauﬀman describes simulated evolution design must play matching game wherein mutation used change connectivity boolean functions reports typical emergence high ﬁtness solutions together increase initialised size. noted above traditional consist nodes updating synchronously discrete time steps asynchronous versions also presented leading classiﬁcation space possible forms asynchronous forms also explored wherein often suggested asynchrony realistic underlying assumption many natural artiﬁcial systems. asynchronous logic devices known potential consume less power dissipate less heat exploitable eﬀorts towards hardware implementations systems. asynchronous logic also harvey bossomaier showed asynchronous exhibit either point attractors seen asynchronous loose attractors network passes indeﬁnitely subset possible states thus asynchrony represents another feature potential signiﬁcantly alter underlying dynamics thereby oﬀering another mechanism simulated evolutionary design process given task. paolo showed possible evolve asynchronous exhibit rhythmic behaviour equilibrium. asynchronous also evolved asynchronous rules within following scheme adopted. initial randomly created rule’s nodes randomly assigned connections many nodes input ﬁelds given task outputs plus other described i.e. ﬁrst connection input node corresponding locus input message. connections assigned random within usual. current input state always considered along current state network update cycle nodes nodes initialised randomly time network determine etc. population initially empty covering applied generate rules standard approach. matching consists executing rule cycles based current input. value chosen value typically within basin attraction rbn. asynchrony implemented randomly chosen node updated given cycle many updates overall network update cycle nodes network before equivalent cycle synchronous case said occurred. alternative schemes. node required. well-known maze problems explored possible actions accordingly required output nodes. extra matching node also required enable rbns match speciﬁc sets inputs. given logical match node regardless output node’s state rule join scheme also exploited within neural ‘windowed approach’ utilised output decided common state last steps example last states node updating prior cycle ending node’s state would paper thereafter match action processing proceeds standard algorithmic description xcs). covering necessitated randomly constructed created executed cycles determine status match output nodes. procedure repeated created matches environment state. parameter self-adaptation ﬁrst explored bull wherein mutation rate locally evolving entity itself; rule mutation rate mutation used applied node’s truth table connectivity rate node’s truth table represented binary string connectivity list integers range since node given ﬁxed value node maintains binary string length forms entries look-up table possible input states node i.e. aforementioned work packard evolving example. strings subjected mutation reproduction self-adapting rate rule. hence within representation evolution deﬁne diﬀerent boolean functions node within given network rule along connectivity map. speciﬁcally rule mutation rate stored real number initially seeded uniform randomly range parameter passed oﬀspring. oﬀspring applies mutation rate using gaussian distribution i.e. mutating rest rule resulting rate. need possible diﬀerent number nodes within rules given task scheme also variable length. truth table connections mutated randomly connected node either added last added node removed probability latter case occurs network currently consists initial number nodes. thus temporally dynamic search process representation scheme. evolving variable-length solutions mutation previously explored number times e.g. traditional seen primarily rely upon recombination search space possible tree sizes although standard mutation operator eﬀectively increases decreases tree size also. whenever oﬀspring classiﬁer created changes occur undergoing mutation parent’s numerosity increased mutation rate oﬀspring’s. apply discrete version dgp-xcs well-known multiplexer task. boolean functions deﬁned binary strings length bits index remaining bits returning value indexed bit. correct classiﬁcation randomly generated input results payoﬀ otherwise figure shows performance constructed system -bit multiplexer problem updated asynchronously pexpl ninit wilson performance exploit trials recorded using -point running average averaged runs. figure seen near optimal solution learnt around trials optimality observed around trial parameter governing mutation declines rapidly reaching bottom around trials shortly discovering optimal solution. number rules initially grows rapidly declining around furthermore average degree connectivity decreases fractionally whilst average network grows approximately extra node however network general match node always return true environment states cases output node always advocates action addition several environment states match node sometimes return true. however cases match node permit rule added action advocated always consistent. additional environment states rule match albeit probability less rule figure re-run before however using traditional synchronous updating scheme. results match node output nodes extremely similar regardless updating mechanism. evolved robust random nature asynchronous updating meaning accurate even relatively rare case nodes updating concurrently i.e. synchronous case. cell maze environments encoded binary bits white space represented obstacles food ‘f’. furthermore actions encoded binary shown figure task simply shortest path food given random start point. obstacles represent cells cannot occupied. teletransportation mechanism employed whereby trial reset agent reached goal state within discrete movements. woods optimal number steps food maze optimal steps woods figures show performance prove beneﬁcial; high expected random number generation example. noted growth event node added essentially neutral since node receives inputs existing nodes addition provides inputs nodes subsequent connectivity mutations. comparative purposes figure shows performance parameters multiplexer updated synchronously. shown performance similar regardless updating scheme thus apparently little overhead updating asynchronously possible beneﬁts mentioned above. figure provides illustration rule generated whilst solving -bit multiplexer problem updated asynchronously. node addition initial truth table shows state node transition given possible inputs. example output node truth table synonymous gate node state output node node state output node truth table node synonymous gate etc. memory register mechanism corporate using rule-linkage neural using recurrent links furthermore proof concept experiment cyclical directed graph neural programming shown capable representing rules memory solve woods however found twice experiments ddgp-xcs woods environment. parameters used identical applied aforementioned multiplexer experiments except ninit seen figure optimality observed around trials. roughly matches performance neural using self-adaptive constructivism faster using messy conditions using stack-based conditions lisp sexpression conditions figure shows average rules evolved. addition figure shows mutation rate declines rapidly trials shortly optimal solution learnt. figure shows average networks extra node average number connections decreases slightly. figures present performance ddgp-xcs maze environment. parameters used identical woods environment however bigger population limit used reﬂecting larger search space. optimality observed around trial similar performance observed using neural self-adaptive constructivism average number rules evolved around average number nodes networks also increases almost average number connections declines slightly parameter governing mutation declines rapidly trials ﬁnally stabilising trials. woods maze non-markov environment containing communicating aliasing states i.e. positions border non-aliasing state identically sensed require diﬀerent optimal actions. thus solve maze optimally form memory must utilised optimal performance previously achieved woods addition input sequence. however clear biological systems make shift registers. registers require interface environment buﬀers input presented simultaneously. impose rigid limit duration patterns deﬁning longest possible pattern requiring input vectors length. furthermore approaches struggle distinguish relative temporal position absolute temporal position hypothesis inherent content-addressable memory existing within synchronous diﬀerent possible routes basin attraction asynchronous case explored extended simply resetting node states step. signiﬁcant advantage approach rule/network’s short-term memory variable-length adaptive i.e. networks adjust memory parameters selecting within limits capacity memory aspects input sequence available computing predictions addition open-ended evolution used maximum size shortterm memory potentially also open-ended increasing number nodes within network grows. here nodes initialised random initial random placing maze thereafter reset subsequent matching cycle. consequently network processes environmental input ﬁnal node states become starting point next processing cycle whereupon network receives environmental input places network trajectory toward diﬀerent locally stable limit point. network given environmental input diﬀerent initial node states fall diﬀerent basin attraction thus rules’ dynamics constantly aﬀected inputs system executes. figures show performance woods environment parameters used identical applied previous maze environment. seen figure ddgp-xcs without node resets able achieve optimal performance woods approximately trials figure shows mutation rate macro-classiﬁers. figure shows average number nodes connections. optimal performance unattainable however nodes reset randomly matching proving system exploiting potential memory within asynchronous here. mechanism works within rules/rbn experience input need match cycle. hence ambiguous states remain accurate payoﬀ received providing action processed previous input appropriate potentially without matching. simplest form short-term memory ﬁxed-length buﬀer containing recent inputs; common extension apply kernel function buﬀer enable non-uniform sampling past values e.g. exponential decay older inputs simple forms memory static i.e. memory parameters ﬁxed advance memory state thus predetermined function paper form presented design asynchronous random boolean networks. shown able design ensembles collectively solve computational task reinforcement learning scheme. particular shown possible exploit inherent dynamics representation scheme solve non-markov maze i.e. without extra balan luke. demonstration neural programming applied non-markovian problems. proceedings genetic evolutionary computation conference gecco pages systems. merelo adamidis h.-g. beyer editors parallel problem solving nature ppsn volume lecture notes computer science pages berlin springer-verlag mutation classiﬁer system controllers. meyer berthoz floreano roitblat wilson editors animals animats proceedings sixth international conference simulation adaptive behavior pages press intelligence simulation evolution. biophysics cybernetic systems proceedings cybernetic sciences symposium pages washington spartan book gershenson. classiﬁcation random boolean networks. proceedings international conference artiﬁcial life pages press miller. empirical study eﬃciency learning boolean functions using cartesian genetic programming approach. proceedings genetic evolutionary computation conference gecco pages asymmetric recurrent neural networks using pdgp-inspired two-dimensional representation. proceedings first european workshop genetic programming pages berlin springer-verlag valenzuela-rend´on. fuzzy classiﬁer system classiﬁer system continuously varying variables. proceedings fourth international conference genetic algorithms pages morgan kaufmann dynamics conceptual framework biomolecular networks. schlosser wagner editors modularity development evolution pages chicago university press", "year": 2012}