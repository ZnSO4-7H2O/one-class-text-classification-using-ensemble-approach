{"title": "Multi-task Recurrent Model for Speech and Speaker Recognition", "tag": ["cs.CL", "cs.LG", "cs.NE", "stat.ML"], "abstract": "Although highly correlated, speech and speaker recognition have been regarded as two independent tasks and studied by two communities. This is certainly not the way that people behave: we decipher both speech content and speaker traits at the same time. This paper presents a unified model to perform speech and speaker recognition simultaneously and altogether. The model is based on a unified neural network where the output of one task is fed to the input of the other, leading to a multi-task recurrent network. Experiments show that the joint model outperforms the task-specific models on both the two tasks.", "text": "utilized improve speaker recognition moreover combination systems already gained attention. instance speech speaker joint inference proposed lstm-based multi-task model proposed although highly interesting research considered multi-task learning speech speaker recognition systems designed trained executed independently. development deep learning techniques speech processing provides hope multi-task learning. since deep recurrent neural networks become state-of-the-art architectures speech recognition recently architecture gained much success speaker recognition least text-dependent conditions tasks deep learning delivers main advantages ﬁrst structural depth extracts task-oriented features second temporal depth accumulates dynamic evidence. similarity model structure simple question rises single model perform tasks together? indeed ‘multi-task learning’ known working well boost correlated tasks example multilingual speech recognition known sharing lowlevel layers dnns improve performance language another experiment phone grapheme recognition treated correlated tasks central idea multi-task learning deep learning correlated tasks share feature extraction low-level layers dnns tasks shared. however feature-sharing architecture apply speech speaker recognition. tasks actually ‘negatively correlated’ speech recognition requires features involving much content information speaker variance removed; speaker recognition requires features involving much speaker information linguistic content removed. tasks feature sharing certainly applicable. unfortunately many tasks negatively correlated e.g. language identiﬁcation speaker recognition emotion recognition speech recognition. finding multi-task learning approach abstract—although highly correlated speech speaker recognition regarded independent tasks studied communities. certainly people behave decipher speech content speaker traits time. paper presents uniﬁed model perform speech speaker recognition simultaneously altogether. model based uniﬁed neural network output task input other leading multi-task recurrent network. experiments show joint model outperforms task-speciﬁc models tasks. speech recognition speaker recognition important research areas speech processing. traditionally tasks treated independently studied independent communities although researchers indeed work areas. unfortunately human processes speech signals always decipher speech content meta information together simultaneously including languages speaker characteristics emotions etc. ‘multi-task decoding’ based foundations human capabilities share signal processing pipeline aural system mutually beneﬁcial success task promotes others’ real life. therefore believe multiple tasks speech processing performed uniﬁed artiﬁcial intelligence system. paper focuses speech speaker recognition demonstrates tasks solved single uniﬁed model. fact relevance speech speaker recognition recognized researchers long time. hand tasks share many common techniques mfcc feature extraction modeling; hand researchers areas used learning other. instance success deep neural networks speech recognition motivated neural model speaker recognition additionally researchers also know long time employing knowledge provided area often helps improve other. instance i-vectors produced speaker recognition used improve speech recognition phone posteriors derived speech recognition paper presents novel recurrent architecture used learn negatively-correlated tasks simultaneously. basic idea output task part input others. would ideal output task provide information others immediately feasible implementation. therefore output task previous time step used provide information others current time step. leads inter-task recurrent structure similar conventional rnns though recurrent connections link different tasks. employed multi-task recurrent learning speech speaker recognition observed promising results. idea illustrated fig. note similar multi-task architecture recently proposed difference focus speaker adaptation demonstrated improvement tasks joint learning. start single-task models sre. mentioned state-of-the-art architecture recurrent neural network especially long short-term memory model also delivers good performance therefore choose lstm build baseline single-task systems. particularly modiﬁed lstm structure proposed used. network structure shown fig. equations terms denote weight matrices associated cells diagonal implementation. terms denote bias vectors. input output symbols respectively; represent respectively input forget output gates; cell cell output. output components derived recurrent next time step recurrent contributes present output only. logistic sigmoid function non-linear activation functions often chosen hyperbolic. denotes element-wise multiplication. multi-task recurrent model basic idea multi-task recurrent model shown fig. output task current frame auxiliary information supervise tasks processing next frame. idea materialized computational model many alternatives need carefully investigated. study recurrent lstm model shown previous section build component component shown fig. components identical structure accept input signal. difference trained different targets phone discrimination speaker discrimination. importantly inter-task recurrent links combine components single network shown dash lines fig. cell cell output output component even output another question computation block receive recurrent information. simply input variable also input gate output gate forget gate non-linear function actually augmenting recurrent information equal feed information simultaneously. note weight matrix introduced extra free parameter recurrent information feedback. moreover component information extracted necessarily different tasks component receives information. however study simply consider symmetric structure. multi-task recurrent model rather ﬂexible. structure shown fig. simple example recurrent information extracted recurrent projection nonrecurrent projection information applied non-linear function superscript denote tasks respectively. computation expressed follows proposed method tested database labelled word transcripts speaker identities. ﬁrst present baselines report multi-task model. experiments conducted kaldi toolkit training involves speech data randomly selected train consists speakers utterances utterances speaker. used train lstm-based single-task systems i-vector baseline proposed multi-task system. test involves three datasets consists speakers utterances. dataset used evaluate performance sre. evaluation consists target trials constructed based test set. system built largely following kaldi nnet recipe except used single lstm layer simplicity. dimension cell dimensions recurrent nonrecurrent projections target delay frames. natural stochastic gradient descent algorithm employed train model input feature dimensional fbanks symmetric -frame window splice neighboring frames. output layer consisted units equal total number pdfs conventional system trained bootstrap lstm model. baseline performance reported table acoustic feature dimensional mfccs. number gaussian components dimension i-vectors r-vector system architecture similar used lstm-based baseline except dimension cell dimensions recurrent nonrecurrent projections additionally target delay. input rvector system system output corresponding speakers training set. similar work speaker vector derived output recurrent nonrecurrent projections averaging output frames. dimension baseline performance reported table observed i-vector system generally outperforms rvector system. particularly discriminative methods offer much signiﬁcant improvement ivector system r-vector system. observation consistent results reported attributed fact r-vector model already learned ‘discriminatively’ lstm structure. reason consider simple cosine kernel scoring rvectors following experiments. ﬂexibility multi-task recurrent lstm structure possible evaluate conﬁgurations. chose typical ones report results table iii. show results combined dataset mentioned before. note last conﬁgure recurrent information gates non-linear activation equal augmenting information input variable results shown table ﬁrst observe multi-task recurrent model consistently improves performance matter recurrent information extracted applies. interestingly task multi-task system obtain equal even better performance i-vector/plda system. ﬁrst time negatively-correlated tasks learned jointly uniﬁed framework boost other. recurrent information looks like recurrent projection sufﬁcient provide valuable supervision partner task. involving information nonrecurrent projection offer consistent beneﬁt. observation however based present experiments. data likely information leads additional gains. recurrent information ‘receiver’ i.e. component receives recurrent information seems input gate activation function equally effective output gate seems appropriate. results seem good. again observations based relative small database; data performance different conﬁgurations become distinguishable. report novel multi-task recurrent learning architecture jointly train multiple negatively-correlated tasks. primary results database demonstrated presented method learn speech speaker models simultaneously improve performance tasks. future work involves analyzing factors target delay exploiting partially labelled data applying approach negatively-correlated tasks. dahl deng acero context-dependent pretrained deep neural networks large-vocabulary speech recognition audio speech language processing ieee transactions vol. hinton deng dahl a.-r. mohamed jaitly senior vanhoucke nguyen sainath deep neural networks acoustic modeling speech recognition shared views four research groups signal processing magazine ieee vol. variani mcdermott lopez moreno gonzalezdominguez deep neural networks small footprint text-dependent speaker veriﬁcation proceedings ieee international conference acoustics speech signal processing ieee senior lopez-moreno improving speaker independence i-vector inputs. proceedings ieee international conference acoustics speech signal processing ieee ferrer mclaren novel scheme speaker recognition using phonetically-aware deep neural network proceedings ieee international conference acoustics speech signal processing modeling speaker variability using long shortterm memory networks speech recognition proceedings annual conference international speech communication association senior beaufays long short-term memory recurrent neural network architectures large scale acoustic modeling proceedings annual conference international speech communication association heigold moreno bengio shazeer end-to-end textdependent speaker veriﬁcation arxiv preprint arxiv. wang zheng transfer learning speech language processing proceedings apsipa annual summit conference. apsipa j.-t. huang deng gong cross-language knowledge transfer using multilingual deep neural network shared hidden layers proceedings ieee international conference acoustics speech signal processing ieee chen qian multi-task learning text-dependent speaker veriﬁcation proceedings annual conference international speech communication association povey ghoshal boulianne burget glembek goel hannemann motlicek qian schwarz kaldi speech recognition toolkit ieee workshop automatic speech recognition understanding epfl-conf-. ieee signal processing society", "year": 2016}