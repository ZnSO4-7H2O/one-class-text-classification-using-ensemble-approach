{"title": "Approximate Separability for Weak Interaction in Dynamic Systems", "tag": ["cs.LG", "cs.AI", "stat.ML"], "abstract": "One approach to monitoring a dynamic system relies on decomposition of the system into weakly interacting subsystems. An earlier paper introduced a notion of weak interaction called separability, and showed that it leads to exact propagation of marginals for prediction. This paper addresses two questions left open by the earlier paper: can we define a notion of approximate separability that occurs naturally in practice, and do separability and approximate separability lead to accurate monitoring? The answer to both questions is afirmative. The paper also analyzes the structure of approximately separable decompositions, and provides some explanation as to why these models perform well.", "text": "approach monitoring dynamic system relies decomposition system weakly interacting subsystems. earlier paper introduced notion weak interaction called separability showed leads exact propagation marginals prediction. paper addresses questions left open earlier paper dene notion approximate separability occurs naturally practice separability approximate separability lead accurate monitoring? answer questions armative. paper also analyzes structure approximately separable decompositions provides explanation models perform well. monitoring state dynamic system face uncertainty central task. perform task need compact probabilistic representations dynamic systems ecient accurate monitoring algorithms. dynamic bayesian networks provide compact representation exploiting conditional independencies hold variables. however exact monitoring dbns hard approximate algorithms needed. approach introduced boyen koller factor variables subsets. joint distribution variables approximated product marginal distributions factors. approach relies intuition complex system decomposed weakly interacting subsystems. exactly weak interaction mean? standard frame idea systems weakly interacting conditionally independent given small interface variables. works well static models. dynamic models shortrun independence lead long-run independence factors satisfy criterion become highly dependent. ideas suggested provide bounds error obtained using approximation terms several quantities. crucial mixing rate system intuitively rate system \\forgets\" errors. important determining method work well property system whole characterization weak interaction. quantities introduce number factors factor depends importantly number inuences. extend analysis introduce measure degree factors forget inuence factors. however bounds obtain using quantities quite weak reective method performs practice. earlier paper presented notion weak interaction based dierent question. question factor distributions obtained using approach correct? occur even though joint distribution product factor distributions. dened criterion called separability saying conditional probability distribution factor separable decomposed additively terms depending factors individually. showed factors separable marginal distributions correctly propagated time step next. however observations break property approach separable models produces exactly correct marginals prediction monitoring. paper left open important questions. whether separable models actually perform well monitoring task. reason believe might case correctly propagate marginal distributions dynamics introduce error conditioning observations unlike non-separable models kinds error. second question asks whether approximating separability property lead natural models still good performance. paper addresses questions. paper dene approximate separability show natural property hold real models. show experimentally simple examples separability approximate separability indeed lead good performance prediction monitoring tasks. thus approximate separability least examples appears sucient condition making work well. also show separability used produce better factorization system \\obvious\" one. analyze structure approximately separable models presenting method automatically determining degree separability conditional probability distribution. finally address question separable approximately separable models perform well monitoring task. first present bound monitoring error separable model simple special case. dene dierent possible sources error arise using approach show much less important other. turns separable models less important kind error simple examples studied goes towards explaining perform well examples. assume reader familiar dbns provide compact representation dynamic model. however monitoring dbns dicult even though variables conditionally independent short generally become dependent long run. result order exact monitoring needs maintain joint distribution state variables infeasible. therefore approximate monitoring algorithms needed. approach approximate monitoring introduced boyen koller approach variables divided factors consists subset variables. instead maintaining complete joint belief state marginal distributions maintained. marginals propagated time step next using junction tree constructed two-time-slice model every factor contained clique. means variable previous time point.) joint disi= provide bound expected distance between show grow time. previous paper asked circumstances approach work well. rather focus dierence however asked marginal equal true marginal answer question introduced notions suciency separability. denitions naturally generalized parents. turns properties equivalent sucient separable. note requirement contrast previous paper required statement separability suciency equivalent denitely holds denition given here. proof implies also holds stricter denition. statements together imply whenever separable decomposition gamma between also gamma unfortunately able prove paper sake ease presentation analysis assume factors disjoint. however ideas paper easily extended nondisjoint factors. indeed previous paper dened notion conditional separability applied non-disjoint factors. naturally extended approximate conditional separability. separability closely related context-specic independence viewed context variable explicitly appear model. separable models also closely related inuence model thus factor separable terms factors previous time step factors self-sucient. separability understood characterizing information dynamic system. intuitively says information factors previous time step factor current time step point time factors selected information one. given self-sucient factors correctly propagate marginal probabilities time step next. unfortunately however true propagating marginals dynamics. conditioning observations breaks property suciency. reason factors observation need know infer know this enough know marginals also need know joint distribution. general correct joint probability distribution factors using approach even separable models. thus propagating marginals separable models exact prediction task observations future monitoring task observations. ideas lead naturally questions. question given fact separable models lead correct propagation marginals dynamics also lead accurate monitoring? hope subject error conditioning observations total monitoring error lower. second question addresses problem dening separable models practice. previous paper gave examples separable models general real-world models similar separability understand approximate separability intuitively characterizing information system. highly separable says information time other. often rare occasions information together. approximate separability also viewed approximate form csi. example tends take value high probability. however also inuence inuence ipped depending makes likely makes likely fact decomposition coincidence. however fact model not. persistence property things tend stay before. natural property dynamic systems. dierent factor small inuence given factor relative terms many times likely change given values others. figure shows performance various models prediction task observations. xaxis shows degree non-separability model left endpoint fully separable model right endpoint completely non-separable model. experiments performed small model factors variable noisy observation gure shows kl-distance true marginal approximate marginal obtained using approach averaged runs random parameters. theory predicts fully separable models zero error. interesting though shape curve. approximately separable models also error; even %-separability leads good performance. figure shows performance dierent models monitoring task. results averaged runs. news good. although theory predict separable models perform well fact small error. curve similar shape; approximately separable models small error. natural hypothesis separable models perform well examples factors less dependent other. turns case. figure shows degree dependence factors measured distance between true joint distribution product marginals. computed kind models figure figure lowest degree dependence actually attained models intermediate degree separability. example example shows using separability lead much better factorization dynamic system. figure shows structure six-node dbn. variables dependent similarly dependent interactions structure suggests natural factorization factors however suppose follows highly separable terms highly non-separable terms cpds similarly designed turns self-sucient factors not. suggests better factorization. note case together smaller inuence theremonitoring results observed follows average absolute error factorization factorization similarly average distance marginal factorization factorization. thus factorization based separability lead much better performance \\obvious\" one. constrained however constraint since degree separability make sense model completely separable. special cases program solved directly. examining special cases yields insights structure approximately separable decompositions. natural questions arise immediately approximately separable models look like perform well least examples studied? section analyze structure approximately separable decompositions presenting method determine degree separability model. notation refers i-th possible value goal given optimal approximately separable decomposition. general formulated linear programming problem symmetric result left hand side negative. must either equality test thus pattern example coincidence. value recover shown always exists feasible solution variables though might negative. intuitively degree deviation situation inuence depend state determined positive deviations. therefore deviations dierent states together limit degree separability. would seem sight states deviations together dicult attain high degree separability. however many states probability mass divided among states would expect individual deviations smaller. thus balance equally difcult achieve high degree separability whether many states. inuence would accumulate would necessarily reduced. case degree separability would inversely proportional number values instead depends maximum minimum deviations. would still expect decrease number values degree. attempt answer question separable models appear perform well prove bound expected error special case separable models. models hidden binary variables depend binary observation depends separable parameterization clear constraints satised constraints higher satisfy those. i.e. partial deviations. appears constraints maximum positive minimum negative place strongest constraints ck). ensure degree inuence changes equal compared maximum minimum changes determines interesting encouraging thing positive absolute negative deviations determine might thought several positive error bound depends number quantities characterizing system. dene following quantities characterize degree value parent previous time step inuences child current time step maintained algorithm. dene error measures. called joint error denoted distance true joint distribution current time point product marginals. second called marginal error denoted distance true marginal time point approximate marginal produced method. following theorem bounding expressions complicated interesting. however provide quite good bounds marginal error. also intuition behind proof informative lemmas describe error develops. based theorem produce average bound error marginal taken random parameterizations compares true average error thus bound less three times actual error. proof result based idea separable model system makes kinds moves illustrated figure kind move variables current time point depend variable previous time point. second kind move depend dierent variables previous time point. addition moves shown gure symmetric moves. four moves chosen point time moves actually chosen process switches dierent kinds moves. point kind move previous joint error forgotten because variable previous time point affects current state. second type move marginal error introduced ignoring dependencies variables conditioning observation. however joint error introduced. eects combine keep marginal error small. particular kind move error characterized follows thus joint error kind move depend previous error error depends degree parent inuences makes sense. depend previous dependence introduced them. error also less informative observation. somewhat surprising makes sense consider perfectly informative evidence serves completely decouple thus marginal error depends marginal error weaker inuence error forgotten. turns marginal error depends complicated expression still main components. results ignoring previous joint error i.e. dependencies factors. component decreases lack inuence parents respective children uninformativeness observation. note eect observation dierent before. uninformative observations lead lower error. second component marginal error result previous marginal error forgotten proportion lack inuence second analysis examines dierent sources error arise approach. identify sources error. following present sources error system factors concepts generalize factors. experiments consider two-factor case. source error called type results taking account previous dependencies factors propagating dynamics obtain prior distribution current time point. approximate posterior distribution previous state marginals. type error error results instead computing prior second source error called type results taking account previous dependencies factors conditioning observations obtain posterior distribution. must pointed dependencies factors taken account conditioning. dependencies introduced single step dynamics fact dierent variables depend variable previous time step. dependencies held factors previous time point taken account. type error produced prior computed marginals thus prior marginals obtained beginning approximate posterior previous time point assuming factors independent. marginals incorporate type error. paper presented approximate separability characterization weak interaction dynamic systems. approximate separability leads accurate propagation marginals using factored approach monitoring. analyzed structure approximately separable models provided explanation perform well. experimentation needed wider array examples strengthen conclusions paper. addition would interesting forms weak interaction noisy-or also allow work well. important open issue dening notion approximate separability continuous variables. another issue explore fully exploiting approximate separability improve eciency perhaps extending ideas would also useful decompose system automatically weakly interacting factors.", "year": 2012}