{"title": "Detecting Dependencies in Sparse, Multivariate Databases Using  Probabilistic Programming and Non-parametric Bayes", "tag": ["stat.ML", "cs.AI", "cs.LG"], "abstract": "Datasets with hundreds of variables and many missing values are commonplace. In this setting, it is both statistically and computationally challenging to detect true predictive relationships between variables and also to suppress false positives. This paper proposes an approach that combines probabilistic programming, information theory, and non-parametric Bayes. It shows how to use Bayesian non-parametric modeling to (i) build an ensemble of joint probability models for all the variables; (ii) efficiently detect marginal independencies; and (iii) estimate the conditional mutual information between arbitrary subsets of variables, subject to a broad class of constraints. Users can access these capabilities using BayesDB, a probabilistic programming platform for probabilistic data analysis, by writing queries in a simple, SQL-like language. This paper demonstrates empirically that the method can (i) detect context-specific (in)dependencies on challenging synthetic problems and (ii) yield improved sensitivity and specificity over baselines from statistics and machine learning, on a real-world database of over 300 sparsely observed indicators of macroeconomic development and public health.", "text": "datasets hundreds variables many missing values commonplace. setting statistically computationally challenging detect true predictive relationships variables also suppress false positives. paper proposes approach combines probabilistic programming information theory non-parametric bayes. shows bayesian non-parametric modeling build ensemble joint probability models variables; eﬃciently detect marginal independencies; estimate conditional mutual information arbitrary subsets variables subject broad class constraints. users access capabilities using bayesdb probabilistic programming platform probabilistic data analysis writing queries simple sql-like language. paper demonstrates empirically method detect context-speciﬁc dependencies challenging synthetic problems yield improved sensitivity speciﬁcity baselines statistics machine learning real-world database sparsely observed indicators macroeconomic development public health. appearing proceedings international conference artiﬁcial intelligence statistics fort lauderdale florida usa. jmlr w&cp volume copyright author. dictive relationships variables first data incomplete require cleaning imputation pairwise statistics calculated. second parametric modeling assumptions underlie standard hypothesis testing techniques appropriate nonlinear multivariate and/or heteroskedastic relationships. third number variables grows becomes harder detect true relationships suppressing false positives. many approaches proposed summary) exhibit limitations practice. example apply fully-observed real-valued data produce probabilistically coherent measures uncertainty. paper proposes approach dependence detection combines probabilistic programming information theory non-parametric bayes. end-toend approach summarized figure queries conditional mutual information between variables interest expressed using bayesian query language sql-like probabilistic programming language. approximate inference crosscat produces ensemble joint probability models analyzed structural dependencies. model structures dependence cannot ruled estimated monte carlo integration. principle approach signiﬁcant advantages. first method scalable high-dimensional data used exploratory analysis without requiring expensive estimation pairs variables. second applies heterogeneously typed incomplete datasets minimal pre-processing third non-parametric bayesian joint density estimator used form estimates model broad class data patterns without overﬁtting highly irregular data. paper shows proposed approach eﬀective real-world database hundreds variables missing data rate detecting common-sense predictive relationships missed baseline methods suppressing spurious relationships baselines purport detect. figure workﬂow computing posterior distributions variables data table using bayesdb. modeling inference bayesdb produces ensemble posterior crosscat samples. model learns factorization joint distribution variables database dirichlet process mixture within block dependent variables. instance model speciﬁes independent turn independent variables dependent. end-user queries expressed bayesian query language. interpreter uses crosscat structures optimize query possible bypassing monte carlo estimation completely queried variables structurally independent and/or dropping redundant constraints structurally independent queried variables. values returned model constitute samples posterior distribution. denote d-dimensional random vector whose sub-vectors denote joint probability density symbol refers arbitrary speciﬁcation generative process parameterizes joint conditional densities. mutual information variables deﬁned usual mutual interpreted kl-divergence product marginals pgpg joint distribution well-established measure existence strength dependence given observation variables {xc= ˆxc} conditional mutual information given {xc= ˆxc} deﬁned analogously open problem literature. various parametric non-parametric methods estimating exist comprehensive review. traditional approaches typically construct point estimate assuming true value paper instead take non-parametric bayesian approach mutual information derived random variable; similar interpretation recently developed independent work randomness mutual information arises treating data generating process parameters random variable whose prior distribution denote composing function induces derived random variable distribution thus expressed expectation distribution monte carlo estimates formed models expressed generative population models probabilistic programming formalism characterizing data generating process inﬁnite array realizations random vector listing summarizes elements interface. gpm-cmi unbiased consistent estimator applicable probabilistic model implemented quality detecting dependencies tied ability capture patterns dataset paper uses baseline non-parametric gpms built using crosscat marginal independence straightforward event context-speciﬁc {xc= ˆxc} decouples said independent context denoted condition equivalent equaling zero. thus estimating able detect ﬁner-grained independencies detected analyzing graph structure learned bayesian network figure illustrates diﬀerent queries used discover three types dependencies various data generators; figure shows queries expressed bayesian query language. approach estimating requires prior model class ﬂexible enough emulate arbitrary joint distribution tractable enough implement algorithm arbitrary sub-vectors. begin dirichlet process mixture model letting denote likelihood variable prior parameters hyperparameters generative process gamma refer algorithms posterior inference assume posterior sample {φd}) parameters dpmm. compute arbitrary query pattern using algorithm need implementations simulate logpdf procedures summarized algorithms algorithm dpmm-simulate require dpmm target condition ensure joint sample categorical return algorithm dpmm-logpdf require dpmm target ˆxa; condition ensure density return ﬁrst three plots verify marginally dependent. next three plots show conditioning decouples children decoupling weaker nats less likely ﬁnal plot shows weighted possibilities. figure posterior distributions dpmm posterior given data points canonical bayes structures. distributions peaked indicate high probability independence. cases posterior distributions correctly detect marginal conditional context-speciﬁc independences ground truth bayes nets despite fact common-cause common-eﬀect structures hypothesis space dpmm prior. subroutine dpmm-cluster-posterior used sampling marginalizing non-parametric mixture components. moreover form conjugate likelihood-prior pair invocations algorithms rao-blackwellized conditioning suﬃcient statistics data cluster thus marginalizing optimization important practice since analytical marginalization obtained closed-form several likelihoods exponential family finally approximate posterior distribution suﬃces aggregate dpmm-cmi ∼iid figure posterior samples multivariate dpmm makes restrictive assumption variables marginally dependent joint distribution fully factorizes conditioned mixture assignment high-dimensional datasets imposing full structural dependence among variables conservative. moreover monte carlo error algorithm scale dimensionality runtime scales linearly dpmm estimating likely prohibitively expensive. relax constraints using crosscat structure learning prior induces sparsity dependencies variables particular crosscat posits factorization accordfigure end-user queries bayesian query language three data analysis tasks; evaluating strength predictive relationships; specifying amount evidence required predictively signiﬁcant relationship; synthesizing hypothetical population censoring probably sensitive variables. proof. refer appendix immediate consequence lemma structure discovery crosscat allows optimize monte carlo estimation ignoring target condition variables block shown algorithm figure algorithm crosscat-cmi require crosscat query condition ˆxc; acc. ensure monte carlo estimate else within block variables distributed according multivariate dpmm; subscripts index block-speciﬁc dpmm parameters. joint predictive density given algorithm figure posterior probability dimensions bivariate gaussian dependent covariance crosscat upper bound useful detecting existence predictive relationship; posterior distribution determine whether strength relationship predictively signiﬁcant based various tolerance levels section illustrates eﬃcacy proposed approach sparse database ongoing collaboration bill melinda gates foundation. gapminder data extensive longitudinal dataset global developmental indicators countries spanning centuries include variables broad categories education health trade poverty population growth mortality rates. experiment cross-sectional slice data figure shows pairwise correlation values variables; column heatmap indicator dataset color cell value figure shows pairwise binary hypothesis tests independence using hsic detects dense dependencies including many spurious relationships methods statistically insigniﬁcant relationships shown figure shows upper bound pairwise probability variables exceeds zero entries estimated using using samples figure comparing runtime crosscat-cmi gpm-cmi randomly generated queries dimensional dataset. dashed curve shows degree line. green dots correspond crosscat detecting structural independence query variables bypassing monte carlo estimation completely. blue dots correspond crosscat optimizing monte carlo estimator ignoring constraint variables structurally independent target variables. dots correspond crosscat learning structural independences requiring full monte carlo estimation resulting comparable runtime dpmm. three cases correspond three posterior crosscat structures illustrated figure targets variables conditioned lemma used addend line zero. also note summand computed crosscat sample ˆgh. dependencies among variables sparse many pairs upper bounded number invocations algorithm required compute pairwise values comparison upper bounding versus exact estimation monte carlo shown figure pairwise heatmaps variables gapminder dataset using three dependency detection techniques. darker cells indicate detected dependence variables. instructive compare dependencies detected crosscat-cmi. table shows pairs variables spuriously reported dependent according correlation; scatter plots reveal either sparsely observed exhibit high correlation large outliers. table shows common-sense relationships pairs variables crosscat-cmi detects not; scatter plots reveal either non-linearly related roughly linear heteroskedastic noise pairwise independent dependent given third variable. recall crosscat product dpmms; practically meaningful conditions weak strong consistency dirichlet location-scale mixtures established supports intuition crosscat detect broad class predictive relationships simpler parametric models miss. figure focuses group four trade-related variables gapminder dataset detected probably dependent trade balance total goods traded exports goods services imports goods services. fails detect statistically signiﬁcant dependence trade balance variables weak linear correlations heteroskedastic noise shown scatter plots economics four variables causally related graphical model figure value node noisy addition subtraction values parents. figure illustrates crosscat recovers predictive relationships variables conditioning exports= balance= centers posterior predictive distribution imports around decouples total goods. posterior curves imports total goods withconditions exports balance formalize decoupling broad acknowledgment techniques dependency detection beyond linear correlation required. existing approaches conditional independence testing include kernel methods copula functions char left plot shows joint posterior density imports goods marginal coupling common parent center plot shows distribution conditioned exports= balance=; imports centers around noiseless value decoupled goods. right plot shows distributions. acteristic functions many capture nonlinear multivariate predictive relationships. unlike methods however approach represents dependence terms conditional mutual information embedded frequentist decisiontheoretic framework. quantity interest full posterior distribution opposed p-value identify null hypothesis cmi= cannot rejected. dependence detection much less studied bayesian literature; polya tree prior compute bayes factor relative evidence dependence versus independence. method used quantify evidence existence assess strength predictive relationship. similar approach work proposed independently recent work compute distribution estimating joint density using encompassing non-parametric bayesian prior. however diﬀerences signiﬁcant. first monte carlo estimator based resampling empirical data. however real-world databases sparse resampling data yield good estimates especially queries given unlikely constraints. instead monte carlo estimator simulating predictive distribution. second prior standard dirichlet process mixture model whereas paper proposes sparsity-inducing crosscat prior permits optimized computations upper bounds posterior probabilities well simplifying queries multivariate conditions. paper shown possible detect predictive relationships integrating probabilistic programming information theory non-parametric bayes. users specify broad class conditional mutual information queries using simple sql-like language answered using scalable pipeline based approximate bayesian inference. underlying approach applies arbitrary generative population models including parametric models classes probabilistic programs work focused exploiting sparsity crosscat model structures improve scalability exploratory analysis. foundation extend technique domains causal structure learning. estimator used conditional-independence test structure discovery algorithm also possible learned probabilities part prior directed acyclic graphs bayesian setting. paper focused detection preliminary assessment predictive relationships; conﬁrmatory analysis descriptive summarization left future work require assessment robustness joint density estimation random sampling assumptions violated. moreover algorithmic insights needed scale technique eﬃciently detect pairwise dependencies high-dimensional databases tens thousands variables.", "year": 2016}