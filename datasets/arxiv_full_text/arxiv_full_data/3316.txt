{"title": "Multiple Instance Dictionary Learning using Functions of Multiple  Instances", "tag": ["cs.CV", "cs.LG", "stat.ML"], "abstract": "A multiple instance dictionary learning method using functions of multiple instances (DL-FUMI) is proposed to address target detection and two-class classification problems with inaccurate training labels. Given inaccurate training labels, DL-FUMI learns a set of target dictionary atoms that describe the most distinctive and representative features of the true positive class as well as a set of nontarget dictionary atoms that account for the shared information found in both the positive and negative instances. Experimental results show that the estimated target dictionary atoms found by DL-FUMI are more representative prototypes and identify better discriminative features of the true positive class than existing methods in the literature. DL-FUMI is shown to have significantly better performance on several target detection and classification problems as compared to other multiple instance learning (MIL) dictionary learning algorithms on a variety of MIL problems.", "text": "class-speciﬁc features mixed background features spread across atoms. contrast dl-fumi provides insight pulling unique target characteristics identifying atoms contain characteristics. summary dl-fumi advances discriminative dictionary learning addressing multiple instance learning problems using shared background model resulting improved target characterization discrimination. variation supervised learning problems inaccurate label information. particular training data segmented positive negative bags. deﬁned multi-set data points. case target detection problem requires positive contains least instance target class negative bags composed entirely non-target data. given training data form overall goal predict either unknown instance-level bag-level labels test data. methods effective problems accurately labeled training data unavailable. approaches focus learning classiﬁcation decision boundary distinguish positive negative instances/bags although decision boundary approaches effective training classiﬁers given inaccurate labels provide intuitive description representative concept characterizes salient discriminative features target class. approaches estimate target representatives often single target concept thus unable account large variation target class. address this dl-fumi learns target atoms characterize target variation. sparse coding refers task decomposing signal sparse linear combination dictionary atoms particular relevance supervised dictionary learning methods however among supervised dictionary learning methods approaches address problem given inaccurate labels. include mmdl trains many linear classiﬁers views estimated parameters dictionary atoms dmil learns class-speciﬁc abstract—dictionary learning functions multiple instances proposed address target detection problems inaccurate training labels. dl-fumi multiple instance dictionary learning method estimates target atoms describe distinctive representative features target class background atoms account shared features found across target non-target data points. experimental results show target atoms estimated dl-fumi discriminative representative target class comparison methods. dl-fumi shown improved performance several detection problems compared multiple instance dictionary learning algorithms. obtaining accurate training label information often time consuming expensive and/or infeasible large data sets. furthermore annotators inconsistent labeling providing inherently imprecise labels. thus many applications access inaccurately weakly labeled training data. sparse coding dictionary learning methods whose lowrank data representations generally reduce redundancy improve discrimination ability successfully applied many applications dl-fumi leverages beneﬁts discriminative dictionary learning target detection applications given inaccurate labels. accomplished novel model assumes target data point mixture target background atoms whereas non-target data points composed background atoms. words unlike majority discriminative dictionary learning methods dl-fumi learn separate dictionary class. instead dl-fumi introduces shared background dictionary used reconstruction target non-target points. advantage model class-speciﬁc dictionaries target atoms need account unique characteristics target resulting discriminative representative target atoms. furthermore target atoms estimated dl-fumi examined uncover discriminates target data points. since approaches estimate class-speciﬁc dictionaries dictionary must characterize class-speciﬁc characteristics characteristics shared among data points. thus methods often difﬁcult unique class without prior insight since second term regularization term promote sparse weights. also includes latent variables account uncertain presence target positive bags. third term robust penalty term promotes discriminative target atoms instead using ﬁxed penalty coefﬁcient introduce adaptive coefﬁcient deﬁned vector angle background atom target atom. since sign signd− discriminative term always positive large penalty term encourages discriminative dictionary promoting background atoms orthogonal target atoms. implementation updated iteration using iteration. expectation-maximization used optimize estimate optimization fact many binary latent variables {zi}n unknown addressed taking expected value likelihood respect shown parameters estimated iteration probability instance true target instance. e-step iteration computed ﬁxed scaling parameter. non-target instance characterized background atoms well thus otherwise true target instance characterized well using background atoms dictionaries maximizing noisy-or model negative instances poorly represented estimated target dictionary. outlined dl-fumi unique existing methods shared background dictionary. rd×n training data dimensionality instance total number training instances. data grouped bags associated binary bag-level labels denotes instance given training data form dl-fumi models instance sparse linear combination target and/or background atoms sparse vector weights instance positive bags contain least instance composed target accomplished minimizing proportional complete negative data log-likelihood subsets corresponding respectively. ﬁrst term computes squared residual error instance estimate using dictionary. term hidden binary latent variables {zi}n indicate whether instance target introduced. points negative bags points positive bags value unknown. also weight included ﬁxed parameter. weight fig. analysis sun-glasses detection using face database comparing dl-fumi dmil em-dd true positive rate false positive rate mi-svm mmdl also plotted. ﬁrst face experiment sun-glasses target concept. speciﬁcally positive training bags instances created. positive contained instances randomly selected images people wearing sunglasses; eight randomly chosen images people without sun-glasses. negative bags constructed randomly selecting instances images individuals wearing sun-glasses. test data included imagery used training. parameters dl-fumi experiment dictionary estimation target conﬁdence computed test instance following sec. receiver operating characteristic curve analysis conducted. fig. shows rocs obtained dl-fumi dmil em-dd obtained mi-svm mmdl also plotted. average tprs dl-fumi em-dd dmil runs shown table fprs average fprs classiﬁcation algorithms mmdl mi-svm respectively. fig. fig. show estimated target background atoms dl-fumi comparison methods respectively. estimate dmil background atoms ﬂipped sign positive negative bags re-trained dictionary. done since stated dmil learn background atoms simultaneously. shown dl-fumi target atoms discriminative representative target class e.g. male female sun-glasses atoms variation light reﬂections. finally overall dictionary estimated dl-fumi qualitatively smooth help reduce error classiﬁcation. m-step performed iteratively optimizing desired parameters. dictionary updated atom-by-atom using block coordinate descent scheme sparse weights {αi}n updated using iterative shrinkage-thresholding algorithm readability derivation update equations described sec. vii. method summarized alg. classification using estimated dictionary given conﬁdence instance target computed using ratio reconstruction errors given target background atoms background atoms dl-fumi evaluated face data recognition problems usps hand-written digits recognition problem. experiments target atoms initialized computing mean random subsets drawn union positive bags. k-means applied union negative bags cluster centers initial background atoms. ar-face data consists frontal-pose images images/person corresponding different expressions illuminations occlusions. preprocessed cropped imagery male female subjects provided martinez used. positive contained images woman second positive contained remaining images woman rest instances positive randomly selected individuals. three negative bags instances constructed randomly selecting images data excluding woman given this positive training instances negative training instances. difﬁcult problem sunglass detection. test data contained images woman images randomly selected images woman overlap training testing data. parameters used dl-fumi experiment rocs shown fig. average tprs dl-fumi em-dd dmil shown table fprs average fprs classiﬁcation algorithms mmdl misvm respectively. table fig. clearly show dlfumi outperforms comparison algorithms. order show estimated target dictionary dl-fumi effective characterizing target class subspace adaptive cosine estimator target detection algorithm applied detection using target dictionary estimated dl-fumi directly. subace rocs using dl-fumi dictionary shows fig. since subace target detection algorithm relies target signatures encompass distinguishing characteristics target class emphasizes target dictionary estimated dl-fumi highly representative target class. fig. show target atoms estimated dl-fumi dmil em-dd woman seen target dictionary atoms estimated dl-fumi discriminative captures different distinct features positive class fig. show background atoms estimated women seen background dictionary estimated dl-fumi better representative quality. size. gray-level pixel values used features experiment. training testing data partitions paper mimics experimental set-up speciﬁcally class positive training bags generated. contains instances total comes true positive class three instances randomly chosen classes. negatively labeled bags also constructed randomly selecting instances classes testing data contains samples total class. experiment parameters used instance level classiﬁcation approach described sec. applied given dictionary estimated given class target class. then ﬁnal class label multi-class classiﬁcation assigned selecting class largest conﬁdence value computed classiﬁcation results dl-fumi comparison algorithms listed table results gd-mil reported table shows dlfumi outperforms multiple instance dictionary learning methods gd-mil mmdl methods misvm em-dd. fig. show estimated dlfumi target non-target dictionary atoms dl-fumi able learn discriminative target dictionary well characteristic background dictionary insight classiﬁcation errors fig. show several examples randomly selected misclassiﬁed instances fig. show reconstructed images dlfumi. example fig. true class label misclassiﬁed reconstructed image shown fig. seen data point appears similar digit even difﬁcult human correctly recognize. similarly fig. show three images fig. show corresponding reconstructed images respectively. fig. examples misclassiﬁed images dl-fumi. true class misclassiﬁed true class misclassiﬁed true class misclassiﬁed true class misclassiﬁed corresponding reconstructed images dl-fumi paper multiple-instance dictionary learning alproposed. dl-fumi leverages gorithm dl-fumi shared information positive negative classes improve discriminative ability estimated target atoms. experimental results show estimated dl-fumi target atoms provide good representation positive class improves target detection classiﬁcation performance comparison methods. section provides derivation dl-fumi update equations. updating dictionary sparse weights {αi}n held ﬁxed. update atoms minimized respect corresponding atom keeping atoms constant. resulting update equations update using gradient descent method step length monotonically decreases value objective function λmax denotes maximum eigenvalue simplicity λmax ramirez sprechmann sapiro classiﬁcation clustering dictionary learning structured incoherence shared features ieee comput. vision pattern recognition bertsekas nonlinear programming. athena scientiﬁc mairal bach ponce sapiro online learning matrix factorization sparse coding mach. learning research vol. z.-h. zhou m.-l. zhang ensembles multi-instance learners european conf. mach. learning. springer kraut scharf mcwhorter adaptive subspace detectors", "year": 2015}