{"title": "Autonomous Grounding of Visual Field Experience through Sensorimotor  Prediction", "tag": ["cs.RO", "cs.AI", "cs.CV", "cs.LG"], "abstract": "In a developmental framework, autonomous robots need to explore the world and learn how to interact with it. Without an a priori model of the system, this opens the challenging problem of having robots master their interface with the world: how to perceive their environment using their sensors, and how to act in it using their motors. The sensorimotor approach of perception claims that a naive agent can learn to master this interface by capturing regularities in the way its actions transform its sensory inputs. In this paper, we apply such an approach to the discovery and mastery of the visual field associated with a visual sensor. A computational model is formalized and applied to a simulated system to illustrate the approach.", "text": "currently successful deep learning methods. however underlined ﬁnal supervision stage deep convolutional object recognition ﬁltered sensory inputs remain unintepreted naive agent. like static snow image ﬁltered generate one. noteworthy enough approaches focus processing sensory leave aside facet problem motor ﬂow. another approach required make initially unintepreted sensory input useful naive agent know world. sensorimotor approach perception inspired sensorimotor contingencies theory promising proposal claims perception mastering sensory inputs actively transformed actions. although original smct span larger scope arguments related cognition consciousness sensorimotor approach perception focuses pragmatical aspect claim. perception acquired letting robot explore world discover motor commands transform sensory inputs. intuitively means naive agent explore motor space check changes incoming static snow image. structure external world thus induce structure generated transformations. contrarily passive sensory processing though structure later useful agent describes navigate sensorimotor space allow select actions reach goal. core idea also blurs boundary perception action agent learns master interface world including perceives acts numerous experimental results suggest sensorimotor account perception relevant particular recent results show humans learn master visual ﬁeld ocular saccades transform visual sensory inputs precisely learn relations different sensory inputs encoding visual feature different positions retina well motor commands them. relation instance vertical edge precisely encoded fovea coarsely encoded projected periphery retina given saccade. shown artiﬁcial setups modiﬁed relations learned leading altered visual abstract—in developmental framework autonomous robots need explore world learn interact without priori model system opens challenging problem robots master interface world perceive environment using sensors using motors. sensorimotor approach perception claims naive agent learn master interface capturing regularities actions transform sensory inputs. paper apply approach discovery mastery visual ﬁeld associated visual sensor. computational model formalized applied simulated system illustrate approach. advocated developmental approach robotics truly autonomous agent explore environment learn interact tabula rasa agent implies discovering environment exist structure properties also exists interface external world body mediates perception action. knowledge emerge naive agent represents intimidating challenge. part traditional robotic approaches prefer relying engineers hand-code knowledge robots form sensory processing decision making control algorithms however priori deﬁnition perception action presents limitations risks. rigid allow robot adapt unforeseen conditions develop ways interact environment. moreover complex system’s designers encompass every aspect rich robot-environment interaction. engineers’ intuitions animals perceive might simply incorrect. order overcome limitations tackle initial challenge understanding naive agent learn interact world. problem following make sense uninterpreted sensorimotor naive agent access without priori knowledge incoming sensory like static snow screen furthermore necessarily encoding image outgoing motor unknown choice actions whose consequences world hidden. confronted difﬁculty large majority unsupervised approaches propose re-encode sensory information based statistical properties. instance case receptive ﬁelds saccadic motor outputs. initially agent naive doesn’t know relations. however discover exploring environment collecting modeling sensorimotor experiences shaped physical constraints. agent learns control interface world sensor constitutes knows different sensory inputs different parts retina correspond visual feature move visual features retina motor commands. number pixels receptive ﬁeld individual excitation pixel state denote saccadic motor commands agent generate multivariate random variable take values number motors individual excitation motor contributing sensor movement note superscript needed receptive ﬁelds moved together saccades. moreover motors could potentially redundant regarding sensor’s displacements world case agent would discover actual working space example sensorimotor structuring). naive agents consider speciﬁc policy explore world. consequently agent’s exploration strategy simply random commands similar motor babbling observed babies. describing probability transition pre-saccadic state receptive ﬁeld given realization saccade agent estimate probability exploring world compute statistics sensorimotor transitions data note temporal variable dropped future developments lighten notations. probabilistic approach nicely framework predictive modeling describes brain predictive machine applied capture sensorimotor contingencies physical embedding sensor world induce constraints agent’s experience; constraints appear structure predictive model. precisely speciﬁc sensorimotor transitions signiﬁcantly probable others correspond visual features shifting receptive ﬁelds saccades. evaluate fig. simpliﬁed illustration retina representing non-uniform distribution light-sensitive cells resulting variable sensory encoding visual features. visual features projected retina shift saccades. sensory encoding visual features depends projection lands. resolution instance signiﬁcantly higher fovea periphery. taking inspiration work sensorimotor approach perception paper proposes formalization visual ﬁeld mastery problem. directly line previous work simpler setup considered below computational model proposed describe sensorimotor transformations related moving visual sensor discovered captured naive agent. simulation introduced illustrate evaluate approach visual search task. finally results analyzed current limitations well future extensions approach discussed. interested agents equipped visual sensor array pixels collecting information limited part environment. taking inspiration human retina consider sensor array divided multiple receptive ﬁelds gathering small neighborhood pixels receptive ﬁeld considered independent sensor generating sensory inputs. note that like human retina receptive ﬁelds don’t necessarily share properties number relative positions nature light-sensible cells pixels case. visual feature visual information coming small part environment thus encoded differently depending receptive ﬁeld processes physical embedding visual sensor world structure latter visual features projected retina shift receptive ﬁeld receptive ﬁeld sensor moves relations thus exist sensory inputs different fig. simulated agent retina move simple environment made white squares black background. retina divided receptive ﬁelds organized layers artiﬁcially decreasing resolutions agent perform saccades shift whole visual scene receptive ﬁeld width directions. retinal projections transformed independently receptive ﬁeld generate sensory inputs. prototypes estimated represent sensory experience receptive ﬁeld using k-means algorithm. entropy measure unpredictability postsaccadic variable conditioned outcome pre-saccadic variable mutual information thus measure much information provides given saccade saccade mutual information thus signiﬁcantly lower pairs receptive ﬁelds visual features shift. relations sensor’s physical structure accessible naive agent. simple agent-environment system simulated order apply evaluate approach. illustrated fig. coarsely captures kind interaction moving environment. agent camera pixels retina. retina divided juxtaposed receptive ﬁelds size pixels. order mimic heterogeneous human retina resolution receptive ﬁeld artiﬁcially practically resolution reduced respectively keeping pixel every pixels rows columns small image received receptive ﬁelds. variable resolution reproduces signiﬁcant loss information center retina fovea periphery. interval extremas respectively corresponding excitation full excitation however order emphasize fact agent rely implicit structure data apply transformations disrupt sensory signal encoding first different linear transformations independently applied pixels retina modify excitation functions drawn transformation ﬁxed considered property sensor second pixels mixed forming sensory state vector order excitations appear vector doesn’t correspond topological organization pixels receptive ﬁeld. mixed order drawn randomly receptive ﬁeld considered ﬁxed property sensor agent’s sensory experience discretized considering receptive ﬁeld ﬁnite number prototype states number states receptive ﬁelds arbitrarily accordingly resolutions states generated data left partial presentation predictive model estimated agent. block corresponds pair receptive mutual information computed block represented matrix motor command saccade pairs receptive ﬁelds display high mutual information receptive ﬁelds visual features shift corresponding movement. residual mutual information blocks environmental structure disappear agent explores white noise visual scenes likewise ﬁnite number saccadic movements considered. correspond sensor’s translations retina plane central foveal receptive ﬁeld exchanges positions receptive ﬁelds layer chosen visual features completely shift receptive ﬁelds saccades. larger saccades could considered instance fovea exchange position others receptive ﬁelds. however purposefully kept reduce computational cost simulation would require parallel porting increase efﬁciency. simple artiﬁcial environments generated agent explore. like illustrated fig. images made black background white squares variable sizes randomly distributed. different environments generated way. simulation agent successively explores amount time. environmental simplicity allows easily keep track captured predictive model however shouldn’t considered drawback approach focus paper lies capturing sensor structure environmental properties. order estimate predictive model agent explores environment randomly generating saccades. number individual sensorimotor transitions experienced agent thus equal estimated based data j|sa gathers predictive models related receptive ﬁelds saccade forms small matrix corresponds pre-saccadic state column post-saccadic state according matrix thus deﬁnes conditional distribution visual search task proposed order illustrate estimated sensorimotor predictive model useful agent. latter placed environment similar ones explored learning process. repeatedly desired deﬁned. agent counterfactually search ﬁeld view perform saccade desired sensory selected looking visual features received receptive ﬁelds encoding projected fovea. ensures desired visual feature present current ﬁeld view desired sensory state potentially reached. moreover saccades receptive ﬁeld width considered learning layer receptive ﬁelds directly surrounding fovea considered search corresponds post-saccadic foveal sensory state. motor command thus maximizes mutual information receptive ﬁeld fovea. external point view saccade makes visual features shift receptive ﬁeld fovea. second saccade agent perform foveate desired visual feature determined fig. transformed saccade latter states determined considering receptive ﬁeld highest mutual information given saccade selecting highest probability sake visualization visual feature encoded sensory state estimated inverting sensory encoding corresponding receptive ﬁeld displayed right. claimed sec. physical embedding sensor world translated predictive model structure highly predictable sensorimotor transitions. illustrated fig. structure indeed observed block matrices predictive model blocks display stronger predictability patterns others formally measured easily visualized looking normalized mutual information computed block according depending executed saccade different pairs receptive ﬁelds display signiﬁcantly higher mutual information others omniscient point view conﬁrm pairs correspond receptive ﬁelds visual features shift corresponding saccade. mutual information matrix displays regular patterns saccade purposefully organized rows columns according receptive ﬁelds order retina. note however agent doesn’t access knowledge cannot take advantage patterns. also observe mutual information receptive ﬁelds binary spectrum intermediary values exist. variability fact predictive model captures structure induced visual sensor also structure induced environment. environment statistically displays local continuity neighboring receptive ﬁelds better predict state target receptive ﬁeld. intuitively receiving uniform black visual feature receptive ﬁeld allows instance agent fairly accurately predict neighboring receptive ﬁelds also receive uniform black feature. continuity property could taken advantage estimate topological different receptive ﬁelds proposed however although help external observer visualize data incentive naive agent build map. demonstrate impact environmental structure predictive model simulation random noise environment figure shows lack environmental structure removes intermediary values mutual information leave ones related actual sensor structure. coupled blocks induced sensor structure estimated predictive model also informs agent sensory states correspond visual feature encoded different parts retina. figure shows example sensory states different sensory states predict coupled receptive ﬁelds given motor commands. along sensory inputs agent access displayed actual visual features correspond observe group sensory states encodes visual feature nonetheless encoded different resolutions. agent thus estimate completely different sensory inputs actually correspond visual feature moreover knows motor action transforms other external point view corresponds making visual feature shift retina. inverting sensory encoding also reveals sensory inputs predicted time uncoupled blocks fig. correspond uniform white black features signiﬁcantly probable artiﬁcial environments. receptive ﬁeld doesn’t inform receptive ﬁeld predicting features safe estimate. finally also notice that resolution loss different retina layers association lower resolution pre-saccadic states higher ambiguous. intuitively resolution post-saccadic ones simply corresponds fact blurry pattern correspond multiple sharp ones. seen second panel fig. sensory state transforms saccade probability foveal state another visual feature also predicted probability note opposite true higher resolution patterns unambiguously predict lower resolution counterpart. argue rationale initially naive agent would naturally prefer foveal encoding visual feature compared every retina encoding unambiguously predict ones. also reason foveation seems like sensible objective visual search task. visual search task described sec. iii-c performed successive iterations. agent succeeded reaching desired foveal state every trial. remarkable success rate visual search task designed desired sensory state foveal reached iteration. however highlights quality estimated predictive model always associates paired sensory states different receptive ﬁelds. simple search task illustrates successfully agent predictive model estimated control initially unstructured sensorimotor interaction environment. paper proposed sensorimotor formalization problem naive agent autonomously learn master visual ﬁeld. computational model deﬁned applied simulated system illustrate agent discover regular transformations induced sensorimotor experiences physical embedding sensor world. transformations deﬁne different sensory inputs coming different parts sensor encode visual features motor commands transform others. regularities discovered exploring world later used agent internally simulate interactions world consequently select favorable action perform like illustrated simple visual search task. simulation also showed speciﬁc sensory states naturally emerge among different ones encode visual feature heterogeneous sensor. retina-like sensor case foveal encodings accurately predict others peripheral encoding higher resolution. future extensions approach illustrate core aspects sensorimotor approach perception. particular we’ll address problem autonomous emergence semantics. simulated agent identiﬁed different sensory states encode visual features seen ﬁrst step towards semantics. however convincing result show different features autonomously grouped together based abstract properties properties indeed identiﬁed corresponding sensory states transformed action. future developments also illustrate sensorimotor transformations organized hierarchical model latter used efﬁcient exploration environments. finally algorithm proposed paper ported beneﬁt parallel computing order evaluate realistic retina exploring complex environments. witzel cinotti o’regan what determines relationship color naming unique hues sensory singularities illuminations surfaces photoreceptors? journal vision vol. herwig schneider predicting object features across saccades evidence object recognition visual search. journal experimental psychology general vol. seth predictive processing theory sensorimotor contingencies explaining puzzle perceptual presence absence synesthesia cognitive neuroscience vol.", "year": 2016}