{"title": "The Sample Complexity of Online One-Class Collaborative Filtering", "tag": ["cs.LG", "cs.AI", "cs.IT", "math.IT", "stat.ML"], "abstract": "We consider the online one-class collaborative filtering (CF) problem that consists of recommending items to users over time in an online fashion based on positive ratings only. This problem arises when users respond only occasionally to a recommendation with a positive rating, and never with a negative one. We study the impact of the probability of a user responding to a recommendation, p_f, on the sample complexity, i.e., the number of ratings required to make `good' recommendations, and ask whether receiving positive and negative ratings, instead of positive ratings only, improves the sample complexity. Both questions arise in the design of recommender systems. We introduce a simple probabilistic user model, and analyze the performance of an online user-based CF algorithm. We prove that after an initial cold start phase, where recommendations are invested in exploring the user's preferences, this algorithm makes---up to a fraction of the recommendations required for updating the user's preferences---perfect recommendations. The number of ratings required for the cold start phase is nearly proportional to 1/p_f, and that for updating the user's preferences is essentially independent of p_f. As a consequence we find that, receiving positive and negative ratings instead of only positive ones improves the number of ratings required for initial exploration by a factor of 1/p_f, which can be significant.", "text": "user likes based ratings user large number users provided past. user-based algorithm ﬁrst identiﬁes similar users predicts ratings given user ratings provided similar users. practice recommender systems typically operate online fashion i.e. items recommended users time ratings obtained response recommendations used improve future recommendations. however many application areas recommender systems users occasionally rate ‘like’ never ‘dislike’. e.g. e-commerce amazon’s recommender system item recommended user user either purchases item indicates ‘like’ user purchase item. purchasing item however necessarily indicate ‘dislike’ since user might even considered recommendation. examples feedback include implicit ratings viewing webpage listening song business-to-business recommender systems problem generating recommendations based positive ratings known one-class lack negative ratings often considered make problem challenging however unclear whether fundamentally difﬁcult absence negative ratings identify user’s preferences sense sample complexity fundamentally larger. additionally little theoretical understanding probability user responding recommendation affects sample complexity one-class algorithm particular cold start time i.e. number recommendations algorithm needs invest learning user’s preferences able make good recommendations. paper address questions turn closely related. introduce probabilistic model oneclass online recommender system corresponding online user-based algorithm termed user-cf analyze performance. model elements algorithm inspired related model algorithm bresler two-class problem i.e. consider online one-class collaborative ﬁltering problem consists recommending items users time online fashion based positive ratings only. problem arises users respond occasionally recommendation positive rating never negative one. study impact probability user responding recommendation sample complexity i.e. number ratings required make ‘good’ recommendations whether receiving positive negative ratings instead positive ratings only improves sample complexity. questions arise design recommender systems. introduce simple probabilistic user model analyze performance online user-based algorithm. prove initial cold start phase recommendations invested exploring user’s preferences algorithm makes—up fraction recommendations required updating user’s preferences—perfect recommendations. number ratings required cold start phase nearly proportional updating user’s preferences essentially independent consequence that receiving positive negative ratings instead positive ones improves number ratings required initial exploration factor signiﬁcant. recommender systems seek identify subset large collection items user likes practice recommender systems often collaborative ﬁltering identify items given setup positive negative ratings available. nutshell user model latent probability preference vector describes extent likes dislikes item. similar users similar preference vectors. given time step user-cf algorithm recommends single item user typically different user. probability speciﬁed corresponding preference vector user likes dislikes recommended item. user likes item user rates probability user like item rating given. item rated cannot recommended again since rating often corresponds consuming item little point e.g. recommending product previously purchased past second time. practice probability could different user ease presentation assume constant users. goal user-cf algorithm maximize number recommendations users likes. user-cf algorithm consists exploitation step recommends items similar users rated positively kinds exploration steps; learn preferences users explore similarity between users. main result stated section guarantees certain cold start time user-cf algorithm items recommends order user fraction c/pf remaining recommendations given user-cf algorithm optimal. here learning rate chosen close zero number users numerical constant. cold start time required identify similar users learn preferences regarding items. also show algorithm make order recommendations make good recommendations therefore user-cf algorithm near optimal. fraction c/pf remaining time steps associated learning preferences users. ‘cost’ c/pf paid upfront paid continuously cold start time user-cf algorithm starts exploiting successfully. again fraction recommendations proportional necessary learn preference users. numerical results section show even data generated probabilistic model based real data cold start time fraction time steps required learn preferences users nearly proportional consequence result obtaining positive negative ratings instead positive ones improves number ratings required initial cold start period factor this note expected number ratings obtained user given number time steps equivalently given number recommendations proportional thus number ratings required initial cold start time inversely proportional number ratings required continuously learning preferences independent since corresponds users giving positive negative feedback number ratings required cold-start time factor larger number ratings required user-based algorithm obtains positive negative ratings. ﬁndings relevant design recommender systems since whether positive negative positive ratings obtained often incorporated design recommender system. therefore understanding associated beneﬁts costs terms sample complexity provided paper important. ﬁnally note goal paper improve upon state-of-the algorithms rather inform design algorithms expect terms sample complexity function various parameters involved. related literature best knowledge ﬁrst work analytically studies one-class online setting theoretical results established multiple class problems. ﬁrst analytical results user-based algorithms asymptotic performance guarantee probabilistic model established biau related approach collaborative-greedy algorithm studied bresler online twoclass problem. collaborative-greedy algorithm differs user-cf algorithm selecting nearest neighbors based thresholding similarity instead selecting similar users preferences users explored. difference exploration steps crucial establishing cold start period user-cf algorithm makes optimal recommendations fraction c/pf remaining time steps. dabeer studies probabilistic model online setup barman dabeer study probabilistic model ofﬂine setup state performance guarantees two-class user-based algorithm. closely related user-based item-based item-based exploits similarity item space recommending items similar given user rated positively past. results extend trivially item-based since corresponding analysis requires assumptions similarity item space additionally exploration strategies item-based algorithms considerably different. discuss item based algorithms here refer recent analysis item based algorithm two-class problem. next note deshpande montanari study recommender systems context multi-armed bandits speciﬁcally deshpande montanari consider model ratings described inner product user item feature vector assume item feature vectors given. conceptually related online learning problem multiarmed bandits dependent arms speciﬁcally variant multi-armed bandit problem arms grouped clusters arms within cluster dependent. assignments arms clusters assumed known. paper assume users cluster user types similar distributions. therefore learning problem paper viewed multi-armed bandit problem dependent arms assignment arms clusters unknown. finally note class learning problems reminiscent considered partial monitoring partial monitoring studied context recommender systems aware papers partial monitoring collaborative ﬁltering. outline section formally specify model motivate state problem. sections contain user-cf algorithm corresponding performance guarantee respectively. section provide numerical results real data. proof main result found supplementary material. model learning problem section introduce probabilistic model learning problem considered paper. mentioned previously model inspired two-class problem. model consider users items. user like item dislike item associated user latent preference vector whose entries probabilities user liking item assume item either likable user i.e. likable i.e. hidden ranking rhidden obtained random rhidden probability probability pui. rhidden ratings stochastic model users fully consistent rating; parameter quantiﬁes inconsistency one-class aspect incorporated model assuming users never reveal dislike item. lows. time step algorithm recommends single item user u—typically item different user—and obtains realization binary random variable bernoulli response independently across follows puipf puipf here corresponds probability user reporting positive rating. mentioned before might treat slightly general case probability different user ease presentation assume constant users. user consumes item recommended subsequent time steps. note means either user user like item assume user belongs user types. users belong type items likable i.e. {pui {pvi items require preference vectors users corresponding user type equivalent. note assumption could relaxed assuming users type share large fraction items likable. assume preference vectors belonging type similar belonging types. speciﬁcally assume subset users type smaller distinct users type users another type. further assume user likes least fraction items. assumption made avoid degenerate situations user like item. assuming users cluster user-item space different user types common implicitly used user-based algorithms perform well practice. justify assumption empirically plot figure clustering user ratings movielens million dataset figure shows user’s ratings cluster user item space. exploiting i.e. recommending items predicted likable based previous ratings. usercf algorithm formally introduced below performs time either preference exploration similarity exploration exploitation step. exploitation step ﬁrst identiﬁes similar users terms rating vectors given user rating vectors consist responses users recommendations made user-cf algorithm previous time steps. exploitation step proceeds recommending item received largest number positive ratings nearest neighbors previous time steps. exploitation step successful crucial similar users learn preferences effectively. accomplished similarity exploration steps recommend items users preference exploration steps recommend random items certain subsets users. formally stating user-cf algorithm illustrate main steps using example. users type items likable users belong second type items likable. preference vectors obtained executing time step preference exploration step recommends randomly chosen items users respectively similarity exploration step recommends item users. responses obtained similarity preference exploration step marked rectangles circles respectively. consider recommending item user exploitation step time nearest neighbors maximized item recommended user happens likable figure user-items rating matrix consisting subset movielens million dataset corresponding rated movies users rated movies. movielens dataset consists million movie ratings took ratings ratings missing ratings depicted black white gray. learning problem reward goal algorithm maximize reward. reasonable reward online problem expected number recommendations user rates positively i.e. pseudo-reward here item recommended time e-commerce setting corresponds number recommended products user buys. note uncertainty user liking item canrhidden expect better maximizing pseudo-reward. paper focus recommending likable items. following therefore consider closely related accumulated reward deﬁned expected total number likable items recommended algorithm time here {pui indicator random variable equal item recommended user time likable zero otherwise recommendations made previous time steps therefore random variable). containing responses user recommendations given previous similarity exploration steps time zero otherwise. moreover number users received recommendation finally user recommend item maximizes ˆpui items rated yet. idea behind user-cf algorithm follows. exploitation step recommends likable items neighbors user type items sufﬁciently well explored ˆpui indicates whether likable large portion ﬁrst steps likely spent similarity exploration. sensible need ensure satisﬁed order make good recommendations. time evolves user-cf algorithm randomly explores batches items batch time order estimate preferences users regarding items corresponding batches. note usercf algorithm would explore entire item space once e.g. recommending item chosen random items time required algorithm make ‘good’ recommendations would grow linearly might large. splitting item space batches user-cf algorithm start exploiting without learned preferences users regarding items. finally note user-cf algorithm recommend item several time steps sensible particular small. theorem suppose least users type user types condition holds ensures user types distinct. moreover assume least fraction items likable given user users. pick suppose sufﬁciently many users user type next formally describe user-cf algorithm explain intuition behind speciﬁc steps. input parameters user-cf algorithm learning rates relevant similarity preference exploration steps respectively batch size relevant preference exploration steps ﬁnally number nearest neighbors relevant exploitation steps. results guarantee range input parameters depends properties model number user types user-cf algorithm performs essentially optimally. prior knowledge model parameters practice optimize hyper-parameters user-cf algorithm using cross validation. initialization user-cf algorithm generates random permutation items required similarity exploration step. furthermore splits item space random equally sized subsets cardinality denoted time steps usercf algorithm performs preference exploration steps. time steps probabilities algorithm performs similarity exploration exploitation steps respectively. similarity exploration step user recommend ﬁrst item permutation recommended user previous steps algorithm. step explores item space important selecting ‘good’ neighborhoods. performing sufﬁcient number similarity exploration steps allows guarantee nearest neighbors given user type. preference exploration step time recommend user item chosen independently uniformly random rated previous time steps. step important learn preferences users. exploitation step users estimate probability liking given item here rating user item obtained previous time steps next users corresponding largest values vector assume simplicity divisible case batch simply contain less items. theorem states initial cold start time order tstart user-cf algorithm recommends likable items fraction time steps. follows since oracle recommends likable items obtains reward yields claim introduction cold start time fraction c/pf recommendations made user-cf algorithm likable. note condition allows number user types near linear number users note particular choice parameters user-cf algorithm theorem mainly expositional convenience; supplementary material contains general statement. theorem proven showing initial cold start time exploration steps recommend likable items high probability. exploration step recommends likable item user provided user types sufﬁciently distinct nearest neighbors user type. former ensured condition latter holds initial cold start time ensures sufﬁciently many similarity exploration steps executed. initial cold start time nearest neighbors user type essentially cost required learn neighborhoods. reﬂected lower bound terms depending becoming negligible becomes large compared tstart. note dependence tstart similar user types longer takes till user-cf guaranteed good neighborhoods. dependence nearly optimal cold start time user-cf algorithm guaranteed small learntheorem proportional rates scaling improved signiﬁcantly following results shows. proposition shows cold start time signiﬁcantly smaller problem instances algorithm mostly recommends non-likable items. proposition consequence fact making order recommendations many users obtain rating. consequence proposition cold start time user-cf algorithm near optimal. recall even initial cold start time constant recommendations might fraction non-likable. fraction cost establishing speciﬁcally order ensure user-cf algorithm needs recommend sufﬁciently many items neighbors ˆpui indicates whether user likes item precisely maximum ˆpui items rated corresponds likable item. established showing ˆpui likable items ˆpui items. since expected number positive ratings recommendation proportional number ratings required ensure proportional /pf. versus class recall implies users provide positive negative ratings user-cf algorithm nearly optimal since expected number ratings obtained user given number time steps proportional consequence result receiving positive negative ratings instead positive ones improves number ratings required initial exploration factor signiﬁcant. ﬁnally note bresler proved performance guarantee closely related two-class collaborative algorithm termed collaborative-greedy. bresler consider regime number users much larger number items i.e. additionally number user types obeys regime theorem particularized essentially reduces theorem however result particularized two-class case also holds number items much larger number users allows number user types near linear number users. improvement differences preference exploically ratings two-class version user-cf algorithm negative none positive rating obtained response recommendation. performed following experiment. user-cf algorithm recommends item user obtains rating response provided denotes entry rml) otherwise two-class user-cf algorithm obtains response. allow algorithms recommend item given user once time steps items recommend users. measure performance terms accumulated reward deﬁned item recommended user corresponding variant user-cf algorithm. results depicted figure show two-class recommender performs better expected since obtains signiﬁcantly ratings. speciﬁcally expected number ratings obtains almost twice expected number ratings one-class user-cf algorithm obtains. recommend likable items mostly non-likable left recommend explains inverse u-shape figure dependence user-cf next validate empirically cold start time number preference exploration steps scale respectively. start former. split items random disjoint sets equal cardinality. perform following experiment alternative exploration strategies sensible preference exploration strategies essential element approach split item space subsets items start exploring allow exploitation steps continue exploring allow exploitation steps forth. explores instead whole item space beginning learning time required ˆpui indicate whether item likable proportional therefore large. this consider preference exploration step recommends single item users chosen uniformly random items expected number ratings obtained executing preference exploration steps relevant estimating whether expected number neighbors recommend therefore proportional trk/m. ensure expectation larger order numerical results section simulate online recommender system based real-world data order understand whether user-cf algorithm behaves predicted theorem even data generated probabilistic model based real data. ideal dataset validate algorithm would consist ratings users items vast majority ratings standard datasets netﬂix movielens dataset unknown. obtain dataset higher proportion ratings following consider subset movielens dataset corresponding frequently rated items users rated many items. movielens dataset consists million movie ratings took ratings ratings missing ratings many items dataset signiﬁcant bias towards positive negative rating. make sure results exploiting biases select frequently rated items unbiased items. note nearest neighbor based algorithm like user-cf algorithm performs well case item ratings biased even neighborhoods randomly selected. resulting dataset denoted ratings remaining ones unknown therefore class versus class start comparing qualitative behavior user-cf algorithm two-class version user-cf algorithm. two-class version user-cf algorithm differs one-class version taking account negative ratings. specifbubeck sébastien cesa-bianchi nicolò. regret analysis stochastic nonstochastic multi-armed bandit problems. foundations trends machine learning deshpande yash montanari andrea. linear bandits high dimension recommendation systems. annual allerton conference communication control computing october heckel reinhard vlachos michail parnell thomas scalable interpretable proddünner celestine. recommendations overlapping co-clustering. ieee international conference data engineering figure left reward obtained single exploitation step performing similarity exploration steps ﬁxed number preference exploration steps. right reward obtained single exploration step performing preference exploration steps ﬁxed number similarity exploration steps. start recommending items chosen uniformly random user provided corresponding rating positive provide rating user-cf algorithm probability expected number positive ratings obtained therefore independent preference exploration steps make sure preferences items explored well. perform similarity exploration steps items sets im/−} recommending item user provide rating user-cf algorithm probability similarity exploration steps perform exploitation step. figure plot reward deﬁned obtained results conﬁrm exploitation step ts/p cold start time required ‘good’ neighborhoods scales inversely proportional since three curves other. next demonstrate number preference exploration steps required learn preferences users proportional /pf. perform experiment above time however ﬁrst perform similarity exploration steps items perform preference exploration steps recommending items chosen uniformly random user. before rating provided algorithm probability figure plot reward obtained performing single exploitation step preference exploration steps tr/pf. results indicate that predicted theory number preference exploration steps required learn preferences proportional curves different other. mentioned previously surprising number positive ratings obtained proportional kveton branislav szepesvari csaba zheng ashkan azin. cascading bandits learning rank cascade model. international conference machine learning pandey sandeep chakrabarti deepayan agarwal deepak. multi-armed bandit problems dependent arms. international conference machine learning icml york theorem suppose least users type user types assume least fraction items likable given user users. moreover suppose users satisfy condition pick suppose number nearest neighbors batch size parameter chosen convenience omit notion dependence signiﬁcance deﬁnitions hold simultaneously recommendation made user exploitation step time likable. therefore lower-bound reward follows follows moreover used fraction preference exploration steps time that note {ηqq performed preference exploration max-. ingredient bounds concentration inequalities particular version bernstein’s inequality proof union bound have proof neighbors. lemma subsets users type suppose that constant condition holds number suppose cardinality satisﬁes nearest neighbors satisﬁes desired. second inequality used proof next establish inequality recall similarity exploration step carried probability /t/). recall discussion inequality fraction time steps time max) binary random proof suppose consider user total number items likable cardinality note implies exist items likable recommended yet. therefore upper bound probability likable items left recommend here ﬁrst inequality follows assumption; second inequality follows ﬁrst inequality follows bernstein’s inequality ﬁnally last inequality holds assumption established using exact line arguments yields bound remains upper bound conclude proof needed establish maximum number neighbors pbad satisﬁes pbad follows directly noting that assumption upper-bounded ruπrvπ random permutation item space drawn user-cf algorithm initialization ruπrvπ binary random variable independent across success probability ﬁxed users different user types. similarly proof lemma start showing ruπrvπ random permutation item space ruπrvπ binary random variable independent across success probability puπpvπ. setting here follows bernstein’s inequality. speciﬁcally random permutation item space well ruirvi binary random variables independent across finally inequality used maxv /∈tu proof lemma assume w.l.o.g. case satisfy treated analogously. prove lemma assume pui. consider ﬁxed item good subset corresponding users type additionally recommendation made drawing items uniformly user cardinality good follows number users received recommendation upper bounded assuming adversarially recommendations given neighbors yield finally follows bernstein’s inequality; apply bernstein’s inequality used variance upper bounded good next note bayes theorem here inequality holds recommend item once). proceed upper bounding recall number times item recommended good neighbors consider random items recommended user; yields upper bound recall items chosen items that assumption neighbors least good. bernstein’s inequality consider given user time expected number ratings obtained upper bounded thus least fraction runs algorithm algorithm information user best recommend random item. choice preference vectors probability recommend likable item. therefore upper bound expected regret given", "year": 2017}