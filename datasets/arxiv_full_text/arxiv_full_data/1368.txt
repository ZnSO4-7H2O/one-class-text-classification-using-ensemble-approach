{"title": "Deep Learning For Smile Recognition", "tag": ["cs.CV", "cs.LG", "cs.NE"], "abstract": "Inspired by recent successes of deep learning in computer vision, we propose a novel application of deep convolutional neural networks to facial expression recognition, in particular smile recognition. A smile recognition test accuracy of 99.45% is achieved for the Denver Intensity of Spontaneous Facial Action (DISFA) database, significantly outperforming existing approaches based on hand-crafted features with accuracies ranging from 65.55% to 79.67%. The novelty of this approach includes a comprehensive model selection of the architecture parameters, allowing to find an appropriate architecture for each expression such as smile. This is feasible because all experiments were run on a Tesla K40c GPU, allowing a speedup of factor 10 over traditional computations on a CPU.", "text": "inspired recent successes deep learning computer vision propose novel application deep convolutional neural networks facial expression recognition particular smile recognition. smile recognition test accuracy achieved denver intensity spontaneous facial action database signiﬁcantly outperforming existing approaches based hand-crafted features accuracies ranging novelty approach includes comprehensive model selection architecture parameters allowing appropriate architecture expression smile. feasible experiments tesla allowing speedup factor traditional computations cpu. neural networks celebrating comeback term deep learning last years training many hidden layers allowing selflearn complex feature hierarchies. makes particular interest computer vision feature description long-standing issue. many advances reported period including training methods paradigm shift training cpus gpus. result advances allow train reliable models much faster. example resulted breakthroughs signal processing. nonetheless deep neural networks magic bullet successful training still heavily based experimentation. activation diﬀerent intensity levels. state-of-the approaches ﬁeld mostly rely hand-crafted features leaving potential higher accuracies. contrast ﬁelds face gesture recognition works deep learning applied facial expression recognition reported architecture parameters ﬁxed. aware publications architecture deep neural network facial expression recognition subject extensive model selection. allows learn appropriate architectures action unit. training neural networks diﬃcult cost functions many local minima. hidden layers diﬃcult training neural network. hence training tends converge local minimum resulting poor generalization network. order overcome issues variety concepts proposed literature named chapter. unsupervised pre-training methods autoencoders allow initialize weights well order backpropagation quickly optimize them. rectiﬁed linear unit dropout regularization methods. training methods concepts also lead signiﬁcant improvements shallow neural networks hidden layers. convolutional neural networks initially proposed lecun recognition hand-written digits. consists layers convolutional layer followed subsampling layer. inspired biological processes exploiting fact nearby pixels strongly correlated cnns relatively insensitive small translations rotations image input. training deep neural networks slow number parameters model. training described vectorized form possible massively parallelize modern gpus thousands cores therefore ideal candidate execution training neural networks. signiﬁcant speedups factor higher reported. diﬃculty write code. last years abstract libraries released. unit annotations diﬀerent levels intensity ignored following experiments action units either unset. disfa selected wider range databases popular ﬁeld facial expression recognition high number smiles i.e. action unit detail action unit images action unit images action unit all. fig. contains sample image disfa. original paper disfa multi-class svms trained diﬀerent levels action unit intensity. test accuracies individual levels binary action unit recognition problem reported three diﬀerent hand-crafted feature description techniques. three cases accuracies smile recognition reported. following experiments aligned version disfa used. aligned version faces cropped annotated facial landmark points. facial landmark points allow compute bounding mouth images. experiments inputs used architecture network follows input images convolution comprising convolutional subsampling layer. convolution followed convolutions become gradually invariant distortions input. second stage regular neural network follows convolutions order discriminate features learned convolutions. output layer consists units smile smile. novelty approach exact number convolutions number hidden layers size hidden layers ﬁxed subject extensive model selection sec. pooling). layers relu units except softmax used output layer. learning rate ﬁxed subject model selection would signiﬁcantly prolong model selection. considerations apply momentum ﬁxed entire database randomly split %/%/% training/validation/test ratio. training neural networks comes uncertainties mostly random initialization weights also random split data. evaluations shown similar experiments carried standard deviation test accuracy standard deviation performing experiment exactly bias therefore relatively safe reasons faster training time. throughout experiments classiﬁcation rate used accuracy measure. model implemented using lasagne generated cuda code executed tesla training allows perform comprehensive model selection feasible amount time. stochastic gradient descent batch size used. table contains four parameters optimized number convolutions number hidden layers number units hidden layer dropout factor. parameter optimized independently training time constraints. lead optimal model proven work empirically well. model trained epochs model selection. layers. case slight translations rotations mouth input stronger consequences classiﬁcation result. entire face sort distortions less problem parts face cheeks contribute smile recognition too. ﬁnal models trained epochs. test accuracies models started converge epochs. mouth face inputs best accuracies achieved epochs respectively. models signiﬁcantly outperform state-of-the-art baselines reported sec. ranging overall strong preference either mouth face input. experiments reduced dataset containing images action unit support hypothesis. concretely test accuracies mouth face input reduced respectively. thus diﬀerence models reduced time giving preference face input. nonetheless diﬀerence representative within experiment error standard deviation reported sec. training time epoch seconds seconds mouth face input models respectively. experiments shown training time mostly depends number convolutions. using tesla allowed speed training time factor execute code generated library. clearly deep learning umbrella term training neural networks potentially many hidden layers using training methods allowing learn complex feature hierarchies data. applied action unit recognition smile recognition particular deep convolutional neural network model overall accuracy signiﬁcantly outperforms existing approaches. underlying extensive model selection allows action unit appropriate architecture order maximize test accuracies. future extend model images multiple databases make predictions image sequences.", "year": 2016}