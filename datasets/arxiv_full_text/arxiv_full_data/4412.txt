{"title": "Appearance invariance in convolutional networks with neighborhood  similarity", "tag": ["cs.CV", "stat.ML"], "abstract": "We present a neighborhood similarity layer (NSL) which induces appearance invariance in a network when used in conjunction with convolutional layers. We are motivated by the observation that, even though convolutional networks have low generalization error, their generalization capability does not extend to samples which are not represented by the training data. For instance, while novel appearances of learned concepts pose no problem for the human visual system, feedforward convolutional networks are generally not successful in such situations. Motivated by the Gestalt principle of grouping with respect to similarity, the proposed NSL transforms its input feature map using the feature vectors at each pixel as a frame of reference, i.e. center of attention, for its surrounding neighborhood. This transformation is spatially varying, hence not a convolution. It is differentiable; therefore, networks including the proposed layer can be trained in an end-to-end manner. We analyze the invariance of NSL to significant changes in appearance that are not represented in the training data. We also demonstrate its advantages for digit recognition, semantic labeling and cell detection problems.", "text": "present neighborhood similarity layer induces appearance invariance network used conjunction convolutional layers. motivated observation that even though convolutional networks generalization error generalization capability extend samples represented training data. instance novel appearances learned concepts pose problem human visual system feedforward convolutional networks generally successful situations. motivated gestalt principle grouping respect similarity proposed transforms input feature using feature vectors pixel frame reference i.e. center attention surrounding neighborhood. transformation spatially varying hence convolution. diﬀerentiable; therefore networks including proposed layer trained end-to-end manner. analyze invariance signiﬁcant changes appearance represented training data. also demonstrate advantages digit recognition semantic labeling cell detection problems. recent successes deep learning partially attributed supervised training networks large numbers parameters using large datasets. computer vision supervised training convolutional networks large labeled datasets provide state-of-the-art solutions many applications object recognition image captioning question answering. shown convolutional networks generalization error generalization capability extend samples adequately represented training data. potential source mismatch training data distribution samples appearance. human images shown figure unambiguously represent digits whereas convolutional network trained original mnist dataset probability producing correct answer modiﬁed digit images. reason human easy time task previously exposed particular representations digits shown figure able adapt novel appearances learned concepts. invariances predetermined transformations translation rotation contrast noise taught network methods tangent prop data augmentation however methods adapt appearances shown figure similarly domain adaptation oﬀers solution suﬃcient number images target domain available. propose novel neighborhood similarity layer show used convolutional network greatly increase generalization accuracy novel appearances without requiring domain adaptation. motivated gestalt principle grouping respect similarity. speciﬁcally computes normalized inner products feature vectors previous layer central pixel acts frame reference spatial neighborhood pixel. parameter-free layer used early convolutional layers network seen inducing appearance invariance. show inclusion results good generalization accuracy classiﬁcation semantic labeling without using domain adaptation source target domains diﬀer. remarkably accuracy network trained mnist tested svhn without domain adaptation surpasses state-of-the-art domain adaptation results. cross-domain appearance invariance without domain adaptation step towards reasoning novel representations learned concepts. also show results improved used conjunction domain adaptation. finally demonstrate context cell detection improve accuracy introducing contrast invariance source target domains same. invariances predetermined transformations learned training. tangent prop penalizes derivative network’s output respect directions corresponding desired invariances rotation scale change. data augmentation seen non-inﬁnitesimal version tangent prop labeled samples generated chosen transformations used directly supervised training. type-invariant pooling creates compact decision layer data augmentation creating transformation invariant features rather capturing possible transformations. data augmentation also applied unlabeled samples penalizing diﬀerences network’s output transformed versions unlabeled sample contractive learning double backprop penalize magnitude derivative network’s output. corresponds promoting output varies slowly respect change input additive noise. adversarial training seen non-inﬁnitesimal version contractive learning. scattering convolution networks compute translation invariant descriptors also stable deformations. maxout networks also learn invariances present training data. however methods adapt variations novel appearances predeﬁned represented training data. unsupervised domain adaptation makes labeled data source domain unlabeled data target domain. co-training uses classiﬁers diﬀerent views generate pseudo-labels used domain adaptation high conﬁdence pseudo-labels slowly added labeled samples target domain. tri-training uses three classiﬁers generating pseudo-labels exclusively target domain. advantage tri-training co-training need partitioning input features diﬀerent views. methods unsupervised reconstruction task target domain supervised classiﬁcation task source domain residual transfer networks ease assumption shared classiﬁer source target domains domain adversarial networks gradient reversal layer extract domain invariant features classiﬁcation. features domain invariant domain classiﬁer predict domain input gave rise features came from. maximization domain classiﬁcation loss source train domain features replaced minimization maximum mean discrepancy. domain separation networks private features domain extracted separately common features. common component features used classiﬁcation purposes domains private common parts used reconstruction. recent work domain invariance forced feature representation rather recommended adapt source images target domain using generative adversarial networks perform classiﬁcation target domain only. domain adaptation possible target domain represented suﬃciently large samples used novel representation learned concept without accompanying target domain dataset. non-local means algorithm non-local means uses gaussian kernel euclidean distance directly space image intensities. proposed also applied directly input image values formulate layer used image feature generating layer network. explicit global perceptual grouping iterative inference deep fully connected networks investigated performs implicit local perceptual grouping feedforward convolutional network. finally using kernel mapping pairs pixels image introduced convolutional kernel networks related proposed nsl. however ckns learn ﬁxed convolutional masks images unsupervised supervised approximate kernel mapping argue leads quality approximations images appearances represented training data. furthermore choice gaussian kernel requires learning standard deviation ties mapping particular images. motivated gestalt principle similarity i.e. structures similar appearance grouped processed together perception. perspective network design used initial convolutional layers appearance invariance inducing transformation image feature maps. transforms input feature using feature vector pixel frame reference i.e. center attention surrounding neighborhood. formulate precisely ﬁrst deﬁne image feature maps neighborhood structures deﬁnition image feature n-dimensional vector valued function discrete d-dimensional image grid n-dimensional euclidean space. deﬁnition neighborhood structure ddimensional non-zero oﬀset vectors neighborhood pixel follows ordered paper taken square patch around excluding center pixel shown figure transformation feature similarity formulated deﬁnition given feature neighborhood structure neighborhood similarity layer vector normalized inner products emphasize following properties parameter free layer hence independent training data convolution spatially varying operation uses feature vectors pixel frame reference output feature dimensionality number pixels square patch vector corresponds square patch similarities around excluding placed feature producing layer network shown figure note that convolutional layer following operates feature vectors correspond square patches similarity vectors. number used diﬀerent layers network. paper experiments focused using single ﬁrst convolutional layer networks appearance invariance inducing transformation. even though parameter-free figure placed layers network. location computes neighborhood similarities creates image dimensional neighborhood similarities ﬂattened dimensional vectors creating output nsl. relationship similarity maps shown color coding. consider case input image consists foreground object background. denote conditional probability density functions foreground background respectively. denote apriori probability belonging foreground background respectively. then probability density function given pbpb. denote conditional expectation respectively. expected value found pbµb. centers subtracting mean unbiased estimator obtain compute conditional expectation consider neighborhood pixels without loss generality assume central pixel part foreground object. assuming independently drawn compute expectation numerator assuming suﬃcient discriminative capacity foreground background i.e. conclude output regardless whether function learned diﬀerent domain consistently positive belong region consistently negative not. furthermore variance distributions small compared ||µf µb|| denominator approximated ||˜µf|| drawn foreground background respectively. approximation normalizes respectively leads appearance invariance property figure visually demonstrates appearance invariance properties nsl. addition mnist-m commonly used domain adaptation experiments created three additional variants mnist. mnist image modiﬁed ﬁrst deﬁning foreground thresholding mnist-m then mnist-p pixels foreground background probabilities respectively. mnist-s insert binary shape subset foreground pixels. diﬀerent shape inserted distractor subset background pixels. mnist-v foreground background intensities drawn gaussian distributions mean diﬀerent standard deviations. network trained mnist tested mnist mnist-mpsv variants. figure rows demonstrate statistics feature maps target domains diﬀer signiﬁcantly statistics source domain hand statistics similarity neighborhoods consistent across source target domains. figure images mnist mnist-m additional variants mnist-p mnist-s mnist-v rows three feature maps ﬁrst pooling layer network trained mnist images only. rows neighborhood similarities computed network foreground background respectively. neighborhood similarities exhibit increased invariance appearance images compared feature maps. cross-domain generalization digit recognition network architecture convolutional network convolutional three fully-connected layers ﬁrst layer uses convolutions produce feature maps followed relu activation functions. followed max-pooling layer size stride square producing similarity feature maps output passed second convolutional layer produces feature maps using convolutions across channels. followed relu activation functions max-pooling layer size stride fully-connected layer neurons relu activation functions. output layer neurons followed softmax. create second model removing nsl. number feature maps ﬁrst convolutional layer chosen match number maps output ensuring input second convolutional layer dimensionality whether included architecture not. considering parameter free degrees freedom model without allows fair comparison. training/testing xavier initialization multinomial logistic loss training. training batch size data pre-processing divide input input range train network epochs initial learning rate exponentially decays later epochs. train mnist test mnist mnist-m svhn also created additional variants mnist name mnist-p mnist-s mnist-v described section network trained mnist also tested variants. next trained svhn tested svhn mnist. repeat training network times report mean standard deviation testing accuracy table also used domain adversarial training adapt network target domain report another testing accuracies case. results first observe inclusion detrimental eﬀect accuracy network mnist mnist improves accuracy modest amount svhn svhn. source target domains diﬀer provides large increase accuracy cases. results state-of-the-art results surpassing source experiments domain adaptation literature proper comparison. furthermore state-of-the-art domain adaptation result mnist→svhn best knowledge. network without using domain adaptation achieves mnist-v network without accuracy around chance level whereas network accurate. note using domain adversarial training increases accuracy cases. mnist-v domain adversarial training without provides gains chance level whereas accuracy accuracy using domain adversarial training together svhn→mnist previous domain adversarial results task state-of-the-art result task uses tri-training suggests using tri-training could lead state-of-the-art results svhn→mnist task future. finally also experimented tried patch gradient maps found ckn-pm give best results target domain reported table good results obtained mnist mnist trained found generalize well mnist-m svhn. object recognition appearance role digit classiﬁcation necessarily case general object recognition. simple convolutional network study impact object recognition cifar- dataset network architecture base network consists convolutional layers kernels followed relu activations pooling stride followed fully connected layer neurons output layer neurons network trained cifar- dataset using multinomial logistic loss. also modify base network insert ﬁrst pooling second convolutional layers. training/testing perform preprocessing subtracting mean image training image. perform type data augmentation. weights initialized randomly gaussian distribution trained epochs. learning rate ﬁrst epochs last epochs. trained networks times. results mean standard deviation testing accuracies base network base+nsl respectively. attribute decrease accuracy appearance information relevant cifar classiﬁcation task discarded nsl. modiﬁed network architecture remedy decrease accuracy create network inserting channel network network layer ﬁrst pooling second convolutional layers parallel nsl. outputs concatenated passed second convolutional layer. testing accuracy network surpasses base network accuracy. included excluded accuracy demonstrating contribute improved accuracy. ﬁnal question remains whether addition parallel stream impacts generalization accuracy training testing domains diﬀer. network described section digit recognition feature maps ﬁrst pooling layer. then concatenate output output feed second convolutional layer. learning rate number epochs experiments section accuracy network mnist mnist-m demonstrating parallel stream adversely aﬀect generalization training testing domains diﬀer. potential explanation parallel streams decouple appearance shape following layers learn relevant information. cross-domain vasculature segmentation evaluated proposed vasculature segmentation fundus images using u-net architecture fully convolutional network biomedical image segmentation. baseline exact network introduced original paper without modiﬁcation label pixels vasculature background. also modify network adding ﬁrst convolution layer. drive stare datasets contain images respectively manually annotated vasculature. divide datasets training testing experiments. measure accuracy vasculature segmentation using f-score deﬁned precision recall/. table shows testing accuracies diﬀerent combinations source target datasets well diﬀerent sizes nsl. first observe inclusion increases accuracy segmentation stare stare moderately decreasing drive drive. importantly inclusion signiﬁcantly increases accuracy segmentation target source domain diﬀer. figure illustrates recall vasculature pixels signiﬁcantly improved cross domain experiments inclusion nsl. emphasize domain adaptation used experiments. larger neighborhood size gives accurate results drive stare whereas results stare drive signiﬁcantly diﬀer remarkably results drive stare surpass results stare stare without nsl. demonstrate improvements accuracy obtained histogram matching domains preprocessed source target domain images converting saturation intensity space performing histogram equalization intensity values converting back rgb. network without found f-scores drive drive drive stare respectively. finally note state-of-the-art results vasculature segmentation obtained convolutional network includes specialized side layers layer incorporated specialized networks improve performance cross-domain applicability further. cell detection used time sequences datasets cell tracking challenge datasets sequences each training testing. ground truth datasets consists annotations approximately centers cells. goal detect cells i.e. cell centers; therefore place small gaussian masks centered annotations create target output images training. train u-net architecture modiﬁed u-net ﬁrst convolution layer. visual results cell detection datasets seen figure addition able identify cells contrast fluo-ndh-gowt dataset. case fluo-ndl-hela dataset observe cells detected clumps individually identiﬁed nsl. quantitative evaluation hungarian algorithm match ground truth annotations local maxima network output compute precision recall f-score. also compared detection results state-of-the-art results evaluated u-net without using locally contrast enhanced images. quantitative results evaluations reported table note improvement signiﬁcantly exceeds improvement obtained contrast enhancement input images provides state-of-the-art accuracy terms f-score. figure fluo-ndh-gowt-; bottom fluo-ndl-hela- left right test image predicted centroids without predicted centroids ground truth centroids overlaid contrast enhanced images proposed transforms input feature using feature vectors pixel frame reference surrounding neighborhood. spatial adaptation shown induce appearance invariance network used conjunction convolutional layers. parameter free layer included image feature layer network. diﬀerentiable; therefore networks including trained end-to-end manner. analyzed invariance properties demonstrated context digit recognition biomedical image segmentation inclusion allows networks better generalize data well represented training data without requiring domain adaptation. showed inclusion also provides increase accuracy domain adaptation. future directions research include used deeper layers network decouple appearance geometry general object recognition. speciﬁc domain adaptation techniques networks nsl/nin combination also interest. finally plan investigate applications biomedical image analysis applications labeled training data might readily available.", "year": 2017}