{"title": "Deep Visual Foresight for Planning Robot Motion", "tag": ["cs.LG", "cs.AI", "cs.CV", "cs.RO"], "abstract": "A key challenge in scaling up robot learning to many skills and environments is removing the need for human supervision, so that robots can collect their own data and improve their own performance without being limited by the cost of requesting human feedback. Model-based reinforcement learning holds the promise of enabling an agent to learn to predict the effects of its actions, which could provide flexible predictive models for a wide range of tasks and environments, without detailed human supervision. We develop a method for combining deep action-conditioned video prediction models with model-predictive control that uses entirely unlabeled training data. Our approach does not require a calibrated camera, an instrumented training set-up, nor precise sensing and actuation. Our results show that our method enables a real robot to perform nonprehensile manipulation -- pushing objects -- and can handle novel objects not seen during training.", "text": "whether possible replace hand-engineered robotic manipulation pipeline single general-purpose learned model connects low-level perception physical prediction. paper take small step direction goal demonstrating approach combining learned predictive model sensory observations modelpredictive control unlike methods robotic learning approach requires minimal human involvement learn entirely self-supervised fashion without detailed reward function image goal ground truth object pose information. test time deﬁne task objective moving pixel group pixels current position desired goal position goal description allows specify robot affect objects environment. also test time method optimizes sequence actions move pixels desired. actions continuously replanned robot executes task receives observations allowing method correct mispredictions. primary contribution paper demonstrate deep predictive models video used real physical robotic systems manipulate previously unseen objects. present algorithm based probabilistic inference learned predictive image model allows robot plan actions move user-speciﬁed objects environment user-deﬁned locations. apply deep predictive model demonstrated video prediction prior work show ability model learn implicit stochastic pixel leveraged within probabilistic framework. evaluate feasibility robotic manipulation learned abstract— challenge scaling robot learning many skills environments removing need human supervision robots collect data improve performance without limited cost requesting human feedback. model-based reinforcement learning holds promise enabling agent learn predict effects actions could provide ﬂexible predictive models wide range tasks environments without detailed human supervision. develop method combining deep action-conditioned video prediction models model-predictive control uses entirely unlabeled training data. approach require calibrated camera instrumented training set-up precise sensing actuation. results show method enables real robot perform nonprehensile manipulation pushing objects handle novel objects seen training. standard robotic manipulation systems consist series modular components perception prediction used plan actions handling objects. imagine robot needs push coffee across table give human. task might involve segmenting observed point cloud objects ﬁtting model object segment executing physics simulator using estimated physical properties ﬁnally choosing actions move desired location. however robots encounter previously unseen objects complex unstructured environments pipelined model-based approach break stage sufﬁciently large modeling error. particular errors early process cause compounding errors later process turn produce actions ineffective real world even small error estimated liquid content friction coefﬁcient might cause robot push high center mass causing contents spill. essence unstructured open world problem robot deal variability real world methods based rigid handengineered processes tend suffer hands special cases exceptions unmodeled effects. learning-based methods shown remarkable effectiveness handling complex unstructured environments passive computer vision tasks image classiﬁcation object detection co-adapting high-level feature representations. motivated large-scale unsupervised robotic learning consider question google brain mountain view berkeley artiﬁcial intellgence research department electrical engineering computer science university california berkeley berkeley video prediction models restrict problem setting nonprehensile pushing tasks. planning model real time show possible learn nonprehensile manipulation skills fast visual feedback control entirely self-supervised setting using unlabeled training data without camera calibration models depth observations physics simulator. although pushing tasks relatively simple performance method suggests underlying predictive model learns sufﬁciently detailed physical model world basic manipulation. best knowledge work ﬁrst instance robotic manipulation using learned predictive video models generalization previously unseen objects. standard model-based methods robotic manipulation might involve estimating physical properties environment solving controls based known laws physics approach applied range problems including robotic pushing despite extensive work area tasks like pushing unknown object desired position remain challenging robotic task largely difﬁculties estimating modeling physical world learning optimization-based methods applied various parts state-estimation problem object recognition pose registration dynamics learning however estimating simulating details physical environment exceedingly difﬁcult particularly previously unseen objects arguably unnecessary goal desired controls. example simple rules adjusting motion increasing force object moving fast enough gaze heuristic used robustly perform visuomotor control without overcomplete representation physical world complex simulation calculations. work represents early step toward using learning avoid detailed complex modeling associated fully model-based approach. several works used deep neural networks process images represent policies robotic control initially driving tasks later robotic soccer recently robotic grasping manipulation although model-free methods learn highly specialized proﬁcient behaviors recover task-speciﬁc policy rather ﬂexible model applied wide variety different tasks. high dimensionality image observations presents substantial challenge model-based approaches successful low-dimensional non-visual tasks helicopter control locomotion robotic cutting nevertheless works considered modeling high-dimensional images object interaction. example boots learn predictive model rgbimages robot moving free space. byravan learn model similar based prior work except predicts rigid motions constructing future depth images instead pixel transformations images. three works propose video prediction models demonstrate method using learned model control. agarwal learn inverse model used poking objects demonstrate generalization objects planning capabilities. works used model-based approaches learned low-dimensional embedding images deﬁning objective using image goal; however methods demonstrated either simple synthetic images without generalization objects. approach require image goal demonstrates generalization objects. approach related visual servoing performs feedback control features image image pixels unlike visual servoing methods approach performs feedback control pixel level using model learned entirely unlabeled real-world video data without requiring explicit camera calibration. demonstrated experiments method used move image pixels directly actuated robot’s joints perform nonprehensile manipulation. generally outside capability standard model-based visual servoing techniques inherent discontinuities complex unknown dynamics. perform visual model-predictive control deep predictive model images trained large dataset robotic pushing experience. section introduce notation brieﬂy describe data collection process model. dataset includes pushing attempts collected using -dof arms involving hundreds objects. data collection containing objects positioned front robot shown figure push attempt starts robot randomly selecting initial pose along outside border bin. subsequently robot iteratively selects target gripper pose moves towards target pose chosen time step episode length. gripper pose represented coordinate frame robot base positional coordinate rotations pitch roll kept constant. thus vector length data collection commanded poses chosen randomly. robot records sensor readings including current gripper pose commanded gripper pose camera image workspace selects commanded poses inputs predictive model timestep consist current previous images denote current previous end-effector poses fig. video prediction model predicts stochastic pixel transformation current frame next frame allows generate predictions subsequent images conditioned sequence future actions. predicted stochastic parameterized normalized convolution ﬁlters give rise independent gaussian distribution future images. internally model predicts multiple stochastic channels order process multiple separate moving objects. channels composited using learned object masks. supervision model consists video action state sequences explicit supervision ﬂows masks. ﬂows masks therefore emergent property model exploit perform visual using high-level user commands. details model found prior work well sequence future commands prediction horizon used training. pairs images states model allow estimate current velocities moving objects. model trained predict distribution sequence future image frames ihp+ result executing actions ahp. however since full posterior images extremely high dimensional relatively simple factorization pixel drawn independent gaussian distribution. although assumption simplistic common simpliﬁcation video image generation models model trained maximum likelihood results mean squared error objective. therefore express model probabilistically shown figure model uses convolutional lstm predict images. intermediate step model outputs probabilistic time step denote describes linear transition operator applied pixel preceding image. intuitively expect different objects different regions image moving different ways. model uses normalized convolution kernels {mc} capture motion object providing distribution nearby pixel locations next timestep. object motion predictions combined using masks {ξc} specify positions objects. denotes probability pixel time originating location time given following. note equation untied convolution operation ﬁlters image since ﬁlters different pixel location operator also seen transition operator markov chain. ˆit+ denote application operator. since operator linear distribution subsequent image obtained simply transforming mean distribution current image. predicted image mean ˆit+ back network recursively generate next image sequence. note explicit supervision provided network training uses image pixels supervision. stochastic maps implicit emergent property model prove useful visual discuss following section. convenience denote function uses learned model output sequence ﬂows conditioned pairs images states well sequence future actions horizon therefore deﬁne predicted image distribution test time system receives high level goal user discuss section iv-a uses model-predictive control together deep video prediction model choose controls realize user’s commanded goal shown figure video prediction models explicitly model objects cannot represent task goal using standard notions object poses. section outline exactly objective speciﬁed represented probabilistically evaluate candidate actions using model goal representation. lastly section iv-c present method planning replanning actions using involves rolling video prediction model timesteps future. show full algorithm algorithm combines learned model high-level goal speciﬁcation probabilistically plan future actions. operators ˆft+k time step used transform prior images independent gaussian pixel distributions independent gaussian pixel distributions next image according ˆit+k ˆft+k ˆit+k−. also stochastic operators predict individual pixels move conditioned sequence actions. since operators stochastic provide distribution pixel motion conditioned actions. suggests natural approach planning using maximum likelihood determine sequence actions maximizes probability designated pixel moving goal position. formally construct initial probability distribution designated pixel’s position current time step denote assume current position designated pixel known time provided user time tracked thereafter. thus deﬁne distribution current time step plan predictive model images need specify task objectives automatically evaluated model’s predicted visual futures. work goal speciﬁed user terms pixel motion. intuitively user speciﬁes pixel image tells robot pixel moved user selects desired source pixels initial image denote pixel’s position given speciﬁes corresponding goal position pixels denote goal position given goal speciﬁcation robot plan move objects selected pixels belong. kind goal speciﬁcation quite general used command arbitrary rearrangements objects clearing table. practical application commands could issued either directly human user selecting points image higher-level planning process. goal representation easy specify require instrumentation environment e.g. motion capture markers represent variety object manipulation tasks. unlike approaches robotic manipulation also need explicit representation objects. example pixel motion goals shown figure here describe method evaluates proposed action sequence using probabilistic inference learned predictive model simplicity ﬁrst consider goal moving single designated pixel initial image goal position need evaluate probability achieving goal model given initial image intial state sequence future actions at+h−. described section video prediction model predicts stochastic goal compute distribution designated pixel’s position horizon denoted choose actions maximize probability corresponds probabilistic inference action sequence att+h−. recall predictive model outˆ time step. puts stochastic operator stochastic corresponds stochastic transition operator pixel positions therefore propagate distribution designated pixel forward time using ˆft. pt+k denote conditional distribution have applying computation recursively steps obtain pt+h− describes probability distribution position designated pixel horizon. probability successfully moving designated pixel goal location given simply pt+h−. process easily extended multiple pixels computing probability success pixel separately summing log-probabilities. interestingly process makes model’s implicit predictions instead predicted images themselves. however ability model predict images enables train without explicit supervision. goal mpc-based controller determine sequence actions maximizes probability designated pixel pixels moved corresponding goal locations. previous section describes evaluate candidate action sequence att+h− sample action sequences model compute distributions future pixel locations multivariate gaussian distribution samples highest probability success determine probability move designated pixel goal location given pt+h− order evaluation choose best actions perform optimization short horizon actions time step using stochastic optimization algorithm called cross-entropy method procedure outlined algorithm described next. quences denoted probabilities tt+h−dt select action sequences highest values t+h− multivariate gaussian distribution selected action sequence resample action sequences distribution. action sequences improves previous resampling reﬁtting process repeated iterations. corresponds stochastic optimization algorithm. last iteration take sampled action sequence t+h− likely successful execute robot. iterations samples iteration samples initial planning phase replanning real-time take iteration samples performing round sampling. note batch samples corresponds forward pass deep recurrent network batch size therefore parallelized efﬁciently. locations changed initial positions motion objects. update estimated position pixel compute optical previous latest image observation using method anderson optical algorithm used large-scale production system. speed optical computation done evaluating model’s video predictions parallel using gpu. fig. experimental setup shown left including test objects previously seen training set. right show four pushing tasks quantitative evaluation. greenoutlined markers indicate human-speciﬁed start goal pixel locations respectively. experimental evaluation answer following questions action-conditioned video prediction models manipulate novel objects previously seen training? video prediction models trained entirely image pixels make meaningful nontrivial inferences behavior physical objects? answer questions conduct qualitative quantitative experiments describe next sections. answer question evaluating method objects seen training answer question comparison baseline methods either move user-speciﬁed positions optical perform continuous replanning. also answer question qualitative experiments aimed construct physically nuanced pushing scenarios require reasoning rotations centers mass. note intent experiments demonstrate approach provides highest accuracy performance precise nonprehensile manipulation rather demonstrate ﬂexibility data-driven learning-based approach illustrate that even prior knowledge objects physics contacts predictive model trained entirely video data still infer characteristics physical world useful robotic manipulation. -dof robot perform pushing tasks experiments camera positioned shoulder shown figure discussed previously pushing task consists episodes length goal move pixels current locations unless otherwise speciﬁed objects experiments seen previously training set. video experiments available online. images resolution pixels planning horizon corresponding baseline method optical solver track position pixel replanning. note however predictive model optical make predictions. optical used replanning phase provide initial distribution. solver also used quantitatively evaluate distance ﬁnal position pixel goal position pixel. note speciﬁcally choose baseline methods prior knowledge objects physics. course possible design model-based pushing algorithm uses object detector physics simulator precisely localize move individual objects scene. however propose superior method nonprehensile manipulation rather explore capabilities limitations learning-based video prediction models performing robotic control tasks scratch minimal prior knowledge. results shown table indicate method indeed able leverage predictive model improve performance baselines. performance method compared last baselines suggests method making meaningful inferences motion objects response arm. although results leave signiﬁcant room improvement suggest predictive models used minimal prior knowledge perform robotic manipulation tasks. video prediction models continue improve expect performance method improve them. next section analyze speciﬁc physical interactions better understand capabilities limitations model. fig. data training model collected robots varying camera angles positions. images show camera angles robots used data collection. note difference position robot base. variations video prediction model learns calibration-invariant representation object interactions. allows replan real time controls computed every reduce dimensionality action space speed inference commanded action across time model considering commanded action kept constant timesteps. short time horizon largely consider pushing tasks involve fast reactive control rather long-term planning. online model computations including replanning done using standard desktop computer single commercially-availble gpu. provide quantitative comparisons three baselines evaluating whether video prediction model learned meaningful nontrivial notion objects physical interaction. recall object identity inertia contact dynamics provided encoded model explicitly must learned entirely data. correspondingly baselines knowledge objects scene reasonably effective short horizon pushing tasks consider. baselines follows designated pixel speciﬁed last baselines ﬁrst pixel only. ﬁrst baseline randomly selecting actions serves calibrate difﬁculty task choosing effective actions. last baselines serve comparison method test whether model learning something meaningful physical object interaction beyond simple motions arm. note last baselines require hand-to-camera calibration model use. since data used training predictive model collected variety robots varying camera placements angles illustrated figure video prediction model forced learn calibration-agnostic predictive strategy. ﬁnal section evaluate capabilities limitations visual qualitative experiments. goal experiments determine whether model perform complex manipulations require reasoning object rotations centers mass. beneﬁts planning actions predictive model pixels model used plan actions affect multiple pixels causing move different directions coordinated fashion. example object rotation represented moving pixels opposite ends object opposite directions. evaluate capability command robot rotate objects specifying opposing motions pixels either extreme object shown fig. failure cases method. ﬁrst scenario goal avoid moving can. moves front occludes occluding causing estimated pixel positions shift causing later bump can. second example goal rotate bottle. although robot makes contact bottle reasonable location perform rotation underestimates mass bottle instead rotating light bottle simply translates along robot’s arm. minimal prior engineering. convolutional lstm model trained unlabeled data collected autonomously team robots. model predicts future camera images image-space pixel conditioned sequence motor commands. inferring commands move individual points image desired target locations continuously plan pushing tasks even novel objects previously seen training. since model trained entirely self-supervised procedure method well suited continuous self-improvement constant data collection. experimental evaluation demonstrates method outperforms simple baselines based geometric heuristics known hand-to-camera calibration. although show generalization completely novel objects model still limited relatively simple shorthorizon tasks. accuracy deep video prediction models improves expect capabilities approach also improve. predictive models estimate distributions future images particularly promising robotic control since planning models corresponds maximum likelihood inference determining sequence actions maximizes probability desired outcome. promising direction future work integrate latest advances probabilistic video prediction models e.g. enabling technologies approach available fast highly parallel gpus runtime evaluation model. experiments commercially available makes approach practical selfcontained robotic systems. however planning horizon replanning rate limited computational power availability even faster parallel computational platforms likely lead improvement capability accuracy. finally believe work represents relatively early ﬁrst step toward model-based robotic control using learned predictive models. deep neural network-based video fig. commanded rotate objects moving end-points opposing directions method plans actions touch object side. initial image left markers designate user-speciﬁed starting pixel positions green-outlined markers show corresponding goal positions. note starts distance object forcing model plan right contact position realize rotation. black tape middle rows original dataset objects not. left figure commanded move pixels object rotates method able produce desired rotational motion seen right side figure examples indicate model indeed used predicting motion multiple pixels planning affect coordinated way. limitation approach handling selfocclusions. occludes object designated pixel instead object method subsequently plans move instead object goal position. example failure case shown figure incorrect model predictions also cause failures performance. shown second figure robot selects sequence actions push bottle close center mass causing translate rather rotate. expect that improving accuracy video prediction models reduce failures increase general performance method. video prediction active area research deep learning computer vision method described work improvements predictive models could translate improvements robotic manipulation capabilities. prediction still early stages state-of-the-art methods making accurate predictions frames future state-of-the-art video prediction improves model-based methods become increasingly powerful. particular interest robotic manipulation hierarchical models operating varying time scales even make practical plan highly elaborate skills entirely using learned predictive models. thank peter pastor ethan holly mrinal kalakrishnan deirdre quillen stefan hinterstoisser technical support project vincent vanhoucke goodfellow george dahl helpful discussions. also thank barron help optical solver. mason mechanics planning manipulator pushing operations international journal robotics research salganicoff metta oddera sandini vision-based learning method pushing manipulation. aaai fall symposium series k.-t. bauza fazeli rodriguez more million ways pushed high-ﬁdelity experimental data planar pushing international conference intelligent robots systems collet berenson srinivasa ferguson object recognition full pose registration single image robotic manipulation international conference robotics automation levine pastor krizhevsky quillen learning hand-eye coordination robotic grasping deep learning large-scale data collection international symposium experimental robotics tassa erez todorov synthesis stabilization complex behaviors online trajectory optimization international conference intelligent robots systems boots byravan learning predictive models depth camera manipulator execution traces international conference robotics automation byravan se-nets learning rigid body motion using lange riedmiller voigtlander autonomous reinforcement learning visual input data real world application international joint conference neural networks watter springenberg boedecker riedmiller embed control locally linear latent dynamics model control images neural information processing systems finn duan darrell levine abbeel deep spatial autoencoders visuomotor learning international conference robotics automation rubinstein kroese cross-entropy method uniﬁed approach combinatorial optimization monte-carlo simulation machine learning. springer science business media", "year": 2016}