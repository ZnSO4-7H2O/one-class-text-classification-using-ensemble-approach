{"title": "Reasoning About Pragmatics with Neural Listeners and Speakers", "tag": ["cs.CL", "cs.NE"], "abstract": "We present a model for pragmatically describing scenes, in which contrastive behavior results from a combination of inference-driven pragmatics and learned semantics. Like previous learned approaches to language generation, our model uses a simple feature-driven architecture (here a pair of neural \"listener\" and \"speaker\" models) to ground language in the world. Like inference-driven approaches to pragmatics, our model actively reasons about listener behavior when selecting utterances. For training, our approach requires only ordinary captions, annotated _without_ demonstration of the pragmatic behavior the model ultimately exhibits. In human evaluations on a referring expression game, our approach succeeds 81% of the time, compared to a 69% success rate using existing techniques.", "text": "figure sample output model. presented target image contrast distractor image model generates description description mentions tree distinguishing object present situates respect objects events scene. order players description must pragmatic must informative ﬂuent concise must ultimately encode understanding behavior. figure example wearing sitting tree accurate descriptions target image second allows human listener succeed high probability. focus many papers computational pragmatics literature provides concrete generation task eliciting broad range pragmatic behaviors including conversational implicature context dependence existing computational models pragmatics divided broad lines work term direct derived approaches. present model contrastively describing scenes context-speciﬁc behavior results combination inferencedriven pragmatics learned semantics. like previous learned approaches language generation model uses simple featuredriven architecture ground language world. like inference-driven approaches pragmatics model actively reasons listener behavior selecting utterances. training approach requires ordinary captions annotated withdemonstration pragmatic behavior model ultimately exhibits. human evaluations referring expression game approach succeeds time compared using existing techniques. present model describing scenes objects reasoning context listener behavior. incorporating standard neural modules image retrieval language modeling probabilistic framework pragmatics model generates rich contextually appropriate descriptions structured world representations. models feature-based architectures predict appropriate behavior without listener representation. quite general principle models require training data annotated speciﬁcally pragmatics mind; data scarce practice. derived models contrast based representation ﬁrst instantiate base listener chooses description causes behave correctly. existing derived models couple hand-written grammars hand-engineered listener models sophisticated inference procedures. exhibit complex behavior restricted small domains grammar engineering practical. approach present paper aims capture best aspects lines work. like direct approaches machine learning acquire complete grounded generation model data without domain knowledge form hand-written grammar hand-engineered listener model. like derived approaches learning construct base model embed within higher-order model reasons listener responses. seen reasoning step allows model make weaker supervision previous data-driven approaches exhibiting robust behavior variety contexts. goal build derived model scales real-world datasets without domain engineering. independent application model also belongs family neural image captioning models popular subject recent study nevertheless approach appears following previous work evaluate model though general architecture could applied tasks pragmatics plays core role. using large dataset abstract scenes like shown figure series games humans role system role descriptions generated model result correct interpretation often recent learned baseline system. experiments explore various aspects computational pragmatics including tradeoffs between adequacy ﬂuency computational efﬁciency expressive power. direct pragmatics example direct approach mentioned introduction fitzgerald collect human-generated referring expressions abstract representations sets colored blocks. given blocks describe model directly learns maximumentropy distribution logical expressions whose denotation target set. research focused referring expression generation computer vision perspective includes kazemzadeh derived pragmatics derived approaches sometimes referred rational speech acts models include smith vogel golland monroe potts couple template-driven language generation probabilistic game-theoretic reasoning frameworks produce contextually appropriate language intelligent listeners reason behavior reﬂexive speakers even higher-order speakers reason listeners. experiments show derived approaches explain human behavior well computational representational issues restrict application simple reference games. require domainspeciﬁc engineering controlled world representations pragmatically annotated training data. posed paper relies extensively recently developed tools multimodal processing language unstructured representations like images. includes image retrieval models select image collection given textual description neural conditional language models take content representation emit string goal produce model play role speaker speciﬁcally given target referent distractor model must produce description uniquely identiﬁes training access non-contrastively captioned referents training description generated associated referent isolation. guarantee would actually serve good referring expression particular context. must thus training data ground language referent representations rely reasoning produce pragmatics. model architecture compositional hierarchical. begin section describing collection modules basic computational primitives mapping referents descriptions reference judgments implemented linear operators small neural networks. modules appear substructures neural architectures variety tasks novel constructing reasoning pragmatic speaker. section describes assemble base models literal speaker maps referents strings literal listener maps strings reference judgments. section describes base models used implement top-level reasoning speaker learned probabilistic derived model pragmatics. formally take description consist sequence words drawn vocabulary known size. encoding also assume access feature representation sentence views—as figure diagrams modules used construct speaker listener models. fully-connected layer relu rectiﬁed linear unit. encoder modules feature representations embeddings ranker describer modules respectively embeddings decisions strings. sequence words feature vector form basis module interactions language. referent representations similarly simple. because model never generates referents—only conditions scores them—a vectorvalued feature representation referents sufﬁces. approach completely indifferent nature representation. experiments paper vector indicator features objects actions present abstract scenes would easy instead pre-trained convolutional representations referring natural images. descriptions denote feature representation referents. figure schematic depictions models. literal listener maps descriptions reference candidates reference decisions. literal speaker maps directly scenes descriptions ignoring context reasoning speaker uses samples scores produce contextually-appropriate captions. serves purpose base listener general derived approach described introduction. additionally construct literal speaker takes referent isolation outputs description. literal speaker used efﬁcient inference space possible descriptions described section essence retrieval model neural captioning model. literal listener given description pair candidate referents literal listener embeds referents passes ranking module producing distribution choices choice ranker choice ranker takes string encoding collection referent encodings assigns score pair transforms scores distribution referents. write probability choosing contrast alternative; example probability answering presented encodings referent describer referent describer takes image encoding outputs description using conditional neural language model. express model distribution indicator feature last description word generated vector indicator features words previously generated referent embedding. -plus-skip-gram model local positional history features global position-independent history features features referent described. implement probability distribution ﬁrst multilayer perceptron compute vector scores wρ). normalj finally pdn+. base models building blocks construct pair base models. ﬁrst literal listener takes description referents chooses referent likely described. neural literal listener described preceding section probabilistic listener. given target pair candidate referents natural specify behavior reasoning speaker simply ﬁrst glance thing necessary implement model representation literal listener itself. possible utterances comes ﬁxed vocabulary grammar small enough exhaustively enumerate operation maxd equation practical. purposes however would like model capable producing arbitrary utterances. score produced discriminative listener model factor along words description dynamic program enables efﬁcient inference space strings. instead sampling-based optimization procedure. ingredient good proposal distribution sample sentences likely assigned high weight model listener. turn literal speaker described previous section. recall speaker produces distribution plausible descriptions isolated images ignoring pragmatic context. source candidate descriptions reweighted according expected behavior full speciﬁcation sampling neural reasoning speaker follows primarily enable efﬁcient inference also literal speaker serve different purpose regularizing model behavior towards choices adequate ﬂuent rather exploiting strange model behavior. past work restricted utterances guarantees ﬂuency. imperfect learned listener model procedure optimizes listener’s contrastive objective ensures approach applicable even naturally-occurring source target–distractor pairs previous work required. note also viewed version loss described smith eisner approximates likelihood objective encourages prefer every possible referent simultaneously. base models intended minimal learned equivalents hand-engineered speakers hand-written grammars employed previous derived approaches neural encoding/decoding framework implemented modules previous subsection provides simple referents descriptions descriptions judgments without worrying much details syntax semantics. past work amply demonstrates neural conditional language models powerful enough generate ﬂuent accurate descriptions images structured representations reasoning model described introduction general derived approach pragmatics constructs base listener selects description makes behave correctly. since assumption listeners behave deterministically often poor common derived approaches implement judgments directly speaker model might accidentally discover kinds pathological optima neural classiﬁcation models known exhibit case sentences cause exactly right response longer bear resemblance human language use. correct this allow model consider questions before likely listener would interpret sentence correctly? additionally likely speaker would produce viewed weighted joint probability sentence uttered literal speaker correctly interpreted literal listener alternatively terms grice’s conversational maxims encodes maxims quality relation ensuring description contains enough information make right choice encodes maxim manner ensuring description conforms patterns human language use. responsibility maxim quantity shared ensures model doesn’t little ensures model doesn’t much. evaluate model reference game described introduction. particular construct instances using abstract scenes dataset introduced zitnick parikh example scenes shown figure figure dataset contains pictures constructed humans described natural language. scene representations available rendered images feature representations containing identity location object; noted section feature produce referent representation dataset previously used variety language vision tasks zitnick consists scenes annotated captions. abstract scenes dataset provides challenging version anything aware existing computational pragmatics literature largely used tuna corpus isolated object descriptions small synthetic datasets contrast abstract scenes data generated humans looking complex images numerous objects features grammatical errors misspellings vocabulary order magnitude larger tuna. unlike previous work prespeciﬁed indomain grammar direct supervision relationship scene features lexemes. perform human evaluation using amazon mechanical turk. begin holding development test set; held-out contains scenes accompanying descriptions. held-out construct sets paired scenes four differences paired scenes hard exactly difference paired scenes. report evaluation metrics. fluency determined showing human raters isolated sentences asking rate linguistic quality scale accuracy success rate figure humans shown images model-generated description asked select image matching description. remainder section measure tradeoff ﬂuency accuracy results different mixtures base models measure number samples needed obtain good performance reasoning listener attempt approximate reasoning listener monolithic compiled listener section report ﬁnal accuracies approach baselines. many samples needed? next turn computational efﬁciency reasoning model. sampling-based inference number samples must drawn proposal critical interest—if many samples needed model slow practice. ﬁxed preceding section measure accuracy versions reasoning model draw samples. results shown table gains continue samples. require complicated inference procedures direct approaches pragmatics typically enjoy better computational efﬁciency derived ones. built accurate derived speaker bootstrap efﬁcient direct speaker? explore this constructed compiled speaker model follows given reference candidates target model produces embeddings concatenates together contrast embedding feeds whole embedding string decoder module. like model generates captions without need discriminative rescoring; unlike contrast embedding means model principle learn produce pragmatic captions given access pragmatic training data. since training data exists train compiled model captions sampled reasoning speaker itself. model evaluated table distribution scores quite different figure tradeoff speaker listener models controlled parameter equation weight placed literal listener model produces highly discriminative somewhat disﬂuent captions. weight placed literal speaker model produces ﬂuent generic captions. dev-all set. collect human ﬂuency accuracy judgments total samples. allows conduct post-hoc search values range compute average accuracy ﬂuency highest scoring sample. varying view tradeoff accuracy ﬂuency results interpolating listener speaker model—setting gives samples gives samples figure shows resulting accuracy ﬂuency various values seen relying entirely listener gives highest accuracy degraded ﬂuency. however adding small weight speaker model possible achieve near-perfect ﬂuency without substantial decrease accuracy. example sentences individual reference game shown figure increasing causes captions become generic. remaining experiments paper take ﬁnding gives excellent performance metrics. figure figure four randomly-chosen samples model. each target image shown left distractor image shown right description generated model shown below. descriptions ﬂuent generally succeed uniquely identifying target scene even perfectly describe samples broadly representative model’s performance table success rates abstract scenes. literal captioning baseline corresponding base speaker contrastive reimplementation approach reasoning model paper. differences model baselines signiﬁcant base model overall gain negligible compiled model signiﬁcantly underperforms reasoning model. results suggest either reasoning procedure easily approximated shallow neural network example descriptions randomly-sampled training pairs provide strong enough signal reﬂex learner recover pragmatic behavior. table comparison compiled pragmatic speaker model literal explicitly reasoning speakers. models evaluated subsets development arranged difﬁculty column headings indicate number differences target distractor scenes. evaluate test comparing reasoning model baselines literal image captioning model trained normally abstract scene captions contrastive model trained soft contrastive objective previously used visual referring expression generation results shown table reasoning model outperforms literal baseline previous work substantial margin achieving improvement pairs hard pairs. figures show various representative comparison model hand-engineered pragmatic behavior—trained using feature representation indicators objects appear target image distractor—produces accuracy figure descriptions image different contexts. target scene contrasted left system describes bat; target scene contrasted right system describes snake. presented approach learning generate pragmatic descriptions general referents even without training data collected pragmatic context. approach built pair simple neural base models listener speaker high-level model reasons outputs order produce pragmatic descriptions. evaluation standard referring expression game model’s descriptions produced correct behavior human listeners signiﬁcantly often existing baselines. generally true existing derived approaches pragmatics much system’s behavior requires hand-engineering generally true direct approaches training possible supervision available precise target task. synthesizing approaches address problems obtaining pragmatic behavior without domain knowledge without targeted training data. believe general strategy using reasoning obtain novel contextual behavior neural decoding models might broadly applied.", "year": 2016}