{"title": "Towards Crafting Text Adversarial Samples", "tag": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "abstract": "Adversarial samples are strategically modified samples, which are crafted with the purpose of fooling a classifier at hand. An attacker introduces specially crafted adversarial samples to a deployed classifier, which are being mis-classified by the classifier. However, the samples are perceived to be drawn from entirely different classes and thus it becomes hard to detect the adversarial samples. Most of the prior works have been focused on synthesizing adversarial samples in the image domain. In this paper, we propose a new method of crafting adversarial text samples by modification of the original samples. Modifications of the original text samples are done by deleting or replacing the important or salient words in the text or by introducing new words in the text sample. Our algorithm works best for the datasets which have sub-categories within each of the classes of examples. While crafting adversarial samples, one of the key constraint is to generate meaningful sentences which can at pass off as legitimate from language (English) viewpoint. Experimental results on IMDB movie review dataset for sentiment analysis and Twitter dataset for gender detection show the efficiency of our proposed method.", "text": "adversarial samples strategically modiﬁed samples crafted purpose fooling classiﬁer hand. attacker introduces specially crafted adversarial samples deployed classiﬁer mis-classiﬁed classiﬁer. however samples perceived drawn entirely diﬀerent classes thus becomes hard detect adversarial samples. prior works focused synthesizing adversarial samples image domain. paper propose method crafting adversarial text samples modiﬁcation original samples. modiﬁcations original text samples done deleting replacing important salient words text introducing words text sample. algorithm works best datasets sub-categories within classes examples. crafting adversarial samples constraint generate meaningful sentences pass legitimate language viewpoint. experimental results imdb movie review dataset sentiment analysis twitter dataset gender detection show eﬃciency proposed method. machine learning algorithms deployed service trained model available users task classiﬁcation/ regression query data. applications like automatic chatbots information retrieval systems uses algorithms various complexities background. data ever expanding important deployer update models using recently available data recent query result overall performance model degrade newly available data. hand adversary attacker aims degrade performance model. introduce malicious queries model apparently seems regular query sample deployer. model gets confused malicious query sample classiﬁes wrongly classes. classiﬁcation performance degrades deployer tries tune parameters classiﬁers feedback query samples eventually degrades performance classiﬁer even tested ordinary query samples. adversarial sample deﬁned appears drawn particular class humans fall diﬀerent class feature space. prevent attacks adversary train classiﬁer beforehand potential malicious samples assuming type adversarial samples used attack limiting problem setting single malicious data generation. considering convolutional neural network choice classiﬁer shown produce good classiﬁcation accuracy task text classiﬁcation. advent deep neural network classiﬁcation highly complex unstructured data achieved good performance accuracy. time dnns chosen preferred classiﬁer image text classiﬁcation tasks. highly complicated structure neural nets helps model intricacies complex features present complex data like image free ﬂowing text document. lots studies vulnerabilities fool classiﬁer successfully. majority prior works ﬁeld synthesizing adversarial samples consider images data work value range interpreted valid pixel image. minor change pixel values image generate meaningful image also change negligible human eyes. properties make synthesize image modiﬁcation image much easier compared structured data like text. hand text samples hard modify synthesize. wordvec approach popular method used data pre-processing feature extraction text samples. also discreet nature whole wordvec makes diﬃcult arbitrary vector valid word vocabulary. another important aspect generate adversarial text sample maintain syntactic meeting sample along grammar changes remain diﬃcult detect human. challenges makes problem adversarial text crafting challenging little work adversarial text crafting text domain. proposed method crafting adversarial samples text domain best suited datasets sub-categories. paper experiment imdb movie review dataset extensively task sentiment analysis. dataset sub-categorized using genre movies considered reviews. generally high contributing words increases probability belonging particular sentiment class reviews. example words like ’good’ ’excellent’ ’like’ etc. indicates positive review irrespective genre movie. however exists words speciﬁc genre movie. example consider sentence \"the movie hilarious\". indicates positive sentiment comedy movie. sentence denotes negative sentiment horror movie. thus word ’hilarious’ contributes sentiment review based genre movie. classiﬁer used sentiment analysis neglect genre information determines sentiment review text globally. however using sub-category level information successfully create adversarial text samples. another alter review sample consider synonyms possible typos high contributing words decreases probability belonging correct class. often presence adverbs alter sentiment review text. example consider sentence \"the movie fair\". sentiment belong either class. however adverb ’extremely’ change sentence \"the movie extremely fair\" indicates movie poor treated negative sentiment. classiﬁer word \"extremely\" contribute much probability belongingness particular class modiﬁed sample becomes adversarial one. similarly removal certain words impact class probability sample text opposite direction. main contribution work craft adversarial samples domain text data preserving semantic meaning sentences much possible. also minimize alteration original input sample. best knowledge work aims craft adversarial text samples minimum possible modiﬁcations preserves semantic meaning sentence best possible extent. rest paper follows section describes related work ﬁeld adversarial sample crafting section describes proposed method section describes experimental results. ﬁnally section concludes paper. learning deployment machine learning models provides opportunity hackers exploit various sensitive informations features nature decision boundary etc. deteriorate model introducing false input feedback system process. confuse classiﬁer deteriorate performance introduce samples apparently seems innocent humans. adversarial samples hard catch humans causes classiﬁer fail signiﬁcant amount classiﬁers falsely retrained. resist attack deployer pre-assume adversarial samples generate synthetic ones. training classiﬁer synthetic adversarial samples correct class-label makes robust attack happen future. szegedy shows smoothness assumption kernels correct makes input-output mapping discontinuous deep neural network. adversarial samples results discontinuity lies pockets manifold dnns. thus adversarial samples form hard negative examples even though distribution inputs provided dnn. simple optimization problem maximizes network’s prediction error good enough create adversarial samples images. popular method creating adversarial sample images existing ones considering gradient cost function classiﬁer introduced goodfellow resultant image becomes adversarial sample. noise generated help gradient cost function classiﬁer respect input image. fast eﬀective create adversarial samples popularly known fast gradient sign method figure shows panda image modiﬁed adversarial sample classiﬁed gibbon well adversarial samples along corresponding predicted class-labels mnist dataset classiﬁer gets generalized less susceptible adversarial attacks. papernot attacker successfully generate adversarial samples. attacker train model using similar input data create adversarial samples using fgsm method. adversarial samples confuse deployed classiﬁer also good probability. thus attacker successful almost information deployed model. papernot introduced term ’gradient masking’ show application real world images like traﬃc signs algorithm performs well. liang proposed algorithm produce adversarial text samples using character level shows problem directly using algorithms like fgsm crafting adversarial text samples. results gibberish texts easily identiﬁed humans noisy samples. work important phrases determined using back propagation gradient cost function. phrases replaced pre-identiﬁed phrases training corpus shown change class probability values. three methods insertion deletion modiﬁcation used modifying text create adversarial sample. however detection correct phrases using create adversarial samples requires heuristics clearly mentioned paper. codebase shared craft adversarial text sample along ideas mostly modify existing words text sample synonyms typos. apart mentioned work couple notable works area adversarial sample crafting text domain. hossein hossein shows strategical insertion punctuations selected words fool classiﬁer toxic comments bypassed model used ﬁler. however modiﬁed texts easily detectable humans qualify good example adversarial sample. lastly conclude crafting adversarial samples text domain niche area compared image counterpart. propose three diﬀerent kinds modiﬁcations alter regular input adversarial sample replacement insertion removal words text. change class-label sample minimum number alteration. pseudo-code proposed method given algo. steps algorithm explained below target words text decreasing order importance contribution class belongingness probability. word text highly contributing removal text going change class probability value large extent. hence contribution word measured where posterior probability sentence belonging class according classiﬁer denotes sentence without target word. however large text sample consists multiple paragraphs calculation time consuming process every word. concept fgsm approximate contribution word calculated where true class sentence containing word cost function classiﬁer hand since −∇sj denotes adjustment made input obtain minimum cost function training good determine importance features particular classiﬁer modify sample text considering word time order ranking based class-contribution factor. consider synonyms typos words well genre sub-category speciﬁc keywords brieﬂy described below. synonyms typos word build candidate pool consists words current word replaced with. example word ’good’ sentence ’the movie good.’ replaced ’nice’ ’decent’ etc. considering synonyms word ’good’. another possible extend candidate pool consider possible typos happen typing review. however consider many typos input text turn meaningless piece text. also typos attract human attention quiet easily detectable spell checker. hence consider typos valid words. example word ’good’ consider typos ’god’ ’goods’ valid english words. genre speciﬁc keywords apart using synonyms typos also consider sub-category genre speciﬁc keywords. based fact certain words contribute positive sentiment particular genre emphasis negative sentiment kind genre movies. keywords capture distinctive properties classes considering term frequencies corpus. word high particular class sample texts texts belonging diﬀerent class safely work distinctive ﬁrst class. denote distinctive keywords class. since dealing class problem distinctive words class denoted respectively. consider sub-category genre information considering distinctive words classes texts belonging genres separately. sets denoted classes samples particular genre using sets keywords terms candidate pool where genre class word building candidate pool words. here considering subset candidate words distinctive opposite class sub-category information avoided. words contribute negatively towards contribution text sample class ideal crafting adversarial sample. consider three diﬀerent approaches change given text sample iteration modiﬁed sample ﬂips class label. iteration word chosen modiﬁcation denoted heuristics modifying text explained below removal words ﬁrst check word consideration i.e. adverb not. adverb contribution score considerably high remove word modiﬁed sample motivation behind heuristics adverbs emphasis meaning sentences often alter grammar sentence introduction removal sentence. replacement word case conditions ﬁrst steps satisﬁed replace obtain obtained genre speciﬁc keywords consider replacement parts speech same. otherwise select next best word replacement. matching parts speech necessary avoid detection keep changing word time obtain unless class-label becomes diﬀerent. since consider words order contribution score crafting adversarial samples least possible changes using idea greedy method. minimum number changes sample text ensures semantics grammar adversarial sample remains similar ofs. also conditions enforced parts speech words helps maintain structure sentence large extent. show experimental results datasets imdb movie review dataset sentiment analysis twitter dataset gender classiﬁcation compare method existing method textfool described using twitter dataset. implemented method described best abilities exact implementation lack proper explanation heuristics mentioned evaluate algorithms adversarial sample crafting done classiﬁcation accuracies original tainted test data shown types model. ﬁrst trained original training obtained respective datasets. second model obtained re-training ﬁrst using adversarial samples obtained modifying samples original training set. classiﬁcation accuracy dataset deﬁned percentage samples correctly labeled classiﬁer hand correct label database. detailed study experiments datasets given below. imdb movie review dataset consists reviews diﬀerent movies along class-label review taken. dataset divided training testing sets contains positive samples negative samples. data preprocessing feature extraction manually found genre movie using imdb called imdbpy using given reviews. next identiﬁed genre movies considerable amount reviews dataset. ﬁltering considering reviews movies genres ’action’ ’comedy’ ’drama’. genres considered sub-categories used selecting genre speciﬁc distinctive keywords. finally extract features using toolbox spacy features denote number times word occurring text sample. results show eﬃciency proposed method comparing accuracy model obtained diﬀerent conﬁgurations. another important factor evaluating eﬀectiveness adversarial samples measure semantic similarity original samples corresponding tainted counterparts. less similarity score denotes semantic meaning original modiﬁed samples quite diﬀerent desired. number changes incurred obtain adversarial sample also good measure evaluating algorithm. number changes made craft successful adversarial sample ideally low. also measure indicates words contributing highly towards determination class-label eqn. detected replaced earlier process crafting. unlike images text sample always convertible adversarial counterpart. presence constraints used crafting process necessary building meaningful text sample. also observed evaluating method textfool comparative study. thus semantic similarity text sample adversarial counterpart valid adversarial sample crafted successfully. experimentation training test given imdb dataset explicitly. accuracy baseline compare variations considered experimentation. adversarial counterpart samples test compare baseline accuracy mentioned measures given table order show eﬀectiveness using genre speciﬁc keywords candidate pool process crafting show mentioned values table genre speciﬁc keywords considered candidate pool apart model performance also observe number test samples converted corresponding adversarial samples successfully semantic similarity pairs. semantic similarity measured using spacy toolbox. average semantic similarity original text sample adversarial counterparts without using genre speciﬁc keywords respectively. semantic similarity original corresponding perturbed samples decrease genre speciﬁc keywords candidate pool number valid adversarial samples generated also increases case seventh eighth table show classiﬁcation accuracy original test perturbed test re-training adversarial samples. diﬀerence accuracies rows less shows model generalized well retraining. table evident proposed method adversarial sample crafting text capable synthesizing semantically correct adversarial text samples original text sample. table also shows inclusion genre speciﬁc keywords deﬁnitely boost quality sample crafting. evident fact drop accuracy classiﬁer re-training original text sample adversarialy crafted text sample genre speciﬁc keywords used. figure shows graph indicates number changes required create successful adversarial samples without using genre-speciﬁc keywords. observe genre speciﬁc keywords creating adversarial samples number tainted sample produced genre speciﬁc keywords used number changes done cases dataset contains twitter comments various topics male female users task predict gender looking tweet data. dataset contains instances features. though twitter dataset much smaller size tweets also shorter length reviews imdb dataset challenging tweets contain lots urls hash descriptions. data preprocessing feature extraction consider features dataset ’texts’ ’description’ determining gender. instances consider instances feature ’gender conﬁdence’ score leaves samples samples used training number samples used testing purpose. concatenate strings features ’text’ ’description’ feature extraction classiﬁcation task. number occurrence words tweets considered features experimentation. average semantic similarity text samples corresponding adversarial counterpart test proposed method textfool respectively. hence proposed method able create large number semantically correct adversarial samples twitter dataset. results show eﬃciency proposed method done imdb movie review dataset. dataset compare work performance textfool table shows classiﬁcation accuracy classiﬁer trained diﬀerent training dataset. ﬁrst case classiﬁer trained original train samples obtained spiting dataset mentioned next synthesize adversarial samples training figure plot showing number adversarial samples produced number changes incurred text samples without using genre speciﬁc keywords imdb movie review dataset. retrain classiﬁer observe classiﬁcation accuracies clean tainted text respectively table shows classiﬁcation accuracy original tainted text samples re-training model. also shows number successful adversarial samples created test evident method able produce larger number adversarial samples also close terms semantic meaning text original form. finally show examples synthetic adversarial samples produced using textfool proposed method datasets fig. .the examples show examples diﬀerent rules incorporated proposed method paper describe method modify input text create adversarial sample. best knowledge ﬁrst papers synthesize adversarial samples complicated text samples. unlike images texts number conditions must satisﬁed modiﬁcation steps ensure preservation semantic meaning grammar text sample. paper considering word time selecting appropriate modiﬁcation greedy way. however much better approach consider sentences text sample modifying eventually confuses classiﬁer. work steps adopted modiﬁcations heuristic nature improved automated obtain better results.", "year": 2017}