{"title": "Object-oriented Neural Programming (OONP) for Document Understanding", "tag": ["cs.LG", "cs.AI", "cs.CL", "cs.NE"], "abstract": "We propose Object-oriented Neural Programming (OONP), a framework for semantically parsing documents in specific domains. Basically, OONP reads a document and parses it into a predesigned object-oriented data structure (referred to as ontology in this paper) that reflects the domain-specific semantics of the document. An OONP parser models semantic parsing as a decision process: a neural net-based Reader sequentially goes through the document, and during the process it builds and updates an intermediate ontology to summarize its partial understanding of the text it covers. OONP supports a rich family of operations (both symbolic and differentiable) for composing the ontology, and a big variety of forms (both symbolic and differentiable) for representing the state and the document. An OONP parser can be trained with supervision of different forms and strength, including supervised learning (SL) , reinforcement learning (RL) and hybrid of the two. Our experiments on both synthetic and real-world document parsing tasks have shown that OONP can learn to handle fairly complicated ontology with training data of modest sizes.", "text": "propose object-oriented neural programming framework semantically parsing documents speciﬁc domains. basically oonp reads document parses predesigned object-oriented data structure reﬂects domain-speciﬁc semantics document. oonp parser models semantic parsing decision process neural net-based reader sequentially goes document process builds updates intermediate ontology summarize partial understanding text covers. oonp supports rich family operations composing ontology variety forms representing state document. oonp parser trained supervision diﬀerent forms strength including supervised learning reinforcement learning hybrid two. experiments synthetic real-world document parsing tasks shown oonp learn handle fairly complicated ontology training data modest sizes. mapping document structured machine readable form canonical probably eﬀective document understanding. quite recent eﬀorts designing neural net-based learning machines purpose roughly categorized groups sequence-to-sequence model neural black neural component predesigned statistical model however argue approaches serious problems cannot used document relatively complicated structures. towards solving problem proposed object-oriented neural programming framework semantically parsing in-domain documents. oonp neural net-based also sophisticated architecture mechanism designed taking outputting discrete structures hence nicely combining symbolism connectionism ability argue paper critical document understanding. emphasize central position objects parsing model indeed representation objects oonp allows neural symbolic reasoning complex structures hence make possible represent much richer semantics. similar object-oriented programming oonp concept class objects following analogousness class deﬁnes types organization information contains deﬁne inheritance class diﬀerent abstract levels needed; object instance certain class encapsulating number properties operations; objects connected relations pre-determined type. based objects deﬁne ontology operations reﬂect intrinsic structure parsing task. parsing oonp reads document parses object-oriented data structure series discrete actions along reading document sequentially. oonp supports rich family operations composing ontology ﬂexible hybrid forms knowledge representation. oonp parser trained supervised learning reinforcement learning hybrid two. experiments synthetic dataset realworld datasets shown eﬃcacy oonp document understanding tasks variety characteristics. addition work semantic parsing mentioned above oonp also related multiple threads work natural language processing machine learning. inspired modeling parsing decision process also state-tracking models dialogue system mixture symbolic probabilistic representations dialogue state. oonp also related modeling transition symbolic state explicit modeling entities. oonp also obviously related recent work neural-symbolism oonp parser consists reader equipped read/write heads inline memory represents document carry-on memory summarizes current understanding document time step. document parse oonp ﬁrst preprocesses puts inline memory reader controls read-heads sequentially inline memory time update carry-on memory. figure overall digram oonp stands symbolic representation stands distributed representation stands hybrid representation symbolic distributed parts. matrix memory denoted mmat matrix-type memory ﬁxed size differentiable read/write controlling neural simplest case could vector hidden state conventional recurrent neural netwokr intuitively mobj stores extracted knowledge deﬁned structure strong evidence mmat keeps knowledge fuzzy uncertain incomplete waiting future information conﬁrm complete clarify. inline memory denoted minl designed save location-speciﬁc information document. sense information inline memory level unstructured waiting reader fuse integrate structured representation. operations oonp. speciﬁcally takes input diﬀerent forms processes updates memory shown figure reader contains neural controller multiple symbolic processors neural controller also policy-net sub-component. similar controller neural turing machine neural controller equipped entirely accurate since inline memory modiﬁed reading process also multiple read-heads write-heads diﬀerentiable read/write matrix memory inline memory possibly variety addressing strategies policy-net however issues discrete outputs gradually builds updates object memory time actions could also updates symbolic part inline memory needed. symbolic processors designed handle information symbolic form object memory inline memory action history policy-net inline memory action history eventually generated policy-net. oonp reached underlined word inline memory. moment oonp objects audi- respectively object memory. reader determines information currently holding updates status property sold along update matrix memory action history. oonp uses symbolic memory graph structure part state parsing process. memory created updated sequential actions decision process used semantic representation text end; roadmap paper rest paper organized follows. elaborate components oonp section actions oonp section give detailed analysis neural-symbolism oonp section section discuss learning oonp followed experiments three datasets section finally conclude paper section section discuss major components oonp namely object memory inline memory reader. omit discussion matrix memory action history since straightforward given description section object including internal properties operations object connected others. internal properties diﬀerent types example string category usually correspond diﬀerent actions composing them string-type property usually copied original text inline memory category properties usually needs rendered classiﬁer. links nature bi-directional meaning added ends modeling convenience might choose directional figure linked objects three classes taking item-object example internal properties linked event-objects stolen disposed link respectively. addition symbolic part object also distributed presentation serves interface distributed representations reader description simplicity refer symbolic part hybrid representation objects ontology slight abuse word. object-embedding serves dual representation symbolic part object recording relevant information associated represented ontology e.g. context text object created. representations object memory including ontology object embeddings updated time operations deﬁned corresponding classes. usually actions driving force operations initiate grow ontology also coordinate diﬀerentiable operations. example object-embedding associated certain object changes non-trivial action concerning object e.g. update internal properties external links even mention without update. paper limit structure classes possible even beneﬁcial hierarchy classes. words classes diﬀerent levels abstractness allow object abstract class child class parsing process information obtained. ﬁnal ground truth change time. partial history text corresponding ontology always part ﬁnal missing part lack information. task section example. important notice categorization depends text also heavily deﬁnition ontology. taking text figure example deﬁne ownership relation person-object item-object ontology becomes dynamical since ownership changed john. inline memory stores relatively representation document follows temporal structure text illustrated figure basically inline memory array memory cells corresponding pre-deﬁned language unit order original text. cell distributed part symbolic part designed save result preprocessing text diﬀerent models certain output reader example previous reading rounds. following examples preprocessing parsing process reader write inline memory discrete continuous outputs process named notes-taking. output continuous notes-taking process similar interactive attention machine translation ntm-style write-head neural controller. output discrete notes-taking essentially action issued policy-net. inline memory provides represent locally encoded level knowledge text read evaluated combined global semantic representation carry-on memory reader. particular advantage setting allows incorporate local decisions models including higher order ones like local relations across language units illustrated left panel figure also rather nonlinear representation document inline memory. particular example location representation current word representation rest sentence representation rest current paragraph enables reader information history future diﬀerent scales illustrated right panel figure reader control center oonp manages operations oonp parsing process. reader three symbolic processors neural controller components reader coupled intensive exchange information shown figure snapshot information processing time reader note consider single action simplicity practice common multiple actions time step requires slightly complicated design policy well processing pipeline. figure particular implementation reader closer look reveals details entanglement neural symbolic components. dashed lines stand continuous signal solid lines discrete signal probability. speciﬁcally given reader forms temporary object structure including symbolic distributed sections. addition also virtual object action class denoted ocnew mat. given time-dependent vector formed reader based information deﬁne following types score functions namely measure level matching information hand existed objects well likeliness creating object nothing. process pictorially illustrated figure therefore deﬁne following probability stochastic policy figure pictorial illustration reader sees determining whether object relevant object read-head inline memory reaches last word sentence figure color arrow line stands diﬀerent matching functions object classes dashed lines object. many actions essentially trivial symbolic part example policy-net chooses none new-assign assigns information hand existed object choose update nothing update.x action aﬀect distributed operations reader. distributed operation aﬀect representation matrix memory object-embedding object memory. update.x step policy-net needs choose property external link update selected object determined new-assign step. update.x chooses update external link policy-net needs determine object links updatewhat updates chosen property links. task static ontology internal properties links locked updated ﬁrst time exception semi-structured property dynamical ontology contrary many important properties links always subject changes. link often determined ends e.g. link states fact tina carries apple either speciﬁed tina apple experiment section practice often convenient make asymmetrical reduce size action space. figure give example entire episode oonp parsing short text given example figure note diﬀerent late treatment actions selection actions absorbed updating actions simplify illustration. oonp oﬀers parse document imitates cognitive process human reading comprehending document oonp maintains partial understanding document mixture symbolic distributed shown figure reader taking issuing symbolic signals continuous signals entangled neural controller. oonp plenty space symbolic processing implementation figure carried three symbolic processors. symbolic processors input symbolic representation could rendered partially neural models therefore providing intriguing entangle neural symbolic components. three examples implemented diﬀerent tasks symbolic analysis action history many symbolic summary history extracted constructed sequence actions e.g. system object person-class words system paragraph starting implementation reader shown figure event-. analysis carried component called symbolic analyzer. based structured representation history reader might able make informed guess like coming paragraph starts might want event- based symbolic reasoning. kind guess directly translated feature assist reader’s decisions resembling high-order features sequential decision makes possible construct much richer class features symbolic reasoning including recursive structure. example found special case oonp event identiﬁcation. symbolic reasoning object memory extra symbolic reasoner take care high-order logic reasoning update object memory caused actions. illustrated following example. tina carries apple tina moves kitchen garden time supposing tina-carry-apple tina-islocatedat-kitchen relation kept object memory time oonp updates tina -islocatedat-kitchen tina -islocatedatgarden time symbolic reasoner help update relation apple -islocatedat-kitchen apple -islocatedat-garden feasible since object memory supposed logically consistent. external logic-based update often necessary since hard neural controller entire object memory diﬃculty distributed representation dynamic structure there. please section experiments. parameters oonp models include operations composing distributed sections inline memory. trained diﬀerent learning paradigms takes supervised learning reinforcement learning allowing diﬀerent ways two. basically supervised learning oracle gives ground truth right action time step entire decision process parameter tuned maximize likelihood truth. sense represents rather strong supervision related imitation learning often requires labeler give ﬁnal truth also decision made. supervised learning objective function given reinforcement learning supervision given rewards decision process extreme case give ﬁnal reward decision process comparing generated ontology ground truth e.g. oonp applied real-world tasks often quite natural speciﬁcally static ontology often infer right actions certain time steps observing ﬁnal ontology based basic assumption e.g. fully reverse-engineered categorical properties object resort determine time decision also need train policy-net content decision. fortunately quite straightforward combine learning paradigms optimization. speciﬁcally maximize combined objective actually indicates deep coupling supervised learning reinforcement learning since episode samples actions related might aﬀect inputs models supervised learning. dynamical ontology impossible derive decisions ﬁnal ontology since change time. those rely mostly supervision time step train action count model learn dynamics ontology evolution ﬁtting ﬁnal ground truth. scenarios discussed section synthetic task. implemented oonp enriched version babi tasks intermediate representation history arbitrary length. experiment considered original babi task- instance shown left panel figure ontology three types objects person-object item-object location-object three types links task oonp read episode story recover trajectory evolving ontology. choose synthetic dataset dynamical ontology evolves time ground truth given snapshot illustrated figure comparing real-world tasks present later babi almost trivial internal property relatively rich opportunities links considering objects diﬀerent types could potentially link. preprocessing trivial names people items locations word-level bi-directional distributed representations inline memory. parsing process reader goes inline word-by-word temporal order original text makes new-assign action every word leaving update.x updatewhat actions time steps read-head inline memory reaches punctuation simple task almost fully neural reader vector matrix memory however symbolic reasoner logic reasoning update links illustrated following example. suppose time ontology training episodes length evenly distributed six. reinforce ﬁnal reward deﬁned overlap generated ontology ground truth step-by-step supervision actions yields almost perfect result evaluation following metrics snapshots test instances since links typically sparse compared possible pairwise relations objects. ‡the logic says item location held person. results summarized table oonp learn fairly well recovering evolving ontology small training weak supervision clearly shows credit assignment earlier snapshots cause much diﬃculty learning oonp even generic policy search algorithm. surprising observe symbolic reasoner helps improve results discovering links improves performance identifying objects although taken within learning. quite interesting observe oonp achieves rather high accuracy discovering links performs relatively poorly specifying objects. probably fact rewards penalizes objects. implement oonp parsing chinese police report illustrated left panel figure consider corpus cases variety crime categories including theft robbery drug dealing others. ontology designed task mainly consists number person-objects item-objects connected event-object several types relations illustrated right panel figure person-object three internal properties name gender types external links event-object. item-object three internal properties name quantity value types external links event-object. compared babi section police report ontology less pairwise links much richer internal properties objects three objects. although language dataset reasonably formal corpus coverages variety topics language styles high proportion typos. average length document chinese characters digit string counted character. oonp model designed generate ontology illustrated figure decision process actions table pre-processing performed regular third party algorithm simple rule-based extraction yield symbolic part inline memory shown figure distributed part inline memory used dilated diﬀerent choices depth kernel size jointly learned training. making new-assign decision reader considers matching structured objects well hints symbolic part inline memory features pictorially illustrated figure updating objects string-type properties copy-paste strategy extracted string reader sees undetermined category properties existed objects policy-net determine object update property update updating operation milestones decision process e.g. reaching punctuation. task since relations single by-default event-object objects relations reduced category-type properties corresponding objects practice. category-type properties cannot recover new-assign update.x actions label resort learning determine part mixed supervised learning updatewhat actions string-type properties. object class-c. assign current information existed object name object- extracted string. name person-object indexed extracted string. quantity item-object indexed extracted string. value item-object indexed extracted string. link event-object item-object ∈{stolen drug robbed swindled damaged other} accuracy new-assign actions made model accuracy predicting category properties objects proportion instances generated ontology exactly ground truth proportion instances generated ontology achieves consistency ground truth measures accuracy model making discrete decisions well generating ﬁnal ontology. empirically examined several oonp implementations compared bi-lstm baseline results given table bi-lstm essentially simple version oonp without structured carry-on memory designed operations basically consists bi-lstm inline memory encoder two-layer acting simple policy-net prediction actions. since baseline explicit object representation support category type prediction. hence train baseline model perform new-assign actions evaluate assignment accuracy modiﬁed version ontology accuracy counts properties predicted bi-lstm hence favor bi-lstm. consider three oonp variants shown table bi-lstm baseline struggles achieve around assignment accuracy test oonp boost performance arguably diﬀerence performance fact bi-lstm lacks object memory relevant information stored bi-lstm hidden states along reading process. start putting symbolic representation operation reader shown result oonp performance signiﬁcantly improved four metrics. speciﬁcally following observations better generalization. since objects task multiple property slots like name gender quantity value. tried adding original text string property slot embedding additional features e.g. length longest common string candidate string relevant property object. using reinforce determine make prediction category property shown result oonp prediction accuracy category property overall ontology accuracy improved. quite interesting positive impact supervised learning task shared parameters. entanglement learning paradigms oonp topic future research e.g. eﬀect predicting right category property new-assign actions predicted category property among features matching function new-assign actions. also implement oonp parsing court judgement theft. unlike previous tasks court judgements typically much longer containing multiple events diﬀerent types well bulks irrelevant text illustrated left panel figure dataset contains chinese judgement documents divided training/dev/testing texts respectively. ontology designed task mainly consists number person-objects item-objects connected number event-object several types links. event-object three internal properties time location type four types external links person-objects four types external links item-objects addition external links event-objects person-object name internal property. item-object three internal properties description value returned addition external links eventobjects description consists words describing corresponding item could come multiple segments across document. person-object itemobject could linked event-object example person could principal suspect event also companion event illustration judgement document corresponding ontology found figure model conﬁguration similar section however following important diﬀerence. experiment oonp performs -round reading text. ﬁrst round oonp identiﬁes relevant events creates empty event-objects notestaking inline memory save information event segmentation details). second round oonp read updated inline memory ﬁlls eventobjects creates ﬁlls person-objects item-objects speciﬁes links them. object created certain event given extra feature indicating connection used deciding links object event object well determining future new-assign actions. actions round reading summarized table description event-object =event. indicator event-k current word. indicator event-k rest sentence move read-head ﬁrst word next sentence indicator event-k rest paragraph move read-head ﬁrst word next paragraph. move read-head next word move read-head ﬁrst word next sentence move read-head ﬁrst word next paragraph. action nd-round newobject assignobject updateobject.name updateobject.description description item-object extracted string. updateobject.value updateobject.time updateobject.location updateobject.type updateobject.items.x value item-object extracted string. time event-object extracted string. location event-object extracted string. type event-object among {theft disposal restitution} link event-object item-object {stolen damaged restituted disposed link event-object person-object {principal companion buyer victim} metric section compare oonp variants oonp oonp bi-lstm. bi-lstm tested secondround reading oonp variant tested two-round reading. results shown table oonp parsers attain accuracy signiﬁcantly higher bi-lstm models. among oonp achieves accuracy getting entire ontology right accuracy getting consistency ground truth. proposed object-oriented neural programming framework semantically parsing in-domain documents. oonp neural net-based equipped sophisticated architecture mechanism document understanding therefore nicely combining interpretability learnability. experiments synthetic real-world document parsing tasks shown oonp learn handle fairly complicated ontology training data modest sizes.", "year": 2017}