{"title": "Multimedia Semantic Integrity Assessment Using Joint Embedding Of Images  And Text", "tag": ["cs.MM", "cs.AI", "cs.CV", "cs.LG"], "abstract": "Real world multimedia data is often composed of multiple modalities such as an image or a video with associated text (e.g. captions, user comments, etc.) and metadata. Such multimodal data packages are prone to manipulations, where a subset of these modalities can be altered to misrepresent or repurpose data packages, with possible malicious intent. It is, therefore, important to develop methods to assess or verify the integrity of these multimedia packages. Using computer vision and natural language processing methods to directly compare the image (or video) and the associated caption to verify the integrity of a media package is only possible for a limited set of objects and scenes. In this paper, we present a novel deep learning-based approach for assessing the semantic integrity of multimedia packages containing images and captions, using a reference set of multimedia packages. We construct a joint embedding of images and captions with deep multimodal representation learning on the reference dataset in a framework that also provides image-caption consistency scores (ICCSs). The integrity of query media packages is assessed as the inlierness of the query ICCSs with respect to the reference dataset. We present the MultimodAl Information Manipulation dataset (MAIM), a new dataset of media packages from Flickr, which we make available to the research community. We use both the newly created dataset as well as Flickr30K and MS COCO datasets to quantitatively evaluate our proposed approach. The reference dataset does not contain unmanipulated versions of tampered query packages. Our method is able to achieve F1 scores of 0.75, 0.89 and 0.94 on MAIM, Flickr30K and MS COCO, respectively, for detecting semantically incoherent media packages.", "text": "metadata might provide date time image taken. independent existence modality makes multimedia data packages vulnerable tampering data subset modalities multimedia package modied misrepresent repurpose multimedia package. tampering possible malicious intent misleading dangerous. location information example aforementioned caption could modied without easy detect tampering. fig. demonstrates example information manipulation photograph paris casino vegas nevada tower) repurposed photograph real eiel tower paris france. nevertheless image visual cues landmark person familiar location easily detect manipulation. however challenging multimedia analysis task especially abstract real world multimedia data composed multiple modalities image video associated text metadata. multimodal data packages prone manipulations subset modalities altered misrepresent repurpose data packages possible malicious intent. therefore important develop methods assess verify integrity multimedia packages. using computer vision natural language processing methods directly compare image associated caption verify integrity media package possible limited objects scenes. paper present novel deep learning-based approach assessing semantic integrity multimedia packages containing images captions using reference multimedia packages. construct joint embedding images captions deep multimodal representation learning reference dataset framework also provides image-caption consistency scores integrity query media packages assessed inlierness query iccss respect reference dataset. present multimodal information manipulation dataset dataset media packages flickr make available research community. newly created dataset well flickrk coco datasets quantitatively evaluate proposed approach. reference dataset contain unmanipulated versions tampered query packages. method able achieve scores maim flickrk coco respectively detecting semantically incoherent media packages. reference format ayush jaiswal∗ ekraam sabir∗ wael abdalmageed premkumar natarajan. multimedia semantic integrity assessment using joint embedding images text. proceedings multimedia conference mountain view pages. introduction real life data presents multiple modalities information entity event incompletely captured modality separately. example caption associated image person might provide information name person location picture taken ∗ayush jaiswal ekraam sabir contributed equally work paper. verication integrity information contained kind data requires existence form prior knowledge. previous example knowledge represented person’s familiarity location. human beings knowledge learned time external sources encyclopedias knowledge bases motivated important observation multimedia analysis algorithms could also take advantage automatically assess integrity multimedia packages. either implicit explicit paper explore reference dataset multimedia packages assess integrity query packages. assumed include copies query image. otherwise existing image retrieval methods would suce verify multimedia package integrity. present novel framework solve limited version multimedia information integrity assessment problem consider data package contain image accompanying caption. data packages reference dataset used train deep multimodal representation learning models learned dmrlms used assess integrity query packages calculating image-caption consistency scores employing outlier detection models inlierness respect evaluate proposed method publicly available datasets flickrk best knowledge work formally dene larger problem provide approach solve work signicantly dierent past work robust hashing watermarking methods focus prevention information manipulation focuses detection semantic level. rest paper organized follows. section reviews related work. section describe proposed method assessing semantic integrity multimedia packages. section discuss existing public datasets well maim dataset. experimental results analysis presented section finally section conclude paper introduce directions future research. related work content integrity multimedia data tackled past perspective prevention manipulation using watermarking authentication hashing work aims detect tampering data especially images approaches recover original data. group work focuses integrity data modality. work dierent focuses assessing integrity across modalities multimodal package semantic level. larger problem dened assumes images tampered might repurposed thus creating fake data packages inconsistent information. methods paper based recent work deep multimodal represenation learning semantic retrieval images captions involving image-caption ranking deep representation learning performs well learning highly non-linear latent representations data large volumes data available. autoencoders popular framework unsupervised representation learning. ngiam showed maes used learn joint representations data multiple modalities. vukoti´c developed bidnn model learns cross-modal mappings joint representations multimodal data. semantic retrieval images captions vice versa gained traction recent years. several methods developed images captions common feature space similarity cosine similarity used rank anity image-caption pairs return top-k candidates hodosh kernel canonical correlation analysis image features caption features common induced space. wetson provide method simultaneously learn linear mappings image caption features common space objective learning associate images correct captions. frome present deep visual-semantic embedding model learns image features space caption features optimizing loss function maximizes cosine similarity image-caption pairs minimizing images randomly picked text. model kiros based similar framework learns caption features space image features instead. experiments showed model performs much beer task image-caption ranking compared devise. kiros also compared model multimodal recurrent neural network model automatically generates captions images. class methods based caption generation explicitly give score image-caption anity relies perplexity used image-caption ranking retrieval. previous work gives rank image-caption pairs based measure similarity provide check consistency information images associated captions respect reference dataset. work paper provides novel contribution towards larger goal assessing integrity multimodal data packages. semantic integrity assessment approach information integrity assessment data object compare existing knowledge-base assumption exists. explicit implicit observation human beings verify information integrity pieces data using world knowledge learned time external sources encyclopedia develop machine learning models mimic world knowledge models assess integrity query data packages. order verify integrity query multimedia package contains image associated caption assume existence reference similar media packages. call reference dataset serves compare query packages measure integrity. specically train outlier detection model image-caption consistency scores packages calculate inlierness query packages. employ deep multimodal representation learning models jointly encoding images corresponding captions inspired success reected recent literature calculate iccss fig. explains complete integrity assessment system. work multimodal autoencoder bidirectional deep neural network unied visual semantic neural language model embedding model. image features given inputs models along either average wordvec embeddings one-hot encodings words captions odms work one-class support vector machine isolation forest discuss aforementioned dmrlms associated iccss odms detail following subsections. deep multimodal representation learning multimodal autoencoder. autoencoder neural network learns reconstruct input autoencoders typically used learn low-dimensional representations data. network architecture designed input goes series layers decreasing dimensionality produce encoding transformed layers increasing dimensionality nally reconstruct input. ngiam showed autoencoder network used learn representations multiple modalities. train image-caption pairs learn shared representation. fig. shows architecture inspired bimodal deep autoencoder ngiam image caption features passed series unimodal layers combining shared representation layer. decoder module mirror image encoder. reconstruction loss iccs. bidirectional deep neural network. bidnn composed unimodal autoencoders tied weights middle representation layers network trained simultaneously reconstruct modality other learning cross-modal mappings well joint representation. fig. shows bidnn architecture illustrates tied weights beer understanding. formulation joint representation vukoti´c i.e. concatenation activations representation layers. used bidnn package made available vukoti´c implement model. reconstruction loss serves iccs case bidnn also. unified visual semantic neural language model. kiros introduced unied visual semantic neural language model learns representations captions embedding space images image embeddings calculated using deep neural network trained optimize contrastive loss aims maximize cosine similarity representation image learned encoding caption minimizing image captions related fig. shows structure vsm. network uses long short term memory units encode variable-length captions. used package made available kiros trained model cosine similarity becomes natural choice iccs case vsm. one-class support vector machine. ocsvm unsupervised outlier detection model trained positive examples learns decision function based distribution training data original kernel space classify complete training dataset positive class everything else high-dimensional space negative class. model used predict whether data point inlier outlier respect training data. formulation ocsvm well approach assessing semantic integrity data package respect isolation forest. isolation forest collection decision trees isolate data point recursive partitioning random subsets features works randomly selecting feature data point nding random splitvalue minimum maximum values. repeated recursively splits. recursive partitioning tree stops node contains provided data point. seing average number splits required isolate point gives indication outlierness. smaller number higher condence data provide quantitative evaluation performance method three datasets flickrk coco dataset created images captions metadata downloaded flickr training validation testing subsets flickrk coco made available kiros makes sure overlap images among subsets necessary image datasets captions image-caption pairs). image-caption pairs flickrk coco respectively total. dataset image-caption pairs exactly caption unique image. randomly split maim training validation testing subsets. treat training subset dataset framework. replace captions half validation testing images captions images create manipulated image-caption pairs evaluation. analysis inlier/outlier decisions odms system serve prediction semantic information manipulation query packages. scores evaluation metrics. tables summarize results experiments combinations dmrlms odms work flickrk coco maim respectively. treat tampered packages positive class calculating f-tampered negative class f-clean. f-tampered f-clean scores coupled i.e. every pair trained model. consistently performs beer bidnn experiments metrics consistently performing worst. gives insights working dmrlms. even though compress multimodal data reconstruction error learn semantic associations images captions well. bidnn model trained learn cross-modal mappings images captions forces learn semantic associations. explains work beer task. model trained captions representation space images. learning objective explicitly requires learn semantic relationships modalities also scores coco significantly beer datasets. expected explained process captions dataset collected. chen used amazon mechanical turk gather captions strong guidelines quality content. numbers higher simply beer quality captions. conclusions future work real world multimedia data multimodal consisting images videos captions metadata. multiple modalities present additional sources information also makes data packages vulnerable tampering subset modalities might manipulated possible malicious intent. paper formally dened problem provided method solve limited version problem step towards larger goal. method combines deep multimodal representation learning outlier detection methods assess whether caption consistent image package. introduced multimodal information manipulation dataset created larger problem containing images captions various metadata make available research community. presented quantitative evaluation method flickrk coco maim datasets. method able achieve scores maim flickrk coco respectively detecting semantically incoherent media packages. work used general formulation bidnn provided models image features aggregated wordvec caption features inputs. possible end-to-end model images captions inputs combination convolution recurrent layers might perform beer. similarly training image encoder jointly caption encoder might boost performance. intend explore future work. future future work also incorporate metadata assess integrity entire packages. easy framework extended include modalities audio video. leave future work. accordance larger goal semantic multimodal information integrity assessment. acknowledgments references sufyan ababneh rashid ansari ashfaq khokhar. scalable multimediacontent integrity verication robust hashing. electro/information technology ieee international conference ieee //ieeexplore.ieee.org/abstract/document// xinlei chen fang tsung-yi ramakrishna vedantam saurabh gupta piotr dollr lawrence zitnick. microso coco captions data collection evaluation server. arxiv preprint arxiv. //arxiv.org/abs/. andrea frome greg corrado shlens samy bengio dean tomas mikolov others. devise deep visual-semantic embedding model. advances neural information processing systems. hp//papers.nips. cc/paper/-devise-a-deep-visual-semantic-embedding-model micah hodosh peter young julia hockenmaier. framing image description ranking task data models evaluation metrics. journal articial intelligence research hp//www.jair.org/papers/ paper.html ryan kiros ruslan salakhutdinov richard zemel. unifying visualsemantic embeddings multimodal neural language models. arxiv preprint arxiv. hps//arxiv.org/abs/. tsung-yi michael maire serge belongie james hays pietro perona deva ramanan piotr dollr lawrence zitnick. microso coco common objects context. european conference computer vision. springer hp//link.springer.com/chapter/./---- xiao devi parikh. leveraging visual question answering imagecaption ranking. european conference computer vision. springer hp//link.springer.com/chapter/./---- tony ming ting zhi-hua zhou. isolation forest. data mining icdm’. eighth ieee international conference ieee hp//ieeexplore.ieee.org/abstract/document// junhua yang jiang wang alan yuille. explain images multimodal recurrent neural networks. arxiv preprint arxiv. hps//arxiv.org/abs/. sutskever ilya dean. phrases mation processing systems. -distributed-representations-of-words-and-phrases-and-their-compositionality jiquan ngiam aditya khosla mingyu juhan honglak andrew multimodal deep learning. proceedings international conference machine learning hp//machinelearning. wustl.edu/mlpapers/paper les/icmlngiam .pdf vedran vukoti christian raymond guillaume gravier. bidirectional joint representation learning symmetrical deep neural networks multimodal crossmodal applications. proceedings international conference multimedia retrieval. //dl.acm.org/citation.cfm?id= xiaofeng wang kemu pang xiaorui zhou yang zhou jianru xue. visual model-based perceptual image hash content authentication. ieee transactions information forensics security hp//ieeexplore.ieee.org/abstract/document// jason weston samy bengio nicolas usunier. large scale image annotation learning rank joint word-image embeddings. machine learning hp//www.springerlink.com/index/y.pdf cai-ping chi-man xiao-chen yuan. multi-scale image hashing using adaptive local feature extraction robust tampering detection. signal processing hp//www.sciencedirect.com/science/article/ pii/s peter young alice micah hodosh julia hockenmaier. image descriptions visual denotations similarity metrics semantic inference event descriptions. transactions association computational linguistics hps//www.transacl.org/ojs/index.php/tacl/article/view/", "year": 2017}