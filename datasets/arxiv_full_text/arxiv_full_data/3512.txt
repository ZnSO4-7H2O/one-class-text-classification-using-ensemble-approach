{"title": "Rethinking Convolutional Semantic Segmentation Learning", "tag": ["cs.LG", "cs.CV", "stat.ML", "68T45"], "abstract": "Deep convolutional semantic segmentation (DCSS) learning doesn't converge to an optimal local minimum with random parameters initializations; a pre-trained model on the same domain becomes necessary to achieve convergence.In this work, we propose a joint cooperative end-to-end learning method for DCSS. It addresses many drawbacks with existing deep semantic segmentation learning; the proposed approach simultaneously learn both segmentation and classification; taking away the essential need of the pre-trained model for learning convergence. We present an improved inception based architecture with partial attention gating (PAG) over encoder information. The PAG also adds to achieve faster convergence and better accuracy for segmentation task. We will show the effectiveness of this learning on a diabetic retinopathy classification and segmentation dataset.", "text": "usual multi-tasks learning model learned independently; segmentation can’t learned independently. another aspect attempt classiﬁcation step trainable loose labels dataset. addressing concerns work deﬁne fully end-to-end learning system learns classiﬁcation segmentation jointly. show model performance diabetic retinopathy classiﬁcation features segmentation dataset. end-to-end joint segmentation classiﬁcation learning contrast existing semantic segmentation models proposed learning system doesn’t require pre-trained model; learns feedback classiﬁcation node. advantages joint segmentation learning system? section quickly early recent works semantic segmentation using deep learning. several recent works using encoder-decoder structure focus improving mean semantic segmentation benchmarks pasacal-voc ms-coco biomedical image datasets. ﬁrst success using convolutional semantic segmentation achieved fully connected layers replaced using unit strided convolution upsampling layers initialized simple bilinear interpolation used reconstruct abstract—deep convolutional semantic segmentation learning doesn’t converge optimal local minimum random parameters initializations; pre-trained model domain becomes necessary achieve convergence.in work propose joint cooperative end-to-end learning method dcss. addresses many drawbacks existing deep semantic segmentation learning; proposed approach simultaneously learn segmentation classiﬁcation; taking away essential need pre-trained model learning convergence. present improved inception based architecture partial attention gating encoder information. also adds achieve faster convergence better accuracy segmentation task. show effectiveness learning diabetic retinopathy classiﬁcation segmentation dataset. semantic segmentation task using deep learning formulated pixel-wise classiﬁcation problem generally it’s encoder-decoder structure encoder encode features lower dimensional features decoder remap features several probabilistic maps width height input using bilinear interpolation transposed convolutions end-to-end learning encoder-decoder model best achieved using pre-trained classiﬁcation model encoder domain. however simple problem spatial resolutions input size fewer number classes pre-trained model isn’t necessary though helps speed learning process. complex problems many numbers classes higher resolutions learning step doesn’t converge best local optimum without pretrained model; leading inferior validation mean iou. problems completely unrelated domain medical images satellite images etc. segmentation becomes unrelated step; ﬁrst deﬁne train classiﬁcation model encoder train encoder-decoder model. simplify segmentation learning domains complexity? formulate two-step processes step; time learning steps? formulate high-level multi-tasks learning concept train segmentation system. idea pure multitasks learning deviates main principle behind simpliﬁcation learn task feedback another task. case segmentation dependent pretrained model achieved using classiﬁcation step completely independent segmentation. general tasks feature map. deconvnet multilayer deconvolution unpooling network used predict segmentation masks. segnet decoder uses encoder max-pooling indices upsample low-resolution feature maps without learning upsampling layers. also used convolution layer upsampling layer dense feature map. recently object detection semantic segmentation jointly learned mask r-cnn used predict segmentation mask region interest. also several recent methods pspnet reﬁnenet enet sharpmask etc. demonstrated advantages encoder-decoder model using convolution transposed convolution task semantic segmentation. general predicted segmentation mask coarse requires postprocessing remove outliers. densecrf effective post-processing layer semantic segmentation reﬁnes segmentation masks exploiting pixel-level pairwise closeness. biomedical image segmentation deep learning based approach proposed unet diabetic retinopathy detection microaneurysms segmentation using deep learning proposed method adopted patch-wise classiﬁcation segmentation. formulate segmentation learning cooperative learning problem agents operate overlapping domains interact achieve respective goals. terms overlapping domains implies datasets classiﬁcation segmentation sampled distribution; it’s necessary identical sample agents. agent learns generate segmentation masks images help agent responsible classiﬁcation. even though classiﬁer agent capable self-learning interaction segmentation agent results improved generalizability. agents shares chunk parameters uses separate optimizers learn parameters. shared parameters agents learned agents different rate; agents share knowledge learn cooperatively. learning rate classiﬁer agent higher segmentation agent possesses class speciﬁc discriminative knowledge domain. outputs agents input calculated using shared parameters ycommon denotes output shared model part yclf denotes output classiﬁer agent private parameters yseg denotes output segmentation agent private parameters softmax cross-entropy cost used learn agents. segmentation agent design learning context refereed encoder decoder. shows interaction agents; sharing common parameters residual inception module used modiﬁed version base inception block proposed additional convolution used max-pooling ensure rich feature representation. added residual connection block input output shown concatenated features convolved another convolution reduce aliasing added convolved input features; operations number output ﬁlters. apart that used convolution factorization version module classiﬁer node. idea convolution factorization proposed partial attention partial attention selected encoder feature maps. feeding encoder information upsampling boost reconstructed feature representation power. attention mechanism focuses encoder feature maps spatial resolutions equal larger upsampling outputs. max-pooling reduce spatial resolution encoder feature maps upsampling output size; max-pooling ensures maximally activated features. shows overview partial attention mechanism used last feature maps convolution block encoder. switch corresponding max-pooling operation stride identity operation cooperative learning model follows compositional design principles stated strided convolution used down-sample encoder spatial resolution. achieve richer feature representation residual inception block shown used encoder. encoder last layer output used input classiﬁer segmentation agents. classiﬁer agent private node designed using residual factorized inception block shown followed global pool layer fully connected layer number classes classiﬁer. spatial dimension level encoder classiﬁer private node multiples cascaded residual inception blocks used. shows complete design joint segmentation classiﬁcation learning. decoder designed using consecutive transposed convolutions stride kernel size followed partial attention block incorporate encoder information recovering object information. partial attention block attend selective encoder feature maps spatial dimension larger equal upsampled decoder output. encoder feature maps learn input object information multiple abstractions; attention mechanism enables faster convergence decoder parameters improved generalization performance. cooperative learning model also used number labeled samples classiﬁer agent small. classiﬁer agent trained partial random labels doesn’t downgrade segmentation agent performance. around labeled samples classiﬁer around samples random labels accuracy classiﬁer agent lowered without effecting performance segmentation agent. observation indicates ability agents learn cooperatively. also helps towards goal training dataset number labeled images; especially relevant medical image domains. dataset train classiﬁcation agent eyepacs diabetic retinopathy classiﬁcation dataset classes. classes dataset indicate severity level; level level mild level moderate level severe proliferative training images used validation performance calculated images. testing used test provided eyepacs. test labeled internally ophthalmologists. image resized segmentation agent trained dataset prepared help ophthalmologists; selected subset around images eyepacs dataset annotated retinal pathological features mask-based annotation. dataset contains annotation around pathological features additional mask annotation retinal artifacts. split training validation set; images training images used validation. preprocessing classiﬁer segmentation used input size. input images resized randomly cropped patch size used input. extensive data augmentation used random left/right up/down random padding used classiﬁcation segmentation. segmentation masks also processed augmentation corresponding image. additionally classiﬁcation additional augmentation changing image pixel values randomly using contrast saturation used. also image standardized it’s mean dividing standard deviation. training procedure batch normalization used reduce covariate shift achieve faster convergence agents. also used nesterov momentum optimizer polynomial learning rate policy. classiﬁer agent learning rate times segmentation agent. batch size used classiﬁer agent times segmentation agent. higher batch size facilitate faster learning information transfer classiﬁer agent segmentation agent. lower learning rate segmentation agent make sure information passes classiﬁer agent minimal generalization. evaluated model performance eyepacs test images. also trained vgg- inceptionv compare classiﬁcation agent performance proposed approach. also segmentation agent performance comparisons trained fcn-s table shows mean-iou comparisons proposed approach existing algorithms. signiﬁcant performance gain obtained join segmentation learning. fcn-s unet models parameters initialized pre-trained model; trained eyepacs classiﬁcation set. randomly initialize fcn-s unet model parameters; results become non-informatory shown table fcn-s unet could achieve convergence optimal local minimum. table table understand limitations importance pre-trained model traditional segmentation learning. joint learning achieves convergence optimal local minimum random initializations. figure shows qualitative performance segmentation agent respect ground truths modiﬁed unet design. joint segmentation performs better improved unet design. considering complexity problem identify small lesions; proposed architecture able learn meaningful features without pre-trained model. presented end-to-end deep convolutional semantic segmentation learning method achieves faster convergence better accuracy random parameters initializations. also network learns classiﬁcation segmentation domain. also showed performance methods biomedical image processing dataset eyepacs detect classify diabetic retinopathy. important aspects work classiﬁer agent trained lose/ partial random labels without degrading segmentation agent performance; helps towards solving label scarcity problems medical image domain. would like thank data team leads rajarajalakshmi kodhandapani ophthalmologists artelus; helped prepare segmentation dataset. also would like thank colleagues anurag sahay lalit pant valuable advice work. szegedy vanhoucke ioffe shlens wojna rethinking inception architecture computer vision. proceedings ieee conference computer vision pattern recognition l.-c. chen papandreou kokkinos murphy l.yuille. deeplab semantic image segmentation deep convolutional nets atrous convolution fully connected crfs. arxiv. zheng jayasumana romera-paredes vineet torr conditional random ﬁelds recurrent neural networks. proceedings ieee international conference computer vision ronneberger fischer brox u-net convolutional networks biomedical image segmentation. international conference medical image computing computer-assisted intervention springer cham. https//github.com/openagi/teﬂa abadi agarwal barham brevdo chen citro ghemawat tensorﬂow large-scale machine learning heterogeneous distributed systems. arxiv preprint arxiv.", "year": 2017}