{"title": "A Generative Model for Deep Convolutional Learning", "tag": ["stat.ML", "cs.LG", "cs.NE"], "abstract": "A generative model is developed for deep (multi-layered) convolutional dictionary learning. A novel probabilistic pooling operation is integrated into the deep model, yielding efficient bottom-up (pretraining) and top-down (refinement) probabilistic learning. Experimental results demonstrate powerful capabilities of the model to learn multi-layer features from images, and excellent classification results are obtained on the MNIST and Caltech 101 datasets.", "text": "generative model developed deep convolutional dictionary learning. novel probabilistic pooling operation integrated deep model yielding efﬁcient bottom-up top-down probabilistic learning. experimental results demonstrate powerful capabilities model learn multi-layer features images excellent classiﬁcation results obtained mnist caltech datasets. develop deep generative statistical model starts highest-level features maps sequence layers ultimately mapping data plane feature given layer mapped multinomial distribution feature block features layer analogous method sense imposing non-zero activation within pooling block. bottom-up pretraining initially sequentially learn parameters layer time bottom based features layer below. however reﬁnement phase model parameters learned jointly topdown. consecutive layer model locally conjugate statistical sense learning model parameters readily performed using sampling variational methods. modeling framework assume gray-scale images {x}n=n rnx×ny; images analyzed jointly learn convolutional dictionary {d}k=k. speciﬁcally consider model assume l-layer model layer layer layer bottom closest data. pretraining stage output layer input layer pooling. layer dictionary elements have figure schematic proposed generative process. left bottom-up pretraining right top-down reﬁnement. block pixels pixel layer relative locations pixels relative locations blocks within block either nxny pixels zero pixel non-zero position pixel selected stochastically multinomial distribution. pixel layer equals largest-amplitude element associated block learning performed top-down generative model constitutes reﬁnement parameters learned pretraining excellent initialization constituted parameters learned pretraining subsequent model performance. reﬁnement phase proceed down generative process constitutes convolution manifested; absent layers except layer data performed. element associated pooling block experimental results apply model mnist caltech datasets. mnist dataset table summaries classiﬁcation results model compared related results mnist data. second layer features corresponding reﬁned dictionary sent nonlinear support vector machine gaussian kernel one-vs-all multi-class classiﬁer classiﬁer parameters tuned -fold cross-validation caltech dataset next consider caltech dataset.for caltech classiﬁcation follow setup yang selecting images category training testing rest. features testing images inferred based top-layer dictionaries sent multi-class svm; gaussian kernel non-linear parameters tuned cross-validation. related results summarized table conclusions deep generative convolutional dictionary-learning model developed within bayesian setting. proposed framework enjoys efﬁcient bottom-up top-down probabilistic inference. probabilistic pooling module integrated model component developing principled top-down generative model efﬁcient learning inference. extensive experimental results demonstrate efﬁcacy model learn multi-layered features images.", "year": 2015}