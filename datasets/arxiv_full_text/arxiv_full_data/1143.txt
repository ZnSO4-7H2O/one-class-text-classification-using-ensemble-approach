{"title": "Online Deep Learning: Growing RBM on the fly", "tag": ["cs.NE", "cs.LG", "stat.ML"], "abstract": "We propose a novel online learning algorithm for Restricted Boltzmann Machines (RBM), namely, the Online Generative Discriminative Restricted Boltzmann Machine (OGD-RBM), that provides the ability to build and adapt the network architecture of RBM according to the statistics of streaming data. The OGD-RBM is trained in two phases: (1) an online generative phase for unsupervised feature representation at the hidden layer and (2) a discriminative phase for classification. The online generative training begins with zero neurons in the hidden layer, adds and updates the neurons to adapt to statistics of streaming data in a single pass unsupervised manner, resulting in a feature representation best suited to the data. The discriminative phase is based on stochastic gradient descent and associates the represented features to the class labels. We demonstrate the OGD-RBM on a set of multi-category and binary classification problems for data sets having varying degrees of class-imbalance. We first apply the OGD-RBM algorithm on the multi-class MNIST dataset to characterize the network evolution. We demonstrate that the online generative phase converges to a stable, concise network architecture, wherein individual neurons are inherently discriminative to the class labels despite unsupervised training. We then benchmark OGD-RBM performance to other machine learning, neural network and ClassRBM techniques for credit scoring applications using 3 public non-stationary two-class credit datasets with varying degrees of class-imbalance. We report that OGD-RBM improves accuracy by 2.5-3% over batch learning techniques while requiring at least 24%-70% fewer neurons and fewer training samples. This online generative training approach can be extended greedily to multiple layers for training Deep Belief Networks in non-stationary data mining applications without the need for a priori fixed architectures.", "text": "propose novel online learning algorithm restricted boltzmann machines namely online generative discriminative restricted boltzmann machine provides ability build adapt network architecture according statistics streaming data. ogd-rbm trained phases online generative phase unsupervised feature representation hidden layer discriminative phase classiﬁcation. online generative training begins zero neurons hidden layer adds updates neurons adapt statistics streaming data single pass unsupervised manner resulting feature representation best suited data. discriminative phase based stochastic gradient descent associates represented features class labels. demonstrate ogd-rbm multi-category binary classiﬁcation problems data sets varying degrees class-imbalance. ﬁrst apply ogd-rbm algorithm multi-class mnist dataset characterize network evolution. demonstrate online generative phase converges stable concise network architecture wherein individual neurons inherently discriminative class labels despite unsupervised training. benchmark ogd-rbm performance machine learning neural network classrbm techniques credit scoring applications using public non-stationary two-class credit datasets varying degrees class-imbalance. report ogdrbm improves accuracy batch learning techniques requiring least fewer neurons fewer training samples. online generative training approach extended greedily multiple layers training deep belief networks non-stationary data mining applications without need priori ﬁxed architectures. approaches applications ranging image classiﬁcation medical diagnostics credit fraud analytics however challenging adaptively train deep neural networks track changes data distribution especially streaming data applications. moreover training multiple layer neural networks requires priori speciﬁcation suitable network architecture thus diﬃcult inform choice architecture statistics data. online learning approaches deep neural networks potential address challenges. several studies forth online learning algorithms training single layer perceptron networks single layer feedforward neural networks trained online fashion using stochastic gradient descent extended kalman filters parameter update. however remains challenging extend successes task training deep neural networks fully online manner. example online algorithms denoising autoencoders used incremental feature learning streaming data need priori training architecture building block learn base features ﬁrst. further incremental learning applied within boosting convolutional neural network framework feature augmentation loss function updation ﬁne-tuned back propagation information accumulating successive minibatches finally also shown updating greedily pre-trained layer-wise restricted boltzmann machines online fashion automatically learns discriminative features classiﬁcation however approaches require pre-training and/or ﬁxed base network architecture precursor incremental online updates streaming data. thus methods evolve network architecture scratch online manner data streams would oﬀer novel capabilities online learning deep neural networks. paper present unsupervised online learning algorithm named online generative discriminative restricted boltzmann machine generative hence layer-wise training dbn. beginning neurons hidden layer rbm. samples stream ability network represent sample assessed using reconstruction error sample. based reconstruction error algorithm either deletes samples well represented adds neuron hidden layer represent sample updates weights existing neurons network. network updates tailored represent distributions distinctive input features network compact inherently discriminative finally features learned generative phase mapped speciﬁc classes discriminative learning. ﬁrst demonstrate unique abilities ogd-rbm represent distinctive class distributions learn manner invariant training data sequence study well-explored mnist data set. sequential invariance much like invariance permutations training seen batch learning algorithms evaluate performance ogd-rbm binary classiﬁcation tasks variety highly unbalanced streaming credit fraud analytics datasets. critical learn distribution minority class highly imbalanced data online learning provides premise eﬃciently learn under-represented minority class owing ability detect novelty data. results show ogd-rbm perform better batch lesser network resources fewer training samples batch methods. main contributions paper paper organized follows. first present ogd-rbm architecture algorithm. next demonstrate learning algorithm ogd-rbm using mnist. then evaluate ogd-rbm relation algorithms applied credit fraud detection problem. finally summarize study outline future directions. describe online generative discriminative restricted boltzmann machine learning algorithm. fig. shows phases training ogd-rbm namely online generative learning phase unsupervised feature representation hidden layer discriminative phase supervised modeling class conditional probabilities. restricted boltzmann machine visible hidden layers connected symmetric weights. inputs correspond neurons visible layer. response neurons hidden layer model probability distribution inputs. figure network architecture training phases. online generative learning performed ﬁrst phase wherein network begins zero neurons hidden layer adds and/or adapts network learning progresses derive feature representation data unsupervised manner. next phase performs supervised discriminative modeling associate feature representation class labels. describe online generative learning process feature representation hidden layer. initially hidden layer neurons. data streams online generative learning algorithm adds neurons and/or updates representations existing neurons depending novelty sample. ﬁrst neuron added based ﬁrst sample data set. given point training process network comprises neurons hidden layer corresponding novel samples history samples presented thus far. next sample reconstruction error compared pre-deﬁned thresholds namely novelty threshold marginal representation threshold based comparison algorithm chooses following steps sample sample deemed novel neuron added hidden layer network. input weights connecting hidden neuron neurons input layer obtained function inputs function work assign including neuron updated according describe discriminative training feature representation learned online generative phase mapped conditional class distributions supervised fashion. weights connecting k-th output neuron i-th hidden neuron. here perform discriminative training epochs supervised training using multi-layer perceptron sigmoidal activation function. demonstrate progression learning within proposed ogd-rbm approach make observations algorithm. characterize algorithm mnist data large well-explored multicategory dataset demonstrate ogd-rbm. network trained online fashion using training data set. validity trained network established independently test oﬄine fashion. fig. show evolution reconstruction error network architecture samples stream training. fig. shows reconstruction error high initial samples. model infancy beginning learn. hence samples novel network resulting neurons added however training progresses network learns suﬃcient representation data reconstruction error reduces progressively resulting fewer neurons added network. evident fig. online generative phase converges stable concise network architecture generative training complete next tested eﬀect training data sequence performance algorithm. trained ogd-rbm independently randomly constructed sequences mnist training samples. case presented diﬀerent sequences training data train network. across training trials classiﬁcation accuracy testing data presentation training samples change accuracy network architecture signiﬁcantly showing network able generalize well concise network architecture. study discriminative potential feature representation learned online generative training phase related number ‘novel’ samples corresponding class labels trials. fig. shows average number hidden layer neurons associated class mnist dataset standard deviation across trials. results show individual neurons trained network inherently discriminative class labels despite unsupervised nature training. further observe variability across trials small proportion average number neurons class suggesting neuron-to-class associations largely independent sequence training data samples. online learning algorithms particularly suitable streaming data applications data distribution evolves time therefore relevant problem credit scoring. credit scoring problem estimating probability borrower might default and/or exhibit undesirable behavior future. problem usually characterized imbalanced data huge inter-personal variability across borrowers. problem calls online learning algorithms capable learning distribution data regardless imbalance distinction samples class. several studies employed batch machine learning techniques credit scoring perform analogous evaluations benchmark online learning algorithm relation batch learning techniques. speciﬁcally perform credit fraud prediction using three publicly available data sets namely german credit data australian credit data kaggle ’give credit’ data evaluate ogd-rbm classiﬁer comparison support vector machine classiﬁer multi-layer perceptron neural network classiﬁer classiﬁcation restricted boltzmann machine classiﬁer scoring table method three credit data sets table total number classes number samples class evident public datasets varying degrees class-imbalance. mildly imbalanced german partially imbalanced kaggle gmsc high imbalance across classes. varying degree class-imbalance provides unique opportunity characterize neuron distribution across classes online learning framework. ﬁlled missing values kaggle ’give credit’ data averaging across similar participants population grouped according ages intervals present results ogd-rbm relation batch learning techniques. reproduce previously obtained batch learning results using classrbm classiﬁers although classrbm results reported ﬁxed architecture neurons batch size learning rate architecture classiﬁers speciﬁed. further training accuracies classiﬁers also reported. hence perform independent evaluations using classrbm classiﬁers report additional performance validation beyond previously reported results. proposed ogd-rbm performs better classiﬁers used comparison. could attributed fact learnt distributions represent data well. moreover algorithms learn data batches updates gradients batches ogd-rbm updates gradients based every sample data set. need priori assumption architecture ogd-rbm builds network learning progresses. helps infer number neurons class help characterize distribution samples class. neurons suﬃcient feature representation. class imbalance increases greater proportion hidden layer neurons associated less prevalent classes. adaptation natural consequence online learning process diﬀerentiates approach batch learning algorithms. introduced novel online generative discriminative restricted boltzmann machines algorithm evolves network architecture fully bottom-up online manner data streams demonstrated algorithm converges stable compact network architecture wherein hidden layer neurons implicitly associated class labels classiﬁcation performance invariant sequence training data samples presented. further ogd-rbm performed better batch techniques credit score classiﬁcation streaming data speciﬁcally online learning achieved better accuracy fewer neurons showed unique ability adapt class imbalance. areas future work include expansions unsupervised discriminative training deeper architectures interpretable models.", "year": 2018}