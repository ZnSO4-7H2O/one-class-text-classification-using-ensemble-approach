{"title": "Understanding Neural Networks Through Deep Visualization", "tag": ["cs.CV", "cs.LG", "cs.NE"], "abstract": "Recent years have produced great advances in training large, deep neural networks (DNNs), including notable successes in training convolutional neural networks (convnets) to recognize natural images. However, our understanding of how these models work, especially what computations they perform at intermediate layers, has lagged behind. Progress in the field will be further accelerated by the development of better tools for visualizing and interpreting neural nets. We introduce two such tools here. The first is a tool that visualizes the activations produced on each layer of a trained convnet as it processes an image or video (e.g. a live webcam stream). We have found that looking at live activations that change in response to user input helps build valuable intuitions about how convnets work. The second tool enables visualizing features at each layer of a DNN via regularized optimization in image space. Because previous versions of this idea produced less recognizable images, here we introduce several new regularization methods that combine to produce qualitatively clearer, more interpretable visualizations. Both tools are open source and work on a pre-trained convnet with minimal setup.", "text": "recent years produced great advances training large deep neural networks including notable successes training convolutional neural networks recognize natural images. however understanding models work especially computations perform intermediate layers lagged behind. progress ﬁeld accelerated development better tools visualizing interpreting neural nets. introduce tools here. ﬁrst tool visualizes activations produced layer trained convnet processes image video found looking live activations change response user input helps build valuable intuitions convnets work. second tool enables visualizing features layer regularized optimization image space. previous versions idea produced less recognizable images introduce several regularization methods combine produce qualitatively clearer interpretable visualizations. tools open source work pretrained convnet minimal setup. last several years produced tremendous progress training powerful deep neural network models approaching even surpassing human abilities variety challenging machine learning tasks ﬂagship example training deep convolutional neural networks supervised learning classify natural images area beneﬁtted combined effects faster computing better training techniques better activation units larger labeled datasets thus considerable improvements knowledge create high-performing architectures learning algorithms understanding large neural models operate lagged behind. neural networks long known black boxes because difﬁcult understand exactly particular trained neural network functions large number interacting non-linear parts. large modern neural networks even harder study size; example understanding widely-used alexnet involves making sense values taken million trained network parameters. understanding learned interesting right also improving models intuitions provided understanding current generation models suggest ways make better. example deconvolutional technique visualizing features learned hidden units dnns suggested architectural change smaller convolutional ﬁlters also note tools enable understanding especially beneﬁt vast numbers newcomers deep learning would like take advantage off-the-shelf software packages like theano pylearn caffe torch domains intuition models work experts also beneﬁt iterate ideas models searching good hyperparameters. thus believe experts newcomers beneﬁt tools provide intuitions inner workings dnns. paper provides tools open source scientists practitioners integrate dnns better understand them. ﬁrst tool software interactively plots activations produced layer trained userprovided images video. static images afford slow detailed investigation particular input whereas video input highlights dnns changing responses dynamic input. present videos processed live user’s computer camera especially helpful users move different items around ﬁeld view occlude combine them perform manipulations actively learn different features network respond. second tool introduce enables better visualization learned features computed individual neurons every layer dnn. seeing features learned important understand current dnns work fuel intuitions improve them. attempting understand computations performed layer dnns increasingly popular direction research. approach study layer group investigate type computation performed neurons layer whole approach informative neurons layer interact pass information higher layers thus neuron’s contribution entire function performed depends neuron’s context layer. another approach interpret function computed individual neuron. past studies vein roughly divide different camps dataset-centric network-centric. former requires trained running data network; latter requires trained network itself. dataset-centric approach display images training test cause high activations individual units. another deconvolution method zeiler fernetwork-centric approaches investigate network directly without data dataset. example erhan synthesized images cause high activations particular units. starting initial input activation caused unit input computed steps taken input space along gradient ∂ai/∂x synthesize inputs cause higher higher activations unit eventually terminating deemed preferred input stimulus unit question. case input space image displayed directly interpretation. others followed suit using gradient images cause higher activations lower activations output units. gradient-based approaches attractive simplicity optimization process tends produce images greatly resemble natural images. instead composed collection hacks happen cause high activations extreme pixel values structured high frequency patterns copies common motifs without global structure fact activations effected hacks better understood thanks several recent studies. speciﬁcally shown hacks applied correctly classiﬁed images cause misclassiﬁed even imperceptibly small changes hacks found even without gradient information produce unrecognizable fooling examples abundance non-natural looking images cause extreme activations explained locally linear behavior neural nets strong evidence optimizing images cause high activations produces unrecognizable images hope using methods obtain useful visualizations? turns able appropriately regularize optimization. simonyan showed slightly discernible images ﬁnal layers convnet could produced l-regularization. mahendran vedaldi also showed importance incorporating natural-image priors optimization process producing images mimic entire-layer’s ﬁring pattern produced speciﬁc input image. build works contribute three additional forms regularization that combined produce recognizable optimization-based samples previous methods. optimization stochastic starting different random initial images produce optifigure bottom shows screenshot interactive visualization software. webcam input shown along whole layer conv activations. selected channel pane shows enlarged version conv channel activations. deconv starting selected channel shown. right three selections nine images shown synthetic images produced using regularized gradient ascent methods described section image patches training deconv images. areas highlighted green star relate particular selected channel conv; selection changes panels update. depicts enlarged numerical optimization results channels. conv channel responds strongly faces also responds ﬂowers blanket bottom half right side image response ﬂowers partially seen optimized images would missed analysis focusing nine images deconv versions contain ﬂowers. conv detects different types faces. nine images human faces responds also cat’s face finally conv activates strongly cat’s face optimized images show catlike ears nine images also cats. image softmax output layer predictions egyptian computer keyboard. ﬁgures paper best viewed digitally color signiﬁcantly zoomed describe release software tool provides live interactive visualization every neuron trained convnet responds user-provided image video. tool displays forward activation values preferred stimuli gradient ascent images unit training deconv highlighting images backward diffs computed backprop deconv starting arbitrary units. combined effect complementary visualizations promotes greater understanding neuron computes single method own. also describe insights gained using tool. extend past efforts visualize preferred activation patterns input space adding several types regularization produce believe interpretable images large convnets tools released open source available http//yosinski.com/deepvis. tools could adapted integrate software framework work popular caffe software package users visualizations caffe pretrained comes pre-computed images optimized activate neuron trained network. pre-trained network nearly identical alexnet architecture local reponse normalization layers pooling layers following trained caffe framework imagenet dataset ﬁrst visualization method straightforward plotting activation values neurons layer convnet response image video. fully connected neural networks order units irrelevant plots vectors spatially informative. however convolutional networks ﬁlters applied respects underlying geometry input; case images ﬁlters applied convolution spatial dimensions image. convolution produces activations subsequent layers channel also arranged spatially. layer. conv layer size depict separate grayscale images. small images contains activations spatial spatial layout input data images simply arbitrarily tiled grid row-major order. figure shows zoomed view particular channel conv responds human animal faces. layers viewed software tool including pooling normalization layers. visualizing layers provides intuitions effects functions. although visualization simple implement informative data ﬂowing network visualized. nothing mysterious happening behind scenes. convnet contains single path input output every layer bottleneck information must pass en-route classiﬁcation decision. layer sizes small enough layer easily computer screen. gleaned several surprising intuitions using tool interesting conclusions representations layers seem surprisingly local. instead ﬁnding distributed representations layers example detectors text ﬂowers fruit faces conv conv. conclusions drawn either live visualization optimized images suggest several directions future research using direct input classify photos flickr google images classiﬁcations often correct highly conﬁdent hand using input webcam predictions often cannot correct items training shown image. training set’s classes though numerous cover common household objects. thus shown typical webcam view person imagenet classes present output single high probability expected. surprisingly however probability vector noisy varies signiﬁcantly response tiny changes input often changing merely response noise webcam. might instead expected unchanging conﬁdence predictions given scene object network trained classify present. plotting fully connected layers also reveals similar sensitivity small input changes. conv layer many invariant detectors faces shoulders text etc. moving oneself objects front camera. even though classes contain explicitly labeled faces text network learns identify concepts simply represent useful partial information making later classiﬁcation decision. face detector denoted conv shown figure activating human lion faces figure activating face. zhou recently observed similar effect convnets trained recognize different scene types playgrounds restaurant patios living rooms etc. learn object detectors intermediate layers. reader encouraged visualization tool herself. code together pre-trained models images synthesized gradient ascent downloaded http//yosinski.com/deepvis. second contribution work introducing several regularization methods bias images found optimization toward visually interpretable examples. regularization methods helps combination even effective. found useful combinations random hyperparameter search discussed below. formally consider image rc×h×w color channels height width pixels. image presented neural network causes activation unit simplicity index runs units layers. also deﬁne parameterized regularization function penalizes images various ways. network trained imagenet ﬁrst subtracting per-pixel mean examples imagenet inputting training examples network. thus direct input network thought zero-centered input. pose optimization problem ﬁnding image practice slightly different formulation. because search starting taking gradient steps instead deﬁne regularization operator maps slightly regularized version itself. latter deﬁnition strictly expressive allowing regularization operators figure view activations channel conv layer deep neural network trained imagenet dataset contain face class contain many images faces. channel responds human animal faces robust changes scale pose lighting context discerned user actively changing scene front webcam loading static images seeing corresponding response unit. photo lions flickr user arnolouise licensed by-nc-sa gradient method easy implement within gradient descent framework simply alternating taking step toward gradient taking step direction given gradient descent step size single step process applies update investigated following four regularizations. designed overcome different pathologies commonly encountered gradient descent without regularization. decay common regularization decay penalizes large values implemented decay tends prevent small number extreme pixel values dominating example image. extreme single-pixel values neither occur naturally great frequency useful visualization. decay also used simonyan gaussian blur producing images gradient ascent tends produce examples high frequency information images cause high activations neither realistic interpretable useful regularization thus penalize high frequency information. implement gaussian blur step gaussianblur. convolving blur kernel computationally expensive regularization methods added another hyperparameter every allow example blurring every several optimization steps instead every step. blurring image multiple times small width gaussian kernel equivalent blurring larger width kernel effect similar even image changes slightly optimization process. technique thus lowers computational costs without limiting expressiveness regularization. mahendran vedaldi used penalty similar effect blurring called total variation work reconstructing images layer codes. clipping pixels small norm ﬁrst regularizations suppress high amplitude high frequency information applying both left contains somewhat small somewhat smooth values. however still tend contain non-zero pixel values everywhere. even pixels show primary object type input causing unit consideration activate gradient respect pixels still generally non-zero pixels also shift show pattern well contributing whatever small ultimately raise chosen unit’s activation. wish bias search away behavior instead show main object letting regions exactly zero needed. implement bias using computes norm pixel sets pixels small norm zero. threshold norm speciﬁed percentile pixel norms clipping pixels small contribution instead clipping pixels small norms something slightly smarter clip pixels small contributions activation. computing pixel’s contribution activation measure much activation increases decreases pixel zero; compute contribution pixel zero. approach straightforward prohibitively slow requiring forward pass every pixel. instead approximate process linearizing around case contribution dimension estimated elementwise product gradient. three channels take absolute value computing ∇xai|. absolute value pixels small contribution either direction positive negative. could choose keep pixel transitions setting pixel zero would result large activation increase shifts already handled gradient ascent prefer clip pixels deemed matter take large gradient steps outside region linear approximation valid. deﬁne operation sets pixels contribution percentile zero. regularization methods applied individually somewhat effective producing interpretable images; figure shows effects individual hyperparameter. however preliminary experiments uncovered combined effect produces better visualizations. pick reasonable hyperparameters methods once random hyperparameter search possible combinations settled four complement well. four selected combinations listed table optimized images using shown gorilla class output unit figure four show high frequency information others frequency; contain dense pixel data others contain sparse outlines important regions. found version lower-left quadrant best single hyperparameters often greater intuition gleaned considering four once. figure shows optimization results computed selection units layers. single image every ﬁlter convolutional layers shown supplementary figure nine images ﬁlter layers including imagenet output classes viewed http//yosinski.com/deepvis. figure visualizations preferred inputs different class units layer -dimensional output network ﬁnal softmax. lower left visualizations four different sets regularization hyperparameters gorilla class classes selected four interpretable visualizations produced regularized optimization method. chose four combinations regularization hyperparameters performing random hyperparameter search selecting combinations complement other. example lower left quadrant tends show lower frequency patterns upper right shows high frequency patterns upper left shows sparse important regions. often greater intuition gleaned considering four once. nearly every case found guess class neuron represents viewing sets optimized preferred images. best viewed electronically zoomed figure visualization example features eight layers deep convolutional neural network. images reﬂect true sizes features different layers. layer show visualizations random gradient descent runs channel. images hand picked showcase diversity interpretability visualizations image ﬁlter convolutional layers shown figure supplementary information. recognize important features objects different scales edges corners wheels eyes shoulders faces handles bottles etc. visualizations show increase complexity variation higher layers comprised simpler components lower layers. variation patterns increases increasing layer number indicating increasingly invariant representations learned. particular jump layer layer brings large increase variation. best viewed electronically zoomed table four hyperparameter combinations produce different styles recognizable images. identiﬁed four reviewing images produced randomly selected hyperparameter combinations. bottom hyperparameter combinations produced top-left top-right bottomleft bottom-right gorilla class visualizations respectively figure third hyperparameters produced visualizations classes figure figure shown discriminative networks easily fooled hacked addition certain structured noise image space oft-cited reason property discriminative training leads networks ignore non-discriminative information input e.g. learning detect jaguars matching unique spots ignoring fact four legs. reason seen hopeless endeavor create generative model randomly samples broad distribution space possible images iteratively transforms recognizable image moving region satisﬁes prior posterior class label past attempts largely supported view producing unrealistic images using method however results presented suggest alternate possibility previously used priors simply weak model needed). careful design learning model biases toward realism able harness large number parameters present discriminately learned model generate realistic images enforcing probability models simultaneously. even simple hand-coded models paper regularizers complex dependencies distant pixels already arise implies discriminative parameters also contain signiﬁcant generative structure training dataset; parameters encode jaguar’s spots extent also four legs. better learned probabilistic models input activations higher layers much structure apparent. work shows interesting results direction. images generated paper photo-realistic suggest figure effects regularization method section used individually. four rows shows linear sweep hyperparameter space regularization strong regularization applied strongly regularizations cause optimization fail images less interpretable reason random hyperparameter search useful ﬁnding joint hyperparameter settings worked well together best viewed electronically zoomed introduced visual tools aiding interpretation trained neural nets. intuition gained tools prompt ideas improved methods future research. discuss several ideas. interactive tool reveals representations later convolutional layers tend somewhat local channels correspond speciﬁc natural parts instead dimensions completely distributed code. said features correspond natural parts raising possibility different decomposition world humans might expect. visualizations suggest study exact nature learned representations whether local single channel distributed across several likely interesting work direction). locality representation also suggests transfer learning models trained atop conv conv representations bias toward sparse connectivity could helpful necessary combine features layers create important features higher layers. second tool regularizations enable improved interpretable optimized visualizations learned features help researchers practitioners understand debug improve models. visualizations also reveal twist ongoing story. previous studtransferring discriminatively trained parameters generative models opposite direction usual unsupervised pretraining approach fruitful area investigation. authors would like thank nasa space technology research fellowship funding wendy shang yoshua bengio brian cheung andrej karpathy helpful discussions freckles feline countenance. references bergstra james breuleux olivier bastien fr´ed´eric lamblin pascal pascanu razvan desjardins guillaume turian joseph warde-farley david bengio yoshua. theano math expression compiler. proceedings python scientiﬁc computing conference june oral presentation. deng dong socher richard li-jia fei-fei imagenet large-scale hierarchical image database. computer vision pattern recognition cvpr ieee conference ieee erhan dumitru bengio yoshua courville aaron vincent pascal. visualizing higher-layer features deep network. technical report technical report university montreal glorot xavier bordes antoine bengio yoshua. deep proceedings intersparse rectiﬁer networks. national conference artiﬁcial intelligence statistics. jmlr w&cp volume volume goodfellow warde-farley david lamblin pascal dumoulin vincent mirza mehdi pascanu razvan bergstra james bastien fr´ed´eric bengio yoshua. pylearn arxiv preprint machine learning research library. arxiv. hannun case casper catanzaro diamos elsen prenger satheesh sengupta coates deep speech scaling end-to-end speech recognition. arxiv e-prints december hinton geoffrey srivastava nitish krizhevsky alex sutskever ilya salakhutdinov ruslan improving neural networks preventing co-adaptation feature detectors. arxiv preprint arxiv. yangqing shelhamer evan donahue jeff karayev sergey long jonathan girshick ross guadarrama sergio darrell trevor. caffe convolutional architecture fast feature embedding. arxiv preprint arxiv. krizhevsky alex sutskever ilya hinton geoff. imagenet classiﬁcation deep convolutional neural networks. advances neural information processing systems tsung-yi maire michael belongie serge hays james perona pietro ramanan deva doll´ar piotr zitnick lawrence. microsoft coco common objects context. corr abs/. http//arxiv.org/ abs/.. nguyen yosinski jason clune jeff. deep neural networks easily fooled high conﬁdence predictions unrecognizable images. arxiv e-prints december simonyan karen vedaldi andrea zisserman andrew. deep inside convolutional networks visualising image arxiv preprint classiﬁcation models saliency maps. arxiv. presented iclr workshop szegedy christian zaremba wojciech sutskever ilya bruna joan erhan dumitru goodfellow fergus rob. intriguing properties neural networks. corr abs/. taigman yaniv yang ming ranzato marc’aurelio wolf lior. deepface closing human-level performance face veriﬁcation. computer vision pattern recognition ieee conference ieee yosinski clune bengio lipson transferable features deep neural networks? ghahramani welling cortes lawrence n.d. weinberger k.q. advances neural information processing systems curran associates inc. december zhou bolei khosla aditya lapedriza `agata oliva aude torralba antonio. object detectors emerge deep scene cnns. corr abs/. http//arxiv.org/ abs/.. main text mentioned images produced gradient ascent maximize activations neurons convolutional networks tend dominated high frequency information hypothesis occurs centers around differing statistics activations channels convnet. conv layer consists blobs color oriented gabor edge ﬁlters varying frequencies. average activation values edge ﬁlters vary across ﬁlters frequency ﬁlters generally much higher average activation values high frequency ﬁlters. experiment observed average activation values lowest frequency edge ﬁlters versus average highest frequency ﬁlters difference factor activation values blobs color generally fall middle range. phenomenon likely arises reasons related power spectrum natural images spatial frequencies tend contain higher energy high spatial frequencies consider connections conv ﬁlters single unit conv. order merge information frequency high frequency conv ﬁlters connection weights high frequency conv units generally larger connections frequency conv units order allow signals affect conv unit’s activation similarly. case larger multipliers activation particular conv unit affected small changes activations high frequency ﬁlters frequency ﬁlters. seen direction gradient information passed higher layers lower layers backprop partial derivative arriving conv unit passed backward multiplied larger values destined high frequency conv ﬁlters frequency ﬁlters. thus following gradient pixel space tend produce overabundance high frequency changes instead frequency changes. discussion focuses differing statistics edge ﬁlters conv note activation statistics subsequent layers also vary across layer. produce similar effect rare higher layer features also overrepresented compared common higher layer features. course hypothesis tentative explanation high frequency information dominates gradient. relies assumption average activation unit representative statistic whole distribution activations unit. observation case units similar albeit scaled distributions. however study needed before deﬁnitive conclusion reached. observed statistics vary higher layers different manner channels layers similar average activations variance across channels dominated small number channels unusually small unusually large averages figure optimized preferred image every channel convolutional layers. images produced hyperparameter combinations third table best viewed electronically zoomed", "year": 2015}