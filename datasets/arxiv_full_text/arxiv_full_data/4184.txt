{"title": "Unsupervised Image-to-Image Translation Networks", "tag": ["cs.CV", "cs.AI"], "abstract": "Unsupervised image-to-image translation aims at learning a joint distribution of images in different domains by using images from the marginal distributions in individual domains. Since there exists an infinite set of joint distributions that can arrive the given marginal distributions, one could infer nothing about the joint distribution from the marginal distributions without additional assumptions. To address the problem, we make a shared-latent space assumption and propose an unsupervised image-to-image translation framework based on Coupled GANs. We compare the proposed framework with competing approaches and present high quality image translation results on various challenging unsupervised image translation tasks, including street scene image translation, animal image translation, and face image translation. We also apply the proposed framework to domain adaptation and achieve state-of-the-art performance on benchmark datasets. Code and additional results are available in https://github.com/mingyuliutw/unit .", "text": "unsupervised image-to-image translation aims learning joint distribution images different domains using images marginal distributions individual domains. since exists inﬁnite joint distributions arrive given marginal distributions could infer nothing joint distribution marginal distributions without additional assumptions. address problem make shared-latent space assumption propose unsupervised image-to-image translation framework based coupled gans. compare proposed framework competing approaches present high quality image translation results various challenging unsupervised image translation tasks including street scene image translation animal image translation face image translation. also apply proposed framework domain adaptation achieve state-of-the-art performance benchmark datasets. code additional results available https//github.com/mingyuliutw/unit. many computer visions problems posed image-to-image translation problem mapping image domain corresponding image another domain. example super-resolution considered problem mapping low-resolution image corresponding high-resolution image; colorization considered problem mapping gray-scale image corresponding color image. problem studied supervised unsupervised learning settings. supervised setting paired corresponding images different domains available unsupervised setting independent sets images consists images domain consists images another domain—there exist paired examples showing image could translated corresponding image another domain. lack corresponding images unsupervised image-to-image translation problem considered harder applicable since training data collection easier. analyzing image translation problem probabilistic modeling perspective challenge learn joint distribution images different domains. unsupervised setting sets consist images marginal distributions different domains task infer joint distribution using images. coupling theory states exist inﬁnite joint distributions arrive given marginal distributions general. hence inferring joint distribution marginal distributions highly ill-posed problem. address ill-posed problem need additional assumptions structure joint distribution. make shared-latent space assumption assumes pair corresponding images different domains mapped latent representation shared-latent space. based assumption propose unit framework based generative adversarial networks variational autoencoders model image domain using vae-gan. adversarial training objective interacts weight-sharing constraint enforces sharedlatent space generate corresponding images domains variational autoencoders relate translated images input images respective domains. applied proposed figure shared latent space assumption. assume pair corresponding images different domains mapped latent code shared-latent space encoding functions mapping images latent codes. generation functions mapping latent codes images. proposed unit framework. represent using cnns implement shared-latent space assumption using weight sharing constraint connection weights last layers tied connection weights ﬁrst layers tied. here self-reconstructed images domain-translated images. adversarial discriminators respective domains charge evaluating whether translated images realistic. framework various unsupervised image-to-image translation problems achieved high quality image translation results. also applied domain adaptation problem achieved state-ofthe-art accuracies benchmark datasets. shared-latent space assumption used coupled joint distribution learning. here extend coupled work unit problem. also note several contemporary works propose cycle-consistency constraint assumption hypothesizes existence cycle-consistency mapping image source domain mapped image target domain translated image target domain mapped back original image source domain. paper show shared-latent space constraint implies cycle-consistency constraint. image domains. supervised image-to-image translation given samples drawn joint distribution unsupervised image-to-image translation given samples drawn marginal distributions since inﬁnite possible joint distributions yield given marginal distributions could infer nothing joint distribution marginal samples without additional assumptions. make shared-latent space assumption. shown figure assume given pair images exists shared latent code shared-latent space recover images code compute code images. postulate exist functions that given pair corresponding images joint distribution conversely within model function maps represented composition g∗). similarly g∗). unit problem becomes problem learning note necessary condition exist cycle-consistency constraint ∗→). reconstruct input image translating back translated input image. words proposed shared-latent space assumption implies cycle-consistency assumption implement shared-latent space assumption assume shared intermediate representation process generating pair corresponding images admits form consequently common high-level generation function maps low-level generation functions respectively. case multi-domain image translation regarded compact high-level representation scene considered particular realization would actual image formation functions modality assuming also allow represent e∗l. next section discuss realize ideas proposed unit framework. framework illustrated figure based variational autoencoders generative adversarial networks consists subnetworks including domain image encoders domain image generators domain adversarial discriminators several ways exist interpret roles subnetworks summarize table framework learns translation directions shot. vae. encoder–generator pair constitutes domain termed vae. input image ﬁrst maps code latent space encoder decodes random-perturbed version code reconstruct input image generator assume components latent space conditionally independent gaussian unit variance. formulation encoder outputs mean vector distribution latent code given identity matrix. reconstructed image note abused notation since treated distribution random vector sampled similarly constitutes encoder outputs mean vector distribution latent code given reconstructed image utilizing reparameterization trick non-differentiable sampling operation reparameterized differentiable operation using auxiliary random variables. reparameterization trick allows train vaes using back-prop. random vector multi-variate gaussian distribution sampling operations implemented respectively. weight-sharing. based shared-latent space assumption discussed section enforce weight-sharing constraint relate vaes. speciﬁcally share weights last layers responsible extracting high-level representations input images domains. similarly share weights ﬁrst layers responsible decoding high-level representations reconstructing input images. note weight-sharing constraint alone guarantee corresponding images domains latent code. unsupervised setting pair corresponding images domains exists train network output latent code. extracted latent codes pair corresponding images different general. even same latent component different semantic meanings different domains. hence latent code could still decoded output unrelated images. however show adversarial training pair corresponding images domains mapped common latent code respectively latent code mapped pair corresponding images domains respectively. shared-latent space assumption allows perform image-to-image translation. translate image image applying term information processing stream image translation stream. image translation streams exist proposed framework streams trained jointly image reconstruction streams vaes. could ensure pair corresponding images mapped latent code latent code decoded pair corresponding images would form pair corresponding images. words composition functions approximates unsupervised image-to-image translation discussed section composition function approximates gans. framework generative adversarial networks real images sampled ﬁrst domain output true images generated output false. generate types images images reconstruction stream images translation since reconstruction stream supervisedly trained stream sufﬁce apply adversarial training images translation stream apply similar processing trained output true real images sampled second domain dataset false images generated cycle-consistency since shared-latent space assumption implies cycle-consistency constraint could also enforce cycle-consistency constraint proposed framework regularize ill-posed unsupervised image-to-image translation problem. resulting information processing stream called cycle-reconstruction stream. learning. jointly solve learning problems image reconstruction streams image translation streams cycle-reconstruction streams hyper-parameters control weights objective terms divergence terms penalize deviation distribution latent code prior distribution. regularization allows easy sample latent space model using laplacian distributions respectively. hence minimizing negative log-likelihood term equivalent minimizing absolute distance image reconstructed image. prior distribution zero mean gaussian objective functions given objective functions conditional objective functions. used ensure translated images resembling images target domains respectively. hyperparameter controls impact objective functions. vae-like objective function model cycle-consistency constraint given negative log-likelihood objective term ensures twice translated image resembles input terms penalize latent codes deviating prior distribution cycle-reconstruction stream hyper-parameters control weights different objective terms. inheriting training proposed framework results solving mini-max problem optimization aims saddle point. seen player zero-sum game. ﬁrst player team consisting encoders generators. second player team consisting adversarial discriminators. addition defeating second player ﬁrst player minimize losses cycle-consistency losses. apply alternating gradient figure illustration dataset. left satellite image. right map. translate holdout satellite images maps measure accuracy achieved various conﬁgurations proposed framework. translation accuracy versus different network architectures. translation accuracy versus different hyper-parameter values. impact weight-sharing cycle-consistency constraints translation accuracy. update scheme similar described solve speciﬁcally ﬁrst apply gradient ascent step update ﬁxed. apply gradient descent step update ﬁxed. translation learning obtain image translation functions assembling subset subnetworks. translating images translating images ﬁrst analyze various components proposed framework. present visual results challenging translation tasks. finally apply framework domain adaptation tasks. performance analysis. used adam training learning rate momentums mini-batch consisted image ﬁrst domain image second domain. framework several hyper-parameters. default values network architecture encoders consisted convolutional layers front-end basic residual blocks back-end. generators consisted basic residual blocks front-end transposed convolutional layers back-end. discriminators consisted stacks convolutional layers. used leakyrelu nonlinearity. details networks given appendix used dataset contained corresponding pairs images domains useful quantitative evaluation. here goal learn translate satellite images maps. operated unsupervised setting used satellite images training ﬁrst domain maps validation second domain. trained iterations used ﬁnal model translate satellite images test set. compared difference translated satellite image corresponding ground truth maps pixel-wisely. pixel translation counted correct color difference within ground truth color value. used average pixel accuracy images test performance metric. could color difference measuring translation accuracy since target translation function unimodal. evaluate translation maps images since translation multi-modal difﬁcult construct proper evaluation metric. experiment varied number weight-sharing layers vaes paired conﬁguration discriminator architectures different depths training. changed number weight-sharing layers results reported figure curve corresponded discriminator architecture different depth. x-axis denoted number weigh-sharing layers vaes. found shallowest discriminator architecture worst performance. also found number weight-sharing layer little impact. residual blocks. tying weight layer effectively constrained layers since residual blocks updated residual information. rest experiments used vaes sharing layer discriminators layers. analyzed impact hyper-parameter values translation accuracy. different weight values negative likelihood terms computed achieved translation accuracy different weight values terms results reported figure found that general larger weight value negative likelihood terms yielded better translation accuracy. also found setting weights terms resulted consistently good performance. hence performed ablation study measuring impact weight-sharing cycle-consistency constraints translation performance showed results figure reported average accuracy trials note removed weight-sharing constraint framework reduced cyclegan architecture found model achieved average pixel accuracy removed cycle-consistency constraint used weight-sharing constraint achieved average pixel accuracy. used full model achieved best performance average pixel accuracy. echoed point ill-posed joint distribution recovery problem constraints beneﬁcial. qualitative results. figure showed results proposed framework various unit tasks. street images. applied proposed framework several unsupervised street scene image translation tasks including sunny rainy night summery snowy vice versa. task used images extracted driving videos recorded different days cities. numbers images sunny/day rainy night summery snowy sets trained network translate street scene image size figure showed several example translation results found method could generate realistic translated images. also found translation usually harder other. speciﬁcally translation required adding details image usually harder additional results available https//github.com/mingyuliutw/unit. synthetic real. figure showed several example results achieved applying proposed framework translate images synthetic images synthia dataset real images cityscape dataset real synthetic translation found method made cityscape images cartoon like. synthetic real translation method achieved better results building road regions human regions. breed conversion. used images husky german shepherd corgi samoyed english sheep dogs imagenet dataset learn translate images different breeds. used head regions extracted template matching algorithm. several example results shown figure found method translated different breed. species conversion. also used images house tiger lion cougar leopard jaguar cheetah imagenet dataset learn translate images different species. used head regions extracted template matching algorithm. several example results shown figure found method translated different specie. face attribute. used celeba dataset attribute-based face images translation. face image dataset several attributes including blond hair smiling goatee eyeglasses. face images attribute constituted domain without attribute constituted domain. figure visualized results translated several images blond hair glasses goatee smiling corresponding images individual attributes. found translated face images realistic. domain adaptation. applied proposed framework problem adapting classiﬁer trained using labeled samples domain classify samples domain labeled samples domain unavailable training. early works explored ideas subspace learning deep feature learning performed multi-task learning trained framework translate images source target domains classify samples source domain using features extracted discriminator source domain. here tied weights high-level layers allows adapt classiﬁer trained source domain target domain. also pair generated images different domains minimized distance features extracted highest layer discriminators encouraged interpret pair corresponding images way. applied approach several tasks including adapting street view house number dataset mnist dataset adapting mnist usps datasets. table reported achieved performance comparison competing approaches. found method achieved accuracy svhn→mnist task much better achieved previous state-of-the-art method also achieved better performance mnist↔svhn task coupled approach state-of-the-art. digit images small resolution. hence used small network. also found cycle-consistency constraint necessary task. details experiments available appendix several deep generative models recently proposed image generation including gans vaes pixelcnn proposed framework based gans vaes designed unsupervised image-to-image translation task could considered conditional image generation model. following ﬁrst review several recent works discuss related image translation works. learning staging zero-sum game generator discriminator. quality gan-generated images improved dramatically since introduction. lapgan proposed laplacian pyramid implementation gans. dcgan used deeper convolutional network. several training tricks proposed wgan used wasserstein distance. vaes optimize variational bound. improving variational approximation better image generation results achieved vae-gan architecture proposed improve image generation quality vaes. vaes applied translate face image attribute conditional generative model popular approach mapping image domain another. existing works based supervised learning work differed previous works need corresponding images. recently proposed domain transformation network achieved promising results translating small resolution face digit images. addition faces digits demonstrated proposed framework translate large resolution natural images. also achieved better performance unsupervised domain adaptation task. conditional generative adversarial network-based approach proposed translate rendering images real image gaze estimation. order ensure generated real image similar original rendering image distance generated original image minimized. note contemporary papers independently introduced cycle-consistency constraint unsupervised image translation. showed cycle-consistency constraint natural consequence proposed shared-latent space assumption. experiment found cycle-consistency weight-sharing constraints rendered comparable performance. constraints jointed used best performance achieved. presented general framework unsupervised image-to-image translation. showed learned translate image domain another without corresponding images domains training dataset. current framework limitations. first translation model unimodal gaussian latent space assumption. second training could unstable saddle point searching problem. plan address issues future work.", "year": 2017}