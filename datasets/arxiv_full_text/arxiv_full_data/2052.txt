{"title": "MCODE: Multivariate Conditional Outlier Detection", "tag": ["cs.AI", "cs.LG", "stat.ML"], "abstract": "Outlier detection aims to identify unusual data instances that deviate from expected patterns. The outlier detection is particularly challenging when outliers are context dependent and when they are defined by unusual combinations of multiple outcome variable values. In this paper, we develop and study a new conditional outlier detection approach for multivariate outcome spaces that works by (1) transforming the conditional detection to the outlier detection problem in a new (unconditional) space and (2) defining outlier scores by analyzing the data in the new space. Our approach relies on the classifier chain decomposition of the multi-dimensional classification problem that lets us transform the output space into a probability vector, one probability for each dimension of the output space. Outlier scores applied to these transformed vectors are then used to detect the outliers. Experiments on multiple multi-dimensional classification problems with the different outlier injection rates show that our methodology is robust and able to successfully identify outliers when outliers are either sparse (manifested in one or very few dimensions) or dense (affecting multiple dimensions).", "text": "detection unusual data instances dataset. outlier detection extremely useful identifying atypical data behaviors unusual outcomes erroneous readings annotations. often used primary data preprocessing step helps remove noisy irrelevant signals dataset time utilized identify interesting patterns data associated either adverse beneﬁcial events novelty detection fraud identiﬁcation network intrusion surveillance disease outbreak detection clinical monitoring alerting despite huge progress outlier detection methodologies majority existing outlier detection methods detect unconditional outliers identiﬁed joint space data attributes. however methods suitable many practical problems want identify unusual responses associated data objects. case outliers depend context properties data objects consider. application unconditional methods easily lead false positives false negatives detections. consider example image annotation problem want detect erroneous image tags. suppose applied unconditional outlier detection approach problem. case images rare subjects even annotations correct would detected scarcity subjects dataset. similarly assume patient rare disease. even though patient’s diagnoses correct manifested symptoms unconditional outlier detection would incorrectly mark case outlier disease rarity. hand assume unusual image modern painting assigned label frequent across database images incorrect speciﬁc image style. case label outlier considered without context becomes proper context considered. similarly moderately high medication dose look frequent respect patient population includes adults children become abnormal considering children. diﬀerences unconditional conditional outlier detection become apparent problems expressed probabilistically. conditional outlier detection seek instances fall probability region outlier detection aims identify unusual data instances deviate expected patterns. outlier detection particularly challenging outliers context dependent deﬁned unusual combinations multiple outcome variable values. paper develop study conditional outlier detection approach multivariate outcome spaces works transforming conditional detection outlier detection problem space deﬁning outlier scores analyzing data space. approach relies classiﬁer chain decomposition multidimensional classiﬁcation problem lets transform output space probability vector probability dimension output space. outlier scores applied transformed vectors used detect outliers. experiments multiple multi-dimensional classiﬁcation problems diﬀerent outlier injection rates show methodology robust able successfully identify outliers outliers either sparse dense permission make digital hard copies part work personal classroom granted without provided copies made distributed proﬁt commercial advantage copies bear notice full citation ﬁrst page. copy otherwise republish post servers redistribute lists requires prior speciﬁc permission and/or fee. woodstock paso texas copyright x-xxxxx-xx-x/xx/xx ..... focus paper development conditional outlier detection methodologies data objects associated multivariate binary outputs goal identify irregularities rare patterns responses. typically multivariate binary outputs correspond label spaces. examples problems fall category identiﬁcation unusual labelings images unusual keywords assigned documents incorrect diagnoses associated patient case etc. conditional outlier detection particularly challenging settings context interdependences response patterns considered detecting outliers. output variable depend values variables denoted univariate models represented learned using variety classic discriminative methods. brieﬂy terms product represents probability observing dimension output space. always calculate product terms express full posterms representation output space accounts context-output output-output dependences. assumption different outlier methods outlier scores successfully deﬁned space. reason keeping terms separate twofold. first errors various model estimation procedures combined together statistic make detection true irregularities hard especially high dimensional second decomposition lets adapt detection procedure diﬀerent types outliers. example outlier instances expected eﬀect dimensions output space outlier scoring space focus diﬀerent statistic derived individual terms opposed statistic would need outliers dense eﬀect many diﬀerent outputs. example considering image labeling assume process generating outliers random rare hence chance seeing outliers multiple dimensions unlikely. other outliers expressed many dimensions outliers aﬀect many dimensions output space. keeping space decomposed still covering contextual output dependences helps detect eﬀectively outliers diﬀerent settings. propose test diﬀerent outlier criteria deﬁned upon output space captures context-output output-output dependences. experiments conducted number multi-dimensional classiﬁcation datasets diﬀerent outlier processes injecting errors output spaces. demonstrate methodology robust able detect outliers outlier signal sparse given training data dtrain observation associated response variables goal identify unusual responses data reside fundamental challenges building multivariate conditional outlier detection model build accurate model representing dependency response variables context variables mutual dependences among response variables. approach problem modeling outlier detection studied extensively data mining statistics communities. accordingly variety approaches proposed applied identify outliers data data streams. outlier detection studies conducted wide range communities concept ill-deﬁned general consensus deﬁnition outlier probably referred deﬁnition given hawkins outlier observation deviates much observations arouse suspicions generated diﬀerent mechanism. given rather broad deﬁnition various methods proposed deviating instances multivariate dataset. methods roughly divided groups depthbased approaches distance-based approaches density-based approaches high-dimensional approaches. depth-based approaches assume outliers fringe response space normal response close center space. typical algorithms class include exploratory data analysis isodepth fast depth contours methods deﬁne depth data gradually removing data convex hulls data samples small depth reported outliers. related method one-class support vector machine assumes training data belong class. resultant decision boundary deﬁnes region normal data whereas data across density-based approaches assume density around normal data example similar density around neighbors. local outlier detection isolation methods common methods. compared approaches density-based approaches locally sensitive tend achieve better accuracy. typical representative local outer factor relative density score estimated extended k-nearest neighbor approach. indicates unusualness instance used outlier index. densitybased approach shown good performance many applications inﬂuenced several subsequent works literature distance-based approaches assume normal data examples come dense neighborhoods outliers correspond isolated points. typical method early outlier detection methods still used many applications. method gives outlier score instance using robust variant mahalanobis distance measures distance instance main body data distribution instances located rest instances identiﬁed outliers. methods fall category include knorr’s uniﬁed approach linearization method randomized pruning method resolution based method etc. limitation distance-based methods suﬀer curse dimensionality problem. number parameters models increase quadratically number dimensions makes less suitable high dimensional data. high-dimensional space greatest challenges data samples sparse meaningful neighborhood space. high-dimensional approaches proposed handle extreme cases. typical methods class either adopt invariant distance measurement angle based outlier detection project data lower dimensional subspace grid based subspace outlier detection suﬃcient dimensionality reduction bayes exponential family sparse recent methods gaussian processes help matrix factorization explore structure independent data vast majority existing outlier detection methods attempts solve unconditional outlier detection problem data instances compared analyzed across attributes. hand increasingly popular approach recent years conditional outlier detection attempts identify outliers subset response variables given values context variables. several approaches proposed extent song proposed model-based conditional outlier detection method uses generative data representation capture conditional relations between context response variables considers instances deviate representation outliers. parameter learning approach exploits chain decomposition reduces multivariate conditional modeling learning classiﬁcation functions makes method scalable large data; however learning gmms requires expensive expectationmaximization steps limits scalability. outlier detection performance signiﬁcant extent also makes method sensitive low-dimensional outliers gmms used able compute conditional joint probability section describes mcode multivariate conditional outlier detection approach. brieﬂy present modelbased outlier detection technique learns data model training dataset assumed outlier-free uses model detect outliers unseen data include outliers. accordingly proposed approach consists following phases ﬁrst build probabilistic multivariate conditional model training data. model applied diﬀerent data instances used estimate outlier scores measure data patterns likely unlikely based trained model. section describe phases detail. outlier detection approach summarizes data model used outlier detection. objective ﬁrst step build accurate probabilistic model relating context variables deﬁning diﬀerent data objects output variables deﬁning response. speciﬁcally want learn accurate predictive probabilistic model problem learning data stud goal learn support multivariate classiﬁcation tasks able automatically assign tags images keywords topics text documents diﬀerent functions genes and/or diseases patients assignment task corresponds ﬁnding maximum posteriori assignment response variables model underlying data representation approach uses multi-dimensional learning approach directly learns conditional probability distribution hand uses gaussian mixture models learn joint distribution however note purposes conditional outlier detection interested using model optimal assignment instead interested assessing likely observed context-output assignment represent individual cpds probabilistic predictive functions logistic regression support vector machines probabilistic outputs naive bayes. work logistic regression regularization. previous section described eﬃciently learn represent multivariate data using model. section present apply model unseen testing data identify multivariate conditional outliers reside them. objective second phase estimate degree outlier-ness unseen data instances using trained model ﬁrst phase. would like deﬁne eﬀective scoring metrics model-based outlier detection. important advantages towards objective gives well-deﬁned model posterior response probability recalling equation allows efhypothesize piecewise posterior probability individual responses contains crucial information identifying multivariate conditional outliers propose outlier detection method along outlier scoring metrics. speciﬁcally method ﬁrst transforms testing data original space probability space using model obtained previous phase. estimates multivariate outlier scores using conditional quantities space. complex high dimensional space deﬁned mixture discrete continuous context variables number possible assignments values output variables exponential many diﬀerent machine learning solutions address ﬁrst problem exist example various discriminative classiﬁcation techniques enhanced feature regularization second problem equally important unfeasible model learn possible output assignments independently. simple solution output space problem binary relevance method assumes responses conditionally independent given context learns functions separately however suﬃce many real-world modeling tasks dependences among responses hold important information build accurate model. introduce dependences among outputs classiﬁer chains approach deﬁnes multi-dimensional model response variables decomposing chain rule product univariate conditional models model variable output space. brieﬂy framework decomposes multivariate conditional distriyπ denotes parents model framework exploits decomposable structures underlying dependency relations among response variables represented note representation generalizes assuming deﬁne reessence summarizes density neighborhood result estimates unusualness instance consideration local density compared local densities neighbors. technical detail theoretical discussion last scoring metric relying one-class support vector machine technique. training ocsvm assumes training data belong class attempts maximum margin hyperplane data origin. following quadratic program formulates training ocsvm instances crossing boundary considered outliers. estimate outlier score testing instances output ocsvm represents relative location instances decision boundary. table summarizes outlier scoring metrics discussed section. obtain outlier scores testing data convert scores percentile rank instances. step allows evenly distribute instances across full range outlier score lets perform stable outlier detection. individual dimensions especially dimensionality data high; patterns deviate gaussian distribution could detected. hand approach diﬀerentiated utilizes likelihood estimation response dimension identify outliers; uses model general) represent data assume gaussian distribution. result proposed approach drives process outlier scoring granular level understanding utilizing conditional behaviors data leads signiﬁcant performance improvement outlier detection. subsection describe outlier scoring metrics multivariate conditional outlier detection approach. recall objective measure outlier score unseen testing data dtest notational convenience ﬁrst deﬁne quantity n-th instance ﬁrst outlier scoring metric univariate scoring metric uses natural interpretation probability. i.e. metric takes instance estimate complementary probability based model note widely used outlier scoring technique robust distance measures deviation instance main body distribution using robust variant mahalanobis distance method. results method maintain notion normal data process outlier scoring. validate approach demonstrate eﬀectiveness present experimental results real-world datasets. particular section would like verify whether considering conditional dependency among response variables improves performance outlier detection whether exploiting piecewise probabilistic estimation individual responses useful identifying outliers. evaluation performance outlier detection however straightforward. unsupervised nature task knowledge outliers exist given dataset. therefore make following assumptions design experiments. small portion outliers that however aﬀect comparison methods general fraction small inﬂuence model building process resultant data representation. based assumptions conduct experiments consist parts. section consider realistic scenario fraction responses outlying conditioned contexts. compare eight different outlier detection methods real-world datasets show approach produces competitive results. section hand controlled situation adjust number incorrect responses wrong outlier. experiments three real-world datasets show approach even sensitive sparse outliers well dense outliers. ﬁrst part experiments evaluate general performance outlier detection approach. multi-dimensional datasets obtained multiple domains. include semantic video/image labeling corelk text categorization reuters clinical patient classiﬁcation medical biology dataset consists continuous features represents observation associated binary labels represents response. table summarizes characteristics datasets including dataset size label cardinality distinct label data domain. part experiments simulate plausible scenarios responses outlying given contexts found virtually everywhere. example semantic video/image labeling video clip image irrelevant tags; clinical diagnosis patient receive inaccurate diagnosis; gene function analysis gene sequence associated wrong functional labels. compare performance approach widely used multivariate outlier detection methods including robust distance approach one-class local outlier factor methods concatenate observation associated responses vector methods joint space data attributes. evaluate multivariate conditional outlier detection approach dependent binary relevance base data model apply scoring metrics presented section refer following identiﬁers mcode-comp uses complementary probability score; mcode-rd uses robust distance score; mcode-l∞ uses norm score; mcodeocsvm uses one-class score; mcodelof uses local outlier factor score. fair comparison following parameters throughout experiments train classiﬁers ocsvm mcode-ocsvm radial basis function kernel; ocsvm parameter mcode-lof number neighbors ﬁxed used original work l-penalized logistic regression dbr; choose regularization parameter cross validation. order scoring metric need train classiﬁer takes posterior probability individual responses inputs. notice that avoid overﬁtting data train ocsvm diﬀerent subset data used train model. this experiments half training data train hold rest training table mean standard deviation area receiver operating characteristic curve best methods dataset shown bold. last shows mean standard deviation ranks methods figure comparisons existing multivariate outlier detection methods multivariate conditional outlier detection approach terms area receiver operating characteristic curve x-axis indicates diﬀerent outlier detection methods. y-axis indicates auc. vertical bars show standard deviation. area receiver operating characteristic curve evaluate diﬀerent methods. single number summary curve draws ratio true positive rate false positive rate sweeping threshold range output scores. particularly useful optimal decision threshold unknown. note higher better performance table shows area receiver operating characteristic curve compared methods. performed ten-fold cross validation three repeats datasets. mean standard deviation runs reported. dataset mark best methods statistically equivalent methods bold. last shows mean standard deviation ranks methods computed friedman test followed holm’s step-down procedure approach consistently produces competitive scores. example mcode-lof outperforms methods four datasets; mcode-rb mcode-l∞ outperform methods datasets respectively. among baseline methods shown close competitor. produces best aucs three datasets results competitive aucs rest three datasets. attribute process relative density estimation i.e. computation local densities understood estimation likelihood conditioned local information. result eﬀectively approximate conditional probability estimation. hand ocsvm seem properly handle multi-dimensional data. unconditional approaches identify outliers joint space data attributes show much eﬃcacy. partially high-dimensionality data figure changes area precision-recall curve according diﬀerent outlier injection rates. x-axis indicates outlier injection rates. y-axis indicates auc-pr. auc. x-axis indicates diﬀerent methods. results grouped scoring techniques gray bars show baseline results green bars show mcode. signiﬁcant improvement baseline mcode especially ocsvm. although described above performance already good directly working conditional probability space mcode-lof even improves scores. summary experimental results demonstrate mcode methods transforms testing data original space conditional probability space actually helps identiﬁcation outliers hence improves results. second part experiments would like test sensitivity methods number outlying dimensions; i.e. moving sparse denser outliers test well method performs along change. three multi-dimensional datasets mediamill bibtex corelk table characteristics datasets. part rather controlled setting adjust number outlying dimensions. note useful testing protocol practice especially problems experts involved data labeling area precision-recall curve similar score auc-pr number summary curve. score relatively conservative useful depict sensitivity methods particularly target distribution imbalanced outlier detection tasks. figure shows auc-pr methods. performed ten-fold cross validation three repeats experiments. y-axis indicates auc-pr. x-axis indicates number outlying dimensions. diﬀerent colors shapes indicate diﬀerent methods. simply speaking dotted lines show aucpr mcode superior general whereas solid lines show baselines. outliers detected. trends well captured ﬁgure methods start bottom quarter plots gradually improve number outlying dimension increases. however mcode methods usually start relatively higher aucprs. number outlying dimension increases diﬀerences become obvious. auc-prs mcode grow rapidly baseline methods relatively slower seem invariant small number outlying dimensions. summary part experiments veriﬁes exploiting piecewise posterior response probability helps improve outlier detection performance general also makes methods sensitive small degree perturbations. ﬁned unusual combinations multiple outcome variable values. reviewed existing outlier detection approaches multi-dimensional learning methods presented conditional outlier detection approach multivariate outcome space. motivation approach transform conditional outlier detection unconditional space solve problem eﬀectively. accordingly deﬁned outlier scoring metrics analyzing data space. experiments outlier detection settings demonstrate approach competitive also sensitive sparse outliers. outliers near linear time randomization simple pruning rule. proceedings ninth sigkdd international conference knowledge discovery data mining pages york acm. aivazian filzmoser kharin editors proceedings seventh international conference computer data analysis modeling pages belarusian state university maci´a-fern´andez v´azquez. anomaly-based network intrusion detection techniques systems challenges. computers security globerson chechik tishby. suﬃcient dimensionality reduction irrelevance statistics. proceedings nineteenth conference uncertainty artiﬁcial intelligence uai’ pages francisco morgan kaufmann publishers inc. forsyth. object recognition machine translation learning lexicon ﬁxed image vocabulary. heyden sparr nielsen johansen editors computer vision eccv volume lecture notes computer science pages springer berlin heidelberg angle-based outlier detection high-dimensional data. proceeding sigkdd international conference knowledge discovery data mining pages york acm. mohamed heller ghahramani. bayesian exponential family pca. koller schuurmans bengio bottou editors advances neural information processing systems pages papadimitriou kitagawa gibbons faloutsos. loci fast outlier detection using local correlation integral. data engineering proceedings. international conference pages ieee geusebroek smeulders. challenge problem automated detection semantic concepts multimedia. proceedings annual international conference multimedia multimedia pages york acm. anomaly-based intrusion detection system using common exploits. recent advances intrusion detection volume lecture notes computer science pages springer berlin heidelberg enhancing eﬀectiveness outlier detections density patterns. proceedings paciﬁc-asia conference advances knowledge discovery data mining pakdd pages london springer-verlag. bayesian network anomaly pattern detection disease outbreaks. fawcett mishra editors proceedings twentieth international conference machine learning pages menlo park california august aaai press.", "year": 2015}