{"title": "Automatic Pattern Classification by Unsupervised Learning Using  Dimensionality Reduction of Data with Mirroring Neural Networks", "tag": ["cs.LG", "cs.AI", "cs.NE"], "abstract": "This paper proposes an unsupervised learning technique by using Multi-layer Mirroring Neural Network and Forgy's clustering algorithm. Multi-layer Mirroring Neural Network is a neural network that can be trained with generalized data inputs (different categories of image patterns) to perform non-linear dimensionality reduction and the resultant low-dimensional code is used for unsupervised pattern classification using Forgy's algorithm. By adapting the non-linear activation function (modified sigmoidal function) and initializing the weights and bias terms to small random values, mirroring of the input pattern is initiated. In training, the weights and bias terms are changed in such a way that the input presented is reproduced at the output by back propagating the error. The mirroring neural network is capable of reducing the input vector to a great degree (approximately 1/30th the original size) and also able to reconstruct the input pattern at the output layer from this reduced code units. The feature set (output of central hidden layer) extracted from this network is fed to Forgy's algorithm, which classify input data patterns into distinguishable classes. In the implementation of Forgy's algorithm, initial seed points are selected in such a way that they are distant enough to be perfectly grouped into different categories. Thus a new method of unsupervised learning is formulated and demonstrated in this paper. This method gave impressive results when applied to classification of different image patterns.", "text": "possible characterization data important steps computer aided pattern recognition. supervised unsupervised depending whether pattern label information provided time training classification. paper deals extracting feature input using mmnn unsupervised classification using forgy’s clustering algorithm. many techniques features extraction object machine learning applied recognition. elaborate discussion several perform nonlinear dimensionality reduction found deal neural network approach dimensionality reduction. dimensionality reduction techniques like ica. dimensionality reduction used visualization patterns data using multi-dimensional scaling. according discussion given neural network approach performs better pca. reconstruction input patterns classification data unsupervised mode dimension reduction reconstruction mmnn used classify data unsupervised mode forgy’s algorithm used. generalized network take different input patterns produce mirrors output. time also reduces dimension input data. simple generalized network need change network architecture training proceeds approach good ability learn reconstruct image patterns extremely different features network. approach report success rate classification different patterns. paper proposes unsupervised learning technique using multi-layer mirroring neural network forgy’s clustering algorithm. multi-layer mirroring neural network neural network trained generalized data inputs perform non-linear dimensionality reduction resultant low-dimensional code used unsupervised pattern classification using forgy’s algorithm. adapting non-linear activation function initializing weights bias terms small random values mirroring input pattern initiated. training weights bias terms changed input presented reproduced output back propagating error. mirroring neural network capable reducing input vector great degree also able reconstruct input pattern output layer reduced code units. feature extracted network forgy’s algorithm classify input data patterns distinguishable classes. implementation forgy’s algorithm initial seed points selected distant enough perfectly grouped different categories. thus method unsupervised learning formulated demonstrated paper. method gave impressive results applied classification different image patterns. nputs mmnn three different categories -bit images size include faces flowers furniture. mmnn uses hyperbolic tangent function accepts input range input intensities linearly rescaled mirroring neural network trained different categories image patterns rescaled according discussion given fixing number layers number nodes layer done considerable experimentation. first hidden layer size followed second hidden layer size algorithm presented attempt classifying different data patterns using mirroring neural network forgy’s unsupervised classification algorithm. first mirroring neural network reduce dimensions input data pattern. reduced dimension feature vectors thus obtained classified using forgy’s unsupervised classification algorithm. thus obtain algorithm performs dimension reduction features also clusters similar data patterns group. work present mmnn compatible number nodes first hidden layer participate learning process accepting input patterns input layer. network designed least possible number nodes central hidden layer reduce dimension input pattern output layer number nodes input layer used reconstruct input data pattern. using least dimensional central hidden layer outputs input feature vector forgy’s algorithm data patterns grouped different clusters. contrast typical training approach neural network accepts categorized input pattern algorithm learns different patterns categorize groups itself. pictorial representation mmnn architecture given fig. mmnn architecture resembles architecture given difference designed specialized mirroring networks category input pattern mmnn network generalized network accept type input pattern. using forgy’s unsupervised clustering algorithm categorized different groups. automatic pattern classification training well test done simple partitional clustering technique engineering applications described implemented using forgy’s algorithm number initial selected seed points equal number distinguishable patterns training set. initially seed points selected must distinct perfectly cluster input patterns test patterns. euclidean distance initial seed points belonging different categories representation inter-set distance categories images. inter-set euclidean distance fixed experimentation depending categories images train mirroring neural network. used threshold value i.e. euclidean distances initial seed points greater initial seed points following procedure followed first seed point randomly selected input data set. then select second seed point euclidean distance first second must greater similarly select seed point euclidean distance present point already selected seed points greater approach categories input data. initial seed points separate input distinguishable groups. selecting initial seed points using aforementioned procedure initializing cluster centroids find cluster centroid nearest sample training comparing euclidean distances mark sample nearest cluster. done samples training output layer size equal input found suitable architecture network. chosen multilayer mirroring network architecture contrast symmetrical dimensions encoder decoder layers autoencoder described auto-associative neural networks discussed this apparent exists nonlinear relationship dimensions adjacent layers accurately reconstruct input output network. modified sigmoidal activation function used hyperbolic tangent function instead logistic function implemented found appropriate input data described functional output node hidden layers output layer activation function form tanh passed modified hyperbolic tangent function discussed below. odified hyperbolic tangent function forces output multilayer mirroring neural network range instead prevents multilayer neural network out-of-range values helps faster convergence. mmnn back propagating network minimizes error input reconstruction using gradient descent learning parameter weights bias terms initialized small random values effectively learn different patterns. training input patterns specified accuracy achieved fixing considerable amount threshold distance input mirror. modified hyperbolic tangent function results output value range compatible truncated input need rescale desired output time training patterns. algorithm tested test images using aforementioned weights bias terms. images entirely images occurring training samples. algorithm automatically classified input images three groups. first group consisted furniture images second group consisted flower images. third group consisted face flower images. test sample space images images classified correctly performance forgy’s clustering technique applied application threshold distance randomly selected initial seed points. threshold made randomly selected seed points sufficiently apart make forgy’s technique cluster input patterns perfectly. results algorithm three different input patterns encouraging. extended architecture wherein network classify input image pattern also learn classify pattern trained patterns. completing process grouping samples compute centroid resulting clusters. based centroids resultant clusters group samples marking nearest cluster centroid. repeat procedure till change cluster groups. done unsupervised mode training network giving information regarding input pattern classification simply based selection distant initial seed points. training mmnn images given input. mmnn trained till successfully mirrored input images. weights algorithm automatically classified images groups. first group contained images .the second group contained face images. input images images classified correctly algorithm tested test images using aforementioned weights bias terms. images entirely occur training set. algorithm automatically classified test images groups. first group contained images second group contained face images. test sample space images images classified correctly training mmnn images given input. mmnn trained till successfully mirrored input images. weights bias terms algorithm automatically classified input images three groups. group contained furniture images samples classification achieved). group contained", "year": 2007}