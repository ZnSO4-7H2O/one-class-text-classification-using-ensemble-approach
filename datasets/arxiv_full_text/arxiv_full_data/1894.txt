{"title": "CLEVR: A Diagnostic Dataset for Compositional Language and Elementary  Visual Reasoning", "tag": ["cs.CV", "cs.CL", "cs.LG"], "abstract": "When building artificial intelligence systems that can reason and answer questions about visual data, we need diagnostic tests to analyze our progress and discover shortcomings. Existing benchmarks for visual question answering can help, but have strong biases that models can exploit to correctly answer questions without reasoning. They also conflate multiple sources of error, making it hard to pinpoint model weaknesses. We present a diagnostic dataset that tests a range of visual reasoning abilities. It contains minimal biases and has detailed annotations describing the kind of reasoning each question requires. We use this dataset to analyze a variety of modern visual reasoning systems, providing novel insights into their abilities and limitations.", "text": "building artiﬁcial intelligence systems reason answer questions visual data need diagnostic tests analyze progress discover shortcomings. existing benchmarks visual question answering help strong biases models exploit correctly answer questions without reasoning. also conﬂate multiple sources error making hard pinpoint model weaknesses. present diagnostic dataset tests range visual reasoning abilities. contains minimal biases detailed annotations describing kind reasoning question requires. dataset analyze variety modern visual reasoning systems providing novel insights abilities limitations. long-standing goal artiﬁcial intelligence research develop systems reason answer questions visual information. recently several datasets introduced study problem visual question answering datasets contains challenging natural language questions images. correctly answering questions requires perceptual abilities recognizing objects attributes spatial relationships well higher-level skills counting performing logical inference making comparisons leveraging commonsense world knowledge numerous methods attacked problems many show marginal improvements strong baselines unfortunately ability understand limitations methods impeded inherent complexity task. methods hampered failures recognition poor reasoning lack commonsense knowledge something else? equal number large things metal spheres? size cylinder left brown metal thing left sphere? sphere size metal cube; made material small sphere? many objects either small cylinders metal things? figure sample image questions clevr. questions test aspects visual reasoning attribute identiﬁcation counting comparison multiple attention logical operations. exempliﬁed clever hans horse appeared able answer arithmetic questions. careful observation revealed hans correctly answering questions reacting cues read human observers statistical learning systems like used develop similar cheating approaches superﬁcially solve tasks without learning underlying reasoning processes instance statistical learner correctly answer question what covers ground? understands scene biased datasets often questions ground snow-covered determine whether system capable sophisticated reasoning exploiting biases world similar clever hans? paper propose diagnostic dataset studying ability systems perform visual reasoning. refer dataset compositional language elementary visual reasoning diagnostics dataset clevr contains rendered images million automaticallygenerated questions unique. chaldesigned clevr explicit goal enabling detailed analysis visual reasoning. images depict simple shapes; simpliﬁes recognition allows focus reasoning skills. ensure information image complete exclusive external information sources commonsense knowledge cannot increase chance correctly answering questions. minimize question-conditional bias rejection sampling within families related questions avoid degenerate questions seemingly complex contain simple shortcuts correct answer. finally structured ground-truth representations images questions images annotated ground-truth object positions attributes questions represented functional programs executed answer question representations facilitate indepth analyses possible traditional datasets. design choices also mean images clevr visually simple questions complex require range reasoning skills. instance factorized representations required generalize unseen combinations objects attributes. tasks counting comparing require short-term memory attending speciﬁc objects questions combine multiple subtasks diverse ways require compositional systems answer. clevr analyze suite models discover weaknesses widely known. example current state-of-the-art models struggle tasks requiring short term memory comparing attributes objects compositional reasoning recognizing novel attribute combinations. observations point novel avenues research. finally stress accuracy clevr goal itself hand-crafted system explicit knowledge clevr universe might work well generalize real-world settings. therefore clevr used conjunction datasets order study reasoning abilities general systems. recent years range benchmarks visual understanding proposed including datasets image captioning referring objects relational graph prediction visual turing tests clevr diagnostic dataset closely related benchmarks visual question answering involves answering natural-language questions images. main differences clevr datasets that clevr minimizes biases prior datasets used learning systems answer questions correctly without visual reasoning clevr’s synthetic nature detailed annotations facilitate in-depth analyses reasoning abilities impossible existing datasets. prior work attempted mitigate biases datasets simple cases yes/no questions difﬁcult apply bias-reduction approaches complex questions without high-quality semantic representation questions answers. clevr semantic representation provided functional program underlying image-question pair biases largely eliminated sampling. winograd schemas another approach controlling bias question answering questions carefully designed ambiguous based syntax alone require commonsense knowledge. unfortunately approach scale gracefully ﬁrst phase winograd schema challenge consists hand-designed questions. clevr also related babi question answering tasks aims diagnose clearly deﬁned competences system clevr focuses visual reasoning whereas babi purely textual. also ﬁrst consider synthetic data studying reasoning. shrdlu performed simple interactive visual reasoning goal moving speciﬁc objects visual scene study ﬁrst demonstrate brittleness manually programmed semantic understanding. pioneering daquar dataset contains synthetic human-written questions generate synthetic questions using eight text templates. contains natural-language questions abstract scenes questions control questionconditional bias equipped functional program representations. clevr similar spirit shapes dataset complex varied terms visual content question variety complexity shapes contains total questions unique questions clevr contains nearly million questions unique. clevr provides dataset requires complex reasoning solve used conduct rich diagnostics better understand visual reasoning capabilities systems. requires tight control dataset achieve using synthetic images automatically generated questions. images associated ground-truth object locations attributes questions associated machine-readable form. figure ﬁeld guide clevr universe. left shapes attributes spatial relationships. center examples questions associated functional programs. right catalog basic functions used build questions. section details. ground-truth structures allow analyze models based example question type question topology question length various forms relationships objects. figure gives brief overview main components clevr describe detail below. objects relationships. clevr universe contains three object shapes come absolute sizes materials eight colors. objects spatially related four relationships left right behind front. semantics prepositions complex depend relative object positions also camera viewpoint context. found generating questions invoke spatial relationships semantic accord difﬁcult. instead rely simple unambiguous deﬁnition projecting camera viewpoint vector onto ground plane deﬁnes behind vector object behind another ground-plane position along behind vector. relationships similarly deﬁned. figure illustrates objects attributes spatial relationships clevr. clevr universe also includes non-spatial relationship type refer sameattribute relation. objects relationship equal attribute values speciﬁed attribute. scene representation. scenes represented collections objects annotated shape size color material position ground-plane. scene also represented scene graph nodes objects annotated attributes edges connect spatially related image generation. clevr images generated randomly sampling scene graph rendering using blender every scene contains three objects random shapes sizes materials colors positions. placing objects ensure objects intersect objects least partially visible small horizontal vertical margins image-plane centers pair objects; helps reduce ambiguity spatial relationships. image positions lights camera randomly jittered. question representation. question clevr associated functional program executed image’s scene graph yielding answer question. functional programs built simple basic functions correspond elementary operations visual reasoning querying object attributes counting sets objects comparing values. shown figure complex questions represented compositions simple building blocks. full details basic function found supplementary material. section representing questions functional programs enables rich analysis would impossible natural-language questions. question’s functional program tells exactly reasoning abilities required solve allowing compare performance questions requiring different types reasoning. categorize questions question type deﬁned outermost function question’s program; example questions figure types query-color exist. figure shows number questions type. question families. must overcome several challenges generate dataset using functional programs. functional building blocks used construct inﬁnite number possible functional programs must decide program structures consider. also need method converting functional programs natural language minimizes question-conditional bias. solve problems using question families. question family contains template constructing functional programs several text templates providing multiple ways expressing programs natural language. example question many things there? formed instantiating text template many things there? binding parameters values nil. functional program count)) question formed instantiating associated program template count))) clevr contains total question families single program template average four text templates. text templates generated manually writing templates family crowdsourcing question rewrites. increase language diversity synonyms shape color material. parameters template small number families generate huge number unique questions; figure shows nearly million questions clevr unique. clevr easily extended adding question families. question generation. generating question image conceptually simple choose question family select values template parameters execute resulting program image’s scene graph answer text templates question family generate ﬁnal natural-language question. however many combinations values give rise questions either ill-posed degenerate. question what color cube right sphere? would ill-posed many cubes right sphere degenerate cube scene since reference sphere would unnecessary. avoiding ill-posed degenerate questions critical ensure correctness complexity questions. figure statistics clevr; majority questions unique questions test sets appear training set. bottom left comparison question lengths different datasets; clevr questions generally much longer. bottom right distribution question types clevr. questions. however number possible conﬁgurations question family exponential number parameters undesirable. makes bruteforce search intractable complex question families. instead employ depth-ﬁrst search valid values instantiating question families. step search ground-truth scene information prune large swaths search space guaranteed produce undesirable questions; example need entertain questions form what color sphere scenes contain spheres. finally rejection sampling produce approximately uniform answer distribution question family; helps minimize question-conditional bias since questions family share linguistic structure. models typically represent images features pretrained cnns word embeddings recurrent networks represent questions and/or answers. models train recurrent networks answer generation multiclass classiﬁers common answers binary classiﬁers imagequestion-answer triples many methods incorporate attention image question methods incorporate memory dynamic network architectures experimenting methods logistically challenging reproduced representative subset methods baselines look image simple baseline performs near state-of-the-art sophisticated methods lstm similar lstm question processed learned word embeddings followed wordlevel lstm ﬁnal lstm hidden state passed multi-layer perceptron predicts distribution answers. method uses image information model question-conditional bias. cnn+bow following question encoded averaging word vectors word question image encoded using features convolutional network question image features concatenated passed predicts distribution answers. word vectors trained googlenews corpus ﬁne-tuned training. cnn+lstm above images questions encoded using features ﬁnal lstm hidden states respectively. features concatenated passed predicts answer distribution. cnn+lstm+mcb images questions encoded above instead concatenation features pooled using compact multimodal pooling cnn+lstm+sa again question image encoded using lstm respectively. following representations combined using rounds soft spatial attention ﬁnal answer distribution predicted mlp. human used mechanical turk collect human responses random questions test taking majority vote among three workers question. implementation details. cnns resnet- models pretrained imagenet ﬁnetuned; images resized prior feature extraction. performed initial experiments dynamic module networks parsing heuristics generalize complex questions clevr work out-of-the-box; supplementary material. cnn+lstm+sa extracts features last layer conv stage giving -dimensional features. methods extract features ﬁnal average pooling layer giving -dimensional features. lstms layers units layer. mlps relu functions dropout hidden layers units layer. models trained using adam experimental protocol. clevr split train validation test sets tuned hyperparameters independently model based validation error. experiments designed validation set; ﬁnalizing design model test set. experimental ﬁndings generalized validation test set. program representation questions analyze model performance different forms reasoning. ﬁrst evaluate performance question type deﬁned outermost function program. figure shows results detailed ﬁndings discussed below. querying attributes query questions attribute particular object clevr world sizes eight colors materials three shapes. questions asking different attributes q-type mode lstm obtain accuracies close respectively showing dataset minimal question-conditional bias questions. cnn+lstm+sa substantially outperforms models questions; attention mechanism help focus target object identify attributes. comparing attributes attribute comparison questions whether objects value attribute valid answers q-type mode lstm achieve accuracies close conﬁrming dataset bias questions. unlike attribute-query figure accuracy questions single spatial relationship single same-attribute relationship. query count questions models generally perform worse questions sameattribute relationships. results exist questions mixed. questions attribute-comparison questions require limited form memory models must identify attributes objects keep memory compare them. interestingly none models able models accuracy approximately also true cnn+lstm+sa model suggesting attention mechanism capable attending objects compare them. illustrates clevr reveal limitations models motivate follow-up research e.g. augmenting attention models explicit memory. existence existence questions whether certain type object present accuracy qtype mode shows answers priori equally likely lstm result suggest questionconditional bias. correlations question length answer questions ﬁltering operations likely answer. biases present even uniform answer distributions question family since questions family different numbers ﬁltering functions. cnn+lstm outperforms lstm performance still quite low. counting counting questions number objects fulﬁlling conditions valid answers range zero ten. images three objects counting questions refer subsets objects ensuring uniform answer distribution challenging; rejection sampler therefore pushes towards uniform distribution questions rather enforcing hard constraint. results question-conditional bias reﬂected accuracies achieved q-type mode lstm. cnn+lstm performs lstm suggesting features contain little information relevant counting. cnn+lstm+sa performs slightly better absolute performance low. figure accuracy questions spatial relationships broken question topology chain-structured questions tree-structured questions joined logical operator. comparing integer quantities. answer distribution unbiased set’s size correlate length description explaining lstm q-type mode. cnn+bow performs better chance mixes words describing making impossible learner discriminate them. cnn+lstm+sa outperforms lstm less more questions model outperforms lstm equal questions. models perform better less more asymmetric question families. analysis relationship type clevr questions contain types relationships spatial same-attribute compare relative difﬁculty types comparing model performance questions single spatial relationship questions single same-attribute relationship; results shown figure query-attribute counting questions same-attribute questions generally difﬁcult; cnn+lstm+sa spatial same-relate query questions particularly large same-attribute relationships require model keep attributes object memory comparison suggesting models augmented explicit memory perform better questions. analysis question topology next evaluate model performance different question topologies chain-structured questions treestructured questions branches joined logical figure compare performance chain-structured questions spatial relationships tree-structured questions relationship along branch. query questions cnn+lstm+sa shows large chain tree questions count questions cnn+lstm+sa slightly outperforms lstm chain questions method outperforms lstm tree questions. tree questions difﬁcult since require models perform subtasks parallel fusing results. question large object left side large blue cylinder front rubber cylinder right side purple shiny thing; shape? effective question shape large object left cylinder? figure many questions answered correctly withcorrectly solving subtasks. given question scene prune functions question’s program generate effective question shorter gives answer. bottom accuracy query questions actual effective question size. accuracy decreases effective question size actual size. shaded area shows conﬁdence interval. effect question size intuitively longer questions harder since involve reasoning steps. deﬁne question’s size number functions program figure show accuracy query-attribute questions function question size. surprisingly accuracy appears unrelated question size. however many questions correctly answered even subtasks solved correctly. example question figure answered correctly without identifying correct large blue cylinder because large objects left cylinder cylinders. quantify effect deﬁne effective question image-question pair prune functions question’s program smallest program that executed scene graph question’s image gives answer original question. question’s effective size size effective question. questions whose effective size smaller actual size need degenerate. question figure degenerate entire question needed resolve object references small effective size since correctly answered without resolving references. figure show accuracy query questions function effective question size. error rate models increases effective question size suggesting models struggle long reasoning chains. figure questions correctly answered using absolute deﬁnitions spatial relationships; example image purple cube bottom half image. bottom accuracy model chain-structured questions function number spatial relationships question separated question type. shows chainstructured questions; bottom excludes questions correctly answered using absolute spatial reasoning. expect questions spatial relationships challenging since require longer chains reasoning. plots figure shows accuracy chain-structured questions different numbers relationships. across three question types cnn+lstm+sa shows signiﬁcant drop accuracy questions spatial relationship; models largely unaffected spatial relationships. spatial relationships force models reason objects’ relative positions. however shown figure questions answered using absolute spatial reasoning. question purple cube found simply looking bottom half image; reasoning position relative metal sphere unnecessary. questions requiring absolute spatial reasoning identiﬁed modifying semantics spatial relationship functions programs instead returning sets objects related input object ignore input object return objects half image corresponding relationship. question requires absolute spatial reasoning executing program modiﬁed semantics change answer. bottommost plots figure show accuracy chain-structured questions different number relationships excluding questions answered paper introduced clevr dataset designed diagnostic evaluation visual question answering systems minimizing dataset bias providing rich ground-truth representations images questions. experiments demonstrate clevr facilitates in-depth analysis possible datasets question representations allow slice dataset along different axes comparing performance along different axes allows better understand reasoning capabilities systems. analysis revealed several shortcomings current systems short-term memory systems tested performed poorly situations requiring short-term memory including attribute comparison integer equality questions same-attribute relationships tree-structured questions attribute comparison questions particular interest since models successfully identity attributes objects struggle compare attributes. long reasoning chains systems struggle answer questions requiring long chains nontrivial reasoning including questions large effective sizes count existence questions many spatial relationships disentangled representations training testing models different data distributions argue models learn representations properly disentangle object attributes; seem learn strong biases training data cannot overcome biases conditions change. study also shows cases current systems successful. particular spatial attention allows models focus objects identify attributes even questions requiring multiple steps reasoning. observations present clear avenues future work vqa. plan clevr study models explicit short-term memory facilitating comparisons values explore approaches encourage learning disentangled representations investigate methods compile custom network architectures different patterns reasoning hope diagnostic datasets like clevr help guide future research enable rapid progress important task. condition cubes gray blue brown yelfigure cylinders green purple cyan; condition color palettes swapped. train models condition test conditions assess generalization performance. show accuracy query color query material questions separating questions shape object queried. absolute spatial reasoning. query questions cnn+lstm+sa performs signiﬁcantly worse absolute spatial reasoning excluded; count questions model outperforms lstm exist questions model outperforms q-type mode. results suggest models learned semantics spatial relationships. practical systems perform well images questions contain novel combinations attributes seen training. models might need learn disentangled representations attributes example learning separate representations color shape instead memorizing possible color/shape combinations. clevr test ability models perform compositional generalization. synthesize versions clevr condition cubes gray blue brown yellow cylinders green purple cyan; condition shapes swap color palettes. conditions contain spheres eight colors. retrain models condition compare performance testing condition testing condition figure show accuracy query-color query-material questions separating questions asking spheres cubes/cylinders models perform asked color spheres perform much worse asked color cubes cylinders; cnn+lstm+sa drops models seem learn strong biases colors objects cannot overcome biases conditions change. asked material cubes cylinders cnn+lstm+sa shows smaller described section shown figure question clevr associated functional program built basic functions. section detail semantics basic functional building blocks. data types. basic functional building blocks operate values following types basic functions. functional program representations questions built following basic building blocks. functions takes image’s scene graph additional implicit input. filtering functions functions ﬁlter input objects attribute returning subset input objects match input attribute. example calling filter size ﬁrst input small return small objects second input. ﬁlter size ﬁlter color ﬁlter material ﬁlter shape query functions functions return speciﬁed attribute input object; example calling query color object returns red. same-attribute relations functions return objects attribute value input object including input object. example calling shape cube returns cubes scene excluding query cube. section note questions correctly answered without correctly resolving intermediate object references deﬁne question’s effective question quantitatively measure effect. question compute effective question pruning functions question’s program; effective question smallest pruned program that executed scene graph question’s image gives answer original question. figure accuracy query questions actual effective question size restricting questions same-attribute relationship. figure shows plots questions without same-attribute relationship. groups questions accuracy decreases effective question size increases. relate function returns objects behind object returns large cube cylinder ﬁlter shape function removes cylinder query color returns singleton containing brown. figure main paper shows model accuracy query-attribute questions function actual effective question size excluding questions same-attribute relationships. questions same-attribute relationships maximum question size questions withsame-attribute relationships maximum size combining questions thus leads unwanted correlapruned questions ill-posed meaning object references refer unique object. example consider question what color cube behind cylinder?; associated program imagine executing program scene shown figure innermost ﬁlter shape gives containing cylinder relate returns containing large cube back outer ﬁlter shape nothing query color returns brown. question ill-posed reference cube cannot resolved without rest question; however question’s effective size less actual size question correctly answered without resolving object reference correctly. compute effective question attempt prune functions program. starting innermost function working whenever function whose input type object objectset construct pruned question replacing function’s input scene function executing smallest pruned program gives answer original program effective question. pruned questions ill-posed execute modiﬁed semantics. output type unique function changed object objectset simply returns input set. functions taking object input modiﬁed take objectset input instead mapping original function input ﬂattening resulting set; thus relate functions return objects scene speciﬁed relationship input objects query functions return sets values rather single values. figure show model accuracy actual effective question size questions same-attribute relationships. similar figure model accuracy either remains constant increases actual question size increases models show clear decrease accuracy effective question size increases. module networks novel approach visual question answering differentiable modules used assemble custom network architecture answer question. module responsible performing speciﬁc function ﬁnding particular type object describing current object attention performing logical operation merge attention masks. approach seems like natural rich compositional questions clevr; unfortunately found parsing heuristics tuned dataset generalize longer complex questions clevr. dynamic module networks generate network architectures performing dependency parse question using heuristics compute layout fragments combining fragments create candidate layouts ranking candidate layouts using mlp. questions heuristics unable produce layout fragments; case system uses simple default network architecture fallback answering question. random sample questions dataset found dynamic module networks resorted default architecture questions; random sample questions clevr default network architecture used questions. suggests parsing heuristics used apply questions clevr; therefore method work out-of-the clevr. remaining pages show randomly selected images questions clevr. question annotated answer question type size. recall section question’s type outermost function question’s functional program question’s size number functions program.", "year": 2016}