{"title": "Question Relevance in VQA: Identifying Non-Visual And False-Premise  Questions", "tag": ["cs.CV", "cs.CL", "cs.LG"], "abstract": "Visual Question Answering (VQA) is the task of answering natural-language questions about images. We introduce the novel problem of determining the relevance of questions to images in VQA. Current VQA models do not reason about whether a question is even related to the given image (e.g. What is the capital of Argentina?) or if it requires information from external resources to answer correctly. This can break the continuity of a dialogue in human-machine interaction. Our approaches for determining relevance are composed of two stages. Given an image and a question, (1) we first determine whether the question is visual or not, (2) if visual, we determine whether the question is relevant to the given image or not. Our approaches, based on LSTM-RNNs, VQA model uncertainty, and caption-question similarity, are able to outperform strong baselines on both relevance tasks. We also present human studies showing that VQA models augmented with such question relevance reasoning are perceived as more intelligent, reasonable, and human-like.", "text": "shows examples relevant irrelevant questions. systems irrelevant questions input understandably produce nonsensical answers humans hand unlikely provide nonsensical answers instead answer irrelevant anknowledge source answer correctly possible. argue implicit assumption systems input question always relevant input image simply untenable systems move beyond standard academic datasets interacting real users unfamiliar malicious. goal work make systems human-like providing capability identify relevant questions. existing work reasoned crossmodal similarity able identify whether question relevant given image novel problem real-world applications. human-robot interaction able identify questions dissociated perception data available important. robot must decide whether process scene perceives query external world knowledge resources provide response. visual question answering task answering natural-language questions images. introduce novel problem determining relevance questions images vqa. current models reason whether question even related given image requires information external resources answer correctly. break continuity dialogue human-machine interaction. approaches determining relevance composed stages. given image question ﬁrst determine whether question visual visual determine whether question relevant given image not. approaches based lstm-rnns model uncertainty caption-question similarity able outperform strong baselines relevance tasks. also present human studies showing models augmented question relevance reasoning perceived intelligent reasonable human-like. visual question answering task predicting suitable answer given image question models typically discriminative models take image question representations output possible answers. work motivated following observation current systems always output answer regardless whether input question makes sense given image not. fig. shown fig. study three types question-image pairs non-visual. questions questions images require information image answered visual false-premise. visual questions apply given image. instance question what girl wearing? makes sense images contain girl them. visual truepremise. questions relevant image hand. introduce datasets train models recognize non-visual false-premise questionimage pairs context vqa. first identify whether question visual non-visual; visual identify whether question truepremise given image. visual nonvisual question detection long short-term memory recurrent neural network trained part speech tags capture visual-speciﬁc linguistic structure. true falsepremise question detection present approaches uncertainty model another pre-trained captioning models generate relevant captions given image compare given question determine relevance. proposed models achieve accuracies detecting non-visual detecting false-premise questions signiﬁcantly outperform strong baselines. also show human studies system reasons question relevance picked signiﬁcantly often intelligent human-like reasonable baseline system not. code datasets publicly available authors’ webpages. large body existing work reasons cross-modal similarity well image matches query text-based image retrieval well image matches caption well video matches description work question deemed irrelevant model says opposed answering question anyway. related perception systems respond input system likely fail. failure prediction systems explored vision speech others attempt provide meaningful answer instead suppressing output model expected fail given input. idea avoid highly speciﬁc prediction chance wrong instead make generic prediction likely right malinowski fritz semantic segmentations approach question answering reason objects present segmentations part answer. best knowledge work ﬁrst study relevance questions vqa. chen classify users’ intention questions community question answering services. related work dodge extract visual text within flickr photo captions used supervisory signals training image captioning systems. motivation endow systems ability detect non-visual questions respond human-like fashion. moreover also detect ﬁne-grained notion question relevance truefalse-premise. task detecting visual non-visual questions assume questions dataset visual since amazon mechanical turk workers speciﬁcally instructed questions displayed image creating also collected non-visual philosophical general knowledge questions internet combining visual questions validation generic nonvisual questions collected internet. call dataset visual non-visual questions also collect dataset truevs. false-premise questions showing workers images paired random questions dataset asking annotate whether applicable not. three workers annotate pair. take majority vote ﬁnal ground truth label. pairs unique images non-applicable refer visual truevs. falsepremise questions dataset vtfq. visual non-visual detection recall task detect visual questions non-visual ones. non-visual questions dogs president usa? often tend difference linguistic structure visual questions does bird what doing?. compare approach baseline rule-based. rule-based approach detect non-visual questions based part speech tags dependencies words question. e.g. question plural noun determiner followed singular verb non-visual question. lstm. train lstm -dim hidden vectors embed question vector predict visual not. instead feeding question words input lstm embeddings tags words embeddings tags learnt end-to-end. captures structure imagegrounded questions rather visual nonsecond task detect whether question entails false-premise image present families approaches measure ‘compatibility’ using uncertainty models using pre-trained captioning models. using uncertainty. work hypothesis model uncertain answer pair question irrelevant given image since uncertainty mean seen similar pairs training data. test approaches entropy. compute entropy softmax output state-of-the model given pair train three-layer multilayer perceptron nodes hidden layer. vqa-mlp. feed softmax output three-layer nodes hidden layer train binary classiﬁer predict whether question truefalse-premise given image. using pre-trained captioning models. utilize image captioning model image question-generation model measure compatibility. note models generate natural language capturing semantics image form statement form question. hypothesis given question relevant given image similar language generated models image. speciﬁcally question-caption similarity neuraltalk pretrained mscoco dataset generate caption given image compute learned similarity question-question similarity neuraltalk re-trained questions dataset generate question image. then compute learned similarity table normalized accuracy results visual non-visual detection truevs. false-premise detection. rule-based q-gen score averaged deterministic. describe learned similarity function similarity model -channel lstm+mlp channel sequentially reads wordvec embeddings corresponding language lstm. last hidden state vectors lstms concatenated inputs outputs -class softmax. entire model learned end-to-end vtfq dataset. also experimented representations included appendix completeness. finally also compare proposed models simpler baseline compute probability input question learned question-generation model. intuition since question generation model trained relevant questions assign high probability relevant. truevs. false-premise detection. random pairs vtfq dataset train remaining test. model uncertainty based approaches perform reasonably well learned similarity approaches perform much better high uncertainty model suggest similar pair seen training; however seem translate detecting irrelevance. language generation models seem work signiﬁcantly better modeling semantic interaction question image. generative approach outperformed discriminative approaches trained explicitly task hand. show qualitative examples q-q’ truevs. false-premise detection fig. also perform human studies compare agents agent-baseline– always answers agent-ours– reasons every question. question relevance responding. question classiﬁed visual true-premise agent-ours answers question using model agent-baseline otherwise responds prompt indicating question seem meaningful image. total questions used. relevant questions answered correctly model. human subjects shown response agents asked pick agent sounded intelligent reasonable human-like every observed pair. pair assessed different subjects. pairs rated subjects. total unique workers participated study. agent-ours picked time winner agent-baseline picked time considered equally reasonable remaining cases. also measure percentage times robot gets picked figure qualitative examples q-q’ sim. show success cases show failure cases. model predicts true-premise false-premise examples show original question generated question interestingly humans often prefer agent-ours agent-baseline even models wrong agent-baseline answers question incorrectly agent-ours incorrectly predicts question irrelevant refuses answer legitimate question. users seem tolerant mistakes relevance prediction vqa. introduced novel problem identifying irrelevant questions vqa. proposed models signiﬁcantly outperform strong baselines tasks. agent utilizes detector refuses answer certain questions signiﬁcantly outperforms several directions future work. possibility includes identifying premise entailed question opposed stating truefalse-premise. another determining external knowledge needed answer non-visual questions. acknowledgements. thank lucy vanderwende helpful suggestions discussions. also thank anonymous reviewers helpful comments. work supported part following national science foundation career awards alfred sloan fellowship army research ofﬁce awards ictas junior faculty awards army research grant wnf--- ofﬁce naval research grant paul allen family foundation allen distinguished investigator award google faculty research award education research grant nvidia donation qualitative results. results methods feature extraction question-caption similarity question-question similarity approaches used truevs. false-premise question detection. implementation details training models. section main document describes rulebased hand-crafted rule-based approach detect non-visual questions. rules added make baseline strong possible rules take precedence others. list examples list words frequently occur non-visual questions infrequently visual questions. include words ‘god’ ‘life’ ‘meaning’ ‘universe’. words list present question question classiﬁed non-visual. figures show success failure cases truevs. falsepremise question detection using sim. note success cases contextual semantic similarity learned even words question generated captioning model different input question bow. test bag-of-words approach vocabulary size words represent questions captions train predict whether question relevant not. representation built setting value features words present either question caption word present both. means question-caption pair represented -dim vector. used -layer hidden units respectively. avg. extract wordvec features question captions’ words compute average features separately question caption concatenate them. similar train -layer figure success cases ﬁrst illustrates examples model thought true-premise also labeled humans. second shows success cases false-premise detection. training avg. lstm vqa-mlp keras deep learning library python. pre-training question caption generation models scratch torch deep learning library rmsprop optimization algorithm lstm adadelta avg. models gaussian random weights initialization momentum.", "year": 2016}