{"title": "Deep-FExt: Deep Feature Extraction for Vessel Segmentation and  Centerline Prediction", "tag": ["stat.ML", "cs.CV", "cs.LG"], "abstract": "Feature extraction is a very crucial task in image and pixel (voxel) classification and regression in biomedical image modeling. In this work we present a machine learning based feature extraction scheme based on inception models for pixel classification tasks. We extract features under multi-scale and multi-layer schemes through convolutional operators. Layers of Fully Convolutional Network are later stacked on this feature extraction layers and trained end-to-end for the purpose of classification. We test our model on the DRIVE and STARE public data sets for the purpose of segmentation and centerline detection and it out performs most existing hand crafted or deterministic feature schemes found in literature. We achieve an average maximum Dice of 0.85 on the DRIVE data set which out performs the scores from the second human annotator of this data set. We also achieve an average maximum Dice of 0.85 and kappa of 0.84 on the STARE data set. Though these datasets are mainly 2-D we also propose ways of extending this feature extraction scheme to handle 3-D datasets.", "text": "abstract. feature extraction crucial task image pixel classiﬁcation regression biomedical image modeling. work present machine learning based feature extraction scheme based inception models pixel classiﬁcation tasks. extract features multi-scale multi-layer schemes convolutional operators. layers fully convolutional network later stacked feature extraction layers trained end-to-end purpose classiﬁcation. test model drive stare public data sets purpose segmentation centerline detection performs existing hand crafted deterministic feature schemes found literature. achieve average maximum dice drive data performs scores second human annotator data set. also achieve average maximum dice kappa stare data set. though datasets mainly also propose ways extending feature extraction scheme handle datasets. recent research biomedical modelling involves qualitative quantitative classiﬁcation single pixel region interest image classiﬁcation tasks mostly involve three main steps feature extraction feature selection classiﬁcation three steps feature extraction step crucial since goes long determine successful classiﬁcation task would feature extraction process generating features used selection classiﬁcation tasks. whole image volume classiﬁcation feature extraction selection serve dimensionality reduction task subset extracted features selected eliminate redundant features maintaining underlying discriminatory information. newly extracted features normally lower dimension original feature space. however pixelwise feature extraction task leads dimensionality extension. features high dimension extracted given pixel neighbourhood. feature extraction techniques come mainly three main ﬂavours hand crafted texture features supervised learned features unsupervised feature extraction. textures complex visual patterns composed entities subpatterns characteristic brightness colour slope size local subpattern properties give rise perceived lightness uniformity density roughness regularity linearity frequency phase directionality coarseness randomness ﬁneness smoothness granulation etc. texture whole review texture features categorization various uses refer groups hand crafted features based diﬀerential geometry analysis gradient hessian pixel intensity. mostly used image enhancement objects speciﬁc shape interest given image. example multiscale second order local structure image examined purpose developing vessel enhancement ﬁlter ultimately vesselness measure obtained basis eigenvalues hessian. vesselness measure serves measure likelihood presence geometrical structures regarded tubular. also curvilinear structure detector called optimally oriented flux proposed vesselness enhancement. ﬁnds optimal axis image gradients projected order compute image gradient ﬂux. second class feature extraction techniques form unsupervised learning transfer learning. mainly autoencoders variations like restricted boltzmann’s machine. autoencoders simple learning circuits transform inputs outputs least possible amount distortion detailed discussion autoencoders unsupervised learning deep architectures refer architectures though simple important ﬁeld machine learning form basic component deep learning architectures. architectures like deep networks also extract hierarchical features supervised manner ground truth annotations. szegedy proposed inceptions model building deeper networks capable learning extracting dense feature maintaining acceptable speed memory usage. idea used building googlenet achieves state results image classiﬁcation task. paper discuss brieﬂy inception models general extend idea build feature extraction layers based inception models autoencoder fashion. also look stack pixelwise features extraction layers form deep architecture tuned purpose supervised learning. main idea inception architecture based ﬁnding optimal local sparse structure convolutional vision network approximated covered readily available dense components inception based networks replaces convolution operations mini-networks uses less parameters less computation. convolution ﬁlter size replaced mini-network layers ﬁlter sizes shown ﬁgure reduces parameter size form building layers state googlenet network presented ilsvrc competition. thorough discussion inception architure found original inception module proposed used networks meant full image classiﬁcation. section consider ways adapting inception module form feature extraction layer pixel wise classiﬁcation tasks. original inception architecture described section designed domain full image classiﬁcation. therefore leads feature dimensionality reduction. however section rather interested extracting features pixel classiﬁcation. ﬁrst steps mini-networks described section depicted ﬁgure obtain ﬁnal feature extraction layer ﬁgure stacking multiple layers together build feature extraction network suitable pixel classiﬁcation. note output layer transformed non-linear activation function moves next layer. concatenated output layer together input image concatenated form ﬁnal feature shown ﬁgure vessel segmentation experiment drive stare datasets. drive dataset made training test annotations group. ﬁrst annotation ground truth training network testing. also compare results second annotation. stare dataset made annotated images annotations each. split data images training remaining testing. results shows deep-fext network performs existing architecture segmentation drive stare dataset. results deep retinal understanding obtained evaluating pre-computed probability maps provided paper’s page. results also stated reported test deep-fext drive stare datasets purpose centerline prediction. generated centerline annotations applying skeletonization various manual annotations used training testing splits used vessel segmentation. evaluated results based centerline prediction alone combine multi-class prediction centerline vessel. compare result second annotator datasets deep-fext outperforms second annotator deep-fext outperforms existing architectures drive stare datasets. believe deep-fext used extract feature general medical segmentation tasks. replacing convolutions also extend deep-fext handle medical volumes. idea mininetworks memory conserved speed also improved. research recommend experimenting deep-fext unsupervised manner auto-encoder fashion. help generating features clustering situation supervised learning feasible lack manually annotated dataset.", "year": 2017}