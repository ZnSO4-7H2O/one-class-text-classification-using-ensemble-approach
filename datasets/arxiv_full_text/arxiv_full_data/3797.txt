{"title": "Extracting Biomolecular Interactions Using Semantic Parsing of  Biomedical Text", "tag": ["cs.CL", "cs.AI", "cs.IR", "cs.IT", "cs.LG", "math.IT"], "abstract": "We advance the state of the art in biomolecular interaction extraction with three contributions: (i) We show that deep, Abstract Meaning Representations (AMR) significantly improve the accuracy of a biomolecular interaction extraction system when compared to a baseline that relies solely on surface- and syntax-based features; (ii) In contrast with previous approaches that infer relations on a sentence-by-sentence basis, we expand our framework to enable consistent predictions over sets of sentences (documents); (iii) We further modify and expand a graph kernel learning framework to enable concurrent exploitation of automatically induced AMR (semantic) and dependency structure (syntactic) representations. Our experiments show that our approach yields interaction extraction systems that are more robust in environments where there is a significant mismatch between training and test conditions.", "text": "advance state biomolecular interaction extraction three contributions show deep abstract meaning representations signiﬁcantly improve accuracy biomolecular interaction extraction system compared baseline relies solely surfacesyntax-based features; contrast previous approaches infer relations sentence-by-sentence basis expand framework enable consistent predictions sets sentences modify expand graph kernel learning framework enable concurrent exploitation automatically induced dependency structure representations. experiments show approach yields interaction extraction systems robust environments signiﬁcant mismatch training test conditions. recent advances genomics proteomics signiﬁcantly accelerated rate uncovering accumulating biomedical knowledge. knowledge available scientiﬁc publications necessitates development automated semi-automated tools extracting useful biomedical information unstructured text. particular signiﬁcant body research identifying biological entities interactions entities bio-medical papers despite recent progress current methods biomedical knowledge extraction suffer number important shortcomings. first existing methods rely heavily shallow analysis techniques severely limit scope. instance existing approaches focus whether interaction pair proteins ignoring interaction types whereas advanced approaches cover small subset possible interaction types second existing methods focus single-sentence extraction makes susceptible noise. ﬁnally owing enormous diversity research topics biomedical literature high cost data annotation often signiﬁcant mismatch training testing corpora reﬂects poorly generalization ability existing methods paper present novel algorithm extracting biomolecular interactions unstructured text addresses challenges. contrary previous works extraction task considered less restricted spans much diverse corpus biomedical articles. realistic settings present important technical problems provide explicit solutions. speciﬁc contributions follows propose graph-kernel based algorithm extracting biomolecular interactions abstract meaning representation amr. best knowledge ﬁrst attempt using deep semantic parsing biomedical knowledge extraction task. suggest hybrid extraction method utilizes amrs syntactic parses given stanford dependency graphs toward goal develop linear algebraic formulation learning vector space embedding edge labels amrs sdgs deﬁne similarity measures amrs sdgs. conduct exhaustive empirical evaluation proposed extraction system research articles cancer containing approximately positive-negative labeled biomolecular interactions. results indicate joint extraction method leverages amrs sdgs parses signiﬁcantly improves extraction accuracy robust mismatch training test conditions. inhibit phosphorylate signal activate transcript regulate apoptose express translocate degrade carboxymethylate depalmitoylate acetylate nitrosylate farnesylate methylate glycosylate hydroxylate ribosylate sumoylate ubiquitinate. bind heterodimerize homodimerize dissociate. representation motivated biopax interaction refers either entity effecting state change another entity; entity binding/dissociating another entity form/break complex while optionally also inﬂuenced third entity. entity type existent pathway protein complex enzyme although refer entity valid types simply protein. change state entity binding type simply termed interaction type work. cases entities capable changing state bind instance special cases also included. examples interaction types shown table abstract meaning representation semantic annotation single/multiple sentences contrast syntactic parses entities identiﬁed typed semantic roles annotated. maps different syntactic constructs conceptual term. instance binding bound bond correspond concept bind-. representation subsumes multiple syntactic representations hypothesize amrs higher utility extracting biomedical interactions. trained english-to-amr parser manually annotated corpora corpus general domain sentences including newswire text published linguistic data consortium; systems biology sentences including in-domain pubmedcentral papers biocreative corpus. part building bio-speciﬁc corpus extended propbank-based framesets used bio-speciﬁc frames phosphorylate- immunoblot extended list standard named entities types enzyme pathway. important note extensions speciﬁc biomolecular interactions cover general cancer biology concepts. fig. depicts manual annotation sentence highlighted entity nodes labels gtp. nodes also entity type annotations enzyme small-molecule respectively; concept node node label bind- corresponds interaction type binding interaction ras-binds-gtp extracted highlighted subgraph bind node. subgraph relationship interaction node bind- entity nodes deﬁned edges edge labels respectively. additionally subgraph assign roles interaction-type protein protein nodes bind- respectively given graph fig. ﬁrst identify potential entity nodes interaction nodes next consider permutations generate potential interactions according format deﬁned above. candidate interaction extract corresponding shortest path subgraph. project subgraph tree structure interaction node root also possibly protein nodes leaves. subgraph constructed represent extracted candidate interaction interaction node root proteins nodes leaves typically; binary label indicating whether subgraph contains not. given training sample subgraph interaction would like infer whether valid not. address problem developing graph-kernel based approach. propose extension contiguous subtree kernel mapping extracted subgraphs implicit feature space. originally kernel uses identity function node labels calculating similarity nodes. instead propose vector space embedding node labels deﬁne sparse kernel node label vectors. similar extensions convolution kernels suggested previously. consider graphs rooted nodes gi.r gj.r respectively gi.c gj.c children nodes denotes positive part; indicator function; unit vector embeddings node labels represent edge labels roles nodes threshold parameter cosine similarity control sparsity bandwidth. contiguous children subsequences respective root nodes gi.r gj.r; tuning parameter; length sequence i··· sub-tree rooted index child node gi.r. here propose sort children node based corresponding edge labels. helps distinguishing mirror image trees. dynamic programming computing convolution graph kernel convolution kernel presented above main computational cost comparison children sub-sequences. since different children sub-sequences given root node partially overlap other dynamic programming avoid redundant computations thus reducing cost. toward goal following decomposition kernel note graphs cycles dynamic program transformed linear program. couple practical considerations kernel computations. first kernel depends tunable parameters intuitively decreasing discounts contributions longer child sub-sequences. parameter hand controls tradeoff computational cost accuracy. based prior tuning found results sensitive parameters. experiments also consistent previous studies normalize graph kernel divided normalization term often interaction mentioned research paper justiﬁes document-level extraction combines evidence multiple sentences. prevailing approach document-level extraction ﬁrst perform inference sentence level combine inferences using type aggregation function ﬁnal documentlevel inference instance inference maximum score chosen. term baseline approach maximum score inference msi. advocate different approach uses evidences multiple sentences jointly collective inference. assume interaction supported sentences {gm··· gmkm} relevant subgraphs extracted sentences. view elements samples distribution graphs which slight abuse notation denote consider interactions i··· g··· graph distributions representing interactions. maximum mean discrepancy valid norm pair distributions gigj graph kernel deﬁned section iii-c term suggests maximum mean discrepancy represents discrepancy mean graph kernel features samples distributions since norm mean feature vectors valid kernel function. note metric attracted considerable attention machine learning community recently purpose prefer using divergence metric others following reasons kernel trick based formulation nicely ﬁtting settings since explicit features representation graphs kernel density graph samples. true kl-d estimation kernel density method. empirical estimate valid norm distance. therefore straightforward derive graph distribution kernel using function rbf. true divergence metrics kl-d renyi iii) suitable compactly supported distributions whereas methods k-nearest neighbor estimation kl-d suitable number samples distribution small seen consistent results extraction experiments using metric opposed others. mentioned reasons focus primary metric computing similarities graph distributions. proposed framework however general limited speciﬁc metric. next brieﬂy describe metrics used gdk. kullback-leibler divergence represents maximum discrepancy mean features distributions kullback-leibler divergence comprehensive measure distance distributions. deﬁning kernel terms kl-d however challenges. first kl-d symmetric function. problem addressed using symmetric version distance kernel distance distribution w.r.t. distribution second even symmetric combination divergences valid euclidian distance. hence guaranteed positive semi-deﬁnite function. issue dealt practical manner nicely discussed namely computed gram matrix using project onto positive semi-deﬁnite using linear algebraic techniques e.g. discarding negative eigenvalues spectrum. since know true divergence approximate empirical estimate data ˆdkl. different approaches estimating divergences samples kernel density estimator shown below note metric looks quite similar mmd. demonstrated experiments however better presumably accounts mean kernel similarity samples distribution. sample sub-graphs inferring interaction evaluate test distribution train distributions {g··· corresponding sample sets. then apply kernel trick based classiﬁer. previous section proposed novel algorithm document-level extraction interactions amrs. looking forward experiments amrs yield better extraction accuracy compared sdgs. result suggests using deep semantic features useful extraction task. hand accuracy semantic parsing good accuracy shallow parsers like sdgs thus whether joint semantic syntactic parses improve extraction accuracy further. intuitive observations justify joint approach shallow syntactic parses sufﬁcient correctly extracting subset interactions; semantic parsers might make mistakes avoidable syntactic ones. instance machine translation based semantic parsers hallucinating phrasal translations introduce interaction/protein parse non-existent true semantics; iii) syntactic/semantic parsers vary test corpus depending upon data used independent trainings. sub-graphs constructed parses sentence respectively. problem classify interaction jointly features sub-graphs. extended multiple evidence sentences. argue graph-kernel framework outlined applied setting well modiﬁcations. sets points. apply framework above need valid kernel deﬁned joint space. deﬁning kernel would using similarity measures amrs sdgs separately combining e.g. linear combination. however advocate different approach ﬂatten joint representation. candidate interaction represented points space. projection valid operation long similarity measure rather problematic since amrs sdgs non-overlapping edge labels address issue inducing similarity measure next develop approach edge-label vector space embedding. understand mean vector space embedding edge-labels. fig. parse activates b-raf. nsubj conveying catalyst interaction activation; acomp meaning b-raf activated. sentence nsubj playing role though higher dimensional roles across diversity sentences would vary. along lines propose embed high dimensional roles vector space termed edge label vectors. describe unsupervised algorithm learns vector space embedding edge labels. algorithm works imposing linear consistency conditions word vector embeddings node labels. describe algorithm using amrs directly applicable sdgs well. linear algebraic formulation formulation ﬁrst learn subspace embedding edge labels transform vectors ﬂattening. fig. again. already word vectors embedding terms activate b-raf denoted wactivate wras wbraf respectively; word vector rm×. embedding edge labels aarg aarg; rm×m. deﬁne following linear algebraic equations. edge label matrices linear transformations word vectors wras wbraf establishing linear consistencies word vectors along edges. deﬁne equations parent-children nodes sub-graph given manually annotated amrs along lines pair edge labels amrs generalized equations below. edge labels matrices. considering occurrences edge labels correspondingly word vectors child node labels stacked rows matrix rni×m; rni×m parent node labels. would subset instances edge labels parent node gives rows). along lines neighborhood edge label deﬁned s.t. pairwise theorem states gauss-seidel method converges linear transformation matrix linear program strictly diagonal dominant formulation diagonal blocks dominate non-diagonal ones row-wise. thus algorithm converge optimum. using algorithm learned edge label matrices amrs sdgs independently corresponding amrs sdgs annotations bio-sentences convergence fast amrs sdgs next ﬂatten edge label matrix rm×m corresponding edge label vector redeﬁne redeﬁnition enables deﬁne kernel similarity amrs sdgs. either original formulation single amr/sdg sub-graph classiﬁed using training sub-graphs amrs sdgs inference samples graph chosen. another option preferable consider maximum score-msi distribution representing interaction generalizing further samples containing number sub-graphs amrs sdgs respectively multiple sentences document classifying graph distribution representation apply section infer using kernel trick based classiﬁer. ﬁnal formulation gives best results experiments discussed next. pubmed dataset manual auto parses amrs amrs auto-parses pubmed articles cancer. amrs extract subgraphs representing interactions applies sdgs. primary data evaluation. found based methods part extraction error attributed poor recognition named entities. minimize effect isolate errors speciﬁc extraction methods themselves follow footsteps previous studies take ﬁltered subset interactions refer data subset pubmed super pubmed-ern aimed publicly available dataset contains sentences abstracts. contrast pubmed dataset limited describes whether given pair proteins interact without specifying interaction type. nevertheless useful include dataset evaluation since enables compare results reported methods. alternatives kernel directly matrices instead ﬂattening accurate plan explore future sentences used learning edge label vectors http//corpora.informatik.hu-berlin.de typical evaluation scenario validation performed random sub-sampling labeled interactions test subset using rest training set. sentence-level validation approach always appropriate extracting protein interactions since interactions single/multiple sentences document correlated. correlations lead information leakage training test sets instance reported score random validation aimed data approx. algorithm even using sdgs gives score settings. however performance drops signiﬁcantly independent test document processed. therefore realistic evaluation divide data sets documents level approx. subsets minimal match subset chosen test rest sets used training kernel classiﬁer. pubmed data sets articles clustered subsets clustering pubmed-ids aimed abstracts clustered subsets abstract-ids. independent test runs single test subset interactions randomly sampled test subset percent train data. classiﬁcation libsvm implementation kernel support vector machines sklearn python wrapper speciﬁcally used settings probability class weight auto}. data class swap addition binary classes swap class means interaction invalid swapping entity roles interaction makes valid. analysis purpose however focus scores positive class i.e. class valid. categorize methods evaluated follows sentence level inference-sli document level using maximum score inference-msi iii) document-level inference subgraphs using graph distribution kernel categories amrs sdgs used independently jointly. edge label vectors used amrs sdgs jointly used referred amr-sdg. table shows score statistics experiments. addition mean precision recall values presented tuples table. following discussion focus scores keep exposition simple. http//scikit-learn.org/stable/modules/generated/sklearn.svm.svc.html note even sentence level inference training/test division done document level. going detailed discussion results make following observations. first that methods obtain much better accuracy using amrs compared sdgs. result remarkable especially taking account fact accuracy semantic parsing still signiﬁcantly lower compared syntactic parsing. second observe overall accuracy numbers considerably lower pubmed-ern data compared ﬁltered data pubmed. focus document-level extraction using msi. much improvement numbers compared pubmed data. hand even simple technique works restricted extraction settings aimed data. works aimed data probably multiple sub-graph evidences varying interaction types even single sentence representing protein-protein pair interaction. high number evidences document level give boost performance even using msi. next consider document-level extraction using proposed method metric. comparing baseline signiﬁcant improvement data sets amrs sdgs effect noise entity recognition possible reason work well data compared data sets. here also that method performs better document level baseline msi; amrs perform better sdgs method also. consider results extraction using amrs sdgs jointly. evaluate using edge label vectors. primary observation joint inference using amrs sdgs improves extraction accuracy across datasets. furthremore pubmed datasets proposed method suitable choice joint inference amrs sdgs. comparing amrs only points increment pubmed-ern data pubmed data. aimed dataset hand best result obtained uses baseline joint inference amrs sdgs. insights consider tuples shown table general trend amrs lead higher recall compared sdgs. pubmed-ern data increase recall cost drop precision values. since entity types noisy data drop precision numbers completely surprising method data however precision drop becomes negligible recall still increases signiﬁcantly. data pubmed precision recall generally higher amrs compared sdgs. again exception approach recall decreases slightly. however corresponding precision almost doubles. ﬁne-grained comparison methods plot score individual test fig. here compare baselines amr-sdg data aimed). general trend across test subsets amrs accurate sdgs joint improving even upon amrs. though exceptions difference marginal three. cross checking exceptions relatively information leakage train-test i.e. less train-test divergence. maximum mean discrepancy-mmd evaluating train-test divergence results method described speciﬁc metric. also evaluated using metrics speciﬁcally pubmed-ern dataset presented table iii. here table also present tuples. kl-d metrics both perform equally well whereas better case sdg. relatively naive approach also performs reasonably well although amrs performs worse compared kl-d. precision recall numbers table similar trends reported table observe recall numbers increase amrs compared sdgs also comparing kl-d former favors higher precision albeit expense lower recall values. different lines work extracting protein extractions. pattern-matching based systems usually yield high precision recall kernel-based methods based various convolution kernels also developed extraction task approaches work string rather parses mentioned works either rely text shallow parses none using semantic parsing extraction task. also works consider protein-protein interactions ignoring interaction types. recent works used distant supervision obtain large data protein-protein pairs experiments previously idea linear relational embedding explored triples concepts relation types concepts embedded latent space. neural networks also employed joint embedding advocate factored embedding concepts embedded ﬁrst using plain text relations embedded linear sub-space. summary developed validated method extracting biomolecular interactions that ﬁrst time uses deep semantic parses biomedical text presented novel algorithm relies graph distribution kernels document-level extraction interactions amrs document. operate parses sentences jointly. rationale behind hybrid approach neither parsing perfect combination yield superior results. indeed experimental results suggest proposed approach outperforms baselines especially practically relevant scenario noticeable mismatch training test sets. facilitate joint approach proposed novel edge vector space embedding method assess similarity different types parses. believe notion edge-similarly quite general applicability wider class problems involving graph kernels. future work intend validate framework number problems improving accuracy amrs parsing sdgs. work sponsored darpa mechanism program pleasure acknowledge fruitful discussions michael pust kevin knight shuyang linhong neal lawton emilio ferrara greg steeg. also grateful anonymous reviewers valuable feedback. laura banarescu claire bonial madalina georgescu kira grifﬁtt hermjakob kevin knight philipp koehn martha palmer nathan schneider. abstract meaning representation sembanking. proceedings linguistic annotation workshop interoperability discourse razvan bunescu ruifang rohit kate edward marcotte raymond mooney arun ramani wong. comparative experiments learning information extractors proteins interactions. artiﬁcial intelligence medicine pages information extraction robust retrieval protein interactions medline. natural language processing biology towards deeper biological literature analysis stephen clark. vector space models lexical meaning. handbook contemporary semantics blackwell aron culotta jeffrey sorensen. dependency tree kernels relation extraction. proc. page emek demir michael cary suzanne paley fukuda christian lemer imre vastrik guanming peter d’eustachio carl schaefer joanne luciano biopax community standard pathway data sharing. nature biotechnology tilmann gneiting. compactly supported correlation functions. journal multivariate analysis arthur gretton karsten borgwardt malte rasch bernhard sch¨olkopf alexander smola. kernel two-sample lawrence hunter zhiyong james firby william baumgartner helen johnson philip ogren bretonnel cohen. opendmap open source ontology-driven concept analysis engine applications capturing knowledge regarding protein transport protein interactions cell-type-speciﬁc gene expression. bioinformatics beomjoon joelle pineau. maximum mean discrepancy imitation learning. proc. martin krallinger florian leitner carlos rodriguez-penagos alfonso valencia. overview protein-protein yashar mehdad alessandro moschitti fabio massimo zanzotto. syntactic/semantic structures textual entailment human language technologies annual conference north american chapter yushi wang jonathan berant percy liang. building semantic parser overnight. proc. dmitry zelenko chinatsu aone anthony richardella. kernel methods relation extraction. jmlr", "year": 2015}