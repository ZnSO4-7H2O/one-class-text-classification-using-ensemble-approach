{"title": "Non-Local Color Image Denoising with Convolutional Neural Networks", "tag": ["cs.CV", "cs.AI"], "abstract": "We propose a novel deep network architecture for grayscale and color image denoising that is based on a non-local image model. Our motivation for the overall design of the proposed network stems from variational methods that exploit the inherent non-local self-similarity property of natural images. We build on this concept and introduce deep networks that perform non-local processing and at the same time they significantly benefit from discriminative learning. Experiments on the Berkeley segmentation dataset, comparing several state-of-the-art methods, show that the proposed non-local models achieve the best reported denoising performance both for grayscale and color images for all the tested noise levels. It is also worth noting that this increase in performance comes at no extra cost on the capacity of the network compared to existing alternative deep network architectures. In addition, we highlight a direct link of the proposed non-local models to convolutional neural networks. This connection is of significant importance since it allows our models to take full advantage of the latest advances on GPU computing in deep learning and makes them amenable to efficient implementations through their inherent parallelism.", "text": "figure image denoising proposed deep non-local model. noisy image corrupted additive gaussian noise psnr denoised image using -stage feed-forward network described sec. psnr restoration tasks based general network architectures fully exploit problem-speciﬁc knowledge. thus reasonable expect incorporating information could lead improvements performance. recently schmidt roth chen pock introduced deep networks whose architecture speciﬁcally tailored certain image restoration problems. however even cases resulting models local ones take account inherent non-local self-similarity property natural images. hand conventional methods exploited property shown gain signiﬁcant improvements compared standard local approaches. notable example block matching collaborative filtering method efﬁcient highly engineered approach held state-of-the-art record image denoising almost decade. propose novel deep network architecture grayscale color image denoising based non-local image model. motivation overall design proposed network stems variational methods exploit inherent non-local self-similarity property natural images. build concept introduce deep networks perform non-local processing time signiﬁcantly beneﬁt discriminative learning. experiments berkeley segmentation dataset comparing several state-of-the-art methods show proposed non-local models achieve best reported denoising performance grayscale color images tested noise levels. also worth noting increase performance comes extra cost capacity network compared existing alternative deep network architectures. addition highlight direct link proposed non-local models convolutional neural networks. connection signiﬁcant importance since allows models take full advantage latest advances computing deep learning makes amenable efﬁcient implementations inherent parallelism. deep learning methods successfully applied various computer vision tasks including image classiﬁcation object detection dramatically improved performance systems setting state-of-the-art. recently promising results also reported image processing applications image restoration super-resolution optical signiﬁcant boost performance achieved deep networks mainly attributed advanced modeling capabilities thanks deep structure presence non-linearities combined discriminative learning large training datasets. however current deep learning methods developed imdeveloped past tackling image reconstruction problems study deep network architectures image denoising. inspired non-local variational methods related approaches design network performs non-local processing time signiﬁcantly beneﬁts discriminative learning. specifically strategy instead manually designing nonlocal regularization functional learn non-local regularization operator potential function following loss-based training approach. contributions work summarized follows propose novel deep network architecture discriminatively trained image denoising. opposed existing deep-learning methods image restoration based local models network explicitly models non-local self-similarity property natural images grouping operation similar patches joint ﬁltering. unroll proximal gradient method deep network learn relevant parameters using simple effective back-propagation strategy. contrast majority recent denoising methods designed processing single-channel images introduce variation network applies color images leads state-of-the-art results. highlight direct link proposed non-local networks convolutional neural networks connection allows models take full advantage latest advances computing deep learning makes amenable efﬁcient implementations inherent parallelism. setting rn·c vectorized versions observed latent images respectively number pixels number image channels assumed i.i.d gaussian noise variance ill-posedness studied problem relates latent image observation canuniquely characterize solution. implies order obtain physically statistically meaningful solution image evidence must combined suitable image priors. among popular powerful strategies available literature combining observation prior information variational approach. framework recovery heavily relies formation objective function whose role quantify quality solution. typically objective function consists terms namely data ﬁdelity term measures proximity solution observation regularizer constrains plausible solutions penalizing exhibit desired properties. regularization parameter balances contributions terms. then restoration task cast minimization objective function minimizer corresponds restored image. note problem consideration since noise corrupting observation i.i.d gaussian data term equal variational restoration approach also direct links bayesian estimation methods interpreted either penalized maximum likelihood maximum posteriori estimation problem image regularization choice appropriate regularizer important since main factors determine quality restored image. reason effort made design novel regularization functionals model important image properties consequently lead improved reconstruction results. existing regularization methods based either synthesisanalysis-based approach. synthesis-based regularization takes place sparsifying-domain wavelet basis restored image obtained applying inverse transform hand analysis-based regularization involves regularizers directly applied image aims restore. general inverse problems latter regularization strategy reported lead better reconstruction results therefore mostly preferred. rr×d regularization operator potential function. common choices differential operators ﬁrst higher orders gradient structure tensor laplacian hessian wavelet-like operators wavelets curvelets ridgelets references therein). potential function popular choices vector matrix norms type functions also frequently used pseudo-norm logarithm. combinations regularization operators potential functions lead existing regularization functionals proven effective several inverse problems including image denoising. notable representative follow work directly gradient-descent algorithm. since indicator function non-smooth instead classical gradient descent algorithm employ proximal gradient method according method objective function split terms differentiable. assume potential function smooth therefore compute partial derivatives. case splitting choose objective function form deﬁned become clear later choice allows reduce signiﬁcantly computational cost training network make learning process feasible. also worth noting decoupled formulation potential function frequently image regularization wavelet regularization anisotropic field-of-experts regularization similar methods penalize derivatives essentially local methods since involve operators restricted region image domain. recently different regularization paradigm introduced non-local operators employed deﬁne regularization functionals resulting non-local methods well-suited image processing computer-vision applications produce competitive results. reason allow long-range dependencies image points able exploit inherent non-local self-similarity property natural images. property implies images often consist localized patterns tend repeat themselves possibly distant locations image domain. worth noting alternative image denoising methods fall category analysis-based regularization schemes still exploit self-similarity property developed produce excellent results. nonexhaustive list methods non-local means ﬁlter learned simultaneous sparse coding weighted nuclear norm minimization besides formulation objective function proper selection regularizer another important aspect variational approach minimization strategy employed obtain solution. case study solution image denoising problem mathematically formulated indicator function convex tion takes value otherwise. presence additional term stems fact type constraints image intensities arise naturally. example reasonable require intensity restored image either nonnegative values speciﬁc range iterations required. addition exact form operator potential function must speciﬁed. determining appropriate values quantities general difﬁcult task. generated increased research interest effort made designing regularization functionals lead good reconstruction results. work pursue different approach conventional regularization methods instead handpicking exact forms potential function regularization operator design network capacity learn quantities directly training data. core idea unroll proximal gradient method limited number iterations derived construct graph network. then learn relevant parameters training network using pairs corrupted ground-truth data. next describe detail overall architecture proposed network trained discriminatively image denoising. first motivate derive structure processing grayscale images explain necessary modiﬁcations processing color images. mentioned earlier non-local regularization methods shown produce superior reconstruction results local counterparts several inverse problems including image denoising. superiority performance mainly attributed ability modeling complex image structures allowing long-range dependencies points image domain. fact highly motivates explore design network exhibit similar behavior. starting point deﬁnition non-local operator serve backbone network structure. consider single-channel image size vector formed stacking together columns further consider image patches size denote vector whose elements correspond pixels r-th image patch extracted vector derived binary matrix indicates elements belong extracted image patches closest neighbors selected. irk} indices similar patches r-th patch next two-dimensional transform applied every patch patch transform represented matrixvector multiplication rf×p note patch representation transform domain redundant. work focus nonredundant case transformed patch group formed using k-closest patches. denoted ﬁnal step non-local operator involves collaborating ﬁltering among group expressed wfir weighting matrix constructed retaining ﬁrst rows circulant matrix. ﬁrst matrix correr× block diagonal matrix whose diagonal elements correspond patch-transform matrix non-local operator rr·f described bears strong resemblance analysis operator studied main difference proposed operator weighted average transformed patches group takes place described figure architecture single stage proposed non-local convolutional network. stage network symmetric consists convolutional de-convolutional layers. layers layer trainable non-linear functions. operator haar wavelet transform applied group. decision particular set-up non-local operator mainly based computational considerations decreasing memory requirements network propose next. adjoint non-local operator important component network since provides reverse mapping transformed patch domain original image domain rr·f convolutional implementation non-local explain next non-local operator deﬁned adjoint deﬁned computed using convolution operations transpose. therefore efﬁciently implemented using modern software libraries cudnn support multi-threaded parallel implementations. concretely image patch extraction patch transform fprx combined computed passing image convolutional layer. order obtain desired output ﬁlterbank consist many ﬁlters number coefﬁcients transform domain. addition support ﬁlters match size image patches. implies case ﬁlters support used. also note based desired overlap consecutive image patches appropriate stride convolution layer chosen. finally non-local weighted operation also computed using convolutions. particular following grouping operation similar transformed patches completely deﬁned desired output obtained convolving grouped data single ﬁlter support necessary steps computing non-local operator using convolutional layers illustrated fig. compute adjoint non-local operator simply follow opposite direction graph shown fig. replace convolution patch grouping operations transpose operations. parameterization potential function besides non-local operator need model potential function indirectly representing partial derivatives linear combination radial basis functions employ gaussian kernels whose centers distributed equidistantly share precision parameter representation using mixtures rbfs powerful allow approximate high accuracy arbitrary non-linear functions. important advantage conventional regularization methods mostly rely limited potential functions ones reported section also note parameterization potential gradient would computationally expensive adopted decoupled formulation potential function. pieces puzzle order architecture single iteration network refer stage depicted fig. note network follows closely proximal gradient iteration difference parameter absorbed potential gradient whose representation learned. observe every stage network consists convolutional deconvolutional layers layer trainable non-linear functions. architecture proposed network shown fig. handle grayscale images. deal color images simple approach would network process image channel independently. however would result sub-optimal restoration performance since network would able explore existing correlations different channels. circumvent limitation follow similar strategy feed noisy color image network apply opponent color transformation results luminance chrominance channels. nature color transform luminance channel contains valuable information primitive image structures higher signal-tonoise-ratio chroma channels. take advantage fact since block-matching operation sensitive presence noise perform grouping patches luminance channel. then exactly group indices image channels. another important modiﬁcation make original network every image channel learn different mixture. reason color transformation three resulting channels different snrs need correctly accounted for. finally important note image channels share ﬁlters convolutional weighted-sum layers transposes. reasoning network better exploit channel correlations. by-product speciﬁc network design search similar patches needs performed compared naive implementation would demand computed independently channel. addition since operation computed noisy input re-used network stages processing color channels take place completely decoupled therefore network admits efﬁcient parallel implementation. noisy input corresponding ground-truth image. achieve increased capacity network learn different parameters stage. therefore overall architecture network exactly proximal gradient method rather adaptive version. nevertheless stage convolution deconvolution layers share ﬁlter parameters thus correspond proper proximal gradient iterations. since objective function need minimize non-convex order avoid getting stuck local-minima also speed-up training initially learn network parameters following greedy-training strategy. approach followed case minimize cost minimize objective function w.r.t parameters employ l-bfgs algorithm l-bfgs quasi-newton method therefore requires gradient w.r.t computed using chain-rule jacobian output t-th stage computed using omit details computation derivatives w.r.t speciﬁc network parameters provide derivations appendix. here sufﬁces gradient loss function efﬁciently computed using back-propagation algorithm clever implementation chain-rule. greedy-training l-bfgs iterations learn parameters stage independently. learned parameters initialization network train stages jointly. joint training figure grayscale image denoising. original image noisy image corrupted gaussian noise psnr denoised image using nlnet psnr denoised image using psnr denoised image using wnnm psnr w.r.t parameters network cost function take account anymore intermediate results depends ﬁnal output network case l-bfgs iterations reﬁne result obtained greedy-training. similarly previous case still employ backpropagation algorithm compute required gradients. train grayscale color non-local models generated training data using berkeley segmentation dataset consists images. split images sets training consists images validation/test consists remaining images. images randomly cropped resulting size pixel. note bsds images used comparisons reported tables strictly excluded training set. proposed models trained nvidia tesla software used training testing built matconvnet grayscale denosing following strategy described section trained stages different varia× tions model refer nlnet main difference connlnet ﬁguration non-local operator. ﬁrst network considered patches size second considered slightly larger patches size cases patch stride every pixel image considered center patch. consequently input images network stage padded accordingly using symmetric boundaries. addition non-redundant patch-transform learned training applied every image-patch group formed using closest neighbors. similar patches searched noisy input network window centered around pixel. group indices used stages network. table report comparisons proposed models several recent statenlnet of-the-art denoising methods standard evaluation dataset images results observe non-local models lead best overall performance exception case table grayscale image denoising comparisons three different noise levels standard berkeley images. restoration performance measured terms average psnr best results highlighted bold. left part table quoted chen results dgcrf taken table color image denoising comparisons three different noise levels standard berkeley images. restoration performance measured terms average psnr best result highlighted bold. denoising method achieves slightly better average psnr compared nlnet worths noting nlnet lower capacity still produces better restoracsf tion results tested cases. attributed non-local information exploits opposed local models. representative tnrd grayscale denoising results demonstrate visually restoration quality proposed models shown fig. color denoising given grayscale case patches bring substantial improvements compared patches color case trained single conﬁguration model considering color image patches size besides standard differences described section between color grayscale versions nlnet model rest parameters size patchgroup search window remain same. important remark make denoising methods considered previously explicitly designed treat single-channel images notable exception indeed exists color-version practice means need restore color-images methods applied independently every image channel. case however denoising performance anymore correspond state-of-theart. reason single-channel design fail capture existing correlations image channels limitation direct impact ﬁnal restoration quality. fact also veriﬁed color denoising comparisons reported table results observe tnrd models outperform single-channel images fall behind restoration performance dbs. fact noise levels cbmd currently produces state-of-the-art results leads psnr gains exceed dbs. comparing proposed non-local model manages provide cbmd observe cnlnet better restoration results reported noise levels psnr gain ranging approximately dbs. aware color-denoising method manages compete cbmd large images. visual inspection color restoration performance cnlnet work proposed novel network architecture grayscale color image denoising. design resulting models inspired non-local variational methods exploits non-local self-similarity property natural images. believe non-local modeling coupled discriminative learning factors improved restoration performance models achieve compared several recent state-of-the-art methods. meanwhile proposed models direct links convolutional neural networks therefore take full advantage latest advances parallel computing deep learning. conﬁdent image restoration many inverse imaging problems non-local networks successfully handle. believe interesting research direction investigate necessary modiﬁcations design current non-local models would allow efﬁciently applied important reconstruction problems. another relevant research question possible train single model handle noise levels. parameters note derivative calculations denominator layout notation. further recall order learn parameters wt}s network consists stages different strategies namely greedy joint training. greedy training learn parameters stage network independently parameters stages minimizing loss function hand joint training complete network parameters learned simultaneously minimizing loss function given hereafter consider case single training example ˆxt. order retain notation simplicity following computations also drop superscript variables necessary. expansion coefﬁcients compute gradient loss function w.r.t expansion coefﬁcients mixture gaussian rbfs ﬁrst express output mixture vector inner product. speciﬁcally holds weighted coefﬁcients simplify computation gradient loss function w.r.t ﬁrst obtain equivalent expression non-local operator deﬁned indeed non-local operator re-written section provide additional grayscale color image denoising results different noise levels. grayscale image denoising compare performance non-local models tnrd epll color image denoising compare non-local state-of-the-art cbmd method besides visual comparisons captions ﬁgures provide psnr score method also allow quantitative comparison.", "year": 2016}