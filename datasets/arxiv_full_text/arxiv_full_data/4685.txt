{"title": "Continuous Time Markov Networks", "tag": ["cs.AI", "cs.LG"], "abstract": "A central task in many applications is reasoning about processes that change in a continuous time. The mathematical framework of Continuous Time Markov Processes provides the basic foundations for modeling such systems. Recently, Nodelman et al introduced continuous time Bayesian networks (CTBNs), which allow a compact representation of continuous-time processes over a factored state space. In this paper, we introduce continuous time Markov networks (CTMNs), an alternative representation language that represents a different type of continuous-time dynamics. In many real life processes, such as biological and chemical systems, the dynamics of the process can be naturally described as an interplay between two forces - the tendency of each entity to change its state, and the overall fitness or energy function of the entire system. In our model, the first force is described by a continuous-time proposal process that suggests possible local changes to the state of the system at different rates. The second force is represented by a Markov network that encodes the fitness, or desirability, of different states; a proposed local change is then accepted with a probability that is a function of the change in the fitness distribution. We show that the fitness distribution is also the stationary distribution of the Markov process, so that this representation provides a characterization of a temporal process whose stationary distribution has a compact graphical representation. This allows us to naturally capture a different type of structure in complex dynamical processes, such as evolving biological sequences. We describe the semantics of the representation, its basic properties, and how it compares to CTBNs. We also provide algorithms for learning such models from data, and discuss its applicability to biological sequence evolution.", "text": "central task many applications reasoning processes change continuous time. recently nodelman introduced continuous time bayesian networks structured representation representing continuous time markov processes structured state space. paper introduce continuous time markov networks alternative representation language represents different type continuous-time dynamics particularly appropriate modeling biological chemical systems. language dynamics process described interplay forces tendency entity change state model using continuous-time proposal process suggests possible local changes state system different rates; global ﬁtness energy function entire system governing probability proposed change accepted capture markov network encodes ﬁtness different states. show ﬁtness distribution also stationary distribution markov process representation provides characterization temporal process whose stationary distribution compact graphical representation. describe semantics representation basic properties compares ctbns. also provide algorithm learning models data demonstrate potential beneﬁt learning approaches. many applications reason processes evolve time. processes involve short time scales long ones examples obvious discrete time unit process evolves. rather natural view process changing continuous time system state certain duration transitions another state. language continuous time markov processes provides elegant mathematical framework reason probability trajectories systems. unfortunately consider system multiple components representation grows exponentially number components. thus construct representation language ctmps compactly encode natural processes high-dimensional state spaces. importantly representation also facilitate effective inference learning. recently nodelman introduced representation language continuous time bayesian networks provides factorized componentbased representation ctmp component characterized conditional ctmp dynamics describes local evolution function current state parents network. representation natural describing systems sparse structure local inﬂuences components. nodelman provide algorithms efﬁcient approximate inference ctbns learning complete incomplete data. paper introduce continuous time markov networks different representational bias. motivating example modeling evolution biological sequences proteins. example state system given time sequence amino acids encoded gene interest. evolution progresses sequence continually modiﬁed local mutations change individual amino acids. mutations different amino acids occur independently probability local mutations survive depends global aspects sequence. example mutation accepted sequence amino acids folds properly functional protein occurs pairs amino acids contact folded protein complementary charges. thus although modiﬁcations local global constraints protein structure function introduce dependencies. capture situations introduce representation specify dynamics process using components. ﬁrst proposal process attempts change individual components system. example process determine rate random mutations protein sequences. second equilibrium distribution encodes preferences global conﬁgurations system. example approximation ﬁtness folded protein. equilibrium distribution static quantity encodes preferences among states system rather dynamics changes. actual dynamics system determined interplay forces local mutations global ﬁtness. represent equilibrium distribution compactly using markov network generally feature-based log-linear model. importantly shall equilibrium distribution parameter indeed equilibrium distribution process. thus representation provides explicit representation dynamics system asymptotic limit. moreover representation ensures equilibrium distribution pre-speciﬁed simple structure. thus view framework continuous-time markov network markov network evolves continuous time. different perspective representation allows capture family temporal processes whose stationary distribution certain locality structure. processes occur often biological physical systems. example recent results socolich suggest pairwise markov networks fairly accurately capture ﬁtness protein sequences. provide reduction ctmns ctbns allowing ctbn algorithms perform effective approximate inference ctmns. importantly also provide procedure learning ctmn parameters data. procedure allows estimate stationary distribution observations system’s dynamics. important applications stationary distribution provides insight domain application. protein evolution example stationary distribution provides description evolutionary forces shape protein thus gives important clues protein structure function. brieﬂy summarize relevant properties continuous time markov processes needed below. refer interested reader taylor karlin chung thorough expositions. suppose family random variables continuous index denotes time. joint distribution random variables homogeneous continuous time markov process satisﬁes markov property time-homogeneity implies right hand side depend provided transition function satisﬁes certain analytical properties dynamics fully captured constant matrix rate intensity matrix whose entries deﬁned indicator function takes value condition argument holds otherwise. markov process also viewed generative process process starts state spending ﬁnite amount time transitions random time random state transition times various states exponentially distributed rate parameters qxy. diagonal elements ensure constraint sums zero. exists independent initial state long time limit probability visiting state independent initial state time distribution called stationary distribution process. ctmp called stationary initial state sampled stationary distribution. stationary ctmp called reversible every condition implies process statistically equivalent running backward time. reversibility intrinsic many physical systems microscopic dynamics time-reversible. reversibility formulated property markov transition function every formally continuous time metropolis process deﬁned symmetric matrix distribution real-valued function semantics process deﬁned generative manner. starting initial state system remains state receiving proposed transition rate rxy. proposal accepted probability accepted system transitions state otherwise remains state process repeated indeﬁnitely. formulate statistical dynamics system consider short time interval case probability proposal transition roughly rxy. since proposed transition accepted probability have proposition reversible ctmp represented continuous time metropolis process. proof according proposition write πysxy symmetric matrix sxy. deﬁne start considering reformulation reversible ctmps continuous time version metropolis sampling process. view process interplay between factors. ﬁrst unbiased random process attempts transition states system second tendency system remain probable states. latter probability taken stationary distribution process. structure process thought going iterations proposed transitions either accepted rejected similar metropolis sampler formally describe process need describe components. ﬁrst unbiased proposal transitions. proposals occur ﬁxed rates. denote rate proposals transition occur. effect deﬁnes ctmp process rate matrix ensure unbiased proposal require symmetric. second component decision whether accept reject proposed transition. decision whether accept transition depends probability ratio states equilibrium. assume given target distribution coincide equilibrium distribution shall reach target equilibrium distribution acceptance probability satisfy simple condition. make precise assume acceptance function takes argument ratio πy/πx returns probability accepting transition function return value satisfy functional relation function fmetropolis standard used metropolis sampling. function flogistic closely linked logistic regression. continuously differentiable which shall facilitates subsequent analysis. assignment state variables assumes ﬁnite values. main challenge dealing large state space succinct representations system’s dynamics within framework continuous time metropolis processes. stages ﬁrst dealing proposal rate matrix equilibrium distribution second assumption concerns structure stationary distribution log-linear models markov networks provide general framework describe structured distributions. log-linear model described features encoding local property system involves variables. example function feature involves variables. feature-based markov network deﬁned vector features feature assigns real number state system. further assume feature function subset variables. notation x|dk denote projection subset variables thus function x|dk; however notational convenience sometimes shorthand based features deﬁne distribution assigning different weights feature. weights represent relative importance feature. notation denote vector weights parameters. equilibrium distribution represented takes log-linear form partition function normalizing factor. structure equilibrium distribution represented undirected graph nodes represent variables xn}. edge corresponding nodes. thus every feature nodes represent variables form clique graph deﬁne markov blanket variable neighbors graph example process variable takes binary take advantage structured representation succinct representation rate matrix process. exploit facts appears explicitly rate ratio πy/πx moreover proposal process includes transitions modify single variable. thus examine ratios agree variables one. straightforward show states identical except value thus acceptance probability change depends state variables markov blanket. property heavily used gibbs sampling markov networks. depending choice features dependencies sparse involve variables process. call process matrix form continuous time markov network consequence form ctmn rate matrix dynamics i’th variable depend directly dynamics neighbors. expect property discuss independencies among variables network. however since examining continuous process need consider independencies full trajectories theorem consider ctmn stationary distribution represented graph subsets separates trajectories conditionally independent given observation full trajectory proof using global independence properties markov network written product function domain trajectories variables given dynamics variables independent ctmns stationary distribution. consequence desired independence. important note although represent reversible ctmp continuous time metropolis process move ctmns longer case. main restriction that ctmns deﬁned them transition involves change state exactly component. thus although language markov networks allow describe arbitrary equilibrium distributions restrictions limit range processes describe ctmns. example domain ctmns suitable consider reasoning biochemical systems component state number molecules particular species transitions correspond chemical reactions. example reaction might takes molecule molecule replace molecule. reactions reversible process might described reversible ctmp. however since reactions change several components once cannot describe system ctmn. factored form allows relate ctmns ctbns. ctbn deﬁned directed graph whose nodes correspond variables process whose edges represent direct inﬂuences variable evolution another. precisely ctbn deﬁned collection conditional rate matrices possible value direct parents ctbn graph matrix qxi|ui rate matrix state space conditional rate matrices combined global rate matrix process nodelman call amalgamation. brieﬂy identical except value x|pai assignment xi’s parents state rate transition conditional rate changing given state parents. again off-diagonal elements variable changes figure shows ctbn structures corresponding ctmn example general ctbn graph corresponding given ctmn built replacing undirected pair directed ones. matches intuition appear context feature mutually inﬂuence other. transformation shows class processes encoded using ctmns subclass ctbns. sense surprising ctbn encode markov process variable transition time. however ctmn representation imposes particular parametrization system dynamics terms local proposal process global equilibrium distribution. parametrization violates local global parameter independence resulting ctbn. particular transition proposed rate regardless whether globally advantageous shall property important ability effectively estimate rate parameters. moreover seen parametrization guarantees stationary distribution process factorizes particular markov network. general even fairly sparse ctbn gives rise fully entangled stationary distribution cannot factorized. indeed even computing stationary distribution given ctbn hard computational problem. contrast deﬁned model temporal dynamics gives rise natural interpretable form stationary distribution. property critical applications stationary distribution element understanding system. figure illustration training data. complete trajectory. x-axis denotes time y-axis denotes state time. filled circles denote transitions. trajectory annotated accepted rejected proposals marks x-axis denote index proposal. illustrate notation text denotes time interval i’th proposal denote actual state i’th proposal denote proposed state i’th proposal. posal took place time second time last entry vector time between last proposal observed time interval. second vector denotes actual state system proposal made. thus initial state system state ﬁrst proposal finally denotes sequence proposed states. clearly m’th proposal accepted rejected otherwise. denote event using indicators likelihood observations product probability density duration proposals probability accepting rejecting proposal. plugging factored form write likelihood compact form. consider problem learning parametrization ctmns data. thus assume given form features need learn parameters governing local rate matrices govern proposal rates variable. start considering problem context complete data observations consist full trajectories system. show deﬁne gradient ascent procedure learning parameters data. result also enables learn incomplete data using standard procedure. namely existing ctbns inference algorithms perform e-step effectively learning partially observable data compute expected sufﬁcient statistics. m-step application learning procedure complete data expected sufﬁcient statistics. combination quite standard follows lines similar procedure ctbns therefore expand here. assume data complete thus observations consist trajectory system described sequence intervals interval system state. using relationship ctbns results nodelman write probability data function sufﬁcient statistics entries conditional rate matrices problem approach entries conditional rate matrix involve parameters parameters thus resulting likelihood function couples estimation sets parameters. however additional information could decouple sets parameters. suppose observe actual trajectories also rejected proposals; figure additional information estimate rate different proposals independently whether accepted not. similarly estimate equilibrium distribution accepted rejected proposals. thus going view learning problem partial data problem annotation rejected proposals missing data. formalize ideas assume evidence trajectory annotated proposal attempts. describe trajectory using three vectors; figure ﬁrst vector represents time intervals consecutive proposals. thus ﬁrst proabsence analytical solution equation learn parameters using gradient-based optimization procedure maximum likelihood. derivation gradient standard exercise; completeness provide details appendix. using flogistic guaranteed procedure ﬁnds unique global maximum. completing data derivation likelihood associated optimization procedure relies assumption rejected transition attempts also observed data. form likelihood failures play important role estimating parameters. question adapt procedure case rejected proposals observed. solution problem expectation maximization view proposal attempts unobserved variables. approach start initial guess model parameters. estimate expected number rejected proposals; treat expected counts though real maximize likelihood using procedure described previous section. repeat iterations convergence. that case e-step fairly straightforward. harder step m-step requires iterative gradient-based optimization procedure. summarize procedure learn complete data perform following steps ﬁrst collect sufﬁcient statistics initialize model parameters iterate steps convergence e-step complete sufﬁcient statistics expected number rejected attempts m-step perform maximum likelihood estimation using expected sufﬁcient statistics using gradient descent gradient maximizing likelihood function maximum likelihood principle estimated parameters ones maximize likelihood function given observations. examine maximize likelihood. decoupling likelihood several terms allows estimate parameters separately. finding maximum likelihood parameters somewhat involved. note likelihood quite different likelihood log-linear distribution given i.i.d. data probability acceptance rejection involves ratios probabilities. therefore partition function cancels appear likelihood. sense likelihood closely related pseudo-likelihood log-linear models recall pseudo-likelihood technique estimating parameters markov network uses different objective function. rather optimizing joint likelihood optimizes conditional likelihood terms variable given neighbors. considering conditional probability variable given neighbors partition function cancels allowing parameters estimated without inference. large sample limit optimizing pseudolikelihood criterion equivalent optimizing joint likelihood results ﬁnite sample sizes tend worse. setting generative model deﬁned terms ratios only. thus case exact likelihood turns take form similar pseudo-likelihood criterion. pseudo-likelihood form allows figure comparison estimates equilibrium distribution ctmn learning procedure ctbn learning procedure markov network parameter learning procedure applied frequency time spent state x-axis denotes total length training trajectories y-axis denotes kl-divergence equilibrium distribution true model estimated model. curves report median performance among data sets error bars report percentiles. report performance learning true structure data generated report results learning parameters structure without edges equilibrium distribution. uniform trajectory length time units. uniform trajectory length time units. goal experiments test ability ctmn learning procedure estimate stationary distributions data various conditions. benchmark compared procedure alternative methods procedure estimates stationary distribution directly frequency visiting state. procedure essentially standard parameter learning method markov networks weight state proportional duration process spends state. procedure uses gradient ascent maximize likelihood process sampling stationary distribution relative time state proportional stationary probability situations expect procedure perform well. examined three procedures three sets synthetic trajectories. ﬁrst generated sampling initial state trajectory stationary distribution sampling states durations target model. data system equilibrium throughout trajectory. second data generated sampling initial state uniform distribution system starts distribution equilibrium. however trajectory long enough system equilibrate. third data similar second except trajectories shorter thus sufﬁcient time equilibrate. evaluate effect training size repeated learning experiments different numbers trajectories. report size training terms total length training trajectories. time reported units expected transition number. time unit equal average time transitions process equilibrium. short long trajectories experiments length expected transitions respectively. measured kullback-leibler divergences true stationary distribution estimated ones. figures show results experiments. sampling stationary distribution three procedures tend data size increases toward correct distribution. small data size performance ctmn learning procedure consistently superior although error bars partially overlap. start seeing difference estimation procedures modify initial distribution. expected markov network learning procedure suffers since learning biased sample. hand performance ctmn ctbn learning procedures virtually unchanged even modify length trajectories. results illustrate ability ctmn ctbn learning procedures robustly estimate equilibrium distribution dynamics even sampled process equilibrium. test robustness network structure also tested performance procedures estimating using wrong structure. figures three procedures converge wrong distribution relative behavior remains similar previous experiment performance ctmn learning procedure still affected nature data. paper deﬁne framework continuous time markov networks model dynamical system governed factors local transition model global acceptance/rejection model using markov network encode equilibrium distribution naturally deﬁne temporal process guaranteed equilibrium distribution particular factored form. showed reduction ctmns ctbns illustrates differences expressive powers formalisms. moreover reduction allows reason ctmns exploiting efﬁcient approximate inference algorithms ctbns. finally provided learning algorithms ctmns allow learn equilibrium distribution exploits understanding system dynamics. demonstrated learning procedure able robustly estimate equilibrium distribution even sampled process equilibrium. results combined learning partial observations plugging learning procedure m-step procedure ctbns work opens many interesting questions. goal learning models estimate stationary distribution. interesting analyze theoretically empirically beneﬁt gained task accounting process dynamics compared learning stationary distribution directly snapshots system moreover tackled problem parameter estimation models. many applications model structure unknown great interest. example models protein evolution want know pair positions protein directly correlated therefore likely structurally interacting. course tackling problem involves learning structure markov network notoriously difﬁcult task. perspective inference reduction ctbns lose much structure model. example stationary distribution pairwise markov network fact interaction model decomposes pairs variables lost induced ctbn. interesting whether construct inference algorithms better exploit structure. finally important limitation ctmn framework restriction exponential distribution duration proposed state changes. although model reasonable many systems settings restrictive. recent work nodelman show expand framework ctbns allow richer duration distributions. essentially solution introduces hidden state internal variable overall transition model variable actually aggregate multiple transitions internal state. similar solution applied setting resulting model would generally encode reversible ctmp. major potential ﬁeld application class models sequence evolution. current state phylogenetic inference based continuous time probabilistic models evolution virtually models assume sequence positions evolve independently models provide natural language modeling dependencies. domain proposal process corresponds mutation rates within sequence equilibrium distribution proportional relative ﬁtness different sequences. latter function course complex empirical evidence modeling pairwise interactions provide good approximation thus systems local mutation process factored equilibrium distribution appropriate making ctmns potentially valuable tool modeling analysis. hope incorporate formalism within phylogenetic inference tools develop methodology leverage models provide insights structure function proteins. felsenstein. inferring phylogenies. heckerman geiger chickering. learning bayesian networks combination knowledge statistical data. mach. learn. metropolis a.w. rosenbluth m.n. rosenbluth a.h. teller teller. equation state calculation fast computing machines. chem. phys. pfeffer dearden. continuous time particle compute derivative gradient loglikelihood speciﬁed proposition parameters appear within scope functions. thus derivatives differentiate functions respect parameters apply chain rule derivatives shows update weighted combination contribution proposed transition. weight transition depends sensitive ratio probabilities feature denoted number times transition accepted rejected captured empirical counts. addition proposal weighted captures improbability acceptance less probable larger change rejection acceptance probabilities respectively. smaller values probable acceptance results smaller gradient likelihood direction parameter. using fmetropolis functions symmetric", "year": 2012}