{"title": "Updating Formulas and Algorithms for Computing Entropy and Gini Index  from Time-Changing Data Streams", "tag": ["cs.AI", "cs.LG", "I.2.6"], "abstract": "Despite growing interest in data stream mining the most successful incremental learners, such as VFDT, still use periodic recomputation to update attribute information gains and Gini indices. This note provides simple incremental formulas and algorithms for computing entropy and Gini index from time-changing data streams.", "text": "despite growing interest data stream mining successful incremental learners still periodic recomputation update attribute information gains gini indices. note provides simple incremental formulas algorithms computing entropy gini index time-changing data streams. information-theoretic entropy introduced shannon celebrated paper since found vast number applications machine learning information gain deﬁned expected entropy reduction splitting leaf given attribute popular impurity measures decision tree learning. however within data stream mining world need computationally cheap update formulas alternative complete expensive recomputation compute entropy examples come changing sample distribution. concrete example scenario found incremental decision tree learners vfdt cvfdt holds gini index another popular impurity measure used decision tree if-then rule learning. theorems give simple update formulas gini index examples enter stream sample counts change respectively algorithms estimate current gini index data stream using formulas sliding windows fading factors theorems give simple update formulas entropy examples enter stream sample counts change algorithms estimate current entropy data stream sliding windows fading factors note organized follows. section derive incremental formulas gini index formulas sliding windows fading factors algorithms computing gini index time-changing data streams. section give analogous formulas entropy sliding windows fading factors algorithms estimating entropy time-changing data streams. conclude note section {xi}n sample positive real numbers sample elements. letting xi/sn discrete distribution. follows work samples positive real numbers interested computing gini index entropy computing gini index entropy distribution formed pi’s. data streams inherently changing usually interested recent gini index. section propose algorithms problem algorithm uses sliding windows algorithm uses fading factors capture recent gini index. algorithm computes gini index last stream elements. achieves using sliding window size meaning space complexity note user-deﬁned parameter indicates subset stream elements recent. algorithm computes recent gini index using fading factors element contributions weighted ﬁxed according element’s age. note fading factor deﬁnes recent means algorithm small constant space complexity. algorithm computing gini index using sliding windows. input sliding window size data stream output ready return gini index sliding window time. proof. idea think terms xi+ri sn+r elements apply theorem subtract sn+r note elements subtracting elements denominator—this subtracting updated entropy note number required operations grows linearly number changed elements elements change need operations. also note formulas become problematic small compared algorithm computing entropy using sliding windows. input sliding window size data stream output ready return entropy sliding window time. sliding window current entropy. number examples. number examples i-th class label. algorithm similarly algorithm deﬁnes recent using fading factors element contributions weighted according element age. algorithm small constant space complexity. derived simple incremental formulas algorithms computing entropy gini index time-changing data streams. derivations elementary easy implement. describe several uses cases formulas algorithms example avoiding recomputation learners vfdt cvfdt apply formulas decision-tree learners incorporate attribute values need prespeciﬁed etc. also thank marko robnik-ˇsikonja martin zoran bosni´c faculty computer information science university ljubljana useful comments suggestions blaˇz fortuna andrej muhiˇc rupnik marko grobelnik artiﬁcial intelligence laboratory joˇzef stefan institute. special thanks andrej muhiˇc pointing issues numerical stability.", "year": 2014}