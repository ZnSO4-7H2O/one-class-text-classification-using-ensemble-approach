{"title": "Multimodal Compact Bilinear Pooling for Visual Question Answering and  Visual Grounding", "tag": ["cs.CV", "cs.AI", "cs.CL"], "abstract": "Modeling textual or visual information with vector representations trained from large language or visual datasets has been successfully explored in recent years. However, tasks such as visual question answering require combining these vector representations with each other. Approaches to multimodal pooling include element-wise product or sum, as well as concatenation of the visual and textual representations. We hypothesize that these methods are not as expressive as an outer product of the visual and textual vectors. As the outer product is typically infeasible due to its high dimensionality, we instead propose utilizing Multimodal Compact Bilinear pooling (MCB) to efficiently and expressively combine multimodal features. We extensively evaluate MCB on the visual question answering and grounding tasks. We consistently show the benefit of MCB over ablations without MCB. For visual question answering, we present an architecture which uses MCB twice, once for predicting attention over spatial features and again to combine the attended representation with the question representation. This model outperforms the state-of-the-art on the Visual7W dataset and the VQA challenge.", "text": "modeling textual visual information vector representations trained large language visual datasets successfully explored recent years. however tasks visual question answering require combining vector representations other. approaches multimodal pooling include element-wise product well concatenation visual textual representations. hypothesize methods expressive outer product visual textual vectors. outer product typically infeasible high dimensionality instead propose utilizing multimodal compact bilinear pooling efﬁciently expressively combine multimodal features. extensively evaluate visual question answering grounding tasks. consistently show beneﬁt ablations without mcb. visual question answering present architecture uses twice predicting attention spatial features combine attended representation question representation. model outperforms state-of-the-art visualw dataset challenge. representation learning text images extensively studied recent years. recurrent neural networks often used represent sentences phrases convolutional neural networks shown work best represent images tasks visual question answering visual grounding approaches require joining representation modalities. combining vector representations current approaches grounding rely concatenating vectors applying element-wise product. generates joint representation might expressive enough fully capture complex associations different modalities. paper propose rely multimodal compact bilinear pooling joint representation. bilinear pooling computes outer product vectors allows contrast element-wise product multiplicative interaction elements vectors. bilinear pooling models recently shown beneﬁcial ﬁne-grained classiﬁcation vision tasks however given high dimensionality bilinear pooling widely used. paper adopt idea shows efﬁciently compress bilinear pooling single modality. work discuss extensively evaluate extension multimodal case text visual modalities. shown figure multimodal compact bilinear pooling approximated randomly projecting image text representations higher dimensional space convolving vectors efﬁciently using element-wise product fast fourier transform space. predict answers task locations visual grounding task. open-ended question answering present architecture uses twice predict spatial attention second time predict answer. multiple-choice question answering introduce third relate encoded answer question-image space. additionally discuss beneﬁt attention maps additional training data task. summarize evaluated tasks four datasets diverse ablations comparisons state-of-the-art. multimodal pooling. current approaches multimodal pooling involve element-wise operations vector concatenation. visual question answering domain number models proposed. simpler models ibowimg baseline concatenation fully connected layers combine image question modalities. stacked attention networks spatial memory networks lstms extract soft-attention image features ultimately element-wise product element-wise merge modalities. d-nmn introduced reinforce dynamically create network element-wise product join attentions element-wise predict answers. dynamic memory networks pool image question element-wise product attending part image question episodic memory module dppnet creates parameter prediction network learns predict parameters second last visual recognition layer dynamically question. similar work dppnet allows multiplicative interactions visual question encodings. recently proposed model extracts multiple co-attentions image question combines co-attentions hierarchical manner using element-wise concatenation fully connected layers. visual grounding task rohrbach propose approach language phrase embedding concatenated visual features order predict attention weights multiple bounding proposals. similarly concatenate phrase embeddings visual features different spatial locations obtain segmentation. bilinear pooling. bilinear pooling applied ﬁne-grained visual recognition task. cnns extract features image combine resulting vectors using outer product fully connected output layer. address space time complexity bilinear features viewing bilinear transformation polynomial kernel. pham pagh describe method approximate polynomial kernel using count sketches convolutions. joint multimodal embeddings. order model similarities modalities many prior works learned joint multimodal spaces embeddings. embeddings based canonical correlation analysis e.g. linear models ranking loss non-linear deep learning models multimodal compact bilinear pooling seen complementary operation allows capture different interactions modalities expressively e.g. concatenation. consequently many embedding learning approaches could beneﬁt incorporating interactions. way. however high dimensional representation leads infeasible number parameters learn example vqa. thus would billion parameters leads high memory consumption high computation times. thus need method projects outer product lower dimensional space also avoids computing outer product directly. suggested single modality rely count sketch projection function projects vector initialize vectors contains either index maps index input index output initialized randomly uniform distribution remain constant future invocations count sketch. initialized zero vector. every element destination index looked using added lines algorithm allows project outer product lower dimensional space reduces number parameters avoid computing outer product explicitly pham pagh showed count sketch outer product vectors expressed convolution count sketches parameters answers locations image embedding question embedding interested getting good joint representation pooling representations. multimodal pooling encodes relationship well becomes easier learn classiﬁer equation section ﬁrst discuss multimodal pooling combining representations different modalities single representation detail architectures visual grounding explaining predict given image representation text representation bilinear models take outer product vectors learn model i.e. denotes outer product denotes linearizing matrix vector. discussed introduction bilinear pooling interesting allows elements vectors interact multiplicative convolution operator. additionally convolution theorem states convolution time domain equivalent element-wise product frequency domain. convolution rewritten fft−) fft)) refers element-wise product. ideas summarized figure formalized algorithm based tensor sketch algorithm pham pagh invoke algorithm note easily extends remains efﬁcient multi-modal inputs combination happens element-wise product. architectures input model image question goal answer question. model extracts representations image question pools vectors using arrives answer treating problem multi-class classiﬁcation problem possible classes. extract image features using -layer residual network pretrained imagenet data images resized output layer -way classiﬁer. perform normalization vector. input questions ﬁrst tokenized words words one-hot encoded passed learned embedding layer. tanh nonlinearity used embedding. embedding layer followed -layer lstm units layer. outputs lstm layer concatenated form vector. vectors passed mcb. followed element-wise signed square-root normalization. pooling fully connected layer connects resulting multimodal representation answers. attention. incorporate spatial information soft attention pooling method. explored image captioning soft attention mechanism easily integrated model. spatial grid location visual representation last convolutional layer pooling merge slice visual feature language representation. depicted figure pooling convolutional layers predict attention weight grid location. apply softmax produce normalized soft attention map. take weighted spatial vectors using attention create attended visual representation. also experiment generating multiple attention maps allow model make multiple glimpses concatenated merged language representation another pooling prediction. predicting attention maps pooling allows model effectively learn attend salient locations based visual language representations. base approach proposed attention. seen figure deal multiple variable-length answer choices choice encoded using word embedding lstm layers whose weights shared across candidates. addition using attention additional pooling merge encoded answer choices multimodal representation original pipeline. resulting embedding projected classiﬁcation vector dimension equal number answers. base grounding approach fullysupervised version grounder overview model shown figure input model query natural language phrase image along multiple proposal bounding boxes. goal predict bounding corresponds query phrase. replace concatenation visual representation encoded phrase grounder combine modalities. contrast rohrbach include linear embedding visual representation normalization input modalities instead batch normalization found beneﬁcial using grounding task. datasets visual question answering real-image dataset consists approximately mscoco images questions image answers question. data splits train validation test additionally subset test named test-dev. accuracies ablation experiments paper reported test-dev data split. tool provided antol evaluation. conducted experiments openended real-image task. table also report multiple-choice real-image scores. visual genome dataset uses images intersection yfccm mscoco. image average question-answer pairs collected. million pairs question types compared dataset visual genome represents balanced distribution question types. moreover average question answer lengths visual genome larger dataset. leverage visual genome dataset additional training data remove unnecessary words answers decrease length answers extract pairs whose answers single-worded. extracted data ﬁltered based answer vocabulary space created dataset leaving additional image-qa triplets. element-wise concatenation concatenation concatenation element-wise product element-wise product element-wise product full bilinear element-wise product vgg- vgg- evaluate models telling task involves questions. natural language answers visualw multiple-choice format question comes four answer candidates correct answer. visualw composed images mscoco total pairs. adam solver dropout lstm layers fully connected layers. experiments table train train split validate validation split report results test-dev split. early stopping validation score improve iterations stop training evaluate best iteration test-dev. visualw task hyperparameters training settings experiments. splits train validate test models. also compute accuracies data using evaluation code. ablation results compare performance non-bilinear bilinear pooling methods table pooling outperforms non-bilinear pooling methods eltwise concatenation eltwise product. could argue compact bilinear method simply parameters non-bilinear pooling methods contributes performance. compensated stacking fully connected layers non-bilinear pooling methods increase number parameters. however even similar parameter budgets nonbilinear methods could achieve accuracy method. example concatenation pooling method approximately million parameters matches million parameters available however performance concatenation method compared mcb’s linear pooling impact accuracy compared full bilinear pooling. section table demonstrates brings improvements regardless image used. primarily resnet paper also improves performance vgg- used. section table shows soft attention model works best pooling. fact attending concatenation layer performance using attention attending layer improves performance points. table compares different values output dimensionality multimodal compact bilinear feature. approximating bilinear feature vector yields highest accuracy. erated attention maps reveals ensembling smoothing effect occurs using multiple maps. table presents results visualw multiplechoice task. attention model outperforms previous state-of-the-art points overall performs better almost every category. table compares approach state-of-theart test set. best single model uses pooling attention maps. additionally augment training data images pairs visual genome dataset. also concatenate learned word embedding pretrained glove vectors points next best approach open-ended task points next best approach multiple-choice task even without ensembles genome att. glove model still outperforms next best result points accuracy versus open-ended task datasets evaluate visual grounding approach datasets. ﬁrst flickrk entities consists images flickrk dataset phrases localized bounding boxes. follow experimental setup rohrbach e.g. selective search object proposals fast r-cnn ﬁne-tuned features second dataset referitgame contains images iapr dataset segmented regions saiapr- dataset associated natural language referring expressions. referitgame follow experimental setup rely ground-truth bounding boxes extracted around segmentation masks. edge object proposals visual features experiments adam solver learning rate embedding size visual language embeddings. pooling found work best visual grounding task. accuracy measured percentage query phrases localized correctly. phrase localized correctly predicted bounding overlaps ground-truth bounding intersection union tables summarize results visual grounding task. present multiple ablations proposed architecture. first replace simple concatenation embedded visual feature embedded phrase resulting flickrk entities referitgame datasets. results improved replacing concatenation element-wise product embedded features slightly increase performance introducing additional convolution element-wise product however even fewer parameters pooling signiﬁcantly improves baseline datasets reaching state-of-the-art accuracy flickrk entities referitgame dataset. figure shows examples improved phrase localization. propose multimodal compact bilinear pooling combine visual text representations. visual question answering architecture attention multiple mcbs gives signiﬁcant improvements datasets compared state-of-the-art. visual grounding task introducing pooling leads improved phrase localization accuracy indicating better interaction query phrase representations visual repwould like thank yang oscar beijbom helpful discussions compact bilinear pooling. work supported darpa afrl muri award awards iis- iis- berkeley artiﬁcial intelligence research lab.", "year": 2016}