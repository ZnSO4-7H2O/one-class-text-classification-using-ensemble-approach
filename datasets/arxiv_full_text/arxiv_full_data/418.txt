{"title": "ZM-Net: Real-time Zero-shot Image Manipulation Network", "tag": ["cs.CV", "cs.AI", "cs.GR", "cs.LG", "stat.ML"], "abstract": "Many problems in image processing and computer vision (e.g. colorization, style transfer) can be posed as 'manipulating' an input image into a corresponding output image given a user-specified guiding signal. A holy-grail solution towards generic image manipulation should be able to efficiently alter an input image with any personalized signals (even signals unseen during training), such as diverse paintings and arbitrary descriptive attributes. However, existing methods are either inefficient to simultaneously process multiple signals (let alone generalize to unseen signals), or unable to handle signals from other modalities. In this paper, we make the first attempt to address the zero-shot image manipulation task. We cast this problem as manipulating an input image according to a parametric model whose key parameters can be conditionally generated from any guiding signal (even unseen ones). To this end, we propose the Zero-shot Manipulation Net (ZM-Net), a fully-differentiable architecture that jointly optimizes an image-transformation network (TNet) and a parameter network (PNet). The PNet learns to generate key transformation parameters for the TNet given any guiding signal while the TNet performs fast zero-shot image manipulation according to both signal-dependent parameters from the PNet and signal-invariant parameters from the TNet itself. Extensive experiments show that our ZM-Net can perform high-quality image manipulation conditioned on different forms of guiding signals (e.g. style images and attributes) in real-time (tens of milliseconds per image) even for unseen signals. Moreover, a large-scale style dataset with over 20,000 style images is also constructed to promote further research.", "text": "figure example results zero-shot image manipulation network manipulate images guided personalized signals real-time. zero-shot style transfer guided different landscape paintings image manipulation conditioned descriptive attributes; left right descriptive attributes input image transformed images corresponding text ‘noon’ ‘afternoon’ ‘morning’ .‘morning’ .‘night’ ‘night’ respectively. many problems image processing computer vision posed manipulating input image corresponding output image given user-speciﬁed guiding signal. holy-grail solution towards generic image manipulation able efﬁciently alter input image personalized signals diverse paintings arbitrary descriptive attributes. however existing methods either inefﬁcient simultaneously process multiple signals unable handle signals modalities. paper make ﬁrst attempt address zero-shot image manipulation task. cast problem manipulating input image according parametric model whose parameters conditionally generated guiding signal propose zero-shot manipulation fully-differentiable architecture jointly optimizes image-transformation network parameter network pnet learns generate transformation parameters tnet given guiding signal tnet performs fast zero-shot image manipulation according signal-dependent parameters pnet signal-invariant parameters tnet itself. extensive experiments show zm-net perform highquality image manipulation conditioned different forms guiding signals realtime even unseen signals. moreover large-scale style dataset style images also constructed promote research. image manipulation aims manipulate input image based personalized guiding signals expressed diverse modalities recently attracted ever-growing research interest derived various real-world applications attributedriven image editing artistic style transfer image manipulation model usually deployed various devices ranging desktop mobile phone. solution applicable argue must meet three requirements ﬁrst model zero-shot immediately capture intrinsic manipulation principles conveyed guiding signal apply target image without retraining distinct models every user input. further support downstream mobile applications inference process target image really efﬁcient user immediately obtain desired output without waiting seconds minutes. third personalized guiding signal usually comes different forms could either artistic style conveyed painting descriptive phrases typed user even speech instruction therefore preferable model possesses capability receiving arbitrary guiding signal multiple modalities. variety relevant approaches developed towards goal real-time zero-shot image manipulation. existing approaches mainly focus training transformation neural networks corresponds small guiding signals paintings. among them cnn-based methods process images real-time however networks tied speciﬁc guiding signal cannot generalize unseen types speciﬁed users unless retraining many networks number guiding signals computationally time prohibitive. although recent approaches encode multiple styles within single network fail perform zero-shot style transfer cannot process guiding signals either real-time distinct modalities paper make ﬁrst attempt explore real-time zero-shot image manipulation task best knowledge. task challenging since model able exploit transform diverse complex patterns arbitrary guiding signals transformation parameters perform image manipulation real-time. propose novel zero-shot manipulation combines parameter network image-transformation network end-to-end framework. pnet generic model produce hierarchy transformation parameters tnet takes generated parameters combines signalinvariant parameters generate image. sense image style transfer pnet embed style image hierarchical parameters used tnet transform content image stylized image. show zm-net digest style images single network rather training network style previous methods did. also trained process guiding signals forms descriptive attributes. moreover ability fast zero-shot manipulation proposed zm-net generate animation single image real-time even though model trained images rather videos. summary main contributions follows best knowledge ﬁrst scalable solution real-time zero-shot image manipulation task proposed zm-net able digest style images single model perform zero-shot style transfer real-time. interestingly even zero-shot setting zm-net still generate images quality comparable previous methods need retrain models style images. zm-net handle general image manipulation tasks different forms guiding signals using small seed style images construct much larger dataset style images much content diversity. experiments show training dataset dramatically decrease testing loss nearly half. related work research efforts devoted image manipulation task among common efﬁcient approach train convolutional neural network directly outputs transformed image input content image example trained perform colorization input images transform content images according speciﬁc styles. although recent method process images real-time train single network speciﬁc type manipulation cannot generalize types manipulation unless retraining model every type usually takes several hours prevents scaled real-world applications. relevant works tries encode multiple styles within single network; however model focuses increasing diversity output images still unable handle diverse unseen guiding signals distinct modalities hand iterative approaches proposed manipulate image either patch patch iteratively updating input image hundreds reﬁnement obtain transformed image. although methods require additional training guiding signal iterative evaluation process usually takes tens seconds even acceleration might impractical especially online users. real-time zero-shot image manipulation -layer network pretrained imagenet transformation network learned given training content images style image. although performing image manipulation single feedforward pass usually three orders magnitude faster optimization-based methods approach largely restricted single transformation network tied speciﬁc style image meaning separate networks trained enable transfer style images. disadvantages obvious timeconsuming train separate networks; needs much memory store networks impractical mobile devices; scalable cannot generalize styles zm-net address aforementioned problems enable image manipulation propose real-time zero-shot general architecture zm-net combines imagetransformation network parameter network different prior works adopt tnet transform images train extra parameter network produce parameters tnet conditioned guiding signals parameters generated given arbitrary guiding signals zm-net avoids training storing many different network parameters distinct signals like prior works. moreover pnet learns embed guiding signal shared space zm-net able perform zero-shot image manipulation given unseen guiding signals. generalize notion style images guiding signals i.e. input guiding signals beyond style images example word embeddings express descriptive attributes order impose speciﬁc semantics input image color histograms guide colorization following ﬁrst present design tnet proposed dynamic instance normalization based introduce pnet variants including serial pnet parallel pnet. tnet dynamic instance normalization enable zero-shot image manipulation must design principled dynamically specify network parameters tnet testing handle unseen signals. naive would directly generate ﬁlters tnet based feature maps pnet conditioning guiding signal however practice layer tnet typically parameters feature maps layer pnet usually entries thus difﬁcult efﬁciently transform high dimensional figure image transformation network ﬁxed loss network described style transfer task guiding signal style image. note transformation network works style. itations zero-shot setting. then present zeroshot manipulation network uniﬁed network structure jointly optimizes parameter network image-transformation network image manipulation cnns image manipulation task formally deﬁned given content image rh×w× guiding signal rh×w× output transformed image rh×w× similar content simultaneously similar style. learning effective representations content styles hence equally essential perform plausible image manipulation. using ﬁxed deep feature maps rcl×hl×wl layer represent content image gram matrix denoted rcl×cl computed express desired style patterns image images assessed similar content style difference corresponding representation small frobenius norm. therefore train feedforward image transformation network typically deep loss function style loss generated image content loss hyperparameters. style layers content layers total number neurons layer transformation network trained given content image generate stylized image without using loss network. figure shows overview model. note computation deﬁned ﬁxed loss network resort dynamically augmenting instance normalization produced scaling shifting parameters pnet. scaling shifting factors treated parameters layer tnet. formally rcl×hl×wl tensor instance normalization. xijk denotes ijk-th element indexes feature maps span spatial dimensions. output rcl×hl×wl dynamic instance normalization thus computed serial pnet. serial pnet deep structure similar tnet generate layer figure shows overview serial architecture. serial pnet equation conditioned feature maps denoted layer pnet. speciﬁcally note equation yijk different share design signiﬁcantly reduces number parameters increases generalization model. interestingly replace βijk computed output convolutional layer input followed vanilla instance normalization equation equivalent concatenating followed convolutional layer vanilla instance normalization used preliminary experiments show although structures similar sufﬁcient model capacity perform image manipulation given guiding signals training generalizes poorly unseen guiding signals cannot used zero-shot image manipulation. parallel pnet. alternatively separate shallow networks generate layer used compute according equation figure shows architecture parallel pnet. different serial pnet higher levels generated higher levels transformation corresponding variance. i-th element ci-dimensional vector generated pnet similarly degenerates vanilla instance normalization become directly learnable parameters irrelevant pnet. degenerates conditional instance normalization cases model loses ability zero-shot learning therefore cannot generalize unseen signals. pnet aims generate multilayer perceptron even recurrent neural network pnet section demonstrate generality proposed zm-net. since content images guiding signals inherently different input pair image manipulation non-exchangeable making problem much difﬁcult typical problems image matching exchangeable input image pair. nonexchangeability connection tnet pnet asymmetric. figure results -style zm-net. column content image column randomly selected training style images corresponding generated images. follows shallow parallel structure. experiments show design would limit effectiveness pnet slightly decrease quality generated tnet consequently generated images therefore section serial pnet unless otherwise speciﬁed. table comparison optimization-based style transfer fast style transfer zm-net. note zm-net’s time cost image ﬁrst time processes style drops that. training test. zm-net trained end-toend manner supervision loss network shown figure testing phase content image guiding signal tnet pnet respectively generating transformed image note loss network irrelevant testing. section ﬁrst demonstrate zm-net’s capacity digesting style images single network followed experiments showing model’s ability zero-shot learning image manipulation tasks another experiments also using simpliﬁed word embeddings expressing descriptive attributes rather style images guiding signals embed speciﬁc semantics content images. show ability zero-shot learning fast image manipulation model generate animation single image real-time even though model image-based. shown table current methods fast style transfer need train different networks different styles costing much time memory. besides also impossible methods generalize unseen styles hand although original optimization-based style transfer method capable zero-shot transfer several orders magnitude slower generating stylized images. zm-net able best worlds performing fast zero-shot style transfer. datasets. ms-coco dataset content images. order zm-net generalize well unseen styles style images training need sufﬁcient diversity prevent model overﬁtting styles. unfortunately unlike photos massively produced work paintings rare difﬁcult collect. address problem impressionism paintings dataset pandora seed style images produce larger dataset style images. speciﬁcally ﬁrst split images training images validation images testing images. randomly select content image impressionism painting three sets input producing style image similar style different content. note different traditional dataset expansion expansion process introduce much content diversity dataset hence prevent training process overﬁtting content style images. experiments show using expanded dataset rather original testing loss nearly half experimental settings. baselines fast style transfer network structures hyperparameters mentioned papers. zm-net follow network structure tnet pnet except part connecting din. serial pnet style transfer task. vgg- loss network content style layers. models trained minibatch size iterations using adam exception train -style zm-net iterations initial learning rate decay every iterations. model capacity. show zm-net enough model capacity digest multiple styles single network train zm-net style images evaluate ability stylize content images style images training set. figure shows results -style zm-net note need train different networks different style images zm-net simultaneously trained multiple styles single network. zm-net achieve comparable performance single network. similarly figure shows results -style zm-net. surprisingly zm-net problem digesting many network either. quantitatively ﬁnal training loss -style zm-net close demonstrates zm-net’s sufﬁcient model capacity. generalization content images also style images. since second level involves style transfer style images unseen training call zero-shot style transfer. figure shows results fast zero-shot style transfer using -style zm-net -style zm-net -style zm-net severely overﬁts style images training generalizes poorly unseen styles. -style zm-net help enough diversity training style images perform satisfactory style transfer even unseen styles models like tied speciﬁc styles fail generalize unseen styles. note tnet pnet zm-net layers pnet connects tnet ﬁrst layers operations equation investigate function different layers turn operations layers perform zero-shot style transfer using zmnet. shown figure layer focuses generating content details layer focuses roughly adjusting colors layer focuses transfer texture-related features. proposes share convolutional layers across different styles ﬁnetune scaling/shifting factors instance normalization style. figure shows style transfer unseen style image ﬁnetuning zm-net iterations. ability zero-shot learning zmnet perform much better even without ﬁnetuning style. figure shows training testing loss training ﬁnetuning ﬁnetuning zm-net. conclude that ﬁnetuning much lower initial training/testing loss ﬁnetuning zm-net even better; zmnet converges faster lower training/testing loss. besides style transfer uses style images guiding signals also zm-net word embeddings input embed speciﬁc semantics images. example taking word embedding word ‘night’ transform photo taken daytime photo night view. setting train zm-net words ‘noon’ ‘night’ successful zero-shot manipulation would take word embeding ‘morning’ ‘afternoon’ transform content image taken noon image taken morning afternoon perform tasks design zm-net deep figure zero-shot style transfer using -style zm-net layers turned column style image. column content images. column layers off. column layer respectively. column layers figure training loss iterations training loss ﬁrst iterations testing loss iterations zm-net. testing loss computed every iterations. convolutional tnet identical used style transfer deep fully connected pnet residual connections facilitate analysis avoid overﬁtting compressed pretrained -dimensional word embeddings -dimensional vectors. ‘night’ training images. note different zm-net style transfer style image used input pnet input ﬁxed loss network word embeddings input pnet corresponding ‘noon/night’ images input loss network. iteration randomly select word embeddings ‘noon’ ‘night’ input guiding signal corresponding image feed loss network. different style transfer even input guiding signal different ‘noon/night’ images loss network. case zm-net actually extracting common patterns/semantics ‘noon’ ‘night’ images instead simply learning perform style transfer. figure column content image style image. column style transfer unseen style image ﬁnetuning zm-net iterations. model ﬁrst trained another style image ﬁnetuning. figure zero-shot image manipulation word embeddings guiding signals compared simply changing image illumination shows images corresponding compressed word embeddings ‘noon’ .‘noon’ .‘afternoon’ ‘afternoon’ ‘morning’ .‘morning’ .‘night’ ‘night’ serial pnet used. shows results parallel pnet used. column shows content image compressed word embeddings. tion serial pnet zm-net. train model word embeddings ‘noon’ ‘night’ word embeddings ‘morning’ ‘afternoon’ guiding signals testing. transformed images gradually change daytime views nighttime views ‘morning/afternoon views’ between. note zm-net’s ability fast zero-shot manipulation generate animation single image real-time even though model image-based baseline figure shows results simple illumination change. zm-net automatically transfer lighting effect content image simple illumination fails besides serial pnet also perform task parallel pnet report results figure comparing results using serial pnet parallel pnet produces much redundant yellow pixels surrounding buildings reasonable daytime photo. comparison shows serial pnet deep structure tends perform higher-quality image manipulation parallel pnet. paper present zm-net general network architecture dynamic instance normalization perform real-time zero-shot image manipulation. experiments show zm-net produces high-quality transformed images different modalities guiding signals generalize unseen guiding signals. zm-net even produce real-time animation single image even though model trained images. besides construct largest dataset style images provide much content diversity reduce testing loss nearly half.", "year": 2017}