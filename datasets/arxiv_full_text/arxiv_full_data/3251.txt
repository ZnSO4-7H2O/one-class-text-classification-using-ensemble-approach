{"title": "Near-separable Non-negative Matrix Factorization with $\\ell_1$- and  Bregman Loss Functions", "tag": ["stat.ML", "cs.CV", "cs.LG"], "abstract": "Recently, a family of tractable NMF algorithms have been proposed under the assumption that the data matrix satisfies a separability condition Donoho & Stodden (2003); Arora et al. (2012). Geometrically, this condition reformulates the NMF problem as that of finding the extreme rays of the conical hull of a finite set of vectors. In this paper, we develop several extensions of the conical hull procedures of Kumar et al. (2013) for robust ($\\ell_1$) approximations and Bregman divergences. Our methods inherit all the advantages of Kumar et al. (2013) including scalability and noise-tolerance. We show that on foreground-background separation problems in computer vision, robust near-separable NMFs match the performance of Robust PCA, considered state of the art on these problems, with an order of magnitude faster training time. We also demonstrate applications in exemplar selection settings.", "text": "recently family tractable algorithms proposed assumption data matrix satisﬁes separability condition donoho stodden arora geometrically condition reformulates problem ﬁnding extreme rays conical hull ﬁnite vectors. paper develop several extensions conical hull procedures kumar robust approximations bregman divergences. methods inherit advantages kumar including scalability noise-tolerance. show foreground-background separation problems computer vision robust near-separable nmfs match performance robust considered state problems order magnitude faster training time. also demonstrate applications exemplar selection settings. matrix factorization inner-dimension factorization usually taken much smaller interpretable part-based representation data seung used wide range applications e.g. topic modeling text mining hyper-spectral image analysis audio source separation microarray data analysis cichocki exact approximate problem np-hard. hence traditionally algorithmic work focused treating instance non-convex optimization cichocki seung hsieh dhillon leading algorithms lacking optimality guarantees beyond convergence stationary point. promising alternative approaches emerged recently based separability assumption data arora bittorf gillis vavasis kumar esser enables problem solved eﬃciently exactly. assumption data matrix said r-separable columns contained conical hull generated subset columns words admits factorization separability assumption states columns present positions given unknown index separability assumption ﬁrst investigated donoho stodden context deriving conditions uniqueness nmf. separability assumption studied topic modeling text kumar arora hyper-spectral imaging gillis vavasis esser separability turned reasonable assumption applications. context topic modeling document-word matrix document-topic topic-word associations respectively translates assuming least word every topic unique present topics. duced kumar near-separable problems frobenius norm loss. xray ﬁnds anchor columns other incrementally expanding cone using exterior columns locate next anchor. xray several appealing features requires iterations parallelizable empirically demonstrates noise-tolerance admits eﬃcient model selection require normalizations preprocessing needed methods. however presence outliers diﬀerent noise characteristics frobenius norm approximations optimal. paper extend xray provide robust factorizations respect loss approximations respect family bregman divergences. figure shows motivating application computer vision. given sequence video frames goal separate nearstationary background foreground moving objects relatively dynamic across frames span pixels. setting natural seek low-rank background imposes sparsity prior residual foreground. unlike case low-rank approximations frobenius spectral norms problem admit svd-like tractable solution. robust principal component analysis considered state application uses nuclear-norm convex relaxation low-rank constraints. paper instead recover tractability imposing separable assumption background matrix. implies variability pixels across frames explained terms observed variability small anchor pixels. restrictive setting shown equivalent median ﬁltering video frames full near-separable model imparts degrees freedom model background. show proposed near-separable algorithms loss competitive rpca separating foreground background outperforming terms computational eﬃciency. algorithms empirically shown robust noise addition background-foreground problem also demonstrate algorithms exemplar selection problem. identifying exemplars data proposed related work existing separable methods work either limited number loss functions factorization error frobenius norm loss kumar norm loss bittorf maximize proxy criteria volume convex polyhedron anchor columns vertices gillis vavasis distance successive anchors arora select anchor columns. hand local search based methods cichocki proposed wide variety loss functions factorization error including norm loss guan park instances bregman divergence dhillon paper close propose algorithms near-separable minimize loss bregman divergence factorization. goal exact matrix cone generated columns contains columns separability assumption columns matrix picked directly also known anchor columns. algorithms paper build cone incrementally picking column every iteration. algorithms execute iterations constructing factorization inner-dimension figure shows cone three iterations algorithm three anchor columns extreme cannot expressed conic combinations points cone extreme ray. identify next anchor column algorithm picks point outside current cone projects current cone distance point projection minimized terms desired measure distance. projection used setup speciﬁc simple criteria maximized data points identiﬁes anchor. anchor added current anchors cone expanded iteratively anchors picked. geometric intuitions inspired clarkson dula present linear programming based algorithms general convex conical hull problems. algorithms projections exterior points current cone also applicable setting data matrix satisﬁes r-separability exactly. case projection corresponding residual vector single exterior point used expand cone anchors recovered correctly algorithm. satisfy rseparability exactly anchor selection criteria derived multiple residuals demonstrate superior noise robustness empirically shown kumar consider case gaussian i.i.d. noise. however algorithms kumar suitable noise distributions gaussian minimize following sections present algorithms near-separable targeted precisely towards goal empirically demonstrate superiority existing algorithms diﬀerent noise distributions. hence minimize xahk denotes element-wise norm matrix columns indexed denote column proposed algorithm proceeds identifying anchor column iteration adding current anchors thus expanding cone generated anchors. iteration consists steps anchor selection step ﬁnds column added anchor projection step data points projected current cone terms minimizing norm. algorithm outlines steps proposed algorithm. selection criterion algorithm shows possibilities choosing exterior point. taking point maximum residual norm exterior point turns robust noise randomly choosing exterior point observed numerical simulations. projection step projection step involves solving multivariate least absolute devitations problems non-negativity constraints. alternating direction method multipliers boyd reformulate problem thus non-negativity constraints decoupled objective admm optimization proceeds alternating sub-problems standard penalized proximity problem variable closed form solution using soft-thresholding operator non-negative least squares problem variable solved using cyclic coordinate descent approach standard primal dual residuals based criteria used declare convergence boyd admm procedure converges global optimum since problem convex. proof. residuals given minb≥kx xabk. forming lagrangian xabk matrix sub-diﬀerential given lemma point exterior current cone exists least satisﬁes previous lemma proof. minb≥kx xabk current anchors. proof previous lemma hence complementary slackness condition λjihji hence since conditions optimum least satisﬁes previous lemma lemma lemma hold true. give method using linear programming. using conditions candidate. know represent elements need i.e. finding feasibility problem solved using since multiple feasible points choose dummy cost function implementation simply which practice almost always satisﬁes lemma generate extreme rays data cone. hence added anchor maximum occurs points anchors others conic combinations anchors. identify anchors subset points calling algorithm recursively. algorithm vector needs satisfy implementation simply used small perturbation vector entries i.i.d. according uniform distribution done avoid possibility collinear strictly convex function domain diﬀerentiable nonempty relative interior bregman divergence deﬁned continuous ﬁrst derivative also assume smooth true bregman divergences interest. bregman divergence form =pij nential family distribution parameters satisfying separability assumption i.e. rr×n rm×r every member distribution exponential family unique bregman divergence associated banerjee solving miny equivalent maximum likelihood estimation parameters distribution hence projection step algorithm changed minb≥ coordinate descent based method solve projection step. select anchor columns bregman projections modify selection criteria wise product vectors. show following result regarding anchor selection property criteria. recall anchor column expressed conic combination columns proof provided appendix. again exterior point chosen select next anchor simulations show taking exterior point maxk gives much better performance noise randomly choosing exterior point. note bregman divergence induced function selection criteria reduces selection criteria xray proposed kumar since bregman divergence generally symmetric also possible projection step minb≥ case selection criteria change point exterior current cone operj⋆ maxj ates element-wise vector however variant meaningful probabilistic interpretation discussed earlier. section present experiments synthetic real datasets demonstrate eﬀectiveness proposed algorithms noisy conditions. addition comparing algorithms existing separable methods bittorf gillis vavasis kumar figure left anchor recovery rate versus noise level sparse noise case right anchor recovery rate versus mean parameter data matrix generated exponential distribution noise matrix i.e. entry matrix i.i.d. outperforms methods including xray-ℓ huge margin noise level increases. highlights importance using right loss function projection step suitable noise model rr×n family distribution gaussian i.e. rm×r mentioned earlier every member distribution exponential family unique bregman divergence associated hence minimize corresponding bregman divergence projection step algorithm discussed section recover anchor columns. commonly used bregman divergences generalized kl-divergence itakura-saito divergence dhillon banerjee f´evotte correspond poisson exponential distributions respectively. report results generalized kldivergence since informative highlighting diﬀerences among various algorithms considered. reason poisson distribution parameter mean std. dev. increasing noise actually increases signal noise ratio. hence anchor recovery gets better increasing almost algorithms perform well xray-kl full range. anchor recovery results is-divergence shown fig. entries data matrix generated matrices generated described previous paragraph. parameter varied steps report average runs value xray-is algorithm signiﬁcantly outperforms methods including xray-ℓ kumar correctly recovering anchor column indices. recovery rate change much increasing since exponential distribution mean parameter std. dev. signal-to-noise ratio practically stays almost varying problem exemplar selection concerned ﬁnding representatives dataset summarize dataset well. exemplar selection used many applications including summarizing video sequence selecting representative images text documents collection etc. denotes data matrix column data point exemplar selection problem translates selecting columns representatives columns. separable algorithms used task working assumption data points expressed non-negative linear combinations exemplars able compare quality selected exemplars diﬀerent algorithms objective manner test classiﬁcation task randomly partition data training test sets training selecting exemplars. train multiclass classiﬁer selected exemplars look accuracy held-out test set. accuracy classiﬁer trained full training taken benchmark also reported. also compare elhamifar recently proposed method exemplar selection named sparse modeling representative selection assume data points expressed convex linear combination exemplars minimize selected exemplars. code provided authors smrs. multiple possibilities anchor selection criteria proposed robustxray xray-ℓ kumar criterion algorithms. report results text datasets reuters reuters greene cunningham subset reuters data corresponding frequent classes data consists datasets evenly split documents training test select exemplars training using various algorithms. fig. fig. show plot accuracy test number selected exemplars used training classiﬁer. number selected anchors varied steps accuracy using full training also shown reuters data proposed robustxray algorithm outperforms methods signiﬁcant margin whole range selected anchors. methods seem perform comparably data. advantage xray family methods need cleaning step remove near-duplicate exemplars needed smrs elhamifar another advantage computational speed experiments xray methods times faster smrs. remarkable even number selected exemplars give reasonable classiﬁcation accuracy methods smrs gives accuracy reuters data using exemplars robustxray gives figure foreground-background separation curves various methods restaurant airport hall lobby video sequences. ranges axes chosen better highlight diﬀerences among curves. section consider problem foreground-background separation video. camera position assumed almost ﬁxed throughout video. video frames camera captures background scene superimposed limited foreground activity background assumed stationary slowly varying across frames foreground assumed composed objects move across frames span pixels. vectorize video frames stack rows form matrix foreground-background separation problem modeled decomposing low-rank matrix sparse matrix connection median filtering median ﬁltering commonly used background modeling techniques sen-ching kamath simply models background pixel-wise median video frames. assumption pixel location stays background half video frames. consider innerelement-wise median vector. hence robust restrictive setting equivalent median ﬁltering video frames hope loosening assumption allowing higher inner-dimension factorization help modeling variations background. three video sequences evaluation restaurant airport hall lobby restaurant airport hall videos taken buﬀet restaurant hall airport respectively. lighting distributed ceilings signicant shadows moving persons cast ground surfaces diﬀerent directions observed videos. lobby video sequence captured lobby oﬃce building background changes lights switched on/oﬀ. ground truth also available video sequences generate curves. mainly compare robustxray robust widely considered state methodology task computer vision community. addition also compare using local search. admm based optimization procedure local-search methods. also show results xray-ℓ kumar highlight importance near-separable nmfs loss problem. xray-ℓ robustxray reﬁtting steps reﬁne solution methods grid search parameters perform almost similarly. airport hall data robustxray tied local-search based robust better methods. surprisingly xray-ℓ performs better local-search based robust low-rank might initialization. lobby data local-search based robust low-rank robust robustxray perform almost similarly better local-search based robust nmf. results three datasets show robustxray promising method problem foreground-background separation huge advantage robust terms speed. matlab implementation least times faster inexact augmented lagrange multiplier implementation proposed generalized conical hull algorithms extend near-separable nmfs robust loss function bregman divergences. empirical results exemplar selection video background-foreground modeling problems suggest promising methodology. avenues future work include formal theoretical analysis noise robustness applications online settings.", "year": 2013}