{"title": "Explanations based on the Missing: Towards Contrastive Explanations with  Pertinent Negatives", "tag": ["cs.AI", "cs.CV", "cs.LG"], "abstract": "In this paper we propose a novel method that provides contrastive explanations justifying the classification of an input by a black box classifier such as a deep neural network. Given an input we find what should be minimally and sufficiently present (viz. important object pixels in an image) to justify its classification and analogously what should be minimally and necessarily \\emph{absent} (viz. certain background pixels). We argue that such explanations are natural for humans and are used commonly in domains such as health care and criminology. What is minimally but critically \\emph{absent} is an important part of an explanation, which to the best of our knowledge, has not been touched upon by current explanation methods that attempt to explain predictions of neural networks. We validate our approach on three real datasets obtained from diverse domains; namely, a handwritten digits dataset MNIST, a large procurement fraud dataset and an fMRI brain imaging dataset. In all three cases, we witness the power of our approach in generating precise explanations that are also easy for human experts to understand and evaluate.", "text": "paper propose novel method provides contrastive explanations justifying classiﬁcation input black classiﬁer deep neural network. given input minimally suﬃciently present justify classiﬁcation analogously minimally necessarily absent argue explanations natural humans used commonly domains health care criminology. minimally critically absent important part explanation best knowledge touched upon current explanation methods attempt explain predictions neural networks. validate approach three real datasets obtained diverse domains; namely handwritten digits dataset mnist large procurement fraud dataset fmri brain imaging dataset. three cases witness power approach generating precise explanations also easy human experts understand evaluate. steve tall long hair wear glasses. explanations used frequently people identify people items interest. case characteristics tall long hair help describe person although incompletely. absence glasses important complete identiﬁcation help distinguish from instance tall long hair wears glasses. common humans state contrastive facts want accurately explain something. implies equal contribution. indicate aﬃliations research university figure comparison versus lime mnist. pp/pn stands pertinent positive/negative. color scheme follows pertinent positives minimal present cyan. minimal absent pink corresponding digit labels number would become pink present. green neutral red/yellow positive relevance blue negative relevance. lime positive relevance white neutral. contrastive facts means list possible characteristics absent input distinguish classes belong rather minimal characteristics/features help distinguish closest class belong paper want generate explanations deep networks which besides highlighting minimally suﬃcient input justify classiﬁcation also want identify contrastive characteristics features minimally critically absent maintain current classiﬁcation distinguish another input closest would classiﬁed diﬀerently thus want generate explanations form input classiﬁed essentially counterfactual stressed recently seem crisp explanations possible binary data. however also applicable continuous data. presence features corresponds signal present features case images would features non-zero input represent objects opposed background pixels image. corresponds signal therefore data speciﬁc. example figure hand-written digits mnist dataset black background represents signal absence speciﬁc features case pixels value zero. non-zero value would indicate presence features/pixels. although argue information loss form explanation believe explanations lucid easily understandable humans always delve details generated explanations precise feature values readily available. fact strong motivation form explanations presence certain human-critical domains. medicine criminology notion pertinent positives pertinent negatives together constitute complete explanation. pertinent positive factor whose presence minimally suﬃcient justifying ﬁnal classiﬁcation. hand pertinent negative factor whose absence necessary asserting ﬁnal classiﬁcation. example medicine patient showing symptoms cough cold fever sputum chills likely diagnosed rather pneumonia. cough cold fever pertinent positives pneumonia however absence sputum chills leads diagnosis thus sputum chills pertinent negatives along pertinent positives critical sense suﬃcient accurate diagnosis. example criminology would murder scene where victims residence safe empty valuables missing. empty safe pertinent negative could indicate theft primary motive opposed murder acquaintance. hence pertinent negatives viewed factors whose absence critical determining correct class example distinguishing closest class. thus propose explanation method called contrastive explanations method deep neural networks highlights pertinent positives also pertinent negatives. seen figure explanation image predicted ﬁrst highlight important pixels present classiﬁed also highlights small horizontal line whose presence would change classiﬁcation image thus absent classiﬁcation remain therefore explanation digit figure would digit cyan pixels present pink pixels absent. second part critical accurate classiﬁcation highlighted state-of-the-art interpretability methods layerwise relevance propagation locally interpretable model-agnostic explanations respective results shown columns figure moreover given original image pertinent positives highlight present necessary suﬃcient example classiﬁed case methods essentially highlight positively negatively relevant pixels necessary suﬃcient justify classiﬁcation. pertinent negatives negatively relevant features another important thing note conceptual distinction pertinent negatives identify negatively correlated relevant features methods highlight. question trying answer input classiﬁed class ergo human asking question wants evidence support hypothesis classiﬁed class pertinent positives well negatives evidences support hypothesis. however unlike positively relevant features highlighted methods also evidence supporting hypothesis negatively relevant features deﬁnition not. hence another motivation work believe human asks question interested evidence supporting hypothesis rather information devalues latter information deﬁnitely interesting secondary importance comes understanding human’s intent behind question. ﬁnds minimal amount features input suﬃcient yield classiﬁcation. solving constrained optimization problem perturbs input minimal number non-zero features made brought closer zero i.e. deleted deleted features maintain original classiﬁcation. words pertinent positives suﬃcient evidence original classiﬁcation input. also ﬁnds minimal amount features absent input prevent classiﬁcation result changing. solving another constrained optimization problem perturbs input minimal number zero valued features made non-zero i.e. added cause neural network classiﬁcation change. added features pertinent negatives absence necessary prediction input. close data manifold obtain realistic explanations. using convolutional autoencoder regularizer objectives data manifold learned using recently shown state-of-theart compared types autoencoders. enhance methods resulting explanations likely close true data manifold thus match human intuition rather arbitrary perturbations change classiﬁcation. course learning good representation using autoencoder possible situations limitations insuﬃcient data data quality. also necessary cases combinations feature values semantics domain. amount perturbation depends metric used. chose elastic regularizer measure amount distortion since shown recently produce best sharpest adversarial examples norms. well form explanations focus presence absence features. method proposed section thus close relations methods proposed adversarial attacks neural networks certain diﬀerences. main attack methods largely unconstrained additions deletions performed simultaneously alter classiﬁcation input. method hand obtains pertinent positives pertinent negatives suﬃcient necessary respectively justify classiﬁcation enforcing applied perturbations deletions additions only. moreover optimization objective distinct searching features minimally suﬃcient maintain original classiﬁcation. such work demonstrates attack methods adapted create explanation methods thus exhibits strong connection two. finally note integration autoencoder perturbation generation method realistic intuitive explanations largely unexplored previously. validate approaches three real-world datasets. ﬁrst hand-written digits dataset mnist generate explanations without autoencoder. second procurement fraud dataset large corporation containing millions invoices tens thousands vendors diﬀerent risk levels. third brain functional imaging dataset publicly accessible autism brain imaging data exchange database comprises resting-state fmri acquisitions subjects diagnosed autism spectrum disorder neurotypical individuals. latter cases consider using autoencoders. fmri dataset insuﬃciently large especially given high-dimensionality. procurement data hand combination allowed feature values reasonable. preceding characteristics make autoencoders less suitable datasets. three cases witness power approach creating precise explanations also match human judgment. researchers great eﬀorts devising frameworks algorithms interpretable modeling. examples include establishment rule/decision lists prototype exploration developing methods inspired psychometrics learning human-consumable models also works focus answering instance-speciﬁc user queries locally approximating high-performing complex model using simpler easy-to-understand could used gain conﬁdence complex model. also recent work proposes uniﬁed approach create local model explanations certain desirable properties many current methods seem lack. moreover also interesting work tries formalize quantify interpretability recent survey looks primarily methods understanding neural networks methods produce prototype given class optimizing conﬁdence score class subject regularization prototype explaining neural network’s decision image highlighting relevant parts using technique called layer-wise relevance propagation technique starts last layer progressively assigns weights neurons layers connected single neuron layer satisfying weight conservation properties across layers. observe type methods local model explanations speciﬁc image type methods global producing prototypes given class. works also investigate methods type discussed vision applications explanation methods however focus features present even highlight negatively contributing features ﬁnal classiﬁcation. such identify features necessarily suﬃciently present absent justify individual example classiﬁcation model. contrastive explanations method section details proposed contrastive explanations method. denote feasible data space denote example example based deﬁned perturbation applied method ﬁnding pertinent positives/negatives formulated optimization problem perturbation variabale used explain model’s prediction results. denote prediction model ensure modiﬁed example still close data manifold natural examples propose autoencoder evaluate closeness data manifold. autoencoder consists encoder compresses high-dimensional input data low-dimensional representations decoder reconstructs input data based low-dimensional representations. denote reconstructed example using autoencoder elaborate role term objective function follows. ﬁrst term designed loss function encourages modiﬁed example predicted diﬀerent class maxi]i. loss function deﬁned diﬀerent original example parameter conﬁdence parameter controls separation maxi=t second third terms jointly called elastic regularizer used eﬃcient feature selection high-dimensional learning problems last term +δ−ae reconstruction error evaluated autoencoder. relevant provided well-trained autoencoder domain obtainable. parameters associated regularization coeﬃcients. maxi]i maxi]i. top- prediction class indicating removed perturbation representative model prediction similar ﬁnding pertinent negatives formulate ﬁnding pertinent positives following optimization problem δpos argminδ∈x∩x step step used.} {strategies solve described section return δpos δneg. {our explanation input classiﬁed class features δpos present features δneg absent. code available https//github.com/chunchentu/cem/blob/master/readme. apply projected fast iterative shrinkage-thresholding algorithm solve problems fista eﬃcient solver optimization problems involving regularization. take pertinent negative example assume denote objective function without regularization term. given initial iterate projected fista iteratively updates perturbation times eventually seen algorithm pertinent negative δneg pertinent positive δpos obtained optimization methods explain model prediction. last term included accurate autoencoder available otherwise zero. section provides experimental results three representative datasets including handwritten digits dataset mnist procurement fraud dataset obtained large corporation millions invoices tens thousands vendors brain imaging fmri dataset containing brain activity patterns normal autistic individuals. compare approach previous state-of-the-art methods demonstrate superiority able generate accurate intuitive explanations. parameter initially searched times guided run-time information. search never reaches next search multiplied otherwise averaged current value next search. search iterations using solver provided tensorflow. initial learning rate square-root decaying step size. best perturbation among searches used pertinent positive/negative respective optimization problems. figure comparison contrastive explanations methods versus lime mnist. means convolutional autoencoder used. color scheme follows pertinent positives minimal present cyan. pertinent negatives minimal absent pink corresponding digit labels number would become pink present. green neutral red/yellow positive relevance blue negative relevance. lime positive relevance white neutral. hand recovers image original size feature latent space. architecture convolution-upsampling-convolution-convolution. again ﬁrst convolution layers relu activation function method applied mnist variety examples illustrated figure addition shown figure introduction results using convolutional autoencoder learn pertinent positives negatives displayed. results without quite convincing clearly improves pertinent positives negatives many cases. regarding pertinent positives cyan highlighted pixels column superset cyan-highlighted pixels column without explanations level conﬁdence regarding classiﬁer explanations using visually interpretable. take instance digit classiﬁed small part tail used explain classiﬁer without explanation using much thicker tail larger part vertical curve. explanation quite clear highlights explanation much thicker pixels. pattern holds pertinent negatives. horizontal line makes much pronounced using cae. change predicted using much pronounced. rows exhibit similar state-of-the-art methods explaining classiﬁer figure lime. experiments used toolbox lime code adapted https//github.com/marcotcr/lime. visually appealing explanation pixel level. pixels deemed irrelevant classiﬁcation positively relevant pixels mostly consistent pertinent positives though pertinent positives highlight pixels easier visualization. obvious examples yellow outlines similar pertinent positive yellow outlines pertinent positive provably deems necessary given prediction. little negative relevance examples though point interesting cases. shows little curve extending upper left slightly right negative relevance similarly blue pixels part image must obviously deleted clear lime also visually appealing. however results based superpixels images ﬁrst segmented relevant segments discovered. explains pixels forming digits found relevant. methods give important intuitions neither illustrate necessary suﬃcient classiﬁer results contrastive explanations method. data spans one-year period consists millions invoices submitted tens thousands vendors across countries. invoices labeled either risk medium risk high risk based large team approves invoices. make assessment besides invoice data team access multiple public private data sources vendor master risky vendors list risky commodity list ﬁnancial index forbidden parties list country perceptions index havens list bradstreet numbers information names vendors registered company addresses account numbers date registration. contain lists potentially fraudulent vendors commodities often easy manipulate. contains information maturity vendor stock trends. released government every year lists suspect businesses. public source scoring risk business particular country. vendor registered duns number makes invoice risk. however came country risk would uplifted given invoice amount already high. vendor registered company keeps risk manageable given risky commodity code. nonetheless part lists invoice would deﬁnitely blocked. high invoice amount risky commodity code physical address makes invoice high risk. risk level would deﬁnitely somewhat lesser vendor registered duns. table example invoices risk level medium high risk level. corresponding pertinent positives negatives highlighted method. also report feedback human expert last column validates quality explanations. numbers events correspond given section lower country worse perception hence higher risk. havens countries cayman islands taxes minimal complete privacy maintained regarding people’s ﬁnancials. bradstreet oﬀers unique duns number duns name business registered them. duns provides certain level authenticity business. based data sources tens features events whose occurrence hints riskiness invoice. representative ones. spend particular vendor signiﬁcantly higher vendors country vendor registered large corporation thus name appears vendor belongs commodity invoice belongs maturity based vendor belongs vendor high risk country vendor bank account located haven vendor duns number vendor employee bank account numbers match vendor possesses street address. data trained three-layer neural network fully connected layers rectiﬁed linear units three-way softmax function. ten-fold cross validation accuracy network high domain experts however wanted know reasons decisions based could help ﬂavor network works could trust experiment didn’t regularization since combinations feature values possible semantic/intuitive inconsistencies crop certain features turned presence others. diﬀerent mnist case purely random perturbation delete pixels result poor semantic interpretation. figure fraction invoices explanations diﬀerent methods deemed appropriate experts. method produces pertinent negatives quite eﬀective seen ﬁgure right. pertinent positives also accurate methods picked positively relevant features proxy pertinent positives. help domain experts evaluated diﬀerent explanation methods. randomly chose invoices classiﬁed risk classiﬁed medium risk classiﬁed high risk. asked feedback invoices terms whether pertinent positives pertinent negatives highlighted methods suitable produce classiﬁcation. evaluate method computed percentage invoices explanations agreed experts based feedback. figure percentage times pertinent positives matched experts judgment diﬀerent methods well additionally pertinent negatives method. used positive relevance proxy pertinent positives competing methods. argued before negatively relevant features conceptually pertinent negatives hence appropriate proxy them. show not-applicable methods. observe table shows example invoices belonging class explanations produced method along expert feedback. expert feedback validates explanations showcases power pertinent negatives making explanations complete well intuitive reason with. interesting aspect medium risk invoice could perturbed towards risk high risk. however method found closer high risk thus suggested pertinent negative takes class. informed decisions made method searches crisp explanation arguably similar humans. brain imaging dataset employed study autism brain imaging data exchange large publicly available dataset consisting resting-state fmri acquisitions subjects diagnosed autism spectrum disorder well neuro-typical individuals. resting state fmri provides neural measurements functional relationship brain regions particularly useful investigating clinical populations. previously preprocessed acquisitions downloaded used c-pac preprocessing pipeline included slice-time correction motion correction skull-stripping nuisance signal regression. functional data band-pass ﬁltered spatially registered using nonlinear method template space limited acquisitions repetition time included original study martino passed additional manual quality control resulting total typical subjects functional parcellation atlas brain totaling regions used estimate brain connectivity matrix. mean time series regions interest extracted subject. pearson product-moment correlation calculated average time series build connectivity matrix subject. positive correlation values functional connectivity matrices considered study. trained single-layer neural network model tensorflow classifying brain imaging data. parameters model regularized elastic-net regularizer. leave-one-out cross validation testing accuracy around matches state-of-the-art results dataset. logits network used model prediction scores figure comparison versus pre-processed resting-state brain fmri connectivity data open-access abide database. seven networks functionally coupled regions across cerebral cortex obtained resting-state functional connectivity color scheme follows. purple visual blue somatomotor green dorsal attention violet ventral attention cream; limbic orange frontoparietal default mode pertinent positives fmri connectivity matrix cem-classiﬁed autistic brain shown upper triangle whereas pertinent negatives shown lower triangle. color intensity represents strength functional connections regions interest brain. functional connections involving rois individual brain functional network cem-classiﬁed autistic neurotypical subjects. column left square represents probability right square represents probability individual subject bolder color higher probability. depict positive relevance functional connections involving seven functional network. help domain experts evaluated performance performed best. lime challenging case since brain activity patterns spread whole image reasonable segmentation images forming superpixels achievable here. subjects randomly chosen classiﬁed autistic rest neuro-typical. since resting-state functional connectivity within large-scale brain functional networks often found altered brain disorders including autism decided compare performance terms identifying atypical patterns. fig. shows strong pertinent positive pertinent negative functional connections classiﬁed subject produced method. group connections respect associated brain network interestingly four classiﬁed autistic subjects pertinent positive mostly associated visual network hand pertinent negative subjects classiﬁed autistic preferably involve default mode network trend appears reversed subjects classiﬁed typical typical subjects pertinent positive involve pertinent negative correspond vis. taken together results consistent earlier studies suggesting atypical pattern brain connectivity autism results obtained using suggest under-connectivity involving over-connectivity visual network consistent prior ﬁndings also identiﬁes positively relevant mainly involve regions typical subjects. however positively relevant found associated visual network autistic subjects. ﬁndings imply superior performance compared robust identiﬁcation pertinent positive information brain functional connectome data diﬀerent populations. best knowledge ﬁrst-ever application neural network models classifying fmri data abide classiﬁcation accuracy matches best existing methods automatically identify meaningful biomarkers brain disorders. extraction pertinent positive negative features help reduce error diagnoses. previous sections showed method eﬀectively used create meaningful explanations diﬀerent domains presumably easier consume well accurate. it’s interesting pertinent negatives play essential role many domains explanations important. such seems though useful inputs diﬀerent classes close other. instance important distinguishing diagnosis pneumonia rather microwave airplane. inputs extremely diﬀerent probably pertinent positives suﬃcient characterize input likely many pertinent negatives presumably overwhelm user. model selection consider models test performance. scenario could model provides better explanations. model provides better explanations turn better generalizability deployed turn robust critical real applications. robustness could tested applying state-of-the-art adversarial attack methods seeing need larger perturbations create adversary average model better explanations. contrastive targeted explanations rather question could input classiﬁed class case cannot directly apply searches least perturbation change classiﬁcation arbitrary class. however case update objectives rather maximum classes obtain targeted contrastive explanations. model debugging pertinent positives negatives used analyze biases model terms kind errors making often. help interpreting model whole. ideally would great could information somehow improve model repeating errors. plan explore directions future. another idea capture data manifold train generative adversarial network opposed autoencoder. gans used generate natural adversaries used smoothly transition classes. general though good generation loosely speaking suﬃcient condition ensuring accurately captured data manifold. challenging many applications somewhat overkill purposes. another thing unclear eﬃciently navigate latent space given subtract constraints input space. would interesting problem translate latent space. such recent work shown high quality images generated much easily autoencoders gans. nonetheless would interesting direction explore especially problem settings high quality generators already available. summary provided novel explanation method called ﬁnds minimally present input justify classiﬁcation black classiﬁers neural networks also ﬁnds contrastive perturbations particular additions necessarily absent justify classiﬁcation. best knowledge ﬁrst explanation method achieves goal. validated eﬃcacy approach multiple datasets diﬀerent domains shown power explanations terms matching human intuition thus making complete well-rounded explanations.", "year": 2018}