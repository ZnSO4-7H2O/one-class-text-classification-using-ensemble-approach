{"title": "A Characterization of the Dirichlet Distribution with Application to  Learning Bayesian Networks", "tag": ["cs.AI", "cs.LG"], "abstract": "We provide a new characterization of the Dirichlet distribution. This characterization implies that under assumptions made by several previous authors for learning belief networks, a Dirichlet prior on the parameters is inevitable.", "text": "recent learning belief bayesian approaches basic components search network goodness-of-fit procedure scoring metric. approaches ponents tures infer causal bayesian suppose mial sample belief network structure ciated ters associated characterization given instance parameters parent nodes explicit edges opposing distinct contribution tistical terminology nology result statistical terizations pose discrete finite domains wish infer joint probability sample pairs values standard ence problem belief rected random variable ditional variables node drawn belief bayesian belief malizing factor compute tions made. first database multinomutually pdf. according pute joint posterior date according observed cording 'l-= symmetric biii {b;ii}f�/. b;i/ {b-j}j�l assume {b.jbil biin} mutually independe pute posterior posterior counts pairs indeed mutually dirichlet ally independent surprising result independence assumption prior dirichlet choice. possibly sion carried implication result works discussed section analogous section theorem {b;j} integers positive {bj.bji mutually independent {b.j biin} mutually independent dirichlet. terms recall terms change variables jacobian sentations assumptions equalit positive tiable tion differentiability take repeated equation ential specialization section proof given appendix. note renaming names written function equalities dependence tain equation valid equivalent possible complete parameters distribution. note three assumptions multi­ indepen­ nomial sampling implicitly since dence complete condition manifested. structure prior non-complete assumption tion specific parameters generates network another identical parents network two-variables associated conditioned equalities ters dirichlet ularity complete result two-variables n-variate solve additional tive proof uses fact cluster three possible belief networks distribution dirichlet consult well. details exponents recall tion written prior therefore equivalent express parameters levels network. terization independence single scribe example knowledge possibility overcoming notion dirichlet alent sample size equivalent user imagine domain pletely mative prior equivalent lower bound. then database would produce sity reflects database real database score database prior learning uninformative algorithm data. specifying handles prior yields dirichlet distributions according global normalization arbitrary tive constants function. satisfies global easily every positive written solution subclass. since single particular rameter work must still lemma local parameter hold networks. two-variables n-variate final comment tional tributions formulated essarily sumed discussion domain variables consider distribution. bivariate-normal gaussian prior parameters performing prior-to-posterior ried {mlvmilbvi denote parameters f--x respec­ network tively. variance associated rameters associated mean regression conditional global alence functional relationship derived solved integrable inverse distribution similarly tion interesting gamma distribution tion times arbitrary arbitrary encodes tional equation solution depends multinomial natural question dence mean gaussian jective assume independent. swer local independence means standardized independent node. allels tial function distribution bution. consequently distribution normal-wishart i.e. prior joint space parameters vector covariance matrix local parameter sume global independence indeed lence. analogous", "year": 2013}