{"title": "Item Recommendation with Evolving User Preferences and Experience", "tag": ["cs.AI", "cs.CL", "cs.IR", "cs.SI", "stat.ML"], "abstract": "Current recommender systems exploit user and item similarities by collaborative filtering. Some advanced methods also consider the temporal evolution of item ratings as a global background process. However, all prior methods disregard the individual evolution of a user's experience level and how this is expressed in the user's writing in a review community. In this paper, we model the joint evolution of user experience, interest in specific item facets, writing style, and rating behavior. This way we can generate individual recommendations that take into account the user's maturity level (e.g., recommending art movies rather than blockbusters for a cinematography expert). As only item ratings and review texts are observables, we capture the user's experience and interests in a latent model learned from her reviews, vocabulary and writing style. We develop a generative HMM-LDA model to trace user evolution, where the Hidden Markov Model (HMM) traces her latent experience progressing over time -- with solely user reviews and ratings as observables over time. The facets of a user's interest are drawn from a Latent Dirichlet Allocation (LDA) model derived from her reviews, as a function of her (again latent) experience level. In experiments with five real-world datasets, we show that our model improves the rating prediction over state-of-the-art baselines, by a substantial margin. We also show, in a use-case study, that our model performs well in the assessment of user experience levels.", "text": "preferences experience∗ subhabrata mukherjee† hemank lamba‡ gerhard weikum† †max planck institute informatics ‡carnegie mellon university email {smukherjee weikum}mpi-inf.mpg.de hlambacs.cmu.edu abstract—current recommender systems exploit user item similarities collaborative ﬁltering. advanced methods also consider temporal evolution item ratings global background process. however prior methods disregard individual evolution user’s experience level expressed user’s writing review community. paper model joint evolution user experience interest speciﬁc item facets writing style rating behavior. generate individual recommendations take account user’s maturity level item ratings review texts observables capture user’s experience interests latent model learned reviews vocabulary writing style. develop generative hmm-lda model trace user evolution hidden markov model traces latent experience progressing time solely user reviews ratings observables time. facets user’s interest drawn latent dirichlet allocation model derived reviews function experience level. experiments real-world datasets show model improves rating prediction state-of-the-art baselines substantial margin. also show use-case study model performs well assessment user experience levels. motivation state-of-the-art collaborative ﬁltering algorithms heart recommender systems items like movies cameras restaurants beer. methods exploit user-user item-item similarities addition history user-item ratings similarities based latent factor models user item features recently explicit links interactions among users data evolve time leading bursts item popularity phenomena like anomalies. state-ofthe-art recommender systems capture temporal aspects introducing global bias components reﬂect evolution user community whole. models also consider changes social neighborhood users. missing approaches though awareness experience maturity levels evolve individual users. individual experience crucial users appreciate items thus react recommendations. example mature cinematographer would appreciate tips movies much ∗this extended version paper published icdm refer general version model ﬁne-grained temporal evolution user experience resulting language model using geometric brownian motion brownian motion respectively. recommendations blockbusters. also facets item user focuses change experience. example mature user pays attention narrative light effects style rather actors special effects. similar observations hold ratings wine beer food etc. approach advances state-of-the-art tapping review texts modeling properties latent factors using explain predict item ratings function user’s experience evolving time. prior works considering review texts learn topic similarities static snapshot-oriented manner without considering time all. prior work considering time ignores text user-contributed reviews harnessing experience. however user experience interest speciﬁc item facets different timepoints often observed indirectly ratings vividly vocabulary writing style reviews. use-cases consider reviews ratings users canon dslr camera facet camera lens. user ﬁrst dslr. excellent camera takes great pictures second user clearly experienced ﬁrst reserved lens quality camera model. future recommendations second user take consideration user’s maturity. second use-case consider following reviews christopher nolan movies facet interest non-linear narrative style. user memento backwards told thriller noir-art ﬁrst user appreciate complex narratives making writing review backwards. second user prefers simpler blockbusters. third user seems appreciate complex narration style inception memento. would consider maturity level experienced user generate future recommendations her. approach model joint evolution user experience interests speciﬁc item facets writing style rating behavior community. item ratings review texts directly observed capture user’s experience interests latent model learned reviews vocabulary. conditioned time considering maturing rate user. intuitively user gains experience writing many reviews also needs continuously improve quality reviews. varies different users enter community experienced. allows generate individual recommendations take account user’s maturity level interest speciﬁc facets items different timepoints. develop generative hmm-lda model user’s evolution hidden markov model traces latent experience progressing time latent dirichlet allocation model captures interests speciﬁc item facets function experience level. explicit input model ratings review texts upto certain timepoint; everything else especially user’s experience level latent variable. output predicted ratings user’s reviews following given timepoint. addition derive interpretations user’s experience interests salient words distributional vectors latent dimensions. although unsurprising users writing sophisticated words experience observe something interesting. instance specialized communities like beeradvocate.com ratebeer.com experienced users write descriptive fruity words depict beer taste table shows snapshot words used different experience levels depict facets beer taste movie plot journalism respectively. apply model million ratings million users million items different communities movies food beer news media achieving improvement mean squared error rating predictions several competitive baselines. also show users experience level indeed exhibit similar vocabulary facet interests. finally use-case study news community identify experienced citizen journalists demonstrates model captures user maturity fairly well. contributions summarize paper introduces following novel elements ﬁrst work considers progression user experience expressed text item reviews thereby elegantly combining text time. approach based intuition strong coupling facet preferences user experience writing style reviews rating behavior. factors jointly evolve time given user. model user experience progression discrete stages state-transition model natural. decision made markovian model simplest thus natural choice. experience level user current instant depends experience level previous instant experience levels latent hidden markov model appropriate. experience progression user depends following factors maturing rate user modeled activity community. engaged user community higher chances gains experience advances writing sophisticated reviews develops taste appreciate speciﬁc facets. writing style user expressed language model current level experience. sophisticated vocabulary writing style indicates higher probability progressing mature level. experience level difference since unlikely user directly progress level level without passing level model instant decides whether user stay current level progress order learn facet preferences language model user different levels experience latent dirichlet allocation work assume review refer exactly item. therefore facet distribution items expressed facet distribution review documents. make following assumptions generative process writing review user time experience level user distribution facets facet preferences user depend experience level facet distribution words words used describe facet depend user’s vocabulary level stupid people supposed wouldnt pass bizarre totally cant level storyline acting time problems evil great times didnt money ended simply falls pretty level movie plot good young epic rock tale believable acting level script direction years amount fast primary attractive sense talent multiple demonstrates establish level realism moments ﬁlmmaker visual perfect memorable recommended genius ﬁnish details deﬁned talented visceral nostalgia level happy people back supposed good wouldnt cant level storyline believable acting time stay laugh entire start funny level narrative cinema resemblance masterpiece crude undeniable admirable renowned seventies unpleasant myth nostalgic level incisive delirious personages erudite affective dramatis nucleus cinematographic transcendence unerring peerless fevered experience level table shows salient words facets amazon movie reviews different levels user experience automatically extracted latent model. facets latent interpret plot/script narrative style respectively. hypotheses initial studies hypothesis writing style depends experience level. expect users different experience levels divergent language models experienced users sophisticated writing style vocabulary amateurs. test hypothesis performed initial studies popular communities beeradvocate million reviews users amazon movie reviews million reviews users. span period years. beeradvocate user gets points basis likes received reviews ratings users number posts written diversity number beers rated time community etc. points measure proxy user’s experience. amazon reviews helpfulness votes users. user aggregate votes reviews take proxy experience. partition users bins based points helpfulness votes received representing experience levels. aggregate review texts users construct unigram language model. heatmap figure shows kullback-leibler divergence lm’s different experience levels beeradvocate case. amazon reviews lead similar heatmap omitted here. main observation divergence higher larger difference experience levels users. conﬁrms hypothesis coupling experience user language. second hypothesis underlying work users similar levels experience similar facet preferences. contrast lm’s words observed facets latent validating falsifying second hypothesis straightforward. performed three-step study latent dirichlet allocation compute support vector regression user. user’s item rating review response variable facet proportions review given features. regression weight interpreted preference user facet finally aggregate facet preferences experience level corresponding facet preference distribution given figure shows divergence facet preferences users different experience levels beeradvocate. divergence clearly increases difference user experience levels; conﬁrms hypothesis. heatmap amazon similar omitted. denotes scalar product. average rating items users. offset average rating given user global rating. likewise rating bias item latent factors associated user item respectively. latent factors learned using gradient descent minimizing mean squared error observed ratings predicted ratings relevant baseline work user learned rate model exploits users experience level similar rating behavior even ratings temporarily apart. experience user item modeled latent variable {...e}. different recommenders learned different experience levels. therefore equation parameterized receui βg+βu+βi+αu parameters learned using limited memory bfgs additional constraint experience levels non-decreasing reviews written user time. however signiﬁcantly different approach. models work basis user rating behavior ignore review texts completely. additionally smoothness evolution parameters experience levels enforced regularization model natural user maturing rate model. also note parametrization experience level estimated user-item pair. however rare user reviews item multiple times. approach instead trace evolution users user-item pairs. user extends latent dirichlet allocation include authorship information. document considered distribution authors. consider special case document exactly author associated multinomial distribution facets symmetric dirichlet prior facets multinomial distribution words drawn vocabulary symmetric dirichlet prior exact inference possible intractable coupling ways approximate inference mcmc techniques like collapsed gibbs sampling variational inference. latter typically much complex computationally expensive. work thus sampling. generative process described unsupervised take ratings reviews account. supervision difﬁcult build mcmc sampling ratings continuous values communities like newstrust.net. discrete ratings review-speciﬁc multinomial rating distribution learned discretizing continuous ratings buckets bypasses problem extent results loss information. approaches overcome problem learning feature weights separately user-facet model. elegant approach using multinomial-dirichlet regression proposed incorporate arbitrary types observed continuous categorical features. facet associated vector whose dimension equals number features. assuming feature vector document dirichlet hyper-parameter document-facet multinomial distribution parametrized exp. model trained using stochastic alternates sampling facet assignments posterior distribution conditioned words features optimizing given facet assignments using l-bfgs. approach explained next section follows similar approach couple user-facet model latent-factor recommendation model start user-facet model based latent dirichlet allocation users distribution facets facets distribution words. determine facets interest user. facet preferences interpreted latent item factors traditional latent-factor recommendation model however supervised opposed ufm. obvious incorporate supervision predict ratings. user-provided ratings items take continuous values cannot incorporate multinomial distribution ratings. propose expectation-maximization approach incorporate supervision latent facets estimated estep using gibbs sampling support vector regression used m-step learn feature weights predict ratings. subsequently incorporate layer experience ufm-lfm model experience levels drawn hidden markov model e-step. experience level transitions depend evolution user’s maturing rate facet preferences writing style time. entire process supervised generative process generating review based experience level user hinged hmm-lda model. consider corpus review documents denoted dd}. user documents ordered timestamps wrote them document sequence words denoted .wnd. word drawn vocabulary unique words indexed consider users involved writing documents corpus author document consider ordered experience levels ...ee} facets ...zz} possible facets. document associated rating item time writing review user experience level assume experience level transitions follow distribution markovian assumption certain constraints. means experience level time depends experience level writing previous document time td−. denotes probability progressing experience level experience level constraint means instant user either stay current experience level move next one. experience-level transition probabilities depend rating behavior facet preferences writing style user. progression also takes account maturing rate modeled intensity activity community time gaps writing consecutive reviews. incorporate aspects prior user’s transition rates deﬁned davg denote number reviews written average number reviews user community respectively. therefore ﬁrst term models user activity respect community average. second term reﬂects time difference successive reviews. user experience unlikely change level writing previous review hours days ago. controls effect time difference small value. note user writes infrequently second term ﬁrst term plays dominating role prior small respect community average active community bringing inﬂuence entire prior. note constructed encapsulates factors experience progression outlined section example user high level experience choose write beer hoppiness story perplexity movie. word writes depends facet chosen language model current experience level. thus draws word multinomial distribution φetd symmetric dirichlet prior example facet chosen beer taste movie plot experienced user choose words coffee roasted vanilla visceral whereas inexperienced user bitter emotional resp. algorithm describes generative process review; figure depicts visually plate notation graphical models. mcmc sampling inference model. inﬂuenced supervision hyper-parameter controlling inﬂuence supervision*/ conditioned supervised facet preference αudetd experience level scaled choose θudetd latent item factors equation correspond latent facets algorithm assume estimation latent facet distribution document iteration mcmc sampling denotes experience level document written denote latent facet document. also estimation preference user facet experience level given θue. user compute supervised regression function user’s numeric ratings currently estimated experience-based facet distribution reviews input features ratings output. denote number transitions experience level users community constraint {ei− note allow selftransitions staying experience level. counts capture relative difﬁculty progressing different experience levels. example easier progress level level level level indicator function taking value argument true otherwise. subscript denotes value variable excluding data position. counts transitions exclude transitions sampling value current experience level gibbs sampling. conditional distribution experience level transition given ﬁrst factor models rate experience progression factoring user activity; second third factor models facet-preferences user language model speciﬁc level experience respectively. three factors combined decide whether user stay current level experience matured enough progress next level. gibbs sampling conditional distribution hidden variable computed based current assignment hidden variables. values latent variables sampled repeatedly conditional distribution convergence. problem setting sets latent variables corresponding respectively. perform collapsed gibbs sampling ﬁrst sample value experience level user current document keeping facet assignments ﬁxed. order this consider experience levels levels current document token positions compute equation choose level highest conditional probability. thereafter sample facet word document keeping currently sampled experience level user document ﬁxed. learned feature weights indicate user’s preference facet experience level feature weights used modify attribute mass facet higher preference level reﬂected next sampling iteration draw facet user’s facet preference distribution smoothed draw word φez. sampling process repeated convergence. latent facet model difﬁcult hyperparameters. therefore prior work assume symmetric dirichlet priors heuristically chosen concentration parameters. approach learn concentration parameter general dirichlet prior multinomial distribution optimize hyper-parameters learn user ratings documents given experience level. describe inference algorithm estimate distributions observed data. user compute conditional distribution hidden variables words review. exact computation distribution intractable. collapsed gibbs sampling estimate conditional distribution hidden variable computed current assignment hidden variables integrating parameters model. experience facet language distribution denote count word occurring document written user experience level belonging facet following equation position distribution indicates summation counts respective argument. baselines consider following baselines work available code experimentation. standard latent factor recommendation model community uniform rate users products community evolve using single global clock different stages community evolution appear uniform time intervals. community prefers different products different times. user uniform rate extends consider individual users modeling different stages user’s progression based preferences experience levels evolving time. model assumes uniform rate experience progression. user learn regression model using facet proportions document features along user item biases user’s item rating response variable. besides facet distribution document biases also depend experience level total number parameters learned solution generate positive negative real numbered weights. order ensure concentration parameters dirichlet distribution positive reals take exp. learned typically small whereas value equation large. therefore scale hyper-parameter control inﬂuence supervision. tuned using validation varying ...}. e-step next iteration choose dirichlet. liblinear package support vector regression. setup perform experiments data communities different domains beeradvocate ratebeer beer reviews amazon movie reviews yelp food restaurant reviews newstrust reviews news media. table gives dataset statistics. total million reviews million users communities combined. ﬁrst four communities used product reviews extract following quintuple model userid itemid timestamp rating review newstrust special community discuss section models used three recent reviews user withheld test data. experience-based models consider last experience level reached user corresponding learned parameters rating prediction. models group light users less reviews training data background model treated single user avoid modeling sparse observations. ignore user. test phase light user take parameters background model. beeradvocate ratebeer yelp facets; amazon movies newstrust much richer user learned rate extends allowing user evolve personal clock time reach certain experience levels depends user model past experience level order determine well model captures evolution user experience time consider another baseline randomly sample experience level reached users timepoint previously lifecycle evolved thereafter. learn model parameters data time predict user’s recent three item ratings. note baseline considers textual content user contributed reviews unlike baselines ignore them. therefore better vanilla content-based methods notion past evolution strongest baseline model. discussions table compares mean squared error rating predictions generated model versus baselines. model consistently outperforms baselines reducing improvements model baselines statistically signiﬁcant p-value performance improvement prominent newstrust community exhibits strong language features topic polarities reviews. lowest improvement achieved amazon movie reviews. possible reason community diverse wide range movies review texts heavily statements movie plots actual review aspects like praising criticizing certain facets movie. situation similar food restaurants case. nevertheless model always wins best baseline works typically user learned rate model. evolution effects observe table model’s predictions degrade applied users’ past experience level compared recent level. signals model captures user evolution past previous timepoint. therefore last experience level attained user informative generating recommendations. qualitative analysis salient words facets experience levels point typical word clusters illustrative labels show variation language users different experience levels different facets. tables show salient words describe beer facet taste movie facets plot narrative style respectively different experience levels. note facets latent labels merely interpretation. similar examples found tables vii. beeradvocate ratebeer focused communities; easier model characterize user experience evolution vocabulary writing style user reviews. observe table users write descriptive fruity words depict beer taste become experienced. movies wording reviews much diverse harder track. especially blockbuster movies tend dominate data reviews kinds aspects. better approach could focus speciﬁc kinds experience level drank maybe terrible dull shit experience level bottle sweet nice hops bitter strong light head smooth good brew better good expertise level sweet alcohol palate down thin glass malts poured thick pleasant hint bitterness copper hard experience level smells sweet thin bitter fresh hint honey sticky yellow slight good faint bitter beer brown good malty deep smooth bubbly damn weak experience level golden head lacing ﬂoral dark fruits citrus sweet light spice hops caramel ﬁnish acquired taste hazy body lacing chocolate coffee roasted vanilla creamy bitterness copper malts spicy honey movies better distinguish experienced users amateurs novices terms reﬁned taste writing style. different experience levels observe weak trend decreases increasing experience level. users highest level experience almost always exhibit lowest mse. tend better predict rating behavior mature users remaining user population. turn enables generating better recommendations connoisseurs community. experience progression figure shows proportion reviews written community members different experience levels right advancing next level. plot users minimum reviews certainly amateurs. large part community progresses level level however users move higher levels leading skewed distribution. observe majority population stays level user experience distribution table shows number users experience level domain users reviews. distribution also follows intuition highly skewed distribution. note almost users reviews belong levels language model facet preference divergence figure show divergence facet-preference language models users different experience levels computed model. facet-preference divergence increases experience levels smooth prominent language models. hand table distribution users different experience levels. level religion iraq responsibility level national reform live krugman questions clear meaningful lives california powerful safety impacts level health actions cuts medicare news points climate major jobs house high vote congressional spending unemployment strong taxes citizens events failure complexity latent facets explicit words. hand also afﬁrms notion grounding model language. baseline model divergence figure shows facetpreference divergence users different experience levels computed baseline model user learned rate contrast heatmaps model baseline revealing. increase divergence increasing experience levels rough baseline model although trend obvious. focused traditional item recommendation items like beers movies. switch different kind items newspapers news articles tapping newstrust online community newstrust features news stories posted reviewed members many professional journalists content experts. stories reviewed based objectivity rationality general quality language present unbiased balanced narrative event. focus quality journalism. framework story item rated reviewed user. facets underlying topic distribution reviews topics healthcare obama administration etc. facet preferences mapped polarity users news community. recommending news articles ﬁrst objective recommend news readers catering facet preferences viewpoints experience. apply joint model task compare predicted ratings ones observed withheld reviews newstrust community. mean squared error results reported table section table shows salient examples vocabulary users different experience levels topic election. identifying experienced users second task experienced members community potential citizen journalists. order good model predicts experience level users consider following ground-truth user experience. newstrust users member levels calculated newstrust staff based community engagement time community users’ feedback reviews proﬁle transparency manual validation. member levels categorize users experienced inexperienced. treated ground truth assessing prediction ranking quality model baseline user learned rate model table viii shows scores competitors. also computed normalized discounted cumulative gain ranked lists users generated models. ndcg gives geometrically decreasing weights predictions various positions ranked list dcgp state-of-the-art recommenders based collaborative ﬁltering exploit user-user item-item similarities latent factors. explicit user-user interactions exploited trust-aware recommendation systems temporal aspects leading bursts item popularity bias ratings evolution entire community whole studied papers studied temporal issues anomaly detection detecting changes social neighborhood linguistic norms however none prior work considered evolving experience behavior individual users. recent work baselines modeled inﬂuence rating behavior evolving user experience. however ignores vocabulary writing style users reviews natural smooth temporal progression. contrast work considers review texts additional insight facet preferences smooth experience progression. prior work tapped user review texts focused issues. sentiment analysis reviews aimed learn latent topics latent aspects ratings useruser interactions uniﬁed various approaches generate user-speciﬁc ratings reviews. leveraged author writing style. however prior approaches operate static snapshot-oriented manner without considering time all. modeling perspective approaches learn document-speciﬁc discrete rating whereas others learn facet weights outside topic model order incorporate continuous ratings proposed complex computationally expensive variational inference algorithm developed simpler approach using multinomial-dirichlet regression. latter inspired technique incorporating supervision. general version work presented ﬁne-grained temporal evolution user experience resulting language model using geometric brownian motion brownian motion respectively. current recommender systems consider user experience generating recommendations. paper proposed experience-aware recommendation model adapt changing preferences maturity users community. model personal evolution user rating items appreciate current maturity level. exploit coupling facet preferences user experience writing style reviews rating behavior capture user’s temporal evolution. model ﬁrst work considers progression user experience expressed text item reviews. experiments data domains like beer movies food news demonstrate model substantially reduces mean squared error predicted ratings compared state-of-the-art baselines. shows method generate better recommendations models. demonstrate utility method use-case study identifying experienced members newstrust community potential citizen journalists. west paskov leskovec potts. exploiting social network structure person-to-person sentiment analysis. transactions association computational linguistics", "year": 2017}