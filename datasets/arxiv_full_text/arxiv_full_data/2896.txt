{"title": "ConceptLearner: Discovering Visual Concepts from Weakly Labeled Image  Collections", "tag": ["cs.CV", "cs.AI", "cs.LG"], "abstract": "Discovering visual knowledge from weakly labeled data is crucial to scale up computer vision recognition system, since it is expensive to obtain fully labeled data for a large number of concept categories. In this paper, we propose ConceptLearner, which is a scalable approach to discover visual concepts from weakly labeled image collections. Thousands of visual concept detectors are learned automatically, without human in the loop for additional annotation. We show that these learned detectors could be applied to recognize concepts at image-level and to detect concepts at image region-level accurately. Under domain-specific supervision, we further evaluate the learned concepts for scene recognition on SUN database and for object detection on Pascal VOC 2007. ConceptLearner shows promising performance compared to fully supervised and weakly supervised methods.", "text": "figure conceptlearner thousands visual concepts learned automatically weakly labeled image collections. weak labels form keywords short description. conceptlearner used recognize concepts image level well detect concepts within image. show examples done learned detectors. tems trained however cumbersome expensive obtain fully labeled datasets. recently growing interest harvest visual concepts internet search engines approaches rerank search results learn concept detectors. learned detectors largely depend quality image search results image search engines sophisticated supervised training procedures. alternatively paper explores another scalable direction discover visual concepts weakly labeled images. weakly labeled images could collected cheaply massively. images uploaded photo sharing websites like facebook flickr instagram typically include tags sentence descriptions. tags descriptions might relevant image contents treated weak labels images. despite noise weak labels still useful information describe scene objects image. thus discovering visual concepts weakly labeled images crucial wide applications large scale visual recognition image retrieval scene understanding. figure shows concept recognition detection results detectors discovered conceptlearner weakly labeled image collections. discovering visual knowledge weakly labeled data crucial scale computer vision recognition system since expensive obtain fully labeled data large number concept categories. paper propose conceptlearner scalable approach discover visual concepts weakly labeled image collections. thousands visual concept detectors learned automatically without human loop additional annotation. show learned detectors could applied recognize concepts image-level detect concepts image region-level accurately. domainspeciﬁc supervision evaluate learned concepts scene recognition database object detection pascal conceptlearner shows promising performance compared fully supervised weakly supervised methods. recent advances mobile devices cloud storage social network increased amount visual data along auxiliary data text. data accumulating exponential rate typically diverse long tail. detecting concepts trends automatically vital exploit full potential data deluge. scaling visual recognition large data important topic computer vision. challenges scaling visual recognition obtain fully labeled images large number categories. majority data fully annotated. often mislabeled labels missing annotations precise name-value pairs. almost impossible annotate data human loop. computer vision research great effort build large-scale fully labeled datasets crowd sourcing imagenet pascal visual object classes places database state-of-the-art object/scene recognition detection domain-selective application weakly-learned concept classiﬁers novel datasets. application learned visual concepts tasks concept recognition detection quantitative evaluation scene recognition object detection domain-selected supervision. rest paper organized follows. section gives overview related work. description model weakly labeled image collections section followed max-margin visual concept discovery weakly labeled image collections using hard instance learning section section shows discovered concepts novel dataset using domain-selected supervision. show applications concept discovery section conclude section gives summary list possible extensions. discovering visual knowledge without human annotation fascinating idea. recently line work learning visual concepts knowledge image search engines. example neil uses semisupervised learning algorithm jointly discover common sense relationships labels instances given visual categories; levan harvests keywords google ngram uses structured queries retrieve relevant diverse instances concept; proposes multiple instance learning algorithm learn mid-level visual concepts image query results. alternative approaches discovering visual patterns weakly labeled data depend strongly results search engine. example uses multiple instance learning boosting discover attributes images associated textual description collected internet. learns object detectors weakly annotated videos. weakly supervised learning object attribute localization imagelevel labels given goal localize tags image regions. learns discriminative patches midlevel image descriptors without text label associated learned patch patterns. work take challenging task image image-level labels noisy weakly labeled image collections. related work include generate sentence description images. either generate sentences image retrieval learn conditional random ﬁeld among concepts utilize image-sentence embedding image-fragment embedding generate sentences. work focuses learning figure nus-wide dataset images multiple tags/keywords. candidate tags dataset. three examples original true tags shown black original noisy tags green possible missing tags red. figure dataset image short description. typically sentence shown image. extract phrases sentence shown side image. phrase represents relationship ordered words. relationship shown capital letters. example amod dependency like attribute+object prep preposition phrases. details dependency types found general concept detectors weakly labeled data. note predicted labels obtained method could also used generate sentence description beyond scope paper. generally speaking categories weakly labeled image collections multiple tags image nus-wide dataset sentence description image dataset analyze representative weakly labeled image collections nuswide dataset respectively. figures illustrate samples nus-wide dataset dataset note tags figure incorrect missing. figure sentences associated images also noisy written image owners images uploaded. image owners usually selectively describe image content personal feelings beyond image content itself. number images number tags image tags associated collections sentence description image extracted phrases using weak labels {τt}t images associated {ii|τt ti}n images associated {ii|τt ti}n dimensionality visual feature vector image stacked visual features visual feature vector image stacked indicator vectors indicator vector image entry associated image otherwise. weight vector including bias term classifying concept operator takes images maps hard subset based concept classiﬁer ywc·x visual feature vector label concept takes operator similar hard images maps easy subset pascalk dataset sentence descriptions generated paid amazon mechanical turk workers rather image owners objective accurate image contents. however labeling expensive scalable millions images. approach could work three categories weakly labeled image collections focus ﬁrst challenging categories. ratio cardinalities negative positive instance sets number image clusters threshold determine hard easy instances number tags based tf-idf concept cluster. name concept using tf-idf across label frequencies w.r.t. clusters compute tf-idf based fmt}; create name concept taking labels based tf-idf; figure sentence phrases example phrases extracted sentences dataset. phrase shows pair words relationship them. details relationship. phrase represent concept group associated images together. group reﬁned using algorithm reﬁned collection groups used learn concept classiﬁers detectors. extract phrases semantic fragments sentence weak label feature image. sentence contains several entities multiple weak tags image also contains relationships entities. relationships entities composed phrases could easily interpreted effectively used human. phrase representation descriptive single keyword describe image content. figure shows examples extracted phrases sentences. simplicity adopt stanford typed dependencies system standard sentence parsing. sentences parsed short phrases occur times kept. note visual phrases manually deﬁned labeled corresponding chunks meaning bigger objects smaller scenes intermediate descriptor image. contrast approach data-driven extracts thousands phrases image sentence descriptions automatically. extracted phrases weak labels images learn visual concepts automatically scale. learning visual patterns weakly labeled image collection challenging labels training images noisy. existing learning methods task include semi-supervised learning multiple instance learning paper formulate problem max-margin hard instance learning visual concepts using svm. since labels every image noisy missing labels clear separation positive negative set. images speciﬁc label considered positive images label images without label negative images would false positives positive false negatives negative set. inspired idea hard instance mining used face detection object detection consider false positives false negatives hard instances learning visual concepts. algorithm iteratively seek max-margin decision boundary separates hard instances. detailed steps algorithm concept discovery listed algorithm algorithm starts initial cache instances positive includes examples label negative random sample images without label iteration remove easy instances cache additional randomly selected negative images. retrained cache positive negative sets. keep positive ﬁxed hard negative instance sampling. ratio size negatives size positives. since number hard negative instance might high keep relatively large ratio hand various views sub-categories related concept better learn several subcategory detectors concept learn single detector using positive set. thus clustering positive sets learning concept detectors. cluster number controls diversity learned detectors. tfidf short term frequency inverse document frequency used important contextual labels label frequency sub-categories could better name learned sub-category detectors. concept detectors learned could directly apply concept recognition image-level. applications need apply concept detector subset detectors pool detectors learned source dataset speciﬁc tasks target dataset simply winner-take-all selection protocol detector selection. deﬁne selection contains labeled instances target dataset. relevant concept detector highest accuracy/precision target dataset selected. note selection separated test target dataset. following experiments scene recognition object detection follow selection protocol automatically select relevant detectors evaluation test set. call domain selected supervision. related topic domain adaptation instances target domain ﬁne-tune learned detectors. instead small subset target domain select relevant concept detectors large pool pre-trained concept detectors. also related issue dataset bias existing current recognition datasets. domain-selected supervision provides nice generalize learned detectors novel datasets. evaluate learning visual concepts weakly labeled image collections nus-wide datasets. nus-wide images tags ground-truth labels. shown average precision recall tags corresponding ground-truth labels indicates half tags incorrect half true labels missing. acquired images dataset. image text description written image owner. examples datasets shown figures dimensional feature vector layer caffe reference network used visual feature image since deep features pre-trained convolutional neural network imagenet shown state-of-the-art performance various visual recognition tasks description converted phrases using stanford english parser phrases count smaller used. used phrases. figure shows sample phrases. could phrases contain rich information relationships attribute-object object-scene object-object. linear liblinear concept discovery algorithm. concepts learned independently datasets using algorithm concepts learned consider different applications concept detection recognition scene recognition object detection. concept detection recognition chose learning concepts nus-wide datasets respectively. scene recognition object detection varied learn selected concepts pooled together possible concept detectors. note determined empirically larger might generate near-duplicate redundant concept detectors might make concept pool diverse. determining automatically label part future work. illustration learned concept detectors along ranked positive images shown figure figure discovered concepts illustration learned concepts nus-wide datasets. montage contains positive images concept followed single negative images. sub-category concept detectors boat respectively illustrated based concepts learned nus-wide. title shows name concept nus-wide. phrases dataset shown titles contextual words ranked tf-idf scores associated central concept name sub-category concept name. indeed sub-categories representing different views concepts contextual words ranked using tf-idf well describe diversity concept. concepts learned dataset show learned phrase detectors figure visual concepts well match associated phrases. example cat-in-basket catin-tree describe different scene contexts; sittingon-beach riding-horse describe speciﬁc actions; wooden-bridge rusty-car describe attributes objects. besides ranked hard negatives also shown ranked positive images. hard negatives visually similar images positive set. evaluate learned concept detectors images database pascal object detection dataset independent nus-wide datasets discover concept detectors. ﬁrst show qualitative results concept recognition detection done learned detectors. perform quantitative experiments evaluate learned concept detectors speciﬁc vision tasks domain-selected supervision scene recognition object detection respectively. compared fully supervised methods weakly supervised methods domain-selected detectors show promising performance. concept recognition detection apply learned concept detectors concept recognition image level concept detection image regions. deep feature novel query image extracted multiply learned detector matrix feature vector response vector element vector response value concept. pick likely concepts image simply sorting response values randomly take images database pascal query images recognition results concept detectors learned nus-wide datasets shown figure predicted concepts well describe image contents various aspects description attributes objects scenes activities image. figure concept detection results concepts discovered nus-wide sbu. bounding boxes high detector responses shown. note legibility manually overlaid text labels large fonts. furthermore could apply learned concept detectors concept detection level image regions. speciﬁcally mount learned concept detectors detection system similar front-end regioncnn selective search ﬁrst used extract region proposals test image. features region proposals extracted. finally deep features every region proposals multiplied detector matrix non-maximum suppression used merge responses overlapped region proposals. concept evaluate learned concept detectors scene recognition database scene categories. ﬁrstly scene name select relevant concept detectors pool learned concepts i.e. scene name appears name concept detector. matched scene categories among concept pool concept pool nus-wide. take images scene categories database randomly split train test sets. size train images category. train linear train fully supervised baseline. note baseline quite strong since linear plus deep feature currently state-of-the-art single feature classiﬁer database evaluate learned concepts domainselected supervision introduced section train used selection set. best scene detectors selected concept pool nus-wide based selection evaluated test set. test image classiﬁed scene category highest detector response. without calibration detector responses classiﬁcation result already reasonsably good. accuracy mean average precision fully supervised baseline domain-selected supervised methods listed table category three methods plotted figure concept detectors perform better nus-wide concept detectors larger amount data. learned concept detectors good performance compared fully supervised baseline strong labels. concept detectors even outperform baseline mountain castle marsh valley categories shown figure concept detectors perform worse scene categories like village hospital wave many good positive examples weakly labeled image collections. figure concept recognition illustration concept recognition using concepts discovered nus-wide datasets. ranked concepts shown respectively. predicted concepts well describe objects scene contexts activities images. figure scene recognition category three methods ranked learned concepts fully supervised baseline. concept detectors weak labels outperform baseline mountain castle marsh valley. concept detectors perform worse village hospital wave lack sufﬁcient positive examples weakly labeled image collections recognition accuracy size selection set. domain-speciﬁc detectors work well samples selection set. select subset images train selection method concepts still achieve accuracy instances category selection pick relevant concept detectors. shows domain-selected supervision works well even samples target validation test sets pascal domainselected supervision ﬁrst select learned concept detectors object name inside name compute validation evaluate selected best concept detectors objects respectively. note nus-wide dataset object classes pascal available provided tags. hence could learn detectors classes nus-wide dataset. table displays results obtained using concept discovery algorithm nus-wide datasets compares state-of-the-art baselines various kinds supervision. cvpr’ r-cnn detection framework fully supervised state-of-the-art method pascal uses train validation bounding boxes train object detectors deep features generates region proposal deep feature testing icml’ state-of-the-art method method weakly supervised approaches pascal assumes image level labeling train validation without bounding boxes train object detectors. uses r-cnn framework compute features image windows train detectors generate region proposals deep features testing. iccv’ another weakly supervised method using dpm. since three methods train validation pascal train detector relevant method upper bound baselines. another relevant comparison methods webly supervised method video supervised method webly supervised method uses items google n-grams queries collect images image search engine training detectors. training detector could considered unlimited number images search engines. video supervised method trains detectors manually selected videos without bounding boxes shows results classes pascal since methods train detectors data source test pascal similar scenario consider direct comparison baselines. method outperforms methods better paper presented conceptlearner maxmargin hard instance learning approach discover visual concepts weakly labeled image collection. concept detectors learned nus-wide datasets apply discovered concepts concept recognition detection. based domainselected supervision quantitatively evaluate learned concepts benchmarks scene recognition object detection promising results compared fully weakly supervised methods. several possible extensions applications discovered concepts. firstly since thousands concepts discovered concept detectors overlaps. example predicted labels second example figure ‘market-fruitnn’‘market-localamod’‘marketadet’‘market-vegetablenn’‘market-farmersnn’ ‘fruit-marketprep redundant describe image. thus bottom-up top-down clustering methods could used merge similar concept detectors merge predicted labels query image. besides measures could introduced characterize properties learned concepts visualness localizability subset concept detectors could grouped used speciﬁc image interpretation task. meanwhile concept recognition concept detection since every concept detected independently spatial co-occurrence constraints could deﬁned used ﬁlter outlier concepts detected image context detected concepts. besides grammatical structure integrated predicted phrases tags could used generate full sentence description image.", "year": 2014}