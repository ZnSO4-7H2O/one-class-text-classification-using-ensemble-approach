{"title": "Generating Images with Perceptual Similarity Metrics based on Deep  Networks", "tag": ["cs.LG", "cs.CV", "cs.NE"], "abstract": "Image-generating machine learning models are typically trained with loss functions based on distance in the image space. This often leads to over-smoothed results. We propose a class of loss functions, which we call deep perceptual similarity metrics (DeePSiM), that mitigate this problem. Instead of computing distances in the image space, we compute distances between image features extracted by deep neural networks. This metric better reflects perceptually similarity of images and thus leads to better results. We show three applications: autoencoder training, a modification of a variational autoencoder, and inversion of deep convolutional networks. In all cases, the generated images look sharp and resemble natural images.", "text": "however exact locations details important perceptual similarity images. distribution details plays role. main insight invariance irrelevant transformations sensitivity local image statistics achieved measuring distances suitable feature space. fact convolutional networks provide feature representation desirable properties. invariant small smooth deformations sensitive perceptually important image properties example sharp edges textures. using distance feature space alone however yield good loss function; fig. since feature representations typically contractive many images including non-natural ones mapped feature vector. hence must introduce natural image prior. build upon adversarial training proposed goodfellow train discriminator network distinguish output generator real images. objective generator trick discriminator i.e. generate images discriminator cannot distinguish real ones. yields natural image prior selects potential generator outputs realistic one. combination similarity appropriate feature space adversarial training allows obtain best results; fig. show three example applications image compression autoencoder generative model based variational autoencoder inversion alexnet convolutional network. demonstrate autoencoder image-generating machine learning models typically trained loss functions based distance image space. often leads over-smoothed results. propose class loss functions call deep perceptual similarity metrics mitigate problem. instead computing distances image space compute distances image features extracted deep neural networks. metric better reﬂects perceptually similarity images thus leads better results. show three applications autoencoder training modiﬁcation variational autoencoder inversion deep convolutional networks. cases generated images look sharp resemble natural images. recently surge interest training neural networks generate images. used wide variety applications unsupervised semisupervised learning generative models analysis learned representations analysis synthesis learning representations future prediction videos. nevertheless little work studying loss functions appropriate image generation task. typically used squared euclidean distance images often yields blurry results fig.b. especially case inherent uncertainty prediction. example suppose reconstruct image feature representation. precise location details preserved features. loss image space leads averaging likely locations details hence reconstruction looks blurry. deepsim loss compress images preserving information structures. generative modeling side show version variational autoencoder trained loss produces images realistic image statistics. finally reconstructions obtained method high-level activations alexnet dramatically better existing approaches. demonstrate even predicted class probabilities contain rich texture color position information. long history neural network based models image generation. prominent class probabilistic models images restricted boltzmann machines deep variants autoencoders widely used unsupervised learning generative modeling too. recently stochastic neural networks become popular deterministic networks used image generation tasks models loss measured image space. combining convolutions unpooling layers models applied large images. large body work assessing perceptual similarity images. prominent examples visible differences predictor spatio-temporal model moving picture quality assessment perceptual distortion metric winkler popular perceptual image similarity metric structural similarity metric compares local statistics image patches. aware work making similarity metrics machine learning except recent pre-print ridgeway train autoencoders directly maximizing ssim similarity images. resembles spirit technically different. psychophysical experiments scope paper believe deep learned feature representations better potential shallow hand-designed ssim. generative adversarial networks proposed goodfellow theory training procedure lead generator perfectly models data distribution. practically training gans difﬁcult often leads oscillatory behavior divergence modeling part data distribution. recently several modiﬁcations proposed make training stable. denton employ multi-scale approach gradually generating higher resolution images. radford make convolutional-deconvolutional architecture batch normalization. gans trained conditionally feeding conditioning variable discriminator generator usually conditioning variable one-hot encoding object class input image. gans learn generate images objects given class. recently mathieu used gans predicting future frames videos conditioning previous frames. approach looks similar conditional gan. however loss directly comparing generated image ground truth. found feature loss introduced present paper essential train complicated tasks feature inversion. related concurrent work larsen general idea measure similarity image space rather feature space. also adversarial training improve realism generated images. however larsen apply approach variational autoencoder trained images faces measure similarity features extracted discriminator. approach much general apply various natural images demonstrate three different applications. suppose given supervised learning task training input-target pairs rw×h×c inputs outputs arbitrary vectors. work focus targets images arbitrary number channels. learn parameters differentiable generator function rw×h×c optimally approximates input-target dependency according loss function typical choices squared euclidean loss ||gθ loss ||gθ y||. demonstrate paper losses suboptimal image generation tasks. propose class losses call deepsim. beyond simple distances image space capture complex perceptually important properties images. losses weighted sums three terms feature loss adversarial loss ladv pixel space loss limg generators. used several different generators experiments. task-speciﬁc describe corresponding sections below. tested generators make up-convolutional layers dosovitskiy up-convolutional layer consists up-sampling subsequent convolution. paper always up-sample factor ’bed nails’ upsampling. network wang gupta architecture alexnet trained using videos triplet loss enforces frames video close feature space frames different videos apart. refer network videonet. exact layers used comparison speciﬁed experiments sections. discriminator. architecture discriminator nearly experiments. version used autoencoder experiments shown table discriminator must ensure local statistics images natural. therefore convolutional layers occasional stride perform global average pooling. result processed fully connected layers followed shown fig. architecture consists three convolutional networks generator implements generator function discriminator discriminates generated images natural images comparator computes features images. loss feature space. given differentiable comparator rw×h×c deﬁne ﬁxed trained; example part generator discriminator. alone provide good loss training. known optimizing similarity feature space typically leads highfrequency artifacts. natural image many non-natural images mapped feature vector therefore natural image prior necessary constrain generated images manifold natural images. adversarial loss. instead manually designing prior mahendran vedaldi learn approach similar generative adversarial networks goodfellow namely introduce discriminator aims discriminate generated images real ones trained concurrently generator generator trained trick discriminator network classifying generated images real. formally parameters discriminator trained minimizing modiﬁcations basic architecture. first dealing large imagenet images increase stride ﬁrst layer second training networks invert alexnet additionally feed features discriminator. process fully connected layers units respectively. concatenate result output global average pooling. modiﬁed caffe framework train networks. optimization used adam momentum initial learning rate prevent discriminator overﬁtting adversarial training temporarily stopped updating ratio ldiscr ladv below certain threshold used batch size experiments. trained mini-batch iterations. started simple proof-of-concept experiment showing deepsim applied training autoencoders. used proposed loss function within variational autoencoder framework. finally applied method invert representation learned alexnet analyzed properties method. quantitative comparisons report normalized euclidean error b||/n. normalization coefﬁcient average euclidean distances pairs different samples test set. therefore error means algorithm performs randomly drawing sample test set. hidden representation -channel feature times smaller input image. trained unlabeled dataset contains images pixels. prevent overﬁtting augmented data cropping random patches training. qualitative results shown fig. quantitative results table underperforming terms euclidean loss approach preserve texture details resulting naturally looking non-blurry reconstructions. interestingly alexnet comparator tends corrupt details perhaps because stride ﬁrst layer. exemplar-cnn comparator preserve exact color explicitly trained invariant color changes. believe carefully selected speciﬁcally trained comparators better results obtained. stress lower euclidean error mean better reconstruction. example imagine black-and-white striped zebra pattern. monotonous gray image twice smaller euclidean error pattern shifted stripe width. classiﬁcation. reconstruction-based models commonly used unsupervised feature learning. checked target generator coincides input task generator encode input compressed hidden representation decode back image. architecture shown table layers convolutional up-convolutional. proposed loss instead ﬁrst term similar larsen comparator part discriminator. technically little difference training autoencoder. first instead predicting single latent vector predict vectors sample standard gaussian element-wise multiplication. second divergence term loss manually weighting term relative rest loss. proper probabilistic derivation nonstraightforward leave future research. trained pixel crops pixel ilsvrc- images. encoder architecture alexnet layer decoder architecture shown table initialized encoder alexnet weights however necessary shown loss functions lead learning meaningful representations usual losses. trained linear svms -channel hidden representations extracted autoencoders trained different losses. interested relative performance thus compare state art. trained folds stl- training tested test set. results shown table expected features learned deepsim perform signiﬁcantly better indicating contain semantically meaningful information. suggests losses standard useful unsupervised learning. note exemplar-cnn comparator trained unsupervised way. standard consists encoder decoder dec. encoder maps input sample distribution latent variables maps latent space distribution images loss function prior distribution latent variables kullback-leibler divergence. ﬁrst term reconstruction error. assume decoder predicts gaussian distribution pixel reduces squared euclidean error image space. second term pulls distribution latent variables towards prior. commonly assamples generated usual loss well three different comparators shown fig. euclidean loss leads blurry samples method yields images realistic statistics. interestingly samples trained videonet comparator look qualitatively similar ones alexnet showing supervised training necessary yield good comparator. results shown appendix. analysis learned representations important largely unsolved problem. approach invert representation. give insights information preserved representation invariance properties. however inverting non-trivial feature representation learned large convolutional network difﬁcult ill-posed problem. proposed approach inverts alexnet convolutional network successfully. surprisingly rich information image preserved deep layers network even predicted class probabilities. interesting result itself also shows deepsim excellent loss function dealing difﬁcult image restoration tasks. simple natural image prior total variation regularizer. method produces images roughly natural features similar input features corresponding however prior limited reconstructions fully connected layers alexnet look much like natural images. dosovitskiy brox train up-convolutional networks large training natural images perform inversion task. distance image space loss function leads approximating networks learn reconstruct color rough positions objects well produce over-smoothed results average potential reconstructions. method seen combining best worlds. loss feature space helps preserve perceptually important image features. adversarial training keeps reconstructions realistic. note similar dosovitskiy brox unlike mahendran vedaldi method require feature representation being inverted differentiable. technical details. generator setup takes features extracted alexnet generates image figure representative reconstructions higher layers alexnet. general characteristics images preserved well. cases reconstructions nearly perfect even leftmost column network generates images them general followed dosovitskiy brox designing generators. modiﬁcation inserted convolutional layers giving network capacity. reconstruct outputs layers conv –fc. layer also include processing steps following layer pooling non-linearities. example conv means pooled features means rectiﬁed values architecture used inverting decoder shown table architectures layers similar except reconstruction conv fully connected layers replaced convolutional ones. discriminator used vae. trained ilsvrc- training evaluated ilsvrc- validation set. ablation study. tested components loss necessary. results components removed shown fig. clearly full model performs best. following give intuition why. training loss image space leads averaging potential reconstructions resulting oversmoothed images. might imagine adversarial training would allow make images sharp. indeed happens resulting reconstructions correspond actual objects originally contained image. reason natural-looking image roughly blurry prediction minimizes loss. withadversarial loss predictions look noisy. withφ. straightforward approach would inject noise generator along features network could randomize outputs. yield desired result since nothing loss function forces generator output multiple different reconstructions feature vector. major problem training data image feature vector i.e. single sample conditioning vector. attack problem paper believe important research direction. figure normalized inversion error reconstructing different layers alexnet different methods. first pair error image space second feature space. best results. representative reconstructions higher layers alexnet shown fig. comparison existing approaches shown fig. reconstructions conv near-perfect combining natural colors sharpness details. reconstructions fully connected layers still good preserving main features images colors positions large objects. normalized euclidean error image space feature space shown table method mahendran&vedaldi performs well feature space image space method dosovitskiy&brox vice versa. presented approach fairly good metrics. iterative re-encoding. performed another experiment illustrating similar features reconstructions original image features. given image compute features generate image those iteratively compute features result generate those. results shown fig. interestingly several iterations signiﬁcantly change reconstruction indicating important perceptual features preserved generated images. results shown appendix. interpolation. morph images linearly interpolating features generating corresponding images. fig. shows objects shown images smoothly warp other. examples shown appendix. different comparators. alexnet network used comparator trained huge labeled dataset. supervision really necessary learn good comparator? show results several alternatives conv features alexnet features alexnet conv alexnet random weights conv network wang gupta refer videonet. results shown fig. alexnet conv comparator provides best reconstructions networks preserve image features well. also preliminary experiments conv features discriminator serving comparator able satisfactory results those. proposed class loss functions applicable image generation based distances feature spaces. applying three tasks image auto-encoding random natural image generation feature inversion reveals loss clearly superior typical loss image space. particular allows reconstruction perceptually important details even lowdimensional image representations. evaluated several feature spaces measure distances. research necessary optimal features used depending task. control degree realism generated images alternative adversarial training approach making feature statistics similar gatys interesting directions future work. denton chintala arthur szlam fergus. deep generative image models using laplacian pyramid adversarial networks. advances neural information processing systems curran associates inc. dosovitskiy fischer springenberg riedmiller brox. discriminative unsupervised feature learning exemplar convolutional neural networks. ieee transactions pattern analysis machine intelligence gregor danihelka graves rezende wierstra. draw recurrent neural network proceedings interimage generation. national conference machine learning icml lille france july figure shows samples variational autoencoders different fully unsupervised videonet loss random initialization encoder bottom right. samples model qualitatively similar others showing initialization alexnet necessary. figures show results iteratively encoding images feature representation reconstructing back image space. seen figure network trained loss image space preserve features well resulting reconstructions quickly diverging original image. radford metz chintala. unsupervised representation learning deep convolutional generative adversarial networks. arxiv. http//arxiv.org/abs/.. simonyan vedaldi zisserman. deep inside convolutional networks visualising image clasiclr worksiﬁcation models saliency maps. shop track http//arxiv.org/abs/ branden lambrecht verscheure. perceptual quality measure using spatio-temporal model human visual system. electronic imaging science technology figure samples approach different comparators. left alexnet conv comparator right alexnet comparator bottom left videonet conv comparator bottom right videonet conv comparator randomly initialized encoder. figure iterative re-encoding reconstructions different layers alexnet. block corresponds iteration number topmost input images left conv right bottom left bottom right figure iterative re-encoding reconstructions network trained reconstruct alexnet layer squared euclidean loss image space. input images shown. corresponds iteration number", "year": 2016}