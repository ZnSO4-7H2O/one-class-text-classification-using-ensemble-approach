{"title": "PRISM: Person Re-Identification via Structured Matching", "tag": ["cs.CV", "cs.LG", "stat.ML"], "abstract": "Person re-identification (re-id), an emerging problem in visual surveillance, deals with maintaining entities of individuals whilst they traverse various locations surveilled by a camera network. From a visual perspective re-id is challenging due to significant changes in visual appearance of individuals in cameras with different pose, illumination and calibration. Globally the challenge arises from the need to maintain structurally consistent matches among all the individual entities across different camera views. We propose PRISM, a structured matching method to jointly account for these challenges. We view the global problem as a weighted graph matching problem and estimate edge weights by learning to predict them based on the co-occurrences of visual patterns in the training examples. These co-occurrence based scores in turn account for appearance changes by inferring likely and unlikely visual co-occurrences appearing in training instances. We implement PRISM on single shot and multi-shot scenarios. PRISM uniformly outperforms state-of-the-art in terms of matching rate while being computationally efficient.", "text": "abstract—person re-identiﬁcation emerging problem visual surveillance deals maintaining entities individuals whilst traverse various locations surveilled camera network. visual perspective re-id challenging signiﬁcant changes visual appearance individuals cameras different pose illumination calibration. globally challenge arises need maintain structurally consistent matches among individual entities across different camera views. propose prism structured matching method jointly account challenges. view global problem weighted graph matching problem estimate edge weights learning predict based co-occurrences visual patterns training examples. co-occurrence based scores turn account appearance changes inferring likely unlikely visual co-occurrences appearing training instances. implement prism single shot multi-shot scenarios. prism uniformly outperforms state-of-the-art terms matching rate computationally efﬁcient. fig. illustration re-id color green label images different camera views arrows indicate entity matches. illustration weighted bipartite graph matching problem denotes camera view node denotes person entity different colors denote different entities edges weighted indicating missing matches entities. entity view associated single multiple images. learn estimate edge weights training instances manually labeled image pairs. formulate problem instance structured learning problem. structured learning employed matching text documents re-id poses challenges. edge weights obtained weighted linear combination basis functions. texts basis functions encode shared related words patterns text documents. weights basis functions learned training data. testing edge weights scored based weighted combination related words. contrast visual words deals maintain entities individuals traverse diverse locations surveilled different cameras non-overlapping camera views. literature paper focus ﬁnding entity matches cameras. re-id presents several challenges. vision perspective camera views non-overlapping conventional tracking methods helpful. variation appearance camera views signiﬁcant arbitrary change view angles poses illumination calibration features seen camera often missing other. resolution images re-id makes biometrics based approaches often unreliable globally issue subset individuals identiﬁed camera appear other. propose prism structured matching method re-id. prism weighted bipartite matching method simultaneously identiﬁes potential matches individuals viewed different cameras. fig. illustrates re-id camera views images labeled green form so-called probe entities labeled form so-called gallery set. graph matching requires edge weights correspond similarity entities viewed different cameras. words texts) suffer well known visual ambiguity spatial distortion. issue compounded re-id problem visual words exhibit signiﬁcant variations appearance changes pose illumination etc. handle visual ambiguity spatial distortion propose basis functions based co-occurrence different visual words. estimate weights different co-occurrences statistics training data. co-occurrence based statistics used works different purpose. largely motivated observation co-occurrence patterns visual codewords behave similarly images different views. words transformation target appearances statistically inferred co-occurrence patterns. seen fig. observe regions distributed similarly images different views robustly presence large cross-view variations. regions provide important discriminant co-occurrence patterns matching image pairs. instance statistically speaking ﬁrst column positive image pairs shows white color camera change light blue camera however light blue camera hardly change black camera shown ﬁrst column negative image pairs. previous work proposed novel visual word co-occurrence model capture important patterns images. ﬁrst encode images sufﬁciently large codebook account different visual patterns. pixels matched codewords visual words resulting spatial distribution codeword embedded kernel space kernel mean embedding latent-variable conditional densities kernels. fact incorporate spatial distribution codewords appearance models provides locality sensitive co-occurrence measures. perspective appearance change corresponds transformation visual word viewed camera another visual word another camera. particularly method assume smooth appearance transformation across different cameras. instead method learns visual word co-occurrence pattens statistically different camera views predict identities persons. structured learning problem method determine important co-occurrences robust noisy cooccurrences. summary main contributions paper propose structured matching method simultaneously identify matches cameras deal single-shot multi-shot scenarios uniﬁed framework; related work re-id received signiﬁcant interest much effort viewed methods seek classify probe image gallery images. broadly re-id literature categorized themes focusing cleverly designing local features focusing metric learning typically local feature design aims re-id speciﬁc representation based properties among data re-id e.g. symmetry centralization pedestrians images color correspondences images different cameras spatial-temporal information re-id videos/sequences discriminative image representation viewpoint invariance prior unlike approaches attempt match local features method attempts learn changes appearance features account visual ambiguity spatial distortion. hand metric learning aims learn better similarity measure using instance transfer learning dictionary learning distance learning/comparison similarity learning dimension reduction template matching active learning contrast metric learning approaches attempt metric features positively associated pairs close distance learning algorithm learns similarity functions imputing similarity features naturally undergo appearance changes. re-id also organized based called singleshot multi-shot scenarios. single-shot learning entity associated single image reid performed based every single image pair. literature methods proposed scenario. instance zhao proposed learning good discriminative mid-level ﬁlters describing images. yang proposed saliency color based image descriptor employed metric learning descriptors re-id. multi-shot learning entity associated least image re-id performed based multiple image pairs. utilize redundant information multiple images difference single-shot learning. proposed localityconstrained collaboratively regularized nearest point model select images generating decision boundaries different entities represented sets points feature space. bazzani propose image representation focusing overall chromatic content presence recurrent local patches. work contrast deals different scenarios within framework. addition allow matches entities handle cases numbers entities probe gallery sets different. meanwhile basis function handle singleshot multi-shot learning directly accounting appearance changes. special cases method bears similarity locally-adaptive decision functions described fundamentally different. ladf proposes second-order decision function based metric learning. contrast compute similarities between entities need impose positive semidefinite conditions training. method also related integer optimization method proposed enforce network consistency re-id testing i.e. maintaining consistency re-id results across network. instance person camera view matches person view also matches person view based consistency match well. network consistency helps improve camera pairwise re-id performance individual camera pairs. contrast graph-structure integral training testing proposed approach. learn-toestimate bipartite graph structures testing pruning feasible solution space based priori knowledge correct matching structures. recently paisitkriangkrai proposed utilizing structured learning integrate metric/color model ensembles structured learning taken means enhance re-id performance individual model. contrast consider structured learning learn classiﬁer working features re-id. summarize contributions method learns assign weights pairs instances using globally known feasible assignments training data. unlike text data conventional approaches weights incorporate appearance changes spatial distortion. express weights linear combination basis functions feasible appearance changes decision function weighting function weights different co-occurrences. training structural constraints induce higher scores ground-truth assignments feasible assignments. testing enforce globally feasible assignment based learned co-occurrence weights. recently open-world re-id introduced persons camera partially overlapping number cameras spatial size environment number people unknown signiﬁcantly larger scale. recall goal paper identify persons given aligned images cases person re-identiﬁcation benchmark datasets open-world re-id system level concept must deal issues person detection tracking re-id data association etc. therefore open-world re-id scope current work. structured learning also used object tracking literature data association. biggest difference however method tracking methods re-id cases temporal location information data general leads totally different goals method aims correct matches among entities using structured matching testing based appearance information tracking algorithms associate object small appearance variations adjacent frames locally. rest paper organized follows section explains structured prediction method detail. section lists implementation details. section reports experimental results benchmark datasets. conclude paper section structured learning formalizes loss functions learning similarity models consistent testing goals build intuition consider example text documents document collection words chosen dictionary documents associated probe gallery denote tuple training probe gallery documents. natural similarity model based shared-words wv{v∈di∩v∈dj}. denotes importance word matching arbitrary documents. learning problem reduces learning weights word training instances minimizes loss function. natural loss function reﬂects objectives testing. particular substituting similarity model ¯yij{v∈di∩v∈dj}. ¯yij{v∈di∩v∈dj} basis function associated word measures frequency word appears matched training instances. loss function must ensure that bipartite matching ground-truth bipartite matching. hinge losses used penalize violations note loss functions constrain weights perform better alternative bipartite matchings rather arbitrary similarity models re-id complex relative example above. first typically images need encode images visual words. second visual words typically shared even among matched entities. indeed challenge account signiﬁcant visual ambiguity spatial distortion large variation appearance people different camera views. propose similarity models based cross-view visual word co-occurrence patterns. insight aspects appearance transformed predictable ways static camera view angles statistically inferred pairwise co-occurrence visual words. allow visual concepts mapped different visual words account visual ambiguity. fig. overview method prism consisting levels entity-level structured matching imposed image-level visual word deformable matching. color represents entity example illustrates general situation re-id including single-shot multi-shot match scenarios. idea visual word co-occurrence measuring image similarities illustrated probabilistic denote person entities denote different visual words denote locations. overview ﬁrst describe problem often encounter testing. given probe entities matched gallery entities fig. depicts scenario entities associated single image multiple images unmatched entity probe/gallery existing methods could fail reason entities matched independently based pairwise similarities between probes galleries leading possibility matching multiple probes entity gallery. structured matching framework address issues. build intuition consider ¯yij binary variable denoting whether match probe entity gallery entity similarity score. goal predict structure seeking maximum bipartite matching could sub-collection bipartite graphs accounting different types constraints. instance ¯yij would account relaxed constraint identify potential matches gallery probe potential matches probe gallery hopefully correct matches among them. fig. illustration predicted bipartite matching graphs blue nodes represent probe gallery sets respectively. graphs examples satisfy conditions testing. illustrate examples predicted graphs testing satisfy conditions fig. would like matches gallery probe. node degrees large accordingly total degree gallery node degree needs similar others probe set. minimizing entropy node degrees gallery easily calculate upper bound gallery node degrees incorporating node degree upper bounds narrow feasible solution space correct matching structures }n×n denote numbers nodes bipartite graph view view denotes entity pair entity probe entity gallery denotes similarity measure function denotes weight vector measuring entity similarities denotes matrix transpose operator denotes matching structure structure denotes predicted matching denote images camera view respectively denote visual words view view denotes shared spatial locations. following along lines text-document setting analogously denote likelihood co-occurrence visual words among matched documents. term data-independent must learned training instances before. basis function given must empirically estimated. basis function measures frequency visual words co-occur accounting spatial proximity. term denotes joint contribution visual words location handle spatial distortion visual words allow visual words deformable similar deformable part model calculating joint contribution. denotes importance location prediction. summary similarity model handles visual ambiguity spatial distortion simultaneously. learn parameters similarity model along lines analogous structured loss functions penalize deviations predicted graph structures ground-truth annotated graph structures. following sections present details different components proposed approach. consider re-id problem bipartite graph matching problem entities represented nodes graph forming sets nodes probe gallery respectively matching relations represented edges weights illustrated fig. insight structured matching testing narrow feasible solution space structured prediction weighted bipartite graph matching based prior knowledge correct matching structures. training since bipartite graph deﬁned based training data degree node easily calculated. testing predict degree node. usually node degrees probe given beforehand. instance would like entity matches gallery entity probe hopefully correct match among them degree node graph however case nodes gallery. therefore without prior graph structure testing enforce following structural properties reasonable practical entities either gallery probe different other every test entity probe equally matched entity gallery. turns actually maximize matching likelihood test entity kernels mapping injective i.e. mapping preserves information distribution addition exploit reproducing property express inner products terms expected values namely obtain simple expressions similarity distributions consider codeword image cooccurrence matrix inner product visual words rkhs space namely particularly proposed latent spatial kernel. type probability product kernel previously proposed encode generative structures discriminative learning methods. context view presence codeword location noisy displacement true latent location insight spatial activation codewords image views conditionally independent conditioned true latent location namely joint probability factorizes p{πu πv|h denote noisy displacement likelihoods p{πu|h simplicity. p{πv|h denotes spatial probability plugging inequality follows rearranging summations standard upper bounding techniques. upper bound computational efﬁciency assume uniform distribution simplicity without learning. main idea introducing latent displacement variables handle view-speciﬁc distortions observed cameras. using different kernel functions upper bound results different latent spatial kernel functions. fig. illustrates whole process generating latent spatial kernel based appearance model given codeword images represented collection codeword slices. codeword slice operation performed every pixel location search functionally stand respectively. ∀i∀j deﬁnes edge weight between node node bipartite graph. method learns assignments edges structural conditions total weight bipartite graph maximized. given edge weights utilize linear programming solve threshold solution return assignments. notice structured matching handle general entity matching problem illustrated fig. different conventional re-id methods. similarity models come question deﬁne similarity measure function recall method deal single-shot learning multi-shot learning visual ambiguity spatial distortion. following fig. deﬁne based cross-view visual word co-occurrence patterns. locally sensitive co-occurrence need co-occurrence models account locality appearance changes also random spatial visual ambiguity inherent vision problems. recall codebooks view view respectively. codebook construction global thus carries information distinctive visual patterns. nevertheless sufﬁciently large codebook distinctive visual patterns mapped different elements codebook effect preserving local visual patterns. speciﬁcally pixel location image view codeword cluster pixels. emphasize local appearance changes look spatial distribution codeword. concretely denote pixel locations associated codeword image associate spatial probability distribution observed collection. visual words embedded family spatial distributions. intuitively clear similarity corresponding spatial distributions quantify pairwise relationship visual words. makes sense visual words spatially locally distributed small distance spatial distributions implies spatial locality. together leads model accounts local appearance changes. quantify similarity distributions number ways kernel mean embedding method particularly convenient task. basic idea distribution reproducing kernel hilbert space namely fig. illustration visual word co-occurrence model generation process here white regions codeword slices indicate pixel locations codeword. denote arbitrary pixel locations image domain. denotes operation sums values point-wise product matrix single value model. spatially closest codeword slice. procedure forms distance transform image mapped spatial kernel presence codeword propagated smoothly uniformly. calculate matching score codeword co-occurrence spatial kernel probe image another gallery image multiplied element-wise summed latent locations. step guarantees descriptor insensitive noise data codeword images. value single entry indexing codeword co-occurrence descriptor matching probe gallery images. result generated high dimensional sparse appearance descriptor. note simply computation model utilizing indicator function pixel location image encoded codeword otherwise maxπu∈πu maxπv∈πv computed independently comparing similarities making calculation much efﬁcient. model cannot however handle multi-shot scenario directly. ground-truth matching structure simply maxi substitute value construct feasible solution space structured matching testing training also utilize priori knowledge correct matching structures reduce chance mismatching. principle solve using -slack structural svms list cutting-plane algorithm training prism alg. basic idea select violated matching structure feasible iteration current feasible resolve using solution searching space dependent rather iteration simply adopt ranksvm solver suitable |yij ¯yij| indeed solve binary quadratic problem efﬁciently solved using similar thresholding trick inference testing. order speed learning alternatively adopt large-scale linear ranksvms large amount randomly sampled matching structures approximately solve trick widely used many large-scale training methods demonstrated effectiveness efﬁciency without notable performance loss. similarly re-id cases implement learning strategies found performance loss marginal. illustrate schematics method fig. training stage extract low-level feature vectors randomly sampled patches training images cluster codewords form codebook used encode every image codeword image. pixel codeword image represents centroid patch mapped codeword. further visual word co-occurrence model calculated every pair gallery probe images descriptors training data utilized train classiﬁer using perform re-id test data using spatial kernel parameter controlling locality. multishot learning take sequence collection independent images utilize average represent entity. even though simple representation turns method outperform current stateof-the-art signiﬁcantly multi-shot scenario demonstrate section choices spatial kernel quite ﬂexible. account computational efﬁciency list three choices i.e. truncated gaussian ﬁlters truncated gradient gaussian ﬁlters ﬁlters deﬁnitions shown below dist otherwise. dist denotes distance function denote corresponding scale parameters functions predeﬁned thresholding parameter. three functions illustrated fig. distance function euclidean distance. compared gaussian function used three functions produce much sparser features making computation efﬁcient. q=··· ∀p∀q denotes person entity camera view refer view probe view gallery set. also denote {yij}ij≥ ground-truth bipartite graph structure same; otherwise method training formulated following structured learning problem weight vector denotes predicted yijφ denotes basis function ground-truth graph structure |yij− ¯yij| denotes loss structures predeﬁned regularization constant denotes norm vector. constraint enforcing structured matching score ground-truth structure highest among possible matching structures order adapt deﬁnition speciﬁcally extract -dim color+sift feature vector pixel patch images utilize k-means generate visual codebooks based randomly selected color+sift features camera view. every color+sift feature quantized visual words based minimum euclidean distance. number visual words view cross-validation. employ chessboard distance consider every pixel location scale parameter cross-validation spatial kernel similarly regularization parameter cross-validation. testing performance measure utilize standard metric re-id namely cumulative match characteristic curve displays algorithm’s recognition rate function rank. instance recognition rate rank-r curve denotes proportion queries correctly matched corresponding gallery entity rank-r better. therefore solve optimization problem. note save computational time prediction testing. follows fact need exact solution long current solution ranks entities gallery probe determine matches. therefore linear programming solver iterations experiments. single-shot multi-shot scenarios. re-implement comparative methods. instead cite numbers/ﬁgures comparative methods either released codes original papers accurately possible table table respectively) necessary. also compare method currently known state-of-theart datasets. experimental results reported average trials. datasets experimental settings viper consists entities captured different camera views denoted cam-a cam-b respectively. image normalized pixels. follow experimental described dataset split half randomly partition training testing. samples cam-a camb form probe gallery sets respectively. cuhk campus consists people captured different camera pairs labeled denoted cam- cam- camera pair form probe gallery sets respectively. camera view images entity image contains pixels. follow experimental settings images captured randomly select individuals dataset training rest individuals testing. fig. interpretation learned model parameter enclosed regions denote pixels encoded visual words used fig. learned weight visual word pair white light-blue camera views positive value contributing identifying person. hand learned weight visual word pair white black negative contributes identifying different persons. randomly selected people image size equal pixels. multi-shot learning pairs image sequences people. length image sequence varies frames average following randomly select people training data rest people testing data. data ﬁrst second camera views forms probe gallery sets respectively. model interpretation start interpreting learned model parameters show typical learned matrix fig. visual words camera view. recall denotes likely images come person according visual word pairs spatial kernel always returns non-negatives indicating spatial distances visual word pairs images camera views. fig. comparing associated learned weights white color camera likely transfered light-blue color unlikely transfered black color camera therefore comparing images camera respectively within local regions white light-blue visual word pair images occurs contribute identifying person; hand white black cooccur within local regions images contribute identifying different persons. single-shot learning discuss results single-shot learning table lists comparison results three datasets numbers matching rates different ranks curves. scncd ladf mid-level ﬁlters mid-level ﬁlters+ladf vw-cooc rqda semantic polynomial kernel qalf semantic scncdf inal ensemble color model metric ensembles kernel ensembles-i kernel ensembles-ii ours prism-i ours prism-ii ours prism-iii based methods combine multiple features/metrics improve matching performance non-fusion methods perform recognition using single type features metric. overall fusion based methods achieve better performance non-fusion based methods methods however lack clear interpretability performance better. among non-fusion based methods viper midlevel ﬁlters+ladf current best method utilized discriminative mid-level ﬁlters features powerful classiﬁer scncdf inal second utilized foreground features. results comparable them. however prism always outperforms original methods signiﬁcantly either powerful classiﬁer foreground information used. cuhk ilidsvid prism performs best. rank- outperforms respectively. curves different methods viper cuhk compared fig. current method utilizes visual word co-occurrence model. integration multiple features explored future work. compared previous work improvement mainly comes structured matching testing precluding matches probably wrong clearly method outperforms viper cuhk rank- rank terms matching rate. compare method others cuhk ilids-vid only list comparison results table clearly prism beats state-of-the-art signiﬁcantly cuhk ilids-vid respectively rank-. note even compared best fusion method cuhk method outperforms rank-. multi-shot curves cuhk also shown fig. comparison. spatial kernel clearly demonstrated compare performances using single-shot learning multi-shot learning cuhk. averaging gallery images entity multi-shot learning visual word co-occurrence model constructed robust discriminative single-shot learning leading signiﬁcant performance improvement. robust person re-identiﬁcation experiment would like demonstrate robustness method including missing match scenarios re-id. compare different methods viper demonstration purpose. utilize kissme comparison includes different metric learning methods namely kissme mahal itml ldml lmnn metric learning methods learn similarities image pairs equivalent apply structured matching method utilizing image pair similarities comparison. ﬁrst simulate re-id scenario every probe match gallery galleries matches probe set. fig. shows comparison results using probes probes probes respectively entities gallery set. metric learning methods structured matching helps improve performances general under different settings. prism always performs best among methods. table summarizes numbers different ranks kissme kissme+sm prism fig. since kissme kissme+sm comparable methods fig. rank- prism outperforms signiﬁcantly least number probes decreases general every rank matching rates methods degrades. however prism matching rates much stable. comparing results table results similar demonstrating robustness structured matching method. display representative matching results rank- fig. using prism with/without structured matching robust re-id. without structured matching probes matched entity gallery inducing incorrect matches. however structured matching fig. examples matching result comparison viper rank- using prism with/without structured matching robust re-id. sizes probe gallery sets respectively. next simulate another re-id scenario probes/galleries matches gallery/probe sets. common situation re-id missing matches occur time. testing randomly select probes matched randomly selected galleries list table results terms average matching accuracy i.e. probe total number true positives true negatives divided total number entities. still structured matching helps improve performance prism achieves best. storage computational time storage computational time testing critical issues real-world applications. method need store image descriptors calculating similarities different entities. computational time divided three parts image descriptors entity-matching similarities entity-level structured matching consider time generating color+sift features since directly existing code without control. rest parameters described section roughly speaking storage data sample computational time linearly proportional size images number visual words. implementation based unoptimized matlab code. numbers listed table identifying matches probes galleries including time saving loading features. experiments multi-thread method efﬁciently demand storage. conclusion paper propose structured matching based method re-id contexts single-shot learning multi-shot learning. formulate core re-id problem i.e. entity matching weighted bipartite graph matching problem predict graph structures. handle huge appearance variation well achieving computational efﬁciency propose basis function capture visual word co-occurrence statistics. experiments several benchmark datasets strongly demonstrate power prism re-id scenarios. demand storage good computational efﬁciency indicate method potentially applied realworld applications. several questions considered future work. would useful reduce computational complexity calculating pair-wise latent spatial kernels. possibility modify learning algorithm decomposing weight matrix separable matrices appearance model decomposed parts probe image gallery image. decomposition accelerate computation. second would interesting learn optimal spatial kernels affect behavior visual word co-occurrence model. third would also interesting extend current structured matching framework multi-camera settings adding constraints matched/dismatched entity pairs enforce structural information network. acknowledgments material based upon work supported u.s. department homeland security science technology directorate ofﬁce university programs grant award -st--ed. views conclusions taskar chatalbashev koller guestrin learning structured prediction models large margin approach icml banerjee nevatia learning neighborhood cooccurrence statistics sparse features human activity recognition avss doretto sebastian rittscher appearance-based person reidentiﬁcation camera networks problem overview current approaches journal ambient intelligence humanized computing vol. wang zhao person re-identiﬁcation system design evaluation overview person re-identiﬁcation corvee bremond thonnat multiple-shot human re-identiﬁcation mean riemannian covariance grid avss mukunoki minoh locality-constrained collaboratively regularized nearest points multiple-shot person reidentiﬁcation proc. korea-japan joint workshop frontiers computer vision gong cristani hospedales reidentiﬁcation challenge person re-identiﬁcation w.-s. zheng gong xiang transfer re-identiﬁcation person set-based veriﬁcation. cvpr", "year": 2014}