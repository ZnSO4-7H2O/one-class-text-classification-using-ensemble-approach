{"title": "Using Trusted Data to Train Deep Networks on Labels Corrupted by Severe  Noise", "tag": ["cs.LG", "cs.CL", "cs.CV", "cs.NE"], "abstract": "The growing importance of massive datasets with the advent of deep learning makes robustness to label noise a critical property for classifiers to have. Sources of label noise include automatic labeling for large datasets, non-expert labeling, and label corruption by data poisoning adversaries. In the latter case, corruptions may be arbitrarily bad, even so bad that a classifier predicts the wrong labels with high confidence. To protect against such sources of noise, we leverage the fact that a small set of clean labels is often easy to procure. We demonstrate that robustness to label noise up to severe strengths can be achieved by using a set of trusted data with clean labels, and propose a loss correction that utilizes trusted examples in a data-efficient manner to mitigate the effects of label noise on deep neural network classifiers. Across vision and natural language processing tasks, we experiment with various label noises at several strengths, and show that our method significantly outperforms existing methods.", "text": "figure label corruption matrix three matrix estimates corrupted cifar- dataset. entry probability label class corrupted class estimate matches true corruption matrix closer confusion matrix forward method. comparisons method descriptions section much gained access small examples labels considered gold standard. scenario realistic usually case number trusted examples gathered validation test sets could gathered necessary. leverage additional information trusted labels propose loss correction empirically verify number vision natural language datasets label corruption. speciﬁcally demonstrate recovery extremely high levels label noise including dire case untrusted data majority labels corrupted. severe corruption occur adversarial situations like data poisoning number classes large. comparison loss corrections employ trusted data method signiﬁcantly growing importance massive datasets advent deep learning makes robustness label noise critical property classiﬁers have. sources label noise include automatic labeling large datasets non-expert labeling label corruption data poisoning adversaries. latter case corruptions arbitrarily even classiﬁer predicts wrong labels high conﬁdence. protect sources noise leverage fact small clean labels often easy procure. demonstrate robustness label noise severe strengths achieved using trusted data clean labels propose loss correction utilizes trusted examples dataefﬁcient manner mitigate effects label noise deep neural network classiﬁers. across vision natural language processing tasks experiment various label noises several strengths show method signiﬁcantly outperforms existing methods. robustness label noise become increasingly important property supervised learning models. advent deep learning need labeled data makes inevitable examples highquality labels. especially true data sources admit automatic label extraction crawling images tasks high-quality labels expensive produce semantic segmentation parsing. additionally label corruption arise data poisoning natural malicious label corruption known sharply degrade performance classiﬁcation systems *equal contribution university chicago foundational research institute toyota technological institute chicago. correspondence mantas mazeika <mantasuchicago.edu>. assume examples potentially corrupted examples true data distribution classes. corruption according label noise distribution also given trusted dataset examples drawn refer trusted fraction. concretely scraper labeling images metadata produce untrusted expert-annotated examples would form trusted dataset gold standard. leveraging trusted data focus investigation stochastic matrix correction approach used approach stochastic matrix applied softmax output classiﬁer resulting softmax output trained match noisy labeling. stochastic matrix engineered approximate label noising procedure approach bring original output close distribution clean labels moderate assumptions. explore avenues utilizing trusted dataset improve approach. ﬁrst involves directly using trusted data training ﬁnal classiﬁer. could applied existing stochastic matrix correction methods ablation studies demonstrate effect. second avenue involves using additional information conferred clean labels obtain better matrix approach. ﬁrst approximation could normalized confusion matrix classiﬁer trained untrusted dataset evaluated trusted dataset. demonstrate however work well estimate used method describe. method makes estimate matrix corruption probabilities estimate obtained train modiﬁed classiﬁer recover estimate desired conditional distribution call method gold loss correction named make trusted gold standard labels. accurate problem settings moderate severe label noise. relative recent method also uses trusted data method data-efﬁcient generally accurate. results demonstrate systems weather label corruption access small number gold standard labels. code available https//github.com/mmazeika/glc. performance machine learning systems reliant labeled data shown degrade noticeably presence label noise case adversarial label noise degredation even worse accordingly modeling correcting learning noisy labels well studied methods allow label noise robustness modifying model’s architecture implementing loss correction. unlike focus binary classiﬁcation aerial images assume labels symmetric consider label noise multi-class problem setting asymmetric labels. authors introduce stochastic matrix measuring label corruption note inability calculated without access true labels propose method forward loss correction. forward loss correction adds linear layer model loss adjusted accordingly incorporate learning label noise. work also make forward loss correction mechanism propose estimate label corruption estimation matrix relies strong assumptions clean labels. contra make assumption training model access small clean labels create label noise correction. assumption leveraged others purpose label noise robustness notably tenuously relates work ﬁeld semi-supervised learning human-veriﬁed labels used train label cleaning network estimating residuals noisy clean labels multi-label classiﬁcation setting. multi-class setting focus work propose distilling predictions model trained clean labels second network trained noisy left hand side equality approximated network softmax output vector. given example true one-hot label term right reduces case conditionally independent given reduces case conditionally independent given still approximate know estimate corruption matrix glc. second equality comes noting known preceding discussion implies approximation relies good estimate number trusted examples class. patrini train corrected classiﬁer. given softmax output classiﬁer train model noisy labels crossentropy loss. conditionally independent given nonsingular follows invertibility identity matrix turn correction. effect allowing label correction handle degree instance-dependency label noise summary method algorithm below. ﬁrst obtain corruption matrix then example true label sample corrupted label categorical distribution parameterized comparing loss correction methods. differs previous loss corrections label noise reasonably assumes access high-quality annotation source. therefore compare loss correction methods method performs starting dataset label noise. words additional information method uses knowledge examples trusted potentially datasets architectures noise corrections mnist. mnist dataset contains grayscale images digits training images test images. preprocessing rescale pixels unit range. train -layer fully connected network dimension network optimized adam epochs using batches size learning rate regularization weight decay layers cifar. cifar datasets contain color images. cifar- classes cifar- classes. cifar- superclasses partition classes semantically similar sets. superclasses hierarchical noise. datasets training images testing images. datasets train wide residual network depth train epochs using widening factor stochastic gradient descent restarts imdb. imdb large movie reviews dataset contains highly polarized movie reviews internet movie database split evenly train test sets. clip reviews length tokens learn -dimensional word vectors scratch train lstm hidden dimensions data. train using adam optimizer epochs batch size suggested learning rate regularization dropout linear output layer keep probability twitter. twitter part speech dataset contains tweets annotated tags. training tweets test pretrained -dimensional word vectors token concatenate word vectors ﬁxed window centered token. form training test set. window size train -layer fully connected network hidden size nonlinearity train using adam optimizer epochs batch size learning rate regularization weight decay linear output layer. sst. stanford sentiment treebank dataset consists single sentence movie reviews. reviews training test set. binarized labels sentiment classiﬁcation. moreover clip reviews length tokens learn -dimensional word vectors scratch vocab size table vision dataset results. percent trusted trusted fraction multiplied unless otherwise indicated values percentages representing area error curve computed test points. best mean result shown bold. classiﬁer noisy labels using resulting softmax probabilities. however method make trusted fraction training data. instead uses argmax percentile softmax probabilities given class heuristic detecting example truly member said class. original paper replace argmax softmax probabilities given class cifar- experiments. estimate used train corrected classiﬁer glc. forward gold. examine effect training trusted labels done augment forward trusted examples. refer resulting method forward gold seen intermediate method forward glc. distillation. distillation method involves training neural network large trusted dataset using network provide soft targets untrusted data. labels distilled neural network. classiﬁer’s decisions untrusted inputs less reliable original noisy labels network’s utility limited. thus obtain reliable neural network large trusted dataset necessary. classiﬁer trained using labels convex combination soft targets original untrusted labels. corruption-generating matrices. consider three types corruption matrices corrupting uniformly classes i.e. ﬂipping label different class corrupting uniformly classes semantically similar. order create uniform corruption different strengths take convex combination identity matrix matrix t/k. refer coefﬁcient corruption strength uniform corruption. corruption strength involves giving off-diagonal column probability mass entries along diagonal probability mass fitable dataset results. percent trusted trusted fraction multiplied unless otherwise indicated values percentages representing area error curve computed test points. best mean result bolded. nally realistic corruption hierarchical corruption. corruption apply uniform corruption semantically similar classes; example corrupted couch beaver cifar-. cifar- examples deemed semantically similar share superclass coarse label speciﬁed dataset creators. experiments analysis results. train models described section uniform label-ﬂipping hierarchical label corruptions various fractions trusted data dataset. assess performance compare loss correction methods baselines train network trusted data without label corrections network trains data without label corrections. additionally report results variant uses normalized confusion matrices elaborate discussion. record errors test sets corruption strengths since compute model’s accuracy numerous corruption strengths cifar experiments involves training wide residual networks. tables report area error curves across corruption strengths baselines corrections. sample error curves displayed figure across experiments obtains better area error curve forward distillation methods. rankings methods baselines mixed. mnist training trusted data alone outperforms methods save confusion matrix performs signiﬁcantly worse cifar- even large trusted fractions. interestingly forward gold performs worse forward several datasets. observe behavior turning corresponding component believe variance introduced training difference signal provided forward method’s estimate clean labels. provides superior estimate thus better able leverage training clean labels. additional results svhn supplementary materials. next benchmark noisy labels obtained weak classiﬁer. models scenario label noise arising classiﬁcation system weaker one’s access information true labels wishes transfer one’s system. example scraping image labels surrounding text pages provides valuable signal labels would train sub-par classiﬁer without correcting label noise. table results obtaining noisy labels sampling softmax distribution weak classiﬁer. percent trusted trusted fraction multiplied unless otherwise indicated values percent error attained indicated correction. best average result dataset shown bold. weak classiﬁer label generation. obtain labels train -layer wide residual networks cifar- cifar- clean labels epochs each. then sample softmax distributions temperature resulting labels. results noisy labels place labels obtained uniform hierarchical corruption methods. weak classiﬁers obtain accuracies cifar- cifar-. despite presence highly corrupted labels able signiﬁcantly recover performance trusted set. note unlike previous corruption methods weak classiﬁer labels corruption strength. thus performance measured percent error rather area error curve. results displayed table analysis results. overall outperforms methods weak classiﬁer label experiments. distillation method performs better small margin highest trusted fraction performs worse lower trusted fractions indicating enjoys superior data efﬁciency. highlighted attaining error rate cifar- trusted fraction original error rate noted however training correction attains error experiment suggesting weak classiﬁer labels bias. improvement conferred signiﬁcant higher trusted fractions. discussion future directions confusion matrices. intuitively reasonable alternative estimate confusion matrix. this would train classiﬁer untrusted examples obtain confusion matrix trusted examples rownormalize matrix train corrected classiﬁer glc. however data-efﬁcient lower-variance method estimating particular another problem using confusion matrices normalized confusion matrices give biased estimate limit using argmax class scores rather randomly sampling class. leads vastly overestimating value dominant entry seen figure correspondingly found outperforms confusion matrices signiﬁcant margin across nearly experiments smaller performance datasets number classes smaller. results displayed main tables. also found smoothing normalized confusion matrices necessary stabilize training cifar-. data efﬁciency. seen works small trusted fractions corroborate data efﬁciency turning clothingm dataset clothingm massive dataset humanannotated noisy labels compare data efﬁciency distillation trusted labels present. clothingm dataset consists million noisily labeled clothing images obtained crawling online marketplaces. images humanannotated examples take subsamples trusted set. distillation ﬁrst ﬁne-tune pretrained -layer resnet untrusted training examples four epochs estimate corruption matrix. thereafter ﬁne-tune network four epochs combined trusted untrusted sets using respective method. tuning freeze ﬁrst seven layers train using gradient descent nesterov momentum cosine learning rate schedule. preprocessing randomly crop resolution mirroring. also upsample trusted dataset ﬁnding give better performance methods. demonstrated modern deep neural network classiﬁers tend overconﬁdent softmax distributions. found case estimate despite higher entropy noisy labels used temperature scaling conﬁdence calibration method proposed paper calibrate shown figure outperforms distillation large margin especially lower numbers trusted examples. distillation requires ﬁne-tuning classiﬁer trusted data alone generalizes poorly examples. contrast estimating matrix done examples. correspondingly advantage decreases number trusted examples increases. trusted labels performance clothingm saturates evident figure consider extreme train entire trusted clothingm. ﬁne-tune pre-trained -layer resnext untrusted training examples estimate corruption matrix. then ﬁne-tune resnext training examples. ﬁne-tuning gradient descent nesterov momentum. ﬁrst epochs tune output layer learning rate thereafter tune whole network learning rate epochs another epochs apply loss correction. ﬁne-tune entire network learning rate epochs continue training early-stop based upon validation set. previous work obtain setting. however method obtains state-of-the-art accuracy procedure forward method obtains accuracy. could impact performance whether simple methods improving could help several variants experiment cifar- label ﬂipping corruption trusted fraction describe. variants averaged area provides beneﬁt percentage points area error curve neither conﬁdence calibration base rate incorporation able change performance original glc. indicates robust uncalibrated networks estimating improving performance difﬁcult without directly improving performance neural network used estimate better performance worst-case corruption. uniform corruption experiments example worst-case corruption sense mutual information zero corruption strength equals found training trusted dataset resulted superior performance corruption setting especially twitter. indicates possible devise re-weighting loss trusted untrusted examples using information theoretic work shown impact small trusted examples classiﬁer label robustness. proposed gold loss correction method handling label noise. method leverages assumption model access small correct labels yield accurate estimates noise distribution. experiments surpasses previous label robustness methods across various natural language processing vision domains showed considering several gimpel kevin schneider nathan o’connor brendan dipanjan mills daniel eisenstein jacob heilman michael yogatama dani flanigan jeffrey smith noah part-of-speech tagging twitter annotation features experiments. proceedings annual meeting association computational linguistics human language technologies short papers volume stroudsburg association computational linguistics. larsen nonboe hintz-madsen hansen design robust neural network classiﬁers. acoustics speech signal processing proceedings ieee international conference volume vol. wang yining singh aarti vorobeychik yevgeniy. data poisoning attacks factorization-based collaborative ﬁltering. corr abs/. http//arxiv.org/abs/.. maas andrew daly raymond pham peter huang andrew potts christopher. learning word vectors sentiment analysis. proceedings annual meeting association computational linguistics human language technologies menon aditya krishna rooyen brendan natarajan nagarajan. learning binary labels instancedependent corruption. corr abs/. http//arxiv.org/abs/.. natarajan nagarajan dhillon inderjit ravikumar pradeep tewari ambuj. learning noisy labels. burges bottou welling ghahramani weinberger advances neural information processing systems curran associates inc. nettleton david orriols-puig albert fornells albert. study effect different types noise precision supervised learning techniques. artif intell april patrini giorgio rozza alessandro menon aditya nock richard lizhen. making deep neural networks robust label noise loss correction approach. september pechenizkiy tsymbal puuronen pechenizkiy class noise supervised learning medical domains effect feature extraction. ieee symposium computer-based medical systems reed scott honglak anguelov dragomir szegedy christian erhan dumitru rabinovich andrew. training deep neural networks noisy labels bootstrapping. december srivastava nitish hinton geoffrey krizhevsky alex sutskever ilya salakhutdinov ruslan. dropout simple prevent neural networks overﬁtting. journal machine learning research veit andreas alldrin neil chechik krasin ivan gupta abhinav belongie serge learning noisy large-scale datasets minimal supervision. corr abs/. http//arxiv. org/abs/.. xiao tong tian yang huang chang wang xiaogang. learning massive noisy labeled data image classiﬁcation. ieee conference computer vision pattern recognition june table vision dataset results. percent trusted trusted fraction multiplied unless otherwise indicated values percentages representing area error curve computed test points. best mean result shown bold. table dataset results. percent trusted trusted fraction multiplied unless otherwise indicated values percentages representing area error curve computed test points. best mean result bolded. table results obtaining noisy labels sampling softmax distribution weak classiﬁer. percent trusted trusted fraction multiplied unless otherwise indicated values percent error attained indicated correction. best average result dataset shown bold.", "year": 2018}