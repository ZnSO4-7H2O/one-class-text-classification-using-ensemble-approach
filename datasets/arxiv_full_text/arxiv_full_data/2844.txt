{"title": "Learning to Explain: An Information-Theoretic Perspective on Model  Interpretation", "tag": ["cs.LG", "cs.AI", "stat.ML"], "abstract": "We introduce instancewise feature selection as a methodology for model interpretation. Our method is based on learning a function to extract a subset of features that are most informative for each given example. This feature selector is trained to maximize the mutual information between selected features and the response variable, where the conditional distribution of the response variable given the input is the model to be explained. We develop an efficient variational approximation to the mutual information, and show that the resulting method compares favorably to other model explanation methods on a variety of synthetic and real data sets using both quantitative metrics and human evaluation.", "text": "introduce instancewise feature selection methodology model interpretation. method based learning function extract subset features informative given example. feature selector trained maximize mutual information selected features response variable conditional distribution response variable given input model explained. develop efﬁcient variational approximation mutual information show resulting method compares favorably model explanation methods variety synthetic real data sets using quantitative metrics human evaluation. interpretability extremely important criterion machine learning model applied areas medicine ﬁnancial markets criminal justice well references therein). many complex models random forests kernel methods deep neural networks developed employed optimize prediction accuracy compromise ease interpretation. paper focus instancewise feature selection speciﬁc approach model interpretation. given machine learning model instancewise feature selection asks importance scores feature prediction given instance relative importance feature allowed vary across instances. thus importance scores explanation speciﬁc instance indicating features model make prediction instance. related concept machine learning feature selection selects subset features useful build good predictor speciﬁed response variable feature selection produces global importance features respect entire labeled data instancewise feature selection measures feature importance locally instance labeled model. existing work interpreting models approach problem directions. ﬁrst line work computes gradient output correct class respect input vector given model uses saliency masking input gradient computed using parzen window approximation original classiﬁer original available another line research approximates model interpreted locally additive model order explain difference model output reference output terms difference input reference input ribeiro proposed lime methods randomly draws instances density centered sample explained sparse linear model predict model outputs instances. shrikumar presented deeplift method designed speciﬁcally neural networks decomposes output neural network speciﬁc input backpropagating contribution back every feature input. table summary properties different methods. multi-class indicates whether method explain multiclass classiﬁcation. training indicates whether method requires training unlabeled data set. efﬁciency qualitatively evaluates computational time single interpretation. additive indicates whether method locally additive. model-agnostic indicates whether method generic black-box models. lundberg used shapley values quantify importance features given input proposed sampling based method kernel shap approximating shapley values. essentially directions approximate model locally additive model different deﬁnitions locality. ﬁrst considers inﬁnitesimal regions decision surface takes ﬁrst-order term taylor expansion additive model second considers ﬁnite difference input vector reference vector. paper approach instancewise feature selection mutual information conceptually different perspective existing approaches. deﬁne explainer instancewise feature selector model returns distribution subset features given input vector. given instance ideal explainer assign highest probability subset features informative associated model response. motivates maximize mutual information selected subset features response variable respect instancewise feature selector. direct estimation mutual information discrete feature subset sampling intractable; accordingly derive tractable method ﬁrst applying variational lower bound mutual information developing continuous reparametrization sampling distribution. high level primary differences approach past work following. first framework globally learns local explainer therefore takes distribution inputs consideration. second framework removes constraint local feature additivity explainer. distinctions enable framework yield efﬁcient ﬂexible natural approach instancewise feature selection. summary contributions work follows furthermore show method compares favorably model explanation methods variety synthetic real data sets using quantitative metric human evaluation amazon mechanical turk. primary ingredients general approach. framework generic applied classiﬁcation regression models current discussion restricted classiﬁcation models. assume access output model conditional distribution response variable given realization input random variable method derived considering mutual information particular pair random vectors begin providing basic background. given random vectors mutual information measure dependence them; intuitively corresponds much knowledge random vector reduces uncertainty other. precisely mutual information given joint marginal probability densities continuous joint marginal probability mass functions discrete. expectation taken respect joint distribution show mutual information nonnegative symmetric random variables. mutual information popular criteria feature selection selects subset features approximately maximizes mutual information response variable selected features propose mutual information criteria instancewise feature selection. describe construct explanations using mutual information. speciﬁc setting pair characterized marginal distribution family conditional distributions form given positive integer subsets size explainer size mapping feature space power allow mapping randomized meaning also think mapping conditional distribution given chosen subset denote sub-vector formed chosen features. view choice number explaining features best left hands user also tuned hyper-parameter. thus deﬁned random vector figure probabilistic graphical model representing construction. formulate instancewise feature selection seeking explainer optimizes criterion words maximize mutual information response variable model selected features function choice selection rule. turns global optimum problem natural information-theoretic interpretation corresponds minimization expected length encoded message model using latter corresponds conditional distribution upon observing selected sub-vector. concretely following theorem letting denote expectation deﬁne proof theorem left appendix practice global optimum obtained explanation family sufﬁciently large. case unknown computationally expensive estimate accurately choose restrict suitably controlled families prevent overﬁtting. direct solution problem possible need approach variational approximation. particular derive lower bound mutual information approximate model conditional distribution suitably rich family functions. equality holds equal distribution. thus obtained variational lower bound mutual information problem thus relaxed maximizing variational lower bound explanation conditional distribution generic choices still difﬁcult solve variational approximation order obtain tractable method need restrict suitable families efﬁcient perform optimization. single neural network parametrizing recall collection continuous respect introduce single neural network function class distribution denotes learnable parameters. deﬁne transformed entries replaced zeros subsets variational approximation. several tricks exist tackling issue like reinforce-type algorithms weighted features parametrized deterministic functions weight feature parametrized function respective feature itself.) employ alternative approach generalized concrete relaxation empirically lower variance reinforce encourages discreteness gumbel-softmax trick uses concrete distribution continuous differentiable approximation categorical distribution. particular suppose want approximate categorical random variable represented one-hot vector category probability random perturbation category independently generated gumbel distribution apply gumbel-softmax trick approximate weighted subset sampling. would like sample subset distinct features dimensions. sampling scheme equivalently viewed sampling k-hot random vector selected subset zero otherwise. importance score depends input vector assigned feature. concretely deﬁne maps input d-dimensional vector entry representing importance score feature. start approximating sampling distinct features features sampling scheme below sample single feature features independently times. discard overlapping features keep rest. scheme samples features easier approximate continuous relaxation. approximate scheme independently sampling independent concrete random vectors deﬁne d-dimensional random vector elementwise maximum random vector used approximate k-hot random vector training. write function collection auxiliary random variables sampled independently gumbel distribution. elementwise product approximation ˜xs. note expectation operator depend parameters training stage apply stochastic gradient methods jointly optimize pair update sample minibatch unlabeled data class distributions model explained auxiliary random variables compute monte carlo estimate gradient objective function explaining stage learned explainer maps sample weight vector dimension entry representing importance corresponding feature speciﬁc sample order provide deterministic explanation given sample rank features according weight vector features largest weights picked explaining features. sample single forward pass neural network parametrizing explainer required yield explanation. thus algorithm much efﬁcient explaining stage compared modelagnostic explainers like lime kernel shap require thousands evaluations original model sample. carry experiments synthetic real data sets. compare method several strong existing algorithms instancewise feature selection including saliency deeplift shap lime saliency refers method computes gradient selected class respect input feature uses absolute values importance scores. shap refers kernel shap. number samples used explaining instance lime shap default experiments. also compare method ranks features absolute value input feature times gradient selected class respect input feature. shrikumar showed equivalent lwrp activations piecewise linear used shrikumar strong baseline. call taylor ﬁrst-order taylor approximation model. experiments rmsprop default hyperparameters optimization. also step size across experiments. temperature gumbel-softmax approximation ﬁxed codes reproducing results available online. switch feature. generate mixture gaussians centered respectively equal probability. generated gaussian centered dimensions used generate like orange skin model. otherwise dimensions used generate nonlinear additive model. figure plots median ranks inﬂuential features sample samples data set. line dotted blue line median mean respectively. lower median ranks better. dotted green lines indicate optimal median rank. ﬁrst three data sets modiﬁed commonly used data sets feature selection literature fourth data designed speciﬁcally instancewise feature selection. every sample ﬁrst data ﬁrst dimensions true features dimension independent response variable combination joint effect second data samples positive labels centered around sphere four-dimensional space. sufﬁcient statistic formed additive model ﬁrst four features. response variable third data generated nonlinear additive model using ﬁrst four features. last data switches important features based sign ﬁrst feature. features true samples generated gaussian centered features true otherwise. dense layers. safely assume neural network successfully captured important features based error rate. taylor saliency deeplift shap lime instancewise feature selection trained neural network models. network structure across synthetic data sets. explainer neural network composed hidden layers. variational family composed three hidden layers. layers linear dimension number desired features number true features. underlying true features known sample hence median ranks selected features sample validation data reported performance metric plots plotted figure observe outperforms methods nonlinear additive feature switching data sets. model deeplift shap achieve best performance. orange skin model algorithms near optimal performance lime achieving stable performance across samples. also report clock time method figure experiments performed single nvidia tesla coded tensorflow. across four data sets shap lime least efﬁcient require multiple evaluations model. deeplift taylor saliency requires backward pass model. deeplift slowest among three probably fact backpropagation gradients taylor saliency built-in operations tensorflow backpropagation deeplift implemented high-level operations tensorflow. method efﬁcient explanation stage requires forward pass subset sampler. much efﬁcient compared shap lime even training time taken consideration moderate number samples need explained. scale data explained increases training accounts smaller proportion over-all time. thus relative efﬁciency algorithms increases size data set. large movie review dataset dataset movie reviews sentiment classiﬁcation contains labeled movie reviews split training testing. average document length words sentences. study popular classes models sentiment analysis imdb data set. convolutional neural networks shown excellent performance sentiment analysis simple model keras imdb data composed word embedding dimension convolutional layer kernel size ﬁlters max-pooling layer dense layer dimension hidden layers. convolutional dense layers followed relu nonlinearity dropout regularization. review padded/cut words. model achieves accuracy test data close state-of-the-art performance would like words make inﬂuence decision model speciﬁc review. number words ﬁxed experiments. automatic metrics human annotators comparing performance different methods. automatic metrics. introduce automatic metrics—post-hoc accuracy variational-mi quantitatively comparing method model explainers. model explainer outputs subset features speciﬁc sample approximate feed sample model unselected words masked zero paddings. compute accuracy using predict samples test data labeled call post-hoc accuracy computed instancewise feature selection. also approximate mutual information variational lower bound obtained replacing concretely compute liotta hulce shine sterling example brotherly love commitment. hulce plays dominick mildly mentally handicapped young putting minutes younger twin brother liotta plays eugene medical school. baltimore deals issues sibling rivalry unbreakable bond twins child abuse good always winning evil. captivating ﬁlled laughter tears. seen please rent promise you’ll amazed wonderful could unnoticed. sorry thought unrealistic boring long. tired watching gena rowlands long arduous battle crisis experiencing. maybe cinematic value represented important step director pure entertainment value. wish would skipped movie chilling reminder bollywood parasite hollywood. bollywood also tends feed past blockbusters furthering industry. vidhu vinod chopra made movie reasoning cocktail deewar waterfront bring home oscar. turned rookie mistake. even idea title inspired elia kazan classic. original brando shown raising doves symbolism peace. bollywood must move hollywoods shadow needs taken seriously. negative small town threatened child killer lady police ofﬁcer goes pretending friend. becomes emotionally involved murderer psyche begins take beating causing lose focus catching criminal. high voltage excitement solid police work good depiction faulty mind psychotic loser. empirical expectation taken test ˆepm estimation marginal distribution similar ideas used topic modeling deﬁne metrics true distribution available like perplexity human annotation. designing human experiments assume words convey attitude toward movie thus used human infer review sentiment. assumption partially validated given aligned outcomes provided post-hoc accuracy human judges alignment implies consistency sentiment judgement based selected words original model humans. based assumption humans amazon mechanical turk infer sentiment review given words selected explainer. words adjacent other like good keep adjacency interface selected simultaneously. reviews different explainers mixed randomly ﬁnal sentiment review averaged results multiple human annotators. measure whether labels human based selected words align labels provided model terms average accuracy reviews test data set. reviews labeled neutral based selected words selected words contain sentiment selected words contain comparable numbers positive negative words. thus reviews neither positive negative class compute accuracy. call metric human accuracy. really hilarious ﬁlms science ﬁction knock off. lead martians jack nicholson take-off side-splitting. plot clever twist seen enjoyed. movie heart excellent acting all. make popcorn great evening. writers together write different story different genre make movie action adventure sci-ﬁ western mess. sorry movie absolutely stinks. giving awefully high rating. said movies like make think could write movies barely write. movie version judy garland james mason shame version opinion much better. denying barbra streisand’s talent all. good actress brilliant singer. acquainted kris kristofferson’s work therefore can’t pass judgment however movie leaves much desired. paced slowly gratuitous nudity foul language difﬁcult through. however rock music natural would like judy garland version better. barbra kris judge yourself. ﬁrst time second renaissance look boring. look least twice deﬁnitely watch part change view matrix. human people ones started thing compare taylor saliency shap lime. taylor absolute value inner product embedding word gradient model respect word embedding importance score word. saliency norm gradient respect word embedding importance score proposed explainer composed -dimensional word embedding three convolutional layers kernel size ﬁlter size variational family composed word embedding layer size followed average pooling -dimensional dense layer. entry output vector explainer multiplied embedding respective word variational family. another competitive class models sentiment analysis uses hierarchical lstm build simple hierarchical lstm putting layer lstm word embeddings yields representation vector sentence using another lstm encoder sentence vectors. output representation vector second lstm passed class distribution linear layer. lstms word embedding dimension word embedding pretrained large corpus review padded contain sentences. hierarchical lstm model gets around accuracy test data. take sentence single feature group study sentence important review model. input vector used importance scores respectively. number samples default shap. explainer composed -dimensional word embedding followed convolutional layer pooling layer encode sentence. encoded sentence vectors three convolutional layers dense layer sampling weights sentence. variational family also encodes sentence convolutional layer pooling layer. encoding vectors weighted output subset sampler passed average pooling layer dense layer class probability. convolutional layers ﬁlter size kernel size setting interpreted hard attention model employs gumbel-softmax trick. comparison carried three metrics. human accuracy selected sentence review shown human annotators. experimental setups kept above. result shown table achieves best performance across three metrics. table shows explanations model four examples. mnist mnist data contains images handwritten digits form subset mnist data choosing images digits images training images testing. train simple neural network binary classiﬁcation subset achieves accuracy test data set. neural network composed convolutional layers kernel size dense linear layer last. convolutional layers contains ﬁlters respectively followed pooling layer pool size explain sample image image patches neural network model patch contains pixels obtained dividing image patches. patches instead pixels features better visualization. compare explainers including taylor saliency shap lime. saliency taylor importance scores patch norm gradient respect pixels absolute value inner product corresponding pixels respectively. parametrize explainer variational family three-layer two-layer convolutional networks respectively pooling added hidden layer. vector sampled explainer upsampled size multiplied input pixels. results comparison shown table randomly selected examples explanations shown figure observe captures informative patches. figure ﬁgure shows randomly selected ﬁgures validation set. ﬁrst line include original digits second line not. selected patches colored pixel activated blue otherwise. proposed framework instancewise feature selection mutual information method seeks variational approximation mutual information makes gumbel-softmax relaxation discrete subset sampling training. shown efﬁciency superior performance compared methods instancewise feature selection synthetic real data sets.", "year": 2018}