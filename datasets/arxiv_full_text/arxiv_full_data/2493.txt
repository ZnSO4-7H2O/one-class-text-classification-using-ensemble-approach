{"title": "Tight Regret Bounds for Stochastic Combinatorial Semi-Bandits", "tag": ["cs.LG", "cs.AI", "math.OC", "stat.ML"], "abstract": "A stochastic combinatorial semi-bandit is an online learning problem where at each step a learning agent chooses a subset of ground items subject to constraints, and then observes stochastic weights of these items and receives their sum as a payoff. In this paper, we close the problem of computationally and sample efficient learning in stochastic combinatorial semi-bandits. In particular, we analyze a UCB-like algorithm for solving the problem, which is known to be computationally efficient; and prove $O(K L (1 / \\Delta) \\log n)$ and $O(\\sqrt{K L n \\log n})$ upper bounds on its $n$-step regret, where $L$ is the number of ground items, $K$ is the maximum number of chosen items, and $\\Delta$ is the gap between the expected returns of the optimal and best suboptimal solutions. The gap-dependent bound is tight up to a constant factor and the gap-free bound is tight up to a polylogarithmic factor.", "text": "stochastic combinatorial semi-bandit online learning problem step learning agent chooses subset ground items subject constraints observes stochastic weights items receives payoff. paper close problem computationally sample efﬁcient learning stochastic combinatorial semi-bandits. particular analyze ucb-like algorithm solving problem known computationally efﬁcient; prove upper bounds n-step online learning problem step learning agent chooses subset ground items subject combinatorial constraints observes stochastic weights items receives payoff. problem viewed learning variant combinatorial optimization linear objective function binary variables. many classical combinatorial optimization problems linear objectives therefore stochastic combinatorial work study variant stochastic combinatorial semi-bandits learning agent access ofﬂine optimization oracle optimal solution weights items. problem instance cardinality ground maximum number chosen items expected returns optimal best suboptimal solutions. also problem instance instance based existing bandit work relatively easy propose ucb-like algorithm solving problem call algorithm combucb. combucb variant calls oracle optimal solution respect upper conﬁdence bounds weights items. chen recently showed n-step regret combucb stochastic combinatorial semi-bandit main contribution derive upper bounds n-step regret combucb bounds signiﬁcant imo. moreover prove kln) novel lower bounds implemented efﬁciently whenever ofﬂine optimization oracle computationally efﬁcient. close problem computationally sample efﬁcient learning stochastic combinatorial semi-bandits showing combucb properties. problem still open adversarial setting proposed simple algorithm stochastic combinatorial semi-bandits. algorithm motivated therefore call combucb. time combucb consists three steps. first computes upper conﬁdence bound expected weight item reason event happens many items simultaneously. therefore event happens observation counters many items increase. based observation divide regret associated event among many items instead attributing separately item prior work step analysis yields tight upper bounds. paper organized follows. section introduce learning problem algorithm solving section summarize results. section prove upper bound regret combucb. section prove upper bound regret combucb. section prove gap-dependent gap-free lower bounds. section evaluate combucb synthetic problem show n-step regret grows suggested gapdependent upper bound. section compare results prior work. section discuss extensions work. conclude section formally stochastic combinatorial semi-bandit tuple ﬁnite items non-empty feasible subsets probability distribution unit cube borrow terminology combinatorial optimization call ground feasible solution. items ground associated vector stochastic weights e-th entry weight item expected weights items deﬁned ew∼p return choosing solution realization weights maximum number chosen items deﬁned maxa∈θ |a|. i.i.d. sequence weights drawn time learning agents chooses solution based observations weights time gains observes weights chosen items time at}. learning agent interacts environment times goal maximize expected cumulative reward time. agent knew priori optimal action would choose optimal solution computationally sample efﬁcient. following deﬁnitions computational sample efﬁciency. algorithm computationally efﬁcient implemented efﬁciently whenever ofﬂine variant problem solved computationally efﬁciently. algorithm sample efﬁcient achieves optimal regret polylogarithmic factors. based deﬁnitions combucb computationally sample efﬁcient. state result slightly formally below. theorem combucb computationally sample efﬁcient stochastic combinatorial semi-bandit ofﬂine optimization oracle maxa∈θ implemented efﬁciently proof. step combucb calls oracle once remaining operations polynomial therefore combucb guaranteed computationally efﬁcient oracle computationally efﬁcient. combucb sample efﬁcient achieves optimal regret polylogarithmic factors. particular gapdependent upper bound n-step regret combucb theorem matches lower bound proposition constant factor. addition gap-free upper bound theorem matches lower bound proposition factor section prove upper bounds n-step regret combucb. theorem assume gaps suboptimal solutions same. theorem relax assumption. solution results section presented didactic value. proofs simple. illustrate main ideas lead tight regret bounds section theorem stochastic combinatorial semi-bandit suboptimal solutions regret combucb bounded proof theorem relies lemmas. ﬁrst lemma bound regret associated initialization combucb event outside high-probability conﬁdence interval around ˆwtt−. lemma combucb initialized calling procedure init returns variables. ﬁrst variable weight vector single observation e-th marginal second variable number initialization steps plus one. weight vector computed follows. init repeatedly calls oracle vector auxiliary weights initialized ones. item observed weight observed weight item zero. init terminates items without loss generality let’s assume item contained least feasible solution. init guaranteed terminate iterations least entry changes zero call optimization oracle. gap-dependent bounds major improvements best known upper bound n-step regret combucb bound theorem asymptotically tighter bound theorem latter tighter exhaustive mutually exclusive. therefore prove either happens sufﬁces show happen. suppose event happens. assumption happens deﬁnition follows that subptimal items items appear optimal solution. regret combucb bounded follows. theorem stochastic combinatorial semibandit regret combucb bounded proof. claim proved appendix bound regret corresponding events items suboptimal solution observed sufﬁciently often time bound regret deﬁne events events obviously mutually exclusive. next lemma prove events exhaustive event happens. prove claim introduce notation. denote items observed sufﬁciently often time proof. detailed proof appendix idea deﬁne item-speciﬁc variants events get; associate regret respectively. then item order events largest smallest show total regret bounded section improve results section derive upper bounds n-step regret combucb. theorem assume gaps suboptimal solutions identical. theorem relax assumption. step analysis deﬁne cascade inﬁnitely-many mutually-exclusive events bound number times events happen suboptimal solution chosen. events parametrized decreasing sequences constants bounds derived k-path semi-bandit problem illustrated figure items ground path segments feasible paths contains unique items. speciﬁcally path contains items without loss generality assume integer. probability distribution weights items deﬁned follows. weights items path equal. weights items different paths distributed independently. weight item bernoulli random variable mean observation problem equivalent -arm bernoulli bandit whose returns scaled learning agent knows weights items path equal. therefore derive lower bounds problem based existing lower bounds bernoulli bandits gap-dependent lower bound derived class consistent algorithms deﬁned follows. algorithm consistent stochastic combinatorial semi-bandit suboptimal number times solution chosen steps. restriction consistent algorithms without loss generality. particular inconsistent algorithm guaranteed perform poorly semi-bandit therefore cannot achieve logarithmic regret semi-bandits combucb. proposition integer regret consistent algorithm k-path semi-bandit problem bounded proof. detailed proof appendix idea introduce item-speciﬁc variants events geit associate regret events. then item order events largest smallest show total regret bounded figure k-path semi-bandit problem section blue nodes starting points paths respectively. optimal path marked red. grid-path problem section blue nodes starting points paths respectively. optimal path marked red. n-step regret combucb grid-path problem. section evaluate combucb synthetic problem demonstrate regret grows suggested upper bound. experiment stochastic longest-path problem square grid items ground edges grid total. feasible paths grid upper left corner bottom right corner follow directions edges. length paths weight edge drawn i.i.d. bernoulli distribution mean kullback-leibler divergence bernoulli random variables means inequality follows fact problem equivalent -arm bernoulli bandit whose returns scaled therefore bound regret using existing lower bound bernoulli bandits inequality proposed combucb analyzed chen derived upper bound n-step regret combucb. paper show regret combucb factor improvement upper bound chen upper bound tight. also prove gap-free upper bound show nearly tight. comband online stochastic mirror descent follow-the-perturbed-leader geometric resampling three recently proposed algorithms adversarial combinatorial semi-bandits. general osmd achieves optimal regret guaranteed computationally efﬁcient sense section achieve optimal regret computationally efﬁcient. open problem whether adversarial combinatorial semi-bandits solved computationally sample efﬁciently. paper close problem stochastic setting. matroid polymatroid bandits instances stochastic combinatorial semi-bandits. n-step regret combucb problems factor smaller suggested upper bound. however note bound kveton less general applies matroids polymatroids. problem viewed linear bandit solution associated indicator vector learning agent observes weight non-zero entry feedback model clearly informative linear bandits learning agent observes weights. therefore learning problem lower sample complexity. partickln) lower bound ular note combinatorial linear bandits. bound audibert proved adversarial setting. nevertheless applies setting worst-case environment proof stochastic. russo derived upper bounds bayes regret thompson sampling stochastic combinatorial semi-bandits. bounds similar form gap-free upper bound theorem however differ work aspects. first bayes regret different performance metric regret. frequentist perspective much weaker metric. second also derive upper bounds. computational efﬁciency combucb depends computational efﬁciency ofﬂine optimization oracle. oracle inefﬁcient suggest resorting approximations. computationally-efﬁcient oracle returns approximation. combucb straightforwardly modiﬁed call instead original oracle. moreover easy bound regret algorithm measured respect best approximate solution hindsight. thompson sampling often performs better practice straightforward propose variant combucb uses thompson sampling replacing ucbs algorithm sampling posterior mean weights. frequentist analysis regret thompson sampling resembles analysis ucb. therefore believe analysis generalized thompson sampling hypothesize regret resulting algorithm main contribution work derive novel gap-dependent gap-free upper bounds regret combucb ucb-like algorithm stochastic combinatorial semi-bandits. bounds tight polylogarithmic factors. words show combucb sample efﬁcient achieves near-optimal regret. well known combucb also computationally efﬁcient implemented efﬁciently whenever ofﬂine variant problem solved computationally efﬁciently. therefore indirectly show stochastic combinatorial semi-bandits solved computationally sample efﬁciently combucb. theorems proved quite generally subject relatively mild constraints. proofs choose geometric sequences. sufﬁcient purpose. choice likely suboptimal lead larger constants upper bounds necessary. leave problem choosing better future work. leave open several questions interest. instance lower bound derived problem suboptimal solutions gaps. technically speaking upper bound tight family problems. open problem whether upper bound tight general. gergely gabor bartok. efﬁcient algorithm learning semi-bandit feedback. international conference algorithmic learning theory volume lecture notes computer science pages", "year": 2014}