{"title": "Invertible Conditional GANs for image editing", "tag": ["cs.CV", "cs.AI"], "abstract": "Generative Adversarial Networks (GANs) have recently demonstrated to successfully approximate complex data distributions. A relevant extension of this model is conditional GANs (cGANs), where the introduction of external information allows to determine specific representations of the generated images. In this work, we evaluate encoders to inverse the mapping of a cGAN, i.e., mapping a real image into a latent space and a conditional representation. This allows, for example, to reconstruct and modify real images of faces conditioning on arbitrary attributes. Additionally, we evaluate the design of cGANs. The combination of an encoder with a cGAN, which we call Invertible cGAN (IcGAN), enables to re-generate real images with deterministic complex modifications.", "text": "generative adversarial networks recently demonstrated successfully approximate complex data distributions. relevant extension model conditional gans introduction external information allows determine speciﬁc representations generated images. work evaluate encoders inverse mapping cgan i.e. mapping real image latent space conditional representation. allows example reconstruct modify real images faces conditioning arbitrary attributes. additionally evaluate design cgans. combination encoder cgan call invertible cgan enables re-generate real images deterministic complex modiﬁcations. image editing performed different levels complexity abstraction. common operations consist simply applying ﬁlter image example augment contrast convert grayscale. these however low-complex operations necessarily require comprehend scene object image representing. hand would want modify attributes face complex challenging modiﬁcation perform. case order obtain realistic results skilled human image edition software would often required. solution automatically perform non-trivial operations relies generative models. natural image generation strong research topic many years promising results achieved deep learning techniques combined generative modeling generative adversarial networks state-of-the-art approaches image generation. gans especially interesting directly optimized towards generating plausible realistic data opposed models focus image reconstruction loss. additionally gans able explicitly control generated images features conditional extension conditional gans however framework lacks inference mechanism i.e. ﬁnding latent representation input image necessary step able reconstruct modify real images. order overcome limitation paper introduce invertible conditional gans complex image editing union encoder used jointly cgan. model allows real images high-feature space perform meaningful modiﬁcations result explicitly control attributes real image could potentially useful several applications creative processes data augmentation face proﬁling. proposing icgans composed crucial parts encoder cgan. apply model mnist celeba datasets allows performing meaningful realistic editing operations arbitrarily changing conditional information introducing encoder conditional framework compress real image latent representation conditional vector consider several designs training procedures leverage performance obtained available conditional information. evaluating reﬁning cgans conditional position conditional sampling different approaches generative models. among them promising ones recently pushing state-of-the-art highly plausible generated images. ﬁrst variational autoencoders impose prior representation space order regularize constrain model sample however vaes main limitation pixel-wise reconstruction error used loss function causes output images look blurry. second approach generative adversarial nets originally proposed goodfellow gans improved deeper architecture radford latest advances introduced several techniques improve overall performance training gans unsupervised approach disentangle feature representations additionally advanced recent work cgans trains model generate realistic images text descriptions landmarks work considered content framework. baseline work radford’s conditional extension. difference approach prior work also propose encoder given input image obtain representation latent variable conditional vector then modify re-generate original image complex variations. dumoulin donahue also proposed encoder gans non-conditional jointly trained setting. additionally makhzani larsen proposed similar idea paper combining promising results. reed implemented encoder similar fashion approach. paper builds alongside work complementary manner. case analyze deeply encoder including conditional information encoding testing different architectures training approaches. also evaluate unexplored design decisions building cgan. composed neural networks generator discriminator networks iteratively trained competing minimax game. generator aims approximate underlying unknown data distribution pdata fool discriminator whilst discriminator focused able tell samples real generated. convergence want pdata generator distribution. ex∼pdata ez∼pz vector noise sampled known simple distribution framework extended conditional gans quite similar vanilla gans difference that case extra information given real sample conditional information strictly depends real samples model density model order sample generated labels generated data then equation reformulated cgan extension cgan trained allows generate samples using level variations constrained unconstrained. constrained variations modeled directly correlates features data explicitly correlated data itself. then variations data modeled encoded introduce invertible conditional gans composed cgan encoder. even though encoders recently introduced framework ﬁrst ones include leverage conditional information design encoding process. section explain encoder included framework conditional setting. section introduce approach reﬁne cgans aspects conditional position conditional sampling. model architecture described section encoder generator framework capability real image latent representation overcome problem train encoder/inference network approximately inverses mapping inversion would allow latent representation real image then would able explore latent space interpolating adding variations would result variations generated image combined cgan latent representation obtained explicitly controlled variations added input image conditional information call combination invertible cgan mapping inverted input image reconstruction. figure example trained icgan used. approach consists training encoder cgan trained similarly considered reed case however encoder composed sub-encoders encodes image encodes image train generator create dataset generated images latent vectors minimize squared reconstruction loss initially used generated images conditional information training. however found generated images tend noisier real ones speciﬁc case could improve directly training real images labels dataset pdata although might seem completely independent adopt different strategies make interact leverage conditional information single encoder shared layers outputs. figure scheme trained icgan composed encoder cgan generator. encode real image latent representation attribute information apply variations generate modiﬁed image recently dumoulin donahue proposed different approaches train encoder framework. interesting approaches consists jointly training encoder discriminator generator. although approach promising work completely independent articles focuses another direction since consider encoder conditional setting. consequently implemented aforementioned approach performs nearly equally strategy. consider main design decisions concerning cgans. ﬁrst optimal conditional position generator discriminator which knowledge previously addressed. secondly discuss best approach sample conditional information generator. conditional position cgan conditional information vector needs introduced generator pdata always concatenated ﬁlter dimension input level discriminator different authors insert different parts model expect earlier positioned model better since model allowed learning interactions experiments regarding optimal position detailed section conditional sampling types conditional information ﬁrst trivially sampled pdata used training discriminator real image associated label second sampled serves input generator along latent vector generate image sampled using different approaches direct interpolation interpolate label vectors training reasoning behind approach interpolations belong label distribution sampling training pdata directly real labels training pdata. gauthier pointed unlike previous approaches method could overﬁt model using conditional information reproduce images training set. however likely occur conditional information extent unique image. case attributes image binary attribute vector could describe varied large enough subset images preventing model overﬁtting given kernel density estimation direct interpolation different ways interpolate nevertheless interpolation mostly suitable attribute information composed real vectors binary ones. case binary conditional information datasets used paper directly interpolating binary vectors would create plausible conditional information interpolated vector would belong pdata using kernel density estimation would make sense either binary labels would fall corners hypercube. therefore directly sample pdata. conditional work paper based torch implementation dcgan recommended conﬁguration dcgan trains adam optimizer learning rate mini-batch size epochs. output image size used baseline also train cgan matching-aware discriminator method reed figure show overview architecture generator discriminator cgan. detailed description model table encoder simplicity show architecture encoders ones give best performance. batch normalization non-linear activation functions removed last layer guarantee output distribution similar additionally trying different conﬁgurations replaced last convolutional layers fully connected layers encoder yields lower error. training conﬁguration used cgan model. image datasets different complexity variation mnist celebfaces attributes mnist digit dataset grayscale images composed training images test images. sample centered image labeled class digit celeba dataset composed face colored images attribute binary vectors. aligned cropped version scale images also ofﬁcial train test partitions training testing. original attributes ﬁlter clear visual impact generated images leaves total attributes. evaluate quality generated samples datasets. however quantitative evaluation performed celeba only considerably complex mnist. goals experiment two. first evaluate general performance cgan attribute predictor network celeba dataset. second test impact adding different layers cgan anet make quantitative evaluation similar manner salimans inception model output given anet good indicator generator ability model them. words predicted anet attributes closer original attributes used generate image expect generator successfully learned capability generate images considering semantic meaning attributes. therefore generator create images conditioned attribute vectors pdata make anet predict them. using anet output build confusion matrix attribute compute mean accuracy f-score test model inserted optimal position generator discriminator. table quantitative cgan evaluation depending inserted position. ﬁrst shows results obtained real celeba images indication anet predictions subject error. table cgans successfully learned generate visual representations conditional attributes overall accuracy best accuracy achieved inserting ﬁrst convolutional layer discriminator input level generator. thus going conﬁguration icgan. accuracy f-score similar long inserted last convolutional layers case performance considerably drops especially generator. then results reinforce initial intuition added early stage model allow learning interactions experiment prioritize visual quality reconstructed samples evaluation criterion. among different encoder conﬁgurations section ind-cond yield similar qualitative performance slightly superior. comparison different conﬁgurations shown figure figure focus reconstructed samples. another level fact generator able encoder reconstruct unseen images test shows cgan generalizing suggests suffer overﬁtting i.e. memorizing reproducing training samples. additionally compare different encoder conﬁgurations quantitative manner using minimal squared reconstruction loss criterion. encoder trained minimizing respect latent representations conditional information then quantitatively evaluate different model architectures using metric test celeba generated images. encoder yields lowest also followed closely ind-cnd worst case furthermore interesting property minimizing loss based latent space instead pixel-wise image reconstruction reconstructed images tend accurately keep high-level features input image detriment local details exact position hair eyes face. consequently latent space based encoder invariant local details making interesting approach encoding purposes. example notice reconstructions last celeba samples figure occluded part face hand. another advantage respect element-wise encoders based reconstructions look blurry. order test model able correctly encode re-generate real image preserving main attributes take real samples mnist celeba test sets reconstruct modiﬁcations conditional information result procedure shown figure show subset celeba attributes image clarity. that mnist able hand-written style real unseen digits replicate style digits. hand celeba reconstructed faces generally match speciﬁed attribute. additionally noticed faces uncommon conditions likely noisy. furthermore attributes mustache often fail generated especially women samples might indicate generator limited unusual attribute combinations. manipulating latent space latent feature representation conditional information learned generator explored beyond encoding real images randomly sampling order linearly interpolate pairs reconstructed images celeba test interpolated faces plausible transition faces smooth demonstrating icgan learned manifold also consistent interpolations. then also good indicator model generalizing face representation properly directly memorizing training samples. addition perform figure attribute transfer pairs faces. infer latent representation attribute information real faces test swap faces re-generate them. previously noticed results suggest encodes pose illumination background information tends represent unique features face. figure result applying icgan real images mnist celeba real image encoded latent representation conditional information decoded image. every modify column obtain variations. figure different ways exploring latent space. take real images linearly interpolate obtain gradual transformation face another. take real images reconstruct swap attribute information them. introduce encoder conditional setting within framework model call invertible conditional gans solves problem gans lacking ability infer real samples latent representation also allowing explicitly control complex attributes generated samples conditional information also reﬁne performance cgans testing optimal position conditional information inserted model. found generator added input level whereas discriminator works best ﬁrst layer. additionally evaluate several ways training encoder. training independent encoders encoding another encoding proven best option experiments. results obtained complex face dataset celeba satisfactory promising. references gregor danihelka graves jimenez rezende wierstra draw recurrent neural network image generation international conference machine learning radford metz chintala unsupervised representation learning deep convolutional generative adversarial networks international conference learning representations goodfellow pouget-abadie mirza warde-farley ozair courville bengio generative adversarial nets advances neural information processing systems ghahramani welling cortes lawrence weinberger eds. curran associates inc. available http//papers.nips.cc/paper/-generative-adversarial-nets.pdf rezende mohamed wierstra stochastic backpropagation approximate inference deep generative models proceedings international conference machine learning vol. kingma rezende mohamed welling semi-supervised learning deep generative models proceedings neural information processing systems available http//arxiv.org/abs/. salimans goodfellow zaremba cheung radford chen improved techniques training gans neural information processing systems available http//arxiv.org/abs/. chen duan houthooft schulman sutskever abbeel infogan interpretable representation learning information maximizing generative adversarial nets neural information processing systems available http//arxiv.org/abs/. larsen sønderby winther autoencoding beyond pixels using learned similarity metric proceedings international conference machine learning available http//arxiv.org/abs/. reed akata logeswaran schiele generative adversarial text image synthesis international conference machine learning available http//arxiv.org/abs/. gauthier conditional generative adversarial nets convolutional face generation class project stanford convolutional neural networks visual recognition winter semester available http//csn.stanford.edu/reports/jgauthie_ﬁnal_report.pdf", "year": 2016}