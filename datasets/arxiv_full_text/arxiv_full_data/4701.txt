{"title": "A Rigorously Bayesian Beam Model and an Adaptive Full Scan Model for  Range Finders in Dynamic Environments", "tag": ["cs.AI", "cs.LG"], "abstract": "This paper proposes and experimentally validates a Bayesian network model of a range finder adapted to dynamic environments. All modeling assumptions are rigorously explained, and all model parameters have a physical interpretation. This approach results in a transparent and intuitive model. With respect to the state of the art beam model this paper: (i) proposes a different functional form for the probability of range measurements caused by unmodeled objects, (ii) intuitively explains the discontinuity encountered in te state of the art beam model, and (iii) reduces the number of model parameters, while maintaining the same representational power for experimental data. The proposed beam model is called RBBM, short for Rigorously Bayesian Beam Model. A maximum likelihood and a variational Bayesian estimator (both based on expectation-maximization) are proposed to learn the model parameters.  Furthermore, the RBBM is extended to a full scan model in two steps: first, to a full scan model for static environments and next, to a full scan model for general, dynamic environments. The full scan model accounts for the dependency between beams and adapts to the local sample density when using a particle filter. In contrast to Gaussian-based state of the art models, the proposed full scan model uses a sample-based approximation. This sample-based approximation enables handling dynamic environments and capturing multi-modality, which occurs even in simple static environments.", "text": "tinne laet joris schutter herman bruyninckx department mechanical engineering katholieke universiteit leuven celestijnenlaan heverlee belgium paper proposes experimentally validates bayesian network model range ﬁnder adapted dynamic environments. modeling assumptions rigorously explained model parameters physical interpretation. approach results transparent intuitive model. respect state beam model paper proposes diﬀerent functional form probability range measurements caused unmodeled objects intuitively explains discontinuity encountered state beam model reduces number model parameters maintaining representational power experimental data. proposed beam model called rbbm short rigorously bayesian beam model. maximum likelihood variational bayesian estimator proposed learn model parameters. furthermore rbbm extended full scan model steps ﬁrst full scan model static environments next full scan model general dynamic environments. full scan model accounts dependency beams adapts local sample density using particle ﬁlter. contrast gaussian-based state models proposed full scan model uses sample-based approximation. sample-based approximation enables handling dynamic environments capturing multimodality occurs even simple static environments. probabilistic approach inaccuracies embedded stochastic nature model particularly conditional probability density representing measurement process. vital importance types inaccuracies aﬀecting measurements incorporated probabilistic sensor model. inaccuracies arise sensor limitations noise fact complex environments represented perceived limited way. dynamic nature environment particular important source inaccuracies. dynamic nature results presence unmodeled possibly moving objects people. paper proposes probabilistic range ﬁnder sensor model dynamic environments. range ﬁnders widely used mobile robotics measure distances objects environment along certain directions relative sensor. derive sensor model form suitable mobile robot localization i.e. indicates measured range position mobile robot environment map. presented model however useful applications range sensors well. first paper derives probabilistic sensor model beam range ﬁnder i.e. beam model. particular paper gives rigorously bayesian derivation using bayesian network model stating model assumptions giving physical interpretation model parameters. obtained model named rbbm short rigorously bayesian beam model. innovations presented approach introduce extra state variables positions unmodeled objects probabilistic sensor model marginalize extra state variables total probability estimation. latter required extra variables increase computational complexity state estimation applications estimating position unmodeled objects primary interest. summary marginalization avoids increase complexity infer probability distributions maintaining modeling dynamic nature environment. contain measured distances beam angles respectively. full scan model accounts dependency beams adapts local sample density using particle ﬁlter. contrast gaussian-based state models proposed full scan model uses sample-based approximation. sample-based approximation allows capture multi-modality full scan model shown occur even simple static environments. paper organized follows. section gives overview related work. section presents bayesian beam model range ﬁnders founded bayesian networks rbbm mathematically derives analytical formula probabilistic sensor model clearly stating assumptions provides useful insights obtained beam model shows obtained analytical sensor model agrees proposed bayesian network. section presents maximum likelihood variational bayesian estimator learn model parameters. section model parameters rbbm learned experimental data resulting model compared state beam model proposed thrun burgard called thrun’s model. section extends rbbm adaptive full scan model dynamic environments. section discusses obtained rbbm adaptive full scan model compares previously proposed range ﬁnder sensor models. state augmentation latent states e.g. position moving objects people environment included estimated states. wang thorpe thrun developed algorithm ‘slam datmo’ short slam detection tracking moving objects. state augmentation however often infeasible since computational complexity state estimation increases exponentially number independent state variables estimate. closely related solution consists adapting according changes environment. since approaches assume environment almost static unable cope real dynamics populated environments recent related approach proposed wolf sukhatme maintains coupled occupancy grids environment static moving objects account environment dynamics. probabilistic approaches extent robust unmodeled dynamics since able deal sensor noise. approaches however sensor noise reﬂect real uncertainty unmodeled dynamics environment. therefore second approach dealing dynamic environments adapt sensor model correctly reﬂect situations measurements aﬀected unmodeled environment dynamics. show approaches capable model noise average approaches work reliably occasional sensor blockage inadequate situations ﬁfty percent measurements corrupted. handle measurement corruption eﬀectively approach based outlier detection used. approach uses adapted sensor model explained previous paragraph. idea investigate cause sensor measurement reject measurements likely aﬀected unmodeled environment dynamics. h¨ahnel schulz burgard h¨ahnel triebel burgard thrun studied problem performing slam environments many moving objects using algorithm ﬁltering aﬀected measurements. able acquire maps environment conventional slam techniques failed. propose diﬀerent kinds ﬁlters entropy ﬁlter suited arbitrary sensor distance ﬁlter designed proximity sensors. ﬁlters detect whether measurement corrupted discard sensor readings resulting objects contained map. paper focuses range ﬁnders whose physical principle emission sound light wave followed recording echo. highly accurate sensor models would include physical parameters surface curvature material absorption coeﬃcient. parameters however diﬃcult estimate robustly unstructured environments. hence literature typically relies purely basic geometric models. range ﬁnder sensor models available literature traditionally divided three main groups feature-based approaches beam-based models correlation-based methods. feature-based approaches extract features range scan match features contained environmental model. beam-based models also known cast models consider distance measurement along beam separate range measurement. models represent one-dimensional distribution distance measurement parametric function depends expected range measurement respective beam directions. addition models closely linked geometry physics involved measurement process. often result overly peaked likelihood functions underlying assumption independent beams. last group range ﬁnder sensor models correlation-based methods build local maps consecutive scans correlate global map. simple eﬃcient likelihood ﬁeld models point model related correlation-based methods. plagemann kersting pfaﬀ burgard nicely summarize advantages drawbacks diﬀerent range ﬁnder sensor models. range ﬁnder sensor models also classiﬁed according whether discrete geometric grids continuous geometric models moravec proposed non-gaussian measurement densities discrete grid possible distances measured sonar; likelihood measurements computed possible positions mobile robot given time. even simpliﬁed models approach turned computationally expensive real-time application. therefore proposed beam model consisting mixture physical causes measurement object object modeled map. last cause accounts dynamic nature environment. analogous mixture adds physical causes sensor failure unknown cause resulting ‘max-range’ measurement ‘random’ measurement respectively. thrun pfaﬀ continuous model choset present discrete analog mixture taking account limited resolution range sensor. pfaﬀ extend basic mixture model monte carlo localization. overcome problems combination limited representational power peaked likelihood accurate range ﬁnder propose adaptive likelihood model. likelihood model smooth global localization peaked tracking. recently diﬀerent researchers tried tackle problems associated beam-based models caused independence assumptions beams. plagemann propose sensor model full scan. model treats sensor modeling task non-parametric bayesian regression problem solves using gaussian processes. claimed gaussian beam processes combine advantages beam-based correlation-based models. underlying assumption measurements jointly gaussian distributed gaussian beam processes suited take account non-gaussian uncertainty dynamic nature environment. alternative approach handle overly-peaked likelihood functions resulting traditional beam models proposed pfaﬀ plagemann burgard locationdependent full scan model takes account approximation error sample-based representation explicitly models correlations individual beams introduced pose uncertainty. measurements assumed jointly gaussian distributed plagemann proposed. plagemann represent covariance matrix parametrized covariance function using gaussian processes whose parameters learned data pfaﬀ learn full covariance matrix less restrictive manner. despite modeled correlation beams measurements still assumed jointly gaussian distributed limits applicability dynamic environments. paper proposes rigorously bayesian modeling probabilistic range sensor beam model dynamic environments referred rbbm. similar work thrun pfaﬀ sensor model derived continuous geometry. unlike previous models thrun pfaﬀ choset mixture components founded bayesian modeling. modeling makes probabilistic graphical models case bayesian networks. graphical models provide simple visualize structure probabilistic model used design motivate models inspection graph insights model including conditional independence properties obtained. next inspired adaptive full scan models literature rbbm extended adaptive full scan model. underlying sample-based approximation full scan model contrast gaussianbased approximation proposed pfaﬀ plagemann enables handling dynamic environments capturing multi-modality occurs even simple static environments. model probabilistic beam model dynamic environments bayesian network. introduce extra state variables positions unmodeled objects probabilistic sensor model prevent exponential increase computational complexity state estimation extra variables variables marginalized total probability estimation. marginalization avoids increasing complexity infer conditional probability distributions interest maintains modeling dynamic nature environment. section explains extra state variables physically relevant section explains marginalization extra state variables. section summarizes assumptions approximations. finally section provides useful insights obtained beam model called rbbm derivation. section shows obtained analytical expression rbbm agrees proposed bayesian network means monte carlo simulation. figure bayesian network probabilistic measurement model supplemented deterministic parameters represented smaller solid nodes. compact representation plates used. plate represents number indicated lower right corner independent nodes single example shown explicitly. bayesian networks graphically represent probabilistic relationships variables mathematical model structure facilitate probabilistic inference computations variables bayesian network deﬁned follows nodes associated random variable connected directed edges forming directed acyclic graph discrete random variable ﬁnite mutually exclusive states; random variable parents conditional probability distribution although deﬁnition bayesian networks refer causality requirement directed edges represent causal impact well-known structuring variables reasoning uncertainty construct graph representing causal relations case graphical models also known generative models since capture causal process generating random variables. application range sensor ideally measures distance closest object map. unknown number unmodeled objects possibly preventing measurement closest object however present environment. depending position unmodeled object along measurement beam unmodeled object occludes not. unmodeled object occludes located front closest object contained map. total number occluding objects unmodeled objects. positions occluding objects measurement beam denoted {xki}i=k. occluded unmodeled object range sensor ideally measure occl position closest occluding object. following extra state variables included bayesian model discrete random variable indicating unknown number unmodeled objects environment; continuous random variable position unmodeled object measurement beam; discrete random variable indicating number objects occluding measurement map; continuous random variable position occluding object measurement beam; occl continuous random variable indicating ideal range measurement closest occluding object. fig. shows bayesian network probabilistic range ﬁnder sensor model variables occur probabilistic sensor model extra variables j}j=n {xki}i=k occl model parameters directed edges graphical model represent causal relationships variables. example unambiguously determine measured range perfect sensor absence unmodeled occluding objects. number occluding objects depends total number unmodeled objects positions respect measurement beam. also causal impact larger expected measurement higher possibility unmodeled objects occluding modeled object corresponding expected measurement. positions along measurement beam occluding objects equal positions unmodeled objects occluding map. therefore random variables inﬂuenced also since objects occluding positions along measurement beam limited interval causal dependency ideal measurement occl occluding object position occluding object closest sensor occl depends positions occluding objects. finally measurement also depends ideal measurement occluding object occl number occluding objects case occlusion inferring probability distribution extra state variables often infeasible. marginalization extra state variables occl avoids increase complexity estimation problem still takes account dynamic nature environment. marginalization requires modelling conditional probability tables conditional probability distributions random variable conditionally parents. measure degree appearance unmodeled objects. precisely probability least unmodeled object present. indicated fig. fig. shows resulting distribution secondly assume nothing known priori position unmodeled objects along measurement beam. hence unmodeled object’s position assumed uniformly distributed measurement beam next expression needed conditional probability i.e. probability unmodeled objects occluding unmodeled object occluding located along measurement beam front closest object map. straightforward show binomial distribution furthermore analytical expression necessary. positions occluding objects equal positions unmodeled objects occluding shown fig. words equals unmodeled object occluding i.e. range ﬁnders truly quite deterministic since measurements great extent explainable underlying physical phenomena specular reﬂections inference underlying phenomena complex therefore costly model. underlying phenomena additional uncertainty measurement uncertainty sensor position inaccuracies world model inaccuracies sensor itself. disturbances measurements unmodeled objects environment included. capture additional uncertainty additional measurement noise added. taking account disturbances unmodeled objects unexplainable measurements sensor failures physical reason expect mean value true measurements deviates expected measurement true measurements distributed asymmetrically around mean. therefore symmetrical noise mean value zero added. facts justify modeling measurement noise normal distribution normal distribution maximizes information entropy among distributions known mean variance making natural choice underlying distribution data summarized terms sample mean variance; underlying phenomena assumed small independent eﬀect measurement central limit theorem states certain conditions large number random variables approximately normally distributed. measurement noise modeled zero mean gaussian standard deviation conditional probability main cases ﬁrst occlusion present sensor observing second case sensor observes occluding object. included bayesian network fig. equation shows conditional probability represents probability perfect measurement nearest occluding object occl i.e. probability nearest occluding object located occl. case objects along measurement beam located occl measured objects along measurement beam located behind occluding object expressed probabilities ﬁrst term right hand side gaussian distribution around ideal measurement multiplied probability occlusion second term integration possible positions occluding object scaled gaussian distribution centered ideal measurement occluding object scaling factor represents probability occluding objects located occl measured. follows scaling factor written approximations made obtain beam model integral scaled gaussian distributions however cannot obtained analytically. therefore ﬁrst approximation marginalization made neglecting noise range measurement case occlusion i.e. using approximation second term right hand side becomes fig. shows quality approximation integral compared ﬁnite approximation small step size. approximation introduces discontinuity around using proposed approximation integral resulting beam model occasionally range ﬁnders produce unexplainable measurements caused phantom readings sonars bounce walls suﬀer cross-talk furthermore additional uncertainty measurements caused uncertainty sensor position inaccuracies world model inaccuracies sensor itself. unexplainable measurements modeled using uniform distribution spread entire measurement range mixture representation shows four possible causes range measurement unmodeled object unknown cause resulting random measurement sensor failure resulting maximum reading measurement. derivation section shows position occluding objects uniformly distributed sensor ideally measured object environment fig. perfectly reasonable considering assumption uniformly distributed unmodeled objects. occl fig. probability occluding objects located occl measured. first probability independent location ideally measured object environment agrees intuition since expects measurements caused occluding objects independent measurement case occlusion. second probability sensing unmodeled objects decreases range expected. easily explained following thought experiment objects present likelihood perception ﬁeld range ﬁnder ﬁrst object closest range sensor sensor likely measure ﬁrst object. measure second object second object probability measuring feature therefore integral scaled gaussian phit decreases expected range. easily explained since probability occluded decreases feature located away. finally discontinuity rbbm shown caused approximation made since state range sensors accurate neglecting measurement noise measurement occluding object acceptable approximation. also shown experiments presented section respect state beam model thrun model proposed here diﬀerent functional form probability range measurements caused unmodeled objects intuitive explanation discontinuity encountered cited paper reduction number model parameters. thrun poccl exponential distribution. exponential distribution results following underlying assumptions unmodeled objects equally distributed environment beam reﬂected constant probability range. last assumption equals assuming probability unmodeled object located certain distance constant. assumption fails capture number unmodeled object ﬁnite probable limited number unmodeled objects huge number them. also assume unmodeled objects equally distributed environment assume number unmodeled objects geometrically distributed capturing ﬁniteness number unmodeled objects higher probability smaller number unmodeled objects. modeling ﬁniteness number unmodeled objects higher probability smaller number unmodeled objects results quadratic decay poccl instead exponential decay poccl found thrun al.. stated previous paragraph discontinuity rbbm caused approximation. thrun’s model considers rate decay poccl independent probability occlusion shown depend parameter therefore rbbm fewer parameters thrun’s model. goal section show means monte carlo simulation rbbm agrees bayesian network fig. monte carlo simulation approximate inference method bayesian networks. idea behind monte carlo simulation draw random conﬁgurations network variables j}j=n {xki}i=k occl suﬃcient number times. random conﬁgurations selected ancestral sampling i.e. successively sampling figure comparison obtained rbbm ﬁnite approximation small stepsize normalized histogram samples obtained monte carlo simulation proposed bayesian network zmax zmax known sensor characteristic. parameters clear physical interpretation; standard deviation zero mean gaussian measurement noise governing phit deﬁned probability occluded probabilities range ﬁnder returns unexplainable measurement maximum reading respectively. physical interpretation parameters allows initialize hand plausible values. however another ﬂexible learn model parameters actual data containing measurements {zι}ι=j corresponding states {xι}ι=j furthermore learning model parameters also validation proposed analytical model learning algorithm succeeds ﬁnding model parameters resulting distribution gives good explanation data analytical model likely agree well reality. paper diﬀerent estimators maximum likelihood variational bayesian estimator presented learn model parameters data. section derives maximum likelihood estimator known approach problem reformulated rbbm. estimator provides point estimates parameters leads overﬁtting since likelihood function generally higher complex model structures. therefore propose variational bayesian estimator section approach learning parameters beam models. estimator fully bayesian learning approach; priors unknown parameters included complex models punished full probability distribution parameters obtained. using mixture representation rbbm estimation problem formulated ﬁnding estimates parameters provided constraint included. general known four possible causes actually caused measurements. case estimation problem diﬃcult lacks closed-form solution. however corresponding causes measurements known solution easily obtained closed form. therefore introduce latent correspondence variable representing unknown cause using -of-s representation. elements give probability measurement result s’th cause. graphical representation mixture formulation including latent correspondence variable shown fig. although estimation problem lacks closed-form solution unknown correspondences expectation-maximization approach solve problem iterating expectation maximization step. expectation step calculates expectation correspondence variables maximization step computes model parameters expectations. estimator provides point estimates parameters sensitive overﬁtting therefore propose variational bayesian estimator approach learning parameters beam models. estimator fully bayesian learning approach; priors unknown parameters included complex models punished full probability distribution parameters obtained. estimator little computational overhead compared estimator bayesian approach attempts integrate possible values uncertain quantities rather optimize approach quantity results integrating latent variables prior latent variables parameters model. integrating parameters penalizes models degrees freedom since models priori model larger range data sets. property bayesian integrations known occam’s razor since favors simpler explanations data complex ones unfortunately computing marginal likelihood intractable almost models interest. variational bayesian method constructs lower bound marginal likelihood attempts optimize bound using iterative scheme intriguing similarities standard algorithm. emphasize similarity ml-em algorithm based variational bayesian inference called vb-em. introducing distribution latent variables complete marginal kl-divergence since kl-divergence always greater equal zero lower bound marginal likelihood. maximizing lower bound respect distribution equivalent minimizing kl-divergence. possible choice allowed maximum lower bound would occur kl-divergence vanishes i.e. equal posterior distribution working true posterior distribution however often intractable practice. possible approximate treatment considers restricted family distributions seeks member family minimizing kl-divergence. variational bayesian treatment uses factorized approximation case latent variables parameter indicates optimality. expressions give explicit solution factors optimal distribution factors depends expectation computed respect factor. therefore iterative procedure similar cycles factors replaces turn revised optimal estimate used. introducing priors since variational bayesian approach fully bayesian approach priors introduced parameters remark variational bayesian estimator standard deviation governing phit estimated also means referred since analysis considerably simpliﬁed conjugate prior distributions used dirichlet prior chosen mixing coeﬃcients gives eﬀective prior number observations associated component mixture. therefore value small posterior distribution mainly inﬂuenced data rather prior. eﬀective number data points associated cause mean eﬀective data points associated cause covariance eﬀective data points associated cause similarity e-step em-algorithm step calculating responsibilities variational bayesian inference known variational e-step. maximization step accordance graphical representation fig. shown variational posterior factorizes ﬁrst optimal factor given dirichlet distribution update equations analogous m-step em-algorithm maximum likelihood solution therefore known variational m-step. variational m-step computes distribution parameters rather point estimate case maximum likelihood estimator. distribution parameters allows calculate predictive density goal section threefold learn model parameters rbbm experimental data compare results proposed ml-em vb-em estimator compare results proposed estimators learning approach thrun’s model proposed thrun experimental setups diﬀerent application areas robotics used. data ﬁrst learning experiment gathered typical mobile robot application robot equipped laser scanner travelling oﬃce environment. data second learning experiment gathered typical industrial pickand-place operation human populated environment. laser scanner mounted industrial robot make aware people unexpected objects robot’s workspace. well learned model explains experiment learned continuous compared discrete experimental data learned ﬁrst discretized using bins experimental pdf. quantize diﬀerence learned figure data second learning experiment reported thrun data consist series measurements obtained mobile robot traveling typical oﬃce environment. measurements measurements centered around diﬀerent expected ranges selected. ﬁrst learning experiment experimental data reported thrun used. data consists series measurements obtained mobile robot traveling typical oﬃce environment. measurements measurements centered around diﬀerent expected ranges selected. obtained sets diﬀerent expected ranges shown fig. parameters learning algorithms listed table fig. table show results ml-em vb-em estimators rbbm compared results estimator thrun’s model sets. results obtained running learning algorithms iteration steps. proposed ml-em vb-em estimator outperform ml-em estimator thrun’s model studied data sets. despite reduced number parameters rbbm compared thrun’s model rbbm least representational power. table discrete kl-divergence square root hellinger distance ﬁrst learning experiment training results ml-em vb-em estimators rbbm ml-em estimator thrun’s model data second learning experiment gathered execution typical industrial pick-and-place operation human-populated environment. sick laser scanner mounted ﬁrst axis industrial kuka robot laser scanner provides measurements robot environment therefore people unexpected objects robot’s workspace. processing measurements ﬁrst step towards making industrial robots aware possibly changing environment moving robots cages. figure build robot’s static environment i.e. without unexpected objects people moving around rotating ﬁrst axis industrial robot. safety reasons people allowed move inside safety region therefore measurements smaller discarded. studied expected ranges second learning experiment range steps indicated ﬁgure selected ranges region. ﬁrst step build robot’s static environment i.e. without unexpected objects people moving around rotating ﬁrst axis industrial robot. next robot performs pick-and-place operation number people walking around random robot environment. diﬀerent sets measurements acquired diﬀerent number people. similar ﬁrst learning experiment measurements selected centered around diﬀerent expected ranges acquired data. studied expected ranges second learning experiment range steps safety reasons people allowed move closer robot i.e. safety region therefore measurements smaller discarded. table shows kullback leibler divergence hellinger distance averaged studied expected range diﬀerent measurements running ml-em vb-em estimators rbbm estimator thrun’s model results obtained running learning algorithms iteration steps. table discrete kl-divergence square root hellinger distance averaged studied expected range diﬀerent measurements second learning experiment. distances training results ml-em vb-em estimators rbbm ml-em estimator thrun’s model ﬁrst column indicates number people walking around environment particular measurements. proposed ml-em vb-em estimator outperform ml-em estimator thrun’s model studied data sets. despite reduced number parameters rbbm compared thrun’s model rbbm least representational power. section extends rbbm adaptive full scan model dynamic environments; adaptive since automatically adapts local density samples using samplebased representations; full scan since model takes account dependencies between individual beams. many applications using range ﬁnder posterior approximated ﬁnite samples peaked likelihood function associated range ﬁnder problematic using ﬁnite samples. likelihood evaluated samples approximately distributed according posterior estimate. basic sensor models typically assume estimate known exactly assume samples corresponds true value. assumption however valid limit inﬁnitely many samples. otherwise probability value exactly corresponds true location virtually zero. consequence peaked likelihood functions adequately model uncertainty ﬁnite sample-based representation posterior furthermore basic range ﬁnder model typically results even peaked likelihood models especially using large number beams measurement multiplication probabilities. practice problem figure comparison results ml-em vb-em estimators rbbm results maximum likelihood estimator diﬀerent expected ranges diﬀerent number people populating robot environment. peaked likelihoods dealt various ways sub-sampling measurement introducing minimal likelihoods beams; inﬂating measurement uncertainty; means regularization resulting likelihoods. solutions satisfactory however since additional uncertainty sample-based representation known advance. additional uncertainty strongly varies number samples uncertainty estimate proposes dynamically adapt number samples means sampling peaked likelihoods however might result huge number samples. lenser veloso thrun burgard dellaert ensure critical mass samples located important parts state space sampling observation model. sampling observation model however often possible approximate inaccurate way. pfaﬀ introduced adaptive beam model dynamic environments explicitly takes location uncertainty sample-based representation account. compute additional uncertainty sample-based representation using techniques density estimation. evaluating likelihood function sample consider certain region around sample depending sample density location. then depending area covered sample variance gaussian governing beam model calculated sample. result beam model automatically adapts local density samples. location dependent model results smooth likelihood function global localization peaked function position tracking without changing number samples. plagemann pfaﬀ showed considering region around samples individual beams become statistically dependent. degree dependency depends geometry environment size location considered region. beam models rbbm implicitly assume however beams independent {zb}b=b {θb}b=b vectors containing measured ranges angles diﬀerent beams respectively; range measured beam angle total number beams instance rbbm neglecting dependency beams resulting likelihoods overly peaked. models taking account dependencies beams consider full range scan therefore called full scan models full scan models proposed plagemann pfaﬀ assume beams range scan jointly gaussian distributed. oﬀ-diagonal elements covariance matrix associated gaussian distribution represent dependency. learn model parameters methods draw samples region around sample perform ray-casting using samples. plagemann train gaussian process models full scan pfaﬀ directly provide maximum likelihood estimate mean covariance gaussian. mann pfaﬀ cannot handle multi-modality. therefore sample-based method obtaining adaptive full scan model beam model able handle multi-modality proposed. section extends adaptive full scan model dynamic environments taking account non-gaussian model uncertainty. distribution representing probability element environment environment modeled circular region around since section consider dynamics environment component rbbm used phit marginalization environment introduces dependencies measurements measurement vector environment explained above depends sample density around sample consideration. pfaﬀ proposed circular region diameter weighted euclidean distance angular diﬀerence. like plagemann pfaﬀ approximation likelihood estimated online sample simulating complete range scans locations drawn using given environment. contrary multivariate gaussian approximation proposed plagemann pfaﬀ propose sample-based approximation able handle multi-modality. sampling environment immediately results sample-based approximation figure panorama taken sick range ﬁnder mounted kuka industrial robot. environment consists rectangular ‘room’ object middle. show even simple static environment presented sample-based full scan model outperforms gaussian-based state models. bad. smooth undesired bumpy behavior limited number samples measurement noise governing phit artiﬁcially increased depending size multiplying factor simple environment consisting rectangular ‘room’ object middle used show marginalization obtain true likelihood introduces dependencies beams also multi-modality. results local uncertainty xy−position rotational uncertainty obtain reference sick range ﬁnder used take large number measurements random locations sampled allow exact positioning sick placed kuka industrial robot. sick range ﬁnder connected laptop controls motion kuka industrial robot network using corba-facilities open robot control software orocos simpliﬁed environment built simulate complete range scans needed construct full scan model. marginal selected beams studied detail. marginal likelihoods selected beam using proposed sample-based approximation gaussian approximation proposed pfaﬀ compared fig. histogram measurements selected beam ﬁgure clearly shows multi-modality likelihood caused dependency beams. contrast gaussian-based state full scan model proposed sample-based approximation able handle multi-modality range ﬁnder data. fig. shows diﬀerence beams experimentally obtained cumulative marginal gaussian-based sample-based approximation beams. mean diﬀerence experimental data sample-based approximation times smaller diﬀerence gaussian-based approximation even simple static environment fig. small adaptive beam model proposed pfaﬀ suited dynamic environments since uses four component mixture beam model date however adaptive full scan likelihood models pfaﬀ plagemann adapted dynamic environments. assumption beams jointly gaussian distributed unable capture nongaussian uncertainty environment dynamics prevents straightforward extension dynamic environments. contrast sample-based approximation full scan likelihood proposed section extended include environment dynamics. replace phit full mixture fig. fig. compare marginals selected beams obtained adaptive full scan model dynamic environments using proposed samplebased approximation gaussian approximation proposed pfaﬀ contrast gaussian-based state full scan model proposed sample-based approximation able handle multi-modality range ﬁnder data. fig. shows probability adaptive full scan model suited dynamic environments example environment fig. probability plots function position shows marginalization environment sample introduces dependency beams also introduces multi-modality. paper proposed experimentally validated rbbm rigorously bayesian network model range ﬁnder adapted dynamic environments. modeling assumptions rigorously explained model parameters physical interpretation. approach resulted transparent intuitive model. rigorous modeling revealed underlying assumptions parameters. clear physical interpretation parameters obtained providing intuition parameter choices. contrast model thrun assumption underlying non-physical discontinuity rbbm discovered. furthermore paper proposes diﬀerent functional form probability range measurements caused unmodeled objects poccl i.e. quadratic rather exponential proposed thrun furthermore compared work thrun choset pfaﬀ rbbm depends fewer parameters maintaining representational power experimental data. bayesian modeling revealed rate decay poccl figure experimental results sample-based adaptive full scan model static environments. models simple environment fig. range ﬁnder located samples shown black dots simulated measurements shown grey. show marginal likelihood selected beams together histogram experimentally recorded range ﬁnder data gaussian-based approximation pfaﬀ sample-based approximation paper. shows difference beams experimentally obtained cumulative marginal gaussian-based sample-based approximation. figure results sample-based adaptive full scan model dynamic environments. show marginal likelihood selected beams fig. together gaussian-based approximation pfaﬀ sample-based approximation extended dynamic environments. shows probability resulting sample-based approximation. probability shows function position map. probability occluded measurement depend parameter state sensor models however assume independency parameters. finally maximumlikelihood variational bayesian estimator proposed learn model parameters rbbm. learning model parameters experimental data beneﬁts rbbm’s reduced number parameters. using sets learning experiments diﬀerent application areas robotics rbbm shown explain obtained measurements least well state model thrun furthermore paper extended rbbm adaptive full scan model steps ﬁrst full scan model static environments next full scan model general dynamic environments. full scan model adapts local sample density using particle ﬁlter accounts dependency beams. contrast gaussian-based state models plagemann pfaﬀ proposed full scan model uses sample-based approximation cope dynamic environments multi-modality authors thank anonymous reviewers thorough constructive reviews. authors also thank wilm decr´e pauwel goethals goele pipeleers ruben smits bert stallaert lieboud broeck marnix volckaert hans wambacq participating experiments. authors gratefully acknowledge ﬁnancial support k.u.leuven’s concerted research action goa// research council k.u.leuven ef// optimization engineering tinne laet doctoral fellow fund scientiﬁc research–flanders belgium.", "year": 2014}