{"title": "Neural Module Networks", "tag": ["cs.CV", "cs.CL", "cs.LG", "cs.NE"], "abstract": "Visual question answering is fundamentally compositional in nature---a question like \"where is the dog?\" shares substructure with questions like \"what color is the dog?\" and \"where is the cat?\" This paper seeks to simultaneously exploit the representational capacity of deep networks and the compositional linguistic structure of questions. We describe a procedure for constructing and learning *neural module networks*, which compose collections of jointly-trained neural \"modules\" into deep networks for question answering. Our approach decomposes questions into their linguistic substructures, and uses these structures to dynamically instantiate modular networks (with reusable components for recognizing dogs, classifying colors, etc.). The resulting compound networks are jointly trained. We evaluate our approach on two challenging datasets for visual question answering, achieving state-of-the-art results on both the VQA natural image dataset and a new dataset of complex questions about abstract shapes.", "text": "figure schematic representation proposed model—the shaded gray area neural module network kind introduced paper. approach uses natural language parser dynamically deep network composed reusable modules. visual question answering tasks additional sequence model provides sentence context learns common-sense knowledge. approaches another line work textual image uses semantic parsers decompose questions logical expressions. logical expressions evaluated purely logical representation world provided directly extracted image paper draw lines research presenting technique integrating representational power neural networks ﬂexible compositional structure afforded symbolic approaches semantics. rather relying monolithic network structure answer questions approach assembles network collection specialized jointly-learned modules rather using logic reason truth values remain entirely domain visual features attentions. visual question answering fundamentally compositional nature—a question like dog? shares substructure questions like color dog? cat? paper seeks simultaneously exploit representational capacity deep networks compositional linguistic structure questions. describe procedure constructing learning neural module networks compose collections jointly-trained neural modules deep networks question answering. approach decomposes questions linguistic substructures uses structures dynamically instantiate modular networks resulting compound networks jointly trained. evaluate approach challenging datasets visual question answering achieving state-of-the-art results natural image dataset dataset complex questions abstract shapes. paper describes approach visual question answering based neural module networks answer natural language questions images using collections jointly-trained neural modules dynamically composed deep networks based linguistic structure. concretely given image associated question wish predict corresponding answer visual task signiﬁcant signiﬁcant applications human-robot interaction search accessibility subject great deal recent research attention task requires sophisticated understanding visual scenes natural language. recent successful approaches represent questions bags words encode question using recurrent neural network train simple classiﬁer encoded question image. contrast monolithic putational units needed answer question well relationships modules. figure ﬁrst produce attention focused passes output location classiﬁer. depending underlying structure messages passed modules image features attentions classiﬁcation decisions; module determined input output types. different kinds modules shown different colors; attention modules shown green labeling modules shown blue. importantly modules independent composable allows computation different problem instance possibly unobserved training. outside ﬁnal answer uses recurrent network read question shown important model common sense knowledge dataset biases evaluate approach visual question answering tasks. recently-released datasets achieve results comparable better existing approaches show approach speciﬁcally outperforms previous work questions compositional structure turns however many questions datasets quite simple little composition reasoning required. test approach’s ability handle harder questions introduce dataset synthetic images paired complex questions involving spatial relations set-theoretic reasoning shape attribute recognition. dataset outperform competing approaches much absolute accuracy. applications considered paper involve visual question answering general architecture potentially broader usefulness might generally applied visual referring expression resolution question answering natural language texts summarize contributions ﬁrst describe neural module networks general architecture discretely composing heterogeneous jointly-trained neural modules deep networks. next visual task speciﬁcally show construct nmns based output semantic parser successfully complete established visual question answering tasks. finally introduce dataset challenging highly compositional questions abstract shapes show model outperforms previous approaches. release dataset well code systems described paper upon publication. network topologies—there single best network tasks. second though different networks used different purposes commonplace initialize systems many vision tasks preﬁx network trained classiﬁcation shown substantially reduce training time improve accuracy. generalize idea useful question answering? rather thinking question answering problem learning single function questions contexts answers it’s perhaps useful think highly-multitask learning setting problem instance associated novel task identity task expressed noisily language. particular simple question like truck? requires retrieve piece information image complicated questions like many objects left toaster? might require multiple processing steps. compositional nature language means number processing steps potentially unbounded. moreover multiple kinds processing might required—repeated convolutions might identify truck kind recurrent architecture likely necessary count arbitrary numbers. thus goal paper specify framework modular composable jointly-trained neural networks. framework ﬁrst predict structure computation needed answer question individually realize structure constructing appropriatelyshaped neural network inventory reusable modules. modules learned jointly rather trained isolation specialization individual tasks arises naturally training objective. consider three lines related work previous efforts toward visual question answering discrete models compositional semantics models structurally similar neural module networks. visual question answering answering questions images sometimes referred visual turing test recently gained popularity following emergence appropriate datasets consisting paired images questions answers. daquar dataset restricted indoor scenes contains relatively examples cocoqa dataset dataset signiﬁcantly larger visual variety. based images coco dataset cocoqa contains question-answer pairs automatically generated descriptions associated coco dataset crowed sourced questions-answer pairs. evaluate approach larger natural datasets. notable classical approaches task include approaches similar semantic parser rely ﬁxed logical inference rather learned compositional operations. several neural models visual questioning already proposed literature standard deep sequence modeling machinery construct joint embedding image text immediately mapped distribution answers. attempt explicitly model computational process needed produce answer beneﬁt techniques producing sequence image embeddings important previous work. important component visual questioning grounding question image. grounding task previously approached authors tried localize phrases image. attention mechanism predict heatmap word auxiliary task sentence generation. attentional component model inspired approaches. general compositional semantics large literature learning answer questions structured knowledge representations question–answer pairs without joint learning meanings simple predicates outside question answering several models proposed instruction following impose discrete planning structure underlying continuous control signal unaware past semantic parser predict network structures generally exploit natural similarity set-theoretic approaches classical semantic parsing attentional approaches computer vision. neural network architectures idea selecting different network graph input datum fundamental recurrent networks recursive neural networks approaches ultimately involve repeated application single computational module cell). another direction kinds memory networks viewed special case model ﬁxed computational graph consisting sequence basic contribution assembling graph simultaneously allowing nodes perform heterogeneous computations messages different kinds—raw image features attentions classiﬁcation predictions—passed module next. unaware previous work allowing mixed collections modules trained jointly. model fully speciﬁed collection modules associated parameters network layout predictor maps strings networks. given above model instantiates network based passes inputs obtains distribution labels thus model ultimately encodes predictive distribution remainder section describe modules used task explain process questions converted network layouts. modules goal identify small modules assembled conﬁgurations necessary tasks. corresponds identifying minimal composable vision primitives. modules operate three basic data types images unnormalized attentions labels. particular task modules described paper almost interesting compositional phenomena occur space attentions unreasonable characterize contribution narrowly attention-composition network. nevertheless types easily added future notation module names typeset fixed form type. type high-level module type kind described section. instance particular instance model consideration—for example attend locates things attend locates dogs. weights shared type instance level. modules arguments implicitly take image input; higher-level arguments also inspect image. attention module attend convolves every position input image weight vector produce heatmap unnormalized attention. example output module attend matrix whose entries regions image containing cats small everywhere else shown above. classiﬁcation module classify takes attention input image maps distribution labels. example classify return distribution colors region attended re-attention module re-attend essentially multilayer perceptron rectiﬁed nonlinearities performing fully-connected mapping attention another. again weights mapping distinct re-attend take attention shift regions greatest activation upward re-attend move attention away active regions. experiments paper ﬁrst fully-connected layer produces vector size second size input. combination module combine merges attentions single attention. example combine active regions active inputs combine active ﬁrst input active second inactive. measurement module measure takes attention alone maps distribution labels. attentions passed modules unnormalized measure suitable evaluating existence detected object counting sets objects. built inventory modules need assemble layout speciﬁed question. transformation natural language question instantiated neural network takes place steps. first natural language questions layouts specify modules used answer given question connections them. next layouts used assemble ﬁnal prediction networks. standard tools pre-trained existing linguistic resources obtained structured representations questions. future work might focus learning prediction process jointly rest system. parsing begin parsing question stanford parser obtain universal dependency representation dependency parses express grammatical relations parts sentence provide lightweight abstraction away surface form answering question color tie? attend module ﬁrst predicts heatmap corresponding location tie. next classify module uses heatmap produce weighted average image features ﬁnally used predict output label. answering question shape circle? attend modules locate shapes circles re-attend shifts attention circles combine module computes intersection measure module inspects ﬁnal attention determines non-empty. next ﬁlter dependencies connected wh-word question gives simple symbolic form expressing part sentence’s meaning. example standing ﬁeld becomes what; color truck becomes color circle next square becomes is). process also strip away function words like determiners modals type cakes they? type cake converted type. code transforming parse trees structured queries provided accompanying software package. representations bear certain resemblance pieces combinatory logic every leaf implicitly function taking image input root represents ﬁnal value computation. approach compositional combinatorial crucially logical inferential computations operate continuous representations produced neural networks becoming discrete prediction ﬁnal answer. layout symbolic representations already determine structure predicted networks identities modules compose them. ﬁnal assignment modules fully determined structure parse. leaves become attend modules internal nodes become re-attend combine modules dependent arity root nodes become measure modules yes/no questions classify modules question types. given mapping queries network layouts described above training example network structure input image output label. many cases network structures different tied parameters. networks high-level structure different instantiations individual modules truck?— classify)) processed batch resulting efﬁcient computation. noted above parts conversion process taskspeciﬁc—we found relatively simple expressions best natural image questions shapes question required deeper structures. summary statistics provided table generalizations easy imagine applications input layout stage comes something natural language parser. users image database example might write sql-like queries directly order specify requirements precisely e.g. indeed possible construct kind visual using precisely approach described paper— system trained learned modules attention classiﬁcation etc. assembled kind outside user without relying natural language speciﬁcally. table structure summary statistics neural module networks used paper. types high-level module types available instances number speciﬁc module instances layouts number distinct composed structures depth greatest depth across layouts size greatest number modules—for example network figure depth size discussion focused neural module architecture without reference remainder figure ﬁnal model combines output neural module network predictions simple lstm question encoder. important reasons. first relatively aggressive simpliﬁcation question takes place parser grammatical cues substantively change semantics question might affect answer discarded. example ﬂying? ﬂying? converted what answers kite kites respectively even given underlying image features. question encoder thus allows model underlying syntactic regularities data. second allows capture semantic regularities missing low-quality image data reasonable guess color bear? answered brown unreasonable guess green. question encoder also allows model effects kind. experiments paper standard single-layer lstm hidden units. question modeling component predicts distribution answers like root module nmn. ﬁnal prediction model geometric average probability distributions dynamically reweighted using text image features. complete model including sequence modeling component trained jointly. training objective simply module parameters maximizing likelihood data. design last module every network outputs distribution labels assembled network also represents probability distribution. dynamic network structures used answer questions weights updated much frequently others. reason found learning algorithms adaptive per-weight learning rates performed substantially better simple gradient descent. experiments described adadelta important emphasize labels assigned distinguish instances module type— etc.—are notational convenience reﬂect manual speciﬁcation behavior corresponding modules. detect ﬁxed even initialized recognizer combine isn’t ﬁxed compute intersections attentions instead acquire behaviors byproduct end-to-end training procedure. seen figure image–answer pairs parameter tying together encourage module specialize appropriate way. begin motivating experiments synthetic data. compositionality corresponding ability answer questions arbitrarily complex structure essential part kind deep image understanding visual datasets intended test. time questions existing natural image datasets quite simple part requiring pieces information extracted image order answer successfully little evaluation robustness presence distractors primary goals work learn models deep semantic compositionality created shapes synthetic dataset places compositional phenomena forefront. dataset consists complex questions simple arrangements colored shapes questions contain four attributes object types relationships. questions images total. eliminate modeguessing viable strategy questions yes-or-no answer good performance requires system learn recognize shapes colors understand spatial logical relations among sets objects. table results shapes dataset. size number modules needed instantiate appropriate nmn. model achieves high accuracy outperforms baseline previous work especially highly compositional questions. modiﬁed training size- questions; results demonstrate model able generalize questions complicated ever seen training time. produce initial image features pass input image convolutional portion lenet jointly trained question-answering part model. compare approach reimplementation vis+lstm baseline similar described swapping pre-trained image embedding lenet. seen table model achieves excellent performance dataset vis+lstm baseline fares little better majority guesser. moreover color detectors attention transformations behave expected indicating joint training procedure correctly allocates responsibilities among modules. conﬁrms approach able model complex compositional phenomena outside capacity previous approaches visual question answering. perform additional experiment modiﬁed version training contains size- questions performance suffer perhaps increases slightly; demonstrates model able generalize questions even complicated seen training. using linguistic information model extrapolates simple visual patterns learned even harder questions. next consider model’s ability handle hard perceptual problems involving natural images. evaluate recently-released dataset. largest resource kind consisting images paired three questions answers question. data generated human annotators contrast previous work generated questions automatically captions learn model using standard train/test split training answers table results test server. nmn+lstm full model shown figure ablation experiment whole-question lstm. full model outperforms previous approaches scoring particularly well questions involving binary decision. baseline numbers reported previous work. results shown table seen outperform best published results task. breakdown questions answer type reveals model performs especially well questions answered object attribute number worse sequence baseline yes/no category. inspection training-set accuracies suggests performance yes/no questions overﬁtting. ensemble sequence-only system might achieve even better results; future work within framework focus redesigning measure module reduce effects overﬁtting. inspection parser outputs also suggests substantial room improve system using better parser. hand inspection ﬁrst parses training suggests questions asking simple properties objects correctly analyzed complicated questions prone picking irrelevant predicates. example people likely experiencing work day? parsed desired analysis parser errors kind could ﬁxed joint learning. figure broadly suggestive kinds prediction errors made system including plausible semantic confusions normal lexical variation answers priori plausible unrelated image paper introduced neural module networks provide general-purpose framework learning collections neural modules dynamically assembled arbitrary deep networks. demonstrated approach achieves state-of-the-art performance existing datasets visual question answering performing especially well questions answered object attribute. additionally introduced dataset highly compositional questions simple arrangements shapes shown approach substantially outperforms previous work. maintained strict separation predicting network structures learning network parameters. easy imagine problems might solved jointly uncertainty maintained network structures throughout training decoding. might accomplished either monolithic network using higher-level mechanism attend relevant portions computation else integrating existing neural module networks trained produce predictable outputs—even freely composed—points toward general paradigm programs built neural networks. paradigm network designers access standard neural parts construct models performing complex reasoning tasks. visual question answering provides natural testbed approach usefulness potentially much broader extending queries documents structured knowledge bases general signal processing function approximation. authors grateful lisa anne hendricks eric tzeng russell stewart useful conversations nvidia hardware grant. supported national science foundation graduate research fellowship. supported fellowship within weltweit-program german academic exchange service work additionally supported darpa afrl muri award awards iis- iis- berkeley vision learning center.", "year": 2015}