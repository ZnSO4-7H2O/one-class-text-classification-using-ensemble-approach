{"title": "Adaptive Bases for Reinforcement Learning", "tag": ["cs.LG", "cs.AI"], "abstract": "We consider the problem of reinforcement learning using function approximation, where the approximating basis can change dynamically while interacting with the environment. A motivation for such an approach is maximizing the value function fitness to the problem faced. Three errors are considered: approximation square error, Bellman residual, and projected Bellman residual. Algorithms under the actor-critic framework are presented, and shown to converge. The advantage of such an adaptive basis is demonstrated in simulations.", "text": "abstract. consider problem reinforcement learning using function approximation approximating basis change dynamically interacting environment. motivation approach maximizing value function ﬁtness problem faced. three errors considered approximation square error bellman residual projected bellman residual. algorithms actorcritic framework presented shown converge. advantage adaptive basis demonstrated simulations. reinforcement learning approach solving markov decision processes interacting unknown environment. main obstacles applying methods cope large state space. general underlying methods based dynamic programming include adaptive schemes mimic either value iteration q-learning policy iteration actor-critic methods. former attempt directly learn optimal value function latter based quickly learning value currently used policy followed slower policy improvement step. paper focus methods. major problems solving mdps large state space. ﬁrst storage problem i.e. impractical store value function optimal action explicitly state. second generalization notion similarity states needed since states visited visited times. thus issues addressed function approximation approach involves approximating value function functional approximators smaller number parameters comparison original number states. success approach rests mainly selecting appropriate features proper choice approximation architecture. linear approximation architecture value state determined linear combination dimensional feature vector. context linear architectures enjoy convergence results performance guarantees approximation quality depends choice basis functions. paper consider possibility tuning basis functions on-line framework. mentioned before agent interacting environment composed sub-systems. ﬁrst critic estimates value function states encountered. sub-system acts fast time scale. second actor based critic output mainly temporal-diﬀerence signal improves agent’s policy using gradient methods. actor operates second time scale slower time-scale critic. bhatnagar proved algorithm appropriate relation time scales converges. suggest third time scale slower critic actor minimizing error criteria adapting critic’s basis functions better problem. convergence value function policy basis guaranteed architecture simulations show dramatic improvement achieved using basis adaptation. using multiple time scales pose convergence drawback ﬁrst sight. approaches applied order overcome problem. first recent work mokkadem pelletier based previous research polyak others demonstrated combining algorithm iterates averaging method leads convergence rate distribution optimal rate. second multiple time scales rate time steps slower faster time scales converge thus time scales close operate fast time scale satisfy condition above easy practical needs. several works done area adaptive bases. works address problem policy improvement adaptive bases. mention noticeable works similar spirit work. ﬁrst work menache algorithms suggested adaptive bases authors algorithm based gradient methods least-squares bardtke barto algorithm based cross entropy method. algorithms demonstrated simulations achieve better performance ﬁxed basis counterparts convergence guarantees supplied. bertsekas suggested several algorithms main problem classes policy evaluation optimal stopping. former closer work latter focus class. three target functions considered work mean error bellman error projected bellman error. main diﬀerence work following. algorithmic variants suggested ﬂavor lstd lspe algorithms work algorithms based thus work matrix inversion involved. also demonstrate eﬀectiveness algorithms current work. paper organized follows. section deﬁne preliminaries outline framework. section introduce algorithms suggested adaptive bases. section show convergence algorithms suggested section demonstrate algorithms simulations. section discuss results. section introduce framework review actor-critic algorithms overview multiple time scales stochastic approximation state related theorem used later proving main results. consider agent interacting unknown environment modeled markov decision process discrete time ﬁnite state action |x|. selected action agent determines stochastic transition matrix ]xy∈x state followed state state agent receives corresponding reward depend current state. agent maintains parameterized policy function probabilistic function denoted mapping observation probability distribution controls parameter irkθ tunable parameter diﬀerentiable function w.r.t. note diﬀerent diﬀerent probability distributions associated denote state-action-reward trajectory subindex speciﬁes time. duces stationary distribution state space denoted distribution induces natural norm denoted k·kd weighted norm deﬁned x⊤dx. note parameter changes norm changes well. denote expectation operator w.r.t. measures several performance criteria investigated literature diﬀer mainly time horizon treatment future rewards work focus average reward criteria deﬁned min{k recurrent state policies assume exist. deﬁne bellman operator eθ|x]. thus based easy show following connection average reward value function given policy i.e. well known class approaches called actor-critic algorithms agent divided components actor critic. critic functions state value estimator using called td-learning algorithm whereas actor attempts select actions based signal estimated critic. components solve optimization problems separately interacting other. columns span subspace thus approximation value function solution following quadratic program minr′∈rkr kφr′ solution yields linear projection operator mentioned above actor receives signal critic based signal actor tries select optimal action. described section actor maintains policy function following state theorem serves foundation policy gradient algorithm described later. theorem relates gradient w.r.t. average reward ∇θηθ signal deﬁne likelihood ratio derivative ∇θµθ/µθ. omit dependency paper. following assumption states bounded. stochastic approximation particular approach widely used method investigating asymptotic behavior stochastic iterates. example consider following stochastic iterate {ζn+} random process {αn} step sizes form positive series satisfying conditions deﬁned later. idea technique following. suppose iterate decomposed mean function denoted noise term denoted classical theory considers iterate ﬁnite dimensional euclidean space. sometimes need deal several multidimensional iterates dependent other iterate operates diﬀerent timescale. surprisingly type called multiple time scale sometimes easier analyze respect iterates operate single timescale. ﬁrst analysis time-scales algorithms given borkar later expanded leslie collins following describe problem mts-sa state related odes ﬁnally state conditions mts-sa iterates converge. follow deﬁnitions interpret second requirement following higher index iterate operates higher time scale. exists step size i-th iterate larger uniformly step size iterates thus i-th iterate advances iterates words operates faster time scale. following assumption aggregates main requirement mts-sa iterates. remark requirement deﬁned recursively requirement initial requirement related l-th requirement describes i-th system recursively based system going denote deﬁne l-th system ﬁrst requirements common conditions iterates converge. third requirement ensures noise term asymptotically vanishes. fourth requirement ensures time scale slower time scales static faster time scales exists function nonlinear respect rest idea probably lose approach general fails many cases possible obtain better ﬁtness thus better performance additional ﬂexibility. mathematically linear parameter related fast time scale non-linear parameter related slow time scale. view note matrix depends i.e. matrix form ease exposition drop dependency following assumption needed proving later results. bootstrapping method. note equation gives non-linear procedure basis parameters. order solve stochastic equations together theorem basis following algorithm. technical reasons requirement iterates bounded practically constraining discussion constrained sa). projection operator deﬁned second equality proved sutton section note projection operator independent depend basis parameter deﬁne thus solution equation yields mspbe deﬁne similar section deﬁne i-th column later give gradient respect implicit form following algorithm gives iterates iterates algorithms therefore omitted. algorithm four time scales. fastest time scale related step sizes estimators time scale i.e. estimators ∂a/∂si ∂b/∂si ∂w/∂ri ∂w/∂si. linear parameters critic i.e. related step sizes estimated second fastest time scale. actor parameter related step sizes estimated second slowest time scale. finally critic non-linear parameter related step sizes estimated slowest time scale. note version fastest times scales operate joint single fastest time scale possible results additional technical diﬃculties convergence proof. begin stating theorem regarding abtd convergence. space limitations give proof sketch based convergence proof theorem bhatnagar self-contained proof general conditions left long version work. proof. three time-scales therefore wish theorem i.e. need prove requirements assumption valid w.r.t. iterations i.e. requirement w.r.t. iterates bhatnagar proved converge speciﬁc assumption implies requirements assumption valid regarding iterates uniformly irks. therefore suﬃcient prove also iterate converges i.e. requirements assumption valid w.r.t. requirement w.r.t. iterate deﬁne σ-algebra deﬁne expressed trivially using assumption liphschitz respect coeﬃcients liphschitz respect coeﬃcients respectively. thus requirement assumption valid. requirements w.r.t. iterate construction iterate bounded. requirement assumption valid using boundedness martingale diﬀerence noise implies using martingale convergence requirement w.r.t. iterate using result bhatnagar fast time scales converge w.r.t. slow time scale. thus requirement valid based fact iterates converge. ﬁrst inequality results inequality second inequality results uniform boundedness involved variables. note related iteration given related lyapunov function given next need show convergence fast time scales slower iterate converges. proof identical theorem therefore omitted. left proving fast timescales converge i.e. iterates iterate converge well. proof follows similar lines proof proof theorem whereas iterate converge stable point ∇se]. garnet problems class randomly constructed ﬁnite mdps serving test-bench algorithms. garnet problem characterized four parameters denoted garnet. parameter number states number actions branching factor variance transition reward. constructing problem generate state reward distributed according state-action reward distributed according transition matrix action composed non-zero terms. consider garnet problems simulated critic’s feature vector reported simulation results garnet problems garnet garnet. based simulations results time steps identical garnet problem simulated graph average repeats. garnet problem simulated graph average repeats. problems evident advantage adaptive base achieve additional ﬁtness problem thus even dimensional problems adaptation crucial. needs climb right mountain engine support straight climb. thus needs accumulate suﬃcient gradational energy applying back forth actions order succeed. applied adaptive basis algorithm problem. chose critic basis functions radial basis functions value exp{− vi}. centers rbfs parameterized variance represented based implementation basis functions uniformly distributed parameter space abtd basis functions location variance basis functions adapt abac basis functions adaptation. adaptive basis gives signiﬁcant advantage performance. moreover even small number parameters performance aﬀected. middle pane dynamics realization basis functions presented dots circles initial positions ﬁnal positions basis functions respectively. circle sizes proportional basis functions standard deviations i.e. section discuss diﬀerences performance algorithm algorithms. unlike mistakenly thought neither algorithms algorithms advantage terms convergence. difference comes fact methods perform gradient algorithm diﬀerently thus result diﬀerent trajectories. fig. case garnet abtd algorithm advantage abtd algorithms static basis algorithm note always case depends problem parameters initial conditions. fig. illustration mountain task. realization abtd basis functions dots basis functions initial position circles ﬁnal position. radii proportional variance. rectangle represents bounded parameter car. simulation result mountain problem solutions sarsa ab-ac basis functions ab-ac basis functions fig. results garnet upper diamond graph abtd algorithm circled green graph abtd acting slow time scale blue crossed line static basis algorithm black stared line abtd acting fast time scale. graph average simulation runnings. introduced three based algorithms critic’s basis adaptive. convergence proofs average reward case provided. note algorithms easily transformed discounted reward. considering target functions algorithms adaptive basis devised e.g. considering objective function yields a⊤td algorithms also mixing diﬀerent algorithm introduced here yield algorithms desired properties. example. devise algorithm linear part updated similar non-linear part updated similar convergence algorithms follow lines proof introduced here. advantage adaptive bases evident relieve domain expert task carefully designing basis. instead choose ﬂexible basis algorithms introduced adapt basis problem hand. methodological point view method introduced paper demonstrates easily transform existing algorithm adaptive basis algorithm. analysis original problem used show convergence faster time scale slow time scale used modifying basis analogously code reuse concept software engineering.", "year": 2010}