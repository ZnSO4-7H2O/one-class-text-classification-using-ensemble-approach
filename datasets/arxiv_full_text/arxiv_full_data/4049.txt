{"title": "3D-R2N2: A Unified Approach for Single and Multi-view 3D Object  Reconstruction", "tag": ["cs.CV", "cs.AI"], "abstract": "Inspired by the recent success of methods that employ shape priors to achieve robust 3D reconstructions, we propose a novel recurrent neural network architecture that we call the 3D Recurrent Reconstruction Neural Network (3D-R2N2). The network learns a mapping from images of objects to their underlying 3D shapes from a large collection of synthetic data. Our network takes in one or more images of an object instance from arbitrary viewpoints and outputs a reconstruction of the object in the form of a 3D occupancy grid. Unlike most of the previous works, our network does not require any image annotations or object class labels for training or testing. Our extensive experimental analysis shows that our reconstruction framework i) outperforms the state-of-the-art methods for single view reconstruction, and ii) enables the 3D reconstruction of objects in situations when traditional SFM/SLAM methods fail (because of lack of texture and/or wide baseline).", "text": "abstract. inspired recent success methods employ shape priors achieve robust reconstructions propose novel recurrent neural network architecture call recurrent reconstruction neural network network learns mapping images objects underlying shapes large collection synthetic data network takes images object instance arbitrary viewpoints outputs reconstruction object form occupancy grid. unlike previous works network require image annotations object class labels training testing. extensive experimental analysis shows reconstruction framework outperforms state-of-theart methods single view reconstruction enables reconstruction objects situations traditional sfm/slam methods fail rapid automatic object prototyping become game-changing innovation many applications related e-commerce visualization architecture name few. trend boosted printing democratized technology acquisition methods accurate eﬃcient moreover trend also coupled diﬀusion large scale repositories object models shapenet state-of-the-art methods object reconstruction however subject number restrictions. restrictions that objects must observed dense number views; equivalently views must relatively small baseline. issue users wish reconstruct object handful views ideally view objects’ appearances expected lambertian albedos supposed non-uniform restrictions stem number technical assumptions. typical assumption features matched across views hypothesized majority methods based slam demonstrated viewpoints separated large baseline establishing feature correspondences extremely problematic local appearance changes self-occlusions. moreover lack texture objects specular reﬂections also make feature matching problem diﬃcult order circumvent issues related large baselines non-lambertian surfaces volumetric reconstruction methods space carving probabilistic extensions become popular. methods however assume objects accurately segmented background cameras calibrated case many applications. diﬀerent philosophy assume prior knowledge object appearance shape available. beneﬁt using priors ensuing reconstruction method less reliant ﬁnding accurate feature correspondences across views. thus shape prior-based methods work fewer images fewer assumptions object reﬂectance function shown shape priors typically encoded form simple primitives demonstrated early pioneering works learned rich repositories models whereby concept ﬁtting models images faces explored much larger extent sophisticated mathematical formulations also introduced adapt shape models observations diﬀerent degrees supervision diﬀerent regularization strategies paper spirit methods discussed above diﬀerence. instead trying match suitable shape prior observation object possibly adapt deep convolutional neural networks learn mapping observations underlying shapes objects large collection training data. inspired early works used machine learning learn d-to-d mapping scene understanding data driven approaches recently proposed solve daunting problem recovering shape object single image given number object categories. approach however leverage ﬁrst time ability deep neural networks automatically learn mere end-to-end fashion appropriate intermediate representations data recover approximated object reconstructions single image minimal supervision. well recent progress single-view reconstruction using convolutional neural networks propose novel architecture call recurrent reconstruction neural network network takes images object instance diﬀerent viewpoints outputs reconstruction object form occupancy grid illustrated fig. note training testing network require fig. sample images objects wish reconstruct notice views separated large baseline objects’ appearance shows little texture and/or non-lambertian. overview proposed d-rn network takes sequence images arbitrary viewpoints input generates voxelized reconstruction output. reconstruction incrementally reﬁned network sees views object. attributes d-rn selectively update hidden representations controlling input gates forget gates. training mechanism allows network adaptively consistently learn suitable representation object information diﬀerent viewpoints becomes available propose extension standard lstm framework call recurrent reconstruction neural network suitable accommodating multi-view image feeds principled manner. network enables reconstruction objects situations traditional sfm/slam methods fail overview reconstruction network shown fig. rest paper organized follows. section give brief overview lstm networks. section introduce recurrent reconstruction neural network architecture. section discuss generate training data give details training process. finally present test results approach various datasets including pascal shapenet section long short-term memory unit. successful implementations hidden states long short term memory unit lstm unit explicitly controls input output allowing network overcome vanishing gradient problem speciﬁcally lstm unit consists four components memory units three gates control information input hidden state hidden state output previous hidden state current hidden state formally time step input received operation lstm unit expressed refer input gate output gate forget gate respectively. refer memory cell hidden state respectively. denote element-wise multiplication subscript refer activation time matrices transform current input previous hidden state respectively represents biases. gated recurrent unit. variation lstm unit gated recurrent unit proposed advantage fewer computations compared standard lstm. update gate controls input forget gates. another diﬀerence reset gate applied nonlinear transformation. formally section introduce novel architecture named recurrent reconstruction network builds upon standard lstm gru. goal network perform singlemulti-view d-lstm. decoder takes d-lstm hidden states transforms ﬁnal voxel occupancy map. convolution layer leakyrelu. versions d-rn shallow network deep residual network reconstructions. main idea leverage power lstm retain previous observations incrementally reﬁne output reconstruction observations become available. network made three components convolutional neural network novel architecture named convolutional lstm deconvolutional neural network given images object arbitrary viewpoints d-cnn then given encoded input newly proposed convolutional lstm units either selectively update cell states retain states closing input gate. finally d-dcnn decodes hidden states lstm units generates probabilistic voxel reconstruction main advantage using lstm-based network comes ability eﬀectively handle object self-occlusions multiple views network. network selectively updates memory cells correspond visible parts object. subsequent view shows parts previously self-occluded mismatch prediction network would update lstm states previously occluded sections retain states parts cnns encode images features. designed diﬀerent d-cnn encoders shown fig. standard feed-forward deep residual variation ﬁrst network consists standard convolution layers pooling layers leaky rectiﬁed linear units followed fully-connected layer. motivated recent study also created deep residual variation ﬁrst network report performance variation section according study adding residual connections standard convolution layers eﬀectively improves speeds optimization process deep networks. deep residual variation encoder network identity mapping connections every convolution layers except pair. core part d-rn recurrence module allows network retain seen update memory sees image. naive approach would vanilla lstm network. however predicting regularization. propose architecture call d-convolutional lstm network made structured lstm units restricted connections. d-lstm units spatially distributed grid structure unit responsible reconstructing particular part intuitively conﬁguration forces d-lstm unit handle mismatch particular region predicted reconstruction ground truth model unit learns reconstruct part voxel space instead contributing reconstruction entire space. conﬁguration also endows network sense locality selectively update prediction previously occluded part object. visualize behavior appendix. moreover convolutional lstm unit restricts connections hidden state spatial neighbors. vanilla lstms elements hidden layer aﬀect current hidden state whereas spatially structured convolutional lstm allows hidden states aﬀected neighboring d-lstm units speciﬁcally neighboring connections deﬁned convolution kernel size. instance section also described gated recurrent unit variation lstm unit. created variation d-convolutional lstm using gated recurrent unit formally gru-based recurrence module expressed encoders propose simple decoder network convolutions deep residual version residual connections followed ﬁnal convolution. last layer activation reaches target data augmentation training used models generating input images ground truth voxel occupancy maps. ﬁrst rendered models transparent background augmented input images random crops pascal dataset also tinted color models randomly translated images. note viewpoints sampled randomly. training training network used variable length inputs ranging image arbitrary number images. speciﬁcally input length training example within single mini-batch kept constant input length training examples across diﬀerent mini-batches varied randomly. enabled network perform singlemultiview reconstruction. training computed loss input sequence order save computational power memory. hand test time could access intermediate reconstructions time step extracting hidden states lstm units. trained iterations batch size except needed batch size nvidia titan gpu. leakyrelu layers slope leak throughout network. deconvolution followed unpooling scheme presented used theano implement network used adam update rule. section validate demonstrate capability approach several experiments using datasets described section first show results diﬀerent variations d-rn next compare performance network pascal dataset state-of-the-art method single-view real-world image reconstruction show network’s ability perform multi-view reconstruction shapenet dataset online products dataset finally compare approach multi view stereo method reconstructing objects various texture levels viewpoint sparsity shapenet shapenet dataset collection models organized according wordnet hierarchy. used subset shapenet dataset consists models major categories complete list). split dataset training testing sets training remaining testing. refer datasets shapenet training testing throughout experiments section. pascal pascal dataset composed pascal detection images augmented model alignment online products dataset contains images items sold online. methods fail images ultra-wide baselines. since dataset ground-truth models used dataset qualitative evaluation. models compare method multi view stereo method collected diﬀerent categories high-quality models. models texture-rich surfaces placed texture-rich paper camera localization method. metrics used metrics evaluating reconstruction quality. primary metric voxel intersection-over-union voxel reconstruction ground truth voxelized model. formally voxelization threshold. higher values indicate better reconstructions. also report cross-entropy loss secondary metric. lower loss values indicate higher conﬁdence reconstructions. tested variations d-rn described section ﬁrst four networks based standard feed-forward ﬁfth network residual network ﬁrst four networks used either lstm units varied convolution kernel networks trained shapenet training tested shapenet testing set. used views experiment. table shows results. observe gru-based networks outperform lstmbased networks networks neighboring recurrent unit connections evaluated performance network single-view reconstruction using real-world images comparing performance recent method make quantitative comparison used images pascal dataset corresponding models pascal dataset experiments conﬁguration except allow method ground-truth object segmentation masks keypoint labels additional inputs training testing. fig. reconstruction samples pascal dataset. failed reconstructions pascal dataset. note trained/tested category takes ground-truth object segmentation masks keypoint labels additional input. training. ﬁne-tuned network trained shapenet dataset pascal used pascal validation hyperparameters number ﬁne-tuning iterations voxelization threshold. results. shown table approach outperforms method every category. however observe network difﬁculties reconstructing thin legs chairs. moreover network often confuses thin panels thick screens given frontal view monitor. approach demonstrates competitive quantitative performance. qualitative results comparisons please fig. trains reconstructs without knowing object category. second network require object segmentation masks keypoint labels additional inputs. demonstrate possibility testing wild unlabeled image estimating segmentation keypoints. however network outperforms method tested ground truth labels. table per-category reconstruction pascal compared using voxel intersection-over-union note experiments conﬁguration except method took ground-truth object segmentation masks keypoint labels additional inputs training testing. experiment setup. used network experiment. evaluated network shapenet testing set. testing consisted models major categories. rendered random views model applied uniform colored background image. report softmax loss intersection union voxelization threshold predicted ground truth voxel models. overall results. ﬁrst investigate quality reconstructed models diﬀerent numbers views. fig. show reconstruction quality improves number views increases. fact marginal gain decreases accords assumption additional view provides less information since random views likely partial overlap. per-category results. also report reconstruction ious major categories testing table observed reconstruction quality improved every category number views increased quality varied depending category. cabinets cars speakers highest reconstruction performance since objects bulky-shaped less variance compared classes. network performed worse lamp bench table categories. classes much higher shape variation classes. example lamp slim large lampshade move around chairs tables various types supporting structures. qualitative results. fig. shows sample reconstructions shapenet testing set. exemplary instance truck shown initial view front part truck visible. network took safest guess object sedan common shape category. network produced accurate reconstruction truck seeing views. instances show similar improvements network sees views objects. fig. shows failure cases. fig. multi-view reconstruction using model shapenet dataset. performance reported median mean cross-entropy loss intersection union values. plot shows caps showing per-category reconstruction shapenet dataset using model. values average iou. fig. shows sample reconstructions. result shows network capable reconstructing real world objects using synthetic data training samples. also demonstrates network improves reconstructions seeing additional views objects. exemplary instance reconstruction couch shown initial side view couch network believe one-seater sofa seeing front couch network immediately reﬁned reconstruction reﬂect observation. similar behaviors also shown samples. failure cases shown fig.. experiment compare approach method reconstructing objects various texture levels diﬀerent number views. methods limited accuracy feature correspondences across diﬀerent views. therefore tend fail reconstructing textureless objects images sparsely positioned camera viewpoints. contrast method require accurate feature correspondences adjacent camera viewpoints. dataset used high-quality models diﬀerent categories augmented texture strengths medium high manually editing textures. rendered models viewpoints uniformly sampled azimuth angles. please refer fig. samples rendered fig. sample reconstructions shapenet testing online products dataset rows input image sequences bottom rows reconstructions time step. failure cases dataset. models across diﬀerent viewpoints texture strengths. texture level number views conﬁguration method network took identical sets images inputs. experiment setup. used patch-match -based oﬀ-the-shelf implementation method. method takes images along camera positions estimated global outputs reconstructed model. network used network trained views. order cope views ﬁne-tuned network samples maximum views iterations using shapenet training set. quantiﬁed quality reconstructions using voxels. network voxelized occupancy probability threshold mesh reconstructed method voxelized results. results shown fig. observed model worked view whereas method failed completely number views less model worked regardless objects’ texture level whereas method frequently failed reconstruct objects texture level even large number views provided. shows method works situations methods would perform poorly completely fail. note reconstruction performance method decreased number also discovered limitations method. first method could reconstruct many details method given diﬀerent views model. second method performed worse reconstructing objects high texture levels. largely models shapenet training texture level. fig. reconstruction performance compared network. shows texture strengths aﬀect reconstructions network averaged input views classes. compares quality reconstruction across number input images averaged texture levels classes. show reconstruction result show reconstruction results method high-texture airplane model input views respectively. work proposed novel architecture uniﬁes singlemultiview reconstruction single framework. even though network take variable length inputs demonstrated outperforms method single-view reconstruction using real-world images. further tested network’s ability perform multi-view reconstruction shapenet dataset online products dataset showed network able incrementally improve reconstructions sees views object. lastly analyzed network’s performance multi-view reconstruction ﬁnding method produce accurate reconstructions techniques fail. summary network require minimum number input images order produce plausible reconstruction able overcome past challenges dealing images insuﬃcient texture wide baseline viewpoints.", "year": 2016}