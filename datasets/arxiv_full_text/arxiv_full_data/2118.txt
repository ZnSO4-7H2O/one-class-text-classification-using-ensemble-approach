{"title": "Censoring Representations with an Adversary", "tag": ["cs.LG", "cs.AI", "stat.ML"], "abstract": "In practice, there are often explicit constraints on what representations or decisions are acceptable in an application of machine learning. For example it may be a legal requirement that a decision must not favour a particular group. Alternatively it can be that that representation of data must not have identifying information. We address these two related issues by learning flexible representations that minimize the capability of an adversarial critic. This adversary is trying to predict the relevant sensitive variable from the representation, and so minimizing the performance of the adversary ensures there is little or no information in the representation about the sensitive variable. We demonstrate this adversarial approach on two problems: making decisions free from discrimination and removing private information from images. We formulate the adversarial model as a minimax problem, and optimize that minimax objective using a stochastic gradient alternate min-max optimizer. We demonstrate the ability to provide discriminant free representations for standard test problems, and compare with previous state of the art methods for fairness, showing statistically significant improvement across most cases. The flexibility of this method is shown via a novel problem: removing annotations from images, from unaligned training examples of annotated and unannotated images, and with no a priori knowledge of the form of annotation provided to the model.", "text": "practice often explicit constraints representations decisions acceptable application machine learning. example legal requirement decision must favour particular group. alternatively representation data must identifying information. address related issues learning ﬂexible representations minimize capability adversarial critic. adversary trying predict relevant sensitive variable representation minimizing performance adversary ensures little information representation sensitive variable. demonstrate adversarial approach problems making decisions free discrimination removing private information images. formulate adversarial model minimax problem optimize minimax objective using stochastic gradient alternate min-max optimizer. demonstrate ability provide discriminant free representations standard test problems compare previous state methods fairness showing statistically signiﬁcant improvement across cases. ﬂexibility method shown novel problem removing annotations images separate training examples annotated unannotated images priori knowledge form annotation provided model. apply machine learning techniques many real-world settings long problem sensitive information. want provide information third party sure third party cannot determine critical sensitive variables. alternatively need make decisions treat category differently another. speciﬁc cases image anonymization fairness respectively. life’s decisions become automated growing need legal ethical reasons machine learning algorithms make fair decisions. decision fair depend upon sensitive variable gender race. naive approach achieving fair decision would simply remove sensitive covariate model. information sensitive variable ‘leak’ back decisions made dependence variables. work focus fair classiﬁers want predict binary variable fair respect binary sensitive variable here fairness means decision not-dependent sensitive variable. previous works listed section tended develop speciﬁc fair variants common classiﬁers solve problem. approach called adversarial learned fair representations learn representations data concurrently fair discriminative prediction task. features used classiﬁer. achieve fair discriminative properties represent dual objective optimization problem cast minimax problem. maintain ﬂexibility representation test fairness using deep feed-forward neural networks part. deep neural network used produce representation; representation critiqued deep neural adversary tries predict sensitive variable representation. paper introduced adversarial method alfr minimax problem describe optimization process evaluate alfr datasets diabetes adult. demonstrates improvement related approach zemel also aside provide relationship discrimination classiﬁer h-divergence used domain adaptation. relationship methods domain adaptation interesting different cases sensitive variable thought different domains. however leave study another paper. many notions problems relating privacy literature. strict forms privacy enforced differential privacy always necessary relaxed notions privacy beneﬁcial reducing distortion making accurate analysis possible particular case privacy certain parts data communicated however many settings hard explicit exactly communicated whether information coupled measured variables. work consider concrete case removing private information image whilst distorting image little possible. examples private information include licence plates cars photos doctors’ annotations medical images x-rays. suggest modiﬁcation autoencoder remove private information validate idea removing surnames collection images faces. similar application might removing logos watermarks images. novelty approach model need trained aligned input/output examples rather examples inputs examples outputs labelled such. example task remove text image aligned input/output pair would image containing text image text removed. unaligned data would simply images labelled containing text images labelled containing text. former sort data would often substantially difﬁcult obtain latter. two-neural-network minimax formalism characterise problem stochastic gradient optimization procedure learn neural network parameters. model applied problem images without annotation good visual affect. neural network longer distinguish well annotated non-annotated images actually annotation obscured. idea adversarial learning representation dependent variable adversary tries predict adversary provides adaptive measure dependence used learn minimizes dependence. adversarial approach best knowledge introduced schmidhuber used learn representation data binary independent experiments work synthetic data later followed learn ﬁlters natural image patches schmidhuber schraudolph referred approach principle predictability minimization. recently goodfellow idea using adversary learn generative model data introduced followed-up work gauthier rudy taylor denton setting representation mixture data samples generated samples binary variable indicating whether given sample data ‘fake’. discussion using ‘distinguishability criteria’ learn generative models goodfellow inspiration alfr comes using adversarial learning domain-adaptation ganin setting variable indicating domain idea learn representation domains indistinguishable motivated bounds ben-david relating performance target domain dissimilarity target source domains. several works proposed variants classiﬁers enforce fairness. include discrimination-free naive-bayes regularized version logistic regression recent approach zafar authors introduce constraints objective functions logistic regression hinge-loss classiﬁers support vector machines. another approach data massaging whereby labels training data changed training data fair similar resampling methods often used tackle class-imbalance problems. approach spirit alfr learned fair representations paper authors learn representation data probability distribution clusters form ‘fair clustering’ learning cluster datapoint tells nothing sensitive variable clustering learned fair also discriminative prediction task. previous work focused enforcing fair decisions whereas alfr fairness side-effect fair representations. advantage latter approach representations potentially reused different tasks possibility separation concerns whereby party responsible making representations fair another party responsible making best predictive model. contrast approach ﬂexible terms kinds representations learn whereas learns essentially categorical representations. addition approach means representations used classiﬁer. concurrent work preprint ‘the variational fair autoencoder’ main differences work theirs. first variational autoencoder factorizes latent variables sensitive variable aspect complementary could incorporated adversarial framework. secondly maximum mean discrepancy penalty reduce dependence representation kernel-based alternative using adversary. clear circumstances prefer adversary hope future work address question. problem removing information images learned manner tackled best knowledge machine learning community. however work detecting private information erroneously left image korayem erickson consider binary classiﬁcation task input space label protected variable label set. provided i.i.d examples drawn joint distribution corresponding random variables goal learning algorithm build classiﬁer high accuracy whilst maintaining property statistical parity fairness number data items equal respectively. measure success classiﬁer using empirical accuracy yacc. following zemel optimize difference discrimination classiﬁcation accuracy section show modiﬁcation autoencoder used learn representation obscures/removes sensitive variable. general case input variable target variable binary sensitive variable objective learn representation preserves information useful predicting approximately independent loss form cost reconstructing measure dependence error predicing scalars hyperparameters controlling weighting competing objectives. don’t speciﬁc prediction task case want remove private information image don’t need term. hand interested reusing representation different predictive tasks also want case want learn transformation data fair preserves semantics representation example certain regulated areas interpretability model paramount. notice also ﬁnal term depends-upon opportunity train semi-supervized fashion labels available data. begin quantifying dependence representation sensitive variable since binary think measuring difference conditional distributions training classiﬁer tell apart called adversary. interested readers wish know measure dependence related notion h-divergence described appendix particular adversary network trained discriminate parameters encoder parameters deﬁne negative standard log-loss binary classiﬁer. adversary’s parameters chosen maximize whilst representation parameters chosen minimize minimax problem four elements model encoder decoder predictor adversary. implemented using feed-forward neural network precize architectures detailed section costs elements given equations joined together give joint loss expecting able train adversary inner loop global optimum unrealistic. instead described goodfellow heuristic variant stochastic gradient descent minibatch decide whether take gradient step respect actors parameters negative gradient step respect adversary’s parameters goodfellow consider simple strict alternation updating adversary actor useful default. give detailed pseudo-code strict alternation algorithm note gradient steps algorithm easily replaced powerful optimizer adam algorithm method heuristic sense provide formal guarantees convergence know solution minimax problem ﬁxed point process. large number papers using method getting good results considerable empirical evidence favour. issue process adversary competent gradients weak actor whereas adversary incompetent gradients uninformative actor. also considered updating adversary instance accuracy predicting threshold updating generator accuracy threshold sometimes improves results investigation needed. apply general setup described section case learning fair classiﬁers described section case sensitive variable would correspond category like gender race target variable would attribute wish predict using fair representations. speciﬁc case worth pointing discrimination ydisc classiﬁer bounded empirical h-divergence shown lemma appendix symmetric hypothesis class including empirical samples given discrimination given best hypothesis must least good particular hypothesis assuming minimizing divergence minimizes discrimination. apply idea censoring representations application removing text images. problem input image sensitive variable describes whether image contains private information prediction task variable contrast alfr interested learning hidden representation reconstructed image case order evaluate model need small amount validation/test data pairs images without text. used choose hyperparameters model never gets train example input/output pairs. used datasets repository lichman demonstrate efﬁcacy alfr. adult dataset consists census data task predict whether person makes dollars year. sensitive attribute chose gender. data instances attributes. used thousand instances training approximately thousand instances validation test sets. diabetes dataset consists hospital data task predict whether patient readmitted hospital. sensitive attribute chose race changed binary variable creating attribute iscaucasian. data around thousand instances attributes. used thousand instances training approximately thousand instances validation test sets. compare alfr split dataset training validation test sets randomly experiments model different hyperparameters. value considered selected model maximizing ytdisc validation data. process repeated times different data splits. since model sees data split observations paired observations difference performance value evaluating results want evaluate approaches different possible tradeoffs accuracy discrimination compare range values explore hyperparameters using random search random search opposed sequential performance driven search able compare models across range values using methods practice select hyperparameters using bayesian optimization similar approach maximize speciﬁc tradeoff cares about. give details priors hyperparameters used random search. autoencoder alfr encoding/decoding layers hidden units hidden layers number hidden units. encoding/decoding unit used relu activation. critic also hidden layers relu activations. predictor network simply logistic regressor central hidden layer autoencoder. models reconstruction error weighting parameter ﬁxed models used found model sensitive hyperparameters/initialization could often stick training given sufﬁcient experiments able obtain good results. figure figure results applying alfr adult diabetes data respectively. cases alfr model able obtain signiﬁcantly better results across range possible tradeoffs accuracy discrimination. step changes ﬁgures correspond places change tradeoff results different form model. also clariﬁes results often sensitive tradeoff parameter. also interested effect hyperparameters discrimination alfr model. particular consider ratio measuring relative importance dependence term prediction error term cost. figure larger relative lower discrimination matches expectations. used adult faces’ dataset bainbridge consisting natural face photographs. preprocessed data rescaling pixels converting grayscale. addition half training images added private information form text overlayed random location image. used photographs validation test validation test sets image without text evaluation. problem sensitive variable indicates whether image contains text. figure results adult dataset. value model maximizing ytdelta validation selected plots show performance selected models test data. ytdelta. second shows mean paired difference ytdelta alfr model model positive values favour alfr. also give around mean. third yacc. bottom ydisc. alfr model better ytdelta every setting considered. moreover difference signiﬁcant values protocols architecture global image autoencoder model used expert patch based model using patches. expert model consists parts patch classiﬁer neural patch autoencoder. image reconstruction formed simply copying patch patch classiﬁer predicts text-label patch. otherwize uses patch autoencoder construct patch. patch classiﬁer pretrained weak-supervision using image level labels patch. decision boundary patch adversary hyperparameter optimized autoencoder probability text-label setting. altogether whole image reconstructed input image using expert patch based model patch image. patch classiﬁer single hidden layer relu units. autoencoder also single hidden layer relu units. adversary convolutional layers ﬁlters size interspersed max-pooling layers pooling size followed dense layer hidden units relu activations. hyperparameters weights chosen hyperparameters chosen evaluation validation data. validation data consists input/output pairs contains text xout corresponding image withtext. performance measured using mean-square error betweeen autoencoder’s output given target xout. figure results diabetes dataset. value model maximizing ytdetla validation selected plots show performance selected models test data. ytdelta. second shows mean paired difference ytdelta alfr model model positive values favour alfr. also give around mean. third yacc. bottom ydisc.we alfr model better ytdelta every setting considered. also difference signiﬁcant never given example input/output pairs. produced images quite plausible artifacts become apparent zooming believe quality images could substantially improved convolutional autoencoder larger dataset since could take account wider context patch removing text. application ﬂexibility adversarial framework compared clustering approach becomes apparent would extremely difﬁcult lfr-style approach work images since must reconstruct images convex combination template images. shown adversarial approach adapted task removing sensitive information representations. model alfr improves upon related approach whilst time ﬂexible. demonstrate ﬂexibility showing setup used remove text image encouraging results. noted difﬁcult train adversarial models owing unstable dynamic actor adversary. work done future developing theory least heuristics improving stability training process. another interesting problem investigate would obscuring text images negative examples images text. assumptions method would applicable assume information text gain traction. example text name person image know name versus test discrimination alfr model adult figure scatter plot dataset. approximately linear relation certain point relative increase little effect discrimination. person image adversary could trained predict bag-of-characters name whereas autoencoder would trained make task difﬁcult adversary. result blurring rather removal text. issue would face approach would lack ground-truth examples validation since many ways obscure text. bastien fr´ed´eric lamblin pascal pascanu razvan bergstra james goodfellow bergeron arnaud bouchard nicolas bengio yoshua. theano features speed improvements. deep learning unsupervised feature learning nips workshop ben-david shai blitzer john crammer koby kulesza alex pereira fernando vaughan jenniferwortman. theory learning different domains. machine learning issn ./s---. http//dx.doi.org/ ./s---. bergstra james breuleux olivier bastien fr´ed´eric lamblin pascal pascanu razvan desjardins guillaume turian joseph warde-farley david bengio yoshua. theano math expression compiler. proceedings python scientiﬁc computing conference june oral presentation. ganin yaroslav ustinova evgeniya ajakan hana germain pascal larochelle hugo laviolette franc¸ois marchand mario lempitsky victor domain-adversarial training neural networks. corr abs/. http//arxiv.org/abs/.. goodfellow pouget-abadie jean mirza mehdi bing warde-farley david ozair sherjil courville aaron bengio yoshua. generative adversarial nets. advances neural information processing systems annual conference neural information processing systems december montreal quebec canada http//papers.nips.cc/paper/-generative-adversarial-nets. korayem mohammed templeman robert chen dennis crandall david kapadia apu. screenavoider protecting computer screens ubiquitous cameras. corr abs/. http//arxiv.org/abs/.. nair vinod hinton geoffrey rectiﬁed linear units improve restricted boltzmann machines. proceedings international conference machine learning june haifa israel http//www.icml.org/papers/ .pdf. schmidhuber eldracher foltin semilinear predictability minimization produces wellknown feature detectors. neural computation issn ./neco..... schraudolph nicol eldracher martin schmidhuber j¨urgen. processing images semilinear predictability minimization. network computation neural systems zafar muhammad bilal valera isabel gomez-rodriguez manuel gummadi krishna fairness constraints mechanism fair classiﬁcation. corr abs/. http//arxiv.org/abs/.. zemel rich swersky kevin pitassi toni dwork cynthia. learning fair representations. dasgupta sanjoy mcallester david proceedings international conference machine learning volume jmlr workshop conference proceedings http//jmlr.org/proceedings/papers/ v/zemel.pdf. h-divergence appendix describe notion h-divergence developed kifer ben-david h-divergence measuring difference distributions using classiﬁers. deﬁnition hypothesis random variable mapping deﬁnition hypothesis class random variable collection hypotheses deﬁnition symmetrical hypothesis class hypothesis class inverse hypothesis deﬁned also case symmetric ben-david show approximated empirically. deﬁnition symmetrical hypothesis class random variables common space given i.i.d samples i.i.d samples deﬁne empirical h-divergence nature empirical approximation shown following probabilistic bound bendavid lemma symmetrical hypothesis class dimension random variables common space given i.i.d samples i.i.d samples that probability least minimizing capability adversary tell difference distributions relates minimizing h-divergence. empirical divergence straightforwardly related discrimination classiﬁer. lemma described section classiﬁer ydisc discrimination described section", "year": 2015}