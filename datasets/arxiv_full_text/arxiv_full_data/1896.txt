{"title": "Speech Recognition Front End Without Information Loss", "tag": ["cs.CL", "cs.CV", "cs.LG"], "abstract": "Speech representation and modelling in high-dimensional spaces of acoustic waveforms, or a linear transformation thereof, is investigated with the aim of improving the robustness of automatic speech recognition to additive noise. The motivation behind this approach is twofold: (i) the information in acoustic waveforms that is usually removed in the process of extracting low-dimensional features might aid robust recognition by virtue of structured redundancy analogous to channel coding, (ii) linear feature domains allow for exact noise adaptation, as opposed to representations that involve non-linear processing which makes noise adaptation challenging. Thus, we develop a generative framework for phoneme modelling in high-dimensional linear feature domains, and use it in phoneme classification and recognition tasks. Results show that classification and recognition in this framework perform better than analogous PLP and MFCC classifiers below 18 dB SNR. A combination of the high-dimensional and MFCC features at the likelihood level performs uniformly better than either of the individual representations across all noise levels.", "text": "sheikhzadeh deng apply hidden ﬁlter models directly acoustic waveforms avoiding artiﬁcial frame boundaries therefore allowing better modelling short duration events. consider consonant-vowel classiﬁcation illustrate importance power normalisation waveform domain although full implementation method tests benchmark tasks like timit remain explored. mesot barber later proposed switching linear dynamical systems explicitly modelling speech time series. slds approach exhibited signiﬁcantly better performance recognising spoken digits additive gaussian noise compared standard hidden markov models however computationally expensive even approximate inference techniques used. turner sahani proposed using modulation cascade processes model natural sounds simultaneously many time-scales application approach remains explored. paper directly time series interpretation impose temporal constraints models. instead investigate effectiveness acoustic waveform front-end robust phoneme classiﬁcation using gaussian mixture models models commonly used conjunction hmms practical applications. section show results exploratory data analysis ﬁrst investigates non-linear structures data sets formed realisations individual phonemes across many different speakers. speciﬁcally consider phoneme segments ﬁxed duration. results suggest data non-linear manifolds lower dimension linear dimension phoneme segments. however given available training data limited estimated values non-linear dimension still relatively large possible accurately characterise manifolds point used improve classiﬁcation. preliminary experiments small subset phonemes therefore employ standard classiﬁers using full covariance matrices followed lower-rank approximations derived probabilistic principal component analysis latter account linear manifold structures data. results experiments show acoustic waveforms potential provide robust classiﬁcation also high dimensional data sparse even mixtures ppca trained accurately. section develop ﬁxed duration segment models using gmms diagonal covariance matrices. reduces number parameters required specify models further beyond achieved ppca. make diagonal covariance matrices good approximation requires suitable orthogonal transform acoustic waveforms. among different transforms type achieve approximate decorrelation waveform features identify discrete cosine transform effective. exact noise adaptation method used preliminary experiments extends immediately resulting features. analogues delta features acoustic waveforms instead consider longer duration segments include information used delta features. preliminary conclusions noise robustness linear features remain valid including standard timit test realistic situations abstract—phoneme classiﬁcation investigated linear feature domains improving robustness additive noise. linear feature domains noise adaptation exact potentially leading accurate classiﬁcation representations involving non-linear processing dimensionality reduction. generative framework developed isolated phoneme classiﬁcation using linear features. initial results shown representations consisting concatenated frames centre phoneme containing frames. phonemes variable duration single optimal phonemes therefore average taken models range values results improved including information entire phoneme transitions. presence additive noise classiﬁcation framework performs better analogous classiﬁer adapted noise using cepstral mean variance normalisation snr. finally propose classiﬁcation using combination acoustic waveform log-likelihoods. combined classiﬁer performs uniformly better either individual classiﬁers across noise levels. systems still lack performance compared human listeners adverse conditions involve additive noise systems improve performance conditions using additional levels language context modelling. however contextual information effective underlying phoneme sequence sufﬁciently accurate. hence robust phoneme recognition important stage asr. accordingly front-end features must selected carefully ensure best phoneme sequence predicted. paper investigate performance front-end features isolated effect higher level context. phoneme classiﬁcation commonly used purpose. particularly interested linear feature domains i.e. features linear function original acoustic waveform signal. domains additive noise acts additively consequently noise adaptation statistical models speech data performed exactly convolution densities. ease noise adaptation linear feature domains contrasts situation commonly used speech representations. instance mel-frequency cepstral coefﬁcients perceptual linear prediction coefﬁcients involve non-linear dimension reduction makes exact noise adaptation difﬁcult practice. order acoustic waveforms realise potential beneﬁts exact noise adaptation modelling classiﬁcation framework required exploring details framework objectives paper. section investigate effect segment duration classiﬁcation error. ﬁndings show single segment duration optimal phoneme classes taking average duration error rate signiﬁcantly reduced. related issue variable phoneme length addressed incorporating information sectors phoneme. frame averaging sector implemented using plp+∆+∆∆ front-end obtain error rate quiet conditions better previously reported results using gmms trained maximum likelihood. stages consistently classiﬁcation using plp+∆+∆∆ representation accurate quiet conditions acoustic waveform robust additive noise. finally consider combination plp+∆+∆∆ acoustic waveform classiﬁers gain beneﬁt representations. resulting combined classiﬁer achieves excellent performance slightly improving best plp+∆+∆∆ classiﬁer give quiet conditions signiﬁcantly robust additive noise existing methods. constructing probabilistic models high-dimensional linear feature speech representations ﬁrst investigate possible lower dimensional structure phoneme classes. supposing structure exists characterised could used better representations speech construct accurate probabilistic models. many speech representations reduce dimension speech signals using non-linear processing prominent examples mfcc plp. methods directly incorporate information structure phoneme class distributions instead model properties speech perception. initially interested data-driven methods dimensionality reduction explored including linear discriminant analysis locally linear embedding isomap linear approaches like projected feature space reduced dimension could deﬁned would preserve beneﬁts linear feature representation. however useful case waveform distribution class zero mean cannot discriminate classes. non-linear methods powerful used reduce dimension feature space nonlinear mapping features would make exact noise adaptation impossible instead would nonlinear dimensional structures phoneme distributions exploit information build better models remain deﬁned original high dimensional space. could include gaussian process latent variable models require input estimate dimension non-linear feature space. shown although intrinsic dimension estimates suggest dimensional structures exist phoneme distributions insufﬁcient data adequately sample manner would practical automatic speech recognition purposes. starting acoustic waveform representation want explore phoneme class distributions approximated dimension manifolds. particular given phoneme class form ﬁxed length-segments extracted centre realisation phoneme database scaled ﬁxed vector norm. -sample segments corresponding sampling rate timit database. thus captures variability phoneme different speakers pronunciations instances. want determine modelled low-dimensional submanifold submanifold could characterised manner would facilitate accurate statistical modelling data. ﬁrst applied number intrinsic dimension estimation techniques extracted sets principal component analysis ﬁrst method considered assumes data contained linear subspace. dimension subspace estimated requiring contain average phoneme energy threshold dimension estimate used reference compare three methods non-linear dimension estimation. particular investigate estimators developed hein costa takens applied phomeme class data. figure shows result dimension estimation phonemes different consonant groups. ﬁndings agree intuition vowel-like phonemes lower dimension fricatives. typical dimension semivowel nasal phoneme given estimates would around case shown figure fricatives like dimension much higher. given non-linear dimension estimates mostly consistent signiﬁcantly lower estimates conclude phoneme distributions modelled lowerdimensional non-linear manifolds. number techniques recently developed non-linear manifold structures data extensive study beneﬁts limitations methods isomap selected application phoneme dataset. considered especially suitable task successfully found low-dimensional structure images human faces handwritten digits studies. explained above although methods structure straightforward apply noise adaptation non-linearly reduced feature sets. would therefore seek identify non-linear structures exploit constrain density models original linear feature space. show however dimensions nonlinear structures case still high learned accurately available quantity data. isomap method ﬁnding lower dimensional approximation dataset using geodesic distance estimates. initial comparison output showed given embedding dimension approximation provided isomap better terms error data. look step change spectrum appropriate gram matrix dimension estimate. however possible phoneme data spectra gram matrices smooth phonemes. found similar results suspected cases cause undersampling manifold. ﬁndings motivated study artiﬁcial problem estimate much data might required sufﬁciently sample phoneme manifolds. simple example uniform probability distributions hyperspheres given dimension considered. smooth histogram pairwise distances among sampled points indicates sufﬁcient sampling uniform target distribution whereas strong peaks resulting fact random vectors high dimensional spaces typically orthogonal suggest undersampling. initially dimension hypersphere comparable phoneme dimension estimates used similar number data points peaks distance histograms indeed present. dimension hypersphere reduced peaks smoothed suggesting ﬁve-dimensional manifold weight mean vector covariance matrix mixture component respectively. case acoustic waveforms additionally impose zero mean constraint models waveform perceived constraint corresponding models represent information phoneme distributions covariance matrices component weights. probabilistic principal component analysis preliminary experiments initially modelled phoneme class densities using gmms full covariance matrices. however possible accurately models components high dimensional space acoustic waveforms instead considered using density estimates derived mixtures probabilistic principal component analysis method dimensionality reduction interpretation produces gaussian mixture model covariance matrix component regularised replacement rank-q approximation corresponding eigenvalue eigenvector empirical covariance matrix eigenvalues arranged descending order. regularisation parameter taken mean remaining eigenvalues noise adaptation primary concern paper investigate performance trained classiﬁers presence additive gaussian noise. generative classiﬁcation particularly suited robust classiﬁcation estimated density models capture distribution noise corrupted phonemes. noise additive acoustic waveform domain signal noise models speciﬁed separately combined exactly convolution. experiments section phoneme data normalised phoneme segment level speciﬁed relative segment rather whole sentence. clearly unrealistic mean energy phonemes differs signiﬁcantly classes. however provide situation phoneme class affected local snr. also think geometrically phoneme class class density blurred convolution isotropic gaussian variance snr. effect noise classiﬁcation indirectly provides information well separated different phoneme classes space acoustic waveforms white gaussian noise model results covariance matrix multiple identity matrix noise variance. assume throughout known estimated reliably periods without speech activity using techniques hence noise adaptation acoustic waveform representation given replacing covariance matrix speech waveforms normalised unit energy sample. clearly normalisation type needed avoid adverse effects irrelevant differences speaker volume classiﬁcation performance issue carefully studied previous work summary ﬁndings experiments suggest speech data manifolds exist acoustic waveform domain under-sampled relatively high intrinsic dimension. number required data points could expected vary exponentially intrinsic dimensions i.e. constant hypersphere experiments approximately four consequently estimated quantity data required sufﬁciently sample phoneme manifold would unrealistic particularly upper range. given data-driven dimensionality reduction methods explored practical task considered turn generic density models problem phoneme classiﬁcation presence additive noise. particular construct generative classiﬁers highdimensional space attempt exploit submanifold structure directly. approximations required sparseness data also computational constraints. generative classiﬁers probability density estimates learned class training data. predicted class test point determined class greatest likelihood evaluated typically log-likelihood used calculation; denote log-likelihood log). classiﬁcation performed using following function gaussian mixture models without assuming additional prior knowledge phoneme distributions gaussian mixture models model phoneme densities. models trained using expectation maximisation algorithm maximise likelihood training data relevant phoneme class. training algorithm determines suitable parameters fig. errorofplpclassiﬁers asafunction oftestsnr.eachcurveshows theerroroftheclassiﬁertrainedatthesnrindicated bythecurvemarker.the curvesshowthesensitivityofplpclassiﬁerswhenthereisamismatchbetween trainingandtestingnoiseconditions.inparticular theclassiﬁerstrainedatdb performs much worse test noise level lower traininglevel. data standardised prior training features zero mean unit variance across entire training considered. discuss variants feature standardisation section iii-a. phoneme distributions modelled using single component ppca mixture principal dimension i.e. experimented values parameters gave best results. figure shows test results classiﬁers trained data corrupted different noise levels. curves thus represents different training snr. clear classiﬁers highly sensitive mismatch training testing noise conditions. example conditions matched error however classiﬁer tested quiet conditions value increases signiﬁcantly analogous plot waveform classiﬁers shown figure phoneme classes modelled acoustic waveform classiﬁers less sensitive mismatch between assumed noise level adapted using true testing conditions. taking classiﬁer adapted example assumed true testing conditions matched error testing quiet remains although error matched conditions higher noise level increase mismatch drastically reduced. next consider scenario true testing conditions matched models trained adapted equivalent taking lower envelopes figures case gives lower error rate waveforms opposite true value. results suggest seek combine classiﬁcation strengths representation speciﬁcally high accuracy classiﬁers high snrs robustness acoustic waveform classiﬁers noise levels. ideally result single combined classiﬁer needs trained quiet conditions easily adapted range noise conditions. investigate concept consider following normalisation leads density models covariance matrices trace dimension data. adding noise numerator equation would give average energy sample also normalise noisy speech unit energy sample hence rescale adapted covariance matrix indicated above. exact method combining models training data noise models case mfcc features representations involve non-linear transforms waveform data. parallel model combination proposed gales young approximate approach mfcc. commonly used alternative method adapting probabilistic models additive noise cepstral mean variance normalisation consider method subsequent sections. exploratory stage study instead matched condition scenario training testing noise conditions separate classiﬁer trained noise condition. practice would difﬁcult computationally expensive distinct classiﬁer every noise condition particular noise varying spectral shape included test conditions. matched conditions nevertheless useful exploratory classiﬁcation experiments training data comes directly desired noisy speech distribution assuming enough data available estimate class densities accurately approach provides optimal baseline noise adaptation methods exploratory study consider realisations phonemes extracted timit database includes examples fricatives nasals semivowels voiced unvoiced stops. classes provide pairwise discrimination tasks varying level difﬁculty. example challenging discrimination /z/. phoneme examples represented centre segment acoustic waveform corresponding samples khz. additionally stops release point prescribed given timit segmentation. data vectors normalised squared norm equal dimension segment corresponding unit energy sample explained above. initial experiments focus centre phonemes investigate effectiveness noise adaptation. well known discrimination improved considering information provided transitions phonemes next. explore section indeed signiﬁcantly help classiﬁcation. phoneme class consists approximately representatives used training testing. classiﬁcation error bars indicated derived considering different splits give indication signiﬁcance differences accuracy classiﬁers. range snrs chosen explore classiﬁcation errors chance level i.e. case classes. total gave testing training conditions; quiet. exploratory stage white gaussian noise considered. number examples class thus prior probabilities equal effect predictions according comparison default order cepstra computed segments. sliding hamming window used overlap leading four frames coefﬁcients four frames concatenated give representation fig. errorofacousticwaveformclassiﬁers asafunction oftestsnr.the curve marker indicates assumed classiﬁer adapted using.theerrorrateislesssensitivetomismatchbetweentheassumedand thetruesnrwhencomparedtothecurvesinfigure. fig. performanceofthecombinedclassiﬁerwhenplpmodelstrainedunder matched conditions used. combined classiﬁer uniformly least accurate derived gives signiﬁcant improvement around snr. inset comparison combined classiﬁer trained quietconditions. convex combination log-likelihoods term normalised relevant representation dimension. lplp lwave log-likelihoods phoneme class combined log-likelihood parameterised given dplp dwave dimensions acoustic waveform representations respectively. would expect almost zero high snrs close snrs order give desired improvement accuracy information combination function suitable range possible values identiﬁed noise level condition error rate error best range broad particular form ﬁtted combination function critical choose following sigmoid function parameters numerically determined suitable ranges gives also consider combinations involving classiﬁers trained quiet conditions adapted noise using cmvn similar gives using multiple streams features consisting waveform features derived waveform segment. data fusion feature level concatenates vectors features source would alternative method combining representations. however method would suitable combination acoustic waveforms predominantly contribution resulting likelihood representation approximately proportional feature space dimension. hence likelihood contribution acoustic waveform portion fused vector would dominate. figure shows result combination acoustic waveform classiﬁers trained quiet conditions adapted noise according classiﬁers trained matched conditions. main plot combined classiﬁer uniformly lower error rate across full range noise conditions. particular around combination performs signiﬁcantly better either underlying classiﬁers. interesting means combination achieves hard switch waveform classiﬁers could. inset shows comparison combined classiﬁers involving trained matched conditions trained quiet adapted using cmvn respectively. approaches training represent extremes performance noise adaptation techniques advanced cmvn expected between. encouragingly inset figure shows appropriate combination waveform classiﬁers performance models trained quiet conditions trained matched conditions dramatically reduced. exploratory data analysis shows acoustic waveform classiﬁers exactly adapted noise noise conditions known also robust mismatch assumed true testing conditions. combined classiﬁer retains accuracy quiet conditions whilst simultaneously providing robustness acoustic waveforms presence noise. order conﬁrm conclusions realistic test required. described above also found best model obtained small number mixture components whether using full covariance matrices restricted density models form mppca. cases many model parameters required specify mixture component meaning mixtures many components cannot learned reliably limited data. next section issue parameter count reduction even acute many phoneme classes even fewer examples considered far. problem addressed using diagonal covariance matrices gmms data appropriately rotated basis approximately decorrelates data. additionally snrs speciﬁed sentence level cause local mismatch provide challenging test robustness classiﬁers. also investigate length segments used represent phonemes. effectively mixture mixtures start selection models parameterised number components takes values subsets entries uniformly distributed scale give good range model complexity without including many complex models. compute model average log-likelihood log-likelihood alternatively mixture weights allocated model could determined posterior densities models development give class dependent weighting i.e. development set. preliminary experiments suggested using posterior weights gives slight improvement therefore adopt uniform weights results shown paper. noise adaptation sentence-normalised data consider realistic case known sentence-level. sentences therefore normalised unit energy sample quiet noisy conditions. different phonemes within sentences higher lower energies reﬂected density models covariance trace dimension feature vectors. relative energy phoneme class discarded section ii-c thus used classiﬁcation. adaptation noise form covariance matrix noise transformed normalised trace white noise identity matrix otherwise estimated empirically noise samples. general full covariance matrix required specify noise structure. however suitable choice resulting close diagonal indeed segmented true experiments pink noise. avoid signiﬁcant computational overheads introducing non-diagonal matrices therefore retain diagonal elements normalisation arises before average clean sentence noise added energy sample normalisation unit energy clean noisy data requires dividing covariances factor. contrast exploratory study section varying local traces longer necessarily equal. consider noise compensation techniques mfcc features. mentioned above cepstral mean variance normalisation approach commonly used practice compensate noise corrupted features. method requires estimates mean variance features usually calculated sentencewise test data moving average similar time window. take realistic baseline. alternatively required statistics estimated training corrupted type level noise used testing. clearly approaches merit. example sentence level cmvn requires direct knowledge test conditions remove speaker speciﬁc variation particularly relevant comparing acoustic waveform classiﬁers plp+∆+∆∆ deltas information neighbouring frames. shown optimising numbers frames representation similar beneﬁt phoneme classiﬁcation using deltas. finally show effect including information whole phoneme rather frames centre. iii. fixed duration representation refined models section consider enhance generative models deal realistic classiﬁcation tasks. previous experiments repeated standard timit benchmark noise added speciﬁed sentence level. means local phoneme segments differ signiﬁcantly sentence level value. large variation size phoneme classes hence relative frequencies greater effect prior also consider model averaging removes need select number components mixture models. diagonal covariance matrices observed preliminary exploration even ppca requires excessive number parameters compared quantity available data. hence gmms diagonal covariance matrices used following experiments. common modelling approximation training data sparse. diagonal covariances matrices good approximation provided data presented basis correlations features weak. acoustic waveform representation clearly case account strong temporal correlations speech waveforms. therefore systematically investigated candidate low-correlation bases derived wavelet transforms dcts. although optimal basis decorrelation training indeed formed phoneme-speciﬁc principal components found lowest test error fact achieved basis. density model used phoneme classes acoustic waveform domain becomes weight mean vector diagonal covariance matrix mixture component respectively. orthogonal transformation selected decorrelate data least approximately. case acoustic waveforms choose matrix explained above. preliminary experiments showed that instead performing single entire phoneme segment advantageous separate dcts non-overlapping subsegments length mirroring frame decomposition mfcc plp. sampling rate data transformation matrix block diagonal consisting blocks. mfcc representations choose identity matrix already involve form features approximately decorrelated. model average general variability training data captured increased number mixture components; however many components used over-ﬁtting occur. best compromise usually located cross validation using classiﬁcation error development set. result single value number components required. alternative approach take model average number components fig. model averaging acoustic waveforms mfcc models trained tested quiet conditions. solid gmms number componentsshown;dashedaverageovermodelsuptonumberofcomponents shown.themodelaveragereducestheerrorrateinallcases. overlap also include comparisons mfcc features. standard implementations mfcc default parameter values used produce -dimensional feature vector time frame. inclusion increases dimension exploratory results section gave successful classiﬁcation acoustic waveforms using window. mfcc representations therefore consider frames closest centre phoneme covering concatenate feature vectors. results shown representations without giving feature vector dimensions respectively. acoustic waveform representation obtained dividing sentence sequence non-overlapping frames taking seven frames closest centre phoneme resulting dimensional feature vector. frame individually processed using -point dct. present results white pink noise approximation using diagonal covariances basis sufﬁcient give good performance. impact number frames included mfcc acoustic waveform representations investigated next section. gaussian mixture models trained components representations. comment brieﬂy results individual mixtures i.e. ﬁxed number components. typically performance quiet data improved number components although signiﬁcant cost training testing. optimal number components mfcc models quiet conditions maximum considered here. however presence noise lowest error rates obtained components; typically improvement beyond four components. explained section iii-a rather working models ﬁxed numbers components average models i.e. number mixture components results reported below. figure shows improvement obtained quiet conditions approximately acoustic waveforms data. estimates less accurate consequence difﬁcult standardise components long feature vectors obtained concatenating frames; instead standardise frame frame. using noisy training cmvn requires test conditions known either data collected generated training conditions. feature means variances obtained accurately particular standardise longer feature vectors. however standardisation used sentences variation individual speakers persist. comparison standardisation techniques shown figure curves displayed methods using features without ∆+∆∆. standardisation noisy training gives lower error rates quiet conditions noise hence results cmvn given method. realisations phonemes extracted sentences timit database. training consists sentences sampled khz. noisy data generated applying additive gaussian noise nine snrs. recall snrs sentence level therefore local individual phonemes differ signiﬁcantly value causing mismatch classiﬁers. total testing training conditions run; increments quiet following extraction phonemes total phoneme realisations. glottal closures removed remaining classes combined groups accordance even combination resulting groups realisations. smallest groups fewer realisations increased size addition temporally shifted versions data. i.e. example small training classes phoneme segments extracted positions shifted samples also included training. increase size smaller training classes ensures training procedure stable. purposes calculating error rates similar phoneme groups regarded identical resulting groups effectively distinguishable phonemes features obtained standard manner frames width shift neighbouring frames correspondingly fig. comparisonofadaptedacousticwaveformclassiﬁerswithmfccand classiﬁers trained quiet conditions adapted feature standardisation. allclassiﬁersusethemodelaverageofmixturesuptocomponents.dotted lineindicates chancelevelat.%.whenthesnrislessthatdbacoustic waveforms signiﬁcantly better representation withan error rate chanceevenat-dbsnr.dashedcurvesshowresultsofmatchedtrainingfor correspondingmfccandplprepresentations. ideally relevant information retained phoneme representation difﬁcult determine exactly information relevant initially choose take consecutive frames closest centre phoneme concatenate them. whilst precise number frames required accurate classiﬁcation could principle inferred statistics phoneme segment durations table durations vary signiﬁcantly classes also standard deviation within class least therefore single length suitable classes. determination optimal data statistics would even complicated ∆+∆∆ included incorporate additional information dynamics signal outside frames. assuming single value optimal phoneme classes instead consider mixture log-likelihoods deﬁned indexed number frames used. taken contains values lowest corresponding error rate example {xf|f vector frames. note adding log-likelihoods different amounts assuming independence different clearly imperfect model e.g. components also contained fully correlated experiments show useful practice. also implemented alternative concatenating longer feature vector training joint model this potential beneﬁts accounting correlations outweighed disadvantages density models higher dimensional spaces. consistent independence assumption noise adapt models results comparing error rates noise phoneme classiﬁcation three domains shown figure mfcc classiﬁers adapted noise using cmvn. method comparable adapted waveform models relies models trained quiet conditions. curve acoustic waveforms models trained quiet conditions adapted appropriate noise level using comparing waveforms ﬁrst mfcc without ∆+∆∆ quiet conditions representation gives lowest error. error rates mfcc signiﬁcantly worse presence noise however acoustic waveforms giving absolute reduction error compared mfcc respectively. results strengthen case adaptability acoustic waveform models gives deﬁnite advantage presence noise crossover point occurring snr. curves also shown mfcc+∆+∆∆ plp+∆+∆∆. trend holds; performance good quiet conditions quickly deteriorates decreases. crossover point around representations. chance-level error rate seen mfcc representations without deltas deltas included whereas acoustic waveform classiﬁer performs signiﬁcantly better chance error even snr. dashed curves figure represent error rates obtained classiﬁers trained matched conditions without ∆+∆∆. results show waveform classiﬁer compares favourably mfcc deltas appended. including ∆+∆∆ reduce error rates signiﬁcantly crossover occurs snr. observations mainly motivate models development below clearly include information similar deltas waveform representation. experiment repeated using pink noise extracted noisex- database results noise types similar waveforms classiﬁers. plp+∆+∆∆ adapted noise using cmvn larger difference noise types pink noise leading lower errors. nevertheless better performance achieved acoustic waveforms snr. results classiﬁcation timit benchmark quiet conditions previously reported errors respectively. ensure baseline valid compared experiment quiet conditions plp+∆+∆∆ obtained comparable error rate indicated bottom right corner figure following encouraging results seek explore effect optimising number frames inclusion information entire phoneme. expectation including frames concatenation acoustic waveforms similar effect adding ∆+∆∆ mfcc plp. direct analogue deltas unlikely useful waveforms mfcc based magnitude spectra change little stationary phonemes local averaging differencing meaningful. waveforms effectively retain fourier component amplitudes also phases phases combine essentially randomly averaging differencing rendering resulting delta-like features useless. fig. comparison phoneme representations. division described resulting sectors three covering duration phoneme duration around transitions. bottom frames closest theﬁvepointsabcdande selected phoneme segment feature vectors although phonemes vary duration gmms require data consistent dimension. next establish method variable length phoneme segments ﬁxed length representation classiﬁcation. previous subsection frames centre phoneme segments used represent phoneme. extend centre-only concatenation information entire segment taking frames centres closest time instants abcd distributed along duration phoneme shown figure manner representation consists sequences frames phoneme. sets frames concatenated give vectors train models sectors combine information provide sector assuming independence taking log-likelihoods sectors figure shows impact number frames concatenated sector classiﬁcation error focusing quiet conditions. best results acoustic waveform classiﬁers achieved around frames around frames without deltas. plp+∆+∆∆ features less sensitive number frames little difference error frames. also assess quantitatively performance beneﬁt including deltas. consider best results obtained without deltas using frames best plp+∆+∆∆ frames performance much smaller compare error rates classiﬁers used number frames. clearly surprising fewer plp+∆+∆∆ frames required level performance deltas direct function neighbouring frames. still worth noting terms ultimate performance classiﬁcation task error rates without deltas similar. results discussed directly comparable baseline results studies shown table iii. error rates obtained using f-average best values acoustic waveforms plp+∆+∆∆ respectively. table shows absolute percentage error reduction four classiﬁers quiet conditions compared single best number mixture components number frames relative beneﬁts f-average sector clear. sector gives bigger improvements cases compared f-average combination methods better still throughout. qualitative trend holds true noise. figure compares performance ﬁnal classiﬁers including f-average sector data corrupted pink noise. solid curves give results acoustic waveform classiﬁer adapted noise using classiﬁer without ∆+∆∆ trained quiet conditions adapted noise cmvn. errors generally signiﬁcantly lower figure showing beneﬁts f-averaging sector sum. plp+∆+∆∆ remains better representation noise waveforms give lower errors beyond crossover point depending whether compare without ∆+∆∆. before also perform better chance snr. dashed lines figure show comparison performance classiﬁers trained matched conditions. explained cmvn matched curves provide extremes would expect classiﬁer perform model adaption analogous used acoustic waveforms possible method improve robustness order polynomial kernel large margin regularized least squares hidden conditional random ﬁelds hierarchical lmgmm optimum-transformed context committee hierarchical lmgmm noise present combined classiﬁer least accurate acoustic waveform classiﬁer signiﬁcantly better around snr. combined classiﬁer improve upon plp+∆+∆∆ classiﬁers trained matched conditions narrows performance order throughout rather comparing plp+∆+∆∆ adapted cmvn. paper studied potential beneﬁts phoneme classiﬁcation linear feature domains directly related acoustic waveform implementing exact noise adaptation resulting density models. section outlined results exploratory data analysis found intrinsic nonlinear dimension estimates lower linear dimension estimates pca. observation suggested possible construct dimensional embeddings used later generative classiﬁers. however existing techniques failed enough structure phoneme dataset sparse accurately deﬁne embeddings. consequently used gmms model phoneme distributions acoustic waveform domains. additionally combined classiﬁer used incorporate performance quiet conditions noise robustness acoustic waveforms. given encouraging results experiments small phonemes progressed realistic task extended classiﬁcation problem include phonemes timit database. gave results could directly compared existing results table classiﬁers representing current progress timit benchmark. entries show error isolated phoneme classiﬁcation except optimum-transformed uses context information derived continuous speech. inclusion context classiﬁers reduces error rate dramatic reduction suggests classiﬁers also developed directly incorporate contextual information signiﬁcant improvements could expected. used standard approximation diagonal covariance matrices reduce number parameters required specify gmms. issue selecting number components mixture models approached taking model average respect number components sufﬁciently large values. results supported earlier conclusions also fig. error rates different representations quiet conditions function number frames considered. dashed prediction using central sector. dotted prediction using ﬁvesectorsleadingtoaclearimprovementinallcases. employed etsi advanced front-end expected matched conditions plp+∆+∆∆ classiﬁer best performance snr. however noise adapted acoustic waveform classiﬁer signiﬁcantly closer matched plp+∆+∆∆ plp+∆+∆∆ cmvn. results shown that preliminary experiments performs best quiet conditions acoustic waveforms robust additive noise. gain beneﬁts representations propose merge linear combination corresponding log-likelihoods parameterised coefﬁcient tplp twave log-likelihoods point used place predict class. combination differs effect prior class probabilities relevant absolute log-likelihoods must used rather scaled quantities. equivalent multistream model sector value independent stream. noise-dependent determined explained section ii-c giving parameter values error combined classiﬁer using models trained quiet conditions shown dash-dotted curve figure quiet conditions combined classiﬁer slightly accurate plp+∆+∆∆ alone corresponding small value chengalvarayan deng hmm-based speech recognition using state-dependent discriminatively derived transforms melwarped features ieee trans. speech audio processing vol. fig. performance classiﬁers pink noise. curves shown best representation fig. using f-average sector sum. dash-dotted line combined waveform plp+∆+∆∆ classiﬁer latteradaptedtonoisebyfeaturestandarisation usingcmvn. illustrated waveforms potentially lacking signiﬁcant beneﬁts obtained ∆+∆∆ features. motivated improve classiﬁers using multiple segment durations taking log-likelihoods. information whole phoneme included repeating process centred points phoneme. best practical classiﬁers paper obtained using combination acoustic waveforms plp+∆+∆∆. expect results improved including techniques considered authors particular committee classiﬁers hierarchy reduce broad phoneme class confusions models could developed explicitly model correlations feature vectors obtained different number frames also feature vectors different sectors provided sufﬁcient data available. additionally weighting sector frame average allowing number frames different sector could investigated. finally given qualitative similarity features different sectors features would emitted different states hmms would also interest explore linear feature sets used context continuous speech recognition. sheikhzadeh deng waveform-based speech recognition using hidden filter models parameter selection sensitivity power normalization ieee trans. speech audio processing vol. rifkin schutte saad bouvrie glass noise robust phonetic classiﬁcation linear regularized least squares second-order features proc. icassp iv––iv– abstract—speech representation modelling highdimensional spaces acoustic waveforms linear transformation thereof investigated improving robustness automatic speech recognition additive noise. motivation behind approach twofold information acoustic waveforms usually removed process extracting low-dimensional features might robust recognition virtue structured redundancy analogous channel coding linear feature domains allow exact noise adaptation opposed representations involve non-linear processing makes noise adaptation challenging. thus develop generative framework phoneme modelling highdimensional linear feature domains phoneme classiﬁcation recognition tasks. results show classiﬁcation recognition framework perform better analogous mfcc classiﬁers snr. combination high-dimensional mfcc features likelihood level performs uniformly better either individual representations across noise levels. speech recognition systems lack robustness manifested substantial performance degradation common environmental distortions discrepancy between training run-time conditions spontaneous conversational pronunciation long believed context language modelling would provide level robustness inherent human speech recognition hence substantial research efforts invested higher levels speech recognition systems. time importance robust recognition isolated phonemes syllables nonsense words fully investigated well known humans attain major portion robustness speech recognition early process independently context effects moreover language context modelling work optimally elementary speech units need recognised sufﬁciently accurately. recognising syllables isolated words human auditory system performs chance level already signiﬁcantly recent detailed studies show human speech recognition remains unaffected noise work done ager department mathematics king’s college london. sollich department mathematics cvetkovi´c department informatics king’s college london strand london automatic speech classiﬁer able achieve performance close human auditory system recognising isolated words phonemes severe noise conditions systems deliver performance owing sophisticated language models combined hidden markov model advances however problem robustness lack thereof still persists underlying concern robustly recognising isolated phonetic units remains important unresolved issues. hence study explore novel approach representing modelling speech investigate effectiveness context phoneme classiﬁcation recognition. many reasons lack robustness major factors could excessive nonlinear compression takes place front-end systems. ﬁrst step speech recognition algorithms consecutive speech segments represented lowdimensional feature vectors commonly cepstral features mel-frequency cepstral coefﬁcients perceptual linear prediction coefﬁcients using low-dimensional features unavoidable initially introduced removes non-lexical variability irrelevant recognition enables learning statistical models limited data using limited computational resources. however paradigm resulted major performance boost decades might bottleneck towards achieving robustness nowadays massive amounts training data available computers orders magnitude powerful. process discarding components speech signal considered unnecessary recognition information makes speech robust message representation might lost. commonly believed speech representations used compression also provide good feature vectors speech recognition. rationale that since speech reconstructed compressed form sound like natural speech human auditory system recognise quite reliably relevant information lost compression. speech production/recognition however analogous channel coding/decoding problem speech compression source coding problem fundamentally different. particular speech production embeds redundancy speech waveforms highly structured manner distributions different phonetic units withstand signiﬁcant amount additive noise distortion overlap signiﬁcantly. speech compression standard front-ends hand remove redundancy manner optimal source coding perspective represent speech space relatively dimension different speech units although separated sufﬁciently apart other; overlap considerably already lower noise levels original domain acoustic waveforms. human speech perception studies shown explicitly information reduction takes place conventional front-ends leads severe degradation human speech recognition performance furthermore noisy environments high correlation human machine errors recognition speech distortions introduced typical front-end processing hence paper study models speech high-dimensional domain acoustic waveforms linear transform thereof. additional beneﬁt considering uncompressed waveforms modelling noisy data given models quiet straightforward. contrast cepstral representations where nonlinearities involved distributions change considerably noise type level. makes efﬁcient adaption speech models different noise conditions challenging. linear representations considered previously authors. sheikhzadeh deng apply hidden ﬁlter models directly acoustic waveforms avoiding artiﬁcial frame boundaries therefore allowing better modelling short duration events. consider consonant-vowel classiﬁcation illustrate importance power normalisation waveform domain although full implementation method tests benchmark tasks remain explored. poritz later ephraim roberts consider modelling speech explicitly time series using autoregressive hidden markov models. work inspired recent advances direction mesot barber develop switching linear dynamical systems framework. slds approach exhibited signiﬁcantly better performance recognising spoken digits additive gaussian noise compared standard hidden markov models used combination cepstral features; however computationally expensive even approximate inference techniques used. turner sahani proposed using modulation cascade processes model natural sounds simultaneously many time-scales application approach remains explored. paper directly time series interpretation impose temporal constraints models. instead investigate effectiveness acoustic waveform front-end robust phoneme classiﬁcation recognition using gaussian mixture models models commonly used conjunction hmms practical systems. assess merits representing speech without information loss non-linear transformation without potentially interfering effects segmentation section ﬁrst develop gaussian mixture models ﬁxed-length segments speech phoneme classiﬁcation presence additive noise. next section investigate effect segment duration classiﬁcation error. section compare high-dimensional representation features phoneme classiﬁcation task uses information entire phonemes. finally section consider phoneme recognition continuous speech standard hmm-gmm framework. scenarios investigate mfcc features excel lownoise conditions high-dimensional linear representation achieve better results higher noise levels starting already around snr. demonstrate combination high-dimensional linear cepstral features achieves better results either individual representations across noise levels. recently power normalised cepstral coefﬁcients features proposed robust speech recognition became aware features time submission paper hence features considered study. generative classiﬁers probability density estimates learned class training data. predicted class test point determined class greatest likelihood evaluated typically log-likelihood log) used calculation. test point thus assigned classes using following function inclusion prior probability class means effectively maximising log-posterior probability class given section build probabilistic models ﬁxed-length segments acoustic waveforms phoneme classes. waveform segment thus vector number time samples segment. highdimensional speech representations acoustic waveform domain investigate possible lower dimensional structures phoneme classes. supposing structure exists characterised could used better representations speech construct accurate probabilistic models. thus initially deployed data-driven methods learning possible low-dimensional manifolds explored including locally linear embedding isomap many speech representations typically variant mfcc reduce dimension speech signals using nonlinear processing. methods directly incorporate information phoneme class distributions model properties speech perception. involved non-linear processing however makes exact noise adaptation challenging instead would non-linear low-dimensional structures phoneme distributions exploit information build better models remain deﬁned original high-dimensional space. could include gaussian process latent variable models require input estimate dimension non-linear feature orthogonal transformation selected decorrelate data least approximately weight mean vector diagonal covariance matrix mixture component respectively. systematically investigated candidate decorrelating bases derived wavelet transforms dcts. although optimal basis decorrelation training indeed formed phoneme-speciﬁc principal components found lowest test error achieved basis. preliminary experiments acoustic waveforms showed that instead performing entire phoneme segment advantageous separate dcts non-overlapping sub-segments. systematically investigated different block lengths found best classiﬁcation results obtained blocks mirroring frame decomposition mfcc plp. sampling rate transformation matrix block diagonal consisting blocks. density modelling motivated need decorrelate data thus make approximation covariance matrices diagonal ones accurate view result representation speech waveforms form short-time spectra analogous done towards extracting cepstral features. however fundamental difference blockdct transform short-time magnitude spectra used derive mfcc features former orthonormal transform rotation coordinate system preserves information whereas latter non-linear transform incurs dramatic information loss. particular discrete fourier transform also orthogonal transform retaining magnitude mfcc equivalent mapping discrete frequency whole circle value radius. gmms given also used mfcc features except component means constrained zero chosen identity matrix since features already involve form approximately decorrelated. general variability training data captured increased number mixture components; however many components used over-ﬁtting occur. best compromise usually located cross validation using classiﬁcation error development set. result single value number components required. however observed optimal number components decreases hence alternative approach take model average number components effectively mixture mixtures gave consistent classiﬁcation improvements individual mixtures across noise levels. thus start selection models parameterised number components takes values subsets entries uniformly distributed scale give good range model complexity without including space. however found intrinsic dimension estimates suggest existence dimensional nonlinear structures phoneme distributions investigation also showed structures still sufﬁciently many dimensions make impractical sample adequately purposes hence turn generic density models. particular construct generative models high-dimensional space attempt exploit submanifold structure directly. approximations still required sparseness data computational constraints. without assuming additional prior knowledge phoneme distributions gaussian mixture models model phoneme densities. case mixture components function form weight mean vector covariance matrix mixture component respectively. additionally impose zero mean constraint models waveform perceived constraint corresponding models represent information phoneme distributions covariance matrices component weights. reliable estimation full covariance matrices challenging even case standard low-dimensional features number components mixture becomes large. problem even pronounced case high-dimensional waveform features already segments dimension feature space becomes therefore considered using density estimates derived mixtures probabilistic principal component analysis method produces gaussian mixture model covariance matrix component regularised replacement rankq approximation however even ppca requires excessive number parameters compared typical amount available data finally gmms diagonal covariance matrices investigated common modelling approximation training data sparse used also state-of-the-art systems modelling distributions cepstral features. modelling approach achieved lowest classiﬁcation error experiments reported paper gmms diagonal covariance matrices used. diagonal covariance matrices good approximation provided data presented basis correlations features weak. acoustic waveform representation clearly case account strong temporal correlations speech waveforms. density model used phoneme classes thus becomes ucexp) model weights loglikelihood given c-component model. alternatively mixture weights could determined posterior densities models development give class dependent weighting i.e. development set. preliminary experiments suggested using posterior weights gives slight improvement therefore adopt uniform weights results shown paper. primary concern paper investigate performance trained classiﬁers presence additive noise. throughout study noise present testing assumed modelled gaussian distribution covariance matrix known exactly estimate. assumption valid real world scenarios good approximation providing noise stationary phoneme level. practice noise variance would estimated input signal many methods available provide good estimates noise types studied white gaussian noise variance known exactly pink noise extracted noisex- data base gaussian therefore tests robustness system case gaussian noise assumption hold. distribution noise estimated gaussian model later used noise adaptation. generative classiﬁcation particularly suited achieving robustness estimated density models capture distribution noise corrupted phonemes. noise additive acoustic waveform domain signal noise models speciﬁed separately combined exactly convolution. consider case sentence-level. sentences therefore normalised unit energy sample quiet noisy conditions. different phonemes within sentences higher lower energies reﬂected density models covariance trace dimension feature vectors. relative energy phoneme class thus implicitly used classiﬁcation. white noise identity matrix otherwise estimated empirically noise samples. general full covariance matrix required specify noise structure. however suitable choice resulting close diagonal indeed segmented true experiments pink noise. avoid signiﬁcant computational overheads introducing non-diagonal matrices therefore retain diagonal elements normalisation arises follows. considering sentences normalised unit energy sample vector containing samples sentence squared norm vector noise samples variance average squared norm shown noise assumed gaussian ﬂuctuations away average small relative order order overall cross-term squared norm noisy sentence vector large case normalising unit energy sample therefore equivalent rescaling rescaling applied noisy phoneme models gives precisely normalisation factor exact method combining models training data noise models case mfcc features representations involve non-linear transforms waveforms. cepstral mean variance normalisation approach commonly used practice compensate noise corrupted features. method requires estimates mean variance features usually calculated sentence-wise test data moving average similar time window. take realistic baseline. alternatively required statistics estimated training corrupted type level noise used testing. clearly approaches merit. example sentence level cmvn requires direct knowledge test conditions remove speaker speciﬁc variation data. estimates less accurate consequence difﬁcult standardise components long feature vectors obtained concatenating frames; instead considered standardising frame frame. using noisy training cmvn requires test conditions known data either collected generated training conditions. feature means variances obtained accurately particular standardise longer feature vectors. however standardisation used sentences variation individual speakers persist. found standardisation noisy training gives lower error rates quiet conditions noise hence results cmvn given method. fig. model averaging acoustic waveforms mfcc models trained tested quiet conditions. solid gmms number componentsshown;dashedaverageovermodelsuptonumberofcomponents shown.themodelaveragereducestheerrorrateinallcases. comment brieﬂy results individual mixtures i.e. ﬁxed number components. gaussian mixture models trained components representations. typically performance quiet data improved number components although signiﬁcant cost training testing. optimal number components mfcc models quiet conditions presence noise lowest error rates obtained components; typically improvement beyond four components. explained section ii-c rather working models ﬁxed numbers components average models results reported below. figure shows improvement obtained quiet conditions approximately acoustic waveforms small improvement seen mfcc also. model average similarly improved results noise. results comparing error rates white gaussian noise phoneme classiﬁcation three domains shown figure mfcc classiﬁers adapted noise using cmvn. method comparable adapted waveform models relies models trained quiet conditions. curve acoustic waveforms models trained quiet conditions adapted appropriate noise level using comparing waveforms ﬁrst mfcc without ∆+∆∆ quiet conditions representation gives lowest error. error rates mfcc signiﬁcantly worse presence noise however acoustic waveforms giving absolute reduction error compared mfcc respectively. curves also shown mfcc+∆+∆∆ plp+∆+∆∆ although representations include information unexploratory stage study also matchedcondition scenario training testing noise conditions separate classiﬁer trained noise condition. practice would impossible distinct classiﬁer every noise condition matched conditions nevertheless useful exploratory classiﬁcation experiments training data comes directly desired noisy speech distribution assuming enough data available estimate class densities accurately approach provides optimal baseline noise adaptation methods experiments reported paper realisations phonemes extracted sentences timit database. training consists sentences sampled khz. noisy data generated applying additive noise nine snrs. recall snrs sentence level therefore local individual phonemes differ signiﬁcantly value causing mismatch classiﬁers. total testing training conditions increments quiet following extraction phonemes total phoneme realisations. glottal closures removed remaining classes combined groups accordance even combination resulting groups realisations. ensure training procedure stable smallest groups fewer realisations increased size addition temporally shifted versions data i.e.if example small training classes phoneme segments extracted positions shifted samples also included training. purposes calculating error rates similar phoneme groups regarded identical resulting groups effectively distinguishable phonemes mfcc features obtained standard manner frames width shift neighbouring frames. standard implementations mfcc default parameter values used produce -dimensional feature vector time frame. inclusion dynamic ∆+∆∆ features increases dimension mfcc representations consider experiment centre phoneme covering concatenate feature vectors. results shown representations without ∆+∆∆ giving feature vector dimensions respectively. acoustic waveform representation obtained dividing sentence sequence non-overlapping frames taking seven frames closest centre phoneme resulting -dimensional feature vector. frame individually processed using -point dct. present results white pink noise approximation using diagonal covariances basis sufﬁcient give good performance. impact fig. resultsofphonemeclassiﬁcationusingﬁxed-lengthsegmentsinwhite gaussian noise. classiﬁers model average mixtures components.dottedlineindicateschancelevelat.%.whenthesnrisless thatdb acoustic waveforms arethesigniﬁcantly better representation anerrorratebelow chanceevenat-dbsnr.dashedcurves showresults matchedtraining forcorrespondingmfccandplprepresentations. take consecutive frames closest centre phoneme concatenate them. whilst precise number frames required accurate classiﬁcation could principle inferred statistics phoneme segment durations durations vary signiﬁcantly classes also standard deviation within class considerable. since single value optimal phoneme classes consider mixture log-likelihoods deﬁned indexed number frames used. taken contains values lowest corresponding error rates example giving {xf|f vector frames. note adding log-likelihoods different amounts assuming independence different clearly imperfect model e.g.all components also contained fully correlated experiments show useful practice. also implemented alternative concatenating longer feature vector training joint model this potential beneﬁts accounting correlations outweighed disadvantages density models higher dimensional spaces. consistent independence assumption noise adapt models separately combine above. applies combinations discussed next. derlying speech signals observation windows i.e. signiﬁcantly longer observation windows used form acoustic waveform representation. trend holds; performance good quiet conditions quickly deteriorates decreases. crossover point cepstral representations. chance-level error rate seen mfcc representations without deltas deltas included whereas acoustic waveform classiﬁer performs signiﬁcantly better chance error even snr. dashed curves figure represent error rates obtained classiﬁers trained matched conditions. results show waveform classiﬁer compares favourably mfcc deltas appended. results agreement working hypothesis highdimensional acoustic waveform representations provide better separation phoneme classes. including ∆+∆∆ reduce error rates signiﬁcantly crossover occurs snr. observations mainly motivate model developments below clearly include information similar deltas waveform representation. experiment repeated using pink noise extracted noisex- database results noise types similar waveforms classiﬁers. plp+∆+∆∆ adapted noise using cmvn larger difference noise types pink noise leading lower errors. nevertheless better performance achieved acoustic waveforms crossover point results classiﬁcation timit benchmark quiet conditions previously reported errors respectively. ensure baseline valid compared experiment quiet conditions plp+∆+∆∆ obtained comparable error rate indicated bottom right corner figure following encouraging results seek explore effect optimising number frames inclusion information entire phoneme. expectation including frames concatenation acoustic waveforms similar effect adding ∆+∆∆ mfcc features. direct analogue deltas unlikely useful waveforms mfcc based magnitude spectra change little stationary phonemes local averaging differencing meaningful. waveforms effectively retain fourier component amplitudes also phases phases combine essentially randomly averaging differencing rendering resulting delta-like features useless. fig. comparison phoneme representations. division described resulting sectors three covering duration phoneme duration around transitions. bottom frames closest theﬁvepointsabcdande selected phoneme segment feature vectors interested assessing relative merits waveform cepstral representations robust phoneme classiﬁcation independently segmentation errors interfering effects assumptions. purpose consider averaging frames across entire phoneme methods mapping variable phoneme duration ﬁxedlength representation proposed towards models used hmm-gmm framework next section extend centre-only frame concatenation information entire phoneme taking frames centres closest time instants distributed along duration phoneme shown figure manner representation consists sequences frames phoneme. sets frames concatenated give vectors train models sectors combine information provide taking corresponding log-likelihoods figure shows impact number frames concatenated sector impact summing loglikelihoods sectors classiﬁcation error focusing quiet conditions. since features gave slightly lower error mfcc features experiments using centre-only representation section show results features only. best results acoustic waveform classiﬁers achieved around frames around frames without deltas. plp+∆+∆∆ features less sensitive number frames little difference error frames. worth noting consider best results obtained without deltas using frames best plp+∆+∆∆ fig. error rates different representations quiet conditions function number frames considered. dashed prediction using central sector. dotted prediction using ﬁvesectorsleadingtoaclearimprovementinallcases. frames performance much smaller compare error rates classiﬁers used number frames. error rates obtained using -average best values acoustic waveforms plp+∆+∆∆ respectively. table shows absolute percentage error reduction four classiﬁers quiet conditions compared single best number mixture components number frames relative beneﬁts -average sector clear. sector gives bigger improvements cases compared -average combination methods better still throughout. qualitative trend holds true noise. figure compares performance ﬁnal classiﬁers including -average sector data corrupted pink noise. averaging number frames done values achieving lowest errors shown figure solid curves give results fig. performance classiﬁers inpink noise. error curves shown obtainedusingthesectorsumandaveragingoverthenumberofframesforﬁve valuesoff achievinglowestclassiﬁcationerrorsaccordingtotheresultsshown figure bold line combined waveform plp+∆+∆∆ classiﬁer thelatteradaptedtonoisebyfeaturestandarisation usingcmvn. numerically determined suitable ranges gives note approach equivalent multistream model sector value independent stream. error combined classiﬁer using models trained quiet conditions shown bold curve figure quiet conditions combined classiﬁer slightly accurate plp+∆+∆∆ alone corresponding small value noise present combined classiﬁer least accurate acoustic waveform classiﬁer signiﬁcantly better around snr. combined classiﬁer improve upon plp+∆+∆∆ classiﬁers trained matched conditions narrows performance order throughout rather comparing plp+∆+∆∆ adapted cmvn. phoneme recognition continuous speech consider extending classiﬁcation results previous sections task phoneme recognition continuous speech using hidden markov models. gmms used classiﬁcation well emission density models hmms developments transferred recognition. exception sector intended mimic states hmms. model average frame average hand remain suitable hmms. importantly noise adaptation classiﬁers acoustic waveform domain given equation directly applied provide good model continuous noisy speech transition matrices remain unaltered noise based assumption noise speech independent. acoustic waveform classiﬁer adapted noise using classiﬁer without ∆+∆∆ trained quiet conditions adapted noise cmvn. errors generally signiﬁcantly lower figure showing beneﬁts -averaging sector sum. plp+∆+∆∆ remains best representation noise waveforms give lower errors crossover points around snr. before also perform better chance snr. dashed lines figure show comparison performance classiﬁers trained matched conditions. matched conditions plp+∆+∆∆ classiﬁer best performance snr. however high noise adapted acoustic waveform classiﬁer signiﬁcantly closer matched plp+∆+∆∆ plp+∆+∆∆ cmvn. explained cmvn matched curves provide extremes would expect classiﬁer perform model adaption analogous used acoustic waveforms possible method improve robustness employed. next section explore performance mfcc features combination etsi advanced front-end vector taylor series noise compensation techniques context phoneme recognition. results shown that preliminary experiments performs best quiet conditions acoustic waveforms robust additive noise. gain beneﬁts representations explore merging convex combination corresponding loglikelihoods parameterised coefﬁcient tplp twave log-likelihoods point corresponding waveform features respectively. used place predict class. would expect optimal almost zero high snrs close snrs. order achieve desired improvement accuracy appropriate combination function suitable range possible values identiﬁed noise level condition error rate error best range broad particular form ﬁtted combination function critical choose following sigmoid function parameters ﬂexible implementation allows comparing results obtained using standard representations obtained acoustic waveforms. however number modiﬁcations standard training procedure required make system work properly acoustic waveform models. standard training process implements ﬂat-start procedure begins single component gmms emission models hmms. ﬁrst stage initialises prototype emission models global statistics input frames sentences phonemes. next process updates emission models state class-wise basis frames training belonging class used estimate density states class. ﬁnal stage aims maximise training objective function re-estimating parameters including emission models state transition matrices. models improved splitting emission model component double number components. process replaces component components means component moved apart along axis maximum variance parent component. following split number re-estimation iterations performed. splitting re-estimation stages repeated emission model consists components. beyond number components error rates increase overﬁtting. using acoustic waveforms training objective needs selected ﬁrst. choice maximum likelihood estimation maximum mutual information minimum phone error large margin methods order provide best adaptation noise maximum likelihood used gives models best reﬂect true distribution phonemes. methods provide better performance quiet matched conditions clear optimising phoneme class models manner affect noise adaptation since models trained true generative models observed speech noise adaptation fail produce accurate model noisy speech. additionally prunes potential alignments likelihoods relative best sequence. alignment particular sentence found sufﬁciently high likelihood sentence excluded training dataset exclusion reduce training time ignoring training data alignments likelihood given current model parameters. higher dimensionality feature vectors acoustic waveform representation likelihood potential alignments cover much wider range case standard cepstral representations. default pruning parameter value indicating allowable tolerance likelihood values used train acoustic waveform models majority data rejected. consequently pruning parameter increased signiﬁcantly. small fraction data still rejected training process faster pruning option disabled. initially standard training method start used results obtained using training procedure poor acoustic waveforms. traced problem component splitting stage means split gaussian components moved apart. acoustic waveform distributions however zero mean gmms provide better models since waveform identically perceived. following this passive method considered enforce zero mean constraint including negative instances training data. however model components still means differed signiﬁcantly zero. overcome problem means instead constrained zero splitting update applied parameters except mean vectors. provided modest improvement appears splitting process major issue training acoustic waveform models mean vectors displaced. ultimately best results obtained gmms trained regions shown figure used initialise emission models three states phoneme. initialisation repeated number components therefore avoids splitting components required number components speciﬁed training gmms. following initialisation variances transition matrices component weights re-estimated using standard baum-welch method. model averaging according still valid concept used phoneme recognition experiments reported next subsection framework likelihood data must evaluated models simultaneously would increase computational load signiﬁcantly. would expect reductions error rates implement model averaging hmms improvement would similar representations observed results would lead different conclusions comparisons representations. previous section number frames used acoustic waveform representation also critical classiﬁcation. range values investigated suitable recognition. necessary optimal feature duration acoustic waveform representations known however parameters used standard representations results classiﬁcation experiments previous sections provided initial range investigation. figure shows phoneme recognition error rates hmms using acoustic waveforms four traininginitialisation approaches detailed section iv-a. investigation considers performance hmms component gmms used emission density models. evidently standard training procedure ineffective acoustic waveforms. notice inclusion negative instances training data fails improve outcome. cases direct inspection model parameters revealed models contained components fig. effect representation duration denoted number frames concatenated. curves shown quiet conditions additive pink noise seven values snr. overall best performance obtained usingframesamsdurationrepresentation. comparison acoustic waveforms cepstral baselines shown figure models acoustic waveforms adapted additive noise according case cepstral features consider standard noise compensation techniques etsi advanced front-end vector taylor series conjunction mfcc features obtain noise-compensated cepstral representations mfcc-afe mfcc-vts respectively. compensated features standardised using sentence-wise cepstral mean variance normalisation signiﬁcantly improved performance single frame used mfcc variants ∆+∆∆ computed usual manner. corresponds time interval frame ∆+∆∆. assumed methods provide optimal baselines comparison commonly used tuned task. figure shows recognition results obtained acoustic waveform representation considering comparison cepstral baselines without ∆+∆∆ acoustic waveform representation duration gives similar error rates cepstral baselines quiet conditions better performance snr. note similar observation made classiﬁcation results obtained ﬁxed-length segments acoustic waveforms cepstral features without ∆+∆∆ information shown figure results shown figure demonstrate phoneme recognition addition ∆+∆∆ features provides signiﬁcant performance gain cepstral representations. observe performance cepstral representations ∆+∆∆ information signiﬁcantly better achieved acoustic waveforms snrs acoustic waveform representation improves noisy conditions giving lower error rates mfcc-afe+∆+∆∆ mfccvts+∆+∆∆ snr. mean vectors signiﬁcantly different zero. overcome issue next method forces means zero stage component splitting. gives much better performance components used. however improvement minor models consist components. ﬁnal training method denoted gmminit. legend figure initialises emission models using gmms trained section iii. case error rates signiﬁcantly lower methods every number components. initialisation method reduces error rate ranging single component components. fig. comparisonofthefourtrainingapproachesfortheacousticwaveform representation quiet conditions default training procedure component splitting default negative instances added training data default emission model mean vectors forced zero splitting emission models initialised using zero-mean sectormodelsfromsectioniii.threecurvesareshownforeachof themethodscorrespondingtodifferentnumberofframesintheconcatenation. model training process acoustic waveforms initially considered frames corresponding feature vectors covering duration respectively extracted every duration corresponds overlap adjacent feature vectors closest standard cepstral representation. effect number frames also illustrated figure observed results improve going indication optimal value. suggests necessary investigate acoustic waveform representation using frames optimum. previous section representations considered classiﬁcation range sufﬁcient optimal value figure shows results phoneme recognition task range curve represents ﬁxed global additive pink noise. slight improvement around results increasing acoustic waveform duration beyond duration error rates increase could representation becoming less localised. fig. phoneme recognition error rates acoustic waveform representations different durations. tests carried additive pink noise. noise compensated mfcc features using vector taylor series andetsiadvanced front-endmethodsareusedasbaselines. fig. comparisonofphonemerecognitionerrorratesinadditivepinknoise. baseline comparisons provided mfcc-afe mfcc-vts. faverage taken range uniformly lower error ratesareachievedbytheconvexcombination ofmfcc-afeandawfa. also re-investigate context effect model averaging combining models corresponding different number frames used represent acoustic waveforms. established lowest error rates achieved using frames models corresponding averaged multi-stream process used recognition. resulting acoustic waveform -average model achieved better performance individual models ﬁxed value finally re-investigate recognition context combining acoustic waveform mfcc-afe hmms according note larger -values waveforms effectively incorporate information provided mfccs consider similar -frame concatenations mfccs. phoneme recognition results obtained frame averaging representation combination additive pink noise shown figure acoustic waveform representation averaging number frames gives lower error rates cepstral representations cross-over point around error rates achieved combined representation uniformly lower individual representations considered. consequence combined model achieves signiﬁcant reductions error rates compared cepstral-only models standard noise compensation techniques. paper explored potential improving robustness additive noise posing problem directly space acoustic waveforms speech linear transform thereof incur information loss. order assess separation phonetic classes acoustic waveform domain domains standard cepstral features ﬁrst considered classiﬁcation phonemes using observations given ﬁxed duration. remarkable result experiment phoneme classiﬁcation acoustic waveform domain signiﬁcantly outperforms classiﬁcation cepstral domains already noise levels even achieves accuracy distinctly random guessing signiﬁcant performance gain classiﬁcation using cepstral features achieved ∆+∆∆ features reﬂect temporal dynamics speech. ﬁnding analogous features acoustic waveform domain nontrivial open problem considerations section demonstrated performance gain acoustic waveform domain achieved extending length basic observation unit thus including information temporal dynamics implicitly. next acoustic waveforms considered context phoneme recognition continuous speech. allow direct comparison cepstral features compatibility existing technologies recognition implemented standard hmm-gmm framework. note however framebasedcepstrahaveco-evolvedasasrsystemcomponentsand hence much tuned other. hmms core acoustic modeling technology might obscure gainsfromnewfeaturesespeciallythosefromlongtimescales; thismaybeonereasonwhyprogresswithnoveltechniqueshas beensodifﬁcult.inparticularsystemsincorporatingnewsignal processingmethodsinthefrontendareatadisadvantagewhen testedusingstandardhmms. still phoneme recognition using acoustic waveforms achieved lower error rates cepstral features noise levels snr. recognition classiﬁcation results presented proof-of-concept study demonstrate representing speech using high dimensional linear features incur loss information promising direction towards achieving long sought-after robustness systems. signiﬁcant improvements potentially made sophisticated broad phoneme class confusions indeed context phoneme recognition much lower confusion rates broad phoneme classes achieved using acoustic waveforms cepstral features illustrated results shown figure finally considering success deep neural networks tasks imperative explore modelling acoustic waveforms speech. dnns exhibited robustness modest differences training test settings performance poor mismatch severe recent study mitra shows however choice features provides scope improving robustness dnns. hence interest explore possible gains achievable using dnns conjunction high dimensional linear representations considered study. zoran cvetkovic would like thank jont allen bishnu atal herve bourlard encouragement support inspiration malcolm slaney valuable suggestions presentation paper. baker deng glass khudanpur morgan o’shaugnessy research developments directions speech recognition understanding part ieee signal process. mag. vol. modelling speech acoustic waveform domain. choice decorrelating basis another area opens scope work. directions methods mllt semi-tied covariance matrices lead improved results. conducted preliminary experiments semi-tied covariance matrices context phoneme recognition. improved recognition performance quiet suffered increased error levels noise. however extensive investigations prove fruitful. even within models introduced study given wide range possibilities choice parameters many extensively tuned. includes weighting model averaging number components gmms averaging number frames either class-independent manner tuned even vary phoneme phonetic group evaluated; uniform weight assumed throughout likely information content used discrimination distributed exactly way. models could potentially also developed explicitly model correlations feature vectors obtained different number frames towards classes models gaussian scale mixture models subset gmms seem particularly suitable modelling distributions speech signal. motivated observation experiments covariance matrices components approximately scaled copies other. densities acoustic waveform representation thus modelled using mixtures scaled components means constrained zero covariance matrices constrained diagonal. probability density function gsmm thus given symbols addition scales scale weights respectively. here range scales corresponds model amplitude distribution given phoneme. eight scale model components provided error rate improved quiet compared standard -component used phoneme classiﬁcation considered section reductions error rates expected scales used given scale distributions adequately modelled eight scales. although gsmm models achieved lower error rates corresponding gmms number components computational constraints prevented exploring direction further. note gsmm models example richter distribution previously used model heavy tailed distributions expect results improved acoustic waveform features effective incorporated techniques considered authors particular committee classiﬁers hierarchy reduce ostendorf roukos stochastic segment model phonemebased continuous speech recognition ieee trans. acoustics speech signal process. vol. december morgan stolcke sonmez sivadas shinozaki ostendorf jain hermansky ellis diddington chen cetin bourlard athineos pushing envelope aside ieee signal process. mag. september hinton deng dahl rahman mohamed jaitly senior vanhoucke nguyen sainath kingsbury deep neural networks acoustic modeling speech recognition shared views four research groups ieee signal process. mag. november mitra wang franco bartels graciarena evaluating robust features deep neural networks speech recognition noisy channel mismatched conditions proc. interspeech september davis mermelstein comparison parametric representations monosyllabic word recognition continuously spoken sentences ieee trans. acoustics speech signal process. vol. sheikhzadeh deng waveform-based speech recognition using hidden filter models parameter selection sensitivity power normalization ieee trans. speech audio process. vol. yousafzai ager cvetkovi´c sollich discriminative generative machine learning approaches towards robust phoneme classiﬁcation workshop information theory applications", "year": 2013}