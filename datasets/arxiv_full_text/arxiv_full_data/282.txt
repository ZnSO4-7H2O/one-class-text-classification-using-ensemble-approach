{"title": "Hard to Cheat: A Turing Test based on Answering Questions about Images", "tag": ["cs.AI", "cs.CL", "cs.CV", "cs.LG"], "abstract": "Progress in language and image understanding by machines has sparkled the interest of the research community in more open-ended, holistic tasks, and refueled an old AI dream of building intelligent machines. We discuss a few prominent challenges that characterize such holistic tasks and argue for \"question answering about images\" as a particular appealing instance of such a holistic task. In particular, we point out that it is a version of a Turing Test that is likely to be more robust to over-interpretations and contrast it with tasks like grounding and generation of descriptions. Finally, we discuss tools to measure progress in this field.", "text": "progress language image understanding machines sparkled interest research community open-ended holistic tasks refueled dream building intelligent machines. discuss prominent challenges characterize holistic tasks argue question answering images particular appealing instance holistic task. particular point version turing test likely robust over-interpretations contrast tasks like grounding generation descriptions. finally discuss tools measure progress ﬁeld. progress machine perception language understanding work holistic tasks complex chain perception representation inference. examples include grounding language generation question answering images recently malinowski fritz presented approach question answering images resembles famous turing test malinowski fritz discuss associated challenges issues. following elaborate data acquisition contrast challenge tasks including grounding language generation well highlight properties like robustness over-interpretation makes hard cheat test. architectures working holistic task question answering based images need deal large gamut challenges. section distilled prominent ones require joint reasoning language visual inputs. also argue holistic architectures beneﬁt common sense knowledge. finally discuss challenges data acquisition show task differs well known tasks. vision language scalability vision language systems ground internal representation external world serves common reference point machines humans. human conceptualization divides percepts different instances categories well spatio-temporal concepts. architectures reproducing space human concepts need capture diversity therefore scale thousands concepts. concept ambiguity number categories grows semantic boundaries become fuzzy hence ambiguities gradual memberships inherently introduced. instance difference ’night stand’ ’cabinet’ ’armchair’ ’chair’ ’sofa’ blurry. ambiguities challenging least ways. methods need distinguish ﬁne-grained differences objects appropriate. objective functions evaluating metrics need gradually penalize methods mistakes. ambiguity reference resolution quality answer depends ambiguous latent notions reference frames intentions understood depending cultural bias context object-centric observer-centric world-centric frames reference moreover uniﬁed notion ’with’ ’beneath’ ’over’ mean. common sense knowledge interestingly questions quite reliably answered access common sense knowledge. instance which object table used cutting? already narrows likely options significantly. example suggests question-answering architectures would signiﬁcantly beneﬁt common sense knowledge. ’object cutting’ directly visual affordance object therefore challenging concept acquire images only. hand cooccurrences visual data represent kind visual common sense knowledge mundane facts probabilistic relations rarely found common sense knowledge bases. advantages tasks terms data acquisition task evaluation. grounding annotating images question answer pairs require detailed annotations whole scenes terms predicates representing objects relations. task also agnostic internal representation method. contrast language generation output space question answering task restricted hence evaluation different architectures task easier formulate. contrast typical computer vision tasks like object detection architectures judged solely right answers internal representation. contrast traditional turing test answering questions images less prone over-interpretations associating meaning machine answers human interrogator. hence method forced answer point rather cheating giving generic answers output open interpretations. measuring progress holistic tasks require identifying goals. instance suitable metric question answering images evaluate architectures based produced answers intermediate results detections logical forms. visual turing challenge seek metric satisﬁes several properties. important automation evaluating answers complex tasks answering questions requires quite deep understanding natural language involved concepts hidden intentions questioner. ideal impractical metric would manually judge every single answer every architecture individually. therefore seeking automatic approximation evaluate different holistic architectures scale. malinowski fritz proposed restrict answer space order achieve goal leaving questions unconstraint. social consensus complex tasks interested inherently ambiguous. ambiguities stem many factors cultural bias different frame reference ﬁned grained categorization. implies multiple interpretations question possible. deal different interpretations words malinowski fritz deﬁne wups scores using lexical databases wu-palmer similarity deal different interpretations question malinowski fritz suggest quality answers measured according social consensus answers evaluated multiple groundtruths. interestingly metric also naturally quantiﬁes social agreement answer serve practical approximation tedious manual evaluation. experimental scenarios many cases success challenging learning problems accelerated external data training. believe visual turing challenge consists sub-task prohibited auxiliary data understand holistic learners generalize limited challenging data established setup. hand limit artiﬁcial restrictions building next generation holistic learners. therefore open sub-tasks permissible additional sources training stated including additional vision language resources synthetic data curated data. goal contribution sparkle discussions challenges benchmarking architectures holistic tasks. also argue question answering images holistic task offers multiple advantages related tasks. example likely less prone cheating over-interpretations traditional turing test annotation process tractable crowdsourcing question answer pairs task artiﬁcially force internal representation methods. recent efforts results establishing visual turing test found website www.d.mpi-inf.mpg.de/visual-turing-challenge.", "year": 2015}