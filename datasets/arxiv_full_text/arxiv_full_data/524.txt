{"title": "Towards Structured Deep Neural Network for Automatic Speech Recognition", "tag": ["cs.CL", "cs.LG", "cs.NE"], "abstract": "In this paper we propose the Structured Deep Neural Network (structured DNN) as a structured and deep learning framework. This approach can learn to find the best structured object (such as a label sequence) given a structured input (such as a vector sequence) by globally considering the mapping relationships between the structures rather than item by item.  When automatic speech recognition is viewed as a special case of such a structured learning problem, where we have the acoustic vector sequence as the input and the phoneme label sequence as the output, it becomes possible to comprehensively learn utterance by utterance as a whole, rather than frame by frame.  Structured Support Vector Machine (structured SVM) was proposed to perform ASR with structured learning previously, but limited by the linear nature of SVM. Here we propose structured DNN to use nonlinear transformations in multi-layers as a structured and deep learning approach. This approach was shown to beat structured SVM in preliminary experiments on TIMIT.", "text": "paper propose structured deep neural network structured deep learning framework. approach learn best structured object given structured input globally considering mapping relationships structures rather item item. automatic speech recognition viewed special case structured learning problem acoustic vector sequence input phoneme label sequence output becomes possible comprehensively learn utterance utterance whole rather frame frame. structured support vector machine proposed perform structured learning previously limited linear nature svm. propose structured nonlinear transformations multi-layers structured deep learning approach. approach shown beat structured preliminary experiments timit. maturity machine learning great efforts made integrate machine learning concepts hidden markov model using deep neural networks good example general hmms consider phoneme structure states transitions among them trained primarily frame level regardless based gaussian mixture model framework hierarchical structure utterance taken care states lexicon language model respectively learned separetely disjoint sets knowledge sources. hand well known exist underlying overall structures utterances behind signals helpful recognition. learn structures comprehensively signals entire utterance globally recognition scenario different. contrary structured learning substantially investigated machine learning tries learn complicated structures exhibited data. conditional random fields structured support vector machine good example approaches. recently structured used perform initial phoneme recognition learning relationships acoustic vector sequence phoneme label sequence whole utterance jointly rather frame level different sets knowledge sources utilizing nice properties classify structured patterns utterances maximized margin. however structured linear therefore limited analyzing speech signals. paper extend structured approach phoneme recognition using structured including nonlinear units multi-layers similarly learning global mapping relationships acoustic vector sequence phoneme label sequence whole utterance. recent work front-end feature extraction integrated weighted finite-state transducers integrate frontend structured completely different previous work. whole picture concept structured phoneme recognition fig. given utterance acoustic vector sequence corresponding phoneme label sequence ﬁrst obtain structured feature vector representing relationships fig. given section feed either fig. fig. score scoring function parameter sets respectively. acoustic vector sequence acoustic features like ﬁlter bank outputs phoneme posteriorgram vectors generated fig. represent entire utterance structure either learns pair score utterance level globally rather frame level structured learning optimized utterance level. based maximized margin concept wish maximize score correct label sequence margin score correct label sequence nearest incorrect label sequences shown figure figure correct label sequence incorrect label sequences blue. score correct label sequence higher highest score among incorrect label sequences difference scores sequences incorrect label sequences scores correct sequence least margin. maximizing margin learning target structured svm. scoring function used structured below linear. structured feature vector mentioned shown figure representing structured relationship vector form represents inner product. train parameter vector using training instances subject following formula cost balancing model complexity inequality slack variable inequality measures distance label sequences. phone error rate used distance paper evaluation metrics also feasible. optimizing function equivalent maximizing margin separating scores correct label sequence label sequences training sample formula solved quadratic programming cutting-plane algorithm equivalent following formula structured learning concept structured learning desired outputs input objects sequences trees lattices graphs rather simply classes real numbers. context supervised learning phoneme recognition utterances given training utterances acoustic vector sequence utterance corresponding reference phoneme label sequence wish assign correct phoneme label sequences unknown utterance. ﬁrst deﬁne function mapping acoustic vector sequence phoneme label sequence parameter learned. achieve assign every possible phoneme label sequence given acoustic vector sequence score scoring function take phoneme label sequence giving highest score output inspired maximum margin concept structured replace linear part structured nonlinear take advantage maximum margin. proposed structured thus optimizes following formula parallel except replaced respectively outer operator replaced summation. loss function would larger zero whenever model parameters penalized inequalities hold. therefore scores correct label sequence label sequences would separated least margin maximized structured scores evaluated parameters learned based framework rather svm. note components loss function piecewise differentiable means back propagation model parameters optimizing according need traverse possible utterance intractable need approximation described subsection structured trained above given acoustic vector sequence unknown utterance need best phoneme label sequence structured subsection linear assumption learned model parameter contains enough information execute viterbi algorithm best label sequence. true structured dnn. principle need search possible phoneme label sequences given acoustic vector sequence pick giving highest score computationally infeasible. loss function example hinge loss function penalizes model inequality hold. formula helpful understanding concept cost function structured subsection scoring function trained parameter label sequence acoustic vector sequence input testing utterance well known viterbi algorithm assumption linear scoring function makes structured limited. instead proposed structured uses series nonlinear transforms build scoring function hidden layers evaluate single output value fig. weight matrix layer nonlinear transform output vector hidden layer parameters note last weight matrix vector gives single value output. different lost functions learning structured deﬁned work described respectively subsections first label phoneme accuracy label sequence deﬁned correct label sequence phoneme error rate given correct label sequence parameter structured trained minimizing following loss function minimizing learns minimize mean square error output given phoneme accuracy training utterances utterance possible phoneme sequences score function thus learned considered estimate phoneme accuracy correct label sequence would tend largest among possible sequences. practice considering possible intractable subset considered training described later subsection training utterance possible label sequences. also impossible train label sequences training utterances. structured linear property able training examples produce maximum margin. structured here choose effective training examples important. besides positive examples work negative examples chosen random lattice decoded wfst. training utterance lattice negative examples three sources completely random sequences random paths lattice n-best paths lattice. acoustic feature sequence output another front-end example generated whose input ﬁlter bank output output phoneme posteriorgram vectors. case back propagation propagate errors structured back front-end dnn. full-scale structured parameters ﬁlter bank whole utterance score jointly learned. fsdnn proposed considered special case convolutional neural network works perfectly computer vision speech recognition power mainly based shared kernel parameters able discover frontend feature ﬁlters. fsdnn view front-end kernel share parameters front end. difference fsdnn uses max-pooling layer forward output front-end dnn. take ﬁlter bank outputs phoneme posteriorgram vectors acoustic vectors utterance frames ...m} phoneme label task decode label sequence ...m}. since successful well known solution problem encode feature vector used here. consists series states important sets parameters transition probabilities states observation probability distribution state. structure slightly complicated work here preliminary work simpliﬁed state phoneme. simpliﬁcation sets probabilistic parameters estimated utterance adding counts transition labels also adding acoustic vectors label shown fig. assume total number different phonemes ﬁrst deﬁne dimensional vector k-th component components k-th phoneme. tensor product helpful here deﬁned ordinary vectors dimensions respectively. right half says vector dimension whose ]-th component i-th component multiplied j-th component expression feature vector fig. used evaluating scoring function conﬁgured concatenation vectors ym}. upper half right hand side accumulate distribution components phoneme acoustic vector sequence locate different sections components feature vector lower half right hand side hand accumulate transition counts pair labels label sequence then concatenation keeps primary statistical parameters different phonemes transitions states enough training utterances corresponding function learn scoring function training parameters vector easily extended higher order markov assumptions example replacing upper half lower half initial experiments performed timit. used training without dialect sentences training core testing testing. models trained phonemes tested phonemes conformed cmu/mit standards used online library structured modiﬁed kaldi code implement structured dnn. experiment based vesely’s recipe kaldi called baseline used lda-mllt-fmllr features obtained auxiliary models pre-training frame cross-entropy training smbr. structured performed lattices obtained vesely’s recipe. used sets acoustic vectors lda-mlltfmllr feature input vesely’s recipe; phoneme posterior probabilities obtained output vesely’s recipe. -dimension feature large reduced dimension adding extra layer vesely’s used one-hot mono-phone training target train extra layer. unless speciﬁed used following parameters hidden layers neurons layer random initial weights structured vesely’s initial weight frontend fsdnn phone error rate mini-batch used momentum learning rate halving learning rate improvements loss function small. computation time used results listed table rows different acoustic features actually acoustic features used vesel’s recipe. column results structured svm. columns proposed structured respectively lost function approximating phoneme accuracy subsection column maximizing margin subsection column column extension column fullscale structured described subsection front-end structured jointly trained. column baseline. clear phoneme posterior better feature vectors used vesel’s recipe accounting powerful feature transform achieved dnn. structured outperformed structured acoustic features v.s. rows surprising structured learned linear transform; structured learned much complex nonlinearity. although results structured obtained rescoring lattices vesel’s results phoneme error rate structured better baseline cases sets acoustic vectors v.s. results showed proposed structured learn substantial information beyond normal frame-level dnn. comparing results columns table selection loss function critical. margin performed much better approximating phoneme accuracy v.s. possible reason follows. loss function approximating phoneme accuracy inevitably dominated negative examples since used much negative examples positive examples training positive negative examples equally weighted. loss function maximizing margin hand focused score difference pair positive negative examples result positive negative examples weighted equally even different numbers. compare structured fullscale structured using loss function v.s. propagating errors back front-end layer offer good improvement best result beat baseline relative improvements v.s. note full potential structured well explored example explained section simply assume single state table phoneme error rate. rows different acoustic vector sequence inputs. column results structured columns structured respectively lost function approximate phoneme accuracy subsection maximizing margin subsection column extension column full-scale structued described subsection column baseline order fsdnn column better baseline column took deeper look data results selected example utterance shown figure ﬁgure phoneme accuracy -best paths example utterance plotted function scores obtained recognizer i.e. fsdnn baseline columns dots ﬁgure path among best color used mark path. note phoneme accuracy discrete single utterance integer number phoneme errors. figure fsdnn gave highest score path highest phoneme accuracy figure however blue point received relatively score kaldi path lower phoneme accuracy highest score kaldi resulted lower phoneme accuracy baseline utterance. evaluated regression line ﬁgures found fsdnn score phoneme accuracy positively correlated figure kaldi score phoneme accuracy negatively correlated. although selected example easy many examples similar situation. noting fsdnn trained large margin criteria considering phoneme accuracy learned positively correlated phonme accuracy. next experiment analyze different choices hyper-parameters full-scale structured number hidden layers number neurons hidden layer. figure result visualized fsdnn using acoustic vectors horizontal axis vertical axis .... therefore ﬁgure consists data points. overall performance approximately less comparable baseline. task training inferencing. better seemed located several disjoint regions best fig. phoneme accuracy evaluate -best paths selected example utterance plotted function scores obtained recognizer fsdnn score fsdnn kaldi score. dots ﬁgure path among best color used mark path result case table disjoint valleys come relatively poor learning lack training data poor initialization. loss function relu like result similar behavior relu training paper propose structured learning architecture structured phoneme recognition jointly considers structures acoustic vector sequences phoneme label sequences globally. preliminary test results show structured outperformed previously proposed structured beat state-of-the-art kaldi results. work multiple states phoneme future explore possibilities approach. abdel-rahman mohamed george dahl geoffrey hinton acoustic modeling using deep belief networks audio speech language processing ieee transactions vol. geoffrey hinton deng dong george dahl abdel-rahman mohamed navdeep jaitly andrew senior vincent vanhoucke patrick nguyen tara sainath deep neural networks acoustic modeling speech recognition shared views four research groups signal processing magazine ieee vol. zolt´an t¨uske pavel golik ralf schl¨uter hermann acoustic modeling deep neural networks using time signal lvcsr proceedings annual conference international speech communication association daniel povey lukas burget mohit agarwal pinar akyazi feng arnab ghoshal ondrej glembek nagendra goel martin karaﬁ´at ariya rastrow subspace gaussian mixture models speech recognition acoustics speech signal processing ieee international conference ieee andrew mccallum early results named entity recognition conditional random ﬁelds feaproture induction web-enhanced lexicons ceedings seventh conference natural language geoffrey zweig patrick nguyen segmental approach large vocabulary continuous speech recogautomatic speech recognition undernition standing asru ieee workshop ieee ioannis tsochantaridis thorsten joachims thomas hofmann yasemin altun large margin methods structured interdependent output variables journal machine learning research tang chao-hong meng lin-shan initial attempt phoneme recognition using structured support vector machine acoustics speech signal processing ieee international conference ieee bernhard boser isabelle guyon vladimir vapnik training algorithm optimal margin classiﬁers proceedings ﬁfth annual workshop computational learning theory. yotaro kubo takaaki hori atsushi nakamura integrating deep neural networks structural classiﬁcation approach based weighted ﬁnite-state transducers. interspeech alex krizhevsky ilya sutskever geoffrey hinton imagenet classiﬁcation deep convolutional neural networks advances neural information processing systems daniel povey arnab ghoshal gilles boulianne lukas burget ondrej glembek nagendra goel mirko hannemann petr motlicek yanmin qian petr schwarz silovsky georg stemmer karel vesely kaldi speech recognition toolkit ieee workshop automatic speech recognition understanding. dec. ieee signal processing society ieee catalog cfpsrw-usb.", "year": 2015}