{"title": "Quality Aware Network for Set to Set Recognition", "tag": ["cs.CV", "cs.AI"], "abstract": "This paper targets on the problem of set to set recognition, which learns the metric between two image sets. Images in each set belong to the same identity. Since images in a set can be complementary, they hopefully lead to higher accuracy in practical applications. However, the quality of each sample cannot be guaranteed, and samples with poor quality will hurt the metric. In this paper, the quality aware network (QAN) is proposed to confront this problem, where the quality of each sample can be automatically learned although such information is not explicitly provided in the training stage. The network has two branches, where the first branch extracts appearance feature embedding for each sample and the other branch predicts quality score for each sample. Features and quality scores of all samples in a set are then aggregated to generate the final feature embedding. We show that the two branches can be trained in an end-to-end manner given only the set-level identity annotation. Analysis on gradient spread of this mechanism indicates that the quality learned by the network is beneficial to set-to-set recognition and simplifies the distribution that the network needs to fit. Experiments on both face verification and person re-identification show advantages of the proposed QAN. The source code and network structure can be downloaded at https://github.com/sciencefans/Quality-Aware-Network.", "text": "figure illustration motivation best viewed color. left column classical puzzle set-to-set recognition. contain noisy image samples caused shake blur. features similar samples class inner class. right column distributions samples identities hyperspace. noisy variances identities large hard negative samples. bottom quality aware network weaken noisy samples narrow identities’ variances makes discriminative. paper targets problem recognition learns metric image sets. images belong identity. since images complementary hopefully lead higher accuracy practical applications. however quality sample cannot guaranteed samples poor quality hurt metric. paper quality aware network proposed confront problem quality sample automatically learned although information explicitly provided training stage. network branches ﬁrst branch extracts appearance feature embedding sample branch predicts quality score sample. features quality scores samples aggregated generate ﬁnal feature embedding. show branches trained end-to-end manner given set-level identity annotation. analysis gradient spread mechanism indicates quality learned network beneﬁcial set-to-set recognition simpliﬁes distribution network needs experiments face veriﬁcation person re-identiﬁcation show advantages proposed qan. source code network structure downloaded github face veriﬁcation person reidentiﬁcation well studied widely used computer vision applications ﬁnancial identity authentication video surveillance. tasks need measure distance face person images. tasks naturally formalized metric learning problem distance images identity smaller different identities. built large scale training data convolutional neural networks carefully designed optimization criterion current methods achieve promising performance standard benchmarks still fail appearance variations caused large pose illumination. practical applications instead single image images identity always collected. example image identity sampled trajectory face person videos. images complementary other provide information single image images different poses. direct aggregate identity information images simply max/average pooling appearance features images. however problem pooling images suitable recognition. shown figure sets left-top left-bottom hold noisy images caused shake blur. noisy images treated equally max/average pooling used aggregate images’ features noisy images mislead ﬁnal representation. paper order robust images poor quality described simultaneously rich information provided images basic idea image quality score aggregation. that propose quality aware network branches aggregated together. ﬁrst branch named feature generation part extracts feature embedding image branch named quality generation part predicts quality score image. features images whole aggregated ﬁnal pooling unit according quality. good property approach supervise model explicit annotations quality. network automatically assign quality scores images poor quality order keep ﬁnal feature embedding useful set-to-set recognition. implement that elaborate model designed embedding branch score generation branch jointly trained optimization ﬁnal embedding. specially paper joint triplet softmax loss image sets. designed gradient image pooling unit ensures correctness automatic process. experiments indicate predicted quality score correlated quality annotated human predicted quality score performs better human recognition. paper show applications proposed method person re-identiﬁcation face veriﬁcation. person re-identiﬁcation task proposed quality aware network improves top- matching rates baseline ilids-vid prid. face veriﬁcation proposed method reduces miss ratio false positive rate youtube face ijb-a benchmarks. proposed quality aware network automatically generates quality scores image leads better representation set-to-set recognition. design end-to-end training strategy demonstrate quality generation part feature generation part beneﬁt back propagation. work build upon recent advances deep learning based person re-identiﬁcation unconstrained face recognition. person re-identiﬁcation features generated deep convolutional network obtain state-of-the-art performance. learn face representations unconstrained face recognition huang uses convolutional restricted boltzmann machine deep convolutional neural network used furthermore deeper convolutional network achieved accuracy even surpasses human performance. accuracy achieved deep learning image-based face veriﬁcation benchmark promoted although deep neural network achieved great performance problems present world unconstrained set-to-set recognition challenging useful. looking backward different approaches handling set-to-set recognition. ﬁrst approach takes image convex hull afﬁne hull subspace settings samples distribute hilbert space grassmann mainfold issue formulated metric learning problem works degrade set-to-set recognition point-to-point recognition aggregating images single representation hyperspace. famous approach kind features uses histogram represent whole feature aggregation. another classical work vector locally aggregated descriptors aggregates local descriptors samples. temporal max/average pooling used integrate frames’ features generated recurrent convolutional network. method uses order statistics aggregate set. order statistics used assuming samples follow gaussian distribution. original faces classiﬁed bins based pose quality. faces pooled generate features ﬁnally feature vectors bins merged ﬁnal representation. uses attention mechanism summarize several sample points single aggregated point. proposed belongs second approach. discards dross selects essential information images. different recent works learn aggregation based ﬁxed feature image learns feature representation aggregation simultaneously. proposed similar quality aware module named memorability based frame selection takes visual entropy score frame. score frame figure end-to-end learning structure quality aware net. input structure three image sets sanchor spos sneg belong class pass fully convolutional network generate middle representations quality generation part feature generation part. former generates quality score image latter generates ﬁnal representation image. scores representations image aggregated pooling unit ﬁnal representation image produced. softmax-loss triplet-loss supervised signal. deﬁned human independent feature generation unit. score automatically learned quality generation unit joint trained feature generation unit. mutual beneﬁt parts training performance improved signiﬁcantly jointly optimizing images aggregation parameter images’ feature generator. work focus improving image embedding model maps image i··· representation ﬁxed dimension image sets different number images comparable other. denote representation determined elements therefore denoted produced feature extraction process containing traditional hand-craft feature extractors convolutional neural network. aggregative function maps variable-length input representation ﬁxed dimension. challenge optimized aggregate features whole image obtain discriminative representation. based notion images higher quality easier recognition images lower quality containing occlusion large pose less effect representation denote paper feature generation aggregation module implemented end-to-end convolutional neural network named shown fig. branches splited middle ﬁrst branch quality generation part followed pooling unit composes aggregation module. second branch feature generation part generates images’ representation. introduce image ﬂows qan. beginning process images sent fully convolutional network generate middle representations. that divided branches. ﬁrst named quality generation part tiny convolution neural network employed predict quality score second called feature generation part generates image representations images. aggregated pooling unit pass fully connected layer ﬁnal representation structure generates quality scores images uses quality scores weight images’ representations sums produce ﬁnal set’s representation. training without quality supervision train end-to-end manner. data shown fig. supposed generate discriminative representations images sets belonging different identities. image level training fully connection layer established feature generation part supervised softmax loss lclass. level training set’s representation supervised lveri formulated lveri loss function referred triplet loss previous works deﬁne anchor positive negative set. function minimizes variances intra-class samples softmax loss cannot calculated according product gradient rii. angle belongs µi’s gradient positive. example shown fig. angle xni−ra less quality score become larger back propagation process. contrast relative direction opposite side gradient making obviously hard sample quality score tend smaller. obviously samples correct directions along gradient always score higher quality wrong directions gain lower weight. example fig. green samples upper area samples lower area keep improving quality consistently middle area sample’s quality reduces. represents whether image good sample hard sample. conclusion demonstrated experiments. regulates attention rii. gradient shown factor together gradient propagated softmax loss. since hard samples lower always poor images even full background noises factor gradient weaken harmful effect whole model. impact parameters feature generation part negligible back propagation. mechanism helps feature generation part focus good samples neglect ones beneﬁts set-to-set recognition. guarantee softmax-loss directly optimizes probability class discrimination representation. keeping mind consider pooling operation gradients back propagated pooling unit formulated follows figure different identities training best viewed color. translucent dots green translucent dots indicate images sets different identities. solid dots denote weighted centers sets also representations sets sanchor sneg. gradients sanchor sneg shown arrows. image representations sets. quality aware network quality generation part convolution neural network. design different score generation parts start different feature maps. split pool instance. shown fig. output spatial pool layer order generate quality score convolution part contains -stride pooling layer ﬁnal pooling layer kernel size fully connected layer followed ﬁnal pooling layer generate original quality score. that origin scores images sent figure samples qualities predicted best viewed color. comparison images person. down column shows frames person. quality better bottom one. bottom random selected images test sorted quality scores left right best viewed color. sigmoid layer group l-normalization layer generate ﬁnal scores split pool block containing three -stride convolution layer stride pooling layer beginning quality generation unit. section ﬁrst explore meaning quality score learned qan. qan’s sensitivity level feature analysed. based knowledge evaluate human re-identiﬁcation benchmarks unconstrained face veriﬁcation benchmarks. finally analyse concept learned compare score labelled human. learned qan? qualitative analysis visualize images generated explore meaning instances person different qualities shown ﬁrst rows fig. images selected test set. images column belong person. upper images random selected images quality scores higher lower images selected images quality scores lower corresponding higher one. easy images delast rows fig. give examples images random selected test set. sorted quality scores left right. observe instances quality scores larger easy recognize human others hard. especially many hard images include bodies center hardly discriminate right target. quantitative analysis order measure relationship quality labelled human predicted images youtube face selected randomly quality rated subjectively volunteers volunteer estimates quality score image ranging ratings volunteer aligned logistic regression. aligned scores image averaged ﬁnally normalized ﬁnal quality score human. divide images partitions based human’s score shown fig. show corresponding quality statistics generated qan. obvious scores given strongly correlated human-deﬁned quality. analyse image pairs images huresults evaluation obeying -fold cross validation prid ilids-vid shown table table beneﬁting large scale training dataset cnn+avepool cnn+min baselines close even better state-of-the-art. notice leading methods listed table consider appearance spatio-temporal information method considers appearance information. prid dataset increase top- matching rate compared cnn+avepool cnn+min. ilids-vid dataset inherent noise much prid signiﬁcantly inﬂuence accuracy cnn+min since operator sensitive avepool noisy samples however achieves gain noisy dataset. increase top- matching rate based experiments signiﬁcantly also peroutperforms baselines datasets. forms better many state-of-the-art approaches pushes top- matching rate higher previous best cnn+rnn prid ilidsvid. performance gain signiﬁcant noisy ilids-vid dataset meets expectation proves qan’s ability deal images poor quality. person re-identiﬁcation collect frames people bounding boxes training data. experiments conducted prid ilids-vid datasets. prid contains frames views captured different positions street. cameraa identities camerab identities videos overlap people. person images average number ilids-vid dataset people person sets also captured different positions. person images. evaluation procedure. results reported terms cumulative matching characteristics table column represents matching rate certain topn matching. settings used comprehensive evaluation. ﬁrst setting follow state-of-the-art method described sets whose frame number larger used prid sets ilids-vid used. dataset divided parts ﬁne-tuning testing respectively. testing sets form cameraa taken probe sets camerab taken gallery. ﬁnal number reported average -fold cross validation. second setting conduct cross-dataset testing. different ﬁrst setting ignore ﬁnetuning process data test model. prid ﬁrst people cameraa serve probes sets camerab used gallery set. ilids-vid cameraa used probe camera serve gallery set. extract representation ilids-vid prid directly using trained without ﬁne-tuning. representation evaluated scores. table shows results baselines. found robust even cross-dataset setting. improves top- matching compared baselines. result shows quality distribution learned different datasets able generalize datasets. number model evaluated youtube face database iarpa janus benchmark dataset. youtube face contains videos identities. challenging faces blurred resolution. ijb-a dataset contains videos people. faces ijb-a large pose variance. evaluation procedure. follow protocol benchmarks evaluate results using receiver operating characteristic curves. area curve accuracy important indicators roc. datasets evaluated using -fold crossvalidation. training details. faces training testing sets detected aligned multi-task region proposal network described crop face regions resize that convolutional neural networks inputs used face veriﬁcation. begins -stride convolution layer followed basic blocks block three -stride convolution layers -stride pooling layers. that fully connected layer used ﬁnal feature. quality generation branch built third pooling layer spatial size middle representation response pre-train network supervised classiﬁcation signal train whole qan. youtube face dataset observed fig. table accuracy baselines similar state-of-the-art methods facenet nan. based baseline reduces error ratio. evaluation metric surpasses deepface ensembles models. ijb-a dataset signiﬁcantly outperforms state-of-the-art algorithm fpr=. shown table compared average pooling baseline reduces false negative rate three fprs explicit supervision signals cascade score generation unit training. another problem arises better human-deﬁned scores instead letting network learn itself? youtube face experiment replace quality score volunteer-rated score following result fig. better baselines inferior result original qan. shows similar human thoughts suitable recognition. quality score human also enhance accuracy still worse qan’s. ﬁrst conﬁguration weight generation part connected image. second ﬁfth conﬁgurations weight generation part four pooling layers block respectively. sixth conﬁguration connect weight generation part fully connected layer. ﬁnal conﬁguration parameters ﬁnal fully connection layer sixth conﬁguration update parameters weight generation part taken seventh structure. minimize inﬂuence parameters’ number total size different models restricted changing channel number. results shown fig. found performance improves beginning reaches accuracy pool. end-to-end training version feature generation part quality generation part performs better ﬁxed. make conclusion middle level feature better learn signiﬁcant improvement achieved jointly training feature generation part quality generation part. paper propose quality aware network set-to-set recognition. automatically learns concept quality sample without supervised signal aggregates discriminative samples generate representation. theoretically experimentally demonstrate quality predicted network beneﬁcial representation better human labelled. seen attention model attention high quality elements image set. however image poor quality still discriminative regions. considering this future work explore ﬁne-grained quality aware network attention high quality regions instead high quality images image set. references ronen basri hassner lihi zelnik-manor. approximate nearest subspace search. ieee transactions pattern analysis machine intelligence jun-cheng chen rajeev ranjan amit kumar ching-hui chen vishal patel rama chellappa. end-to-end system unconstrained face veriﬁcation deep convolutional neural networks. iccv workshops pages michela farenzena loris bazzani alessandro perina vittorio murino marco cristani. person re-identiﬁcation symmetrydriven accumulation local features. cvpr ieee conference pages ieee gaurav goswami romil bhardwaj richa singh mayank vatsa. mdlface memorability augmented deep learning video face biometrics ieee international joint recognition. conference pages ieee hassner iacopo masi jungyeon jongmoo choi shai harel prem natarajan gerard medioni. pooling faces template based face recognition pooled face images. cvpr’ workshops pages martin hirzer csaba beleznai peter roth horst bischof. person re-identiﬁcation descriptive discriminative classiﬁcation. proc. scandinavian conference image analysis gary huang. learning hierarchical representations face veriﬁcation convolutional deep belief networks. cvpr cvpr pages washington ieee computer society. gary huang manu ramesh tamara berg erik learnedmiller. labeled faces wild database studying face recognition unconstrained environments. technical report technical report university massachusetts amherst zhiwu huang ruiping wang shiguang shan xilin chen. projection metric learning grassmann manifold application video based face recognition. cvpr’ pages herv´e j´egou matthijs douze cordelia schmid patrick p´erez. aggregating local descriptors compact image representation. cvpr’ pages ieee joshua klontz brendan klare scott klum anubhav jain mark burge. open source biometric recognition. biometrics theory applications systems pages ieee martin koestinger martin hirzer paul wohlhart peter roth horst bischof. large scale metric learning equivalence constraints. cvpr’ pages ieee svetlana lazebnik cordelia schmid jean ponce. beyond bags features spatial pyramid matching recognizing natural scene categories. cvpr’ volume pages ieee haoxiang gang xiaohui shen jonathan brandt. eigen-pep video face recognition. computer vision– accv pages springer florian schroff dmitry kalenichenko james philbin. facenet prouniﬁed embedding face recognition clustering. ceedings ieee conference computer vision pattern recognition pages xiaogang wang xiaoou tang. deeply learned face representations sparse selective robust. proceedings ieee conference computer vision pattern recognition pages ruiping wang huimin larry davis qionghai dai. covariance discriminative learning natural efﬁcient approach image classiﬁcation. cvpr’ pages ieee chunhua shen anton hengel. deep recurrent convolutional networks video-based person re-identiﬁcation end-to-end approach. arxiv preprint arxiv. tong xiao hongsheng wanli ouyang xiaogang wang. learning deep feature representations domain guided dropout person re-identiﬁcation. arxiv preprint arxiv. meng yang pengfei gool zhang. face recognition based regularized nearest points image sets. automatic face gesture recognition workshops pages ieee liang zheng yifan jingdong wang shengjin wang tian. mars video benchmark large-scale person re-identiﬁcation. european conference computer vision pages springer", "year": 2017}