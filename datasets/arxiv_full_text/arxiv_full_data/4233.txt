{"title": "SIMILARnet: Simultaneous Intelligent Localization and Recognition  Network", "tag": ["cs.CV", "cs.AI"], "abstract": "Global Average Pooling (GAP) [4] has been used previously to generate class activation for image classification tasks. The motivation behind SIMILARnet comes from the fact that the convolutional filters possess position information of the essential features and hence, combination of the feature maps could help us locate the class instances in an image. We propose a biologically inspired model that is free of differential connections and doesn't require separate training thereby reducing computation overhead. Our novel architecture generates promising results and unlike existing methods, the model is not sensitive to the input image size, thus promising wider application. Codes for the experiment and illustrations can be found at: https://github.com/brcsomnath/Advanced-GAP .", "text": "global average pooling used previously generate class activation image classiﬁcation tasks. motivation behind similarnet comes fact convolutional ﬁlters possess position information essential features hence combination feature maps could help locate class instances image. propose biologically inspired model free differential connections doesn’t require separate training thereby reducing computation overhead. novel architecture generates promising results unlike existing methods model sensitive input image size thus promising wider application. codes experiment illustrations found https//github.com/brcsomnath/advanced-gap. current advances computer vision image recognition seen wide convolutional neural networks shown convolutional units various layers cnns capable detecting position object image without supervision location object. show although earlier convolutional layers capable capturing low-level features image higher layers able capture task-speciﬁc features. however information location features image lost fully connected layers used classiﬁcation. fully convolutional networks proposed recently googlenet network network reduce number network parameters maintaining performance avoiding fully-connected layers. work introduced concept global average pooling layers structural regularizer prevent overﬁtting. however shows average pooling layers used retain localization ability ﬁnal layers network. concept also used localization binary classiﬁcation food items. main disadvantage using global average pooling layers lies fact models require differential connections training deployment. looking biology human nervous system know case connections brain. connections pruned stabilized development period organism. therefore looked methods bridge came architecture need alter connections network. major motivation work comes fact different high level features correspond different classes classiﬁcation image particular class depends certain features excited heavily others. blocking certain speciﬁc features affect perception humans perceive classify image particular class. drawing idea believe errors classiﬁcation ﬁlter absent would useful understand importance features captured ﬁlter. keeping mind present novel architecture used localize positions instances classes image classify hotspots. unlike previous methods architecture sensitive size input image hence wider scope application. experiments done mnist dataset discussions presented point view text extraction natural images proof concept easily extended datasets domains. work described using le-net architecture although method proposed easily scalable cnn. network trained mnist dataset classify images classes following training network obtain reasonably good classiﬁcation accuracy ﬁgure importance ﬁlter last layer classifying digits. since ﬁnal layer ﬁlters information spatial location speciﬁc features well linear combination ﬁlters could provide heatmap features image required classiﬁed classes. idea linear combination ﬁlters would provide activation comes fact every super-pixel corresponding class instance activates ﬁlters responsible classiﬁcation class. therefore linear combination ﬁlters would enhance features captured ﬁlters. however giving equal weights ﬁlters leads information ﬁlter importance getting dropped. ﬁlter responsible capturing important features given weight linear combination. weights learned training separate neural network. however identify importance ﬁlter already trained network itself. since decision boundary approximated network piece-wise linear function difﬁcult understand importance ﬁlter weights learnt network. therefore error classiﬁcation absence ﬁlter metric importance ﬁlter unlike training another network record error classiﬁcation presence ﬁlters baseline. weights generation heatmap using linear combination ﬁlter responses difference error baseline. therefore represents weight vector heatmap generation overall classiﬁcation error error vector represents error classiﬁcation ﬁlter missing where total number ﬁlters. suppose ﬁlter response ﬁnal layer ﬁlters represented represents ﬁlter response ﬁlter. heatmap corresponding position class instances image represented given weighted average ﬁlter responses. mnist handwritten digits dataset experimentation. train network mnist images. training images test images. network used identify position class instances natural images. network trained using adam optimizer learning rate learning rate decay batch size kept images network trained iterations results show network able segment text images. results shown figure network able extract text numbers images similarity features. high threshold value heatmap generated linear combination ﬁlters show extraction property network. although network trained numbers network capable extracting text well. features required classify numbers characters similar. class-wise accuracy mentioned table proposed network architecture clearly used localization recognition trained class instances image. results presented different size images illustrate versatility network. experiments would entail deployment complex datasets using deeper networks possibly checking class-speciﬁc category-speciﬁc heatmaps locate instances objects belonging similar categories i.e. objects respond similar features. szegedy sermanet reed anguelov erhan vanhoucke rabinovich. going deeper convolutions. proceedings ieee conference computer vision pattern recognition pages zhou khosla lapedriza oliva torralba. learning deep features discriminative localization. computer vision pattern recognition ieee conference pages ieee", "year": 2017}