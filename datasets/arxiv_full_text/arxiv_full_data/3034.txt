{"title": "3D Object Reconstruction from a Single Depth View with Adversarial  Learning", "tag": ["cs.CV", "cs.AI", "cs.LG", "cs.RO"], "abstract": "In this paper, we propose a novel 3D-RecGAN approach, which reconstructs the complete 3D structure of a given object from a single arbitrary depth view using generative adversarial networks. Unlike the existing work which typically requires multiple views of the same object or class labels to recover the full 3D geometry, the proposed 3D-RecGAN only takes the voxel grid representation of a depth view of the object as input, and is able to generate the complete 3D occupancy grid by filling in the occluded/missing regions. The key idea is to combine the generative capabilities of autoencoders and the conditional Generative Adversarial Networks (GAN) framework, to infer accurate and fine-grained 3D structures of objects in high-dimensional voxel space. Extensive experiments on large synthetic datasets show that the proposed 3D-RecGAN significantly outperforms the state of the art in single view 3D object reconstruction, and is able to reconstruct unseen types of objects. Our code and data are available at: https://github.com/Yang7879/3D-RecGAN.", "text": "paper propose novel d-recgan approach reconstructs complete structure given object single arbitrary depth view using generative adversarial networks. unlike existing work typically requires multiple views object class labels recover full geometry proposed d-recgan takes voxel grid representation depth view object input able generate complete occupancy grid ﬁlling occluded/missing regions. idea combine generative capabilities autoencoders conditional generative adversarial networks framework infer accurate ﬁnegrained structures objects high-dimensional voxel space. extensive experiments large synthetic datasets show proposed d-recgan signiﬁcantly outperforms state single view object reconstruction able reconstruct unseen types objects. code data available https//github. com/yang/d-recgan. scenarios ar/vr applications semantic understanding robot grasping obstacle avoidance. class popular approaches offthe-shelf low-cost depth sensing devices kinect realsense cameras recover model object captured depth images. approaches typically sample multiple depth images different views object create complete structure however practice always feasible scan surfaces object leads incomplete models occluded regions large holes. addition acquiring processing multiple depth views require signiﬁcant computational power ideal many applications require real-time response. paper tackle problem inferring complete model object using single depth view. challenging task since partial observation object theoretically associated inﬁnite number possible models. traditional reconstruction approaches typically interpolation techniques plane ﬁtting poisson surface estimation estimate underlying structure. however recover limited occluded/missing regions e.g. small holes gaps quantization artifacts sensor noise insufﬁinterestingly humans surprisingly talent ambiguity implicitly leveraging prior knowledge. example given view chair rear legs occluded front legs humans easily able guess likely shape behind visible parts. recent advances deep neural nets data driven approaches suitable deal task. paper acquire complete geometry object given single depth view. utilizing high performance convolutional neural nets large open datasets models approach learns smooth function view complete shape. particularly train end-to-end model estimates full volumetric occupancy depth view object thus predicting occluded structures partial scan. state-of-the-art deep learning approaches shape reconstruction achieve encouraging compelling results limited small resolution typically less voxel grids. result learnt shape tends coarse inaccurate. however increase model resolution without sacriﬁcing recovery accuracy challenging even slightly higher resolution would exponentially increase search space potential mapping functions resulting difﬁculties convergence neural nets. recently deep generative models achieve impressive success modeling complex high-dimensional data distribution among generative adversarial networks variational autoencoders emerge powerful frameworks generative learning including image text generation latent space learning past years number works apply generative models learn latent space represent object shapes solve simple discriminative tasks image generation object classiﬁcation recognition shape retrieval. however shape reconstruction difﬁcult generative task fully explored. paper propose d-recgan novel model combines autoencoder generate full structure conditioned single view. particularly model ﬁrst encodes view lowdimensional latent space vector implicitly represents general geometric structures decodes back recover likely complete structure. rough structure feed conditional discriminator adversarially trained distinguish whether coarse shape plausible not.the autoencoder able approximate corresponding shape adversarial training tends details estimated shape. ensure ﬁnal generated shape corresponds input single partial view adversarial training model based contributions follows formulate novel generative model reconstruct full structure using single arbitrary depth view. drawing autoencoder approach end-to-end trainable high level generality. particularly model consumes simple occupancy grid without requiring object class labels annotations predicting compelling shape high resolution voxel grid. exploit conditional training reﬁne shape estimates autoencoder. contribution latent distribution rather binary variable discriminator train discriminator autoencoder. using latent distribution high-dimensional real fake reconstructed shapes discriminator signiﬁcantly stabilizes training using standard binary variable training leads crash easily. conduct extensive experiments single category multi-category reconstruction outperforming state art. besides approach also able generalize previously unseen object categories. evaluate approach synthetic datasets virtually scanned models. ideally task evaluated real world depth views challenging obtain ground truth shape regard speciﬁc view training evaluation. best knowledge good open datasets ground truth occluded/missing parts holes view real world. extensive experiments demonstrate d-recgan outperforms state large margin. reconstruction results quantitatively accurate also qualitatively details. example chair completion shown figure review different pipelines reconstruction shape completion. conventional geometry based state-of-the-art deep learning based approaches covered. model/shape fitting. uses plane ﬁtting complete small missing regions applies shape symmetry holes. although methods show good results relying predeﬁned geometric regularities fundamentally limits structure space hand-crafted shapes. besides approaches likely fail missing occluded regions relatively big. another similar ﬁtting pipeline leverage database priors. given partial shape input retrieve identical likely model align partial scan. however approaches explictraditionally dense recovery requires collection images geometric shape recovered dense feature extraction matching directly minimizing reprojection errors basically methods used traditional visual slam unable build structures featureless regions white walls. recently leverage deep neural nets learn shape multiple images. although directly require ground-truth labels supervision training rely additional signals contextual camera information supervise view consistency. obviously extra efforts required acquire additional signals. additionally resolution recovered occupancy shape usually small scale single-view reconstruction. predicting complete object model single view long-standing challenging task. reconstructing speciﬁc object category model templates used. example morphable models exploited face recovery concept extended reconstruct simple objects general complex object completion recent machine learning approaches achieve promising results. firman trained random decision forest predict unknown voxels. shapenets amongst early work using deep networks predict multiple solutions single partial view. also adopted similar strategy generate multiple plausible point clouds single image. however strategy signiﬁcantly less efﬁcient directly training end-toend predictor vconv-dae used shape completion originally designed shape denoising rather partial range scans. proposed d-inn estimate skeleton single image recovering accurate complete structure. developed d-epn complete object’s shape using deep nets predict occupancy grid synthesize higher resolution model based shape database. achieves promising results end-to-end system relies prior model database. perspective transformer nets recent ws-gan introduced learn object structures resolution occupancy grid. although need explicit labels supervision requires large number silhouettes masks speciﬁc camera parameters. addition training procedure twostage rather end-to-end. song proposed sscnet scene completion semantic label prediction. although outputs high resolution occupancy requires strong voxel-level annotations supervision. also needs special encoding techniques elimination view dependency strong gradients tsdf. tree structures applies hibert maps representation recover shape thus able produce relatively higher resolution shape. however deep networks consist encoder decoder without taking advantage adversarial learning. varley provides architecture shape completion single depth view producing occupancy grid. although reconstruction results encouraging network scalable higher resolution shape heavy fully connected layers. method aims predict complete shape object takes arbitrary single depth view input. output shape automatically aligned corresponding partial scan. achieve task object model represented voxel grid. simple occupancy information encoding represents occupied cell remains empty cell. speciﬁcally input denoted output shape denoted occupancy grids networks. input shape directly calculated single depth image. generate ground true training evaluation pairs virtually scan objects modelnet figure t-sne visualization partial views corresponding full shapes multiple general chair models. green represents t-sne embedding view whilst embedding corresponding shapes. seen multiple categories inherently similar mapping relationships. essentially neural network learn smooth function denoted maps green dots dots high dimensional space shown equation function parametrized convolutional layers general. generating training pairs feed networks. ﬁrst part network loosely follows idea autoencoder u-net architecture autoencoder serves generator followed conditional discriminator adversarial learning. instead reconstructing original input learning efﬁcient encoding autoencoder network aims learn correlation partial complete structures. supervision complete labels autoencoder able learn function generate reasonable shape given brand partial view. testing phase however results tend graining without details. address issue training phase reconstructed shape autoencoder conditional discriminator verify plausibility. particular partial input view paired corresponding complete shape called real reconstruction partial view paired corresponding output shape autoencoder called fake reconstruction. discriminator aims discriminate fake reconstruction real reconstruction. original framework task discriminator simply classify real fake input jensen-shannon divergence-based loss function difﬁcult converge. recent wgan leverages wasserstein distance weight clipping loss function stabilize training procedure whilst extended work wgan-gp improves training process using gradient penalty respect input. drecgan apply wgan-gp loss function conditional discriminator guarantees fast stable convergence. overall network architecture training shown figure testing phase needs well trained autoencoder shown figure overall main challenge reconstruction arbitrary single view generate information including ﬁlling missing occluded regions unseen views keeping estimated shape corresponding speciﬁc input view. training phase d-recgan ﬁrstly leverages autoencoder generate reasonable fake reconstruction applies adversarial learning reﬁne fake reconstruction make similar real reconstruction jointly updating parameters autoencoder. testing phase given novel view input jointly trained autoencoder able recover full model satisfactory accuracy discriminator longer used. generator based autoencoder skipconnections encoder decoder. unlike vanilla generator generates data arbitrary latent distributions d-recgan generator synthesizes data latent distribution views. particularly encoder convolutional layers bank ﬁlters strides followed leaky relu activation function pooling layer ﬁlters strides number output channels pooling layer starts doubling subsequent layer ends encoder lastly followed fully-connected layers embed semantic information latent space. decoder composed symmetric up-convolutional layers followed relu activations except last layer sigmoid function. skip-connections encoder decoder guarantee propagation local structures input view. noted without fully connected layers skip-connections vanilla autoencoder unable learn reasonable full structures latent space limited local structure preserved. training generator supervised supplying ground true shapes. loss function optimization methods described section discriminator aims distinguish whether estimated shapes plausible not. based conditional discriminator takes real reconstruction pairs fake reconstruction pairs input. particularly consists convolutional layers bank ﬁlters strides followed relu activation function except last layer followed sigmoid activation function. number output channels layer encoder part. unlike original conditional discriminator designed binary discriminator simply classify fake real reconstructions. reason real reconstruction pairs fake reconstruction pairs extremely high dimensional distributions i.e. dimensions. naively classify categories would result unable capture geometric details object discrimination loss unlikely beneﬁt generator back-propagation. instead discriminator designed output long latent vector represents distributions real fake reconstructions. therefore discriminator distinguish distributions latent representations fake real reconstructions generator trained make distributions similar possible. wgan-gp loss functions d-recgan. objectives objective function d-recgan includes main parts object reconstruction loss autoencoder based generator; objective function lgan conditional gan. generator inspired work modiﬁed binary cross-entropy loss function instead standard version. standard binary crossentropy weights false positive false negative results equally. however voxel grid tends empty network easily gets false positive estimation. regard impose high penalty false positive false negative results. particularly weight hyperparameter assigned false positives false negative results shown following equation discriminator leverage stateof-the-art wgan-gp loss functions. unlike original loss function presents overall loss real fake inputs separately represent loss funcgan equation generating fake reconstruction tion pairs equation discriminating fake real reconstruction pairs. detailed deﬁnitions derivation loss functions found modify conditional settings. controls tradeˆy optimizing gradient penalty original objective wgan represents voxel value e.g.{} input view estimated value corresponding voxel generator target value voxel. generator d-recgan network loss functions optimize. discussed section minimizing tends learn overall shapes whilst minimizing estimates plausible structures conditioned input views. minimize improve performance discriminator distinguish fake real reconstruction pairs. metrics evaluate performance reconstruction. ﬁrst metric voxel intersection-overunion predicted voxel grid ground true voxel grid. formally deﬁned follows indicator function index predicted value voxel three dimensions voxel yijk ground true value threshold voxelization. experiments predicted value likely occupied probabilistic aspect. higher value better reconstruction model. metrics evaluate overall reconstruction performance reconstructed geometric details unlikely well evaluated way. therefore large number qualitative results reconstructed models visualized section compare alternative reconstruction methods. ﬁrst well-known traditional poisson surface reconstruction mostly used completing surfaces dense point clouds. second stateof-the-art deep learning based approach proposed varley similar approach terms input output data encoding completion task. encouraging reconstruction performance fully connected layers model unable deal higher resolutions less generality shape completion. also compare autoencoder alone network i.e. without named d-recae short. adopt end-to-end training procedure whole network. simultaneously optimize generator discriminator alternate gradient descent step discriminator step generator. wgan-gp gradient penalty ends modiﬁed cross entropy loss function joint loss function adam solver applied discriminator generator batch size three adam parameters default values i.e. learning rate ﬁrst epoch decaying following epochs. dropout batch normalization testing phase exactly training stage without reconﬁguring network parameters. whole network trained single titan scratch. data synthesis task dense reconstruction single view obtaining large amount training data obstacle. existing real rgb-d datasets surface reconstruction suffer occlusions missing data corresponding complete structure single view. recent work d-epn synthesizes data object completion encoding scheme complicated tsdf different network requirement. tackle issue modelnet database generate large amount training testing data synthetically rendered depth images corresponding complete shape ground truth. particularly subset object categories selected experiments. category generate training data around models train folder synthesizing testing data around models test folder. model create virtual depth camera scan different angles uniformly sampled views roll pitch space. virtual scan depth image corresponding complete voxelized structure generated regard camera angle. depth image simultaneously transformed partial voxel grid using virtual camera parameters. pair partial view complete shape synthesized. overall around training pairs testing pairs generated object category. data produced blender. per-category results. networks separately trained tested three different categories network conﬁgurations. table shows results figure compares qualitative results different reconstruction approaches. multi-category results. study generality networks trained tested multiple categories withgiven class labels. table shows results figure shows qualitative results. cross-category results. investigate generality network trained category tested another different categories. particularly group network trained chair tested sofa stool table toilet stand; group network trained stool tested chair sofa table toilet stand; group network trained toilet tested chair sofa stool table stand. table shows results; figure compare qualitative crosscategory reconstruction results group group group respectively. extensive experiments percategory multi-category object reconstruction demonstrate proposed d-recgan able complete partial views accurate structures ﬁne-grained details outperforming state large margin. addition d-recgan performs well challenging cross-category reconstruction task demonstrates work proposed novel framework drecgan reconstructs full structure object arbitrary depth view. leveraging generalization capabilities autoencoders generative networks d-recgan predicts accurate structures details outperforming traditional poisson algorithm method varley single-view shape completion individual object category. tested network’s ability perform reconstruction multiple categories without providing object class labels training testing showed network able predict satisfactory shapes. finally investigated network’s reconstruction performance unseen categories objects. showed even challenging cases proposed approach still predict plausible shapes. conﬁrms network capability learning general latent features objects rather simply ﬁtting function training datasets. summary network requires single depth view recover accurate complete shape details.", "year": 2017}