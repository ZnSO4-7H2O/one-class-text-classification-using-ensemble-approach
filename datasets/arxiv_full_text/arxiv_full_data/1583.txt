{"title": "Using Soft Constraints To Learn Semantic Models Of Descriptions Of  Shapes", "tag": ["cs.CL", "cs.AI", "cs.HC", "cs.LG"], "abstract": "The contribution of this paper is to provide a semantic model (using soft constraints) of the words used by web-users to describe objects in a language game; a game in which one user describes a selected object of those composing the scene, and another user has to guess which object has been described. The given description needs to be non ambiguous and accurate enough to allow other users to guess the described shape correctly.  To build these semantic models the descriptions need to be analyzed to extract the syntax and words' classes used. We have modeled the meaning of these descriptions using soft constraints as a way for grounding the meaning.  The descriptions generated by the system took into account the context of the object to avoid ambiguous descriptions, and allowed users to guess the described object correctly 72% of the times.", "text": "abstract— contribution paper provide semantic model words used web-users describe objects language game; game user describes selected object composing scene another user guess object described. given description needs ambiguous accurate enough allow users guess described shape correctly. build semantic models descriptions need analyzed extract syntax words’ classes used details). modeled meaning descriptions using soft constraints grounding meaning. language seen system learnt used humans communicating learning covers wide range daily activities. social phenomenon resulting evolving system great complexity. language inextricably linked human capability converse learn reason make decisions environment imprecision uncertainty lack information. viewed complex reality represented step step incremental fashion. respect relevant feature language meaning include meaning/use isolated words also meaning/use expressions whole. general meaning/use words integrating expression grasped relation words within meaning/use expression whole context work part ongoing project called smart-bees. smart-bees project aims study machines learn communicate human-like ways computing words actions perceptions perspective users share common environment play different language-games case share blackboard geometric shapes different colors sizes positions play guessing describing games. describing game given image selected object users describe selected object users non-ambiguous guessing game contrary given description image users guess object described. project roots wittgentstein’s ideas meaning language zadeh’s ideas linguistic variables computing words generalized constraints trillas’ ideas words fuzzy sets roy’s ideas meaning grounding guadarrama’s works computing words actions perceptions learn semantic models descriptions shapes given users several steps needed; collect descriptions shapes web-users; learn lexicon syntax used descriptions; link lexicon syntax features shapes learn semantics; generate descriptions using syntax semantic learned; test web-users. ﬁnal goal learn concepts words sort syntax semantics building model grounded shared perceptions. contribution paper provide semantic model words used webusers describe objects language game; game user describes selected object among composing scene another user guess object described given description needs ambiguous accurate enough allow users guess described object correctly. different words allowed system learn lexicon syntax semantics shape description task. method proposed paper performing quite well obtaining correct spelled words syntactically correct sentences semantically correct sentences; however users spelled average correctly words wrote syntactically correct sentences provided semantically correct sentences. rest paper structured follows. section describe related works compare one. section present model meaning words based soft constraints section present learning algorithm learn soft constraints data section present descriptions generated. finally section presents main results section main conclusions paper. experiment presented inspired describer system done presented similar problem learning descriptions provided user scene composed nonoverlapping squares rectangles. nevertheless turned experiment realistic several aspects allowing different users provide descriptions including kind shapes allowing overlap also important remark previous experiment user native english speaker provided consistent descriptions without spelling syntactical errors ambiguous descriptions experiment variety users different countries non-english native speakers. case system proposed using bi-grams syntax learning gaussian mixtures semantical learning obtaining correct descriptions. user spelled correctly words wrote syntactically correct sentences able provide semantically correct sentences comparison case start users different countries average spelled correctly words wrote syntactically correct sentences able provide semantically correct sentences. previous works contrasted aspects. first language learning integrated process sensory-action learning social learning supervised learning interleaved combined. second start multi-user perspective different users agents interact share knowledge. main difference approach respect published works path taken movement manipulation measurements manipulation perceptions syntax-based systems semantics-based systems. approaches underestimate importance imprecision inherent language perception tried reduce simple forms uncertainty instead dealing general theory uncertainty meaning word language therefore context-dependent. actually words grounded actions perceptions learnt semisupervised environment. summarize main problems faced work collect human descriptions shapes test results interactive website. system learn descriptions provided humans method described paper produce descriptions. examples simple descriptions given users green rectangle green triangle brown rectangle. examples compound descriptions light green rectangle bottom pink circle behind dark green square shape green light blue circle middle orange circle behind yellow circle green small square background dark orange rectangle behind triangle. paper focus semantic learning lexicon syntax learnt also presented conference) generation descriptions validation. using results transformed original problem pairs descriptions shapes problem sets pairs words shapes. represents class words extracted syntax. labels attached. given words’ classes associated objects need learn word class used based features shapes problem similar multiple labeling problem object words’ class need decide labels applicable degree. given pairs words shapes need learn label used according features shapes relations shapes grammatical rules. calculate degree matching description selected object scene important since used later calculate degree ambiguity comparing matching degrees description shapes forming scene. recall results lexical syntax learning phases paper words frequency smaller ﬁltered remained words clustering formed words’ classes generated syntax composed patterns shown table classes words class class background front class circle oval triangle rectangle ellipse square class behind class light dark class bottom right left class pink blue green orange yellow purple violet brown system needs learn speciﬁc words used describe object context analyzed images segment extract objects measure features. used scaffolding learning starting simple descriptions learning compound descriptions; descriptions words lexicon simple compound. words belonging class different meanings; example given class words {’blue’ ’red’ ’green’ ’yellow’..} assume word different meaning therefore represented different model even though cases different words applied object extent. fuzzy edge detector used edges shapes using ﬁlling transformation found regions inside edges ﬁnally using color-based clustering overlapping detection grouped regions shapes. obtaining candidate shapes comprised pixels matched selected object corresponding description. notice different users describe differently objects even used different words different syntax. training data could contain different labels object label all. objects labels word’s classes all; example blue square specify color blue shape square nothing size position object described. obtain robust classiﬁer despite aforementioned problems decided fuzzy decision trees robustness ﬂexibility. also also feature selection learning process different features could relevant class words. used fuzzy decision trees classify objects according labels cross validation prune tree select relevant features. ﬁgure seen fuzzy decision tree class features selected none related class class means current features meaning remains unground fact classes related syntax semantics nevertheless fuzzy decision tree learns frequent word used default. fuzzy decision trees built word’s class calculate degree matching every object every word obtaining soft constraint label. example case class class obtain fuzzy labels plotted ﬁgures respectively. degree ambiguity description scene depends degrees matching description objects scene. object high degree matching description could refer various objects ambiguous. object highest degree matching represents degree matching description objects present scene. thus higher degree matching objects higher degree ambiguity description would discriminative enough. method green circle method light green circle method green circle front scene shown ﬁgure method rectangle method pink rectangle method rectangle generating descriptions scenes using three methods included web-page users guess objects described. warranty fairness experiment users don’t know descriptions generated automatically system ones come users. actually description shown user selected randomly among all. counting correct descriptions users guessed right obtained results showed ﬁgure avoid ambiguous descriptions allowing users guess described object correctly. future work study construction complex phrases referring object. approach taken work possibility study semantic models speciﬁc words used speciﬁc users speciﬁc contexts opened. seen step development computing words whose relevance highlighted zadeh pancho guadarrama syntax learning description scenes composed geometric shapes ieee world congress computational intelligence barcelona spain submitted publication. from computing numbers computing words. manipulation measurements manipulation perceptions ieee transactions circuits systems fundamental theory applications vol. test-score semantics natural languages meaning representation pruf. river edge world scientiﬁc publishing frontier computation? computation information described natural language proceedings symposium fuzzy systems computer science fscs ﬁgure seen method performing bellow average obtains descriptions correct ranked means users performing even worse. method performing little better obtaining descriptions correct ranked method performing quite well obtaining descriptions correct ranked system registered users different countries provided descriptions using different words allowed system learn lexicon syntax semantics shape description task. best method performing quite well obtaining correct spelled words syntactically correct sentences semantically correct sentences; despite variety users spelled correctly words wrote syntactically correct sentences provided semantically correct sentences. trillas renedo guadarrama fuzzy sets language computational intelligence theory practice ser. studies fuzziness soft computing reusch springer vol. guadarrama computing actions case driving simulated race international fuzzy systems associationeuropean society fuzzy logic technologies world congress liang jordan klein learning semantic correspondences less supervision proceedings joint conference association computational linguistics international joint conference natural language processing processing singapore pradera trillas guadarrama renedo fuzzy theories fuzzy logic. spectrum theoretical practical issues ser. studies fuzziness soft computing wang ruan kerre eds. springer vol.", "year": 2010}