{"title": "Monaural Audio Speaker Separation with Source Contrastive Estimation", "tag": ["cs.SD", "cs.AI", "cs.LG", "stat.ML"], "abstract": "We propose an algorithm to separate simultaneously speaking persons from each other, the \"cocktail party problem\", using a single microphone. Our approach involves a deep recurrent neural networks regression to a vector space that is descriptive of independent speakers. Such a vector space can embed empirically determined speaker characteristics and is optimized by distinguishing between speaker masks. We call this technique source-contrastive estimation. The methodology is inspired by negative sampling, which has seen success in natural language processing, where an embedding is learned by correlating and de-correlating a given input vector with output weights. Although the matrix determined by the output weights is dependent on a set of known speakers, we only use the input vectors during inference. Doing so will ensure that source separation is explicitly speaker-independent. Our approach is similar to recent deep neural network clustering and permutation-invariant training research; we use weighted spectral features and masks to augment individual speaker frequencies while filtering out other speakers. We avoid, however, the severe computational burden of other approaches with our technique. Furthermore, by training a vector space rather than combinations of different speakers or differences thereof, we avoid the so-called permutation problem during training. Our algorithm offers an intuitive, computationally efficient response to the cocktail party problem, and most importantly boasts better empirical performance than other current techniques.", "text": "response related work last decade adapted familiar matrix factorization approaches spectral features derived magnitude response though quickly become apparent higher model complexity required. necessary model complexity modeled priori knowledge empirically derived training data stage machine learning signal processing practices. neural network approaches re-entered mainstream machine learning community papers past couple years attempted adapt speech separation problem. methods found recurrent neural networks speech processing shown promise modeling acoustic time series developing cost functions neural networks separate speakers challenging traditional machine learningbased approaches typically rooted classiﬁcation problem. contrast speaker separation usable speakers secondly label ambiguity major issue training actual order separated signals arbitrary so-called permutation problem many works concentrated efforts. solution consider every possible pair speakers training costly approach. alternatively according analysis vector space projection shown best separation date minimizing difference correlation time-frequency time-frequency bins. effective inherent inefﬁciency exposed underlying algorithm speaker attributes optimized relate makes distinct. moreover auto-correlation time-frequency bins unnecessary detrimental performance. using referenced works starting point propose algorithm directly optimize vector space isolates speciﬁc speaker characteristics. borrow concepts negative sampling based approaches natural language processing instead train embedding speakers explicitly contrasted other. conjecture intuitive approach provide better discrimination cost function appropriately models goal. call proposed algorithm source-contrastive estimation abstract—we propose algorithm separate simultaneously speaking persons other cocktail party problem using single microphone. approach involves deep recurrent neural networks regression vector space descriptive independent speakers. vector space embed empirically determined speaker characteristics optimized distinguishing speaker masks. call technique source-contrastive estimation. methodology inspired negative sampling seen success natural language processing embedding learned correlating decorrelating given input vector output weights. although matrix determined output weights dependent known speakers input vectors inference. ensure source separation explicitly speaker-independent. approach similar recent deep neural network clustering permutation-invariant training research; weighted spectral individual speaker frequencies ﬁltering speakers. avoid however severe computational burden approaches technique. furthermore training vector space rather combinations different speakers differences thereof avoid so-called permutation problem training. algorithm offers intuitive computationally efﬁcient response cocktail party problem importantly boasts better empirical performance current techniques. source separation signal denoising problem multiple media century applications ranging acoustic speech processing underwater vessel tracking. application techniques addressing problem extended array processing adaptive signal processing component analysis problem setup majority instances assume well-posed information theoretical guarantees placed source based temporal spatial origins relative sensors. unfortunately guarantees cannot extended monaural case audio recorded single location. previous scenarios assumptions explicitly made specify large degree control environment listening devices usually form multi-microphone systems specially designed radiation patterns. common scenario monaural audio comes audio readily recordable proliferation portable devices scenarios seldom case remainder paper describes approach source separation ﬁnding optimal vector spaces using source-contrastive estimation. consider review state monaural source separation sec. approach described sec. implementation details sec. experimental results shown sec. followed summarization discussion future work latest turn deep learning principal approaches monaural source separation centered matrix factorization techniques among advanced algorithms non-negative matrix factorization commonly cited baseline. attempts address monaural underdetermined separation problems matrix factorization paradigm either focus model variance augmenting number sensor channels applying speech source separation shares commonalities research denoising speech enhancement even closer ties vocals-music separation problem problems categories signal separated qualitatively distinct; aiming separate vocals vocals instrumentals instrumentals source separation complex optimal solutions identiﬁable permutation—it doesn’t matter words whether speaker ends track track long speaker ends one. several attempts made resolve so-called permutation problem though come price additional computational complexity. particular looks possible assignments speakers reconstructed outputs selecting minimal loss across assignments. like prior work ﬁeld treat separation problem matter class-based segmentation. deep clustering addresses permutation problem ﬁrst partition-based segmentation models source separation ﬁeld. constructs timefrequency embedding space trained speaker difference. inference time separate mixtures theoretically number speakers regardless number identity speakers training data. training learning objective deep clustering encourages embedding model generate similar vectors time-frequency associated particular speaker. necessitates comparing time-frequency time-frequency bin. related another approach deep attractor networks also projects every time-frequency low-dimensional embedding space objective pull time-frequency embedding vector given speaker toward using attractor vectors embedding space. separation masks calculated according distance embedding attractors various sources. leads well-separated vector spaces made signiﬁcant progress toward solving source separation problem. observations contributions motivate present work. particular pairwise comparison time-frequency bins needlessly cumbersome. sidesteps comparing embedding attractor vectors number sources considered. greatly reduces number comparisons made leads second observation training source-speciﬁc attractors induced centroids source’s embedding space—meaning attractor locations depend properties example source change positions arbitrarily. embedding techniques like wordvec contrast optimize embeddings targets tandem embeddings inputs. goal training maximize similarity representation target source embedding space joint optimization approach might offer direct solution. inference time target-speciﬁc embedding models discarded input embeddings still retain desirable properties acquired training. moreover approach could obviate need attractors inference time overcoming major limitation approach monaural source separation operates assumption linearly mixed speech wellseparated individual speakers given speaker speaker often done masking magnitude response ﬁltering information timefrequency bins short-time fourier transform belong him/her passing time-frequency bins speaker implemented either ratio case binary mask. }m×t total number speakers training number mixed. masks speaker loudest time frequency otherwise. language processing embedding techniques like wordvec given word embedding represent speciﬁc words. instead word embedding speaker embedding similarly optimized vector spaces. ﬁrst vector space input embedding implicitly deﬁnes speaker associated anyone particular. also output embedding explicitly trains corpus known speakers. then performing inference input vector space possible generalize possible speaker clustering neural network outputs. notation input output vector spaces given sample implemented tensors embedding space labeled respectively. additionally fig. inference output vector space true computations reduced intention out-of-set speaker allowed. fact even though train mixes fewer speakers inference situations arbitrary numbers speaker. algorithm implemented tensorﬂow model architecture consists bidirectional long short term memory layers units each. followed fully connected layer maps output second blstm layer input vector space ﬁnal fig. blstm layers tanh nonlinearities fully connected layer linear. batch inputs output blstm layers rb×t×. ﬁnal layer neural network technically fully-connected linear layer implemented convolution output tensor ﬁlter r××f·e. output convolution reshaped give input vector space rb×t×f×e. implementation allows model arbitrary input useful inference time. efﬁcient evaluation cost function across batches speaker vectors speakers represented batch assembled tensor rb×m×e. ordering speakers must match ordering used otherwise arbitrary. efﬁciently compute products broadcasting expand dimensions input vector space rb×t×f××e output vectors expands rb×××m×e. gives output product operation tensor rb×t×f×m compatable labels multiplied together elementwise give argument sigmoid remaining portion cost function easily evaluated. batch size training. input tensors dimensions rb×t×f label tensors rb×t×f×m length total time steps sample number frequency bins used. experiments signals resampled khz. generate features scaled zero mean unity standard deviation. prior processing applied preemphasis ﬁlter coefﬁcient signals converted short time fourier transform spectrograms. parameters used hanning windows input waveform overlap computing fourier transform signal window columns either tensor dimensions denote vectors associated speaker’s likeness. entire process training testing shown fig. train generate embeddings recurrent neural network regression compare total blstm layers dense layer convolved output vector produced ﬁnal blstm. similarities however. intuitively output neural network time output vector embedding speaker frequency speaker louder speaker time frequency sample would ideally like correlation embedding produced neural network vector speaker high. would like mathematically speaking would like pushing away non-speaker vectors speakers attribute appropriate correlation/anti-correlation determined label former case latter. important note save computation accuracy optimizing stacking resultant spectrograms together obtain representation signal. complex phases saved separately post separation processing. separate spectrograms signal computed training speaker evaluation purposes total spectrogram computed elementwise speakers spectrograms passed square root nonlinearity percent normalized. similar procedure suggested however obtained better results square root rather logarithmic nonlinearity. inference time signal consisting unknown mixture sources preprocessed described previous subsection giving complex estimate single source signal ˆstf input feature generated model obtain vectors k-means clustering performed vectors order generate labeling prediction rt×f×k element associated cluster label. element associated vector belongs otherwise labelings cluster used masks reconstruct source clusters. representations inferred sources calculated elementwise multiplication input spectrogram inferred labeling. fig. comparison vector-vector correlation vectors deep clustering proposed vector space color scale. note in-between values deep clustering versus di-chromicity proposed algorithm. indicative conﬁdent assignments better deﬁned clusters. models trained speaker mixes generated train-clean- subset librispeech corpus subset consists hours high quality read english speech speakers training subset split three ways train model monitor cost ﬁnal compute in-set speakers signal-to-distortion ratio improvement. splits contained unique readings present splits speakers. model out-of-set speakers computed librispeech’s test-clean subset. mixtures generated additively combining different utterances within split create mixed signals known sources. addition sparse baselines compare latest state include convolutional model hershey al.’s deep clustering proposed method source-contrastive estimation listed last tables. comparison embedding vector space learned deep clustering learned seen fig. models attempt learn embedding space vectors belonging speaker close another optimization objectives models quite different. deep clustering optimizes taking frobenius norm difference inferred afﬁnity matrix known afﬁnity matrix cost function. model optimize afﬁnity matrix optimizes visualization vector embeddings example second mixture seen fig. point represents time-frequency color coded according speaker corresponds vectors corresponding different speakers different regions high dimensional space. evaluation separation quality performed eight types mixture sets. problem separating speech signiﬁcantly difﬁcult speakers female male improvement calculated separately femalefemale male-male mixes. addition female-male mixes also evaluated well mixes uniformly random speakers testing splits. improvement mixes consisting three randomly selected speakers also evaluated order test ability models generalize beyond types mixes used training. since model explicitly makes speaker identities training performance measured separately mixtures containing utterances speakers training set. table shows evaluated improvement four types speakers used training. femalefemale female-male mixtures model outperforms deep clustering maintains comparable performance malemale mixtures. improvement mixtures speakers training seen table application type mixture well deﬁned model evaluated mixtures. improvement somewhat lower mixtures model still favorably compares related models outperforming deep clustering pit-s-cnn model female-female female-male mixtures. despite trained mixes speakers deep clustering model ability separate mixtures speakers. performance randomly selected mixtures three speakers given table iii. models give improvement model performs somewhat better out-of-set separation. training runtime concern. nvidia titan card pit’s cnnbased model takes much twice time single training update batch examples model takes averaged thousands training iterations. perform source separation using contrastive estimation. achieves gain compared snmf baseline gains deep learning approaches in-set speakers gain out-of-set speakers. approach saves computational time less burdensome sampling-based technique. future work involves alternative feature representations limited cepstral-based features. proposed work replicates blstms comparisons-sake also explore architectures layers reduce computational load. sanz-robinson huang rieutort-louis wagner sturm verma robust blind source separation reverberant room based beamforming large-aperture microphone array. icassp ieee hansen petersen monaural white noise mixtures hard proceedings ica’ fourth int. symp.. independent component analysis blind signal separation nara japan april virtanen monaural sound source separation nonnegative matrix factorization temporal continuity sparseness criteria ieee transactions audio speech language processing vol. march koldovsk tichavsk time-domain blind separation audio sources basis complete decomposition observation space ieee trans. speech audio language processing vol. february hershey chen roux watanabe deep clustering discriminative embeddings segmentation separation acoustics speech signal processing ieee international conference ieee weng seltzer droppo deep neural networks single-channel multi-talker speech recognition ieee/acm transactions audio speech language processing vol. mikolov sutskever chen corrado dean distributed representations words phrases compositionality advances neural information processing systems curran associates inc. levenberg man´e monga moore murray olah schuster shlens steiner sutskever talwar tucker vanhoucke vasudevan vi´egas vinyals warden watv tenberg wicke zheng tensorflow large-scale machine learning heterogeneous systems software available tensorﬂow.org. wang narayanan wang training targets supervised speech separation ieee/acm transactions audio speech language processing vol. panayotov chen povey khudanpur librispeech corpus based public domain audio books acoustics speech signal processing ieee international conference ieee", "year": 2017}