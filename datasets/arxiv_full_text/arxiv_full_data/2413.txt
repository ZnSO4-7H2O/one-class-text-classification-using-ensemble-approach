{"title": "Output Space Search for Structured Prediction", "tag": ["cs.LG", "cs.AI", "stat.ML"], "abstract": "We consider a framework for structured prediction based on search in the space of complete structured outputs. Given a structured input, an output is produced by running a time-bounded search procedure guided by a learned cost function, and then returning the least cost output uncovered during the search. This framework can be instantiated for a wide range of search spaces and search procedures, and easily incorporates arbitrary structured-prediction loss functions. In this paper, we make two main technical contributions. First, we define the limited-discrepancy search space over structured outputs, which is able to leverage powerful classification learning algorithms to improve the search space quality. Second, we give a generic cost function learning approach, where the key idea is to learn a cost function that attempts to mimic the behavior of conducting searches guided by the true loss function. Our experiments on six benchmark domains demonstrate that using our framework with only a small amount of search is sufficient for significantly improving on state-of-the-art structured-prediction performance.", "text": "consider framework structured prediction based search space complete structured outputs. given structured input output produced running time-bounded search procedure guided learned cost function returning least cost output uncovered search. framework instantiated wide range search spaces search procedures easily incorporates arbitrary structured-prediction loss functions. paper make main technical contributions. first deﬁne limited-discrepancy search space structured outputs able leverage powerful classiﬁcation learning algorithms improve search space quality. second give generic cost function learning approach idea learn cost function attempts mimic behavior conducting searches guided true loss function. experiments benchmark domains demonstrate using framework small amount search sufﬁcient significantly improving state-of-the-art structuredprediction performance. structured prediction involves learning predictor produce complex structured outputs given complex structured inputs. example consider problem image scene labeling structured input image structured output semantic labeling image regions. study search-based approach structured prediction. approach involves ﬁrst deﬁning combinatorial search space complete structured outputs allows traversal output space. next given structured input state-based search strategy guided learned cost function used explore space outputs speciﬁed time bound. least cost output uncovered search returned prediction. effectiveness approach depends critically identiﬁcation effective combination search space search strategy structured outputs ability learn cost function effectively guiding search high quality outputs. main contribution work provide generic solutions issues. first describe limited-discrepancy search space generic search space complete outputs customized particular problem leveraging power classiﬁcation learning algorithms. second give generic cost function learning algorithm instantiated wide class ranking-based search strategies. idea learn cost function allows imitating search behavior algorithm guided true loss function. also provide experimental results approach number benchmark problems show even using relatively small amount search performance comparable better state-of-the-art. typical approach structured prediction learn cost function scoring potential structured output given structured input given cost function input output computation involves solving so-called argmin problem minimum cost output given input. example cost function often represented linear model template features unfortunately exactly solving argmin problem often intractable efﬁcient solutions exist limited cases dependency structure among features forms tree. cases might simplify features allow tractable inference heuristic optimization methods detrimental prediction accuracy. contrast potential advantage search-based approach relatively insensitive dependency structure features used deﬁne cost function. search procedure needs able evaluate cost function speciﬁc input-output pairs. thus free increase complexity cost function without considering impact inference complexity. another potential beneﬁt approach since search complete outputs inference inherently anytime procedure meaning stopped time return best output discovered far. approach addressing inference complexity cascade weiss taskar weiss efﬁcient inference achieved performing multiple runs inference coarse level abstraction. approaches shown good success however place restrictions form cost functions facilitate cascading. another potential drawback cascades approaches either ignore loss function problem require loss function decomposable supports loss augmented inference. approach sensitive loss function makes minimal assumptions requiring blackbox evaluate potential output. alternative framework classiﬁer-based structured prediction. algorithms avoid directly solving argmin problem assuming structured outputs generated making series discrete decisions. approach attempts learn recurrent classiﬁer given input iteratively applied order generate series decisions producing target output simple training methods shown good success positive theoretical guarantees recurrent classiﬁers prone error propagation recent work e.g. searn smile dagger attempts address issue using sophisticated training techniques shown state-of-the-art structured-prediction results. however approaches classiﬁers produce structured outputs single sequence greedy decisions. unfortunately many problems decisions difﬁcult predict greedy classiﬁer crucial good performance. contrast approach leverages recurrent classiﬁers deﬁne good quality search spaces complete outputs allows decision making comparing multiple complete outputs choosing best. closely related framework samplerank framework learns cost function guiding type monte-carlo search space complete outputs. shares work idea explicit search output space signiﬁcant differences. samplerank framework focused monte-carlo search approach instantiated wide range search algorithms. important since well understood search literature appropriate type search changes problem problem. addition samplerank framework highly dependent hand-designed proposal distribution guiding search effectively deﬁning search space. rather describe generic approach constructing search spaces shown effective across variety domains. structured prediction problem speciﬁes space structure inputs space structured outputs nonnegative loss function loss associated labeling particular input output true output provided training input-output pairs drawn unknown target distribution goal return function/predictor structured inputs outputs whose predicted outputs expected loss respect distribution. since algorithms learning cost functions input-output pairs assume availability feature function computes dimensional feature vector pair. output space search. consider framework structured prediction based state-based search space complete structured outputs. states search space pairs inputs outputs representing possibility predicting output search space states speciﬁed functions initial state function returns initial search state input successor function search state returns successor states noting successor must involve input parent. given cost function returns numeric cost input-output pair compute outputs using search procedure guided cost function. particular given input search procedure starts initial state traverses space according search strategy typically sensitive speciﬁed amount time search halts best state according traversed returned predicted output. effectiveness search-based approach depends quality search space deﬁned search strategy quality following sections describe contributions toward deﬁning effective search spaces learning cost functions. section describe search spaces structured outputs flipbit space simple baseline limited-discrepancy search space intended improve baseline. start describing recurrent classiﬁers used deﬁnition spaces. recurrent classiﬁer constructs structured outputs based series discrete decisions. formalized given structured-prediction problem deﬁning appropriate primitive search space. -tuple function maps input initial search node ﬁnite actions successor function maps search node action successor search node feature function search nodes real-valued feature vectors terminal state predicate maps search nodes indicating whether node terminal not. terminal node search space corresponds complete structured output non-terminal nodes correspond partial structured outputs. thus decision process constructing output corresponds selecting sequence actions leading initial node terminal. recurrent classiﬁer function maps nodes primitive search space actions typically mapping terms feature function returns feature vector search node. thus given recurrent classiﬁer produce output starting initial node primitive space following decisions reaching terminal. example sequence labeling problems initial state given input sequence node containing labeled elements. actions correspond selection individual labels successor function adds selected label next position. terminal nodes correspond fully labeled sequences feature function computes feature vector based input previously assigned labels. basic approach learning recurrent classiﬁer exact imitation. this assume training input-output pair efﬁciently action sequence solution path producing exact imitation training approach learns classiﬁer creating classiﬁcation training example node solution path structured example feature vector label equal action followed path experiments recurrent classiﬁers trained exact imitation sophisticated methods searn could also used. flipbit search space simple baseline space complete outputs uses given recurrent classiﬁer bootstrapping search. search state represented sequence actions primitive space ending terminal node representing complete output. initial search state corresponds actions selected classiﬁer equal output generated recurrent classiﬁer. search steps generated successor function change value action sequence position parent state. sequence labeling problem corresponds initializing recurrent classiﬁer output searching ﬂips individual labels. ﬂip-bit space often used local search techniques similar search space underlying gibbs sampling. notice flipbit space uses recurrent classiﬁer initializing search. motivation behind space aggressively exploit recurrent classiﬁer order improve search space quality. originally introduced context problem solving using heuristic search context describe terms using classiﬁer structured prediction given primitive search space. learned classiﬁer accurate number incorrect action selections relatively small. however even small number errors propagate cause poor outputs. idea behind realize classiﬁer response corrected small number critical errors much better output would produced. conducts search space possible corrections hope ﬁnding solution better original. formally given classiﬁer selected action sequence length discrepancy pair index decision step action generally different choice classiﬁer step discrepancies classiﬁer selects actions identically except returns action decision step thus discrepancies viewed overriding preferred choice particular decisions steps possibly correcting errors introducing errors. structured input denote output returned search space conditioned extreme empty simply corresponds output produced greedy classiﬁer. extreme speciﬁes action step inﬂuenced completely speciﬁed discrepancy set. practice reasonably accurate primarily interested small discrepancy sets relative size decision sequence. particular error rate classiﬁer individual decisions small number corrections needed produce correct output correspondingly small. problem know corrections made thus conducts search discrepancy sets usually small large sets. search space deﬁnition. given recurrent classiﬁer deﬁne corresponding limited-discrepancy search space complete outputs follows. search state space represented structured input discrepancy set. view state equivalent input-output state initial state function simply returns corresponds original output recurrent classiﬁer. successor function state returns states form additional discrepancy. path search space starts output generated recurrent classiﬁer traverses sequence outputs differ original number discrepancies. given reasonably accurate expect high-quality outputs generated relatively shallow depths search space hence generated quickly. recall experiments train recurrent classiﬁers exact imitation extremely simple approach compared elaborate methods searn. show desirable property exact imitation accuracy optimized approach directly related quality search space quality relates expected amount search needed uncover target output. formally given input-output pair deﬁne target depth example classiﬁer minimum depth state space corresponding given distribution inputoutput pairs denote expected target depth classiﬁer intuitively depth state search space highly related amount search time required uncover node thus measure simplicity assume decision sequences structured-prediction problem ﬁxed length consider input-output pair corresponding sequence actions generate given classiﬁer deﬁne exact imitation error number mistakes makes nodes along action sequence further given distribution input-output pairs denote expected exact imitation error respect examples drawn distribution. note exact imitation training approach aims learn classiﬁer minimizes ǫei. also denote expected recurrent error expectation randomly drawn hamming distance action sequence produced applied true action sequence error actual measure performance applied structured prediction. recall error propagation possible much worse much factor proposition shows related rather potentially much larger proof. example depth equal number imitation errors made this simply create discrepancy contains discrepancy position imitation error corrects error. depth equal number imitation errors classiﬁer exactly produce exact action sequence producing result follows noting expected number imitation errors equal ǫei. illustrative compare result flipbit space. expected target depth flipbit space randomly drawn easy since search step correct single error expected number errors action sequence initial node since practice theory substantially larger shows space often superior baseline flipbit space terms expected target depth. since depth relates difﬁculty search learning expect space advantageous larger ǫei. experiments indeed case. states ranking decision action. following theorem proved adapting proof minor changes e.g. discounting actions applies stochastic well deterministic search procedures. theorem ﬁnite class ranking functions. target ranking function independent runs rank-based search procedure guided drawn target distribution inputs probability every consistent runs satisﬁes ǫlmax lmax maximum possible loss output. although theoretical result assumes target cost function hypothesis space practice guaranteed. minimize chances able consistent hypothesis include smaller ranking decisions sufﬁcient preserve best output algorithm time step. since decisions speciﬁc every search procedure describe approach speciﬁc search algorithms greedy search best-ﬁrst beam search. greedy search greedy search search step best open node best output uncovered evaluated loss function remembered. level include decisions rank higher siblings best-ﬁrst beam search best-ﬁrst beam search search step open nodes best output encountered maintained beam width. best open node expanded computed best nodes expansion. relevant ranking decisions ensure outputs ranked higher ranked higher every output reduce number constraints considered learner following greedy search beam search. ranking constraints exact imitation generated reaching correct output generate constraint rank higher best cost open node evaluated current cost function continue search guided cost function. search spaces search strategies. approach motivated observation variety structured prediction problems uncover high quality output guide output-space search loss function respect target output since target output available testing time learn cost function mimics search behavior loss function training data. appropriate choice hypothesis space cost functions good performance training data translates good performance testing data. precisely deﬁne notion guiding search loss function. loss function invoked arbitrarily search procedure matching performance would require cost function approximate arbitrarily closely needlessly complex cases. hence restrict ranking-based search deﬁned follows. ranking-based search. anytime search procedure takes input calls cost function pairs number times outputs structured output ybest ranking-based search procedure results calls used compare relative values different pairs ﬁxed breaker. comparison tie-breaking called ranking decision characterized tuple binary decision indicates better output input requested returns best output ybest encountered thus evaluated cost function. note constraints prohibit search procedure sensitive absolute values cost function particular search states pairs consider relative values. many typical search strategies greedy search best-ﬁrst search beam search satisfy property. given hypothesis space cost functions cost function learning works follows. runs search procedure training example maximum time tmax substituting loss function cost function records di). ranking deranking decisions internal states search procedure correspond approach consists main components recurrent classiﬁer cost function train sequentially. first train recurrent classiﬁer described section trained classiﬁer deﬁne search spaces complete outputs every training input second train cost function score outputs given combination search space complete outputs search procedure described section test time learned recurrent classiﬁer cost function make predictions follows. test input deﬁne search space complete outputs using recurrent classiﬁer execute search procedure search space guided cost function speciﬁed time bound. return best cost output uncovered search prediction datasets. evaluate approach following structured prediction problems handwriting recognition input sequence binary-segmented handwritten letters output corresponding character sequence dataset contains roughly examples divided folds consider different variants task hw-small version fold training remaining folds testing vice-versa hw-large. nettalk stress. task assign stress labels letter word. training words test words standard dataset. sliding window size observational features. nettalk phoneme. similar nettalk stress except task assign phoneme labels letter word. chunking. goal task syntactically chunk english sentences meaningful segments. consider full syntactic chunking task dataset conll shared task consists sentences training data sentences testing data. tagging. consider tagging problem english language goal assign part-of-speech word sentence. standard data wall street journal corpus used experiments. scene labeling. dataset contains images outdoor scenes image divided patches placing regular grid size patch takes semantic labels simple appearance features like color texture position used represent patch. training performed images remaining images used testing. sequence labeling problems recurrent classiﬁer labels sequence using left-to-right ordering scene labeling problem ordering top-left right-bottom row-wise raster form. train recurrent classiﬁer output label previous token used feature predict label current token sequence labeling problems exception chunking tagging labels previous tokens used. scene labeling labels neighborhood patches used. experiments train recurrent classiﬁer using exact imitation perceptron iterations learning rate prediction accuracy measured loss chunking task hamming loss remaining tasks. cases cost function input-output pairs second order meaning features neighboring label pairs triples along features structured input. trained cost function described section online manner perceptron updates learning rate iterations learners. report results several instantiations framework. first consider framework using greedy search procedure ﬂip-bit spaces denoted lds-greedy fb-greedy. training testing greedy search number steps equal length sequence. using longer runs impact results signiﬁcantly. second performed best-ﬁrst beam search beam width ﬂib-bit spaces denoted lds-bst-b fb-bst-b. best-ﬁrst search expansions case. tried larger beam widths search steps performance similar. third impact adding additional search test time greedily trained cost function also used cost function learned lds-greedy fb-greedy context bestﬁrst beam search test time ﬂip-bit space denoted lds-bst fb-bst. also report performance recurrent classiﬁer exact imitation accuracy described earlier related structures ﬂip-bit spaces. results structured precompare searn cascades algorithms report best published results whenever available. remaining cases used publicly available code implementation generate results. percent training data used tune hyper-parameters. crfs trained using sgd. svmhmm used train svmstruct value parameter chosen based validation set. cascades trained using implementation provided authors used sequence labeling problems hamming loss. searn report best published results linear classiﬁer indicated table otherwise implementation searn optimal approximation described optimized interpolation parameter validation set. note compare results samplerank fact performance highly dependent hand-designed proposal distribution varies domain another. comparison state-of-the-art. table shows prediction accuracies different algorithms across benchmarks even basic instantiations framework lds-greedy fbgreedy produce results comparable signiﬁcantly better state-of-the-art. particularly interesting since results achieved using relatively small amount search simplest search method results tend better instantiations. likely reason outperforming crfs svm-struct second-order features approaches ﬁrst-order features since exact inference higher order features costly especially during training. stated earlier advantages approach higher-order features negligible overhead. whether approach beneﬁt increasing feature order generated results approach cascades using third-order features net-talk handwriting domains. cascades improved results second-order cost function handwriting dataset degraded netfinally improvement scene labeling domain signiﬁcant searn achieves accuracy versus lds-greedy. domain prior work considered simpler task classifying entire images discrete classes best knowledge considered structured prediction approach patch classiﬁcation. reported result patch classiﬁcation aware obtain accuracy non-linear svms trained i.i.d. patches using sophisticated features ours. adding search. lds-bst fb-bst generally better lds-greedy fb-greedy biggest improvement challenging scene labeling domain improving shows effective strategy train using greedy search insert cost function elaborate search test time improvement. similar results ldsbst-b fb-bst-b cost function trained using best-ﬁrst beam search. signiﬁcant improvement net-talk datasets scene labeling compared lds-bst fb-bst. illustrates approach effectively train using complex search strategy best-ﬁrst beam search. interesting note lds-bst lds-bst-b perform similarly. methods best-ﬁrst search procedure test time differ trains greedy search best-ﬁrst search. shows based results clear advantage trainstate-of-the-art performance validating effectiveness framework. future work includes studying robust training approaches mitigate error propagation cost function non-realizable addressing scalability issues. tsochantaridis ioannis hofmann thomas joachims thorsten altun yasemin. support vector machine learning interdependent structured output spaces. icml space flipbit space. generally instances method space outperforms corresponding instances flipbit space. interestingly large difference exact imitation accuracy recurrent classiﬁer accuracy space signiﬁcantly better ﬂip-bit space. particularly true complex problem scene labeling difference quite large flipbit. further compared anytime curves ldsgreedy fb-greedy show accuracy achieved method versus inference time bound prediction time. generally found lds-greedy comparable better fb-greedy curve especially handwriting scene labeling problems. figure shows anytime curves scene labeling problem. lds-greedy dominant improves accuracy much quickly fb-greedy. example second time bound lds-greedy achieves accuracy fb-greedy using seconds. results show beneﬁt using space empirically conﬁrm observations section quality flipbit spaces related exact imitation recurrent errors respectively. studied general framework structured prediction based search space complete outputs. showed powerful classiﬁers leveraged deﬁne effective search space complete outputs gave generic cost function learning approach score outputs given combination search space search strategy. experimental results showed small amount search needed improve upon", "year": 2012}