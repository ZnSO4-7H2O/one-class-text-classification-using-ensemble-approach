{"title": "Device Placement Optimization with Reinforcement Learning", "tag": ["cs.LG", "cs.AI"], "abstract": "The past few years have witnessed a growth in size and computational requirements for training and inference with neural networks. Currently, a common approach to address these requirements is to use a heterogeneous distributed environment with a mixture of hardware devices such as CPUs and GPUs. Importantly, the decision of placing parts of the neural models on devices is often made by human experts based on simple heuristics and intuitions. In this paper, we propose a method which learns to optimize device placement for TensorFlow computational graphs. Key to our method is the use of a sequence-to-sequence model to predict which subsets of operations in a TensorFlow graph should run on which of the available devices. The execution time of the predicted placements is then used as the reward signal to optimize the parameters of the sequence-to-sequence model. Our main result is that on Inception-V3 for ImageNet classification, and on RNN LSTM, for language modeling and neural machine translation, our model finds non-trivial device placements that outperform hand-crafted heuristics and traditional algorithmic methods.", "text": "bahdanau speech synthesis together success growth size computational requirements training inference. currently typical approach address requirements heterogeneous distributed environment mixture many cpus gpus. environment common practice machine learning practitioner specify device placement certain operations neural network. example neural translation network layer attention layer softmax layer computed although decisions made machine learning practitioners challenging especially network many branches minibatches larger. existing algorithmic solvers hand ﬂexible enough work dynamic environment many interferences. paper propose method learns optimize device placement training inference neural networks. method illustrated figure takes account information environment performing series experiments understand parts model placed device arrange computations communication optimized. method sequence-to-sequence model read input information operations well dependencies them propose placement operation. proposal executed hardware environment measure execution time. execution time used reward signal train past years witnessed growth size computational requirements training inference neural networks. currently common approach address requirements heterogeneous distributed environment mixture hardware devices cpus gpus. importantly decision placing parts neural models devices often made human experts based simple heuristics intuitions. paper propose method learns optimize device placement tensorflow computational graphs. method sequence-tosequence model predict subsets operations tensorflow graph available devices. execution time predicted placements used reward signal optimize parameters sequence-to-sequence model. main result inception-v imagenet classiﬁcation lstm language modeling neural machine translation model ﬁnds non-trivial device placements outperform hand-crafted heuristics traditional algorithmic methods. past years neural networks proven general effective tool many practical problems image classiﬁcation speech recognition graves jaitly hannun chan machine translation recurrent neural language model neural machine translation single-step measurements show scotch yields disappointing results three benchmarks suggesting graph-based heuristics ﬂexible enough them. method non-trivial placements times faster. applied train three models real time placements found method faster human experts’ placements. work closely related idea using neural networks reinforcement learning combinatorial optimization space possible placements computational graph discrete model placements using sequenceto-sequence approach trained policy gradients. however experiments early work concerned datasets whereas work applies framework large-scale practical application noisy rewards. reinforcement learning also applied optimize system performance. example propose train resource management algorithm policy gradients. however optimize expected value hand-crafted objective function based reward unlike work optimize directly running time conﬁgurations hence relieving need design intermediate cost models. graph partitioning intensively studied subject computer science. early work kernighan kirkpatrick fiduccia mattheyses johnson employ several iterative reﬁnement procedures start partition continue explore similar partitions improve. alternative methods hagen kahng karypis kumar perform spectral analyses matrix representations graphs partition them. despite extensive literature graph partitioning algorithms remain heuristics computational graphs. reason order apply algorithms construct cost models graphs concern. since models expensive even estimate virtually cases accurate graph partitioning algorithms applied lead unsatisfying results show section paper. ments. scotch mapper attempts balance computational load collection tasks among connected processing nodes reducing cost communication keeping intensively communicating tasks nearby nodes. scotch relies collection graph partitioning techniques k-way multilevel method band method diffusion method dual recursive bipartitioning mapping scotch models problem graphs. ﬁrst graph called target architecture graph whose vertices represent hardware resources cpus gpus whose edges represent communication paths available them pcie network link. second graph called source graph models computation mapped onto target architecture graph. case tensorflow computations programs modeled graph whose vertices represent operations graph edges represent multidimensional data arrays communicated them. scotch users choose given partitioning applied graphs. however experiment rely software’s default strategies implemented scotch already extensively tuned. consider tensorflow computational graph consists operations list available devices. placement assignment operation device denote time takes perform complete execution placement goal device placement optimization execution time minimized. seek minimize execution time direct optimization results major issues. first beginning training process placements sampled measurements noisy leading inappropriate learning signals. second model gradually converges placements sampled become similar other leading small differences corresponding running times results less distinguishable training signals. empirically square root running time makes learning process robust. accordingly propose train stochastic poluse sequence-to-sequence model lstm content-based attention mechanism predict placements. figure shows overall architecture model divided parts encoder decoder rnn. input encoder sequence operations input graph. embed operations concatenating information. speciﬁcally input graph ﬁrst collect types operations. operation’s type describes underlying computation matmul convd. type store tunable embedding vector. record size operation’s list output tensors concatenate ﬁxed-size zero-padded list called output shape. also take one-hot encoding vector represents operations direct inputs outputs operation. finally embedding operation concatenation type output shape one-hot encoded adjacency information. decoder attentional lstm ﬁxed number time steps equal number operations graph step decoder outputs device operation encoder time step. device tunable embedding input next decoder time step. challenge applying method tensorflow computational graphs graphs generally thousands operations modeling large number operations sequence-to-sequence models difﬁcult vanishing exploding gradient issues large memory footprints. propose reduce number objects place difwork deﬁned attentional sequence-to-sequence model describe section learn network parameters using adam optimizer based policy gradients computed reinforce equation simple moving average baseline works well experiments. practice computational graphs large memory footprints placements fail execute e.g. putting operations huge lstm single exceed device’s memory limit. cases square root running time large constant call failing signal. specify failing signal manually depending input graph. observe throughout training process placements sporadically unexpectedly fail perhaps factors state machine phenomenon particularly undesirable towards training process since large difference baseline leads large update parameters potentially perturbs parameters good minimum. thus hard-code training process steps performs parameter update sampled placement placement executes. experiments also initializing baseline failing signal results exploration. several heuristics create co-location groups. first rely tensorflow’s default co-location groups co-locating operation’s outputs gradients. apply simple heuristic merge operations co-location groups. speciﬁcally output operation consumed another operation operations co-located. many initialization operations tensorflow grouped way. experiments apply heuristic recursively iteration treat co-location groups operations groups merged. certain models apply speciﬁc rules construct co-location groups. example convnets treat several convolutions pooling layers co-location group models treat lstm cell group. speed training process model using asynchronous distributed training shown figure framework consists several controllers execute current policy deﬁned attentional sequence-to-sequence model described section controllers interact single shared parameter server. note parameter server holds controllers’ parameters input graph’s parameters keeping input graph’s parameters parameter server potentially create latency bottleneck transfer parameters. controller framework interacts workers number monte carlo samples equation second phase worker executes placement receives measures running time. reduce variance measurements placement executed steps average running time steps ﬁrst recorded. observe tensorflow ﬁrst step take longer execute compared following steps hence treat itss runing time outlier. controller waits workers ﬁnish executing assigned placements returning running times. running times received controller uses running times scale corresponding gradients asynchronously update controller parameters reside parameter server. experiments controllers either workers. setting takes hours best placement models experiments. using workers controller yields accurate estimates policy gradient equation comes expense possibly workers idle states. also note discrepancies machines stable controller baseline. following experiments apply proposed method assign computations devices three important neural networks deep learning literature recurrent neural language model attentional neural machine translation inceptionv compare placements strong existing baselines described section training process alternating phases. ﬁrst phase worker receives signal indicates wait placements controller controller receives signal indicates sample placements. sampled placement comes probability. controller independently sends recurrent neural network language model layers grid structure model introduces tremendous potential parallel executions lstm cell start soon input previous states available. neural machine translation attention mechanism architecture model similar rnnlm large number hidden states source target sentences necessitates model parallelism. sutskever propose place lstm layer attention layer softmax layer separate device. authors observe signiﬁcant improvements training time choices optimal. fact show experiments trained policy signiﬁcantly better placements. inception-v widely-used architecture image recognition visual feature extraction inception network multiple blocks. block several branches convolutional pooling layers concatenated make inputs next block. branches executed parallel network’s depth restricts potential since later blocks wait previous ones. model details. inception-v step executed batch images size widely-used setting imagenet challenge rnnlm model lstm layers sizes respectively. number unrolling steps rnnlm well maximum length source target sentences pass rnnlm consists minibatch sequences. co-location groups. pre-process tensorflow computational graphs three aforementioned models manually create co-location groups. precisely; rnnlm treat lstm cell embedding lookup attention step softmax prediction step group; inception-v treat branch group. table shows grouping statistics models. metrics. implement training operations rnnlm using adam inception-v using rmsprop evaluate placement total time takes perform forward pass backward pass parameter update. reduce measurement variance average running times several trials. additionally train model scratch using placements found single-cpu. placement executes whole neural network single cpu. processing large models gpus infeasible memory limits leaving singlecpu choice despite slow. scotch. estimate computational costs operation well amount data ﬂows along edge neural network model feed scotch static mapper also annotate architecture graph compute communication capacities underlying devices. expert-designed. rnnlm lstm layer device. also attention mechanism softmax layer device highest lstm layer embedding layer device ﬁrst lstm layer. inception-v common practice batch size entire model single gpu. implementation inception-v batch using gpu. create intuitive baseline multiple gpus heuristically partition model contiguous parts roughly number layers. compare approach section common practice inception-v larger batch size apply data parallelism using gpus. runs replica model processes batch size compare approach section table running times placements found rl-based method baselines model ﬁrst shows results gpus; second shows results gpus. last column shows improvements running time achieved rl-based placement fastest baseline. reduce variance running times less seconds measured times averages recorded. memory. figure rl-based placement neural graph. encoder bottom decoder. devices denoted colors transparent color represents operation unique color represents different gpu. placement achieves improvement running time compared ﬁne-tuned expert-designed placement. methods placements. despite given information running times placements number available devices model learns subtle tradeoffs performance gain parallelism costs induced inter-device communications. available rl-based placer ﬁnds efﬁcient gpus reducing model’s per-step running time seconds seconds. result signiﬁcant neither baselines could placement better assigning operations single gpu. rnnlm. method detects possible whole rnnlm graph decides save inter-device communication latencies. resulting placement twice faster best published human-designed baseline. neural method ﬁnds non-trivial placement leads speedup gpus. method also learns less computational expensive operations embedding lookups cpu. suspect whilst slowest device handle lookup operations reduce load gpus. inception-v. inception-v batch size rl-based placer learns gpus available degree freedom model parallelism limited. thus places operations single however gpus also conduct simple extension experiments increasing batch sizes rnnlm lstm sizes respectively. makes models’ memory footprints large even layer cannot ﬁtted single device hence ruling human-designed placement. nevertheless several steps ﬁnding placements fail approach manages successfully place input models devices running times placements found large rnnlm seconds respectively. figure rl-based placement inception-v. devices denoted colors transparent color represents operation unique color represents different gpu. rl-based placement achieves improvement running time compared expert-designed placement. inception-v. train inception-v imagenet dataset model reaches accuracy validation set. practice often inception models trained data parallelism rather model parallelism. thus compare placements found algorithm baselines. ﬁrst baseline called asynchronous towers puts replica inception-v network gpu. replicas share data reading operations assigned cpu. replica independently performs forward backward passes compute model’s gradients respect minibatch images updates parameters asynchronously. second baseline called synchronous tower asynchronous towers except waits gradients copies making update. settings learning rate trained using rmsprop. figure training curves inception-v model using rl-based placement expert-designed placements synchronous towers asynchronous towers. per-step running time well perplexities averaged runs. figure shows training curves three settings inception-v. seen ﬁgure end-toend training result conﬁrms rl-based placement indeed speedups training process compared neural train neural model english-german dataset. experiments pre-process dataset word pieces vocabularies languages consist word pieces. order match model’s settings consider translation pairs sentence word pieces. train model steps record train perplexities. training machine nvidia tesla gpus intel haswell cpu. since inevitable noises computer systems measuring running times train model times independently average per-step running times perplexities. rl-based placement runs faster expertdesigned placement shown training curves figure quantitatively expert-designed placement puts layer different takes hours; meanwhile rlbased placement takes hours giving speed total training time. note measured speedup rate models appear different reported table measuring method several overheads. synchronous tower. asynchronous towers gives better per-step time synchronous approaches lead faster convergence. training curve rl-based placement slower ﬁrst eventually crosses training curve asynchronous towers. figure computational load proﬁling model rlbased expert-designed placements. smaller blocks color correspond feedforward path same-color upper blocks correspond backpropagation. rl-based placement performs balanced computational load assignment expert-designed placement. neural ﬁrst compare per-device computational loads rl-based placement expert-designed placement model. figure shows performance proﬁling. rl-based placement balances workload signiﬁcantly better expert-designed placement. interestingly take account time back-propagation expert-designed placement makes sense workload balanced imbalance much signiﬁcant back-propagation time considered. figure computational load memory copy proﬁling inception-v rl-based synchronous tower placements. ﬁgure operation runtime gpus. smaller blocks color correspond feedforward path same-color upper blocks correspond backpropagation. rl-based placement produces less balanced computational load synchronous tower. bottom ﬁgure memory copy time. memory copy activities synchronous tower general slower copies take place rl-based placement. inception-v. inception-v however rl-based placement seek balance computations between gpus illustrated figure -top. suspect inception-v dependencies allowing less room model parallelism across gpus. reduction running time rl-based placement comes less time spends copying data devices shown figure -bottom. particular models parameters device operations them unlike synchronous tower towpaper present adaptive method optimize device placements neural networks. approach sequence-to-sequence model propose device placements given operations neural network. model trained optimize execution time neural network. besides execution time number available devices information hardware conﬁguration feed model. tradeoff computation communication hardware. range tasks including image classiﬁcation language modeling machine translation method surpasses placements carefully designed human experts highly optimized algorithmic solvers.", "year": 2017}