{"title": "Deep CNN based feature extractor for text-prompted speaker recognition", "tag": ["eess.AS", "cs.CL", "cs.LG", "cs.SD", "stat.ML"], "abstract": "Deep learning is still not a very common tool in speaker verification field. We study deep convolutional neural network performance in the text-prompted speaker verification task. The prompted passphrase is segmented into word states - i.e. digits -to test each digit utterance separately. We train a single high-level feature extractor for all states and use cosine similarity metric for scoring. The key feature of our network is the Max-Feature-Map activation function, which acts as an embedded feature selector. By using multitask learning scheme to train the high-level feature extractor we were able to surpass the classic baseline systems in terms of quality and achieved impressive results for such a novice approach, getting 2.85% EER on the RSR2015 evaluation set. Fusion of the proposed and the baseline systems improves this result.", "text": "deep learning still common tool speaker veriﬁcation ﬁeld. study deep convolutional neural network performance text-prompted speaker veriﬁcation task. prompted passphrase segmented word states i.e. digits test digit utterance separately. train single high-level feature extractor states cosine similarity metric scoring. feature network max-feature-map activation function acts embedded feature selector. using multitask learning scheme train high-level feature extractor able surpass classic baseline systems terms quality achieved impressive results novice approach getting evaluation set. fusion proposed baseline systems improves result. i-vector-based systems well known state-of-the-art solutions text-independent speaker veriﬁcation problem nonetheless problem gradually gaining attention deep learning perspective. particularly studies make deep neural network order divide acoustic space senone classes classic total variability model applied discriminate speakers space afterwards phonetic discriminative dnn-based systems major techniques distinguished. ﬁrst uses posteriors calculate baum-welch statistics second uses bottleneck features pair speaker speciﬁc features full tv-ubm system training. recent publications suggest substantial advancement state-of-the-art text-dependent veriﬁcation systems mainly based progress text-independent speaker recognition task. therefore successful application hand direct speaker discrimination natural speaker veriﬁcation. several profound studies advantageous usage deep end-toend solutions discriminating speakers directly textdependent task paper describes extracts small speaker footprint used discriminate speakers. paper presents well performing implementation extractor based speaker discriminative approach text-independent task. paper focuses text-prompted speaker veriﬁcation scenario. require user remember speciﬁc passphrase reduces risk replay attacks system. previously shown segmenting passphrase word states prior supervector extraction able construct accurate statistical models speech signals present study continues approach suggest ways improvement deep speaker veriﬁcation systems. work exploits deep convolutional neural network max-feature-map activation function based maxout activation function direct speaker discrimination text-dependent setting. train deep high-level feature extractor prompted passwords. experiments mainly conducted part database contains series randomized digit sequences representing passwords. results proposed baseline systems compared section encouraged success deep learning model replay attack spooﬁng detection task endeavour improve state-of-the-art techniques text-prompted speaker veriﬁcation employing similar network architecture. cnn-based system also operates distinct states hmm-based segmentation used split passphrase separate digits. power spectra extracted speech signal input features. feature size along frequency domain axis ﬁxed bands varying utterance time span must adjusted ﬁxed length frames estimation longest digit pronouncement time. done either cropping features along time axis wrap padding done cepstral mean variance normalization done digit. network composed several layer groups represented convolutional layer followed layer optionally pooling layer. groups stacked together followed dense layers produce embeddings input power spectra features. details covered table ways training deep neural network extractor text-prompted scenario. ﬁrst train network discriminate speakers second complex train network discriminate speakers digits simultaneously latter approach used also section brieﬂy describes three state-of-the-art textdependent speaker veriﬁcation systems referred baseline systems. passphrase segmentation hidden markov model based viterbi alignment. frontend baseline systems computes mel-frequency cepstral coefﬁcients well ﬁrst second time derivatives yield -dimensional vector frame. framing done every window. gaussian mixture model based voice activity detector used remove non-speech frames. also apply cepstral mean subtraction apply feature warping cepstral coefﬁcients. baseline gmm-svm system implemented accordance mean supervector obtained relevant maximum posteriori adaptation speaker-independent universal background model passphrase. segmentation done system. trained passphrase database development set. compensate inter-speaker variability nuisance attribute projection applied. support vector machine used backend classiﬁer. finally score s-normalization done. system segmentation used split passphrase individual digits. digit state-gmm mean supervector extracted described state associated unique speaker-independent trained database training set. speakerdependent means state obtained adaptation means. speaker-dependent mean supervector obtained concatenation speaker state mean vectors states. score s-normalization also utilized system. log-likelihood ratio score digit tested utterance obtained plda scoring procedure. ﬁnal score utterance calculated scores states score normalization needed. exploit multitask setup assign individual class speaker pronouncing particular digit. total amount classes increases factor i.e. nspeakers× ndigits. network trained multitask mode multiclass cross entropy loss function. training last fully-connected layer softmax activation removed network order obtain extractor high-level representations speaker pronounced digits. evaluation step embeddings individual digit utterance obtained network forward pass. cosine similarity metric used afterwards compare corresponding targets. test digit embedding compared digit embedding enrollment averaged enrollment sessions. finally average score digits passphrase returned. note discriminant analysis backend instead cosine similarity. training also extended wells fargo bank dataset described contains short digit passphrase utterances training part stc-russiandigits dataset. contains utterances random russian digit sequences pronounced native speakers. speaker recorded sessions consists microphone records made different devices android-based mobile phone ios-based mobile phone web-camera. record includes pronunciations russian digits random order. stc-russian-digits database split training evaluation parts according table tables present equal error rate minimum detection cost function various systems. best performance among baseline systems demonstrated stgmm-svm yielding pooled male female conditions. speaker discriminative deep trained single task mode could surpass baseline results achieving eer. however showed signiﬁcant performance improvement multitask remarkably language corpora foreign classes presented training system learns discriminate embeddings speakers languages based common speaker variability bottom lines table show extending training cnn-based system leads performance boost. best performing system stcn pooled english russian subcorpora. unlike baseline systems beneﬁt training in-domain data only deep cnn-based system improves out-of-domain data added learning phase multitask setup. figure illustrates embedding discriminative capability system randomly chosen speaker embeddings projected principal axes t-sne advantages using speaker text discriminative embeddings trained english russian digspeech signals. first automatically validate correctness passphrase. second used languages paper proposed deep cnn-based solution text-prompted speaker veriﬁcation problem. high level feature extractor trained discriminate speakers digits simultaneously embeddings measured simply cosine similarity. using multitask learning scheme able surpass classic baseline systems terms quality achieved impressive results novice approach obtaining evaluation set. fusion proposed baseline systems almost decrease test sets. najim dehak patrick kenny r´eda dehak pierre dumouchel pierre ouellet front-end factor analysis speaker veriﬁcation ieee transactions audio speech language processing vol. sergey novoselov timur pekhovsky oleg kudashev valentin mendelev alexey prudnikov nonlinear plda i-vector speaker veriﬁcation sixteenth annual conference international speech communication association oleg kudashev sergey novoselov timur pekhovsky konstantin simonchik galina lavrentyeva usage speaker recognition advantages problems isnn. springer sergey novoselov timur pekhovsky andrey shulipa oleg kudashev plda-based system textprompted password speaker veriﬁcation advanced video signal based surveillance ieee international conference pavel matˇejka ondˇrej glembek ondˇrej novotn`y oldˇrich plchot frantiˇsek gr´ezl luk´aˇs burget honza cernock`y analysis approaches speaker identiﬁcation acoustics speech signal processing ieee international conference ieee hossein zeinali lukas burget hossein sameti ondrej glembek oldrich plchot deep neural networks hidden markov models i-vector-based odyssey-the text-dependent speaker veriﬁcation speaker language recognition workshop gautam bhattacharya jahangir alam themos stafylakis patrick kenny deep neural network based text-dependent speaker recognition preliminary results shi-xiong zhang zhuo chen yong zhao jinyu yifan gong end-to-end attention based textdependent speaker veriﬁcation spoken language technology workshop ieee. ieee georg heigold ignacio moreno samy bengio noam shazeer end-to-end text-dependent speaker veriﬁcation ieee international conference acoustics speech signal processing ehsan variani erik mcdermott ignacio lopez moreno javier gonzalez-dominguez deep neural networks small footprint text-dependent speaker veriﬁcation ieee icassp. ieee david snyder daniel garcia-romero daniel povey sanjeev khudanpur deep neural network embeddings text-independent speaker veriﬁcation proc. interspeech galina lavrentyeva sergey novoselov egor malykh alexander kozlov oleg kudashev vadim shchemelinin audio replay attack detection deep learning frameworks proc. interspeech anthony larcher kong haizhou database text-dependent speaker veriﬁcation using multiple pass-phrases thirteenth annual conference international speech communication association", "year": 2018}