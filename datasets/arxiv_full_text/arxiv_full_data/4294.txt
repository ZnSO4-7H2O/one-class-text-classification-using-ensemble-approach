{"title": "Generative Models for Stochastic Processes Using Convolutional Neural  Networks", "tag": ["stat.ML", "cs.NE", "physics.comp-ph", "q-fin.CP"], "abstract": "The present paper aims to demonstrate the usage of Convolutional Neural Networks as a generative model for stochastic processes, enabling researchers from a wide range of fields (such as quantitative finance and physics) to develop a general tool for forecasts and simulations without the need to identify/assume a specific system structure or estimate its parameters.", "text": "present paper aims demonstrate usage convolutional neural networks generative model stochastic processes enabling researchers wide range fields quantitative finance physics develop general tool forecasts simulations without need identify/assume specific system structure estimate parameters. widely known procedures identification estimation simulation stochastic processes somewhat already well established mathematics computing related fields sub-fields statistics physics econometrics. hand rely fact that work properly observer must impose system structure estimate respective parameters hamilton hayashi often assume probability distribution function. parallel strategies possible verify revival artificial neural networks mostly forgotten mid-s considered black-boxes without intelligibility inner computations seen benitez kolman margaliot important reasons revival success deep neural networks successfully employed tasks pattern recognition classification prediction performing better humans tasks encompass wide range different problems computer vision problems character recognition object recognition others; audio processing; defeating world-class human players complex computer games chess. composing deep networks enabling filtering desired multiscale/multidimensional features enhance classification/forecasting capabilities interpreted understood plus softmax classifier/regressor basically works normalized multinomial logistic regressor bishop given huge success idea present paper adapt specific kind deep neural network successfully applied generation audio waveforms oord images oord text multivariate systems show kind neural network also used work generative model data retrieved wide known deterministic/stochastic data generation processes simplest complex processes damped oscillators autoregressive conditional heteroskedastic jump-diffusion models. avoiding traditional identification estimation procedures approach proposed here estimate hyperparameters convolutional neural network i.e. number convolutional layers discretization scheme dilations. hence hope demonstrate data generation processes understood simulated using statistical approach without need assuming hard-structural form imposing kind restrictions. moreover data encoded/decoded outside neural network means transforming regression task classification task assumption distribution data generating process must made. addition that demonstrate original data distribution recovered. potential applications huge. able simulate predict stochastic processes properly desired wide range sub-fields within scope finance economics asset pricing time series analysis risk analysis. accomplish goal modified existing python/tensorflow implementation wavenet oord order read synthetic time series instead audio files avoiding discussion implementation strategies focusing solely mathematical/statistical aspects usage. that simulate data generating process using properly model time series following approach terms convolutional neural network wavenet architecture consists stacking called dilated causal convolutional layers consists stacking structures figure pointed before softmax layer consists multinomial logistic classifier given stacked layers structures generalization discrete wavelet filters given fact that basically discrete wavelet transforms thought cascade linear operations; stacking features non-linear operators provide general approximator shift-invariance discussed bruna mallat cheng fernandes enabling researcher capture important nonlinearities; lution operations specified figure denotes hypothesis output pertaining specific class here worth mentioning that given classification structure observed variables stochastic process must keeping mind dilation convolutional layers stacked organized feature added previous layer features following residual scheme follows figure enabling deeper models faster convergence according four deterministic cases convolutional neural network behave similar standard ordinary differential equation solver difference equation solver. case stochastic processes chosen following processes tion function instead rectified linear activation functions popular activation funciton kind neural network fact that shown oord outperforms traditional approach. case gated activation function described cases convolutional neural network simulate stochastic process compatible original standard stochastic differential/difference equation simulator. present paper four deterministic data generation processes five stochastic process tested order verify generative capabilities wavenet architecture. chosen deterministic processes were order setup hyperparameters convolutional neural network according synthetic time series adopted forward method start layers dilations second order increased dilations order dilations original paper chosen deal eventual long-range dependencies found text-to-speech applications. addition that generated single time series samples samples used train neural network samples used back-testing purposes. whenever poor results obtained additional convolutional layer added starting dilations second order. moreover specific application -bit encoding used discretize data classes; skipchannels used; filter width equal covering hyperparameters established oord test capabilities architecture show first results deterministic processes simulations afterwards results stochastic processes simulations. visibility purposes case logistic show first observations out-ofsample. also worth mentioning that modelling deterministic processes case numpy.argsort method generate deterministic choices softmax layer output obeying magnitude probabilities. generate different realizations processes simulations process carried monte-carlo approach using numpy.random.choice method generate random choices obey given distribution returned softmax layer wavenet. figures four graphics dashed green lines represent observations used back-testing purposes; lines represent predicted outputs model; dashed black lines represent original signal used train neural network. also interesting notice that figure observation model able obtain precise out-ofsample forecasts data figure given non-linear multivariable nature system best outof-sample guess average past occurrences. said repeat experiment five proposed stochastic processes. however instead plotting time series also plot distribution structural parameters simulated series. hypothesis supported fact that structural parameters compatible original ones given fact know true data generating process parameters simulated process compatible original one. also worth noticing figures medivalues plotted true parameter values plotted blue. direct comparison true known structural parameter values estimated simulated series done. present work aimed establish simulation data generation processes avoid traditional identification estimation procedures proposing technique based convolutional neural network namely wavenet architecture estimate hyperparameters case number convolutional layers discretization scheme dilations. accomplish that simulated different deterministic stochastic processes using existing implementation wavenet architecture code adapted specific purpose conjunction statistical package. different simulations show generated data compatible original data generation process fair wide extent potential attractive tool employed several different research areas. perspective future works research suggest following experiments complex stochastic processes also given high computational cost training procedures important develop inforthree first linear models possible verify results reasonable given fact networks learnt realization stochastic process parameters deviation true values large. aäron oord sander dieleman heiga karen simonyan oriol vinyals alex graves kalchbrenner andrew senior koray kavukcuoglu. wavenet generative model audio. arxiv.v aäron oord sander dieleman lasse espeholt oriol vinyals alex graves kalchbrenner koray kavukcuoglu. conditional image generation pixelcnn decoders. arxiv.v", "year": 2018}