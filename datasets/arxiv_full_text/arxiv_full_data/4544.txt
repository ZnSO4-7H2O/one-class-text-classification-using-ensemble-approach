{"title": "Convergence of Bayesian Control Rule", "tag": ["cs.AI", "cs.LG"], "abstract": "Recently, new approaches to adaptive control have sought to reformulate the problem as a minimization of a relative entropy criterion to obtain tractable solutions. In particular, it has been shown that minimizing the expected deviation from the causal input-output dependencies of the true plant leads to a new promising stochastic control rule called the Bayesian control rule. This work proves the convergence of the Bayesian control rule under two sufficient assumptions: boundedness, which is an ergodicity condition; and consistency, which is an instantiation of the sure-thing principle.", "text": "recently approaches adaptive control sought reformulate problem minimization relative entropy criterion obtain tractable solutions. particular shown minimizing expected deviation causal input-output dependencies true plant leads promising stochastic control rule called bayesian control rule. work proves convergence bayesian control rule under suﬃcient assumptions boundedness ergodicity condition; consistency instantiation surething principle. behavior plant control signal fully known designer choose controller produces desired dynamics. instances problem include hitting target cannon known weather conditions solving maze controlling robotic manufacturing plant. however behavior plant unknown designer faces problem adaptive control. example shooting cannon lacking appropriate measurement equipment ﬁnding unknown maze designing autonomous robot martian exploration. adaptive control turns diﬃcult nonadaptive counterpart. even plant dynamics known belong particular class optimal controllers available constructing corresponding optimal adaptive controller general recently formulations adaptive control problem based minimization relative entropy criterion attracted interest control reinforcement learning community. example shown large class optimal control problems solved eﬃciently problem statement reformulated minimization deviation dynamics controlled system uncontrolled system similar approach minimizes deviation causal input/outputrelationship bayesian mixture controllers true controller obtaining explicit solution called bayesian control rule control rule particularly interesting leads stochastic controllers infer optimal controller on-line combining plant-speciﬁc controllers implicitly using uncertainty dynamics trade-oﬀ exploration versus exploitation. although bayesian control rule constitutes promising approach adaptive control currently proofs guarantee convergence desired policy. paper develop suﬃcient conditions convergence provide proof. analysis limited simple case controllers ﬁnite amount modes operation. special care taken illustrate motivation behind concepts. spectively shorthand like used simplify notation strings. symbols underlined glue together ao≤t assumed interaction controller plant proceeds cycles cycle controller issues action plant responds observation equations constitute bayesian control rule. result obtained using properties interventions using causal calculus worth point resulting controller fully treating diﬀerent controllers hypotheses bayesian model. context bayesian control rule hypotheses called operation modes. note resulting control general stochastic. representing probabilities emitting action collecting observation given respective history. similarly plant deﬁned probability distribution characterized conditional probabilities na¨ıve approach would minimize relative entropy controller respect true controller averaged possible values however syntactically incorrect. important observation made ortega braun want minimize deviation deviation causal dependencies causal dependencies figure realization divergence processes associated controller operation modes divergence processes diverge whereas stay dotted bound. hence posterior probabilities vanish. policy diagram abstracts away underlying details plant’s dynamics representing sets states transitions enclosed areas similar venn diagram. choosing particular policy plant amounts partially controlling transitions taken state space thereby choosing subset plant’s dynamics. accordingly policy represented subset state space illustrated figure simultaneous realizations divergence processes controller. intuitively speaking processes provide lower bounds accumulators surprise value measured information units. fact statistical properties depend particular policy applied; hence given divergence process diﬀerent growth rates depending policy indeed behavior divergence process might depend critically distribution actions used. example happen divergence process stays stable policy diverges another. context bayesian control rule problem aggravated time step policy apply determined stochastically. speciﬁgeneral divergence process complex virtually classes distributions interest control well beyond i.i.d. stationary processes. increased complexity jeopardize analytic tractability divergence process i.e. predictions asymptotic behavior made anymore. speciﬁcally growth rates divergence processes vary much realization realization posterior distribution operation modes vary qualitatively realizations. hence needs impose stability requirement akin ergodicity limit class possible divergence-processes class analytically tractable. light insight following property introduced. figure illustrates property. boundedness property going used construct results paper. ﬁrst important result posterior probability true operation mode bounded below. grows unboundedly core note demanding strictly positive probability execution time step guarantees controller possible ﬁnite time-intervals. following theorem shows posterior probabilities operation modes core vanish almost surely. wants identify operation modes whose posterior probabilities vanish enough characterize whose hypothesis match true hypothesis. figure illustrates problem. here three hypotheses along associated policies shown. share prediction made region diﬀer region hypothesis diﬀers everywhere others. assume true. long apply policy hypothesis make wrong predictions thus divergence process diverge expected. however evidence accumulated. apply policy long enough time controller eventually enter region hence accumulate counter-evidence long enough mean? executed short period controller risks visiting disambiguating region. unfortunately neither right policy right length period known beforehand. hence controller needs clever time-allocating strategy test even operation mode core i.e. given essentially indistinguishable m∗’s control still happen diﬀerent policies. figure shows example this. hypotheses share region diﬀer region addition operation modes policies respectively conﬁned region note operation modes core other. however policies diﬀerent. means unclear whether multiplexing policies time ever disambiguate hypotheses. undesirable could impede convergence right control law. words core policy converge m∗’s policy. intuitively property parallels well-known sure-thing principle expected utility theory following theorem shows consistency suﬃcient condition convergence right control law. operation modes ﬁnite extra assumptions suﬃcient prove convergence. ﬁrst boundedness imposes stability divergence processes partial inﬂuence policies contained within operation modes. condition regarded ergodicity assumption. second consistency requires hypothesis makes predictions another hypothesis within relevant subset dynamics hypotheses share policy. relevance formalized core operation mode. concepts proof strategies developed work appealing intuitive interpretation formal simplicity. importantly strengthen intuition potential pitfalls arise context controller design. approach presented work also considered guide possible extensions inﬁnite sets operation modes. example think partitioning continuous space operation modes essentially diﬀerent regions representative operation modes subsume neighborhoods finally convergence proofs play crucial rˆole mathematical justiﬁcation theory control. hopefully proof contribute establish relative entropy control theories solid alternative formulations problem adaptive control.", "year": 2010}