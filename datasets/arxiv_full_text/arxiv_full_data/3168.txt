{"title": "Is margin preserved after random projection?", "tag": ["cs.LG", "cs.CV", "stat.ML"], "abstract": "Random projections have been applied in many machine learning algorithms. However, whether margin is preserved after random projection is non-trivial and not well studied. In this paper we analyse margin distortion after random projection, and give the conditions of margin preservation for binary classification problems. We also extend our analysis to margin for multiclass problems, and provide theoretical bounds on multiclass margin on the projected data.", "text": "random projections applied many machine learning algorithms. however whether margin preserved random projection non-trivial well studied. paper analyse margin distortion random projection give conditions margin preservation binary classiﬁcation problems. also extend analysis margin multiclass problems provide theoretical bounds multiclass margin projected data. margin separating classes data concept many existing classiﬁcation algorithms including support vector machines boosting classiﬁers fundamentally involved identifying characterising margins described terms accuracy generality random projections attracted much attention within range ﬁelds including signal processing clustering largely fact distances preserved transformations certain circumstances random projections also applied classiﬁcation variety purposes however whether margin preserved well studied. figure counter-example illustrating problem unnormalised margin preservation. data spread along horizontal axis becomes increasingly unlikely randomly selected projection direction result linearly separable projection onto required subspace however data spreading unnormalised margin data before projection changed. means datasets ﬁxed large positive unnormalised margin within chance linearly separable zero conditions margins preserved random projection show error free margins preserved binary multiclass problems conditions met. also demonstrate results hold one-parameter multiclass classiﬁcation explains approach used vein build upon work balcan provided lower bound number dimensions required random projection given probability maintaining half original margin data. although important step balcan solve problem resulting formulation demands inﬁnite many projections order guarantee preservation error free margin. trix maps onto dimensional subspace. projected data linearly separable subspace onto projected must within grey area dashed lines figure chosen randomly uniform distribution probability projected data linearly separable angle separating dashed lines divide expand along horizontal line grey area angle shrinks shown figure fact push inﬁnitely away angle reduces keeping original margin unchanged. means exist data positive margin chance projected data linearly separable close zero. balcan studied problem margin preservation random projection binary classiﬁcation. derived formula probability margin would decreased less half particular projection. provided margin deﬁnitions below using dataset deﬁnition data distribution product normal distributed variables. approach might compute variance using chebyshev’s inequality resulting bound would loose. ﬁrst main result show angle small inner product well preserved. theorem main results underpins analysis follow. proof deferred section theorem shares similar insight magen magen showed random projections preserve volumes distances aﬃne spaces. similar result inner product obtained arriaga vempala dataset random projection still separated certain margin. proof achieved essentially showing parameter vector using angle preservation theorem union bound yields following theorem. note theorem lower bound margin random projection become negative certain values negative margin implies projected data linearly separable. since lower bound implication case separability projected data longer guaranteed high probability. lower bound positive theorem indicates margin separability binary classiﬁcation preserved high probability random projection. seem odds initial counter-example diﬀerence lies distinction deﬁnition deﬁnition counter-example pushing apart reduces probability achieving separable projection zero. however process margin deﬁned definition also shrinking zero thus diminished margin need preserved. multiclass extension counter-example shown figure shows multiclass margin always preserved random projection. binary classiﬁcation case thus introduce normalised multiclass margin. theorem shows existence parameter vector margin preserved orl) term increases logarithmically chance complement subset linearly separable projection. ysis would expect acute angle imply better angle preservation random projection thus fewer projections would required achieve reasonable separation. also expected rejection probability decreases increase. likewise inner product preserved random projection angle acute visible figure interesting empirical rejection probability angle preservation signiﬁcantly smaller inner product preservation. figure empirical rejection probability plot acute angles inner product acute angle obtuse angles inner product obtuse angle. demonstrates angle preserved better inner product random projection angle acute empirical rejection probability angles much smaller inner product conditions. neither angle inner product preserved angle obtuse figure empirical rejection probability plots normalised binary margin unnormalised binary margin normalised multiclass margin unnormalised multiclass margin. generated random gaussian matrices. used random matrices project data computed normalised margin unnormalised margin. empirical rejection probability margin original margin also computed. show plots binary multiclass cases. figure empirical rejection probability decreases number projection increases. implications svms shown results applied even case data linearly inseparable often case real classiﬁcation problems. testing method shows exhibits smaller testing error ticc handwritten digit dataset example multiclass algorithm liblinear conjecture signiﬁcantly reduced dimensionality speciﬁcally result application one-parameter method. projecting features lower dimensional space significantly reduce model capacity dimension thus consequent generalisation bounds reduced margin preservation good. provided analysis margin distortion under random projections described conditions under margins preserved given bounds margin distortion. shown particularly margin preservation closely related acute angle preservation inner product preservation. smaller acute angle better preservation angle inner product. angle well preserved margin well preserved too. this normalised margin informative unnormalised margin. also provided theoretical underpinning classiﬁcation methods random projection achieve multiclass classiﬁcation single model parameter vector. contrast previous work area shown possible provide bounds error free margin preservation without requiring inﬁnite number projections done arbitrary tolerances rather half original margin. addition achieved multiclass rather solely binary classiﬁers. worth pointing error free margin deﬁned dataset traditional margin concepts whereas balcan error allowed margin deﬁned data distribution. bounds derived conservative however based union bound data. margin primarily determined data boundary however. even small distortion data near boundary change margin signiﬁcantly whereas distortion data boundary less likely thus seems likely margin bound tightened taking account data distribution. work supported australian research council decra grant thank anders eriksson discussion counter-example maria-florina balcan avrim blum discussion error-allowed margin.", "year": 2012}