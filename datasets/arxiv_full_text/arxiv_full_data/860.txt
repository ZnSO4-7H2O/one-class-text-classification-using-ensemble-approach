{"title": "Why does Deep Learning work? - A perspective from Group Theory", "tag": ["cs.LG", "cs.NE", "stat.ML"], "abstract": "Why does Deep Learning work? What representations does it capture? How do higher-order representations emerge? We study these questions from the perspective of group theory, thereby opening a new approach towards a theory of Deep learning.  One factor behind the recent resurgence of the subject is a key algorithmic step called pre-training: first search for a good generative model for the input samples, and repeat the process one layer at a time. We show deeper implications of this simple principle, by establishing a connection with the interplay of orbits and stabilizers of group actions. Although the neural networks themselves may not form groups, we show the existence of {\\em shadow} groups whose elements serve as close approximations.  Over the shadow groups, the pre-training step, originally introduced as a mechanism to better initialize a network, becomes equivalent to a search for features with minimal orbits. Intuitively, these features are in a way the {\\em simplest}. Which explains why a deep learning network learns simple features first. Next, we show how the same principle, when repeated in the deeper layers, can capture higher order representations, and why representation complexity increases as the layers get deeper.", "text": "deep learning work? representations capture? higher-order representations emerge? study questions perspective group theory thereby opening approach towards theory deep learning. factor behind recent resurgence subject algorithmic step called pretraining ﬁrst search good generative model input samples repeat process layer time. show deeper implications simple principle establishing connection interplay orbits stabilizers group actions. although neural networks form groups show existence shadow groups whose elements serve close approximations. shadow groups pretraining step originally introduced mechanism better initialize network becomes equivalent search features minimal orbits. intuitively features simplest. explains deep learning network learns simple features ﬁrst. next show principle repeated deeper layers capture higher order representations representation complexity increases layers deeper. modern incarnation neural networks popularly known deep learning accomplished record-breaking success processing diverse kinds signals vision audio text. parallel strong interest ensued towards constructing theory paper opens group theory based approach towards theoretical understanding round training layer connected temporary output layer trained learn weights needed reproduce input step executed layer-wise starting ﬁrst hidden layer sequentially moving deeper often referred pre-training hinton salakhutdinov hinton bengio resulting layer called autoencoder figure shows schematic autoencoder. weight learnt network. subsequently presented input network produce output point output units well weight discarded. alternate characterization autoencoder unit above maps input space itself. moreover learning deﬁnition stabilizer input input signals often decomposable features autoencoder attempts succinct features inputs decomposed into. satisfying pmeans learned conﬁgurations reproduce features. figure illustrates post-training behavior. hidden units learned features then comes back input output must words learning feature equivalent searching transformation stabilizes idea stabilizers invites analogy reminiscent orbit-stabilizer relationship studied theory group actions. suppose group acts moving points around consider points reachable group action. called orbit. subset group elements leave unchanged. subset stabilizer possible deﬁne notion volume group inverse relationship volumes holds even actually subset example ﬁnite groups product |ox| |sx| order group. figure alternate ways decomposing signal simpler features. neurons could potentially learn features bottom row. almost surely simpler ones learned. gradient-descent error landscape. alternate classes features reconstruct input reconstructed signal denoted simplicity. note error function unbiased classes learning select whichever encountered earlier. inverse relationship volumes orbits stabilizers takes central role connect back many possible ways decompose signals smaller features. figure illustrates point rectangle decomposed l-shaped features straightline edges. experiments date suggest neural network likely learn edges. why? answer this imagine space autoencoders form group. batch learning iterations stops whenever stabilizer found. roughly speaking search markov chain bigger stabilizer earlier hit. group structure implies stabilizer corresponds small orbit. intuition suggests simpler feature smaller orbit. example mathematically orbit element action group deﬁned line-segment generates many fewer possible shapes linear deformations ﬂower-like shape. autoencoder learn simpler features ﬁrst falls line experiments intuition naturally extends many-layer scenario. hidden layer ﬁnding feature stabilizer. beyond ﬁrst level inputs longer inhabit space training samples. simple feature space actually corresponds complex shape space input samples. process repeats number layers increases. effect layer learns edge-like features respect previous layer locally simple representations obtain learned higher-order representation. contributions main contribution work formal substantiation intuition connecting autoencoders stabilizers. first build case idea random search process large stabilizers construct evidential examples neural networks incorporate highly nonlinear transformations analogy group transformations directly actual networks. however turns deﬁne construct shadow groups approximate actual transformation network reason instead. finally examine happens compose layers multilayer network. analysis highlights critical role sigmoid show enables emergence higher-order representations within framework theory random walks parameter space stabilizer volumes learning process resembles random walk accurately markov-chain-monte-carlo type sampling. already known e.g.see bengio newly arriving training sample prior correlation current state. order computing partial derivatives also randomized. effectively then subsequent minimization step takes almost random direction guided gradient towards minimal point stabilizes signal. figure shows schematically. consider current network conﬁguration neighbourhood radius input signal suppose possible decompositions features denote reconstructed signal note features also signals reconstruction error usually given error term distance fi). collection really enables good reconstruction input i.e.i stabilizer input deﬁnition. competing feature-sets gradient descent eventually move conﬁguration stabilizers. probability network discovers stabilizers signals neighbourhood radius would denote stabilizer signal volume measure space transformation. roughly exposing structure features stabilizers orbits parameter space actually ﬁnite group could following theorem. orbit-stabilizer theorem group acting stabilizer subgroup element denote corresponding orbit f|.|s |g|. figure stabilizer subgroups gl). stabilizer subgroup dimension isomorphic inﬁnite cylinder sans real line. circle ellipse hand stabilizer subgroups dimensional. fact suitable measure stabilizer higher dimension larger volume therefore orbit smaller volume. assuming group actions substantiated later explains emergence simple signal blocks learned features ﬁrst layer. provide evidential examples analytically computing dimensions. simple illustrative examples emergence gabor-like filters consider action group invertible linear transforms various shapes. figure illustrates three example cases estimating stabilizer sizes. edge edge stabilizer must direction edge i.e.it must eigenvector direction eigenvalue second eigenvector direction giving rise isomorphic sans direction ﬁrst eigenvector turn isomorphic unit circle punctured point. note isomorphism refers topological isomorphism between sets. second eigenvalue anything considering entire circle already accounts every pair effective isomorphic positive half real-axis only. summary stabilizer subgroup r+\\r+. space looks like cylinder extended inﬁnitely direction importantly actually non-compact set. dimension corresponding orbit revealed equation circle circle stabilized rigid rotations plane well reﬂections possible lines centre. together form orthogonal group theory groups known ellipse stabilizer ellipse isomorphic circle. ellipse deformed circle transformed transformed back. isomorphism summary random walk inside likelihood hitting edge-stabilizer high compared shapes circle ellipse compact also dimension less. ﬁrst layer deep learning network trying learn images almost always discovers gabor-ﬁlter like shapes. essentially edges different orientation inside images. stabilizer view background perhaps surprising all. reasoning symmetry groups convenient. shall show possible continue reasoning deep learning network even employs non-linearity. ﬁrst discuss notion intrinsic space. consider binary image; it’s typically represented vector simply intrinsically dimensional object. resolution determines change that’s intrinsic image itself. similarly gray-scale image three intrinsic dimensions ﬁrst accounts euclidean plane third gray-scales. signals similar intrinsic spaces. start deﬁnitions. input space original space signal inhabits. signals interest compactly supported bounded real functions vector space function space denoted {φ|φ deﬁne intrinsic space every subset neural network maps point another point inside induces deformation subsets. example. binary image function naturally corresponds subset therefore intrinsic space plane itself. implicit section similarly monochrome gray-scale image intrinsic space cases input space figure subset intrinsic space called ﬁgure i.e. note point actually ﬁgure moduli space figures imagine space parametrizes various ﬁgures denote call moduli space ﬁgures. point corresponds ﬁgure group acts consistently extends i.e. another ﬁgure symmetry-group intrinsic space intrinsic space collection invertible mapping event ﬁnite permutation group. vector space linear invertible transformations. sigmoid function refer standard sigmoid function denoted convolution view neuron start conventional view neuron’s operation. vector representation input given weights neuron performs following function equivalently neuron performs convolution input signal first weights transform input signal coefﬁcient fourier-like space. deconvolution brings signal back original domain. outgoing weights deﬁned arguments indicate domain frequency space indexed range coefﬁcients space indexed dummy output layer auto-encoder space essentially identical input layer. deconvolution already observed point ﬁgure intrinsic space hence naturally induces following space itself space deformations intrinsic space i.e. {γ|γ although deforms ﬁgure another ﬁgure action necessarily extend uniformly entire deﬁnition trouble realizing consistent follows. restriction needs consistent ways; i.e. restriction maps agree that’s guaranteed randomly selected naturally extend translate questions asked questions intrinsic space dimension hope easier analyses. particular examine stabilizer subgroups tractable. examine ﬁgures effectively captured group actions sufﬁces consider action input time. eliminates conﬂicts arising different inputs. i.e.the action speciﬁc still incomplete respect automorphism extend action entire consistently? turns yes. theorem neural network input network. action consistely extended automorphism i.e.γ proof given appendix. couple notes. first input appears parameter automorphism alone cannot deﬁne consistent self-map second correspondence necessarily unique. there’s family automorphisms correspond action we’re interested existence least them. shadow stabilizer-subgroups search group actions approximate automorphisms established. since group action exactly neural network closely mimics latter refer groups shadow groups. existence underlying group action asserts corresponding stabilizers ﬁgure stabilizer subgroup lets argue learnt ﬁgures actually correspond minimal orbits high probability thus simplest possible. following theorem asserts fact. theorem neural network working ﬁgure corresponding self-map fact homeo homeomorphism group theorem shows although neural networks exactly deﬁne group approximated well group actions homeomorphism group intrinsic space. further inspect action locally i.e.in small vicinity point. next result shows locally approximated elements much simpler group study; fact results section really light action group dimensional case. theorem guarantees underlying group action. large stabilizers mapped small stabilizers vice versa? next theorem asserts bottom-up correspondence well every group symmetry intrinsic space counter-part mapping onto itself. theorem intrinsic space group element stabilizes corresponding element stabilizes moreover summary argument showed theorem neural network action counterpart group homeomorphisms intrinsic space. presence shadow group lets carry orbit/stabilizer principle discussed section actual neural network transforms. asserts simple features ones learned ﬁrst. analyse features look like examine locally lens even simpler group. theorems collectively establish this. theorem shows every neural network element there’s nearby group element. large stabilizer then corresponding stabilizer subgroup ought large else impossible nearby group element everywhere. also note doesn’t require strict one-to-one correspondence; existence group element enough assert this. theorem pushes argument reverse imagine sufﬁciently discrete version coarse-grained picture small ε-neighbourhood element represented corresponding neural network furthermore another element outside neighbourhood another different network. implies large volume cannot mapped small volume general hence true stabilizer volumes well. discuss orbit/stabilizer interplay extends multiple layers. root lies principle layer-wise pre-training identity function. particular show succinct step algorithmic principle quite powerful. principle stays across layers; hence every layer learns simplest possible objects input space. simple objects deeper layer represent complex object input space. understand precisely ﬁrst examine critical role sigmoid function. denote space real functions space imagine space inﬁnite number neurons indexed weight-functions note also viewed element plus family {τw} induces mapping real functions i.e. sigmoid thought composed steps. turning input number zero one. then cases automatic thresholding happens creating binarization denote ﬁnal step reduces output element ﬁgure space three steps applying viewed construction recursive layers envision neural building representations moduli spaces moduli spaces hierarchically another. example layer- learning layer- neuron actually learns ﬁgure intrinsic space collective output layer thought ﬁgure second order ﬁgures become inputs layer- neurons collectively learning minimal-orbit ﬁgure space second-order ﬁgures learning higher order representations let’s recap. layer neurons collectively learn ﬁgures intrinsic space. true depth learnt ﬁgures correspond largest stabilizer subgroups. figure deep network constructs higher order moduli spaces. learns ﬁgures increasingly smaller symmetry groups; corresponds increasing complexity words ﬁgures enjoy highest possible symmetry. simple examples section revealed emerging ﬁgures edges. layer arbitrary depth working different space corresponding ﬁgures clearly physical edges. nevertheless we’ll refer generalized edges. figure captures generic multi-layer setting. let’s consider neuron-layer i-th level let’s denote embedding space features learns i.e. layer learns ﬁgures space ﬁgure refereed generalized edge schematically shown geodesic segment picture. thinking recursively space clearly moduli-space ﬁgures space point corresponds generalized edge mi−. whole segment therefore corresponds collection generalized edges mi−; collection general clearly lesser symmetry generalized edge itself. words simple object actually corresponds much complex object mi−. moduli-spaces determined underlying input-space nature training. precise calculations them deﬁning space automorphisms computing volumes corresponding stabilizer sets difﬁcult unaware work context. however following simple example illustrates idea quite clearly. examples higher order representation consider intrinsic space edge plane line segment moduli-space edges therefore entire -dimensional real euclidean space sans origin r/{}. figure captures this. point space corresponds edge plane generalized-edge r/{} standard line-segment -dimensional euclidean space corresponds collection edges real plane. depending orientation generalized edge upstairs obtain many different shapes downstairs. trapezoid ﬁgure leftmost column ﬁgure shows schematic trapezoid. obtained points correspond non-intersecting line-segments triangle middle column shows example starting point line segments connecting generalized edge points line parallel coordinate axes middle point maps line-segment that’s intermediate starting lines stabilizing upstairs effectively stabilizes triangular area plane. butterﬂy third column shows another pattern drawn edges intersect other. plotting intermediate points generalized edge plane lines butterﬂylike area swept out. again stabilizing generalized edge effectively stabilizes butterﬂy plane would otherwise take long time found stabilized ﬁrst layer. general constructions also imagine even generic shapes learnt way. consider polygon thought collection triangles composing triangle would correspond generalized edge layer-. result whole polygon effectively learnt network hidden layers. nutshell mechanism ﬁnding maximal stabilizers moduli-space ﬁgures works uniformly across layers. layer ﬁgures largest stabilizers learnt candidate features. ﬁgures correspond complex shapes space learnt earlier layers. adding deeper layers becomes possible make network learn increasingly complex objects originial input-space. related work starting inﬂuence paper steps described hinton salakhutdinov authors ﬁrst introduced idea layer-by-layer pre-training autoencoders. principles restricted boltzmann machines applied image recognition later work showed perhaps ﬁrst time deep network builds increasingly complex representations across depth. since then several variants autoencoders well rbms taken center stage deep learning research. bengio bengio provide comprehensive coverage almost every aspect techniques. although chose analyse auto-encoders paper believe principle extend rbms well especially context recent work kamyshanska memisevic reveals seemingly equivalence autoencoders rbms. deﬁne energy function autoencoders corresponds free energy rbm. also point energy function imposes regularization space. hypothesis implicit regularization mechanism also made earlier erhan although haven’t investigated direct connection symmetry-stabilization regularization evidences connected subtle ways recently anselmi proposed theory visual-cortex that’s heavily inspired principles group actions; although direct connection layer-wise pre-training context. bouvrie studied invariance properties layered network group theoretic framework showed derive precise conditions must order achieve invariance close work terms machineries used unsupervised learning algorithm learns representations. mehta schwab recently showed intriguing connection renormalization group deep-learning. constructed explicit mapping renormalization group block-spin ising model architecture. face result complementary ours albeit slightly different settings. renormalization process coarse-graining system ﬁrst throwing away small details model examining system simpliﬁed model sense orbit-stabilizer principle re-normalizable theory allows exact coarse-graining operation every layer namely keeping minimal orbit shapes passing parameters next layer theory remains unchanged every scale. generally good many recognition tasks networks shown fail surprising ways. szegedy showed mapping network learns could sudden discontinuities. example sometimes misclassify image derived applying tiny perturbation image actually classiﬁes correctly. even reverse also reported here network tested grossly perturbed versions already learnt images perturbed extent humans cannot recognize original still classiﬁed originals. szegedy made related observation random linear combination high-level units deep network also serve good representations. concluded space rather individual units contain semantic information high layers network. don’t speciﬁc conﬂicts observations orbit-stabilizer principle view possible explanations phenomena clear scope future work. conclusions future work nutshell paper builds theoretical framework unsupervised primarily inspired principle ﬁnding generative model input samples ﬁrst. framework based orbit-stabilizer interplay group actions. assumed layer-wise pre-training since conceptually clean theory even many layers learnt simultaneously orbit-stabilizer phenomena still apply. also analysed higher order representations emerge networks deeper. today expanded well beyond principles pand several factors size datasets increased computational power improved optimization methods domain speciﬁc tuning contribute success. clearly theory all-encompassing. particular large enough labeled datasets available training fullly supervised mode yielded great results. orbit-stabilizer principle cannot readily extended supervised case; absence self-map hard establish underlying group action. believe hope principled study representations form eventually single theory. section involves elementary concepts different areas mathematics. functional analysis bollob´as. elementary ideas groups groups representation theory recommend artin; fulton harris. relevant ideas topology looked munkres hatcher. lemma group invertible square matrices dense square matrices. proof well known result provide proof sake completeness. matrix square necessarily invertible. show non-singular matrix nearby. this consider arbitrary non-singular matrix i.e.det consider following polynomial parametrized real number since ﬁnite degree polynomial certainly identically zero vanish ﬁnite number points. even must arbitrarily close corresponding matrix arbitrarily close non-singular identically vanish. lemma action neural network approximated network that’s completely invertible. proof three layer neural network represented sigmoid function linear transforms. already invertible need show existence invertible approximations linear components. rm×n matrix. matrix dimension rn×m. consider ﬁrst case however lifted rm×m transform additional columns zeros. let’s call then lemma possible obtain square invertible figure homotopy extension intrinsic space imaginary curve diffeomorphisms induces family continuous maps homotopy extended entire space homotopy extension theorem. transform serves good approximation hence obtain similar invertible approximation thus composite required approximation that’s completely invertible. case easier; follows logic without need adding columns. lemma action neural network ﬁgure intrinsic space. action induces continuous mapping sets proof let’s consider inﬁnitely small subset f\\εa. described let’s imagine inﬁnitesimal deformation ﬁgure continuously deforming since change inﬁnitesimal continuous output let’s call differs inﬁnitesimally. means there’s give rise must true subset lemma allows assume invertible mapping change input detectable output. thus induces mapping inﬁnitesimal sets split input ﬁgure inﬁnitesimal parts thereby obtain set-correspondence input output. proof theorem assume neural network implements differentiable input output. means diff) i.e.the diffeomorphisms admits smooth structure moreover parametrized neural-network parameters connected well makes sense think curve space. let’s denote identity transform space consider curve diff) lemma deﬁnes continuous words induces partial homotopy mathematically words curve induces continuous family deformations refer ﬁgure visual representation correspondence. language topology family deformations known homotopy. denote homotopy easy check pair satisﬁes homotopy extension property. addition exists initial mapping nothing identity mapping. well known homotopy extension theorem asserts possible lift proof theorem note lemma already guarantees invertible mapping beteen means context theorem inverse homotopy extended opposite direction. means actually homeomorphism i.e.a continuous invertible mapping itself. homeo group deﬁnition. proof theorem neural network action consideration. theorem corresponding homeomorphism operator acting although necessarily differentiable everywhere operator differentiable means locally approximated fr´echet derivative near however ﬁnite dimension nothing jacobian transformation represented ﬁnite dimensional matrix. linear approximation deformation since homeomorphism inverse function theorem exists. therefore really represents element easy deﬁned stabilizes however possibility although ﬁgure well-deﬁned function avoid pathological case make assumption functions considerations bounded. means exists upper bound every consideration bounded supremum norm f|supp deﬁne auxiliary function follows. always construct continuous approximation approximation. ready deﬁne neural network essentially collection mappings ﬁgures deﬁned follows whenever second part theorem holds observe since essentially reﬂect group actions intrinsic space action really deﬁned point-wise. words ﬁgures following restriction holds. remain valid functions ﬁgures consider u∩u. however collection mapping uniquely deﬁnes action another group element agrees every ﬁgure agreement translated point-wise equality asserting note thresholding function section primarily based discussion around sigmoid function thought mechanism binarization thereby produces ﬁgures moduli space. moduli space becomes intrinsic space next layer. however theory extends types thresholding functions well intrinsic spaces would vary based nature thresholding. example using linear rectiﬁcation unit would mapping space elements functions taking values range intrinsic space next level output thought ﬁgure intrinsic space allowing rest theory carry over. anselmi fabio leibo joel rosasco lorenzo mutch tacchetti andrea poggio tomaso. unsupervised learning invariant representations hierarchical architectures. corr abs/. http//arxiv.org/abs/.. cardy scaling renormalization statistical physics. cambridge lecture notes physics. cambridge university press isbn http//books.google.com/ books?id=wtsfjyac. erhan dumitru bengio yoshua courville aaron manzagol pierre-antoine vincent pascal bengio samy. unsupervised pre-training help deep learning? journal machine learning research honglak grosse roger ranganath rajesh andrew convolutional deep belief networks scalable unsupervised learning hierarchical representations. proceedings annual international conference machine learning szegedy christian zaremba wojciech sutskever ilya bruna joan erhan dumitru goodfellow fergus rob. intriguing properties neural networks. arxiv preprint arxiv.", "year": 2014}