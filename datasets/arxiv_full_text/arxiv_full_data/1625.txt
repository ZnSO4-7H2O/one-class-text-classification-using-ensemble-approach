{"title": "UTCNN: a Deep Learning Model of Stance Classificationon on Social Media  Text", "tag": ["cs.CL", "cs.AI", "cs.LG"], "abstract": "Most neural network models for document classification on social media focus on text infor-mation to the neglect of other information on these platforms. In this paper, we classify post stance on social media channels and develop UTCNN, a neural network model that incorporates user tastes, topic tastes, and user comments on posts. UTCNN not only works on social media texts, but also analyzes texts in forums and message boards. Experiments performed on Chinese Facebook data and English online debate forum data show that UTCNN achieves a 0.755 macro-average f-score for supportive, neutral, and unsupportive stance classes on Facebook data, which is significantly better than models in which either user, topic, or comment information is withheld. This model design greatly mitigates the lack of data for the minor class without the use of oversampling. In addition, UTCNN yields a 0.842 accuracy on English online debate forum data, which also significantly outperforms results from previous work as well as other deep learning models, showing that UTCNN performs well regardless of language or platform.", "text": "neural network models document classiﬁcation social media focus text information neglect information platforms. paper classify post stance social media channels develop utcnn neural network model incorporates user tastes topic tastes user comments posts. utcnn works social media texts also analyzes texts forums message boards. experiments performed chinese facebook data english online debate forum data show utcnn achieves macroaverage f-score supportive neutral unsupportive stance classes facebook data signiﬁcantly better models either user topic comment information withheld. model design greatly mitigates lack data minor class without oversampling. addition utcnn yields accuracy english online debate forum data also signiﬁcantly outperforms results previous work well deep learning models showing utcnn performs well regardless language platform. introduction deep neural networks widely used text classiﬁcation achieved promising results focus content information models convolutional neural networks recursive neural networks however user-generated posts social media like facebook twitter information ignored. social media platforms user either author post reader expresses comments post. paper classify posts taking account post authorship likes topics comments. particular users likes hold strong potential text mining. example given posts related speciﬁc topic user’s likes dislikes provide clues stance labeling. user point view users positive attitudes toward issue leave positive comments posts praise even post’s content; post point view positive posts attract users hold positive stances. also investigate inﬂuence topics different topics associated different stance labeling tendencies word usage. example discuss women’s rights unwanted babies topic abortion criticize medicine usage crime topic marijuana even posts speciﬁc topic like nuclear power variety arguments raised green energy radiation pollution comments treat additional text information. arguments comments commenters provide hints post’s content facilitate stance classiﬁcation. paper propose user-topic-comment neural network deep learning model utilizes user topic comment information. attempt learn user topic representations encode user interactions topic inﬂuences enhance text classiﬁcation also incorporate comment information. evaluate model post stance classiﬁcation task forumstyle social media platforms. contributions paper follows propose utcnn neural network text modern social media channels well legacy social media forums message boards anywhere reveals users tastes well replies posts. classifying social media post stances leverage users including authors likers. user embeddings generated even users never posted anything. incorporate topic model automatically assign topics post single topic dataset. show overall proposed method achieves highest performance instances information extracted whether users topics comments still contributions. extra-linguistic features stance classiﬁcation paper text well features complement deep learning model. stance classiﬁcation domain previous work showed text features limited suggesting adding extra-linguistic constraints could improve performance example hasan well thomas require posts written author stance addition constraint yields accuracy improvements models datasets. hasan later added user-interaction constraints ideology constraints former models relationship among posts sequence replies latter models inter-topic relationships e.g. users oppose abortion could conservative thus likely oppose rights. work focusing online forum text since posts linked user replies sequential labeling methods used model relationships posts. example hasan hidden markov models model dependent relationships preceding post burfoot iterative classiﬁcation repeatedly generate estimates based current state knowledge sridhar probabilistic soft logic model reply links collaborative ﬁltering facebook dataset study comments instead reply links. however ultimate goal paper predicting comment stance post stance treat comments extra information predicting post stance. deep learning extra-linguistic features recent years neural network models applied document sentiment classiﬁcation text features used deep networks capture text semantics sentiment. example dong adaptive layer recursive neural network target-dependent twitter sentiment analysis targets topics windows taylor swift recursive neural tensor networks utilize sentence parse trees capture sentence-level sentiment movie reviews mikolov predict sentiment using paragraph vectors model paragraph continuous representation show performance thus improved delicate text models. others suggested using extra-linguistic features improve deep learning model. userword composition vector model inspired possibility strength sentiment words user-speciﬁc; capture user embeddings model. upnn later extension product-word composition product embeddings arguing products also show different tendencies rated reviewed addition user information yielded improvements accuracy compared abovementioned rntn paragraph vector methods. also seek inject user information neural network model. comparison research tang sentiment classiﬁcation product reviews difference two-fold. first take account multiple users post whereas user involved review. second comment information provide features post stance classiﬁcation. none factors considered previously deep learning model text stance classiﬁcation. therefore figure document composition convolutional neural network three convolutional ﬁlters usertopic-dependent semantic transformations. respectively word embedding word word embedding word transformation user topic matrix embeddings user topic section ﬁrst describe cnn-based document composition captures usertopicdependent document-level semantic representation word representations. show comment information construct user-topic-comment neural network usertopic-dependent document composition shown figure general semantic transformations document composition given document engaged user topic composite words word associated word embedding vector dimension. word embedding apply operations shown equation rdu×d models user reading preference certain semantics rdt×d models topic semantics; dimensions transformed user topic embeddings respectively. model semantically user prefers read and/or write model semantics topic. operation transforms global representation user-dependent representation. likewise operation transforms topicdependent representation. operations user-dependent topic-dependent word vectors concatenated form usertopic-dependent word vector transformed word embeddings used input. apply three conm+lcf−] volutional layers concatenated transformed word embeddings rd·lcf figure utcnn model. assuming post author likers topics word embedding word document; word embedding word comments; moderator matrix vector embedding moderator topic matrix vector embedding topic commenter matrix vector embedding commenter simplicity explicitly plot topic vector embedding part comments include maximum pooling layer documents. index words; non-linear activation function rlen×d·lcf convolutional ﬁlter input length output length window size convolutional operation; output bias convolution layer respectively. experiments three window sizes three convolution layers three encoding unigram bigram trigram semantics accordingly. convolutional layer maximum pooling layer among convolutional outputs obtain unigram bigram trigram n-gram representations. succeeded average pooling layer element-wise average three maximized convolution outputs. figure illustrates utcnn model. user interact given post ﬁrst maximum pooling layer user matrix embedding layer user vector embedding layer form moderator matrix embedding moderator vector embedding moderator respectively used semantic transformation document composition process mentioned previous section. term moderator denote pseudo user provides overall semantic/sentiment engaged users document. embedding models moderator stance preference pattern revealed user stance whether user willing show preference whether user likes show impartiality neutral statements reasonable arguments wants show strong support stance. ideally latent user stance modeled user. likewise topic information maximum pooling layer added topic matrix embedding layer topic vector embedding layer form joint topic matrix embedding joint topic vector embedding topic respectively models semantic transformation topic users models topic stance tendency. latent topic stance also modeled topic. comments view short documents authors without likers comments. therefore apply document composition comments although users commenters noticed word embeddings word posts comments same transformed document composition process shown figure might become different different engaged users. output comment representation together commenter vector embedding topic vector embedding concatenated maximum pooling layer added select important feature comments. instead requiring comment stance agree post utcnn simply extracts important features comment contents; could helpful whether show obvious agreement disagreement. therefore combining comment information here maximum pooling layer appropriate pooling merging layers. indeed believe reason utcnn’s performance gains. finally pooled comment representation together user vector embedding topic vector embedding document representation fully connected network softmax applied yield ﬁnal stance label prediction post. start experimental dataset describe training process well implementation baselines. also implement several variations reveal effects features authors likers comment commenters. results section compare model related work. dataset tested proposed utcnn different datasets fbfans createdebate. fbfans privately-owned single-topic chinese unbalanced social media dataset createdebate public multiple-topic english balanced forum dataset. results using datasets show applicability superiority different topics languages data distributions platforms. fbfans dataset contains data anti-nuclear-power chinese facebook groups september august including posts author liker ids. total authors likers commenters unique users. annotators asked take account post content label stance posts whole dataset supportive neutral unsupportive sup/uns posts support anti-reconstruction; posts evincing neutral standpoint topic irrelevant. agreement annotators indicating high agreement. specifically cohen’s kappa labeling labeling posts inconsistent labels ﬁltered development testing sets randomly selected left. posts development testing sets involved least user appeared training set. number posts stance shown left-hand side table twenty percent posts labeled stance number supportive posts much larger unsupportive ones thus highly skewed data complicates stance classiﬁcation. average users involved post. maximum minimum comments average comments post. maximum minimum zero. test whether assumption paper posts attract users hold stance like reliable examine likes authors different stances. posts fbfans dataset used analysis. calculate like statistics distinct author posts. numbers authors stances largely imbalanced numbers normalized number users stance. table shows results. posts stances attract users stance. neutral posts also attract supportive neutral users like observe supportive posts neutral posts attract even neutral likers. results suggest users prefer posts stance least posts obvious stance might cause annoyance reading hence support user modeling approach. createdebate dataset collected english online debate forum discussing four topics abortion rights obama marijuana posts annotated replies posts dataset also labeled stance hence data format posts. labeling results shown right-hand side table observe dataset balanced fbfans dataset. addition unique users dataset. compare hasan ng’s work conducted ﬁve-fold cross-validation present annotation results average number folds fbfans dataset integrated functions createdebate dataset; thus model utilize linguistic extra-linguistic features. createdebate dataset hand like comment features available still implemented model using content author topic information. utcnn training process cross-entropy used loss function adagrad optimizer. fbfans dataset learned -dimensional word embeddings whole dataset using glove capture word semantics; createdebate dataset used publicly available english -dimensional word embeddings pre-trained also using glove. word embeddings ﬁxed training process. learning rate user topic embeddings randomly initialized range matrix embeddings users topics sized vector embeddings users topics length applied topic model fbfans dataset determine latent topics build topic embeddings general known topic nuclear power plants. learned latent topics assigned three topics post. createdebate dataset constitutes four topics topic labels posts used directly without additionally applying lda. table performance post stance classiﬁcation fbfans dataset. *utcnn results statistically signiﬁcant respect methods except utcnn shared user embedding. average precision recall three class. adopted macroaverage f-score evaluation metric overall performance experimental dataset severely imbalanced common contentious issues; stance classiﬁcation content minor-class posts usually important applications. createdebate dataset accuracy adopted evaluation metric compare results related work baselines model following baselines unigram bigram trigram features standard rather strong classiﬁer text features; average word embedding document represented continuous representation averaging embeddings composite words; average transformed word embeddings equation document represented continuous representation averaging transformed embeddings composite words; mature deep learning models text classiﬁcation recurrent convolutional neural networks hyperparameters based work; deep learning models comment information; utcnn without user information representing pure-text model user matrix user embeddings user; utcnn without model representing utcnn works single-topic dataset; utcnn without comments model predicts stance label given user topic information. models trained training parameters well kernel selections ﬁne-tuned development set. also adopt oversampling svms rcnn fbfans dataset highly imbalanced. results fbfans dataset table show results utcnn baselines fbfans dataset. majority yields good performance since fbfans highly biased neutral class. models perform well perform poorly showing content information insufﬁcient predict stance labels especially minor class. transformed word embedding feature achieve comparable performance n-gram feature. however much fewer feature dimension transformed word embedding makes word embeddings efﬁcient choice modeling large scale social media dataset. rcnn models perform slightly better models still content information insufﬁcient achieve good performance posts. adding comment information models since commenters always hold stance author simply adding comments post contents together merely adds noise model. among utcnn variations user information important followed topic comment information. utcnn without user information shows results similar svms well detects uns. best f-scores among methods show enough training data content-based models perform well; time lack user information results clues minor-class posts either predict stance directly link users posts improved performance. improvement adding user information suggests user information especially useful dataset highly imbalanced. models consider user information predict minority class successfully. uctnn without topic information works well achieves lower performance full utcnn model. performance gain brought shows although satisfactory single topic datasets adding latent topics still beneﬁts performance even discussing topic different arguments supporting evidence. lastly improvement adding comment information achieves comparable performance utcnn without topic information shows comments also beneﬁt performance. platforms user pixelated otherwise hidden adding comments text model still improves performance. integration user content comment information full utcnn produces highest f-scores stances among models predict class highest macro-average f-score overall. shows ability balance biased dataset supports claim utcnn successfully bridges content user topic comment information stance classiﬁcation social media text. another merit utcnn require balanced training data. supported outperforming models though oversampling technique applied utcnn related experiments shown paper. thus conclude user information provides strong clues still rich even minority class. also investigate semantic difference user acts author/liker commenter. evaluated variation embeddings user forced identical setting yielded improvement model without comments statistically signiﬁcant. however separating authors/likers commenters embeddings achieved much greater improvements attribute result tendency users different wording different roles observed user acting author attempts support argument nuclear power using improvements solar power; acting commenter though interacts post contents criticizing past politicians supported nuclear power arguing proposed evacuation plan case nuclear accident ridiculous. based ﬁnding ﬁnal utcnn setting train user matrix embeddings user author/liker role commenter role. table shows results utcnn baselines implemented fbfans datset related work createdebate dataset. adopt oversampling models createdebate dataset almost balanced. previous work integer linear programming linearchain conditional random ﬁelds proposed integrate text features author ideology user-interaction constraints text features unigram bigram pos-dependencies; author constraint tends require posts author topic hold stance; ideology constraint aims capture inferences topics author; user-interaction constraint models relationships among posts user interactions replies n-gram average word embedding feature performs similar majority. however transformed word embedding achieves superior results. shows learned user topic embeddings really capture user topic semantics. ﬁnding obvious fbfans dataset might unfavorable data skewness svm. rcnn perform slightly better svms found table fbfans. compared methods utcnn user embeddings encode author user-interaction constraints ideology constraint modeled topic embeddings text features modeled cnn. signiﬁcant improvement achieved utcnn suggests latent representations effective overt model constraints. model jointly labels author post stance using probabilistic soft logic considering text features reply links authors posts hasan ng’s work. table reports result best setting represents full joint stance/disagreement collective model posts hence relevant utcnn. contrast model utcnn user embeddings represent relationships authors utcnn models utilize link information posts. though model advantage able jointly label stances authors posts performance posts lower models. utcnn signiﬁcantly outperforms models posts potential predict user stances generated user embeddings. createdebate dataset also evaluated performance using topic embeddings user embeddings; replies dataset viewed posts setting without comment embeddings available. table shows ﬁndings table improvement accuracy demonstrates user information vital. ﬁnding also supports results related work user constraints useful yield improvement accuracy considering topic information yields improvement suggesting knowing subject debates provides useful information. table together table show utcnn achieves promising performance regardless topic language data distribution platform. proposed utcnn neural network model incorporates user topic content comment information stance classiﬁcation social media texts. utcnn learns user embeddings users minimum active degree i.e. post like. topic information obtained topic model pre-deﬁned labels improves utcnn model. addition comment information provides additional clues stance classiﬁcation. shown utcnn achieves promising balanced results. future plan explore effectiveness utcnn user embeddings author stance classiﬁcation. clinton burfoot steven bird timothy baldwin. collective classiﬁcation congressional ﬂoor-debate transcripts. proceedings annual meeting association computational linguistics human language technologies-volume pages association computational linguistics. dong furu chuanqi duyu tang ming zhou adaptive recursive neural network target-dependent twitter sentiment classiﬁcation. proceedings annual meeting association computational linguistics pages association computational linguistics. dong furu ming zhou adaptive multi-compositionality recursive neural models applications sentiment analysis. proceedings conference association advancement artiﬁcial intelligence. aaai. kazi saidul hasan vincent extra-linguistic constraints stance recognition ideological debates. proceedings sixth international joint conference natural language processing pages association computational linguistics. kazi saidul hasan vincent stance classiﬁcation ideological debates data models features constraints. proceedings sixth international joint conference natural language processing pages association computational linguistics. johnson tong zhang. effective word order text categorization convolutional neural networks. proceedings conference north american chapter association computational linguistics. yoon kim. convolutional neural networks sentence classiﬁcation. proceedings conference empirical methods natural language processing pages association computational linguistics. siwei liheng kang zhao. recurrent convolutional neural networks text classiﬁcation. proceedings conference association advancement artiﬁcial intelligence pages aaai. jeffrey pennington richard socher christopher manning. glove global vectors word representation. proceedings conference empirical methods natural language processing pages association computational linguistics. yafeng zhang meishan zhang donghong context-sensitive twitter sentiment classiﬁcation using neural network. proceedings conference association advancement artiﬁcial intelligence. aaai. richard socher brody huval christopher manning andrew semantic compositionality recursive matrix-vector spaces. proceedings joint conference empirical methods natural language processing computational natural language learning pages association computational linguistics. richard socher alex perelygin jean jason chuang christopher manning andrew christopher potts. recursive deep models semantic compositionality sentiment treebank. proceedings conference empirical methods natural language processing volume page association computational linguistics. dhanya sridhar james foulds bert huang lise getoor marilyn walker. joint models disagreement stance online debate. proceedings annual meeting association computational linguistics. association computational linguistics. duyu tang bing ting liu. learning semantic representations users products document level sentiment classiﬁcation. proceedings annual meeting association computational linguistics international joint conference natural language processing pages association computational linguistics. duyu tang bing ting yuekui yang. user modeling neural network review rating prediction. proceedings twenty-fourth international joint conference artiﬁcial intelligence pages matt thomas pang lillian lee. vote determining support opposition congressional ﬂoor-debate transcripts. proceedings conference empirical methods natural language processing pages association computational linguistics. marilyn walker pranav anand robert abbott ricky grant. stance classiﬁcation using dialogic properties persuasion. proceedings conference north american chapter association computational linguistics human language technologies pages association computational linguistics.", "year": 2016}