{"title": "Using Simulation and Domain Adaptation to Improve Efficiency of Deep  Robotic Grasping", "tag": ["cs.LG", "cs.AI", "cs.CV", "cs.RO"], "abstract": "Instrumenting and collecting annotated visual grasping datasets to train modern machine learning algorithms can be extremely time-consuming and expensive. An appealing alternative is to use off-the-shelf simulators to render synthetic data for which ground-truth annotations are generated automatically. Unfortunately, models trained purely on simulated data often fail to generalize to the real world. We study how randomized simulated environments and domain adaptation methods can be extended to train a grasping system to grasp novel objects from raw monocular RGB images. We extensively evaluate our approaches with a total of more than 25,000 physical test grasps, studying a range of simulation conditions and domain adaptation methods, including a novel extension of pixel-level domain adaptation that we term the GraspGAN. We show that, by using synthetic data and domain adaptation, we are able to reduce the number of real-world samples needed to achieve a given level of performance by up to 50 times, using only randomly generated simulated objects. We also show that by using only unlabeled real-world data and our GraspGAN methodology, we obtain real-world grasping performance without any real-world labels that is similar to that achieved with 939,777 labeled real-world samples.", "text": "fig. bridging reality proposed pixel-level domain adaptation model takes input synthetic images produced simulator produces adapted images look similar real-world ones produced camera physical robot’s shoulder. train deep vision-based grasping network adapted real images reﬁne feature-level adaptation. points might collected autonomously cases considerable cost time money recent studies suggest performance grasping systems might strongly inﬂuenced amount data available natural avenue overcome data requirements look back success analytic model-based grasping methods incorporate prior knowledge physics geometry. incorporate prior knowledge learning-based grasping system ways. first could modify design system model-based grasping method example scoring function learning-based grasping second could prior knowledge construct simulator generate synthetic experience used much real experience. second avenue explore work particularly appealing essentially learning system. however incorporating simulated images presents challenges simulated data differs systematic ways real-world data simulation must sufﬁciently general objects. addressing challenges principal subject work. abstract— instrumenting collecting annotated visual grasping datasets train modern machine learning algorithms extremely time-consuming expensive. appealing alternative off-the-shelf simulators render synthetic data ground-truth annotations generated automatically. unfortunately models trained purely simulated data often fail generalize real world. study randomized simulated environments domain adaptation methods extended train grasping system grasp novel objects monocular images. extensively evaluate approaches total physical test grasps studying range simulation conditions domain adaptation methods including novel extension pixel-level domain adaptation term graspgan. show that using synthetic data domain adaptation able reduce number real-world samples needed achieve given level performance times using randomly generated simulated objects. also show using unlabeled real-world data graspgan methodology obtain real-world grasping performance without real-world labels similar achieved labeled real-world samples. grasping fundamental robotic manipulation problems. virtually prehensile manipulation behavior ﬁrst step grasp object question. grasping therefore emerged central areas study robotics range methods techniques earliest years robotics research present day. central challenge robotic manipulation generalization grasping system successfully pick diverse objects seen design training system? analytic model-based grasping methods achieve excellent generalization situations satisfy assumptions. however complexity unpredictability unstructured real-world scenes tendency confound assumptions learning-based methods emerged powerful complement learning robotic grasping system beneﬁt generalization objects real-world statistics beneﬁt advances computer vision deep learning. indeed many grasping systems shown best generalization recent years incorporate convolutional neural networks grasp selection process however learning-based approaches also introduce major challenge need large labeled datasets. labels might consist human-provided grasp improvement grasping performance monocular images incorporating synthetic data propose approaches incorporating synthetic data end-to-end training vision-based robotic grasping show achieves substantial improvement performance particularly lower-data no-data regimes. detailed experimentation simulation-to-real world transfer experiments involved real grasps diverse test objects consider number dimensions nature simulated objects kind randomization used simulation domain adaptation technique used adapt simulated images real world. ﬁrst demonstration effective simulation-to-real-world transfer purely monocular vision-based grasping knowledge work ﬁrst demonstrate successful simulation-to-realworld transfer grasping generalization previously unseen natural objects using monocular images. robotic grasping widely explored areas manipulation. complete survey grasping outside scope work refer reader standard surveys subject complete treatment grasping methods broadly categorized groups geometric methods data-driven methods. geometric methods employ analytic grasp metrics force closure caging methods often include appealing guarantees performance typically expense relatively restrictive assumptions. practical applications approaches typically violate assumptions. reason data-driven grasping algorithms risen popularity recent years. instead relying exclusively analytic understanding physics object data-driven methods seek directly predict either human-speciﬁed grasp positions empirically estimated grasp outcomes number methods combine ideas example using analytic metrics label training data simulation-to-real-world transfer robotics important goal simulation source practically inﬁnite cheap data ﬂawless annotations. reason number recent works considered simulation-toreal world transfer context robotic manipulation. saxena used rendered objects learn visionbased grasping model. gulatieri viereck considered simulation-to-real world transfer using depth images. depth images abstract away many challenging appearance properties real-world objects. however situations suitable depth cameras coupled cost simple cameras considerable value studying grasping systems solely monocular images. number recent works also examined using randomized simulated environments simulationto-real world transfer grasping grasping-like manipulation tasks extending prior work randomization robotic mobility works apply randomization form random textures lighting camera position simulator. however unlike work prior methods considered grasping relatively simple visual environments consisting cubes basic geometric shapes demonstrated grasping diverse novel real-world objects kind considered evaluation. domain adaptation process allows machine learning model trained samples source domain generalize target domain. case source domain simulation whereas target real world. recently signiﬁcant amount work domain adaptation particularly computer vision prior work grouped main types feature-level pixel-level adaptation. feature-level domain adaptation focuses learning domain-invariant features either learning transformation ﬁxed pre-computed features source target domains learning domain-invariant feature extractor often represented convolutional neural network prior work shown latter empirically preferable number classiﬁcation tasks domain-invariance enforced optimizing domain-level similarity metrics like maximum mean discrepancy response adversarially trained domain discriminator pixellevel domain adaptation focuses re-stylizing images source domain make look like images target domain knowledge methods based image-conditioned generative adversarial networks work compare number different domain adaptation regimes. also present method combines feature-level pixel-level domain adaptation simulation-to-real world transfer vision-based grasping. goal work show effect using simulation domain adaptation conjunction tested data-driven monocular vision-based grasping approach. effect approach recently proposed levine section concisely discuss approach main domain adaptation techniques method based grasping approach work consists components. ﬁrst grasp prediction convolutional neural network accepts tuple visual inputs {xixic} motion command outputs predicted probability executing result successful grasp. image recorded robot becomes visible starts grasp attempt image recorded current timestep. speciﬁed frame base robot corresponds relative change end-effector’s current position rotation vertical axis. consider top-down pinch grasps motion command thus dimensions position sine-cosine encoding rotation. second component method simple manually designed servoing function uses grasp probabilities predicted choose motor command continuously control robot. train grasp prediction network using standard supervised learning objectives optimized independently servoing mechanism. work focus extending ﬁrst component include simulated data training grasp prediction network leaving parts system unchanged. datasets training grasp prediction collections visual episodes robotic arms attempting grasp various objects. grasp attempt episode consists time steps result distinct training samples. sample includes xivi success label entire grasp sequence. visual inputs images randomly cropped region training encourage translation invariance. central work compare different training regimes combine simulated real-world data training although consider training entirely simulated data discuss section iv-a training regimes consider combine medium amounts real-world data large amounts simulated data. self-supervised real-world grasping dataset collected levine using physical kuka iiwa arms. goal robots grasp object within speciﬁed goal region. grasping performed using compliant two-ﬁnger gripper picking objects metal monocular camera mounted behind arm. full dataset includes million grasp attempts approximately different objects resulting million real-world images. half dataset collected using random grasps rest using iteratively retrained versions aside variety objects robot differed slightly terms wear-and-tear well camera pose. outcome grasp attempt determined automatically. particular objects front robot regularly rotated increase diversity dataset. examples grasping images camera’s viewpoint shown figure trained entire real dataset best used approach outlined achieved successful grasps time. levine reported additional increase also including million images different robot. excluded additional dataset sake controlled comparison avoid additional confounding factors domain shift within real-world data. starting kuka dataset experiments study effect adding simulated data reducing number real world data points taking subsets varying size fig. setup used collecting simulated real-world datasets. bottom images used training simulated grasping experience procedurally generated objects; real-world experience varied collection everyday physical objects. cases pairs image inputs grasp success prediction model images images current timestamp. part proposed approach domain training adaptation pixel-level domain adaptation. ganin introduced domain–adversarial neural networks architecture trained extract domain-invariant expressive features. danns primarily tested unsupervised domain adaptation scenario absence labeled target domain samples although also showed promising results semi-supervised regime model’s ﬁrst layers shared modules ﬁrst predicts task-speciﬁc labels provided source data second separate domain classiﬁer trained predict domain inputs. dann loss cross-entropy loss domain prediction task ldann ∑ns+nt ground truth domain label sample nsnt number source target samples. shared layers trained maximize ldann domain classiﬁer trained adversarially minimize minimax optimization implemented gradient reversal layer output identity function negates gradient backprop. lets compute gradient domain classiﬁer shared feature extractor single backward pass. task loss interest simultaneously optimized respect shared layers grounds shared features relevant task. dann makes features extracted domains similar goal pixel-level domain adaptation learn generator function maps images source target domain input level. approach decouples process domain adaptation process task-speciﬁc predictions adapting images source domain make appear sampled target domain. images adapted replace source dataset relevant task model trained domain adaptation required. although methods similar spirit ideas primarily pixelda simgan suitable task. models particularly effective goal maintain semantic original adapted synthetic images transformations primarily low-level methods make assumption differences domains primarily low-level rather high-level represent dataset samples source domain i}nt represent dataset samples target domain. generator function parameterized maps source image adapted fake image function learned help adversary discriminator function outputs likelihood given image real-world sample. trained using standard adversarial objective given learned generator function possible create dataset {gys}. finally given adapted dataset task-speciﬁc model trained training test data distribution. pixelda evaluated simulation-to-real-world transfer. however models used renderer high-ﬁdelity scans objects real-world dataset. work examine ﬁrst time technique applied situations models objects real-world available system supposed generalize another previously unseen objects actual real-world grasping task. furthermore images double resolution makes learning generative model much harder task requires signiﬁcant changes compared previous work architecture training objective losses training generator different original implementations resulting novel model evaluated conditions. aims work study ﬁnal grasping performance affected object models simulated experience based scene appearance dynamics simulation simulated real experience integrated maximal transfer. section outline three factors proposals effective simulation-to-real-world transfer task. major difﬁculty constructing simulators robotic learning ensure diversity sufﬁcient effective generalization real-world settings. order evaluate simulationto-real world transfer used dataset real-world grasp attempts multiple datasets simulation. latter built basic virtual environment based bullet physics simulator simple renderer shipped environment emulates kuka hardware setup simulating physics grasping rendering camera mounted looking kuka shoulder would perceive contains object objects grasp scenes similar ones robot encounters real world. central question regarding realism models used objects grasp. answer evaluate different sources objects experiments procedurally generated random geometric shapes realistic objects obtained publicly-available shapenet model repository. procedurally generated objects attaching rectangular prisms random locations orientations seen fig. converted prisms mesh using offthe-shelf renderer blender applied random level smoothing. object given texture coordinates random colors. shapenet-based datasets used shapenetcore.v collection realistic object models shown figure particular collection contains models categories household objects furniture vehicles. rescaled object random graspable size maximum extent gave random mass based approximate volume object. models imported simulator collected simulation datasets similar process real world differences. mentioned above real-world dataset collected using progressively better grasp prediction networks. networks swapped better versions manually rather infrequently contrast physical kuka iiwa robots used collect data real world used simulated arms given time collect synthetic data models used collect datasets updated continuously automated process. resulted datasets fig. comparison procedural shapenet objects used data collection simulation objects used evaluating grasping real-world seen training. variety shapes sizes material properties makes test challenging. collected grasp prediction networks varying performance added diversity collected samples. training grasping approach simulated environment simulated robots successful simulated grasp attempts. note grasp success prediction models used experiments trained scratch using simulated grasp datasets. another important question whether randomizing visual appearance dynamics scene affects grasp performance way. ﬁrst kind diversities considered addition horizontal components motor command. improved real grasp success early experiments added kind randomization simulated samples. adding noise real data help. study effects virtual scene randomization built datasets four different kinds scene randomization randomization similar real-world data collection varied camera pose location used different real-world images backgrounds; visual randomization varied tray texture object texture color robot color lighting direction brightness; dynamics randomization varied object mass object lateral/rolling/spinning friction coefﬁcients; visual dynamics randomization. mentioned sect. primary types methods used domain adaptation feature-level pixellevel. propose feature-level adaptation method novel pixel-level call graspgan. given original synthetic images graspgan produces adapted images look realistic. subsequently trained generator graspgan ﬁxed module adapts synthetic visual input performing feature-level domain adaptation extracted features account transferred images synthetic motor command input. experiments found using dann loss layer yielded superior performance compared applying activations layers. used domain classiﬁer proposed early research questions faced interaction batch normalization dann loss would examined previous work. every layer na¨ıve implementation training models data domains setting call na¨ıve mixing batch statistics calculated without taking domain labels sample account. however domains bound different statistics means calculating using separately simulated real-world data using parameters might beneﬁcial. call training data domains domain-speciﬁc batch normalization mixing show useful tool domain adaptation even dann loss used. pixel-level domain adaptation model graspgan shown fig. convolutional neural network follows u-net architecture uses average pooling downsampling bilinear upsampling concatenation convolutions u-net skip connections instance normalization discriminator patch-based convolutional layers effective input size fully convolutional scales input images stacked channel input producing domain estimates patches combined compute joint discriminator loss. novel multi-scale patch-based discriminator design learn assess global consistency generated image well realism local textures. stacking channels input images enables discriminator recognize relationships images encourage generator respect task model grasp success prediction train graspgan employ least-squares generative adversarial objective encourage produce realistic images. training generator maps synthetic images adapted images individually passing instances generator network displayed figure similar traditional training perform optimization alternating steps minimizing following loss terms w.r.t. parameters sub-network lgen ldiscr lsgan generator discriminator losses ltask task loss lcontent content-similarity loss respective weights. lsgan discriminator loss distance likelihood output domain labels fig. proposed approach overview pixel-level domain adaptation model graspgan. tuples images simulation generator produce realistic versions discriminator gets unlabeled real world images trained distinguish them. real adapted images also grasp success prediction network trained parallel thus gets feedback make adapted images look real maintain semantic information. architectures blue boxes denote convolution/normalization/activation-layers nsinrelu means ﬁlters stride instance normalization relu activation. unless speciﬁed convolutions dann model conv layers conv layers. details found domain classiﬁer uses unit layers. fake real images generator loss label ﬂipped high loss disciminator predicts generated image. task loss measures well network predicts grasp success transferred real examples calculating binomial cross-entropy labels utmost importance graspgan generator making input image look like image real world scenario change semantics simulated input instance drawing robot’s objects different positions. otherwise information extract simulation order train task network would correspond anymore generated image. thus devise several additional loss terms accumulated lcontent help anchor generated image simulated semantic level. straightforward restriction allow generated image deviate much input. effect pmse loss also used also leverage fact semantic information every pixel synthetic images computing segmentation masks corresponding rendered images background tray robot objects. masks training generator also produce additional output adapted image standard reconstruction loss. intuitively forces generator extract semantic information objects scene encode intermediate latent representations. information available generation output image well. finally additionally implement loss term provides dense feedback task tower single information grasp success. encourage generated image provide semantic information task network corresponding simulated penalizing differences activations ﬁnal convolutional layer images. similar principle perceptual loss uses activations imagenetpretrained model anchor restylization input image. contrast trained time loss speciﬁc goal helps preserve semantics ways relevant prediction task. section aims answer following research questions simulated data quality simulator aiding improving grasping performance real world? improvement consistent varying amounts real-world labeled samples? realistic graspable objects simulation need randomizing virtual environment affect simulation-to-real world transfer randomization attributes help most? domain adaptation allow better utilization simulated grasping experience? order answer questions evaluated number different ways training grasp success prediction model simulated data domain adaptation. simulated data used number simulated samples always approximately million. follow grasp success evaluation protocol described levine used kuka iiwa robots real-world experiments table effect choices simulated objects randomization terms grasp success. compared performance models trained jointly grasps procedural shapenet objects real data. models trained dann mixing. test consisting objects shown fig. used different objects robot. objects included real-world training used creating simulation datasets. robot executes grasps total test grasps evaluation. execution robot picks objects side drops other alternating every grasps. prevents model repeatedly grasping object. optimal models selected using accuracy held-out validation real samples. ﬁrst conclusion results simulated data off-the-shelf simulator always aids improving vision-based real-world grasping performance. fig. shows real grasp success gains incorporating simulated data procedurallygenerated objects using simulated data signiﬁcantly consistently improves real-world performance regardless number real-world samples. also observed need realistic models obtain gains. compared effect using random procedurally-generated shapes shapenet objects combination real-world data randomization scenarios. shown table found using procedural objects better choice cases. ﬁnding interesting implications simulation real-world transfer since content creation often major bottleneck producing generalizable simulated data. based results decided solely procedural objects rest experiments. table shows main results grasp success performance different combinations simulated data generation domain adaptation methods different quantities real-world samples. different settings real-only model given real data; na¨ıve mixing simulated samples generated virtual scene randomization mixed real-world samples half batch consists simulated images; mixing randomization simulated dataset generated visual-only randomization. simulated samples mixed real-world samples naive mixing case models dbn; mixing dann simulated samples generated virtual scene randomization model trained domain-adversarial method dbn; mixing dann randomization simulated samples generated visual randomization model trained domain-adversarial method dbn; graspgan table success grasping diverse unseen physical objects methods trained different amounts real-world samples million simulated samples procedural objects. method names explained text. mixing dann non-randomized simulated data ﬁrst reﬁned graspgan generator reﬁned data used train dann mixing. generator trained real dataset size used train dann. figure examples. table shows using visual randomization mixing improved upon na¨ıve mixing randomization experiments across board. effect visual dynamics combined randomization procedural shapenet objects evaluated using real data available. table shows using visual randomization slightly improved grasp performance procedural objects differences generally conclusive. terms domain adaptation techniques proposed hybrid approach combining graspgan dann performs best cases shows gains lower real-data regimes. using danns mixing performed better na¨ıve mixing cases. however effect danns randomized data conclusive equivalent models produced worse results cases. believe interesting results however ones experiments labeled real data. compared best domain adaptation method model trained simulated data without randomization. trained graspgan million real samples without using labels. grasping model trained data reﬁned results table show unsupervised adaptation model outperformed sim-only models without randomization also real-only model labeled real samples. although absolute grasp success numbers consistent ones reported previous grasping work reports higher absolute grasp success. however note following goal show train best possible grasping system amount real-world data inclusion synthetic data helpful; relied previous work grasping approach used; evaluation conducted diverse challenging range objects including transparent bottles small round objects deformable objects clutter; method uses monocular images over-the-shoulder viewpoint without depth wrist-mounted cameras. make setup considerably harder standard ones. paper examined simulated data incorporated learning-based grasping system improve performance reduce data requirements. study grasping over-the-shoulder monocular images particularly challenging setting depth information analytic models available. presents challenging setting simulation-to-real-world transfer since simulated images typically differ much real ones compared simulated depth images. examine effects nature objects simulation randomization domain adaptation. also introduce novel extension pixel-level domain adaptation makes suitable high-resolution images used grasping system. results indicate including simulated data drastically improve vision-based grasping system achieving comparable better performance times fewer real-world samples. results also suggest important realistic models simulated training. finally experiments indicate method provide plausible transformations synthetic images including domain adaptation substantially improves performance cases. although work demonstrates large improvements grasp success rate training smaller amounts real world data number limitations. adaptation methods consider focus invariance either transforming simulated images look like real images regularizing features invariant across domains. features incorporate appearance action structure network explicit reasoning physical discrepancies simulation real world done. consider randomization dynamics properties show indeed important. several recent works looked adapting physical discrepancies explicitly incorporating ideas grasping exciting avenue future work. approach simulation real world transfer considers monocular images though extending method stereo depth images would straightforward. finally success rate reported experiments still room improvement expect research area lead even better results. insight work comes comparison different methods aiming propose novel grasping system rather study incorporating simulated data improve existing one. chang funkhouser guibas hanrahan huang savarese savva song xiao shapenet information-rich model repository corr ioffe szegedy batch normalization accelerating network tion conditional adversarial networks arxiv. wang smolley least squares generative adversarial networks arxiv. johnson alahi fei-fei perceptual losses real-time", "year": 2017}