{"title": "e-QRAQ: A Multi-turn Reasoning Dataset and Simulator with Explanations", "tag": ["cs.LG", "cs.AI", "cs.CL"], "abstract": "In this paper we present a new dataset and user simulator e-QRAQ (explainable Query, Reason, and Answer Question) which tests an Agent's ability to read an ambiguous text; ask questions until it can answer a challenge question; and explain the reasoning behind its questions and answer. The User simulator provides the Agent with a short, ambiguous story and a challenge question about the story. The story is ambiguous because some of the entities have been replaced by variables. At each turn the Agent may ask for the value of a variable or try to answer the challenge question. In response the User simulator provides a natural language explanation of why the Agent's query or answer was useful in narrowing down the set of possible answers, or not. To demonstrate one potential application of the e-QRAQ dataset, we train a new neural architecture based on End-to-End Memory Networks to successfully generate both predictions and partial explanations of its current understanding of the problem. We observe a strong correlation between the quality of the prediction and explanation.", "text": "paper present dataset user simulator e-qraq tests agent’s ability read ambiguous text; questions answer challenge question; explain reasoning behind questions answer. user simulator provides agent short ambiguous story challenge question story. story ambiguous entities replaced variables. turn agent value variable answer challenge question. response user simulator provides natural language explanation agent’s query answer useful narrowing possible answers not. demonstrate potential application e-qraq dataset train neural architecture based end-to-end memory networks successfully generate predictions partial explanations current understanding problem. observe strong correlation between quality prediction explanation. recent years deep neural network models successfully applied variety applications machine translation object recognition game playing dialog more. however lack interpretability makes less attractive choice stakeholders must able understand validate inference process. examples include medical diagnosis business decision-making reasoning legal safety compliance etc. opacity also presents challenge simply debugging improving model performance. neural systems move realms transparent symbolic models currently employed must mechanisms ground neural computation meaningful human concepts inferences explanations. approach problem treat explanation problem learning problem train network explain results neural computation. done either single network learning jointly explain predictions separate networks prediction explanation. regardless availability sufﬁcient labelled training data impediment. previous work developed synthetic conversational reasoning dataset user presents agent simple ambiguous story challenge question story. ambiguities arise entities story replaced variables need known answer challenge question. successful agent must reason answers might given ambiguity possible answer value relevant variable reduce possible answer set. paper present dataset e-qraq constructed augmenting qraq simulator ability provide detailed explanations whether agent’s response correct why. using dataset perform preliminary experiments training extended end-to-end memory network architecture jointly predict response partial explanation reasoning. consider types partial explanation experiments relevant variables agent must know relevant reasoned question; possible answers agent must know answer correctly. demonstrate strong correlation qualities prediction explanation. current interpretable machine learning algorithms deep learning divided approaches approach aims explain black models model-agnostic fashion anstudies learning models particular deep neural networks visualizing example activations gradients inside networks work studied interpretability traditional machine learning algorithms decision trees graphical models learned rule-based systems notably none algorithms produces natural language explanations although rule-based system close humanunderstandable form features interpretable. believe major impediments getting explanations lack datasets containing supervised explanations. datasets often accelerated advance machine learning perspective areas including computer vision natural language reasoning etc. recently natural language explanation added complement existing visual datasets crowd-sourcing labeling however know question answering reasoning datasets offer explanations. obviously labeling large number examples explanations difﬁcult tedious task easily delegated unskilled worker. make progress dataset available techniques obviate need follow approach existing work generate synthetic natural language explanations simulator. qraq domain introduced actors user agent. user provides short story domain similar homeworld domain given initial context followed sequence events temporal order challenge question. stories semantically coherent contain hidden sometimes ambiguous entity references agent must potentially resolve answer question. agent query user value variables hide identity entities story. point interaction agent must determine whether knows answer provide otherwise must determine variable query reduce potential answer example actors treated variables whose value unknown agent. ﬁrst event example refers either hannah emma agent can’t tell which. realistic text enexample qraq problem hannah emma ofﬁce. john park. george square. hannah picks gift. goes ofﬁce park. goes park bank. goes ofﬁce square. emma goes square bank. goes square bank. gift? tity obfuscation might occur spelling transcription errors unknown descriptive references emma’s sibling indeﬁnite pronouns somebody. several datasets problems varying difﬁculty released research community available download paper’s main contribution extension original qraq simulator provides extensive explanations reasoning process required solve qraq problem. explanations created dynamically runtime response agent’s actions. following examples illustrate explanations several different scenarios context events question parts problem identical qraq problem. addition trace interaction trained agent model user simulator. simulator provides kinds explanations response agent’s query answer. ﬁrst kind denoted indicates whether agent’s response correct why. second kind explanation denoted provides full description inferred current state interaction. case relevant information possible answers different points interaction relevant variables example agent asks value user responds answer well explanation indicating correct why. speciﬁcally instance helpful enabled inference reduced possible answer hand example example query corresponding critical explanation. answers answering user provide feedback depending whether agent enough information answer; whether possible answers contains answer. agent enough information user provide feedback whether answer correct correct answer answer false. agent enough information hence guessing user list still relevant variables resulting possible answers. queries querying user provide several kinds feedback depending useful query was. query variable even occurring problem trigger explanation says variable problem. query irrelevant variable result explanation showing story’s protagonist cannot entity hidden variable. finally useful query result feedback showing inference possible knowing variable’s reference. inference also serve detailed explanation obtain correct answer above. testing consider network predict entity explanation output vector surpasses threshold index corresponding entity. tried several thresholds adaptive found ﬁxed threshold works best. evaluate model’s ability jointly learn predict explain predictions performed experiments. first investigate prediction accuracy affected jointly training network produce explanations. second evaluate well model learns generate explanations. understand role explanation content learning process perform experiments types explanation relevant variables possible answers. perform hyperparameter optimization memory network since interested relative performance. show single experimental figures results nearly identical experimental runs. proglems means user acts scripted counterpart agent simulated eqraq environment. show interaction ﬂows supervised reinforcement learning modes. additionally want point figure i.e. natural language explanation internal state explanations. performance accuracy measured user compares agent’s suggested actions agent’s suggested explanations ground truth known user. experiments user simulator explanations train extended memory network. shown figure network architecture extends end-to-end memory architecture adding layer multi-layer perceptron concatenation hops network. explanation response prediction trained jointly. preliminary experiments train directly natural language explanation explanation inferred current state future experiments work explanations directly. speciﬁcally figure modiﬁed ee-memory network architecture simultaneously generating answers challenge question explanations internal belief state shown four internal hops. experiments provide classiﬁcation label prediction output generating agent’s actions vector following form explanation output one-hot encoding dimensionality reed scott akata zeynep honglak schiele bernt. learning deep representations ﬁne-grained viproceedings ieee confersual descriptions. ence computer vision pattern recognition ribeiro marco tulio singh sameer guestrin carlos. model-agnostic interpretability machine learning. proc. icml workshop human interpretability machine learning york june russakovsky olga deng krause jonathan satheesh sanjeev sean huang zhiheng karpathy andrej khosla aditya bernstein michael berg alexander fei-fei imagenet large scale visual recognition challenge. international journal computer vision ./s---y. shrikumar avanti greenside peyton shcherbina anna kundaje anshul. black learning important features propagating activation differences. arxiv preprint arxiv. sukhbaatar sainbayar weston jason fergus others. end-to-end memory networks. advances neural information processing systems http//papers.nips.cc/paper/ -end-to-end-memory-networks. weston jason bordes antoine chopra sumit rush alexander merri¨enboer bart joulin armand mikolov tomas. towards ai-complete question answering prerequisite tasks. arxiv preprint arxiv.", "year": 2017}