{"title": "A User Simulator for Task-Completion Dialogues", "tag": ["cs.LG", "cs.AI", "cs.CL"], "abstract": "Despite widespread interests in reinforcement-learning for task-oriented dialogue systems, several obstacles can frustrate research and development progress. First, reinforcement learners typically require interaction with the environment, so conventional dialogue corpora cannot be used directly. Second, each task presents specific challenges, requiring separate corpus of task-specific annotated data. Third, collecting and annotating human-machine or human-human conversations for task-oriented dialogues requires extensive domain knowledge. Because building an appropriate dataset can be both financially costly and time-consuming, one popular approach is to build a user simulator based upon a corpus of example dialogues. Then, one can train reinforcement learning agents in an online fashion as they interact with the simulator. Dialogue agents trained on these simulators can serve as an effective starting point. Once agents master the simulator, they may be deployed in a real environment to interact with humans, and continue to be trained online. To ease empirical algorithmic comparisons in dialogues, this paper introduces a new, publicly available simulation framework, where our simulator, designed for the movie-booking domain, leverages both rules and collected data. The simulator supports two tasks: movie ticket booking and movie seeking. Finally, we demonstrate several agents and detail the procedure to add and test your own agent in the proposed framework.", "text": "despite widespread interests reinforcement-learning task-oriented dialogue systems several obstacles frustrate research development progress. first reinforcement learners typically require interaction environment conventional dialogue corpora cannot used directly. second task presents speciﬁc challenges requiring separate corpus task-speciﬁc annotated data. third collecting annotating human-machine human-human conversations taskoriented dialogues requires extensive domain knowledge. building appropriate dataset ﬁnancially costly time-consuming popular approach build user simulator based upon corpus example dialogues. then train reinforcement learning agents online fashion interact simulator. dialogue agents trained simulators serve effective starting point. agents master simulator deployed real environment interact humans continue trained online. ease empirical algorithmic comparisons dialogues paper introduces publicly available simulation framework simulator designed movie-booking domain leverages rules collected data. simulator supports tasks movie ticket booking movie seeking. finally demonstrate several agents detail procedure test agent proposed framework. practical dialogue systems consist several components. natural language understanding module maps free texts structured semantic frames utterances. natural language generation module maps structured representations back natural-language form. knowledge bases state trackers provide access side information track evolving state dialogue respectively. dialogue policy central component system chooses action given current state dialogue. traditional systems dialogue policies might programmed explicitly rules. however rulebased approaches several weaknesses. first complex systems easy design reasonable rule-based policy. second optimal policy might change time user behavior changes. rule-based system cannot cope non-stationarity. thus reinforcement learning policies learned automatically experience offers appealing alternative. typically researchers seek optimize dialogue policies either supervised learning reinforcement learning methods. approaches policy trained imitate observed actions expert. supervised learning approaches often require large amount expert-labeled data training. task-speciﬁc domains intensive domain knowledge usually required collecting annotating actual human-human human-machine conversations often expensive time-consuming. additionally even large amount training data possible dialogue state spaces explored sufﬁciently training data preventing supervised learner good policy. contrast approaches allow agent learn without expert-generated example. given reward signal agent optimize dialogue policy interaction users. unfortunately require many samples environment making learning scratch real users impractical. overcome limitation many researchers dialogue systems community train agents using simulated users goal user simulation generate natural reasonable conversations allowing agent explore policy space. simulation-based approach allows agent explore trajectories exist previously observed data overcoming central limitation imitation-based approaches. dialogue agents trained simulators serve effective starting point deployed real humans improve reinforcement learning. given reliance research community user simulations seems important assess quality simulator. best assess user simulator remains open issue universally accepted metric important feature good user simulator requires coherent behavior throughout dialogue; ideally good metric measure correlation user simulation real human behaviors hard widely accepted metric. therefore best knowledge standard build user simulator. here summarize literature user simulation different aspects many models introduced user modeling different dialogue systems. early work employed simple naive bi-gram model predict next user-act based last system-act parameters model simple cannot produce coherent user behaviors reasons model look last system action user changes goal bi-gram model might produce illogical behavior since consider user goal generating next user-act. much follow-up work user simulators tried address issues. ﬁrst issue addressed looking longer dialogue histories select next user action second issue attacked explicitly incorporating user goal user state modeling recently proposed sequence-to-sequence approach inspired end-to-end trainable user simulators approach treats user-turn dialogue agent-turn dialogue source-to-target sequence generation problem might suitable chatbot-like systems work well domain-speciﬁc task-completion dialogue systems require ability interact databases aggregate useful information system responses. beneﬁt modelbased approaches need intensive feature engineering typically require large amount labeled data generalize well deal user states included training data. hand agenda-based user simulation provides convenient mechanism explicitly encode dialogue history user goal. user goal consists slot-value pairs describing user’s requests constraints. stack-like format models state transitions user action generation sequence simple push operations ensures consistency user behavior course conversation. paper combine beneﬁts model-based rule-based approaches. user simulation task-completion dialogue setting follows agenda-based approach dialogact level sequence-to-sequence natural language generation component used convert selected dialog-act natural language. consider dialogue system helping users book movie tickets look movies want interacting natural language. course conversation agent gathers information customer’s desires ultimately books movie tickets identify movie interest. environment assesses binary outcome conversation based whether movie booked whether movie satisﬁes user’s constraints. data data used paper collected amazon mechanical turk annotation done internally using schema. intents slots slots informable slots users constrain search requestable slots users values agent. example numberofpeople cannot requestable slot since arguably user knows many tickets wants buy. total labeled dialogues movie domain average number turns dialogue approximately work follow agenda-based user simulation approach stack-like representation user state provides convenient mechanism explicitly encode dialogue history user’s goal user state update modeled sequences push operations stacks. here describe rule-based user simulator detail. task-oriented dialogue setting ﬁrst step user simulation generate user goal; agent knows nothing user goal objective help user accomplish goal. hence entire conversation exchange around goal implicitly. generally deﬁnition user goal contains parts make user goal realistic constraints user goal slots split groups. movie-booking scenario elements must appear user goal called elements required slots includes moviename theater starttime date numberofpeople; rest slots optional slots; ticket default slot always appears request_slots part user goal. generated user goals labeled dataset using mechanisms. mechanism extract slots ﬁrst user turns data since usually ﬁrst turn contains required information user. mechanism extract slots ﬁrst appear user turns aggregate user goal. dump user goals user-goal database simulator. every time running dialogue randomly sample user goal user goal database. first user-act work focuses user-initiated dialogues randomly generated user goal ﬁrst turn make user-act reasonable constraints generation process. example ﬁrst user turn usually request turn; least informable slot; user knows movie name moviename appear ﬁrst user turn; etc. course dialogue user simulator maintains compact stack-like representation named user agenda user state factored agenda goal consists constraints request time-step user simulator generate next user action based current status last agent action amt− update current status here training testing policy without natural language understanding error model introduced simulate noise component noisy communication user agent. types noise channels error model intent level slot level. furthermore slot level three kinds possible noise training testing policy natural language understanding necessary error model component introduces noise. agent action inform inform agent gathered information ready book movie ticket. user simulator check whether current stack empty also conduct constraint checking make sure agent trying book right movie tickets. guarantees user behaves consistent goal-oriented manner. three statuses dialogue no_outcome_yet success failure. status no_outcome_yet agent issued inform action number turns conversation exceeded maximum value; otherwise dialogue ﬁnished either success failure outcome. success dialogue agent must answer questions book right movie tickets ﬁnally within maximum number turns. cases failure dialogues. example whole dialogue exceeds limit turns agent books wrong movie tickets user. special case user’s constraints satisﬁable movie database agent correctly informs ticket booked. argue successful outcome agent correct. here choose treat failure ticket booked. noted choice affect algorithm comparison much. natural language understanding component recurrent neural network model long-short term memory cells. single model intent prediction slot ﬁlling simultaneously. joint modeling intent slots predicted concatenated iob-format slot tags intent tags additional token <eos> introduced utterance supervised label intent supervised label preceding words tag. still sequence-to-sequence training approach last hidden layer sequence supposed condensed semantic representation whole input utterance utilized intent prediction utterance level. model trained using available dialogue actions utterance pairs labeled dataset. user simulator designed dialog level also work utterance level provide natural language generation component framework. limited labeled dataset empirical tests found pure model-based might generalize well introduce noise policy training. thus hybrid approach consists template-based outputs predeﬁned rule-based templates dialog acts model-based trained labeled dataset sequence-to-sequence fashion. takes dialog-acts input generates template-like sentences slot placeholders lstm decoder. then post-processing scan performed replace slot placeholders actual values lstm decoder apply beam search iteratively considers best sentences time step generating token time step sake trade-off speed performance beam size experiments. conduct experiments training agents user simulator following tasks. ﬁrst task-completion dialogue setting movie-booking domain here agent’s engage user dialogue ultimate goal helping user successfully book movie. measure quality agent three metrics {success rate average reward average turns}; provides different information quality agents. exists strong correlation among them generally good policy higher success rate higher average reward lower average turns. here choose success rate major evaluation metric report quality agents. appendix table demonstrates example dialogues task. second task pertains training kb-infobot setting simpliﬁed version previous goal-oriented dialogues agent user communicate intents accordingly task experiments kb-infobot engage simpliﬁed version simulator described paper using aforementioned intents slots. paper knowledge-base drawn imdb dataset. appendix table demonstrates example dialogues kb-infobot. paper demonstrated rule-based user simulation safe train reinforcement learning agents task-completion dialogues. since rule-based user simulation requires applicationspeciﬁc domain knowledge curate hand-crafted rules usually time-consuming process. improvement current user simulation task-completion dialogue setting include user goal changes make dialogue complex also realistic. another potential direction future improvement model-based user simulation task-completion dialogues. advantage model-based user simulation adapted domains easily long enough labeled data. since model-based user simulation data-driven potential risk asks large amount labeled data train good simulator might risky user simulator train agents uncertainty model. training reinforcement learning agents user simulator agents easily learn errors loopholes existing model-based user simulator make false dialogues success. case quality learned policy misleadingly high. model-based user simulator task-completion dialogue setting still good direction investigate. heriberto cuayáhuitl steve renals oliver lemon hiroshi shimodaira. human-computer dialogue simulation using hidden markov models. ieee workshop automatic speech recognition understanding. ieee bhuwan dhingra lihong xiujun jianfeng yun-nung chen faisal ahmed deng. end-to-end reinforcement learning dialogue agents information access. arxiv. wieland eckert esther levin roberto pieraccini. user modeling spoken dialogue system evaluation. automatic speech recognition understanding proceedings. ieee workshop pages ieee dilek hakkani-tür gokhan asli celikyilmaz yun-nung chen jianfeng deng ye-yi wang. multi-domain joint semantic frame parsing using bi-directional rnn-lstm. interspeech sangkeun jung cheongjae kyungduk minwoo jeong gary geunbae lee. data-driven user simulation automated evaluation spoken dialog systems. computer speech language esther levin roberto pieraccini wieland eckert. stochastic model human-machine interaction learning dialog strategies. ieee transactions speech audio processing zachary lipton jianfeng lihong xiujun faisal ahmed deng. efﬁcient exploration dialogue policy learning networks replay buffer spiking. arxiv. olivier pietquin. consistent goal-directed user model realisitc man-machine task-oriented spoken dialogue simulation. ieee international conference multimedia expo. ieee olivier pietquin thierry dutoit. probabilistic framework dialog simulation optimal strategy learning. ieee transactions audio speech language processing jost schatzmann blaise thomson steve young. error simulation training statistical dialogue systems. ieee workshop automatic speech recognition understanding jost schatzmann karl weilhammer matt stuttle steve young. survey statistical user simulation techniques reinforcement-learning dialogue management strategies. knowledge engineering review konrad schefﬂer steve young. automatic learning dialogue strategy using dialogue simulation reinforcement learning. proceedings second international conference human language technology research. morgan kaufmann publishers inc. pei-hao milica gasic nikola mrksic lina rojas-barahona stefan ultes david vandyke tsung-hsien steve young. continuously learning neural dialogue management. arxiv. tsung-hsien milica gaši´c nikola mrkši´c lina rojas-barahona pei-hao stefan ultes david vandyke steve young. conditional generation snapshot learning neural dialogue systems. emnlp tsung-hsien milica gaši´c nikola mrkši´c pei-hao david vandyke steve young. semantically conditioned lstm-based natural language generation spoken dialogue systems. emnlp framework provides develop compare different algorithms/models dialogue system consists parts agent user simulator. here walk examples show build plug agents user simulators. agents re-implement functions initialize_episode state_to_action. state_to_action function makes assumption structure agent interface implement mapping state action core part agent. example requestbasicsagent rule-based agents support either inform request action practice implement sophisticated rule-based agent support multiple actions including inform request conﬁrm_question conﬁrm_answer deny etc. agent_dqn.py provides agent wraps model. besides functions major functions agent run_policy train. run_policy implements \u0001-greedy policy train calls batch training function dqn. agent_cmd.py provides command line agent agent interact user simulator. command line agent supports types input natural language dialog act. listing shows example command line agent interacting user simulator natural language; listing shows example command line agent interacting user simulator dialog form. note last user turn request action system show line suggested available answers database agent like turn listing rule-based agents agent answer user slot values database. special case command line agent human might type random answer user’s request typed answer database state tracker correct force agent values database agent response. example turn listing input inform actual answer received user inform paciﬁc doesn’t exist database avoid wired behavior agent informs user unavailable value restrict agent values suggested list. last second turn agent usually inform dialog form something like okay tickets booked. natural language inform user simulator agent nearly completes task ready book movie tickets. .json --goal_file_path .\\deep_dialog\\data\\user_goals_first_turn_template.part.movie.v.p -intent_err_prob --slot_err_prob --episodes --act_level --run_mode -cmd_input_mode .json --goal_file_path .\\deep_dialog\\data\\user_goals_first_turn_template.part.movie.v.p -intent_err_prob --slot_err_prob --episodes --act_level --run_mode -cmd_input_mode turn tickets deadpool seattle? turn city want ticket? turn want watch seattle. turn theater want? turn want watch pacific place theater. turn date would like? turn want tomorrow turn start time like? turn want watch turn many tickets need? turn want tickets please turn okay tickets booked. turn thank turn thanks successful dialog turn theater play deadpool turn inform turn need tickets turn request turn want tickets please turn request turn want watch birmingham. turn request turn want watch turn request turn want today turn inform turn thank turn thanks successful dialog similarly user simulator class provides common interfaces users implement user simulators. user simulators inherited class re-implement functions initialize_episode next. usersim_rule.py implements rule-based user simulator. next function implements rules mechanism issue next user action based last agent action. example usersim_rule.py train agent either start rule policy experience tuples initialize experience replay buffer pool start empty experience replay buffer pool. recommend rule supervised policy initialize experience replay buffer pool many work demonstrated beneﬁts strategy good initialization speed training. here simple rule-based policy initialize experience replay buffer pool. agent network. training \u0001-greedy policy dynamic experience replay buffer pool. size experience replay buffer pool dynamic changing. important trick introduce target network updated slowly used compute target value short period. training procedure goes like simulation epoch simulate dialogues state transition tuples experience replay buffer pool train update current network. simulation epoch current network updated multiple times depending batch size current size experience replay buffer simulation epoch target network replaced current network target network updated simulation epoch. experience replay strategy critic training experience reply buffer update strategy follows beginning accumulate experience tuples simulation ﬂush experience reply buffer pool till current agent reaches success rate threshold experience tuples current agent re-ﬁll buffer. intuition behind initial performance good generate enough good experience replay tuples thus ﬂush experience replay pool till current agent reach certain success rate think good example performance rule-based agent. following training process every simulation epoch estimate success rate current agent current agent better enough experience replay buffer poll ﬂushed re-ﬁlled. figure shows learning curve agent without figure learning curve agent takes longer time train agent adapt errors noise nlg. table shows success failure dialogue examples generated rule-based agent agent interacting user simulator movie-booking domain. informative also explicitly show user goal head dialogue agent knows nothing user goal goal help user accomplish goal book right movie tickets. table shows sample dialogues user simulator simplerl-softkb endend-rl agents value critic_rating slot common source error user simulator hence learned policies tend value multiple times. figure learning curve policy training without green line rule agent employ initialize experience replay buffer pool; blue line learning curve agent; orange line optimal upper bound computed ratio number reachable user goals database agent total number user goals. figure learning curve end-to-end policy training green line rule agent employ initialize experience replay buffer pool; blue line learning curve agent; orange line optimal upper bound computed ratio number reachable user goals database agent total number user goals. table sample dialogues generated rule-based agent agent user simulator left column shows rule agents succeed; right column shows rule-based agent fails agent succeeds. rule-based agent user start time cloverﬁeld lane? agent movie interested user want watch cloverﬁeld lane. agentwhat time would like user time playing tomorrow? need tickets. city would like? useri care. date would like watch user want tomorrow. agent theater would like? user theater available? agent many tickets need? user want tickets please agent okay booked tickets cloverﬁeld lane tomorrow. user thank you. agent thank you. failure agent answer questions user. agent user theater book tickets cloverﬁeld lane? agent time would like user theater start time available tomorrow? agent available. user theater available? agent regal live stadium available. user could help book tickets? agent okay able book tickets cloverﬁeld lane regal live stadium tomorrow. userthank agent thank success rule-based agent user tickets zoolander agent movie interested user want watch zoolander agent time would like user want watch agent city would like? user want watch seattle. agent date would like watch user want tomorrow. agent theater would like? user want watch regal meridian agent many tickets need? user want tickets please agent great able purchase tickets zoolander tomorrow regal meridian theater seattle user thank you. agent thank you. user want watch seattle. agent many tickets need? user want tickets please agent available. user want watch regal meridian agent great able purchase tickets zoolander tomorrow regal meridian theater seattle user thank you. agent thank you. success simplerl-softkb user would like know moviename whose genre drama critic_rating agent request user cannot remember agent request user cannot remember agent request user think agent request user think agent inform user looking moviename mpaa_rating director agent request user cannot remember agent request user think agent request user cannot remember agent request user think agent request user think agent inform user moviename director director khan mpaa_rating agent request user cannot remember agent inform user looking moviename actor dylan release_year genre horror. agent inform user moviename natasha actor? agent request user cannot remember agent request user music agent request user agent inform end-to-end user would like know moviename whose genre drama critic_rating agent request user cannot remember agent request user milan cheylov director agent inform user looking moviename mpaa_rating critic_rating agent request user cannot remember agent request user cannot remember agent request user think agent request user think agent request user cannot remember agent inform user looking moviename director khan critic_rating mpaa_rating agent request user cannot remember user cannot remember agent request user cannot remember agent inform user looking moviename actor dylan release_year genre horror. agent inform user moviename natasha actor? agent request user think agent request user think agent request user cannot remember", "year": 2016}