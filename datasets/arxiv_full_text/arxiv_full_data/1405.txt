{"title": "Quad-networks: unsupervised learning to rank for interest point  detection", "tag": ["cs.CV", "cs.LG", "cs.NE"], "abstract": "Several machine learning tasks require to represent the data using only a sparse set of interest points. An ideal detector is able to find the corresponding interest points even if the data undergo a transformation typical for a given domain. Since the task is of high practical interest in computer vision, many hand-crafted solutions were proposed. In this paper, we ask a fundamental question: can we learn such detectors from scratch? Since it is often unclear what points are \"interesting\", human labelling cannot be used to find a truly unbiased solution. Therefore, the task requires an unsupervised formulation. We are the first to propose such a formulation: training a neural network to rank points in a transformation-invariant manner. Interest points are then extracted from the top/bottom quantiles of this ranking. We validate our approach on two tasks: standard RGB image interest point detection and challenging cross-modal interest point detection between RGB and depth images. We quantitatively show that our unsupervised method performs better or on-par with baselines.", "text": "matched correspondences related images used estimating sparse structure scene camera positions. although intuition properties interest points possess unclear design optimal detector satisﬁes them. result give task human assessor would probably select whatever catches might repeatable. cases humans intuition points let’s assume wants could \"interesting\". match images untextured parts existing model ﬁrst step could interest point detection different modalities depth representing model. goal would points detected both. particularly challenging design detector since depth maps look different natural images. means simple heuristics fail strongest corners/blobs might come texture missing depth maps. aiming independent human assessment propose novel approach interest point detection unsupervised learning. knowledge unsupervised learning task explored previous work. earlier works hand-crafted detectors like recent works used supervised learning select \"good\" subset detections hand-crafted detector. example lift aims extract subset detections matched correctly later stages sparse reconstruction. however relying existing detectors option complicated cases like cross-modal one. method contrast learns solution scratch. idea method train neural network maps object point single real-valued response rank points according response. ranking optimized repeatable desired transformation classes point higher ranking anone still higher transformation. consequently top/bottom quantiles response repeatable used interest points. idea illustrated fig. several machine learning tasks require represent data using sparse interest points. ideal detector able corresponding interest points even data undergo transformation typical given domain. since task high practical interest computer vision many hand-crafted solutions proposed. paper fundamental question learn detectors scratch? since often unclear points \"interesting\" human labelling cannot used truly unbiased solution. therefore task requires unsupervised formulation. ﬁrst propose formulation training neural network rank points transformation-invariant manner. interest points extracted top/bottom quantiles ranking. validate approach tasks standard image interest point detection challenging cross-modal interest point detection depth images. quantitatively show unsupervised method performs better on-par baselines. machine learning tasks typically subdivided groups supervised unsupervised recently labelled data millions examples become available microsoft coco signiﬁcant progress supervised learning research. progress partly emergence convenient labelling systems like amazon mechanical turk. still human labelling process expensive scale well. moreover often requires substantial effort explain human annotators label data. learning interest point detector task labelling ambiguity goes extremes. images example interested sparse image locations detected repeatably even image undergoes signiﬁcant viewpoint illumination change. points detecting interest points often required output position point image also additional parameters like scale rotation. detected values parameters inﬂuenced transformations applied images. transformations split groups based desired impact output detector. transformations detector supposed give result called invariant. transformations transform result detector together transformation thus parameters estimated latent variables called covariant learning detector method choose covariant invariant transformations suits goals. choice implemented choice training data inﬂuence formulation. paper organized follows. section discuss related work. section introduce formulation detection problem unsupervised learning rank problem show optimize section demonstrate apply method interest point detection images. finally section validate approach experimentally conclude section summarizing paper listing possibilities future work. currently unsupervised learning comprises many directions learning distribution best explains data restricted boltzmann machines generative adversarial nets clustering dimensionality reduction unsupervised segmentation isomap normalized cuts t-sne learning simulate task solvers learning data representation suitable task deep convolutional adversarial nets learning context prediction learning tracking videos metric learning learning predicting inpainting learning solving jigsaw puzzles tasks actually non-human label others none all. instead auxiliary task hard enough order learn representation useful already existing tasks designing task non-trivial therefore successful approaches exist particular application method interest point detection images. existing image interest point detectors hand-crafted select particular visual elements like blobs corners edges. include detector harris corner detector afﬁne-covariant version fast corner detector mser detector recently also emerged methods supervised learning building upon hand-crafted solution lift aims extract sfmsurviving subset detections tilde uses collecting training samples training points ﬁlter gives large absolute-value response. building upon hand-crafted detector restricts supervised approaches subset basic method detections makes approaches inapplicable cases good detector yet. unsupervised method instead learns detector completely scratch optimizing repeatable ranking. finally particularly challenging case image interest point detection cross-modal interest points repeatable among different image modalities. several works mention complex issue propose general solution. approach contrary general sense learning procedure could applied different tasks show work rgb/rgb rgb/depth modality pairs. section introduce problem learning interest point detector problem learning rank points. consider interest points come top/bottom quantiles response function. quantiles preserved certain transformation classes good detector re-detects points. quantiles ranking preserved search ranking invariant transformations. consider objects every object nd-dimensional tuple points point comes points. object undergo transformations transformation preserves certain point correspondences points object correspond points object assume point correspondence object. simplify notation assume correspondences indexes object transformation. denote corresponding point indexes ikdt} number correspondences points want rank object points represent ranking single real-valued response function figure left image undergoes perspective change transformation. right learned response function visualized heat produces ranking image locations reasonably invariant transformation. since resulting ranking largely repeatable top/bottom quantiles response function also repeatable unfortunately loss hard optimize either gradient gradient zero. instead upperbound discontinuous loss differentiable one. work choose hinge loss learning detectors scratch hard task since non-trivial formulate good detector criteria optimization framework. investigated good detector produce interest points robust viewpoint/illumination changes sparse comply earlier introduced terminology image position image represented patch transformation viewpoint/illumination change correspondence sets patch-to-patch correspondences images observing scene. typical interest point detectors ensure sparsity ways retaining top/bottom quantiles response function retaining local extrema response function observation suggests reproducibility thus repeatable interest point detector needs sort points object response take top/bottom quantiles interest points. next section state optimization objecthus proposed objective beneﬁcial detector pipeline consists non-maximum suppression contrast ﬁltering. pipeline followed many detectors including popular detector following section explain train image interest point detector objective. training need sample image transformation perform training objective could course take images transformations available image dataset correspondences. address important questions achieve invariance exactly transformations want? example real images taken up-right relative rotation pair them. want detector robust cases rotation. augment training images? example objects training images might wellilluminated. testing images objects might shadow others light. might want robust cases. achieve invariance transformation class sample random transformations apply quadruple transformations training quadruples element-wise. expresses preference preserve ranking even random transformation applied image. augment data transformation class sample random transformations apply means apply transformation patches correspondence create training data. objective function based pairs correspondences forming training quadruples train detector need obtain correspondences. investigated learning detector ground-truth correspondences describe setup experiments. detector class. concentrate commonly used type detectors scale-space-covariant rotationinvariant ones example belongs type. detectors consider interest point characterized image location scale points detected -dimensional space using response function consequently non-maximum suppression contrast ﬁltering work -dimensional space well since rotation estimated detector required invariant invariance achieved random sampling detector evaluation. widely used detector nowadays baseline evaluation. whole detector multi-stage pipeline substitute crucial part ﬁlter used convolve image. order make fair evaluation stages pipeline. whole procedure works follows. first apply response function spatial positions image considered scales. stage aiming substitute learned function second non-maximum suppression scale-space. third accurate localization based second-order taylor expansion response function around potential interest points finally take points absolute value response larger threshold. figure quad-network forward pass training quadruple. patches correspondence pairs different images come ﬁrst image come second image. patches extracted random rotation. quantitative evaluation repeatability measure described repeatability ratio number points correctly detected pair images number detected points image lowest number detections. meaningful compare methods producing number interest points otherwise method might report many points unfairly outperform others therefore consider range top/bottom quantiles producing desired numbers points compare methods ﬁxed numbers. response function. experiments response function neural network. describe tuple layers notation experiments response function applied grayscale patches. training data color convert grayscale. patches preprocessed typical neural networks mean whole patch subtracted divided standard deviation patch. augmentation. augment training data random rotations random scale changes adadelta algorithm version gradient descent chooses gradient step size per-parameter automatically. implement model optimization using torch framework batch size models trained epochs consisting randomly sampling pair corresponding images randomly sampling quadruples pair. eventually time training stops models seen million sampled quadruples. establish correspondences training detector. training. used robot image dataset points coming laser scanner camera poses allow project points pairs images extract image patches centered projections. projections form correspondence pairs training. testing. used oxford dataset commonly chosen kind evaluation. dataset consists image pairs. architectures. experiment tested architectures linear model non-linear hidden layer results. demonstrate ﬁlter learned linear model different ﬁlters baselines fig. furthermore show detections linear model comparison fig. learned model detects points different evenly distributed images. usually proﬁtable estimating geometric transformations camera frames. learned response functions investigated architectures demonstrate better performance baselines cases shown table moreover non-linear model performs better linear majority cases. matched. matching score i.e. ratio correct matches matches. detectors +sift slightly better dog+sift cases shown fig. methods performed worse dataset measuring robustness jpeg compression included training. table repeatability random ﬁlter linear non-linear methods. entries omitted enough points non-maximum suppression. left-most column transformation class used abbreviations viewpoint zoom+rotation illumination. understanding design good solution hand. learn detector depth images training nyuv dataset detector application augmenting un-colored point cloud colors newly obtained image. training. random frames nyuv contains view-aligned kinect rgbd frames testing. random frames nyuv architectures. evaluated following architectures response function goal experiment show ground-truth correspondences additional data source necessary train detector method. instead sample random transformations obtain correspondences. training. experiment used images dataset different illuminations. generate correspondence patch randomly selected image randomly transformed. considered afﬁne warps preserving area together illumination changes uniformly sampled provided dataset. afﬁne warps parametrized diag rot) rotation scaling factor considered settings small warps large warps testing. used oxford dataset architectures. considered linear models. results. shown table methods outperform half cases. cross-modal rgb/depth detector results. repeatability ﬁlters best model shown fig. fig. best model outperformes others large relative value. shown repeatability plot produces relatively small number interest points. extract number points sensors fair comparison explained beginning section produces depth channel smooth lacks texture. opposite methods produce points learn \"spread\" image patches training making response distribution peaky. compare detections best model fig. work proposed unsupervised approach learning interest point detector. idea method produce repeatable ranking points object top/bottom quantiles ranking interest points. demonstrated learn detector images. show superior comparable performance method respect different settings learning standard detector scratch learning detector repeatable different modalities future work includes learning descriptor jointly detector. also could investigate applying method detection beyond images", "year": 2016}