{"title": "Deep CNNs along the Time Axis with Intermap Pooling for Robustness to  Spectral Variations", "tag": ["cs.CL", "cs.LG", "cs.NE"], "abstract": "Convolutional neural networks (CNNs) with convolutional and pooling operations along the frequency axis have been proposed to attain invariance to frequency shifts of features. However, this is inappropriate with regard to the fact that acoustic features vary in frequency. In this paper, we contend that convolution along the time axis is more effective. We also propose the addition of an intermap pooling (IMP) layer to deep CNNs. In this layer, filters in each group extract common but spectrally variant features, then the layer pools the feature maps of each group. As a result, the proposed IMP CNN can achieve insensitivity to spectral variations characteristic of different speakers and utterances. The effectiveness of the IMP CNN architecture is demonstrated on several LVCSR tasks. Even without speaker adaptation techniques, the architecture achieved a WER of 12.7% on the SWB part of the Hub5'2000 evaluation test set, which is competitive with other state-of-the-art methods.", "text": "structural advantages cnns enable modeling speech data without feature-level engineering spectrograms ﬁlter-banks. previous researchers introduced time-delayed neural networks cnns convolutions along time axis learn temporal dynamics features researchers applied convolutions along frequency axis attain invariance frequency-shifts however acoustic features speech vary frequency weight sharing along frequency axis appropriate. limited weight sharing method weights convolved within subsection frequencybands employed efforts overcome problem however settling appropriate band divisions ﬁlters require work. limitation common preceding approaches employed convolution pooling layers. another limitation relationship topography ﬁlters trained supervised learning intensively investigated. unsupervised feature extraction previous researchers imposed sparsity terms small groups neighborhoods feature maps image speech data attained topographicallyorganized maps smoothly varying oriented edge ﬁlters tonotopic disordered topography spectrotemporal features found primary visual auditory cortex respectively. paper argue convolution along time axis effective along frequency axis acoustic models. order network learns temporal dynamics adequately increase depth convolution layers small ﬁlters. instead frequency-axis convolution pooling propose addition convolutional maxout layer namely intermap pooling layer order increase robustness spectral variations. previously convolutional maxout network proposed however applied convolutions along frequency axis. show cnns time convolution reduce word error rates more. result cnns model temporal dynamics remain robust spectral variations. cnns consist alternation convolution pooling layers fully connected layers top-most layer. stand input convolution layer ﬁlters convolution ﬁlter denoted denoting ﬁlters height width respectively designating number feature maps input. abstract—convolutional neural networks convolutional pooling operations along frequency axis proposed attain invariance frequency shifts features. however inappropriate regard fact acoustic features vary frequency. paper contend convolution along time axis effective. also propose addition intermap pooling layer deep cnns. layer ﬁlters group extract common spectrally variant features layer pools feature maps group. result proposed achieve insensitivity spectral variations characteristic different speakers utterances. effectiveness architecture demonstrated several lvcsr tasks. even without speaker adaptation techniques architecture achieved part hub’ evaluation test competitive state-of-the-art methods. strated remarkable performance improvements automatic speech recognition deep neural networks trained label frame processed speech data state hidden markov model however difﬁculty fact acoustic features vary widely frequency articulation rate depending harmonics vocal tract characteristic speaking styles. efforts effectively handle variations categorized feature-level model-level approaches. amongst feature-level approaches speaker-adapted methods fmllr proposed. acoustic features concatenated i-vectors represent speaker information also employed input dnns model-level approaches employed hybrid nn-hmm systems convolutional neural networks recurrent neural networks fig. illustration convolution layer followed intramap pooling layer intermap pooling layer. sizes convolution ﬁlters feature maps denoted ‘××’. number ﬁlters denoted pooling size denoted convolution input padded zeros ends time axis order preserve frame length convolutions. time axis reasonable. however sharing ﬁlters along frequency axis suitable features within lower frequency-band regions signiﬁcantly different higher regions. instead convolution along frequency axis architecture employs intermap pooling layer following ﬁrst convolution layer. approach demonstrates robustness frequency-shifted features also spectro-temporally distorted features. moreover require engineered efforts consider varying characteristics different frequency-bands. sufﬁciently deep depth convolution pooling layers necessary precisely represent complex acoustic features temporal spectral variations. individual frames also labeled minutely number states thousands tri-phone modeling. however context windowed inputs tiny stacking multiple intramap pooling layers decreases feature size proportion pooling size thereby restricting depth cnns. since previous researchers chosen large convolution ﬁlter intramap pooling sizes sufﬁcient increases depths cnns realized. illustrated fig. architecture applies convolution intramap pooling layers along time axis. pooling size intramap pooling layers small decrease temporal resolution much. furthermore motivated performance deep cnns inserted convolution layers small ﬁlters intramap pooling layers. combination ﬁlters pooling layers increases non-linearity results network rich feature expressions. conducted experiments using hour switchboardrelease dataset conversational telephone speech task well wall street journal corpus aurora database read speech. used -hour training dataset corpus. aurora database subset clean utterances added different noise types and/or convolved microphone distortions. following results intramap pooling layer typically called max-pooling propagates maximum value sub-region feature map. non-overlapping sub-regions height width output pooling layer given several categories acoustic features harmonics formants on/offsets spectral variations acoustic features appear shifts frequency axis time order ensure robustness model spectral variations propose addition convolutional maxout layer intermap pooling layer. like maxout networks layer groups ﬁlters pools feature maps inside group. speciﬁcally intermap pooling layer partitions feature maps groups. group propagates maximum activation value position. formally output group consisting consecutive feature maps given structural comparison intermap intramap pooling layers shown fig.. note method pursued paper introduce additional learning terms except intermap grouping ﬁlters. central idea ﬁlters group learn common spectrally variant features frequency-shifted harmonics pooled feature invariant feature variations within group. pooled feature maps representative feature maps group. supervised learning pooled feature maps become discriminative features recognizing phonemes. phoneme since spectral variations among different speakers utterances discriminative information individual ﬁlters group spontaneously represent common spectrally variant features even though layer ensure this. sets. moreover validated convolution along time axis always outperforms convolution along frequency axis. furthermore cnns trained log-mel features lower fmllr features layers. results show weight sharing along time axis effectively reduces increased nonlinearity obviates preprocessing speaker adaptation. decoding results imp-cnns different numbers maps pooling sizes compared table investigated intermap pooling layer groups overlap stride one. cnns intermap pooling layer performed better -layer without. especially ‘l-imp’ performs best test showing relative improvement -layer cnn. note table layer applied cnns along frequency axis fmllr features performance declines. addition performed well aurora corpus shown tableiii respectively. fig. conﬁgurations architectures swbd. relu nonlinearity function used every activation. made layers excluding repeating blue colored layers. aurora datasets fully connected layers smaller hidden neurons remainder same. speech signal processed short-time fourier transform hamming window window shifts. used -dimensional log-mel ﬁlter bank features without energy coefﬁcient concatenated frames context window size feed networks inputs. trained gmm-hmm system fmllr features. forced alignment frame gmm-hmm baseline system target label neural networks. random initialization weights biases gaussian distribution respectively cnns optimized stochastic gradient descent method. particular cnns deeper -layers faced infeasible training layer backpropagates errors multiplying small initial weights resulting vanishing gradients. therefore increased standard deviation gaussian distribution lower layers. layer trained momentum l-decay term mini-batch size epoch training trained model accepted validation cost decreases. otherwise trained model rejected training starts latest accepted model halved learning rate. initial learning rate training stops epochs. implementation developed upon kaldi toolkit swbd task decode speech using trigram language model vocabularies trained words rescore decoding results using gram trained fisher english part transcripts aurora corpus used word extended dictionary trigram pruned language model exactly ’recipe kaldi. fig. shows decoding results cnns swbd evaluation sets various depths layers layers deeper cnns produced lower wers -layer achieving total evaluation fig. trained ﬁlters ﬁrst convolution layer. filters -layer cnn. ﬁlters biggest l-norm sorted decreasing order. groups four ﬁlters ‘l-imp’. order groups arranged according feature category group. part successive ﬁlters ‘l-impo’. decoding results summarized table ‘limp’imp improved gmm-hmm baseline max-out network demonstrating relative improvement respectively. also performs -layer i.e. non-imp additional convolution layers. finally compared tdnn cnns employed -dimensional convolutions note compare previous results without sequence training smbr. even though deep speaker adaptation techniques yielded comparative word error rate simply employing intermap pooling increasing depths. present experiments demonstrate convolution along time axis effective along frequency axis processing speech. depth convolution layers crucial sufﬁcient representation complex temporal dynamics inherent acoustic features speech. order achieve greater robustness spectral variations speech recognition proposed addition intermap pooling cnns. visualization trained ﬁlters veriﬁed ﬁlters grouped together learn similar spectrotemporal features form topological map. even without speaker adaptation techniques proposed delivered competitive performance switchboard aurora databases. learnt ﬁlters ﬁrst convolution layer visualized fig. categories spectrotemporal features ﬁlters. harmonic features narrow frequency-region broad high frequency-region. on/off-set detecting ﬁlters temporally selective also sensitive several frequencies. features gabor-like ﬁlters centered frequency-bands presumably detect formants. features formant changes directional diagonal lines spectrotemporal modulations middle frequency-bands. note different features appear different frequency-bands local features type different bandwidth sizes. trained ﬁlters group intermap pooling layer presented fig. importantly ﬁlters group belong common category. example ﬁlters harmonic extractor formant change detector groups marginally shifted features frequency axis. ﬁgure veriﬁes intermap pooling lead ﬁlters group extract common spectrally variant features although additional architectural constraints guarantee this. consecutive trained ﬁlters impo layer drawn fig. ﬁlters form -dimensional topological neighboring ﬁlters respond similar spectrotemporal features. along topological axis ﬁlters appear discontinuously feature categories reﬂecting fact feature categories become deﬁnitely distinguishable system trained. recent neurophysiological studies consensus multiple tonotopic maps exist human auditory system however studies suggest topography includes sound features temporal spectral joint modulations trained topography provide clue human auditory neurons organize efﬁciently process information povey ghoshal boulianne burget glembek goel hannemann motlicek qian schwarz silovsky stemmer vesely kaldi speech recognition toolkit autom. speech recognit. underst. ieee work. ieee herdener esposito schefﬂer schneider logothetis uludag kayser spatial representations temporal spectral sound cues human auditory cortex cortex vol. santoro moerel martino goebel ugurbil yacoub formisano encoding natural sounds multiple spectral temporal resolutions human auditory cortex plos comput. biol. vol. hinton deng dahl a.-r. mohamed jaitly vanhoucke nguyen sainath kingsbury deep neural networks acoustic modeling speech recognition signal process. mag. vol. rath povey vesel cernock improved feature processing deep neural networks interspeech saon soltau nahamoo picheny speaker adaptation neural network acoustic models using i-vectors ieee work. autom. speech recognit. underst. abdel-hamid a.-r. mohamed jiang penn applying convolutional neural networks concepts hybrid nn-hmm model speech recognition ieee int. conf. acoust. speech signal process. graves a.-r. mohamed hinton speech recognition deep recurrent neural networks acoust. speech signal process. ieee int. conf. ieee graves jaitly mohamed hybrid speech recognition deep bidirectional lstm autom. speech recognit. underst. ieee work. ieee waibel hanazawa hinton shikano lang phoneme recognition using time-delay neural networks acoust. speech signal process. ieee trans. vol. pham largman unsupervised feature learning audio classiﬁcation using convolutional deep belief networks. adv. neural inf. process. syst. sainath a.-r. mohamed kingsbury ramabhadran deep convolutional neural networks lvcspr acoust. speech signal process. ieee int. conf. hyv¨arinen patrik emergence phase shift invariant features decomposition natural images independent feature subspaces neural comput. vol.", "year": 2016}