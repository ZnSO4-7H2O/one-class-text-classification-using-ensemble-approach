{"title": "Deep Learning for Unsupervised Insider Threat Detection in Structured  Cybersecurity Data Streams", "tag": ["cs.NE", "cs.CR", "cs.LG", "stat.ML", "62-07"], "abstract": "Analysis of an organization's computer network activity is a key component of early detection and mitigation of insider threat, a growing concern for many organizations. Raw system logs are a prototypical example of streaming data that can quickly scale beyond the cognitive power of a human analyst. As a prospective filter for the human analyst, we present an online unsupervised deep learning approach to detect anomalous network activity from system logs in real time. Our models decompose anomaly scores into the contributions of individual user behavior features for increased interpretability to aid analysts reviewing potential cases of insider threat. Using the CERT Insider Threat Dataset v6.2 and threat detection recall as our performance metric, our novel deep and recurrent neural network models outperform Principal Component Analysis, Support Vector Machine and Isolation Forest based anomaly detection baselines. For our best model, the events labeled as insider threat activity in our dataset had an average anomaly score in the 95.53 percentile, demonstrating our approach's potential to greatly reduce analyst workloads.", "text": "present online unsupervised deep learning system ﬁlter system data analyst review. insider threat behavior widely varying attempt explicitly model threat behavior. instead novel variants deep neural networks recurrent neural networks trained recognize activity characteristic user network concurrently assess whether user behavior normal anomalous real time. streaming scenario mind time space complexity methods constant function stream duration; data cached indeﬁnitely detections made rapidly data models. analysts interpreting system decisions model decomposes anomaly scores human readable summary major factors contributing detected anomaly several difﬁculties applying machine learning cyber security domain model attempts address. user activity network often unpredictable seconds hours contributes difﬁculty ﬁnding stable model normal behavior. model trains continuously online fashion adapt changing patterns data. also anomaly detection malicious events particularly challenging attackers often closely mimic typical behavior. model stream system logs interleaved user sequences user-metadata provide precise context activity network; allows model example identify truly typical behavior user employees role employees project team etc. assess effectiveness models synthetic cert insider threat dataset includes system logs line-level annotations insider threat activity. ground truth threat labels used evaluation. frequent approach insider threat detection frame problem anomaly detection task. comprehensive overview anomaly detection provided chandola concludes anomaly detection techniques online multivariate sequences underdeveloped; analysis organization’s computer network activity component early detection mitigation insider threat growing concern many organizations. system logs prototypical example streaming data quickly scale beyond cognitive power human analyst. prospective ﬁlter human analyst present online unsupervised deep learning approach detect anomalous network activity system logs real time. models decompose anomaly scores contributions individual user behavior features increased interpretability analysts reviewing potential cases insider threat. using cert insider threat dataset threat detection recall performance metric novel deep recurrent neural network models outperform principal component analysis support vector machine isolation forest based anomaly detection baselines. best model events labeled insider threat activity dataset average anomaly score percentile demonstrating approach’s potential greatly reduce analyst workloads. insider threat complex growing challenge employers. generally deﬁned actions taken employee potentially harmful organization; e.g. unsanctioned data transfer sabotage resources. insider threat manifest various novel forms motivated differing goals ranging disgruntled employee subverting prestige employer advanced persistent threats orchestrated multi-year campaigns access retrieve intelligence data cyber defenders tasked assessing large volume real-time data. datasets high velocity heterogeneous streams generated large possible entities activities goal efﬁcient utilization human resources automated methods ﬁltering system data analyst focus much past current research work included. ∗email brian.hutchinsonwwu.edu. phone address high street bellingham copyright association advancement artiﬁcial intelligence rights reserved. issues addressed paper. real world system anomaly detection system logs address constraints given real time nature task provide features suitable application domain concurrent tracking multiple entities analysis structured multivariate data adaptation shifting distribution activities interpretable judgments. work surveyed addresses subset components work addresses constraints features. mentioned above common approach tasks like intrusion detection insider threat anomaly detection. carter streilein demonstrate probabilistic extension exponentially weighted moving average application anomaly detection streaming environment. method learns parametric statistical model adapts changing distribution streaming data. advantage present approach using deep learning architectures ability model wider range distributions fewer underlying assumptions. gavai compare supervised approach expert-developed classiﬁer unsupervised approach using isolation forest method task detecting insider threat network logs. also aggregate information features contribute isolation point within tree produce motivation user ﬂagged anomalous. considering reasonable approach include isolation forests baselines. researchers also applied neural network-based approaches cybersecurity tasks. ryan train standard neural network hidden layer predict probabilities users created distribution unix commands given day. detect network intrusion probability less users network. differing work input features structured train network online fashion. early work modeling normal user activity network using rnns performed debar train convergence representative sequence unix command line arguments predict network intrusion trained network user poorly predicting login logout sequence. work partially addresses online training continuously train network take account changing user habits time. veeramachananeni present work using neural network auto-encoder online setting. aggregate numeric features time window ﬁrewall logs ensemble unsupervised anomaly detection methods principal component reconstruction signal auto-encoder neural network multivariate probabilistic model feature space. additionally incorporate analyst feedback continually improve time explicitly model individual user activity time. recurrent neural networks have course successfully applied anomaly detection various alternative domains; e.g. malhotra domain signals mechanical sensors machinery engines vehicles chuahan domain heart data marchi acoustic signal processing domain. contrast present work applications faced task processing multivariate combination categorical continuous features. figure provides overview anomaly detection system. first events system user logs feature extraction system aggregates counts outputs vector user day. user’s feature vectors neural network creating networks user. variant system dnns; other rnns. either case different user models share parameters maintain separate hidden states. neural networks tasked predicting next vector sequence; effect learn model users’ normal behavior. anomaly proportional prediction error sufﬁciently anomalous behavior ﬂagged analyst investigate. components system described greater detail below. feature extraction practical consideration deep learning anomaly detection system must address transformation system lines heterogeneous tracking sources numeric features suitable input. system extracts kinds information sources categorical user attribute features continuous count features. categorical user features refer attributes user’s role department supervisor organization. table list categorical features used experiments addition categorical features also accumulate counts activities user performed ﬁxed time window example counted activity number uncommon non-decoy copies removable media hours p.m. p.m. figure visually enumerates count features simply follow path right left choosing item along way. traversals count features. user time period categorical values activity counts concatenated dimensional numeric feature vector structured stream neural network core system neural network models series feature vectors given user probability distribution next vector user’s sequence. model trained jointly users simultaneously online fashion. first describe model explicitly model temporal behavior followed does. discuss remaining components making predictions structured feature vectors identiﬁcation anomaly stream feature vectors. deep neural network model model takes input series feature vectors user produces output series hidden state vectors hidden layers ﬁnal hidden state output hidden layer recurrent neural network model like model maps input sequence hidden state sequence unlike hidden state computed function sequence rather current input alone allows capture temporal patterns user behavior build increasingly accurate model user’s behavior time. popular long short-term memory architecture time function longhidden state deep lstm hidden layterm memory cell ﬁnal hidden state output hidden layer depends input sequence cell states follows zero vectors denote element-wise multiplication logistic sigmoid function respectively. vector hidden representation based current input previous hidden state vectors modulate cell-state information propaiu gated across time input incorporated cell state hidden state relates cell state respectively. trainable parameters lstm weight matrices bias vectors weights shared among users. probability decomposition given hidden state time model outputs parameters probability distribution next observation anomaly user time probability complicated fact feature vectors thus predictions model makes include categorical variables addition dimensional count vector. therefore actually joint probability count vector categorical variables role project functional identity function; instead network must exploit statistical regularities data achieve reconstruction error commonly found patterns expense high reconstruction error uncommon patterns networks trained unsupervised fashion demonstrated effective several anomaly detection application domains given everything know including time predict input counts anomalous unlikely produce distribution assigns large density refer approach same time step prediction. detecting insider threat ultimately goal model detect insider threat. assume following conditions model produces anomaly scores used rank user-days anomalous least provide highest ranked user-day pairs analysts judge whether anomalous behavior indicative insider threat. assume daily budget imposes maximum number user-day pairs judged actual case insider threat presented analyst correctly detect model trained online fashion anomaly scores start quite large trend lower time place anomaly score user time proper context compute exponentially weighted moving average estimate mean variance anomaly scores standardize score arrives. feature model anomaly score decomposes negative probabilities variables; continuous count random variable further decomposes individual feature terms /σi. allows identify features largest contributors anomaly score; example model could indicate particular user-day ﬂagged anomalous primarily abnormal number emails sent attachments uncommon recipients between providing insight user-day ﬂagged improve speed accuracy analysts’ judgments insider threat behavior. online training standard training scenario rnns individual mini-batches sequences gradients training objective computed back propagation time weights adjusted gradient-descent-like algorithm. dnns individual mini-batches samples weights updated gradients computed standard backpropagation. either case process usually iterates ﬁxed-size dataset model converges model applied data make predictions. denotes softmax function. additional weight matrices additional bias vectors introduced seven variables predicting. like lstm weights parameters shared among users. parametric forms conditional probabilities described next. conditional probabilities model conditional probabilities categorical variables discrete model conditional probability counts continuous. discrete models standard approach probability category simply element vector whose dimension equal number categories. example roles softmax output activation produce elements non-negative sum-toone. count vector multivariate normal dent−) consider varisity assume covariance identity. identity covariance maximizing log-likelihood true data equivalent minimizing squared error second assume diagonal covariance model outputs mean vector diagonal portion model seen simpliﬁed mixture density network prediction targets deﬁne prediction target approaches next time step same time step. recall eqn. anomaly inversely proportional probability observation time given hidden representation time given everything know including time predict outcome time approach normal paradigm rnns sequential data; experiments refer approach next time step prediction. however common anomaly detection literature auto-encoder detect anomaly. auto-encoder parametric function trained reproduce input features output. complexity typically constrained prevent learning trivial approach faces challenges online anomaly detection setting dataset streaming effectively unbounded model tasked making predictions data learns. attempting shoehorn scenario standard training setup impractical infeasible either store repeatedly train unbounded streaming dataset periodically retraining model ﬁxed-size recent events risks excluding important past events. accommodate online scenario make important adjustments standard training regimen. dnns primary difference restriction observing sample once. situation complicated. train multiple user sequences concurrently backpropagating adjusting weights time feature vector user. logically corresponds training user weights shared users hidden state sequences per-user. practice accomplish training single supplementary data structure stores ﬁnite window past inputs hidden cell states user. time feature vector user model hidden cell states user used context calculating forward pass backpropagating error. baseline models assess effectiveness models compare popular anomaly/novelty/outlier detection methods. speciﬁcally compare one-class support vector machine isolation forest principle component analysis baselines scikit-learn’s implementation one-class isolation forest included part novelty outlier detection functionality baseline project feature vector onto ﬁrst principle components back original feature space. anomaly proportional error reconstruction. hyperparameter tuned development set. assess effectiveness model implemented tensorﬂow series experiments. section describe data used hyperparameters tuned present results analysis. data given security privacy concerns surrounding network data real world datasets must undergo anonymization process publicly released research purposes. anonymization process obscure potentially relevant factors system logs. particularly user attribute metadata available system administrator cert consists event lines simulated organization’s computer network generated sophisticated user models. sources events logon/logoff activity http trafﬁc email trafﬁc operations external storage device usage. course days users generate events among events manually injected domain experts representing insider threat scenarios taking place. additionally user attribute metadata included; namely categorical attributes listed table since unsupervised task supervised training required. therefore split entire dataset chronologically subsets development test. former subset used model selection hyper-parameter tuning latter subset held assessing generalization performance. table summarizes dataset statistics. predictions made granularity user-day; fewer threat user-days events malicious users often conduct several threat events course single day. note although test includes events threat user-days. ﬁnal note ﬁltered data keep weekdays because normal qualitatively different weekdays weekends. desired second system could trained model normal weekend behavior. tuning tune models baselines development using random hyper-parameter search. tune number hidden layers hidden layer dimension batch size samples learning rate tune hidden layers hidden layer dimension ranges also learning rate batch size tuned larger batch sizes speed model training important dnn. also tune number time steps back propagate inputs outputs include categorical variables additionally tune hyper-parameter determines size input embedding vector category relation many classes category neural network models tanh hidden activation function trained using adam variant gradient descent. also tune baseline models. baseline tune number principal components isolation forest baseline tune number estimators contamination whether bootstrap feature hyper-parameter ﬁxed default baseline tune kernel whether shrinking heuristic polynomial kernel tune degree kernels default value remaining hyper-parameters. models tuning criteria cumulative recall deﬁne recalls budgets including computational efﬁciency evaluate budgets increments deﬁned recall budget cr-k actually +··· cr-k thought approximation area recall curve. model picked hyper-parameters maximized maximum value achievable given assumptions ﬁxed daily analyst budget cannot carried next true positives rare cost missed detection substantially larger cost false positive feel recall-oriented metrics cr-k suitable measurement performance precision-oriented ones. first assess effect including excluding categorical variables model input output. table shows comparison lstm models differing whether include exclude categorical information. shows difference huge model clearly performs better without categorical information. original intention including categorical features provide context model hypothesize dataset simple enough context necessary also added model complexity hinders trainability leading loss perfortable cumulative recall daily budgets comparing performance diagonal covariance lstm models predicting counts next time steps current time step. mance. inclusion categorical features adds computational complexity model harms performance remaining experiments reported paper count features only. second experiments designed determine prediction modes work best task same time step next time step table shows results comparing lstm models. same time step approach yields better performance models although difference dramatic lstm. based result same time step remaining experiments. interestingly lstm perform equivalently. suspect cert dataset contain enough temporal patterns unfolding multiple days offer real advantage lstm though would expect offer advantages real-world datasets. ﬁnal experiments designed assess effect covariance type continuous features contrast baseline models. table shows results. among baselines isolation forest model strongest giving third best performance dnn-diag lstm-diag. results also show diagonal covariance leads better performance identity covariance. obvious advantage diagonal covariance capable effectively normalizing data wondering well identity model would perform data normalized ahead time conducted pilot study counts standardized exponentially weighted moving average estimate mean variance found improvement either identity diagonal covariance models. contrast global normalization scheme diagonal covariance model capable conditioning mean variance local context example might expect greater mean variance number emails sent abnormally large number emails received. said clear whether data exhibits patterns models take advantage dynamic normalization. perform analyses better understand system’s behavior using best model illustrate. ﬁrst look effect time model’s notion anomaly. model begins completely untrained anomaly scores users high ﬁrst days. model sees examples user behavior quickly learns normal. fig. shows anomaly function percentile ranges shown malicious user-days overlayed dots. notice malicious events percentile anomaly percentile. second analysis study effect daily budget recall best best lstm three baseline models. fig. plots recall curves. impressively daily budget dnn-diag lstm-diag isolation forest model obtain recall. also shows lstm-diag system recall obtained budget presented system employing online deep learning architecture produces interpretable assessments anomaly task insider threat detection streaming system user logs. insider threat takes different forms practical explicitly model system instead models normal behavior uses anomaly indicator potential malicious behavior. approach designed support streaming scenario allowing high volume streams ﬁltered manageable number events analysts review. further probabilistic anomaly scores also allow system convey felt given user anomalous given hope interpretability improve human analysts’ speed accuracy. evaluation using cert insider threat dataset lstm models outperformed three standard anomaly detection technique baselines probabilistic output model uses context-dependent diagonal covariance matrix rather ﬁxed identity covariance matrix provides better performance. also contrasted prediction scenarios probabilistically reconstructing current input given compressed hidden representation probabilistically predicting next time step experiments found ﬁrst works slightly better. many ways could extend work. first would like apply wider range streaming tasks. although focus insider threat underlying model offers domain agnostic approach anomaly detection. experiments lstm performed equivalently suspect lstm yield superior performance applied large-scale real-world problems complicated temporal patterns. ities times. current work aggregates features individual users day; potential miss anomalous patterns happening within single day. again lstm model greatest potential generalize model could applied individual events log-lines using hidden state memory detect anomalous sequences actions. would reduce eliminate feature engineering required aggregate count-style features. could also dramatically narrow individual events analyst must inspect determine whether anomalous behavior constitutes insider threat. research described paper part analysis motion initiative paciﬁc northwest national laboratory. conducted laboratory directed research development program pnnl multi-program national laboratory operated battelle u.s. department energy supported part u.s. department energy ofﬁce science ofﬁce workforce development teachers scientists visiting faculty program", "year": 2017}