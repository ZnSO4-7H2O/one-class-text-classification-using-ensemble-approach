{"title": "An Integrated Classification Model for Financial Data Mining", "tag": ["cs.AI", "cs.LG"], "abstract": "Nowadays, financial data analysis is becoming increasingly important in the business market. As companies collect more and more data from daily operations, they expect to extract useful knowledge from existing collected data to help make reasonable decisions for new customer requests, e.g. user credit category, churn analysis, real estate analysis, etc. Financial institutes have applied different data mining techniques to enhance their business performance. However, simple ap-proach of these techniques could raise a performance issue. Besides, there are very few general models for both understanding and forecasting different finan-cial fields. We present in this paper a new classification model for analyzing fi-nancial data. We also evaluate this model with different real-world data to show its performance.", "text": "abstract. nowadays financial data analysis becoming increasingly important business market. companies collect data daily operations expect extract useful knowledge existing collected data help make reasonable decisions customer requests e.g. user credit category churn analysis real estate analysis etc. financial institutes applied different data mining techniques enhance business performance. however simple approach techniques could raise performance issue. besides general models understanding forecasting different financial fields. present paper classification model analyzing financial data. also evaluate model different realworld data show performance. today deluge financial datasets. large sizes data sources possible human analyst come interesting information used decision making process. global competitions dynamic markets rapid development information communication technologies major challenges today’s financial industry. instance financial institutions constant needs data analysis becoming large complex. amount data available constantly increasing ability process becomes difficult. efficient discovery useful knowledge datasets therefore becoming challenge massive economic need. hand data mining process extracting useful often previously unknown information so-called knowledge large data sets. mined knowledge used various applications market analysis fraud detection churn analysis etc. also proven effective profitable analyzing financial datasets however mining financial data presents special challenges; complexity external factors confidentiality heterogeneity size. data miners' challenge find trends quickly valid well recognize time trends longer valid. besides designing appropriate process discovering valuable knowledge financial data also complex task. different techniques proposed literature data analyzing various financial applications. instance decision-tree first-order learning used stock selection. neural networks support vector machine techniques used predict bankruptcy nearest-neighbors classification fraud detection. users also used techniques analyzing financial time series imputed financial data outlier detection etc. different businesses different behavior-response mapping relationships find universal fitting model every particular field time-consuming impossible common approach mining financial data classification capable adapting different business area needed. indeed financial dataset always large building universal model classification usually impracticable. hybrid parallel models particular financial dataset developed. however common structure follow financial dataset feature e.g. categorical attributes summarized concepts whose rules uncertain classification task. contrary numerical data usually process unified field. thus need approach minimize using nominal attribute logically seeking optimal model classification help business instant decision making e.g. credit risk analysis customer churn prediction house price rank instant notification etc. paper propose hybrid classification process understand forecast financial datasets also gain useful structural knowledge e.g. significant nominal groups tightness groups. also evaluate model real-world datasets. indeed present capacity model parallel computing paradigm speed training analyzing process. rest paper organized follows. section present technique background paper related work. next section describe combined model financial dataset classification. show criteria partitioning evaluation scheme designed model section experiments analysis given section finally summarize work cite future work last section. section evaluate traditional data mining techniques widely used analyzing financial datasets decision tree bayes network clustering neural networks gaussian process next resume related work context. decision tree. popular decision tree model greedily chooses largest information gain ratio build. however small perturbations dataset probably cause considerable difference produced decision tree. pruning used avoid overfitting there’s theoretically guarantee efficiency. moreover -way growth numerical attribute inefficient. bayes network probabilistic graphical model representing conditional dependencies directed acyclic graph efficient learning paralleled easily. however universally accepted best training method involves expert decide explainable causal influences. clustering. business clustering used instance segment customers number groups additional analysis marketing strategy. clustering also drawbacks e.g. traditional clustering k-means clustering handle numerical attributes weak computing accurate behavior-response mapping relationship since training unsupervised dropping targets. neural networks. multi-layer perceptron handle complex classification problem however cons clear prior idea optimal size hidden layer. small setting produce poor network potential over-generalizing. large setting cause slow training many hypeplane actually coincide training over-fitting problem. gaussian process. contrasts giving guess class label gaussian process gives class probabilities output. gaussian process classification equals hidden layer infinite number hidden neurons. tractable exact inference feasible latent function posterior obtained laplace approximate inference second order taylor expansion newton’s method. possibilities classes binary classification symmetrical. paper discriminative approach used model target possibility function stands class contrast class latent function. financial dataset always large building universal model classification usually impracticable accurate. hybrid models financial dataset developed e.g. hybrid model includes uses rule learners decision lists decision tree association rules. however mainly replies nominal labels; uses decision tree genetic algorithm based hybrid model. handle small disjunct small number training examples. mixes genetic algorithms optimize feature subset parameters svm. however svms handle numerical attributes binominal labels; integrates financial ratios intellectual capital ratios neural network. however involves numerical ratios common structure importantly follow financial dataset features e.g. categorical attributes summarized concepts whose rules uncertain classification task missing record branches/companies/periods. contrary numerical data usually devices unified field. thus need common approach minimize using nominal attribute logically seeking optimal model classification help business instant decision making e.g. credit risk analysis customer churn prediction house price rank instant notification etc. section present application data mining techniques structural understanding forecasting financial dataset differently scaled attributes consists nominal numerical attributes assuming similar behaviorresponse clusters exist. training forecast processes shown derive scheme g-km-nc. model consists three parts stands grouping; stands k-means clustering particular group. stands non-linear classifier technique e.g. omitted group tight vision clustering criteria discussed section first dataset grouped nominal attribute largest gain ratio without concerning attribute dependency. however gain ratio based decision tree replace single attribute grouping dependency relationship known. grouping helps analyst name significant nominal property helping classification. second grouped datasets normalized km-nc sub-model. grouped datasets clustered k-means clustering second-order paralleling computing grouping detailed structural knowledge grouped dataset upon usage statistical methods used. centroids stored forecast. first corresponding nominal group found data example normalized according preprocessing scheme used training group. second closest cluster km-nc found finding closest centroid data example. where vinput input centroid cluster. lastly data example normalized according preprocessing scheme closest cluster non-linear classifier outputting result. information gain normalized decision tree prompt wide subtree. order compensate this quinlan suggests using gain ratio defined besides well-known internal criterion davies-bouldin index used evaluate clustering. smaller value gives significant clustering. present gain ratio well evaluate grouping clustering model section produces class output without possibility forecasted class class output otherwise forecasted class class besides produces possibility guess binary classification situation possibility classes regard forecasted class class output otherwise class accuracy nonlinear classifiers order evaluate model perform four main experiments. first four universal non-linear classifiers decision tree bayes network gaussian process carried different datasets. compare performance model. next evaluate grouping part model performance proposed model shown third experiments. finally also test scalability model speedup performance. three well-known datasets belonging different financial topics tested paper. german credit dataset uses fold cross validation form training cases validation cases. churn dataset provides training validation examples phone number feature dropped since unique every customer contains useful info. house price dataset uses fold cross validation well consists training cases validation cases. structure x-y- indicates input neurons hidden layer neurons optimal priori. linear logistic function activation function interval/golden section search based conjugate gradient optimization give validation performances universal nonlinear classifiers baseline performances bayes network gpc. picks optimal hidden layer size experiments avoid overfitting under-fitting. churn dataset house price dataset omitted since complexity makes training impracticable. numerical attributes datasets. table models using nominal labels always outperform numerical models test grouping using nominal attribute. structure g-nc. hidden layer size among grouped datasets assumption grouped datasets nominal attribute spatial distributive complexity. table notice quality grouping understanding behavior financial dataset related gain ratio nominal attribute. gainratio forecast capability tends improve. gainratio grouping usually improve forecast. higher gainratio indicates better grouping model generally. threshold figuring grouping nominal attribute significant pointless classification gpc. moreover performance optimal close good g-gpcs outperform universal models. churn dataset house price dataset used confirm grouping process. since complexity high test datasets. table churn section grouping attribute helps improve predictive capability churn dataset grouping attribute keeps accuracy gainratio house price section phenomenon listed. gmlps gainratio>. least draw best universal models. indeed grouping g-km-nc model gives first order parallel ability. nominal attribute dependency known reasonable group dataset multilayer decision tree. gain ratio distinguishes important noncritical features information measure feature selection according grouping outperforms universal models validation accuracy also disperses computing pressure either gpc. next discover inner distribution structure within grouped dataset gain structural knowledge financial dataset. k-means clustering used exclude much noise since recorded financial examples trusted generally. furthermore k-means clustering paralleled table nominal labels attribute german dataset numbers brackets numbers test cases group cross validation. lowest dbis give best accuracies groups since lower gives lower average similarity clusters indicating significant clustering. however appropriate universal threshold clustering significance business varies. g-km-nc discards areas clusters exchange parallel performance improvement extricates mutual interference classification surfaces different clusters. g--gpc gives best accuracy thus german dataset results churn house price dataset listed table international plan attribute churn dataset central attribute house price dataset. since datasets large impracticable used nonlinear classifier optimal hidden layer size brackets assuming clusters group distribution complexity. g--mlp churn dataset gets overall accuracy g--mlp house price dataset gets accuracy. three models outperform basic universal model. rouped dataset clustering gives second order parallel ability dispersing computing pressure further. gives detailed structure groups. clustering improves validation accuracy clustered lowest dbi. lowest obvious indicates group tight cannot partitioned like ca=n group house price. lowest obviously exists clustering higher illogical reduce predictive capability. suggested group large optimal obviously exists clustering otherwise skip high complexity dominated cholesky decomposition computations number training data samples. becomes impractical train universal dataset large. grouping clustering partitions dataset sub-datasets expected complexity thread lowers overall complexity times parallel threads. g-km-mlp reduces training complexity thread. experiments computers intel core memory cores. results table show model scalable greatly improves performance nonlinear classifier multi-threading paradigm. paper present integrated classification model g-km-nc helping analyzing different financial datasets referenced practical data mart storage cognitive need group/cluster structure. model combined different data mining techniques grouping based gain ratio clustering non-linear classification evidence g-km-nc outperforms single-technique based universal model presented efforts made reduce computing complexity paralleling logically. model expert understand financial dataset structurally also gain good forecast capability. g-kmnc model flatter compared fixed structure whose structure different different fields lightweight universal accurate universal classifier techniques mentioned paper uses single nominal attribute instead ones. g-kmgpc outperforms g-km-mlp providing class possibility class forecast need priori knowledge. main drawback complexity. explore precise scope g-km-gpc model introduce stacked generalization lower computational burden find scalable scheme. indeed also show g-km-nc gives good parallel structure classifying financial datasets. multi-threading approach scalable analyzing large datasets high performance platforms designed model well suitable used star schema business data mart tell dimension tables meaningful predicting others not. however practical data mart size business companies banks indicates g-km-gpc method suits small business environment. future work includes hierarchical grouping larger dataset requires dependency knowledge particular field hierarchical clustering explores inner sub-structure clustered datasets.", "year": 2016}