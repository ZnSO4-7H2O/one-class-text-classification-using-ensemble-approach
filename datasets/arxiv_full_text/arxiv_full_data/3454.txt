{"title": "Generative Models of Visually Grounded Imagination", "tag": ["cs.LG", "cs.CV", "stat.ML"], "abstract": "It is easy for people to imagine what a man with pink hair looks like, even if they have never seen such a person before. We call the ability to create images of novel semantic concepts visually grounded imagination. In this paper, we show how we can modify variational auto-encoders to perform this task. Our method uses a novel training objective, and a novel product-of-experts inference network, which can handle partially specified (abstract) concepts in a principled and efficient way. We also propose a set of easy-to-compute evaluation metrics that capture our intuitive notions of what it means to have good visual imagination, namely correctness, coverage, and compositionality (the 3 C's). Finally, we perform a detailed comparison of our method with two existing joint image-attribute VAE methods (the JMVAE method of Suzuki et.al. and the BiVCCA method of Wang et.al.) by applying them to two datasets: the MNIST-with-attributes dataset (which we introduce here), and the CelebA dataset.", "text": "easy people imagine pink hair looks like even never seen person before. call ability create images novel semantic concepts visually grounded imagination. paper show modify variational auto-encoders perform task. method uses novel training objective novel product-of-experts inference network handle partially speciﬁed concepts principled efﬁcient way. also propose easy-to-compute evaluation metrics capture intuitive notions means good visual imagination namely correctness coverage compositionality finally perform detailed comparison method existing joint image-attribute methods bivcca method wang applying datasets mnist-with-attributes dataset celeba dataset consider following two-party communication game speaker thinks visual concept black hair generates description concept sends listener; listener interprets description creating internal representation captures meaning. think representing mental images depict concept test whether listener correctly understood concept draw real images depict concept sends back speaker checks images correctly match concept call process visually grounded imagination. paper represent concept descriptions terms ﬁxed length vector discrete attributes allows specify exponentially large concepts using compact combinatorial representation. particular specifying different subsets attributes generate concepts different levels granularity abstraction. arrange concepts compositional abstraction hierarchy shown figure directed acyclic graph nodes represent concepts edge node parent added whenever drop attributes child’s concept deﬁnition. note dont make assumptions order attributes dropped thus tree shown ﬁgure subset extracted full concepts shown illustration purposes. describe concept creating attribute vector specify value attributes subset remaining attributes unspeciﬁed assumed take possible legal values. example consider following concepts order increasing abstraction cmsb c∗sb c∗∗b attributes gender smiling hair color represents don’t care. good model able generate images different levels abstraction hierarchy shown figure figure compositional abstraction hierarchy faces derived attributes hair color smiling gender. show sample images generated model trained celeba different nodes hierarchy. section show extend variational autoencoder framework kingma welling create models perform task. ﬁrst extension modify model multi-modal setting image attribute vector precisely assume joint generative model form prior latent variable image decoder description decoder. additionally assume description decoder factorizes speciﬁed attributes extend devising novel objective function call telbo training model paired data however test time allow unpaired data hence three inference networks embed image description shared latent space respectively); lets translate images descriptions vice handle abstract concepts method based product experts particular inference network attributes attributes speciﬁed posterior equal prior. condition attributes posterior becomes narrower corresponds specifying precise concept. enables generate diverse images represent abstract concepts less diverse images represent concrete concepts show below. section discusses evaluate performance method objective way. speciﬁcally ﬁrst ground description generating images check sampled images consistent speciﬁed attributes also check images spans extension concept exhibiting suitable diversity concretely check attributes speciﬁed vary across different images; call coverage. finally want images high correctness coverage even concept combination attribute values seen training. example train cmsb able test cmnb call property compositionality. able generate plausible images response truly compositionally novel queries essence imagination. together call criteria visual imagination. section reports experimental results different datasets. ﬁrst dataset modiﬁed version mnist call mnist-with-attributes render modiﬁed versions single mnist digit canvas varying location orientation size. contributions paper threefold. first present novel extension vaes multimodal setting introducing principled training objective deriving interpretation previously proposed objective valid alternative appendix second present novel handle missing data inference networks based product experts. third present novel criteria evaluating conditional generative models images extends prior work considering notion visual abstraction imagination. standard vaes. variational autoencoder latent variable model form pθpθ prior although assumption relaxed) likelihood usually represented neural network. perform approximate posterior inference inference network form maximize empirical distribution elbo evidence lower bound kullback leibler divergence distributions default case write elbo. however using encourage posterior closer factorial prior encouarges latent factors disentangled proved achille soatto known β-vae trick allowing useful later multiple modalities. joint vaes telbo. extend model images attributes deﬁning joint distribution pθpθpθ image decoder attribute vector. corresponding training objective want maximize becomes empirical distribution derived paired data joint elbo given call jvae model. usually λy/λx scale likelihood dimensional attribute vector match likelihood high dimensional image joint model above proceed train unpaired inference networks embed images attributes shared latent space. keeping family ﬁxed joint model natural objective maximize following figure illustration product experts inference network. expert votes part latent space implied observed attribute. ﬁnal posterior intersection regions. attributes observed posterior narrowly deﬁned gaussian attributes missing posterior broader. right illustrate inclusion universal expert product ensures posterior always well-conditioned even missing attributes. scale likelihood terms parameters using validation set. since training generative model aligned data simply retroﬁtting inference networks freeze terms training last elbo terms above optimize terms. enables optimize terms equation jointly. alternatively ﬁrst joint model unimodal inference networks. section compare methods training joint vaes proposed literature. handling missing attributes. order handle missing attributes test time product experts model attribute instantiates expert. motivated prior work shows linear factor analysis model posterior distribution product k-dimensional gaussians visible dimension. since model nonlinear extension factor analysis choose form approximate posterior inference network product gaussians gaussian expert prior. similar model concurrently proposed bouchacourt perform inference images. unlike product experts model model multiplies gaussians bernoullis observed attributes. intuitively imposes increasing number constraints observed explained williams agakov setting observe attributes posterior reduces prior. observe attributes posterior becomes narrower since precision matrices reﬂecting increased speciﬁcity concept speciﬁed illustrated figure always include prior term product since without posterior well-conditioned missing attributes illustrated figure implementation-level details model architectures appendix attribute classiﬁer trained large dataset images attributes held constant across methods evaluated. plays role human observer. similar spirit generative adversarial networks declare generated image good enough binary classiﬁer cannot distinguish real image. related evaluating generative image models terms likelihood.) however attribute classiﬁer checks images look realistic also desired attributes. quantify this deﬁne correctness fraction attributes generated image match speciﬁed concept’s description correctness yk). however also want measure diversity values unspeciﬁed missing attributes comparing empirical distribution values attribute induced generated true distribution attribute induced training set. measure difference distributions using jensen-shannon divergence since symmetric satisﬁes k∈m). desired deﬁne coverage follows coverage combine correctness coverage single number computing divergence attributes where observed attributes delta function empirical distribution gives convenient pick hyperparameters. however analysis helpful report correctness coverage separately. high inception score means distribution entropy generated images match class marginal high entropy images diverse. however inception score created evaluate unconditional generative models images check generated images consistent concept degree diversity vary response level abstraction concept. finally assess well model understands compositionality checking correctness generated images response test concepts differ least attribute training concepts. call compositional split data. much harder standard split since asking model predict effects novel combinations attributes seen note abstraction different compositionality abstraction asking model predict effects dropping certain attributes instead predicting novel combinations attributes. conditional models. many conditional generative image models form proposed recently class label vector attributes sentence another image etc. models usually based vaes gans. however interested learning shared latent space either descriptions images means need joint symmetric model. eqφy term requires sampled good generating different xn’s co-occur show empirically section problem partially compensated increasing reduces penalty required ensure broad distribution good coverage concept. jmvae objective suzuki form elboλ−α ﬁrst glance forcing close seems undesirable since latter typically close delta function since little posterior uncertainty image however appendix results hoffman johnson show aggregated posterior induced images qavg associated description ensures cover embeddings images associated concept however since term diversity samples slightly reduced novel concepts compared telbo show empirically section side beneﬁt using aggregated posterior inference network expect sharper images ensures sample seen image decoder joint training. aggregated posterior exactly match prior regularizing respect prior generate samples parts space seen image decoder potentially lead less correct samples. again empirical ﬁndings section conﬁrm tradeoff correctness coverage implicit choices telbo jmvae. scan method higgins ﬁrst standard β-vae model unlabeled images maximizing second maximizing similar jmvae since matching pair images labels. important difference however scan treats attribute vectors atomic symbols; advantage need handle missing inputs disadvantage cannot infer meaning unseen attribute combinations test time unless taught paired images. also rely compositionality assuming disentangled latent space sufﬁce. however appendix show unsupervised learning latent space given images alone result poor results attributes compositional concept hierarchy non-visual parity mnist digit. approach always takes labels consideration learning latent space permitting well-organized latent spaces even presence non-visual concepts handling missing inputs. conditional generative models images form problems missing input attributes inference networks vaes. hoffman uses mcmc latent gaussian model principle handle missing data; however initializes markov chain posterior mode computed inference network cannot easily handle missing inputs. approach joint model estimate impute missing values follows maxym models dependencies attributes. sample images using approach used handle case pixels passed inference network observed. however conditioning imputed value give different results conditioning missing inputs; latter increase posterior uncertainty order correctly represent less precise concepts broader support. gaussian embeddings. many papers embed images text points vector space. however want represent concepts different levels abstraction therefore want images text regions latent space. prior works gaussian embeddings words sometimes conjunction images method differs approaches several ways. first maximize likelihood pairs whereas methods learn gaussian embedding using contrastive loss. second formulation ensures covariance posterior adaptive data condition particular becomes narrower observe attributes property shared embedding methods. abstraction compositionality. young represent extension concept terms images whose captions match phrase. contrast parametric probability distribution latent space generate images. vendrov order embeddings explicitly learn subsumption-like relationships learning space respects partial order. contrast reason generality concepts uncertainty induced latent representation. work compositionality language/vision literature johnson agrawal none papers generative models arguably much stringent test whether model truly understood meaning components composed. section jvae model different datasets using telbo objective well bivcca jmvae. measure quality resulting model using show method handling missing data behaves qualitatively reasonable way. dataset. section report results mnist-a dataset. created modifying original mnist dataset follows. ﬁrst create compositional concept hierarchy using discrete attributes corresponding class label location orientation size thus xxx= unique concepts total. sample example images concept create compositional split data. appendix details. models algorithms. train jvae model dataset using telbo bivcca jmvae objectives. adam optimization learning rate minibatch size train models steps models typically take around train nvidia titan gpus. image models dcgan architecture radford generated images size radford attribute models mlps. joint inference network combined mlp. latent dimensions models. choose hyperparameters method maximize js-overall overall measure correctness coverage validation attribute queries. appendix details model architectures. figure samples attribute vectors seen training time generated different models. plot posterior mean pixel caption little image predicted attribute values. border generated image attributes predicted incorrectly. orientation location. consequently reliable assess quality samples various generative models compute correctness coverage dataset coverage comp dataset. familiar concrete concepts. start assessing quality models simplest setting test concepts fully speciﬁed concepts seen training figure shows correctness scores three methods. telbo correctness close jmvae methods signiﬁcantly outperform bivcca gain insight figure shows samples methods leaf concept chosen random. images generated bivcca blurry reasons discussed section note blurry images correctly detected attribute classiﬁer. also jmvae samples look good samples telbo also good although error figure show quantitaive results mnist-a. qualitative results mnist-a various queries. reﬁned/fully speciﬁed queries telbo jmvae produce good correctness i.e. images produced follow constraints placed speciﬁed attributes. attribute ‘orientation’ unspeciﬁed telbo produces upright counter clockwise digits jmvae produces clockwise upright digits. finally leave digit unspeciﬁed telbo appears generate diverse digits jmvae produces novel abstract concepts. next assess quality models test concepts abstract i.e. attributes speciﬁed. figure shows correctness scores jmvae seems drop somewhat although remains steady telbo bivcca. also coverage telbo higher methods regularizer discussed section figure illustrates methods respond concepts different levels abstraction. samples telbo seem diverse consistent numbers figure compositionally novel concrete concepts. finally assess quality models test concepts fully speciﬁed seen figure shows quantitative results. correctness telbo jmvae dropped since task much harder requires strong generalization. however before telbo jmvae outperform bivcca correctness appendix qualitative results details. section report results celeba dataset particular version used perarnau selects visually distinctive attributes generate images size appendix details celeba dataset appendix details model architectures. figure shows sample qualitative results. left show images generated three methods given concept shown left column. telbo jmvae generate realistic diverse images. generated images generally males mouth slightly open smiling attributes present images. hand bivcca generates mean image. bottom left show happens drop attributes thus specifying abstract concepts. drop gender mixture male female images telbo jmvae. going further drop smiling attribute samples comprise people smiling well smiling mixture genders samples. further greater diversity samples also notice slight drop image quality appendix qualitative examples celeba. right show examples visual imagination models generate images concept bald female occur training set. telbo jmvae sometimes fairly reasonable finally bottom right illustrates interesting bias dataset model generate images specify value eyeglasses attribute nearly samples fail included glasses since prior probability attribute rare section demonstrate initial results show imagination models used concept naming task assign label images illustrating concept depicted images. similar problem studied previous work tenenbaum tenenbaum studies naming problem integers show construct likelihood function given hypothesis capture notions minimal/smallest hypothesis explains observed samples set. extend approach concept-naming images incorporating perceptual uncertainty using confusion matrix weighted likelihood term. approach ﬁrst extracts labels image performs concept naming test well generative model able generalize concept naming without ever performing explicit classiﬁcation images. figure sample celeba results. left show attributes speciﬁed present absent generating images. middle show samples generated telbo jmvae bivcca. telbo jmvae genreate better samples bivcca collapses mean. middle bottom show samples telbo jmvae response queries unspeciﬁed attributes approaches generate samples generalizing meaningfully across unspeciﬁed attributes. detail problem setup concept naming follows given input images corresponds concept compositional abstraction hierarchy figure task assign label images. challenges concept learning understand generalize concept hierarchy given limited number positive examples given small images top-left corner bottom-right corner must infer concept opposed top-left. words wish least common ancestor corresponding images given number images consistent set. consider heuristic solutions problem concept-latent approach instead working observed space work latent space. pick miny kl|q) approximated mixture gaussians. divergence computed mnist-a dataset concept naming studies. consider fully speciﬁed attribute labels mnist-a hierarchy consider differrent patterns missingness dropping attributes. speciﬁcally ignore case attribute speciﬁed consider uniform distribution rest patterns missingness. fully speciﬁed attribute pattern split mnist-a sample four missingness patterns repeat across fully speciﬁed attributes form bank candidate names model must choose. randomly select three subsets candidate names form query concept naming namely tuples speciﬁcally given images eval concept form using randomly sampled subset images. report accuracy metric measuring often selected concept matches ground truth concept across three different splits datapoints. figure qualitative illustration examples concept naming models. top-left example sample correctly named concept-nb model. however concept-nb model strong often gets simple concepts digits incorrect making mistakes example likely concept-nb approach reasons \"meaningful\" dimensional latent variable sampling distribution high dimensional space images. concept-latent model able better images classify concept finally show failure case model incorrectly classiﬁes digits large ignores fact digits top-left. evaluate best versions telbo jmvae bivcca split mnist-a concept naming general concept-nb approaches perform signiﬁcantly worse concept-latent approaches. example best concept-nb approach gets accuracy around concept-latent using jmvae gets general numbers better random chance baseline would picking frequent fully-speciﬁed depicted across image gets figure shows qualitative examples concept-nb well concept-latent models concept classiﬁcation. observe concept-latent models much powerful using concept-nb terms naming concept based positive examples support set. shown create generative models imagine compositionally novel concrete abstract visual concepts. future would like explore richer forms description beyond attribute vectors natural language text well compositional descriptions scenes require dealing variable number objects. would like thank hernan moraldo help writing jvae library alex alemi valuable insights telbo jmvae sergio guadarrama harsh satija numerous discussions around project. finally would like thank devi parikh advice celeba experiments stefan yash goyal feedback initial version draft. diane bouchacourt ryota tomioka sebastian nowozin. multi-level variational autoenaaai coder learning disentangled representations grouped observations. https//www.microsoft.com/en-us/research/wp-content/uploads/ //bouchacourtmlvae.pdf. irina higgins loic matthey arka christopher burgess xavier glorot matthew botvinick shakir mohamed alexander lerchner. beta-vae learning basic visual concepts constrained variational framework. iclr irina higgins nicolas sonnerat loic matthey arka christopher burgess matthew botvinick demis hassabis alexander lerchner. scan learning abstract hierarchical compositional visual concepts. arxiv july yangqing joshua abbott joseph austerweil thomas grifﬁths trevor darrell. visual concept learning combining machine vision bayesian generalization concept hierarchies. nips justin johnson bharath hariharan laurens maaten fei-fei lawrence zitnick ross girshick. clevr diagnostic dataset compositional language elementary visual reasoning. cvpr alec radford luke metz soumith chintala. unsupervised representation learning deep convolutional generative adversarial networks. iclr http//arxiv.org/ abs/.. peter young alice micah hodosh julia hockenmaier. image descriptions visual denotations similarity metrics semantic inference event descriptions. trans. assoc. comp. ling. average posteriors concept posterior indices possible examples given latent code description |qφy term equation tells jmvae encourages inference close average posteriors induced images associated since close delta function essentially requiring cover embeddings images. scale sample scale values gaussian centered standard deviation small sample gaussian centered standard deviation cases reject draw sample values outside range avoid artifacts upsampling problems illegible digits. orientation clockwise label sample amount rotation apply digit gaussian centered degrees standard deviation degrees. anti-clockwise gaussian degrees standard deviation degrees. upright rotation degrees always. location location place gaussians centers four quadrants image apply offset image_size/ shift centers towards corresponding corners. standard deviation image_size/ sample locations centers digits. reject draw sample location center would place extremities digit outside canvas. repeat process sampling labels applying corresponding transformations generate images times image original mnist dataset. trial samples labels uniform categorical distribution sample space corresponding attribute. thus mnist-a dataset images original mnist dataset images. split images train test data respectively create split. create compositional split split xxx= possible label combinations sample train/val/test split giving splits dataset non-overlapping label combinations. figure visualization beneﬁt semantic annotations learning good latent space. small digit single sample generated corresponding point latent space. β-vae images without annotations. color point inferred looking attributes training image maps point space using note region almost existent. joint-vae images annotations. color point inferred β-vae higgins approach aims learn disentangled latent spaces. modifying elbo objective scales term factor gives rise disentangled spaces since prior factorized details). however learn latent spaces correspond high level concepts sufﬁcient need labeled data well. illustrate this experiment learn latent space standard mnist digit images replace label binary attributes parity magnitude call dataset mnist-bit. figure show results ﬁtting β-vae model images mnist-bit ignoring attributes. perform hyperparameter sweep pick gives best looking latent space point latent space show single image sampled derive colors point latent space proceed follows embed training image latent space computing associate label point space. derive label arbitrary point lookup closest embedded training image distance space) corresponding label. latent space useful autoencoding capture relevant semantic properties parity magnitude. fact argue forcing model learn latent space captures high level conceptual properties images alone. figure show results ﬁtting joint model mnist-bit optimizing elbo images attributes elbo terms experiment.) color codes derived rather using nearest neighbor retrieval. latent space autoencodes well also captures relevant types concepts. particular regions convex linearly seperable facilitates learning good imagination function interpolation retrieval latent-space tasks. skeptic might complain created arbitrary partitioning data unrelated appearance objects learning concepts therefore unnatural. consider agent interacting environment touching digits screen. suppose amount reward depends whether digit touch small even. environment would useful agent structure internal representation capture concepts magnitude parity rather terms level visual similarity. showed pigeons learn simple numerical concepts magnitude rewarding exactly this) language considered realization concepts enables agents share useful information common environments easily. details neural network architectures explained main paper joint graphical model inference networks thus overall model made three encoders decoders across models exponential linear unit leaky non-linearity often used train vaes. explain architectures detail below. mnist-a model architecture label decoder label decoder assumes factorized output space individual attribute. parameterize two-layer hidden units each. apply small amount regularization weight matrices. image label encoder architecture image-label encoder ﬁrst separately processes images labels concatenates downstream network passes concatenated features multi-layered perceptron. speciﬁcally convolutional layers process image feature maps strides corresponding layers. batch normalization convolutional layers applying non-linearity. label encoder side ﬁrst encode attribute label continuous vector pass individual attribute vector -layered hidden dimensions each. example mnist-a attributes gives vectors concatenate vectors pass layer mlp. finally concatenate label feature image feature convolutional layers pass result layer predict mean standard deviation latent space gaussian. following standard practice predict standard deviation order values positive. figure architecture network jvae models mnist-a. images class possible values scale possible values orientation possible values location possible values. image encoder image encoder uses architecture process image image feature extractor network described above. conv-features pass result -layer latent state mean standard deviation vectors following procedure described above. label encoder label encoder part architecture uses design choices process labels label encoder part network. obtaining concatenated label feature vectors pass result -layered hidden dimensions ﬁnally obtain mean values dimension latent state vae. mnist-a observation classiﬁer model next describe architecuture observation classiﬁer evaluating mnist-a dataset. observation classiﬁer convolutional neural network ﬁrst convolutional layer ﬁlters size channels followed pooling layer applied stride followed another convolutional layer ﬁlter size output channels. followed another pooling layer stride this network four heads single hidden layer dropout applied activations. ﬁnal layer outputs logits classifying attribute corresponding categorical labels associated train model scratch mnist-a dataset using stochastic gradient descent batch size learning rate celeba model architecture design choices celeba closely mirror models built mnist-a. primary difference latent dimensionality celeba experiments matches number attributes model. meanwhile architectures image encoder image decoder exactly identical described mnist-a execept encoders take input -channel image decoders produce -channel output. replace bernoulli likelihood quantized normal likelihood terms label encoder follow figure quite closely except input categorical class labels input process labels single hidden layer concatenation hidden layers post concatenation finally joint encoder based heavily figure feed input labels opposed process single layer concatenate them pass result hidden layer point concatenate result image feature image feature head figure finally process feature another single hidden layer produce values. figure shows images sampled telbo model trained mnist-a. also shows attributes predicted attribute classiﬁer. classiﬁer often produces reasonable results humans would also agree with. thus acts reasonable proxy humans classifying labels generated images. discuss hyperparameter choices different objectives impact performance mnist-a dataset. across objectives vary addition also discuss private hyperparamter choices loss telbo jmvae wang bivcca affect performance. js-overall metric picking hyperparameters explained main paper. effect search values objectives. general setting elbo terms critical good performance example correctness numbers best performing telbo model drop λy=) validation figure randomly sampled images telbo model randomly sampled concepts training set. also show outputs observation classiﬁer images. note visualize mean images classiﬁer samples model. figure best viewed zooming figure compositional generalization mnist-a. models given unseen compositional query shown three columns shows mean image distribution generated models. images marked observation classiﬁer detected incorrect. also show classiﬁcation result observation classiﬁer image. telbo jmvae really well bivcca substantially poorer. queries. similar trends observed jmvae bivcca objectives well seen qualitative evidence shows likelihood scaling affects disentangled latent space along speciﬁed attributes. latent space grouped organized high-level attributes posterior distribution given concept multimodal hard gaussian inference network capture. leads poor correctness values. effect addition scaling term common across objectives telbo scaling factor controls scale term elboγ term. sweep values parameter. general effect term smaller performance term. based setting parameter that example correctness values fully speciﬁed queries change validation queries. effect generally works best jmvae across different choices explored wang namely example decreasing value reduces correctness fully sepciﬁed queries respectively validation queries. effect bivcca search running training experiment four times picked best hyperparameter choice across runs. found best value however performance difference across different choices large. intuitively higher values lead improved performance compared lower values lower values mean weight elbo term inference network inference network results sharper samples. next show examples compositional generalization mnist-a validation queries. compositinal experiments reused parameters best models splits models trained models iterations. design choices same. figure shows qualitative results. celeba consists face colored images attribute binary vectors. version dataset used uses subset visually distinctive attributes preprocesses image aligned cropped scaled figure telbo creates diverse images jmvae. show attributes present absent input query. below show results generation attributes speciﬁed drawing samples each. telbo jmvae create accurate images satisfying constraints. note concept male absent query celeba means female present. next unspecify whether image contain male female. setting telbo better mixing male female images jmvae produces single male image ofﬁcial train test partitions training testing. note split attribute vectors test occur training even though images people unique. total original dataset attributes speciﬁed unique visual concepts dataset attributes spans different visual concepts. section claim generations bald female images compositionally novel concept. claim comes minor caveat/clariﬁcation concept bald= male= occur training examples incorrect labelings shown figure further images generated model qualitatively different images here showing model memorized examples. finally show qualitative examples performance celeba dataset. focus telbo jmvae objectives here since bivcca generally produces poor samples figure shows example generations concept speciﬁed attributes telbo jmvae produce correct images provided full attribute queries however stop specifying attribute male male telbo provides diverse samples spanning male female ties explanation appendix show |qφy unimodal inference interpret jmvae optimizing since jmvae reasons aggregate posterior opposed prior tendency generate less diverse samples shown unseen concepts.", "year": 2017}