{"title": "Not Just a Black Box: Learning Important Features Through Propagating  Activation Differences", "tag": ["cs.LG", "cs.CV", "cs.NE"], "abstract": "Note: This paper describes an older version of DeepLIFT. See https://arxiv.org/abs/1704.02685 for the newer version. Original abstract follows: The purported \"black box\" nature of neural networks is a barrier to adoption in applications where interpretability is essential. Here we present DeepLIFT (Learning Important FeaTures), an efficient and effective method for computing importance scores in a neural network. DeepLIFT compares the activation of each neuron to its 'reference activation' and assigns contribution scores according to the difference. We apply DeepLIFT to models trained on natural images and genomic data, and show significant advantages over gradient-based methods.", "text": "paper describes older version deeplift. https//arxiv.org/ abs/. version. purported black nature neural networks barrier adoption applications interpretability essential. present deeplift efﬁcient effective method computing importance scores neural network. deeplift compares activation neuron ‘reference activation’ assigns contribution scores according difference. apply deeplift models trained natural images genomic data show signiﬁcant advantages gradient-based methods. neural networks become increasingly popular black reputation barrier adoption interpretability paramount. understanding features lead particular output builds trust users lead novel scientiﬁc discoveries. simonyan proposed using gradients generate saliency maps showed closely related deconvolutional nets zeiler fergus guided backpropagation another variant considers gradients positive error signal. shown figure saliency maps substantially improved simply multiplying gradient input signal corresponds ﬁrst-order taylor approximation output would change input zero; show layer-wise relevance propagradient-based approaches problematic activation functions rectiﬁed linear units gradient zero ﬁring relu still carry information similarly sigmoid tanh activations popular choices activation functions gates memory units recurrent neural networks grus lstms activations near-zero gradient high inputs even though inputs signiﬁcant. figure simple network inputs reference values output gradients w.r.t inactive relu comparing activations reference values deeplift assigns contributions present deeplift method assigning feature importance compares neuron’s activation ‘reference’ reference activation neuron network provided ‘reference input’ addresses limitation gradient-based approaches difference reference non-zero even gradient zero. deeplift method neurons whose activations minimally sufﬁcient compute activation sufﬁcient compute activation layman’s terms full non-redundant inputs following property holds show contributions deﬁned computed using following rules computation reminiscent chain rule used gradient backpropagation equation makes possible start contribution scores later layers contribution scores preceding layers. avoid issues numerical stability particular neuron small rather computing contribution scores explicitly instead compute multipliers that multiplied difference-from-reference give contribution activation functions softmax sigmoid maximum summation property contribution scores individual features lower several redundant features present. example consider default activations inputs however avoid attenuation contribution presence redundant inputs contributions rather cases here ...ayn afﬁne functions inputs. represent neuron input ...ayn wxyi represent coefﬁcient ayi. ay...ayn followed softmax transformation wxyi effectively zero contribution ati. observed substituting wxyiax expression canceling ewxyi mentioned previous subsection order avoid attenuation signal highly conﬁdent predictions compute cxyi rather cxti. ensure cxyi zero wxyi meannormalized weights follows i.e. afﬁne functions input vector given vector activations inputs split segments segment unique afﬁne function dominates maxout coefﬁcient individual input segment wxy. denote fraction ax−a segment have convolutional neuron operating one-hot encoded rows constraint column sees). weights denoted bias advisable normalized weights ¯wxy bias mean wxy. note maintains output neural because constant normalization desirable because afﬁne functions multipliers equal weights thus sensitive take example convolutional neuron operating one-hot encoded rows mean-normalizing column ﬁlter ensure contributions columns systematically overestimated underestimated relative contributions columns. results tiny imagenet model architecture trained using keras framework scaled-down version imagenet dataset dubbed ‘tiny imagenet’. images dimension belonged output classes. results shown figure reference input input zeros preprocessing. apply deeplift models trained genomic sequence. positive class requires patterns ’gata’ ’cagatg’ appear length- sequence together. negative class patterns appearing twice. outside core patterns randomly sample four bases trained using keras framework one-hot encoded sequences convolutional ﬁlters length stride pool layer width stride followed fully connected layers size prelu nonlinearities used hidden layers. model performs well auroc misclassiﬁed examples primarily occur patterns erroneously arises randomly sampled background. importance scores figure comparison methods. channels summed per-pixel importance. left-toright original image absolute value gradient positive gradient*input positive deeplift. deeplift assign importance score base correctly predicted sequences. reference input input zeros post weight-normalization ﬁrst convolutional layer compared results gradient*input figure deeplift scores gradient*input plotted position sequence colored base deeplift discovers patterns assigns large importance scores. gradient-based methods miss gata pattern. discussion prevailing feature importance methods saliency maps simonyan deconvolutional nets zeiler guided backpropagation springenberg variants computing gradients. shown figure give misleading results local gradient zero. deeplift instead considers deviation neuron’s reference activity. makes capable handling memory units gated activations vanishing gradients thus denominator intermediate layer cancelled leaving respect term left denominator activation last layer relevance neurons ﬁnal layer equal activation would cancel simply equal activation multiplied gradient respect situations relevance last layer activation simply compute gradient*input respect linear term ﬁnal nonlinearity nonlinearity backward signal simply propagated onto lower layer ignoring rectiﬁcation operation obviously gradient*input noted rectiﬁed linear unit inactive activation zero rule ﬁltering would assign zero importance. furthermore rectiﬁed linear unit active gradient thus unit inactive gradient*input assigns signal; unit active gradient*input equal output assigns signal. approaches converge. conceived deeplift. implemented deeplift software. application genomics. application tiny imagenet. provided guidance feedback. prepared manuscript. bach obviously rely gradients; however show activations piecewise linear reduces gradient*input reference activations zero deeplift give similar results practice biases often non-zero deeplift produces superior results show activations piecewise linear bias terms included calculation layer-wise relevance propagation bach reduces gradient*input. refer samek concise description unpooling backwards signal redirected proportionally onto location activation recorded forward pass trivially gradient*input gradient*input zero locations activation pooling layer equal output location does. filtering consider ﬁrst rule described samek weighted activation neuron onto neuron next layer index layer term involving included avoid issues numerzij near zero. second rule described samek another variant designed address problem numerical instability. show gradient*input gives exact result references bach sebastian binder alexander montavon gr´egoire klauschen frederick m¨uller klaus-robert samek wojciech. pixel-wise explanations non-linear classiﬁer decisions layer-wise relevance propagation. plos july simonyan karen vedaldi andrea zisserman andrew. deep inside convolutional networks visualising image classiﬁcation models saliency maps. december", "year": 2016}