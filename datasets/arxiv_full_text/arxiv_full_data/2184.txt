{"title": "Larger is Better: The Effect of Learning Rates Enjoyed by Stochastic  Optimization with Progressive Variance Reduction", "tag": ["cs.LG", "cs.AI", "math.OC", "stat.ML"], "abstract": "In this paper, we propose a simple variant of the original stochastic variance reduction gradient (SVRG), where hereafter we refer to as the variance reduced stochastic gradient descent (VR-SGD). Different from the choices of the snapshot point and starting point in SVRG and its proximal variant, Prox-SVRG, the two vectors of each epoch in VR-SGD are set to the average and last iterate of the previous epoch, respectively. This setting allows us to use much larger learning rates or step sizes than SVRG, e.g., 3/(7L) for VR-SGD vs 1/(10L) for SVRG, and also makes our convergence analysis more challenging. In fact, a larger learning rate enjoyed by VR-SGD means that the variance of its stochastic gradient estimator asymptotically approaches zero more rapidly. Unlike common stochastic methods such as SVRG and proximal stochastic methods such as Prox-SVRG, we design two different update rules for smooth and non-smooth objective functions, respectively. In other words, VR-SGD can tackle non-smooth and/or non-strongly convex problems directly without using any reduction techniques such as quadratic regularizers. Moreover, we analyze the convergence properties of VR-SGD for strongly convex problems, which show that VR-SGD attains a linear convergence rate. We also provide the convergence guarantees of VR-SGD for non-strongly convex problems. Experimental results show that the performance of VR-SGD is significantly better than its counterparts, SVRG and Prox-SVRG, and it is also much better than the best known stochastic method, Katyusha.", "text": "paper propose simple variant original stochastic variance reduction gradient hereafter refer variance reduced stochastic gradient descent different choices snapshot point starting point svrg proximal variant prox-svrg vectors epoch vrsgd average last iterate previous epoch respectively. setting allows much larger learning rates step sizes svrg e.g. vr-sgd svrg also makes convergence analysis challenging. fact larger learning rate enjoyed vr-sgd means variance stochastic gradient estimator asymptotically approaches zero rapidly. unlike common stochastic methods svrg proximal stochastic methods prox-svrg design different update rules smooth non-smooth objective functions respectively. words vr-sgd tackle non-smooth and/or non-strongly convex problems directly without using reduction techniques quadratic regularizers. moreover analyze convergence properties vr-sgd strongly convex problems show vr-sgd attains linear convergence rate. also provide convergence guarantees vr-sgd non-strongly convex problems. experimental results show performance vr-sgd signiﬁcantly better counterparts svrg prox-svrg also much better best known stochastic method katyusha convex function formulation arises many places machine learning signal processing data science statistics operations research regularized empirical risk minimization instance popular choice component function binary classiﬁcation problems logistic loss i.e. log) collection training examples ∈{±}. popular choices regularizer include -norm regularizer -norm regularizer elastic-net regularizer +λx) regularization parameters. examples applications include deep neural networks group lasso sparse learning coding phase retrieval matrix completion conditional random ﬁelds eigenvector computation principal component analysis singular value decomposition generalized eigen-decomposition canonical correlation analysis paper especially interested developing efﬁcient algorithms solve regularized problems involving large component functions. standard effective method solving problem gradient descent method including accelerated proximal gradient smooth objective functions update rule commonly referred step-size optimization learning rate machine learning. regularizer non-smooth e.g. -norm regularizer need introduce following proximal operator i=∇fi. methods mentioned proven achieve linear convergence strongly convex problems attains optimal convergence rate non-strongly convex problems denotes number iterations. however per-iteration cost batch methods expensive. instead evaluating full gradient iteration effective alternative stochastic gradient descent method evaluates gradient single component function iteration thus much lower per-iteration cost successfully applied many large-scale learning problems update rule formulated follows index chosen uniformly random although expectation ∇fik unbiased estimation i.e. variance stochastic gradient estimator ∇fik large variance random sampling thus stochastic gradient estimators also called noisy gradients need gradually reduce step size leading slow convergence. particular even strongly convex condition standard attains slower sub-linear convergence rate recently many methods variance reduction techniques proposed stochastic average gradient stochastic variance reduced gradient stochastic dual coordinate ascent saga stochastic primal-dual coordinate proximal variants prox-sag prox-svrg prox-sdca accelerated methods constant step size instead diminishing step sizes fall following three categories primal methods svrg saga dual methods sdca average gradients progressively reduce variance stochastic gradient estimators well dual primal-dual methods leads revolution area ﬁrst-order methods thus also known hybrid gradient descent method semi-stochastic gradient descent method particular strongly convex condition accelerated methods enjoy linear convergence rates overall complexity log) obtain \u0001-suboptimal solution l-smooth µ-strongly convex. complexity bound shows converge signiﬁcantly faster deterministic methods whose complexity ol/µ) log) component functions dual variables. beginning epoch svrg full gradient computed snapshot pointx updated periodically. update rule smooth optimization problem given estimator ∇fik i.e. e∇fik−∇f however non-strongly convex problems accelerated methods mentioned converge much slower batch methods fista namely recently many acceleration techniques proposed speed variance-reduced stochastic methods mentioned above. techniques mainly include nesterov’s acceleration technique used reducing number gradient calculations early iterations projection-free property conditional gradient method stochastic sufﬁcient decrease technique momentum acceleration trick speciﬁcally proposed accelerating catalyst framework achieved complexity onl/µ) log) strongly convex problems. proved accelerated methods attain best known complexity o+nl/\u0001) nonpoint-saga achieve best-known complexity onl/µ) log) strongly convex problems identical upper complexity bound katyusha best known stochastic optimization method strongly convex non-strongly convex problems. proximal gradient update rules formulated follows momentum parameters. eliminate need parameter tuning ﬁxed unfortunately accelerated methods mentioned above including katyusha require least auxiliary variables momentum parameters lead complicated algorithm design high per-iteration complexity discussion accelerated stochastic variance reduction methods applications based stochastic variance reduced gradient method thus improvement svrg important research stochastic optimization. paper propose simple variant original svrg referred variance reduced stochastic gradient descent snapshot point starting point epoch vr-sgd average last iterate previous epoch respectively. different settings svrg prox-svrg points vr-sgd different makes convergence analysis challenging svrg prox-svrg. empirical results show performance vr-sgd signiﬁcantly better counterparts svrg prox-svrg. impressively vr-sgd sufﬁciently large learning rate performs much better best known stochastic method katyusha main contributions paper summarized below. snapshot point starting point vr-sgd different vectors. epochs except particular setting vr-sgd allows take much larger learning rates step sizes svrg e.g. thus signiﬁcantly speeds convergence svrg prox-svrg practice. moreover vr-sgd advantage svrg terms robustness learning rate selection. different proximal stochastic gradient methods e.g. prox-svrg katyusha uniﬁed update rule cases smooth non-smooth objectives vr-sgd employs different update rules cases respectively below. empirical results show gradient update rules smooth optimization problems better choices proximal update formulas finally theoretically analyze convergence properties vr-sgd option option strongly convex problems show vr-sgd attains linear convergence rate. also give convergence guarantees vr-sgd option option non-strongly convex objective functions. preliminary related work throughout paper denote -norm i=|xi|. denotes full gradient differentiable subgradient lipschitz continuous. epoch inner iteration random chosen index. mostly focus case problem component function l-smooth µ-strongly convex. common assumptions deﬁned follows. note regularizer non-smooth inequality needs revised simply replacing gradient arbitrary sub-gradient contrast non-strongly convex general convex function inequality always satisﬁed speed standard proximal methods many variance reduced stochastic methods proposed special cases problem case l-smooth µ-strongly convex roux proposed stochastic average gradient method attains linear convergence rate. however needs store gradients well incremental aggregated gradient methods saga storage required general problems similarly sdca requires storage dual variables scales contrast svrg well proximal variant prox-svrg similar convergence rate sdca without memory requirements gradients dual variables. particular svrg estimator popular choice stochastic gradient estimators. besides stochastic gradient estimators include saga estimator stochastic recursive gradient estimator although original svrg convergence guarantees special case problem l-smooth µ-strongly convex extend svrg proximal setting introducing proximal operator shown line algorithm words non-smooth update rule svrg becomes researchers borrowed variance reduction techniques admm minimizing convex composite objective functions subject equality constraint. applied efﬁcient stochastic solvers compute leading eigenvectors symmetric matrix generalized eigenvectors symmetric matrices. ﬁrst method vr-pca shamir convergence properties vr-pca algorithm non-convex problem also provided. garber analyzed convergence rate svrg convex function non-convex component functions. moreover proved svrg saga minor modiﬁcations converge asymptotically stationary point non-convex ﬁnite-sum problems. distributed variants accelerated methods also proposed. important class stochastic methods proximal stochastic gradient method prox-svrg saga katyusha different standard variance reduction methods svrg section propose efﬁcient variance reduced stochastic gradient descent method iterate averaging. different choices snapshot starting points svrg prox-svrg vectors epoch vr-sgd average last iterate previous epoch respectively. unlike common stochastic gradient methods svrg proximal stochastic gradient methods prox-svrg design different update rules smooth non-smooth objective functions respectively. usually chosen within epoch need compute full gradient snapshotxs deﬁne variance reduced stochastic gradient estimator ∇fikxs epoch vr-sgd average previous epoch e.g.xs gradient noise also suggested fact choice option algorithm i.e. option algorithm leads better robustness also works well practice shown fig. therefore provide convergence guarantees algorithms option algorithms option next section. particular effects choice option option algorithm allow taking much larger learning rates step sizes svrg practice e.g. vr-sgd svrg main reason vr-sgd converges signiﬁcantly faster svrg. actually larger learning rate enjoyed vr-sgd means variance stochastic gradient estimator goes asymptotically zero faster. unlike prox-svrg whose starting point initialized average previous epoch starting point epoch vr-sgd last iterate previous epoch. last iterate previous epoch becomes starting point vr-sgd prox-svrg completely different thereby leading relatively slow convergence general. clear starting point snapshot point epoch original svrg last iterate previous epoch points prox-svrg average previous epoch different settings svrg prox-svrg starting snapshot points vr-sgd different vectors mentioned above makes convergence analysis vr-sgd challenging svrg prox-svrg shown section emphasized noise introduced random sampling inevitable generally slows convergence speed sense. however variants probably used optimization algorithms deep learning particular shown adding noise step noisy gradient descent escape saddle points efﬁciently converge local minimum non-convex optimization problems well application deep neural networks randomly chosen however empirical results suggest option better choice option convergence guarantee svrg option strongly convex objective functions provided fig. comparison vr-sgd option option solving -norm regularized logistic regression ridge regression problems covtype data set. plot vertical axis shows objective value minus minimum horizontal axis number effective passes. note blue lines stand results lines correspond results part propose efﬁcient vr-sgd algorithm solve strongly convex objective functions outlined algorithm well known original svrg works case smooth strongly convex objective functions. however many machine learning applications e.g. elastic regularized logistic regression strongly convex objective function non-smooth. solve class problems proximal variant svrg prox-svrg subsequently proposed. unlike svrg prox-svrg vr-sgd solve smooth objective functions directly tackle non-smooth ones. regularizer smooth e.g. -norm regularizer update rule vr-sgd fig. comparison svrg vr-sgd different learning rates solving -norm regularized logistic regression ridge regression problems covtype data set. plot vertical axis shows objective value minus minimum horizontal axis number effective passes. note blue lines stand results svrg different learning rates lines correspond results vr-sgd different learning rates different proximal stochastic gradient methods prox-svrg uniﬁed update rule smooth non-smooth cases vr-sgd different update rules cases stated leads following advantage prox-sg methods stochastic gradient update rule usually outperforms proximal stochastic gradient update rule well classes update rules katyusha fig. demonstrates vr-sgd signiﬁcant advantage svrg terms robustness learning rate selection. vr-sgd yields good performance within range learning rate whereas performance svrg sensitive selection learning rates. thus vr-sgd convenient apply various real-world problems large-scale machine learning. fact vr-sgd much larger learning rates svrg logistic regression problems practice e.g. vr-sgd svrg shown fig. although many variance reduced stochastic methods proposed them including svrg proxsvrg convergence guarantees case problem objective function strongly convex. however non-strongly convex many machine learning applications lasso -norm regularized logistic regression. suggested class problems transformed strongly convex ones adding proximal term efﬁciently solved algorithm however reduction technique degrade performance involved algorithms theory practice thus present efﬁcient vr-sgd algorithm directly solving non-strongly convex problem outlined algorithm main difference algorithm algorithm setting learning rate. similar algorithm learning rate algorithm also ﬁxed constant. inspired existing accelerated stochastic algorithms learning rate algorithm gradually increased principle leads faster convergence different existing stochastic methods katyusha update rule learning rate algorithm deﬁned follows initial learning rate generally requires additional storage. result epoch requires component gradient evaluations. addition extremely sparse data introduce lazy update tricks algorithms perform update steps non-zero dimensions example rather dimensions. words per-iteration complexity vr-sgd improved sparsity feature vectors. moreover vr-sgd much lower per-iteration complexity existing accelerated stochastic variance reduction methods katyusha least update rules additional variables shown shown mini-batching effectively decrease variance stochastic gradient estimates. part ﬁrst extend proposed vr-sgd method mini-batch setting well convergence results below. here denote mini-batch size inner-iteration m−}. variance reduced stochastic gradient estimator becomes oracle nesterov’s smoothing homotopy smoothing techniques smoothen them thereby obtain smoothed approximations functions addition directly extend algorithms non-smooth setting e.g. algorithm considering component function maybe different degrees smoothness picking random index non-uniform distribution much better choice commonly used uniform random sampling well without-replacement sampling with-replacement sampling done using techniques j=lj. moreover vr-sgd method also combined accelerated techniques proposed svrg. instance epoch length vr-sgd automatically determined techniques instead ﬁxed epoch length. reduce number gradient calculations early iterations leads faster convergence general. moreover also introduce nesterov’s acceleration technique momentum acceleration trick improve performance vr-sgd. section provide convergence guarantees vr-sgd solving smooth non-smooth general convex problems. also extend results mini-batch setting. moreover analyze convergence properties vrsgd solving smooth non-smooth strongly convex objective functions. ﬁrst introduce following lemma useful analysis. part analyze convergence properties vr-sgd solving general non-strongly convex problems. considering proposed algorithms different update rules smooth non-smooth problems give convergence guarantees vr-sgd cases follows. proof lemma included appendix lemma provides upper bound expected variance variance reduced gradient estimator i.e. svrg estimator independently introduced algorithm option ﬁxed learning rate give following result analysis. lemma convex l-smooth following inequality holds proof. order simplify notation stochastic gradient estimator deﬁned since component function l-smooth implies gradient average function also lsmooth i.e. y∈rd lemma theorem proofs convergence analysis different existing stochastic methods svrg prox-svrg algorithm option ﬁxed learning rate give following lemma convergence analysis. lemma convex l-smooth following inequality holds proof theorem found appendix clearly theorems show vr-sgd option option attains sub-linear convergence rate smooth general convex objective functions. means vr-sgd guaranteed similar convergence rate variance reduced stochastic methods saga slower theoretical rate accelerated methods katyusha nevertheless vr-sgd usually converges much faster best known stochastic method katyusha practice next provide convergence guarantee problem objective function non-smooth non-smooth) non-strongly convex. ﬁrst give following lemma. lemma optimal solution problem convex lemma viewed generalization lemma essentially identical corollary lemma hence proof omitted. algorithm option ﬁxed learning rate give following results. lemma convex l-smooth following inequality holds corollaries viewed generalizations lemma theorem respectively hence proofs omitted. obviously theorems corollary show vr-sgd option option attains sublinear convergence rate non-smooth general convex objective functions. hard verify lemma essentially identical theorem hence proof omitted. based variance upper bound lemma analyze convergence properties vr-sgd mini-batch setting. lemma ﬁrst extended mini-batch setting follows. ﬁrst inequality holds young’s inequality second inequality follows lemma substituting inequality inequality taking expectation random mini-batch theorem ﬁrst term right-hand side diminishes. words vr-sgd method degenerates deterministic method convergence rate furthermore theorem degenerates theorem part analyze convergence properties vr-sgd solving strongly convex objective function according analysis convex convex component function l-smooth algorithms converge optimal solution. following provide stronger convergence rate guarantees vr-sgd strongly convex condition. ﬁrst give following assumption. proof theorem found appendix addition also provide linear convergence guarantees algorithm option option solving smooth strongly convex objective functions. results vr-sgd attains linear convergence rate smooth non-smooth strongly convex minimization problems. section evaluate performance vr-sgd method solving various problems logistic regression lasso ridge regression compare performance several related stochastic variance reduced methods including svrg prox-svrg katyusha codes vr-sgd related methods downloaded author’s website. fig. comparison options solving ridge regression problems regularizer plot vertical axis shows objective value minus minimum horizontal axis number effective passes. used four publicly available data sets experiments adult covtype protein sido listed table noted example date sets normalized unit length leads upper bound lipschitz constants i.e. suggested epoch length stochastic variance reduced methods svrg prox-svrg katyusha well vr-sgd method. parameter tune hand step size since katyusha much higher per-iteration complexity svrg prox-svrg vr-sgd compare performance terms number effective passes running time computing single full gradient evaluating component gradients considered effective pass data. fair comparison implemented svrg prox-svrg katyusha vr-sgd matlab interface performed experiments intel ram. addition compare stochastic algorithms saga catalyst shown comparable inferior katyusha fig. comparison options solving lasso problems regularizer plot vertical axis shows objective value minus minimum horizontal axis number effective passes. last iterate average point previous epoch respectively. paper note johnson zhang ﬁrst presented choices options setting option suggested paper. following compare performance three choices snapshot starting points solving ridge regression lasso problems shown figs. except three different settings snapshot starting points update rules ridge regression lasso problems respectively. results shown figs. algorithms option consistently converge much faster svrg choices options strongly convex non-strongly convex cases. indicates setting option suggested paper better choice options stochastic optimization. training examples regularization parameters. note log)+x. formulation includes -norm -norm elastic regularized logistic regression problems. figs. show objective i.e. decreases -norm -norm elastic regularized logistic regression problems respectively. results make following observations. regularization parameters relatively large e.g. prox-svrg usually converges faster svrg strongly convex -norm regularized logistic regression) non-strongly convex -norm regularized logistic regression) cases shown figs. figs. contrary svrg often outperforms prox-svrg regularization parameters relatively small e.g. observed main reason different initialization settings katyusha converges much faster svrg prox-svrg cases regularization parameters relatively small e.g. whereas often achieves similar inferior performance regularization parameters relatively large e.g. shown figs. figs. note implemented original algorithms option katyusha. words katyusha accelerated proximal stochastic gradient method. obviously observation matches convergence properties katyusha provided mµ/l katyusha attains best known overall complexities vr-sgd method consistently converges much faster svrg prox-svrg especially regularization parameters relatively small e.g. shown figs. figs. main reason vr-sgd much larger learning rates svrg vr-sgd svrg) leads faster convergence. veriﬁes setting snapshot starting points algorithms better choice options algorithm particular vr-sgd generally outperforms best-known stochastic method katyusha terms number passes data especially regularization parameters relatively large e.g. shown figs. figs. since vr-sgd much lower per-iteration complexity katyusha vr-sgd obvious advantage katyusha terms running time. algorithms katyusha proposed learning rate katyusha least similarly learning rate used vr-sgd comparable katyusha main reason performance vr-sgd much better katyusha. also implies algorithm enjoys larger learning rates yield better performance. part compare original katyusha algorithm i.e. algorithm slightly modiﬁed katyusha algorithm katyusha-i following update rules smooth objective functions used replace original proximal stochastic gradient update rules similarly also implement proximal versions original svrg proposed vr-sgd methods denote proximal variants svrg-ii vr-sgd-ii respectively. here original katyusha method denoted katyusha-ii. figs. show performance katyusha-i katyusha-ii solving ridge regression problems popular data sets adult covtype. also report results svrg vr-sgd proximal variants. clear katyusha-i usually performs better katyusha-ii converges signiﬁcantly faster case regularization parameter seems main reason katyusha inferior performance regularization parameter relatively large shown section contrast vr-sgd proximal variant similar performance former slightly outperforms latter cases well svrg proximal variant. suggests stochastic gradient update rules better choices proximal stochastic gradient update rules smooth objective functions. also believe insight help design accelerated stochastic optimization methods. katyusha-i katyusha-ii usually outperform svrg proximal variant especially regularization parameter relatively small e.g. shown figs. unfortunately katyusha-i katyusha-ii cannot solve convex objectives without regularization term large small regularization parameters e.g. shown figs. moreover seen vr-sgd proximal variant achieve much better performance methods cases also comparable katyusha-i katyusha-ii remaining cases. veriﬁes vr-sgd suitable various large-scale machine learning. finally compare performance algorithm ﬁxed varied learning rates solving -norm regularized logistic regression lasso problems shown fig. note learning rates algorithm varied according update formula observe algorithm varied step-sizes performs similar algorithm ﬁxed step-sizes cases. remaining cases former slightly outperforms latter. paper proposed simple variant original svrg called variance reduced stochastic gradient descent unlike choices snapshot point starting point svrg proximal variant prox-svrg points epoch vr-sgd average last iterate previous epoch respectively. setting allows much larger learning rates svrg e.g. vr-sgd svrg also makes vr-sgd robust terms learning rate selection. different existing proximal stochastic methods prox-svrg katyusha designed different update rules smooth non-smooth objective functions respectively makes vr-sgd method suitable non-smooth and/or non-strongly convex problems without using reduction techniques contrast svrg prox-svrg cannot directly solve non-strongly convex objectives furthermore empirical results showed smooth problems stochastic gradient update rules better choices proximal stochastic gradient update formulas practical side choices snapshot starting points make vr-sgd signiﬁcantly faster counterparts svrg prox-svrg. theoretical side setting also makes convergence analysis challenging. analyzed convergence properties vr-sgd strongly convex objective functions show vr-sgd attains linear convergence rate. moreover also provided convergence guarantees vr-sgd non-strongly convex problems show vr-sgd achieves sub-linear convergence rate. results imply vr-sgd guaranteed similar convergence rate variance reduced stochastic methods svrg prox-svrg slower theoretical rate accelerated methods katyusha nevertheless various experimental results show vr-sgd signiﬁcantly outperforms svrg prox-svrg still much better best known stochastic method katyusha proof. convenience stochastic gradient estimator deﬁned component function l-smooth implies gradient average function also l-smooth i.e. y∈rd allen-zhu katyusha ﬁrst direct acceleration stochastic gradient methods proc. symp. theory comput. krizhevsky sutskever hinton imagenet classiﬁcation deep convolutional neural networks proc. adv. neural inf. allen-zhu hazan variance reduction faster non-convex optimization proc. int. conf. mach. learn. ouyang tran gray stochastic alternating direction method multipliers proc. int. conf. mach. learn. shang cheng accelerated variance reduced stochastic admm proc. aaai conf. artif. intell. linear convergence svrg statistical estimation arxiv.v paquette drusvyatskiy mairal harchaoui catalyst acceleration gradient-based non-convex optimization duchi ruan stochastic methods composite optimization problems arxiv. recht parallel stochastic gradient algorithms large-scale matrix completion math. prog. comp. vol. zhang wang stochastic variance-reduced gradient descent low-rank matrix recovery linear measurements allen-zhu doubly accelerated methods faster generalized eigendecomposition arxiv.v nesterov method solving convex programming problem convergence rate soviet math. doklady vol. introductory lectures convex optimization basic course. boston kluwer academic publ. tseng accelerated proximal gradient methods convex-concave optimization technical report university washington beck teboulle fast iterative shrinkage-thresholding algorithm linear inverse problems siam imaging sci. vol. robbins monro stochastic approximation method ann. math. statist. vol. zhang solving large scale linear prediction problems using stochastic gradient descent algorithms proc. int. conf. mach. learn. bubeck convex optimization algorithms complexity found. trends mach. learn. vol. rakhlin shamir sridharan making gradient descent optimal strongly convex stochastic optimization proc. int. schmidt roux bach minimizing ﬁnite sums stochastic average gradient inria paris tech. rep. shalev-shwartz zhang accelerated proximal stochastic dual coordinate ascent regularized loss minimization math. program. nitanda stochastic proximal gradient descent acceleration techniques proc. adv. neural inf. process. syst. zhou optimal randomized incremental gradient method arxiv.v frostig kakade sidford un-regularizing approximate proximal point faster stochastic algorithms empirical frank wolfe algorithm quadratic programming naval res. logist. quart. vol. hazan variance-reduced projection-free stochastic optimization proc. int. conf. mach. learn. shang cheng yoshida variance reduced stochastic gradient descent sufﬁcient decrease arxiv. defazio simple practical accelerated method ﬁnite sums proc. adv. neural inf. process. syst. zhao arora haupt nonconvex sparse learning stochastic optimization progressive variance reduction zhong kwok fast stochastic alternating direction method multipliers proc. int. conf. mach. learn. zheng kwok fast-and-light stochastic admm proc. int. joint conf. artif. intell. reddi poczos smola proximal stochastic methods nonsmooth nonconvex ﬁnite-sum optimization proc. adv. bengio learning deep architectures found. trends mach. learn. vol. huang yuan escaping saddle points online stochastic gradient tensor decomposition proc. conf. flammarion bach from averaging acceleration step-size proc. conf. learn. theory qian barzilai-borwein step size stochastic gradient descent proc. adv. neural inf. process. syst. carpenter lazy sparse stochastic gradient descent regularized multinomial logistic regression tech. rep. langford zhang sparse online learning truncated gradient mach. learn. res. vol. nesterov smooth minimization non-smooth functions math. program. vol. yang homotopy smoothing non-smooth problems lower complexity proc. adv. neural koneˇcn´y richt´arik semi-stochastic gradient descent methods arxiv preprint optimal method stochastic composite optimization math. program. vol. fig. comparison svrg prox-svrg katyusha vr-sgd solving -norm regularized logistic regression problems plot vertical axis shows objective value minus minimum horizontal axis number effective passes running time fig. comparison svrg prox-svrg katyusha vr-sgd -norm regularized logistic regression problems four data sets adult protein covtype sido plot vertical axis shows objective value minus minimum horizontal axis number effective passes running time fig. comparison svrg prox-svrg katyusha vr-sgd solving elastic regularized logistic regression problems four data sets adult protein covtype sido plot vertical axis shows objective value minus minimum horizontal axis number effective passes running time fig. comparison svrg katyusha vr-sgd proximal versions solving ridge regression problems different regularization parameters adult data set. plot vertical axis shows objective value minus minimum horizontal axis number effective passes running time fig. comparison svrg katyusha vr-sgd proximal versions solving ridge regression problems different regularization parameters covtype data set. plot vertical axis shows objective value minus minimum horizontal axis number effective passes running time fig. comparison algorithm ﬁxed varying learning rates solving -norm regularized logistic regression lasso problems note regularization parameter solving lasso problems covtype data set.", "year": 2017}