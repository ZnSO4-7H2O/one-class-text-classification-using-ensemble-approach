{"title": "Nonparametric Nearest Neighbor Descent Clustering based on Delaunay  Triangulation", "tag": ["stat.ML", "cs.CV", "cs.LG"], "abstract": "In our physically inspired in-tree (IT) based clustering algorithm and the series after it, there is only one free parameter involved in computing the potential value of each point. In this work, based on the Delaunay Triangulation or its dual Voronoi tessellation, we propose a nonparametric process to compute potential values by the local information. This computation, though nonparametric, is relatively very rough, and consequently, many local extreme points will be generated. However, unlike those gradient-based methods, our IT-based methods are generally insensitive to those local extremes. This positively demonstrates the superiority of these parametric (previous) and nonparametric (in this work) IT-based methods.", "text": "laboratory neuroinformation ministry education china school life science technology university electronic science technology china chengdu china *corresponding author. abstract physically inspired in-tree based clustering algorithm series free parameter involved computing potential value point. work based delaunay triangulation dual voronoi tessellation propose nonparametric process compute potential values local information. computation though nonparametric relatively rough consequently many local extreme points generated. however unlike gradient-based methods it-based methods generally insensitive local extremes. positively demonstrates superiority parametric nonparametric it-based methods. introduction proposed physically inspired clustering algorithm in-tree structure first constructed. structure organizes data points clusters several undesired connections requiring removed. series proposed several methods remove redundant edges either using semi-supervised interactive strategies combining decision graph recently proposed rodriguez laio popular methods affinity propagation isomap efforts seem quite effective showing strong extensibility structure. example proposed method lets post processing structure overcomes weakness non-spherical cluster detection. proposed method replaces k-nearest-neighbor structure isomap structure maps structure low-dimensional space guaranteeing clusters distinguishable generally hard isomap so-called crowding problem motivation however it-based methods rodriguez laio’s method involve free parameter computing either potential variable density variable quantitatively potential values inversely proportional density values solutions nonparameterization work both. compute potential density data points free parameter involved? delaunay triangulation used another recent paper shed light considering fact volumes basic lattices visually quite consistent density distribution dataset. fact delaunay triangulation dual voronoi tessellation wide applications density estimation builds basis fulfill idea. fig. delaunay voronoi tessellation dataset. delaunay graph consists triangulars. neighbors node denoted blue. point inside basic lattice called voronoi cell method step compute potentials data points. dataset d-dimensional euclidean space first construct delaunay triangulation dual voronoi tessellation potential point defined function monotonous functions. variants density defined total volume neighboring lattices node volume voronoi cell node fact step define median distances node neighbor nodes much faster definitions especially dealing high-dimensional dataset. illustration four methods computing fig. step nearest neighbor descent. node directed node defined methods without parameter necessarily superior ones parameter cases. monotonous‐increasing functions ‐e‐x lead result since don’t change relative relationships potential values thus hardly make effect step main role increase visual difference potential values nodes fig. density defined inverse total volume neighboring lattices node inverse volume voronoi cell practice statistics mean also appropriate degree. distance nodes null consequently structure obtained. step undesired edges clusters. general cutting method previous works used here. step identify root node node. step divides structure separate sub-its representing cluster. sub-it root node. root node viewed representative cluster. since node directed path reach root node sub-it root node identified searching along directed path consequently nodes root node assigned cluster. experiments fig. show delaunay triangulations several datasets upper panels corresponding structures lower panels. figs. respectively show performance cutting methods nonparametric-it-ss-ii figure shows results semi-supervised cutting method based cell-like divisive mechanism divisive mechanism takes labeled data genetic material independent structure cell. process edge cutting thus viewed cell dividing. although edges explored according lengths whether edge removed depended whether cutting behavior contributes dividing impure cells purer ones. details consequently edges clusters removed desired. obtained clusters contain kind labeled data points. pleasing results demonstrate semi-supervised cutting method quite suitable proposed nonparametric strategy. nonparametric-it-dg figure shows results interactive cutting method based rodriguez laio’s decision graph however show decision graphs based variables potential edge length structures need select pop-out points values variable high values variable directed edges started corresponding nodes identified points removed. eventual clustering results quite consistent visual perception except last one. note tests figs. based definition comparable results takes definition shown fig. note don’t restrict node select directed node among neighbors graph obtained step moreover indexes data points used complementary potential variable mainly functioning close points especially overlapped ones potential indexes make representative build connection nodes guarantee redundant connection clusters generally one. denote semi‐supervised cutting method ref. type cell without genetic material allowed. problem previous cutting methods it-ss it-dg it-map it-ap least type data fig. hard cluster successfully nonparametric framework; well suitable kind nonparametric proposal. best suitable it-ss. next it-dg it-map. however g-ap performances generally much worse previous kernel-based solutions. comparing gradient-based solutions gradient-based solutions routinely used researchers directly indirectly density-based graph-based physics-based methods cluster centers equated extreme points density peaks irrespective local ones not. therefore besides problems methods common problem sensitive estimation density inverse form—the potential. since potentials work roughly estimated lead many local fake extreme points terms potential variable. gradient-based methods means many fake clusters would occur. comparison proposed method abandons gradient-based solution generally avoiding problem shown figs. therefore work provides optional avoid free parameter previous methods. importantly also demonstrates positive superiority strategy constructing structure. structures lower panels sub-graphs corresponding delaunay graph upper panels since connections upper panels used step datasets choose compute potential fig. results nonparametric-it-ss-ii. upper panels triangulars denote labeled points. cluster assumed point labeled. labels different clusters differentiated different colors. supervised labeled data points connections clusters automatically removed. lower panels corresponding clustering results. fig. results nonparametric-it-dg. upper panels it-based decision graphs. pop-out points correspond identified start nodes redundant edges structure. note number pop-out points decision graph less rodriguez laio’ decision graph. lower panels corresponding clustering results. fig. results different cutting methods panels denote problematic results. test first datasets it-map. shows performance embeddings worse ref. fig. structure spiral dataset colors nodes denote different potential values. hard previous cutting method obtain satisfactory result. however number labeled data points large enough it-ss-ii still obtain ideal result. yang physically inspired clustering algorithm evolve like particles. arxiv preprint arxiv.. effective semi‐supervised divisive clustering algorithm. arxiv preprint arxiv.. generalized affinity propagation clustering algorithm nonspherical cluster discovery. arxiv preprint arxiv.. it‐map effective nonlinear dimensionality reduction method interactive clustering. arxiv preprint arxiv.. rodriguez laio clustering fast search find density peaks. science frey dueck clustering passing messages data points. science tenenbaum silva langford global geometric framework nonlinear dimensionality reduction. science maaten hinton visualizing data using t‐sne. journal machine learning research delaunay sphere vide. izv. akad. nauk sssr otdelenie matematicheskii estestvennyka nauk space. arxiv preprint arxiv.. barr schoenberg voronoi estimator intensity inhomogeneous planar poisson process. biometrika schaap delaunay tessellation field estimator. ramella nonino boschin fadda cluster identification voronoi tessellation. arxiv preprint astro‐ph/. fränti virmajoki iterative shrinking method clustering problems. pattern recognit. gionis mannila tsaparas clustering aggregation. trans. knowl. discovery data fukunaga hostetler estimation gradient density function applications pattern recognition. ieee trans. inf. theory cheng mean shift mode seeking clustering. ieee trans. pattern anal. mach. intell. hinneburg keim efficient approach clustering large multimedia databases noise. proceedings international conference knowledge discovery data mining agrawal p.e. stolorz piatetsky‐shapiro eds. koontz narendra fukunaga graph‐theoretic approach nonparametric cluster analysis. ieee trans. comput. ruta gabrys framework machine learning based dynamic physical fields. natural computing", "year": 2015}