{"title": "Convolutional Neural Network-based Place Recognition", "tag": ["cs.CV", "cs.LG", "cs.NE"], "abstract": "Recently Convolutional Neural Networks (CNNs) have been shown to achieve state-of-the-art performance on various classification tasks. In this paper, we present for the first time a place recognition technique based on CNN models, by combining the powerful features learnt by CNNs with a spatial and sequential filter. Applying the system to a 70 km benchmark place recognition dataset we achieve a 75% increase in recall at 100% precision, significantly outperforming all previous state of the art techniques. We also conduct a comprehensive performance comparison of the utility of features from all 21 layers for place recognition, both for the benchmark dataset and for a second dataset with more significant viewpoint changes.", "text": "recently convolutional neural networks state-of-the-art performance various classification tasks. paper present first time place recognition technique based models combining powerful features learnt cnns spatial sequential filter. applying system benchmark place recognition dataset achieve increase recall precision significantly outperforming previous state techniques. also conduct comprehensive performance comparison utility features layers place recognition benchmark dataset second dataset significant viewpoint changes. early convolutional neural networks used achieve excellent performance variety tasks handwriting recognition face detection. recently supervised deep convolutional neural networks shown deliver high level performance challenging classification tasks supporting factors behind impressive results ability learn tens millions parameters using large amounts labelled data. trained cnns shown learn discriminative humaninterpretable feature representations impressively approaches capable producing state performance tasks model explicitly trained including object recognition caltech subcategory dataset recognition caltech-uscd birds dataset scene recognition dataset object detection authors school electrical engineering computer science queensland university technology australia. email zetao.chenstudent.qut.edu.au. work supported funding australian research council centre excellence robotic vision. pascal dataset good generalization performance tasks datasets indicates cnns provide general universal visual feature learning framework applicable tasks. encouraged positive results paper develop place recognition framework centered around features pre-trained cnns illustrated figure figure schematic illustration deep learning-based place recognition system. deep learning features extracted test image matched training images. spatial sequential continuity check final match reported. place recognition considered image retrieval task consists determining match current scene previously visited location. state-of-the-art visual slam algorithms fab-map match appearance current scene past place converting image bag-of-words representations built local features sift surf. however recent evidence suggests features extracted cnns trained large datasets significantly outperform sift tasks. donahue shows using mid-level features models trained imagenet database efficiently remove dataset bias domain adaption studies words approach. paper investigate whether advantages deep learning recognition tasks carries place recognition. present deep learning-based place recognition algorithm compares response feature layers trained imagenet methods filtering subsequent place recognition hypotheses. conduct experiments benchmark place recognition dataset viewpoint varying dataset providing quantitative comparison state place recognition algorithms analysis utility different layers within network viewpoint invariance. paper proceeds follows. section provides overview recognition techniques convolutional neural networks. section describe components deep learning-based system. experiments described section results presented section finally conclude paper section discuss ongoing future work. predominant sensor modality place recognition cost power requirements small footprint rich information content. extensive research best represent match images places. several authors described approaches apply global feature techniques process incoming sensor information. authors propose gist feature-based place recognition system using panoramic images urban environments. histograms image gray values texture also widely used feature place recognition systems compact representation rotation invariance. however global features computed entire image rendering unsuitable effects partial occlusion lighting change perspective transformation local features less sensitive external factors widely used appearance-based loop closure detection sift surf widespread examples. state-of-the-art slam systems fabmap represent appearance data using sets local features converting images bag-of-words enables efficient retrieval. feature-less representations also proposed. seqslam directly uses pixel values match image sequences perform place recognition across extreme perceptual changes. however rapidly becoming apparent recognition tasks hand-crafted features outperformed learnt features prompting convolutional neural networks multi-layer supervised networks features automatically datasets last years cnns achieved state-of-the-art performance almost important classification tasks primary disadvantage require large amounts training data. however recent studies shown performance achieved networks trained using generic data possibility developing place recognition system based features learnt datasets classification focus. similar approach already achieved excellent performance various visual tasks object recognition subcategory recognition scene recognition detection research area separate relevant place recognition problem task image retrieval query image present database search images containing objects scenes. mid-level features cnns evaluated image retrieval application achieve performance comparable others using stateof-the-art features. interestingly best performance obtained using mid-network features rather learnt final layers. place recognition essentially task image similarity matching. features various layers cnns evaluated compared sift descriptors descriptor matching results demonstrate deep features different layers cnns consistently perform better sift descriptor matching; indicating sift surf preferred descriptors matching tasks anymore. paper thus inspired excellent performance cnns image classification evidence feasibility feature matching. section describe components approach feature extraction spatio-temporal filtering place match hypotheses output comparison responses. schematic illustration method procedure shown figure figure procedure generating confusion matrix. features extracted overfeat testing image matched features training images. matrix element represents euclidean distance training image testing image. apply continuity filters place match hypotheses extracted confusion matrix. first consecutive first-ranked place match hypotheses must occur close indices confusion matrix providing constraint require specific motion model. specifically plausible measurement place match hypothesis evaluated follows threshold consecutive first-ranked match difference determines back time evaluation goes current testing image. positive match reported figure provides illustration spatial continuity check action. constraint reduces eliminate consequently implement secondary sequential filter step implements actual motion model described next section. figure illustration spatial continuity constrain. blue squares indicate column. left square represents non-plausible match consecutive match difference within black square exceeds threshold right square indicates plausible match. pretrained network called overfeat originally proposed imagenet large scale visual recognition challenge overfeat network trained imagenet dataset consists million images classes. network comprises five convolution stages three fully connected stages bottom convolution stages consists convolution layer pooling layer rectification nonlinearity layer. third fourth stages consist convolution layer zero-padding layer relu non-linear layer. fifth stage contains convolution layer zero-padding layer relu layer maxpooling layer. finally sixth seventh stages contain fully-connected layer relu layer eighth contains fully-connected output layer. total layers. image input network produces sequence layered activations. denote corresponding output layer given input image vectors deep learnt representation image place recognition performed comparing feature vector responses different images. network capable processing images size equal greater pixels consequently experiments described used images resized pixels. layer output generate corresponding confusion matrix whole dataset training images testing images element represents euclidean distance feature vector responses training image testing image rather searching coherent diagonal coherent diagonal sequences strong matching hypotheses sequences strong matching hypotheses linear polynomial models matches matches local sequence using sequence length used section sequence length used section current frame describes slope describes slope linear model sequence represents represents second first traverse. velocity ratio second first traverse. shown figure place match hypotheses place match hypotheses comprising sequence accepted velocity ratio comprising sequence accepted velocity ratio within certain bound around reference velocity around reference velocity parameter swept range swept range values generate precision-recall curves shown section recall curves shown section also note odometry source also note odometry source available sequence search could significantly available sequence search could significantly simplified manner similar smart approach simplified manner similar smart approach eynsham dataset eynsham dataset used metre tolerance gps-derived ground truth provided derived ground truth provided eynsham dataset consistent tolerance used eynsham dataset consistent tolerance used original fab-map study study seqslam study dataset ground truth obtained ground truth obtained arsing frame building frame manually parsing frame tolerance frames correspondence. tolerance frames corresponding approximate approximately meters. final place match hypothesis figure describe final place match hypothesis local sequence estimated fitting linear model local sequence slope linear model within slope linear model bound around reference velocity therefore final match therefore final match generated linear model considered plausible match. generated linear model considered plausible match. details datasets used used summarized table dataset consists traverses along dataset consists traverses along route first traverse used training first traverse used training testing. second testing. environments environments first converted gray-scale histogram normalized scale histogram normalized reduce effect illumination variations. reduce effect illumination variations. images input resized pixels cnns. eynsham dataset large road eynsham dataset large road-based traverses) used used newman fab-map seqslam studies. seqslam studies. panoramic images captured meter intervals panoramic images captured meter intervals using ladybug camera. dataset dataset collected using hand-held camera walking around held camera walking around queensland university technology campus hnology campus viewpoint shift metres lateral camera metres lateral camera movement first second traverse figure aerial overhead images showing dataset route aerial overhead images showing dataset route eynsham dataset. eynsham dataset. imagery google data google. illustration moderate viewpoint illustration moderate viewpoint variation dataset. section present sets results section present sets results eynsham datasets eynsham datasets; firstly comparison performance proposed approach performance proposed approach fab-map seqslam benchmark seqslam benchmark eynsham dataset well evaluation eynsham dataset well evaluation performance feature performance feature layer viewpoint layer viewpoint invariant place recognition. invariant place recognition. also provide compute performance statistics discuss feasibility performance statistics discuss feasibility real-time implementation. recall curves section presents precision-recall curves eynsham dataset deep learning deep learning-based place recognition algorithms using features layers recognition algorithms using features cnns comparison seqslam seqslam fabmap. precision-recall curve generated recall curve generated performing parameter sweep slope tolerance slope tolerance discussed section network layers provide best performance result network layers provide best performance result consistent image retrieval experiment consistent image retrieval experiments suggest middle network suggest middle network layers provide general feature description layers provide general feature description layers overtrained imagenet task. layers overtrained imagenet task. figure scores dataset eynsham subset across dataset eynsham subset across layers. results campus dataset; results eynsham layers. results campus dataset; results eynsham subset; figure precision-recall curves eynsham dataset eynsham dataset. maximal recall rates precision using different algorithms; recall rates precision using different algorithms; recall curves deep learning method state-of-the-art precision-recall curves deep learning method state method indicates result using features ndicates result using features layer network; zoom particular section figure demonstrates maximum recall rates demonstrates maximum recall rates precision achieved using best performing precision achieved using best performing feature layers seqslam feature layers seqslam fab-map. maximum recall rate achieved deep maximum recall rate achieved deep learning-based approach compared based approach compared approximately recall rate achieved seqslam. approximately recall rate achieved seqslam. also noteworthy result achieved using also noteworthy result achieved using filter analogous seqslam operating sequence filter analogous seqslam operating sequence length rather sequence length length rather sequence length recall performance achieved. recall performance achieved. figures present precision figures present precision-recall performance curves layers. clearly middle performance curves layers. clearly middle evaluate viewpoint invariance different evaluate viewpoint invariance different network layers using custom dataset specifically network layers using custom dataset specifically gathered lateral camera variance selecting camera variance selecting subsection eynsham dataset subsection eynsham dataset travelling reverse direction opposite side travelling reverse direction opposite side road. achieved layer cnn. clear trend increasing clear trend increasing viewpoint invariance later network layers. viewpoint invariance later network layers. lines represent performance baseline performance baseline calculated ifferences image using absolute differences comparison. green dotted performance offset matching measure performance offset matching measure frequently used increase viewpoint invariance frequently used increase viewpoint invariance technique provide qualitative illustration superiority provide qualitative illustration superiority using deep learnt features simple techniques like using deep learnt features simple techniques like present comparison subsection present comparison subsection confusion matrix layer layer generated using approach layer using figure comparison confusion matrix absolute difference deep learning features absolute difference deep learning features clear diagonal pattern observed bottom figure. clear diagonal pattern observed bottom figure. notoriously deep deep notoriously computationally-intensive examination real intensive examination realtime capability particular necessary. experiments time capability particular necessary. experiments paper used overfeat network feature paper used overfeat network feature extraction significantly slower real extraction significantly slower real-time single however recently single however recently re-implemented system using another convolutional architecture system using another convolutional architecture dubbed caffe initial studies initial studies suggest recognition performance near rmance near-identical many orders magnitude faster. many orders magnitude faster. consequently present calculation consequently present calculation computation required extracting features feature computation required extracting features feature matching using caffe. largest feature vector layer largest feature vector contains uint values. comparing contains uint values. comparing training images require training images require results paper demonstrate results paper demonstrate task place place incorporating features learnt using cnns. incorporating features learnt using cnns. particular performance using even relatively simple framework performance using even relatively simple framework around around performance performance significantly better current state significantly better current state algorithms. furthermore interesting note algorithms. furthermore interesting note different layers appear suitab different layers appear suitable different aspects place recognition task aspects place recognition task middle layers optimal recognition relatively static optimal recognition relatively static similar viewpoint datasets later layers appear similar viewpoint datasets later layers appear perform better viewpoint variance becomes perform better viewpoint variance becomes significant. section discuss discuss opportunities challenges exist field. opportunities challenges exist field. datasets inherently biased computer vision datasets inherently biased computer vision researchers demonstrated researchers demonstrated supervised deep model trained large amounts labelled data model trained large amounts labelled data reduces remove data bias. reduces remove data bias. network trained different trained different classification task; therefore although demonstrates classification task; therefore although demonstrates impressive generalization performance different impressive generalization performance recognition task major question remains question remains unanswered; whether performance whether performance improved training network scratch place recognition training network scratch place recognition datasets. potential problem approach datasets. potential problem approach relative sparsity large place recognition relative sparsity large place recognition datasets comparison millions frames datasets comparison millions frames found imagenet database. found imagenet database. option keep parameters keep parameters pre-trained model final domain specific classification layer final domain specific classification layer trained particular dataset. approach trained particular dataset. domain adaption work adopted domain adaption cnns object recognition krizhevsky sutskever hinton \"imagenet classification deep convolutional neural networks\" presented advances neural information processing systems fei-fei fergus perona \"learning generative visual models training examples incremental bayesian approach tested object categories\" computer vision image understanding vol. lowe \"object recognition local scale-invariant features\" presented proceedings international conference computer vision-volume volume herbert andreas tinne tuytelaars gool \"surf speeded robust features\" computer vision image understanding vol. milford \"seqslam visual route-based wyeth navigation sunny summer days stormy winter nights\" international conference robotics automation paul united states rodner hoffman donahue darrell saenko \"towards adapting imagenet reality scalable domain low-rank adaptation transformations\" preprint arxiv.", "year": 2014}