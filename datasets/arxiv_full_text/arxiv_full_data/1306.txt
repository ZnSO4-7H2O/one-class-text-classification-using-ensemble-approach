{"title": "Unsupervised Feature Learning by Deep Sparse Coding", "tag": ["cs.LG", "cs.CV", "cs.NE"], "abstract": "In this paper, we propose a new unsupervised feature learning framework, namely Deep Sparse Coding (DeepSC), that extends sparse coding to a multi-layer architecture for visual object recognition tasks. The main innovation of the framework is that it connects the sparse-encoders from different layers by a sparse-to-dense module. The sparse-to-dense module is a composition of a local spatial pooling step and a low-dimensional embedding process, which takes advantage of the spatial smoothness information in the image. As a result, the new method is able to learn several levels of sparse representation of the image which capture features at a variety of abstraction levels and simultaneously preserve the spatial smoothness between the neighboring image patches. Combining the feature representations from multiple layers, DeepSC achieves the state-of-the-art performance on multiple object recognition tasks.", "text": "paper propose unsupervised feature learning framework namely deep sparse coding extends sparse coding multi-layer architecture visual object recognition tasks. main innovation framework connects sparse-encoders different layers sparse-to-dense module. sparse-to-dense module composition local spatial pooling step low-dimensional embedding process takes advantage spatial smoothness information image. result method able learn several levels sparse representation image capture features variety abstraction levels simultaneously preserve spatial smoothness neighboring image patches. combining feature representations multiple layers deepsc achieves state-of-the-art performance multiple object recognition tasks. visual object recognition major topic computer vision machine learning. past decade people realized central problem object recognition learn meaningful representations image/videos. large amount focus constructing effective learning architecture combines modern machine learning methods meanconsiders characteristics image data vision problems. work combine power deep learning architecture bag-of-visual-words pipeline construct unsupervised feature learning architecture learning image representations. compared single-layer sparse coding framework method extract feature hierarchies different levels abstraction. sparse codes layer keeps spatial smoothness across image patches different hierarchies also capture different spatial scopes representation abstraction. result method richer representation power hence better performance object recognition tasks. compared deep learning methods method beneﬁts effective hand-crafted features sift features input. module architecture sound explanation formulated explicit optimization problems promising computational performance. method shows superior performance state-ofthe-art methods multiple experiments. rest section review technical background framework including pipeline using bag-of-visual-words object recognition low-dimensional embedding method called drlim. review bag-of-visual-words pipeline consisting hand-crafted descriptor computing bag-of-visual-words representation learning spatial pyramid pooling ﬁnally classiﬁer. ∗heyunlonggatech.edu georgia institute technology †koraydeepmind.com deepmind technologies ‡yunwangprinceton.edu princeton university §aszlamccny.cuny.edu city college york ¶yanjunvirginia.edu university virginia ﬁrst step pipeline exact overlapped image patches image ﬁxed patch size spacing centers adjacent image patches also ﬁxed. d-dimensional hand-crafted feature descriptor computed image patch. denote feature descriptors converted overlapped image patches extracted i-th image i.e. rd×m denote feature descriptors training images. second step pipeline consists dictionary learning process bag-of-visual-words representation learning process. case using sparse coding learn bag-of-visual-words representation processes uniﬁed following problem. rd×k denotes dictionary visual-words columns rk×m learned sparse codes parameter controls sparsity code. note however sparse encoding methods vector quantization could used learn sparse representations review comparisons). moreover dictionary learning process ﬁnding often conducted online style feature descriptors i-th image stored encoded bag-of-visual-words representations stored k-dimensional space intuitively speaking components bag-of-visual-words representation less correlated compared components dense descriptors. therefore compared dense feature descriptors high-dimensional sparse representations favorable classiﬁcation tasks. third stage pipeline sparse bag-of-visual-words representations image patches image pooled together obtain single feature vector image based histogram statistics visual-words. achieve this image divided three levels pooling regions suggested spatial pyramid matching technique ﬁrst level pooling region whole image. second level consist pooling regions quadrants whole image. third level consist pool regions quadrants second level pooling regions. obtain overlapped pooling regions. pooling region max-pooling operator applied sparse codes whose associating image patch center locates pooling region obtain single feature vector result. max-pooling operator maps number vectors dimensionality single vector whose components maximum value corresponding components mapped vectors. formally given descriptors y··· pooling region calculate operated component-wisely. second stage framework know nonzero elements sparse code imply appearance corresponding visual-words image patch. therefore max-pooling operator actually equivalent calculating histogram statistics visual-words pooling region. finally pooled bag-of-visual-words representations pooling regions concatenated obtain single feature vector regarded representation image linear used training testing representation. since labels training images used ﬁnal training whole pipeline regarded unsupervised method. rest paper focus version pipeline feature learning part performed sparse coding step review method called dimensionality reduction learning invariant mapping base model method subsection different traditional unsupervised dimensionality reduction methods drlim relies training instances y··· also binary labels {lij index pairs label corresponding instance pair available. binary label pair training instances similar instances known dissimilar. notice similarity indicated usually extra resource instead knowledge learned data instances y··· directly. drlim learns parametric mapping embeddings similar instances attract low-dimensional space embeddings dissimilar instances push away low-dimensional space. spirit exact loss function drlim follows parameter contrastive loss term decides extent want push dissimilar pairs apart. since parametric mapping assumed decided parameter. drlim learn mapping minimizing loss function respect parameters mapping could either linear nonlinear. example assume two-layer fully connected neural network minimize loss function respect weight. finally data instance ynew low-dimensional embedding represented without knowing relationship training instances. recent progress deep learning shown multi-layer architecture deep learning system deep belief networks helpful learning feature hierarchies data different layers feature extractors able learn feature representations different scopes. results effective representations data beneﬁts tasks. rich representation power deep learning methods motivate combine deep learning bagof-visual-words pipeline achieve better performance object recognition tasks. section introduce learning framework named deep sparse coding built multiple layers sparse coding. first build feature hierarchies bottom-level features important take advantage spatial information image patches higher-level feature composition lower-level features. however issue hardly addressed simply stacking sparse encoders. figure three-layer deep sparse coding framework. three layers contains three modules. ﬁrst module converts input dense codes. second module sparse encoder converting dense codes sparse codes. sparse codes sent next layer simultaneously spatial pyramid pooling module. outputs spatial pyramid pooling modules used tasks classiﬁcation. instance overlapped image patches similar sift descriptors corresponding sparse codes different. another sparse encoder applied sparse codes would lost afﬁnity available sift descriptor stage. therefore stacking sparse encoders would make dimensionality feature higher higher without gaining informations. based observations above propose deep sparse coding framework follows. ﬁrst layer deepsc framework exactly bag-of-visual-words pipeline introduced subsection following layer framework sparse-to-dense module converts sparse codes obtained last layer dense codes followed sparse coding module. output sparse code sparse coding module input next layer. furthermore spatial pyramid pooling step conducted every layer sparse codes current layer converted single feature vector layer. finally concatenate feature vectors layers input classiﬁer. summarize deepsc framework figure important emphasis whole framework unsupervised ﬁnal classiﬁer. sparse-to-dense module innovation deepsc framework pooling function proposed tackle aforementioned concerns. pooling function composition local spatial pooling step low-dimensional embedding step introduced subsection subsection respectively. hand local spatial pooling step ensures higher-level features learned collection nearby lower-level features hence exhibit larger scopes. hand low-dimensional embedding process designed take account spatial afﬁnities neighboring image patches spatial smoothness information lost dimension reduction process. combination steps pooling function ﬁlls gaps sparse coding modules power sparse coding spatial pyramid pooling fully expressed multi-layer fashion. subsection introduce details designing local spatial pooling step performs ﬁrst part pooling function. first deﬁne pooling function sparse codes sampling grid dense codes sampling grid. assume sampling grid includes sampling points image figure ﬁrst second third level sampling grids consists sampling points blue green colors respectively. local spatial pooling step performed local grid. adjacent sampling points ﬁxed spacing them. introduced subsection sampling point corresponds center image patch. rk×m sparse codes sampling grid associated sampling point according associated image patch. mathematically pooling function deﬁned sampling grid sampling points rd×m stores d-dimensional dense codes associated sampling points sampling grid feature representations learned layer expected larger scope previous layer enforce sampling points grid cover larger area image. achieve this take center neighboring sampling points sampling points taking center every neighboring sampling points spacing neighboring sampling points twice result coarser grid sampling grid determined ﬁnish local spatial pooling step applying max-pooling operator subsets sparse codes {y··· obtain pooled sparse codes associated sampling grid speciﬁcally denote pooled sparse codes associated i-th sampling point {··· feature vector transformed lower-dimensional space part information discarded preserved. introduced subsection drlim trained collection data instance pairs associated binary label indicating relationship. therefore provides option incorporate prior knowledge dimensionality reduction process determining binary labels training pairs based prior knowledge. collection training pairs drlim follows. extract training pairs always exist overlapped pixels corresponding patches. pooled sparse codes corresponding image patches overlapped pixels distance them calculated based coordinate image patch centers. given thresholding generated indicates image patches mostly overlapped indicates image patch partially overlapped. process generating training pairs ensures training transformation focused difﬁcult pairs. experiments shows instead take pooled sparse codes far-apart image patches negative pairs drlim suffers downgrading performance. sensitivity system thresholding parameter demonstrated table linear transformation deﬁned transformation matrix rd×k section evaluate performance deepsc framework image classiﬁcation three data sets caltech- caltech- -scene. caltech- data contains images belonging classes images class. images caltech medium resolution i.e. caltech- data contains images categories. collection higher intra-class variability object location variability caltech-. images similar size caltech-. -scene data compiled several researchers contains total images falling categories number images category ranging categories include living room bedroom kitchen highway mountain street data average per-class recognition accuracy reported. reported number average repeated evaluations random selected training testing images. image following sample image patches -pixel spacing dimensional sift feature basic dense feature descriptors. ﬁnal step classiﬁcation performed using one-vs-all libsvm toolkit parameters drlim parameter control sparsity sparse coding selected layer layer crossvalidation. following present comprehensive experimental results discuss inﬂuence parameters independently. rest paper deepsc- indicates two-layer deepsc system; deepsc- represents three-layer deepsc system spm-sc means layer baseline i.e. pipeline sparse coding plus spatial pyramid pooling. shown figure deepsc framework utilizes multiple-layers feature abstraction better representation images. ﬁrst check effect varying number layers utilized framework. table shows average per-class recognition accuracy three data sets using dictionary size. number training images class three data sets caltech- caltech- -scene respectively. second shows results layer sparse coding third fourth describe results layers deepsc three layers deepsc. clearly multi-layer structured deepsc framework superior performance three data sets compared single-layer spm-sc system. moreover classiﬁcation accuracy improves number layers increases. table average per-class recognition accuracy three data sets using dictionary size. number training images class three data sets caltech- caltech- -scene respectively. deepsc-/ two/three layers deep sparse coding. spm-sc normal pipeline layer sparse coding plus spatial pyramid pooling. examine performance proposed deepsc framework changes varying dictionary size sparse coding. three data sets consider three settings dimension sparse codes number training images class experiments caltech- caltech- -scene respectively. report results three data sets table table table respectively. clearly increasing dictionary size sparse coding accuracy system improves three data sets. observe performance deepsc always improved layers case performance boost term accuracy signiﬁcant. probably parameter space case already large limited training data size. another observation made table table table deepsc- always performs better spm-sc deepsc- always performs better spm-sc comparisons demonstrate simply increasing dimension sparse codes doesn’t give performance boost increasing number layers therefore deepsc framework indeed beneﬁts feature hierarchies learned image. furthermore check performance change varying number training images class caltech data sets. dimension sparse codes caltech- compare cases randomly select images category respectively training images test rest. caltech- randomly select images category respectively training images test rest. table table show smaller training images deepsc framework still continues improve accuracy layers. table report performance variations tuning parameters drlim. parameter threshold selecting positive negative training pairs parameter hinge loss drlim model controlling penalization negative pairs. important choose proper thresholding parameter transformation learned drlim differentiate mostly overlapped image pairs partially overlapped image pairs. compare results algorithms table direct baselines deepsc compare sparse coding plus framework ssc. table shows comparison deepsc versus scspm ssc. results comparable lower accuracy -scene data method proposed reported achieve caltech- using using deepsc- achieved caltech- using using overall system achieves state-of-the-art performance three data sets. table comparison results image recognition algorithms scspm ssc. dictionary size number training images caltech- caltech- -scene respectively.", "year": 2013}