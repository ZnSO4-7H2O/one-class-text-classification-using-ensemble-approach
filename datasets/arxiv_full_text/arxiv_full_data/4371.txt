{"title": "Photo-Realistic Single Image Super-Resolution Using a Generative  Adversarial Network", "tag": ["cs.CV", "stat.ML"], "abstract": "Despite the breakthroughs in accuracy and speed of single image super-resolution using faster and deeper convolutional neural networks, one central problem remains largely unsolved: how do we recover the finer texture details when we super-resolve at large upscaling factors? The behavior of optimization-based super-resolution methods is principally driven by the choice of the objective function. Recent work has largely focused on minimizing the mean squared reconstruction error. The resulting estimates have high peak signal-to-noise ratios, but they are often lacking high-frequency details and are perceptually unsatisfying in the sense that they fail to match the fidelity expected at the higher resolution. In this paper, we present SRGAN, a generative adversarial network (GAN) for image super-resolution (SR). To our knowledge, it is the first framework capable of inferring photo-realistic natural images for 4x upscaling factors. To achieve this, we propose a perceptual loss function which consists of an adversarial loss and a content loss. The adversarial loss pushes our solution to the natural image manifold using a discriminator network that is trained to differentiate between the super-resolved images and original photo-realistic images. In addition, we use a content loss motivated by perceptual similarity instead of similarity in pixel space. Our deep residual network is able to recover photo-realistic textures from heavily downsampled images on public benchmarks. An extensive mean-opinion-score (MOS) test shows hugely significant gains in perceptual quality using SRGAN. The MOS scores obtained with SRGAN are closer to those of the original high-resolution images than to those obtained with any state-of-the-art method.", "text": "despite breakthroughs accuracy speed single image super-resolution using faster deeper convolutional neural networks central problem remains largely unsolved recover ﬁner texture details super-resolve large upscaling factors? behavior optimization-based super-resolution methods principally driven choice objective function. recent work largely focused minimizing mean squared reconstruction error. resulting estimates high peak signal-to-noise ratios often lacking high-frequency details perceptually unsatisfying sense fail match ﬁdelity expected higher resolution. paper present srgan generative adversarial network image superresolution knowledge ﬁrst framework capable inferring photo-realistic natural images upscaling factors. achieve this propose perceptual loss function consists adversarial loss content loss. adversarial loss pushes solution natural image manifold using discriminator network trained differentiate super-resolved images original photo-realistic images. addition content loss motivated perceptual similarity instead similarity pixel space. deep residual network able recover photo-realistic textures heavily downsampled images public benchmarks. extensive mean-opinion-score test shows hugely signiﬁcant gains perceptual quality using srgan. scores obtained srgan closer original high-resolution images obtained state-of-the-art method. highly challenging task estimating highresolution image low-resolution counterpart referred super-resolution received substantial attention within computer vision research community wide range applications ill-posed nature underdetermined problem particularly pronounced high upscaling factors texture detail reconstructed images typically absent. optimization target supervised algorithms commonly minimization mean squared error recovered image ground truth. convenient minimizing also maximizes peak signal-to-noise ratio common measure used evaluate compare algorithms however ability capture perceptually relevant differences high texture detail limited deﬁned based pixel-wise image differences illustrated figure highest psnr necessarily reﬂect perceptually better result. figure left right bicubic interpolation deep residual network optimized deep residual generative adversarial network optimized loss sensitive human perception original image. corresponding psnr ssim shown brackets. work propose super-resolution generative adversarial network employ deep residual network skip-connection diverge sole optimization target. different previous works deﬁne novel perceptual loss using high-level feature maps network combined discriminator encourages solutions perceptually hard distinguish reference images. example photo-realistic image superresolved upscaling factor shown figure recent overview articles image include nasrollahi moeslund yang focus single image super-resolution discuss approaches recover images multiple images prediction-based methods among ﬁrst methods tackle sisr. ﬁltering approaches e.g. linear bicubic lanczos ﬁltering fast oversimplify sisr problem usually yield solutions overly smooth textures. methods particularly focus edge-preservation proposed powerful approaches establish complex mapping lowhigh-resolution image information usually rely training data. many methods based example-pairs rely training patches corresponding counterparts known. early work presented freeman related approaches problem originate compressed sensing glasner authors exploit patch redundancies across scales within image drive paradigm self-similarity also employed huang self dictionaries extended allowing small transformations shape variations. proposed convolutional sparse coding approach improves consistency processing whole image rather overlapping patches. reconstruct realistic texture detail avoiding edge artifacts combine edge-directed algorithm based gradient proﬁle prior beneﬁts learning-based detail synthesis. zhang propose multi-scale dictionary capture redundancies similar image patches different scales. super-resolve landmark images retrieve correlating images similar content propose structure-aware matching criterion alignment. neighborhood embedding approaches upsample image patch ﬁnding similar training patches dimensional manifold combining corresponding patches reconstruction kwon authors emphasize tendency neighborhood approaches overﬁt formulate general example pairs using kernel ridge regression. regression problem also solved gaussian process regression trees random forests multitude patch-speciﬁc regressors learned appropriate regressors selected testing. wang algorithms shown excellent performance. authors encode sparse representation prior feed-forward network architecture based learned iterative shrinkage thresholding algorithm dong used bicubic interpolation upscale input image trained three layer deep fully convolutional network end-to-end achieve stateof-the-art performance. subsequently shown enabling network learn upscaling ﬁlters directly increase performance terms accuracy speed deeply-recursive convolutional network presented highly performant architecture allows long-range pixel dependencies keeping number model parameters small. particular relevance paper works johnson rely loss function closer perceptual similarity recover visually convincing images. state many computer vision problems meanwhile speciﬁcally designed architectures following success work krizhevsky shown deeper network architectures difﬁcult train potential substantially increase network’s accuracy allow modeling mappings high complexity efﬁciently train deeper network architectures batchnormalization often used counteract internal co-variate shift. deeper network architectures also shown increase performance sisr e.g. formulate recursive present state-of-theart results. another powerful design choice eases training deep cnns recently introduced concept residual blocks skip-connections skipconnections relieve network architecture modeling identity mapping trivial nature however potentially non-trivial represent convolutional kernels. context sisr also shown learning upscaling ﬁlters beneﬁcial terms accuracy speed improvement dong bicubic interpolation employed upscale observation feeding image cnn. pixel-wise loss functions struggle handle uncertainty inherent recovering lost high-frequency details texture minimizing encourages ﬁnding pixel-wise averages plausible solutions typically overly-smooth thus poor perceptual quality reconstructions varying perceptual illustration patches natural image figure manifold super-resolved patches obtained mse-based solution appears overly smooth pixel-wise average possible solutions pixel space drives reconstruction towards natural image manifold producing perceptually convincing solutions. quality exempliﬁed corresponding psnr figure illustrate problem minimizing figure multiple potential solutions high texture details averaged create smooth reconstruction. mathieu denton authors tackled problem employing generative adversarial networks application image generation. porikli augment pixel-wise loss discriminator loss train network super-resolves face images large upscaling factors gans also used unsupervised representation learning radford idea using gans learn mapping manifold another described wand style transfer inpainting. bruna minimize squared error feature spaces scattering networks. dosovitskiy brox loss functions based euclidean distances computed feature space neural networks combination adversarial training. shown proposed loss allows visually superior image generation used solve ill-posed inverse problem decoding nonlinear feature representations. similar work johnson bruna propose features extracted pretrained network instead low-level pixel-wise error measures. speciﬁcally authors formulate loss function based euclidean distance feature maps extracted network. perceptually convincing results obtained super-resolution artistic style-transfer recently wand also investigated effect comparing blending patches pixel feature space. work speciﬁcally design perceptual loss weighted combination several loss components model distinct desirable characteristics recovered image. individual loss functions described detail section adversarial network architecture general idea behind formulation allows train generative model goal fooling differentiable discriminator trained distinguish super-resolved images real images. approach generator learn create solutions highly similar real images thus difﬁcult classify encourages perceptually superior solutions residing subspace manifold natural images. contrast solutions obtained minimizing pixel-wise error measurements mse. core deep generator network illustrated figure residual blocks identical layout. inspired johnson employ block layout proposed gross wilber speciﬁcally convolutional layers small kernels feature maps followed batch-normalization layers parametricrelu activation function. increase resolution input image trained sub-pixel convolution layers proposed discriminate real images generated samples train discriminator network. architecture shown figure follow architectural guidelines summarized radford leakyrelu activation avoid max-pooling throughout network. discriminator network trained solve maximization problem equation contains eight convolutional layers increasing number ﬁlter kernels increasing factor kernels network strided convolutions used reduce image resolution time number features doubled. resulting feature maps followed dense layers ﬁnal sigmoid activation function obtain probability sample classiﬁcation. gans provide powerful framework generating plausible-looking natural images high perceptual quality. procedure encourages reconstructions move towards regions search space high probability containing photo-realistic images thus closer natural image manifold shown figure paper describe ﬁrst deep resnet architecture using concept gans form perceptual loss function photo-realistic sisr. main contributions propose srgan gan-based network optimized perceptual loss. replace mse-based content loss loss calculated feature maps network invariant changes pixel space conﬁrm extensive mean opinion score test images three public benchmark datasets srgan state large margin estimation photo-realistic images high upscaling factors describe network architecture perceptual loss section quantitative evaluation public benchmark datasets well visual illustrations provided section paper concludes discussion section concluding remarks section sisr estimate high-resolution superresolved image low-resolution input image low-resolution version highresolution counterpart high-resolution images available training. training obtained applying gaussian ﬁlter followed downsampling operation downsampling factor image color channels describe real-valued tensor size respectively. ultimate goal train generating function estimates given input image corresponding counterpart. achieve this train generator network feed-forward parametrized {wl; denotes weights biases l-layer deep network obtained optimizing sr-speciﬁc loss function lsr. training images deﬁnition perceptual loss function critical performance generator network. commonly modeled based improve johnson bruna design loss function assesses solution respect perceptually relevant characteristics. formulate perceptual loss weighted content loss adversarial loss component instead relying pixel-wise losses build ideas gatys bruna johnson loss function closer perceptual similarity. deﬁne loss based relu activation layers pre-trained layer network described simonyan zisserman indicate feature obtained j-th convolution i-th maxpooling layer within network consider given. deﬁne loss euclidean distance feature representations reconstructed image reference image widely used optimization target image many state-of-the-art approaches rely however achieving particularly high psnr solutions optimization problems often lack highaddition content losses described also generative component perceptual loss. encourages network favor solutions reside manifold natural images trying convolutional. scaled range input images images loss thus calculated images intensity range feature maps also rescaled factor obtain losses scale comparable loss. equivalent multiplying equation rescaling factor optimization adam srresnet networks trained learning rate update iterations. employed trained mse-based srresnet network initialization generator training actual avoid undesired local optima. srgan variants trained update iterations learning rate another iterations lower rate alternate updates generator discriminator network equivalent used goodfellow generator network identical residual blocks. test time turn batch-normalization update obtain output deterministically depends input implementation based theano lasagne performed test quantify ability different approaches reconstruct perceptually convincing images. speciﬁcally asked raters assign integral score super-resolved images. raters rated versions image nearest neighbor bicubic srcnn selfexsr drcn espcn srresnet-mse srresnet-vgg∗ srgan-mse∗ srgan-vgg∗ srganvgg original image. rater thus rated instances presented randomized fashion. raters calibrated versions images training set. pilot study assessed calibration procedure test-retest reliability raters subset images adding method’s images twice larger test set. found good reliability signiﬁcant differences ratings identical images. raters consistently rated interpolated test images original images perform experiments three widely used benchmark datasets testing experiments performed scale factor lowhigh-resolution images. corresponds reduction image pixels. fair comparison reported psnr ssim measures calculated y-channel center-cropped removal -pixel wide strip border images using daala package. super-resolved images reference methods including nearest neighbor bicubic srcnn selfexsr obtained online material supplementary huang drcn results obtained gg/.) srresnet images distinct testing images. obtained images downsampling images using bicubic kernel downsampling factor mini-batch crop random images distinct training images. note apply generator model images arbitrary size fully also evaluate performance generator network without adversarial component losses gg/. refer srresnet-mse srresnet. note training srresnet-vgg added additional total variation loss weight gg/. quantitative results summarized table visual examples provided figure even combined adversarial loss provides solutions highest psnr values however perceptually rather smooth less convincing results achieved loss component sensitive visual perception. caused competition mse-based content loss adversarial loss. attribute minor reconstruction artifacts observed minority srganmse-based reconstructions competing objectives. could determine signiﬁcantly best loss function srresnet srgan respect score set. however srgan-vgg signiﬁcantly outperformed srgan srresnet variants terms mos. observed trend using higher level feature maps yields better texture detail compared examples perceptual improvements srgan srresnet provided supplementary material. compare performance srresnet srgan bicubic interpolation four state-of-theart methods. quantitative results summarized table conﬁrm srresnet sets state three benchmark datasets. please note used publicly available framework evaluation reported values might thus slightly deviate reported original papers. obtained ratings srgan reference methods bsd. examples images superresolved srresnet srgan depicted supplementary material. results shown table conﬁrm srgan outperforms reference methods large margin sets state photorealistic image differences highly signiﬁcant except srcnn selfexsr. distribution collected ratings summarized figure conﬁrmed superior perceptual performance srgan using testing. shown standard quantitative measures psnr ssim fail capture accurately assess image quality respect human visual system focus work perceptual quality super-resolved images rather computational efﬁciency. presented model contrast optimized video real-time. however preliminary experiments network architecture suggest shallower networks potential provide efﬁcient alternatives small reduction qualitative performance. contrast dong found deeper network architectures beneﬁcial. speculate resnet design substantial impact performance deeper networks. found even deeper networks increase performance srresnet however come cost longer training testing times found srgan variants deeper networks increasingly difﬁcult train appearance high-frequency artifacts. particular importance aiming photo-realistic solutions problem choice content loss illustrated figure work found yield perceptually convincing results attribute potential deeper network layers represent features higher abstraction away pixel space. speculate feature maps deeper layers focus purely content leaving adversarial loss focusing texture details main difference super-resolved images without adversarial loss photo-realistic images. also note ideal loss function depends application. example approaches hallucinate ﬁner detail might less suited medical applications surveillance. perceptually convincing reconstruction text structured scenes challenging part future work. development content loss functions describe image spatial content invariant changes pixel space improve photo-realistic image results. described deep residual network srresnet sets state public benchmark datasets evaluated widely used psnr measure. highlighted limitations psnrfocused image super-resolution introduced srgan augments content loss function adversarial loss training gan. using extensive testing conﬁrmed srgan reconstructions large upscaling factors considerable margin photo-realistic reconstructions obtained state-ofthe-art reference methods.", "year": 2016}