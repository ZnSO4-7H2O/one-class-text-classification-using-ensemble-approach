{"title": "On the equivalence between Kolmogorov-Smirnov and ROC curve metrics for  binary classification", "tag": ["cs.AI", "cs.CV", "I.2; I.5.2"], "abstract": "Binary decisions are very common in artificial intelligence. Applying a threshold on the continuous score gives the human decider the power to control the operating point to separate the two classes. The classifier,s discriminating power is measured along the continuous range of the score by the Area Under the ROC curve (AUC_ROC) in most application fields. Only finances uses the poor single point metric maximum Kolmogorov-Smirnov (KS) distance. This paper proposes the Area Under the KS curve (AUC_KS) for performance assessment and proves AUC_ROC = 0.5 + AUC_KS, as a simpler way to calculate the AUC_ROC. That is even more important for ROC averaging in ensembles of classifiers or n fold cross-validation. The proof is geometrically inspired on rotating all KS curve to make it lie on the top of the ROC chance diagonal. On the practical side, the independent variable on the abscissa on the KS curve simplifies the calculation of the AUC_ROC. On the theoretical side, this research gives insights on probabilistic interpretations of classifiers assessment and integrates the existing body of knowledge of the information theoretical ROC approach with the proposed statistical approach based on the thoroughly known KS distribution.", "text": "abstract binary decisions common artificial intelligence. applying threshold continuous score gives human decider power control operating point separate classes. classifier’s discriminating power measured along continuous range score area curve application fields. finances uses poor single point metric maximum kolmogorov-smirnov distance. paper proposes area curve performance assessment proves auc_roc auc_ks simpler calculate auc_roc. even important averaging ensembles classifiers n-fold cross-validation. proof geometrically inspired rotating curve make chance diagonal. practical side independent variable abscissa curve simplifies calculation auc_roc. theoretical side research gives insights probabilistic interpretations classifiers assessment integrates existing body knowledge information theoretical approach proposed statistical approach based thoroughly known distribution. human decider power control impacts decision. classifiers produce hard decisions already presenting predicted class focus research lack control flexibility. classifiers interest multidimensional input space scalar decider sets decision threshold create classes based business kpis. study quality classifier assessed comparing predicted class true class pattern test sample potential decision thresholds. consequently performance assessment metrics also cover least range scalar region interest decision making threshold specific metrics error rates adequate assess quality flexible classifiers. paper focused area-based metrics auc_roc gini coefficient proposed auc_ks measure performance integrating impact classifier score range. related work particularly focused equivalence areas curve kolmogorov-smirnov statistical distribution curve. sample size number examples target class number examples complementary class number examples target class i-th example number examples complementary class i-th example conclusions paper demonstrated equivalence area curve receiver operating characteristics curve area curve kolmogorov-smirnov distribution fact paper proved auc_roc auc_ks. result important scientists’ disposal performance assessment binary classification consolidated statistical knowledge kolmogorovsmirnov distribution available since years telecommunications much longer debut artificial intelligence. paper opens perspective integrating theoretical approaches. despite formal proof before first author already detected numerical equivalence metrics applying kolmogorov-smirnov distribution optimization criterion embedding statistical knowledge variables transformations equivalence proved needs optimize auc_ks whenever classifier´s performance measured auc_roc. practical applications data mining theoretical result also simplifies averaging ensembles classifiers estimate overall performance. choose either vertical averaging threshold averaging former calculation involves interpolation higher level imprecision latter. threshold averaging involves return scores thresholding specific sample quantiles calculation error-bars coordinates point detailed reference return scores inherent curve parametric curve classifiers’ scores visible. curve score rank explicit independent variable abscissa error-bars vertical axis needs calculate error-bars specific quantiles apply proposed transformation error-bars projected coordinates. much simpler precise approach analysed furthermore decision support systems managers need define decision threshold score produce binary decision. score directly available kolmogorov-smirnov distribution. direct score important assessing technical separability classifier also simulating operating point business performance indicators interactive environment would effective decision making control parameter. research completed equivalence established krzanowski hand curves single point metrics extending areas curves important metrics binary classification. brought perspective field interpreting binary decisions impacts much beyond paper. possible impact using auc_ks metrics could definition confidence intervals performance assessment classifiers without need resample data. kolmogorov-smirnov statistics however developed maximum vertical adeodato arnaud role temporal feature extraction bagging neural networks solving wcci ford classification challenge. proceedings international joint conference neural networks doi=http//dx.doi.org/./ijcnn... souza continuous variables segmentation reordering optimal performance binary classification tasks. proceedings international joint conference neural networks (beijing china july doi=http//dx.doi.org/./ijcnn...", "year": 2016}