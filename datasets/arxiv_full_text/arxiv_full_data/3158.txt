{"title": "Recurrent Attentional Networks for Saliency Detection", "tag": ["cs.CV", "cs.LG", "stat.ML"], "abstract": "Convolutional-deconvolution networks can be adopted to perform end-to-end saliency detection. But, they do not work well with objects of multiple scales. To overcome such a limitation, in this work, we propose a recurrent attentional convolutional-deconvolution network (RACDNN). Using spatial transformer and recurrent network units, RACDNN is able to iteratively attend to selected image sub-regions to perform saliency refinement progressively. Besides tackling the scale problem, RACDNN can also learn context-aware features from past iterations to enhance saliency refinement in future iterations. Experiments on several challenging saliency detection datasets validate the effectiveness of RACDNN, and show that RACDNN outperforms state-of-the-art saliency detection methods.", "text": "convolutional-deconvolution networks adopted perform end-to-end saliency detection. work well objects multiple scales. overcome limitation work propose recurrent attentional convolutional-deconvolution network using spatial transformer recurrent network units racdnn able iteratively attend selected image sub-regions perform saliency reﬁnement progressively. besides tackling scale problem racdnn also learn context-aware features past iterations enhance saliency reﬁnement future iterations. experiments several challenging saliency detection datasets validate effectiveness racdnn show racdnn outperforms state-of-the-art saliency detection methods. saliency detection refers challenging computer vision task identifying salient objects imagery segmenting object boundaries. despite studied years saliency detection still remains unsolved research problem tough goal model high-level subjective human perceptions. recently saliency detection methods received considerable amount attention wide growing range applications facilitated notable applications saliency detection object recognition visual tracking image retrieval traditionally methods saliency detection leverage low-level saliency priors contrast prior center prior model approximate human saliency. however low-level priors hardly capture high-level information objects surroundings traditional methods still away saliency works context human perceptions. incorporate high-level visual concepts saliency detection framework figure example applying recurrent attention-based saliency reﬁnement initial saliency produced convolutional-deconvolutional network. compared initial saliency reﬁned saliency signiﬁcantly sharper edges preserves object details. natural consider convolutional neural networks computer vision tasks cnns shown remarkably effective. also ﬁrst learning algorithm achieve human-competitive performances large-scale image classiﬁcation task high-level vision task like saliency detection. although works developing cnns visual saliency modeling either focus predicting ﬁxations applying cnns predict saliency value visual sub-units independently besides conventional cnns downsize feature maps multiple convolutional pooling layers lose detailed information problem densely segmenting salient objects. convolutionaldeconvolutional network semantic segmentation paper adapt network detect salient objects end-to-end fashion. framework input image output corresponding saliency map. deconvolutional network variant performs convolution unpooling produce dense pixel-precise outputs. however cnn-decnn works poorly objects multiple scales ﬁxed-size receptive ﬁelds. overcome limitation propose recurrent attentional network reﬁne saliency maps generated cnndecnn. racdnn uses spatial transformer recurrent network units iteratively attend ﬂexibly-sized image sub-regions reﬁnes saliency predictions sub-regions. shown figure racdnn perform saliency detection ﬁner scales ability attend smaller sub-regions. another advantage racdnn attended sub-regions previous iterations provide contextual information saliency reﬁnement sub-region current iteration. example figure racdnn make visible front legs deers help reﬁning saliency values less-visible back legs. perform experiments several challenging saliency detection benchmark datasets compare proposed method state-of-the-art saliency detection methods. experimental results show effectiveness proposed method. saliency detection methods coarsely categorized bottom-up top-down methods. bottom-up methods make level local visual cues like color contrast orientation texture. top-down methods based high-level task-speciﬁc prior knowledge. recently deep learning-based saliency detection methods successful. instead manually deﬁning tuning saliencyspeciﬁc features methods learn low-level features high-level semantics useful saliency detection straight minimally processed images. however works employ neither attention mechanism improve saliency detection. best knowledge ﬁrst work exploit recurrent attention along deep learning saliency detection. attention models variant neural networks aiming model visual attention. often used recurrent neural networks achieve sequential attention. formulates recurrent attention model surpasses image classiﬁcation tasks. extends work making model deeper apply multi-object classiﬁcation task. overcome training difﬁculty recurrent attention model propose differentiable attention mechanism apply generative image generation image classiﬁcation. propose differentiable efﬁcient sampling-based spatial attention mechanism spatial transformation used. unlike works mostly small attention networks low-resolution digit classiﬁcation task attention mechanism used work much complex tied large cnn-decnn dense pixelwise saliency reﬁnement. section describe proposed saliency detection method detail. method initial saliency maps ﬁrst generated convolutional-deconvolutional network takes entire images input outputs saliency maps. saliency maps reﬁned iteratively another cnn-decnn operated recurrent attentional framework. unlike initial saliency prediction done single feedforward passes entire images saliency reﬁnement done locally selected image sub-regions progressive way. every processing iteration recurrent cnn-decnn attends image sub-region spatial transformer-based attention mechanism. attentional saliency reﬁnement helps alleviate inability cnndecnn deal multiscale saliency detection. addition sequential nature attention enables network exploit contextual patterns past iterations enhance representation attended sub-region hence improve saliency detection performance. conventionally cnns downsize feature maps multiple convolutional pooling layers construct spatially compact image representations. although spatially compact feature maps well-suited wholeimage classiﬁcation tasks tend produce coarse outputs applied dense pixelwise prediction tasks tackle dense prediction tasks multi-layered convolutional learning setting append deconvolutional network shown convolutional-deconvolutional framework learns globally meaningful representations decnn upsizes feature maps learns increasingly localized representations. unlike work preserve spatial information cnn’s output using convolutional layers. practice preserving spatial information works better without preserving preserved spatial information provides good head start decnn spatial transformer achieves spatial attention mapping input feature ra×b×c output feature ra′×b ′×c. spatial sizes different must share number channels since consider spatial attention. given spatial transformer ﬁrst computes transformation matrix determines point coordinates transformed example v-to-u coordinatewise transformation shown figure wide range transformation types supported spatial transformer. simplicity restrict transformation basic form spatial attention involving isotropic scaling translation. afﬁne transformation matrix isotropic scaling translation given scaling horizontal translation vertical translation parameters respectively. aligning recent works recurrent visual attention modeling parameters deciding attention takes place produced localization network floc. details floc introduced equation section subsequently transformation matrix applied regular coordinates obtain sampling coordinates. based sampling coordinates formed sampling feature points using bilinear interpolation. generally attention mechanisms applied input images. however saliency reﬁnement method decnn demands input output ends point image sub-region. propose inverse spatial transformer reﬁned saliency output back sub-region attended input end. assuming transformation matrix input inverse spatial transformer takes decnn almost identical conventional cnns except minor differences. firstly deconvolutional networks convolution operations often carried resulting feature maps retain spatial sizes input feature maps. done adding appropriate zero paddings beforehand. secondly pooling operators adopted cnns substituted unpooling operators decnns. given input feature maps unpooling operators work upsizing feature maps contrary pooling operators achieve. variants unpooling methods proposed previously tackle several computer vision tasks involving spatially large dense outputs. paper employ simple unpooling method demonstrated whereby block input feature maps mapped left corner blank output block spatial size effectively increases spatial size whole feature maps factor processing pipeline cnn-decnn saliency detection ﬁrst transforms input image spatially compact hidden representation cnn. then transformed saliency decnn decnn. obtain ﬁnal saliency lies within probability range perform passing saliency element-wise sigmoid activation function given groundtruth saliency loss function cnn-decnn saliency detection binary cross-entropy resulting network trained end-toend fashion perform saliency detection. although cnndecnn achieve pixelwise labeling works poorly objects multiple scales ﬁxed-size receptive ﬁelds used. furthermore long-distance contextual information important saliency detection canwell captured locally applied convolution ﬁlters decnn. address issues propose recurrent attentional network iteratively attends image sub-regions saliency reﬁnement described next subsections. realize attention mechanism saliency reﬁnement adopt spatial transformer network proposed spatial transformer sub-differentiable samplingbased neural network spatially transform input feature maps resulting output feature maps attended region input feature maps. differentiability spatial transformer relconvolution ﬁlters input-to-hidden connections convolution ﬁlters hiddent-tohidden connections consecutive iterations bias term. hidden-to-hidden connections allow contextual information gathered previous iterations passed future iterations. since racdnn attentional already attended sub-regions help guide saliency reﬁnement upcoming sub-regions. beneﬁcial task saliency detection saliency object highly dependable surrounding regions. different conventional rnns matrix product inputto-hidden hidden-to-hidden connections connections method convolution operations using recurrent connections convolutional preserve spatial information hidden representation mentioned section preserving spatial information hidden representation decnn favorable decnn’s upsizing-related operations. recurrent neural networks class neural networks developed modeling sequential dependencies sub-instances sequential data. hidden state time step iteration computed non-linear function input previous iteration’s hidden state hi−. given input iteration hidden state formulated learnable weights inputto-hidden hidden-to-hidden connections respectively bias term nonlinear activation function. explicitly making current hidden state dependable previous hidden state able encode contextual information gained past iterations future iterations. result powerful representation learned. work combine recurrent computational structure cnn-decnn well spatial transformer attention mechanism establish recurrent attentional convolutional-deconvolutional networks illustrated figure given intiail saliency produced initial cnn-decnn racdnn iteratively uses spatial transformer attend sub-region applies cnn-decnn perform saliency reﬁnement attended sub-region learning powerful context-aware features using rnn. spatial transformer function produces output image sampled input image given transformation matrix computed previous iteration localization network floc. then racdnn uses recurrent-based encode attended input spatially-compact hidden representation similar except used recurrent setting recurrent instances share network parameters. form recurrent hidden state iteration representation combined hidden state previous iteration perform saliency reﬁnement initial saliency maps using decnn initial saliency maps generated global cnn-decnn single forward passes. instead replacing values initial saliency output racdnn iteration initial saliency reﬁned cumulatively number iterations. iteration saliency reﬁned added saliency output decnn spatially transformed back attended sub-region using inverse spatial transformer unattended regions saliency reﬁnement values zero thus regions affect number iterations section sigmoid activation function applied resulting ﬁnal saliency ¯sr. besides saliency reﬁnement outputs every iteration racdnn generate determine sub-region attend next iteration. simple achieve simply treating input fully-connected network-based regressor. however model sequential dependencies attended locations simplistic approach insufﬁcient. focus mainly modeling contextual dependencies saliency reﬁnement multiple kinds dependency. better model locational dependencies propose another recurrent layer racdnn. hidden state second recurrent layer iteration denoted formulated weights bias semantically counterparts ﬁrst recurrent layer equation input second recurrent layer output ﬁrst recurrent layer making racdnn stacked recurrent network. considering nature regression task fully-connected layers recurrent input hidden connections second recurrent layer. finally given floc used regress transformation matrix next iteration iteration provided accepts whole image region input. observing full image region iteration helps racdnn better decide sub-regions attend subsequently. similar cnn-decnn used saliency detection loss function radcnn binary cross-entropy ﬁnal saliency output groundtruth saliency since every component radcnn differentiable errors backpropagated network layers parameters radcnn making trainable gradient-based optimization methods network weights decnn learnable parameters radcnn. initial saliency detection cnn-decnn independent cnn-decnn used saliency reﬁnement stage. part initialized weights vgg-cnn-s relatively powerful model pre-trained imagenet dataset. vgg-cnn-s consists convolutional layers fully-connected layers. discard fully-connected layers vgg-cnn-s retain convolutional pooling layers network initialization. accepts images inputs outputs feature maps feature channels. decnn part initial cnn-decnn network convolutional layers unpooling layer convolutional layer. increase representational capability decnn without adding many weight parameters append layer convolution layer convolution kernel decnn convolutional layer. initial cnn-decnn decnn outputs saliency map. output size achieves good balance computational complexity saliency pixels details. performance evaluation saliency resized input image’s original size. initial cnn-decnn trained adam default learning settings. mentioned previously decnn used racdnn trained executed independently initial cnn-decnn. hand decnn initialized using pre-trained weights decnn initial cnn-decnn. recurrent layers racdnn rectiﬁed linear unit employed non-linear activation feature maps hidden state size feature channels. second recurrent layer’s hidden state feature representation -dimensional vector. weight parameters wloc wloc floc matrices respectively. number recurrent iterations racdnn saliency detection experiments. racdnn trained using rmsprop initial learning rate learning rate reduced order magnitude whenever validation performance stops images belong object classes butterﬂy coffee jump giraffe plane. challenging images contain salient object. hkuis recently released saliency detection dataset annonated images. ecssd challenging saliency detection dataset many semantically meaningful structurally complex images. contains images. small saliency dataset images. image salient objects. evaluate proposed method based precisionrecall curves commonly used evaluation metric saliency detection. saliency output thresholded integer values within range threshold value binarized saliency output compared binary groundtruth mask obtain pair precision-recall values. another popular evaluation metric saliency detection f-measure combination precision recall values. following recent saliency detection benchmark paper weighted f-measure favors precision recall precision×recall reported maximum f-measure computed precision-recall pairs good summary detection performance according even though f-measure commonly used evaluation metric saliency detection comprehensive enough consider true negative saliency labeling. comprehensive experimental evaluation consider another evaluation metric known mean absolute error adopted given width height saliency map; real-valued saliency output normalized range saliency groundtruth. saliency binarization needed measures mean absolute differences groundtruth saliency pixels given saliency pixels. improving. training gradients hard-clipped within range mitigate gradient explosion problem occurs training recurrentbased networks. speed training improve training convergence apply batch normalization weight layers initial cnn-decnn radcnn. saliency detection methods employ object segmentation techniques output image segments consistent saliency values within segment. furthermore edges output segments sharp. achieve similar effects apply mean shift-based segmentation method outputs racdnn post-processing step. learning-based methods require amount training samples generalize examples well. however saliency detection datasets small. possible train deep models well experimental evaluations done dataset split training testing validation sets proportions. here follow dataset procedure recent deep learningbased saliency detection work train deep models proposed method saliency datasets different datasets used experimental evaluations. training datasets dut-omron rgbd salient object detection dataset imagenet segmentation dataset data samples datasets reach total number roughly size dataset used randomly split combined datasets training samples validation samples. although training considered large saliency detection context still small deep learning methods cause overﬁtting. thus apply data augmentation form cropping translation color jittering training samples. evaluate proposed number challenging saliency detection datasets msrak largest publicly available saliency detection dataset containing annonated saliency images. thurk highlight advantages recurrent attention mechanism proposed network racdnn cnndecnn baseline methods experiments. compared proposed method baseline cnn-decnn recurrent attention mechanism perform iterative saliency reﬁnement. baseline method cnn-decnn paired non-recurrent attentional convolutional-deconvolutional network place racdnn. nacdnn racdnn variant whose layers made non-recurrent. removing recurrent connections nacdnn cannot learn context-aware features useful saliency reﬁnement despite attention mechanism. computational iteration nacdnn works almost like cnn-decnn except localization network floc accepts cnn’s output input outputs spatial transformation matrix. compare proposed method baseline methods f-measure evaluation metrics. fmeasure scores mean square errors comparisons baselines shown table datasets evaluation metrics proposed method achieves better results baseline methods. shows racdnn help improve saliency outputs cnn-decnn using recurrent attention mechanism alleviate scale issues cnn-decnn learn region-based contextual dependencies easily modeled mere convolutional deconvolutional network operations. second baseline method nracdnn attention mechanism performs better non-attentional ﬁrst baseline. however lack recurrent connections nracdnn inferior racdnn exploit contextual information past iterations saliency reﬁnement. addition baseline methods compare proposed method cnn-decnn racdnn several state-of-the-art saliency detection methods rrwr bsca drfi drfi top-performing methods evaluated rrwr bsca recent saliency detection works. obtain results methods original codes provided authors recommended parameter settings. precision-recall curves given figure figure qualitative saliency results evaluated images. leftmost column input image saliency groundtruth saliency output maps proposed method mean-shift post-processing mcdl rrwr bsca drfi compute curves based saliency maps generated proposed method. overall proposed method cnn-decnn racdnn performs better evaluated state-of-the-art methods. especially datasets complex scenes performance gains proposed method state-of-the-art methods noticeable. also compare proposed method cnn-decnn racdnn state-of-the-art methods terms f-measure scores mean square errors evaluation metrics performance gains methods signiﬁcant. hkuis ecssd dataset f-measure improvements proposed method next top-performing method drfi proposed method also pushes maes challenging datasets large margin. besides quantitative results show qualitative results figure proposed method cnn-decnn racdnn better detect multiple intermingled salient objects shown second image rabbit. method detect objects well. success method image attributed attention mechanism allows attend different object regions local reﬁnement making less likely negatively affected distant noises objects. however proposed method tends fail detect salient objects mostly made background-like colors textures evaluate proposed method cnn-decnn racdnn compare recent deep learningbased saliency detection methods hkuis ecssd datasets. trained models provided authors. f-measure scores maes given table showing paper introduce novel method using recurrent attention convolutional-deconvolutional network tackle saliency detection problem. proposed method shown effective experimentally. still performance proposed method limited quality initial saliency maps. overcome limitation recurrent attentional network potentially revamped detect saliency scratch end-to-end manner. also work readily adapted vision tasks require pixel-wise prediction", "year": 2016}