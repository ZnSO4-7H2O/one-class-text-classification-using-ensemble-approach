{"title": "Early Detection of Combustion Instabilities using Deep Convolutional  Selective Autoencoders on Hi-speed Flame Video", "tag": ["cs.CV", "cs.LG", "cs.NE"], "abstract": "This paper proposes an end-to-end convolutional selective autoencoder approach for early detection of combustion instabilities using rapidly arriving flame image frames. The instabilities arising in combustion processes cause significant deterioration and safety issues in various human-engineered systems such as land and air based gas turbine engines. These properties are described as self-sustaining, large amplitude pressure oscillations and show varying spatial scales periodic coherent vortex structure shedding. However, such instability is extremely difficult to detect before a combustion process becomes completely unstable due to its sudden (bifurcation-type) nature. In this context, an autoencoder is trained to selectively mask stable flame and allow unstable flame image frames. In that process, the model learns to identify and extract rich descriptive and explanatory flame shape features. With such a training scheme, the selective autoencoder is shown to be able to detect subtle instability features as a combustion process makes transition from stable to unstable region. As a consequence, the deep learning tool-chain can perform as an early detection framework for combustion instabilities that will have a transformative impact on the safety and performance of modern engines.", "text": "paper proposes end-to-end convolutional selective autoencoder approach early detection combustion instabilities using rapidly arriving ﬂame image frames. instabilities arising combustion processes cause signiﬁcant deterioration safety issues various human-engineered systems land based turbine engines. properties described self-sustaining large amplitude pressure oscillations show varying spatial scales periodic coherent vortex structure shedding. however instability extremely diﬃcult detect combustion process becomes completely unstable sudden nature. context autoencoder trained selectively mask stable ﬂame allow unstable ﬂame image frames. process model learns identify extract rich descriptive explanatory ﬂame shape features. training scheme selective autoencoder shown able detect subtle instability features combustion process makes transition stable unstable region. consequence deep learning tool-chain perform early detection framework combustion instabilities transformative impact safety performance modern engines. deep learning models shown outperform state-of-the-art machine learning techniques handling large dimensional data spaces learn hierarchical features order perform various machine learning tasks. however studied applications primarily domains image speech texts processing. example convolutional neural network-based applications include graph transformer networks rapid online recognition handwriting natural language processing large vocabulary continuous speech recognition avatar captcha machine image recognition training machines distinguish human faces computer generated faces. paper propose novel selective autoencoder approach within deep convolutional architecture implicit labeling order derive soft labels extreme classes explicitly labeled either positive negative examples. particular property signiﬁcant tracking continuous temporal phenomenon transition combustion stability instability labels extreme states available intermediate state labels not. explicit labels utilized selectively mask selective features allowing features remain. figure shows greyscale images describing typical gradual development instability stated parameters swirl-stabilized combustor used experiment. labeling considered multi-class classiﬁcation problem example three stage hidden markov models used handling speech recognition problems parts speech tagging sequence labeling derive relationships observations state state state dynamic systems. maximum entropy markov model discriminative modiﬁcation introduced overcome latter’s recall precision problems especially labeling texts. models conditional probability desired labels learnt directly based unimplicit soft labeling problem train deep model using hi-speed ﬂame videos explicit labels stable unstable ﬂames recognizes onset instability early combustion process makes transition stable unstable region. conceptually similar cognitive psychologists’ description human reasoning object classiﬁcation example consider child taught intrinsic classes. similar problem detecting cross breed wolf including close animal either classes. contributions main contributions paper delineated below track onset combustion instability detect pre-transition phenomena ’intermittence’. intermittence temporary blast instability characterized small partially observable coherent structure. paper organization paper introduced earlier section idea motivating problem. next section apart discuss prior work proposed approach chosen problem essential part attack technique. section main architecture problem discussed followed measure similarity access result quantitatively. section provided opportunity introduce problem dataset collection implementation composite architecture. results obtained hypothesis discussed section conclude paper section well give insights direction future works. section provides brief overview convolutional networks description example problem detecting combustion instability notion implicit labeling. convolutional networks type deep networks oﬀer discriminative advantages memm well providing globally relationship observations crf. architectures rely primarily local neighborhood matching data dimension reduction using nonlinear mapping label bias defects memm conditional random field joint markov random field states conditioned whole observations later explored enabled considering global labels observation localization labels memm however labeling case made computationally complex relaxation statistical independence assumption observations models assume. recurrent neural networks utilized sequence labeling problems cyclic connections neurons well temporal modeling ability. although earlier construction rnns known short ranged memory issues restrictive unidirectional information context access formulation bidirectional long short term memory resolved issues. however construction adds complexity model signiﬁcantly typically rnns connected output layer. application standpoint early detection instability combustion chambers dynamic systems aids anticipative actions reducing consequent eﬀects. visualizing features characterizing intermediate frames spectrum important approach unravel processes precedes instability. authors introduced deep belief networks dbns viable technique achieve view exploring machine learning conﬁrmation. improved applying modular neural-symbolic approach another publication. paper propose deep convolutional selective autoencoder-based anomaly detection framework crucial physical process combustion pure black model unacceptable order enable domain interpretation better understanding underlying complex physics. combustion instability signiﬁcant anomaly characterized high-amplitude ﬂame oscillations discrete frequencies reduces eﬃciency longevity aircraft gas-turbine engines. full-blown instability diﬀerentiated stable combustion video analysis high conﬁdence unstable combustion ﬂames show distinct coherent structures similar ’mushroom’ shapes. extremely diﬃcult detect onset instability early fast spatio-temporal transience video data. therefore instability detection problem boils unit feature maps common shared weights kernels eﬃcient training relatively compared fully connected layers lower trainable parameters added additive bias squashed. feature extraction classiﬁer learning main functions networks however learn expressive features determine invariance rich codes embedded data follow fully connected layer reduce dimensionality data important codes dimension examples. many image processing complex simulations depend invariance property convolution neural network stated prevent overﬁtting learning expressive codes. feature maps able preserve local neighborhood patterns receptive ﬁeld over-complete dictionaries fully connected layers tend complement learned features propagating highly active weights serving classiﬁer. detailed review found authors note advantage local correlation enforcing convolution spatio-temporal recognition. eﬃcient learning purposes convolutional networks able utilize distributed mapreduce frameworks well computing. combustion instability reduces eﬃciency longevity aircraft gas-turbine engines. considered signiﬁcant anomaly characterized high-amplitude ﬂame oscillations discrete frequencies. frequencies typically represent natural acoustic modes combustor. combustion instability arises positive coupling heat release rate oscillations pressure oscillations. coherent structures ﬂuid mechanical structures associated coherent phase vorticity structures whose generation mechanisms vary system wise cause large scale velocity oscillations overall ﬂame shape oscillations curling stretching. structures caused shed/generated duct acoustic modes forcing amplitudes high. recent research interest detection correlation coherent structures heat release rate unsteady pressure. popular methods resorted detection coherent structures proper orthogonal decomposition dynamic mode decomposition tools spectral theory derive spatial coherent structure modes. semi-supervised training classiﬁcation takes advantage labels ﬁnal layers. variant structured labeling called implicit labeling used derive soft labels extreme classes explicitly labeled either positive negative examples. explicit labels usually utilized selectively mask feature especially interested leaving parsing class interest. however explicit labels serve classiﬁer intrinsic classes test sets learnt training set. implicit labeling also bears similarity sequence labeling extra constraint utilizing prior knowledge provided explicit label. fused convolutional auto-encoder architecture algorithm described section determine intermediate transition phases– mixed breed wolf instance–and importantly degree animal wolf. thus attempts derive soft labels expert-informed hard-mined labels illustrated composite architecture. based convolutional network’s performances several similar tasks reviewed found suitable candidate composite architecture examine hypothesis soft label generation. previously utilized convnet architecture end-to-end convolutional auto-encoder designed tested examine another perspective current problem instead adding symbolic graphical model stsa level. constituent steps model learning data outlined below. generated represents original images masked frames considered explicitly ground truth. images normalized pixel intensities zero mean standard deviation preprocessing. convolutional layers convolutional autoencoders start propagation input layer convolution layer penultimate step output layer deconvolution layer. convolution deconvolution squashing function denoting convolution operator joint weights wzicc biases input previous layer xzimn. enhance invariance further pooling done representative features selection local neighborhood. pooling schemes exist chose highly activated units take figure structure convolutional autoencoder associated layer parameters. best viewed screen color. encoder portion extracts meaningful features convolution sub-sampling operations decoder portion reconstructs output original dimensions deconvolution upsampling. unpooling layer reversal pooled dimension done stretching widening identiﬁed features ﬁlters previous layer. also upscaling feature maps around axes symmetry reconstructed feature maps optimized back-propagation algorithm. error minimization phase akin feedback stage control paradigm scenario teacher– labeled data–provides feedback performance measure well student–the machine–has learned features related particular application–the task. process included regularization function avoid overﬁtting data. nesterov momentum-based stochastic gradient descent used improved results compared loss functions adaptive subgradient adaptive learning rate method reconstruction error updates given reconstructed output ˆymn labels ymn. weights biases layfully connected layers feature maps previous layers ﬂattened vectors passed bottleneck layer. encoding layer encodes important feature input previous layer following expression stands encoder decoder functions respectively nonlinear function known rectiﬁed linear unit denotes biases denotes weights layer. subscripts indicates encoder decoder. relu nonlinearity performed argument given towards downstream testing proposed architecture transition videos seconds length collected stable combustion progressively becomes unstable ’intermittence’ phenomenon reducing increasing afr. transition conditions follows clarity data sets named respectively analysis subsequent sections paper. frames labeled stable remaining labeled unstable. images combination datasets diﬀerent premixing lengths either wide range fuel lpms combustor either stable unstable state. learning rate momentum found train model best nesterov based stochastic gradient descent formulation. network trained epochs order conveniently strike good minima validation error. stated earlier widen parameter search space locating minima helping minimize diﬀerence test training. also enhances sparsity algorithm ensuring likely units activated. training done titan black learning rate equivalent step size optimization problems. details found background materials presented thus subsection important aspects embedded improvements. similarity index selected instability measure correlation ratio reported mathematically proven computational requirement reducing already-large computation architecture. also useful ability quantify relationship image frames diﬀering intensities well directly including actual images computation hence choice performance metric. assuming inzi enumerations pixels respectively. like chosen measure dissimilarity norm correlation ratio usually varies uncorrelated images fully correlated images. dataset collection experimental setup collect training data learning coherent structures thermoacoustic instability induced laboratory-scale combustor swirler figure shows setup detail description found combustor diﬀerent instability conditions induced seconds hi-speed videos captured levels premixing. figure presents secuda cores equipped video memory using python-based machine learning frameworks theano lasagne nolearn lasagne oﬀers wide variety control layer types nonlinearity types objective functions interfacing theano many features figure schematics experimental apparatus. settling chamber inlet duct inlet optical access module test section small extension ducts pressure transducers swirler location transducer port location fuel injection location visible coherent structure greyscale images full premixing experimentally less costly produce results. algorithm training done batches training examples found suitable cross validation. note batch iterative training nolearn lasagne functions replaced theano’s lenet early stopping algorithm showed improvements test performance. architecture shows layers interlinked training stage leads overall learnable parameters. training progress indicated algorithm’s loss proﬁle showing validation loss validloss reduction well training loss denoted trainloss. note training loss raised lowering regularization parameter order allow training epochs. helps reduce validation loss better result. leveraging capability generating results trained model based section results obtained algorithm discussed analyzed closely. first consider detection presence region properties frames supposedly region early instability detection paradigm. discuss network explores space stable unstable regions softer labels assuming system static. early detection combustion instability stable region denoted spectrum unstable region spectrum. emphasis training algorithm done explicitly available ground truth labels. categorized frames stable ﬂame types frames unstable ﬂame types. unit frames stable region given labels unstable region retained algorithm training. figure shows algorithm’s ability reproduce training frames trained algorithm’s selective ability shown feature maps model shown highlight detected features reconstructed outputs. important feature maps visualized fully connected layers serve least important purposes namely reduce image dimensions towards rich explanatory features ensuring structural consistency reshaping gradually restore feature maps output images dimensions similar input. frames unstable region corresponding feature maps showed activated units responding mushroom structures characteristic unstable combustion. highlighted stable region information seen rapidly diﬀusing input hidden layers. layer joint parameters capture trade-oﬀ discarded retained information stable unstable training sets. based understanding hypothesized trained model could identify frames ﬂame types intersecting stable unstable regions discussed motivating example. subsequent parts section devoted analysis. figure results transition protocols plate a)to b)to c)to purple arrows indicate expected results stability instability green arrows diﬀerent intensities indicate strength early instability presence supposedly stability region anomaly features note similarity measure introduced section used evaluate strength algorithm’s ability mask examples closer stable region compared nearer unstable region. thereafter local regression smoothing applied obtain weighted moving averages visualizing transitional trends. general trends ﬂuctuations instability measures shown results similar reported framework used neural-symbolic approach combination convolutional neural networks symbolic time series analysis obtain instability measures. output frames stable region suppressed output frames unstable region entirely visible. essentially model become ﬁlter enables desired features show running test data diﬀerent transition conditions trained model results presented ﬁgure shows capability model suppressing unwanted features masking revealing desired outputs. worthy mention intermittency precursor combustion instability. regions train model produces output partially reveals unstable features highlighted phenomenon observed reported intermittency phenomena observed pressure data analysis image data. hence proposed metric localizes intermittencies prior fullblown instability prominence state-ofthe-art approaches better accuracy tracking intermittence leads early detection instability less false alarm frame labeling computationally complex decision attempting implicit labeling results would search frames adjacent neighbors given frame. clear terms means ﬁnding frames come chosen frame. kind search usually diﬃcult primitive dimensional local labeling algorithms memm dependency depth labeling bias limitations respectively. hypothesize simplifying high dimensional problem using single value average instability measure composite convolutional auto-encoder would facilitate soft labeling. especially required regions abrupt transitioning averagely linear lines superimposed frames nearer complex topology frames’ arrangement could simpliﬁed linear plot enhances determination likely nearest neighbor frames given reference frame. proposed approach adjacency labeling transition protocols shown considering averaged sections abrupt transition gradual labels could explored implicit neighborhood graph decision. note data case smoothened remove transients introduced dynamics combustor. however richness dynamics signiﬁes defect approach labeling problems generic applications. lines average linear lines examples static system similar result considered. results transition protocol closest explicit labels example used training algorithm lines constant sudden jump. also neighboring graphs less graduated whose protocols represent steady rise transition property average instability measure. however protocol subtlety fuzzy transition region prominence second region’s property ﬁrst. closest representation implicit labeling problem among datasets shown given frame random would able determine sets neighbors regions graduation average instability measure especially random shuﬄing frame positions cases knowledge ground truth states individual frames available. also implicit labeling helps higher level learning ﬂame dynamics video using probabilistic graphical model stsa static applications. application however gradual build lobes mushroom-like structure frame frame well increasing average instability measure pointer graduated transitioning ability framework. note dynamics regions line would hide information frames selected there. thus could easily frames back original position static applications soft labels generated. however expected discriminative advantage network would intuitively support presumption. consequence marginalizing hidden layer given previous layer aided determining roughly neighboring ﬂame patterns thus providing coarse ﬁner labels. end-to-end convolutional selective autoencoder developed generate fuzzy labels prior knowledge hard labeled examples. framework used perform early detection combustion instabilities using hi-speed ﬂame video. validation results presented using data laboratory scale swirl-stabilized combustor. results discussed light high ﬁdelity similarity metric used gauge closeness ground truth unstable ﬂames. using measure architecture extended address neighborhood implicit graph labeling problem. framework generalized highdimensional data order perform soft-labeling interpolation explicit labels. framework shown eﬃcient diagnostics technique combustion process laboratory experiments large scale validation underway demonstrate wide-range applicability. apart that framework also enabling domain experts learn coherent structures appear combustion instabilities. technical point view future research involve extending framework multi-class implicit labeling problems. tion performed vikram ramanan satyanarayanan chakravarthy indian institute technology madras chennai. authors also gratefully acknowledge support nvidia corporation donation geforce titan black used research. collobert weston. uniﬁed architecture natural language processingdeep neural networks multitask learning. international conference machine learning pages sarkar lore sarkar. early detection combustion instability neural-symbolic analysis hi-speed video. workshop cognitive computation integrating neural symbolic approaches montreal canada december sarkar lore sarkar ramaman chakravarthy phoha ray. early detection combustion instability hi-speed ﬂame images deep learning symbolic time series analysis. annual conference prognostics health management management society pages scherer muller behnke. evaluation pooling operations convolutional architectures object recognition. intenational conference artiﬁcial neural networks icann pages", "year": 2016}