{"title": "A Causal And-Or Graph Model for Visibility Fluent Reasoning in  Human-Object Interactions", "tag": ["cs.CV", "cs.AI"], "abstract": "Tracking humans that are interacting with the other subjects or environment remains unsolved in visual tracking, because the visibility of the human of interests in videos is unknown and might vary over times. In particular, it is still difficult for state-of-the-art human trackers to recover complete human trajectories in crowded scenes with frequent human interactions. In this work, we consider the visibility status of a subject as a fluent variable, whose changes are mostly attributed to the subject's interactions with the surrounding, e.g., crossing behind another objects, entering a building, or getting into a vehicle, etc. We introduce a Causal And-Or Graph (C-AOG) to represent the causal-effect relations between an object's visibility fluents and its activities, and develop a probabilistic graph model to jointly reason the visibility fluent change (e.g., from visible to invisible) and track humans in videos. We formulate the above joint task as an iterative search of feasible causal graph structure that enables fast search algorithm, e.g., dynamic programming method. We apply the proposed method on challenging video sequences to evaluate its capabilities of estimating visibility fluent changes of subjects and tracking subjects of interests over time. Results with comparisons demonstrated that our method clearly outperforms the alternative trackers and can recover complete trajectories of humans in complicated scenarios with frequent human interactions.", "text": "figure illustration visibility ﬂuent changes. three states visible occluded contained. person approaches vehicle state changes visible occluded contained person person vehicle passes person occluded. state person changes visible occluded corresponding top-view trajectories. numbers persons arrows indicate moving direction. traditional trackers likely fail objects become invisible proposed method could jointly infer objects’ locations visibility ﬂuent changes helps recover complete trajectories. best viewed color. sequences likely fail track subjects whose visibility status change. deal challenges work propose explicitly reason subjects’ visibility status time tracking subjects interests surveillance videos. developed techniques slight modiﬁcations generalized scenarios e.g. hand-held cameras driverless vehicles. idea method introduce ﬂuent variable subject interest explicitly indicate his/her visibility status videos. fluent ﬁrstly used newton denote time varying status object. also used represent varying object status commonsense reasoning paper visibility status objects described ﬂuents varying time. illustrated fig. person person walking parking person person entering sedan. visibility status person’s person’s changes ﬁrst visible occluded tracking humans interacting subjects environment remains unsolved visual tracking visibility human interests videos unknown might vary times. particular still difﬁcult state-of-the-art human trackers recover complete human trajectories crowded scenes frequent human interactions. work consider visibility status subject ﬂuent variable whose changes mostly attributed subject’s interactions surrounding e.g. crossing behind another objects entering building getting vehicle etc. introduce causal and-or graph represent causal-effect relations object’s visibility ﬂuents activities develop probabilistic graph model jointly reason visibility ﬂuent change track humans videos. formulate joint task iterative search feasible causal graph structure enables fast search algorithm e.g. dynamic programming method. apply proposed method challenging video sequences evaluate capabilities estimating visibility ﬂuent changes subjects tracking subjects interests time. results comparisons demonstrated method clearly outperforms alternative trackers recover complete trajectories humans complicated scenarios frequent human interactions. tracking objects interest videos fundamental computer vision task great potentials many video based applications e.g. security surveillance disaster response border patrol. applications critical problem obtain complete trajectory object interest observing moving scene camera views. challenging problem since object interest might frequent interactions surrounding e.g. entering vehicle building objects e.g. passing behind another subject. interactions visibility status subject varying time e.g. changes invisible visible vice versa. literature state-of-the-art trackers employ appearance cues motion cues localize subjects video correct visibility statues correctly recover complete trajectories. contrast alternative trackers recover part trajectories occlusion/containment. contributions. three major contributions proposed framework causal and-or graph model represent object visibility ﬂuents varying time; joint probabilistic formulation object tracking ﬂuent reasoning; iii) occlusion reasoning dataset cover objects diverse ﬂuent changes. multiple object tracking extensively studied last decades. past tracking-bydetection become mainstream framework speciﬁcally general detector ﬁrst applied obtain detection proposals data association techniques employed link detection proposals times order object trajectories. approach follows pipeline well focused reasoning object visibility status. occlusion handling perhaps fundamental problem visual tracking extensively studied past literatures. methods roughly divided three categories using depth information modeling partial occlusion relations iii) modeling object appearing disappearing globally methods strong assumptions appearance motion cues mainly deal short-term occlusions. contrast paper presents principled explicitly reason object visibility status short-term interactions e.g. passing behind another object long-term interactions e.g. entering vehicle moving together. causal-effect reasoning popular topic received much attentions ﬁeld computer vision. studies instances differences cooccurrence causality aims learn causal knowledge automatically low-level observations e.g. images videos. popular causality models bayesian network grammar models notably fire introduced causal grammar infer causal-effect relationships object’s status e.g. door open/close agent’s actions e.g. pushing door. studies problem using manually designed rules video sequences settings. work extend causal grammar models infer objects’ visibility ﬂuent ground task challenging videos surveillance systems. fig. visualizes action-ﬂuent relationship using causal and-or graph occlusion status object might caused multiple actions need reason actual causality videos. actions alternative choices lead occlusion status form or-nodes. leaf node indicates action sub-event describe and-nodes. taking videos shown fig. instance status occluded caused following actions walking behind vehicle; walking behind person; iii) inertial action maintains ﬂuent unchanged. basic hypothesis model that particular scenario limited number actions cause ﬂuent change. given video sequence need create optimal c-aog or-node select best choice order optimal causal parse graph shown lines fig. develop probabilistic graph model reason object’s visibility ﬂuent changes using c-aog representation. formula integrates object tracking purposes well enable joint solution tracking ﬂuent change reasoning mutually beneﬁcial. particular subject interest method uses variables represent subjects’ positions videos; visibility status well best causal parse graph. utilize markov chain prior model describe transitions variables i.e. current state subject dependent previous state. reformulate problem integer linear programming model utilize dynamic programming search optimal states time. evaluations apply proposed method challenging sequences include frequent human-vehicle human-human intersections. results showed method readily predict figure proposed causal and-or graph model ﬂuent visibility. c-aog represent visibility status subject. node indicates possible choice arrow shows visibility ﬂuent transits among states. series atomic actions could possibly cause visibility ﬂuent change. atomic action describes interactions among people interacting objects. denotes person door trunkbag respectively. dash triangle denotes ﬂuent. corresponding ﬂuent could visible occluded contained person; open closed occluded vehicle door truck. text details. paper deﬁne three states visibility ﬂuent reasoning visible occluded contained. multiple object tracking methods based tracking-by-detection framework obtain good performance visible partially occluded situations. however full occlusions take place trackers usually regard disappearing-and-reappearing objects objects. although objects fully occluded contained states could invisible still evidences infer object’s location ﬁll-in complete trajectory. distinguish object fully occluded object contained three empirical observations. firstly motion independence. fully occluded state person staying behind pillar motion person independent pillar. contained state person vehicle trunk position motion person/bag would vehicle. important infer visibility ﬂuent object want track objects accurately complex environment. secondly coupling actions object ﬂuent changes. example illustrated fig. person gets vehicle related sequential atomic actions approaching vehicle opening vehicle door getting vehicle closing vehicle door; related object ﬂuent changes vehicle door closed open closed. ﬂuent change consequence agent actions. ﬂuentchanging actions happen object maintain current ﬂuent. example person contained vehicle remain contained unless he/she opens vehicle door gets vehicle. thirdly visibility alternative camera views. full occlusion state person occluded pillar though person could observed current viewpoint he/she could seen viewpoints; causal and-or graph paper propose causal and-or graph represent action-ﬂuent relationship illustrated fig. c-aog types nodes or-nodes represent variations choices and-nodes capture decomposition top-level entity. arrow represents causal relation action ﬂuent transition. example c-aog expressively model series action-ﬂuent relations. c-aog capable representing multiple alternatives causes occlusion potential transitions. four levels c-aog visibility ﬂuents possible states state transitions agent actions. nodes represent alternative causes visibility ﬂuents state levels; ﬂuent multiple states state multiple transitions. event decomposed possible atomic actions represented nodes e.g. opening vehicle door opening vehicle trunk loading baggage. scene denotes object time size i.e. number objects time unknown inferred observations. object represented location appearance features study visibility ﬂuent figure illustration hierarchical and-or graph. vehicle decomposed different views semantic parts ﬂuents. detection results drawn below different colored bounding boxes denoting different vehicle parts solid/dashed boxes denoting state closed/open. indicates object detection score indicates container detection score sigmoid function. object either visible contained state appearance information describe probability existence object containing location. object occluded visual evidence determine state. therefore utilize temporal information generate candidate locations. employ algorithm small actions could cover common interactions among people vehicles. euclidean distance locations speed threshold indicator function. location displacement term measures motion consistency object successive frames. second term measures state transition energy since subject interest enter nearby container discover optimal causal parse graph need jointly track container subject interest. similar equation energy function container following. illustrated fig. re-formulated graph structure directed acyclic graph thus adopt dynamic programming technique efﬁciently search optimal solution eqn. ramanan fowlkes generate trajectory fragments candidate locations identiﬁed misses complete object trajectories. energy thus deﬁned cost generating virtual trajectory location. compute energy computing visual discrepancy neighboring tracklet moment. moment neighboring tracklet appearance descriptor tracklet computed average pooling image descriptor time. distance threshold virtual path generated connect tracklets using b-spline ﬁtting. human represented his/her skeleton consists multiple joints estimated sequential prediction technology feature joint deﬁned relative distances joint four saddle points. relative distances normalized dividing length head eliminate inﬂuence scale. feature vector concatenating features joints extracted assumed follow gaussian distribution vehicle described viewpoint semantic vehicle parts vehicle part ﬂuents. vehicle ﬂuent represented hierarchical and-or graph illustrated fig. feature vector vehicle ﬂuent obtained computing ﬂuent scores vehicle part concatenating together. compute average pooling feature action training data vehicle ﬂuent template. given vehicle ﬂuent computed image distance integer linear formulation order derive scalable efﬁcient inference algorithm. denoted locations vehicles edges possible pairs nodes whose time consecutive locations close. whole transition graph shown fig. objects pedestrian evident interaction visibility ﬂuent changes. thus collect scenarios typical human-object interactions person suitcase vehicle several places. parkinglot. capture video sequences parking shows vehicles entering/exiting parking people getting in/out vehicles people interacting trunk/suitcase. sequences captured gopro camera frame rate resolution total number frames dataset exist severe occlusions large scale changes making dataset challenging traditional tracking methods. beside testing data collect another video clips training. avoid over-ﬁtting different camera positions different people vehicles testing settings. training data consists video clips covering events walking opening vehicle door entering vehicle exiting vehicle closing vehicle door opening vehicle trunk loading baggage unloading baggage closing vehicle trunk. action category contains video clips average. datasets short clips annotated bounding boxes people suitcase vehicles visibility ﬂuents people suitcase. types status visible occluded contained. utilize vatic annotate videos. results comparisons people-car dataset compare proposed method state-of-the-arts methods successive shortest path algorithm kshortest paths algorithm probability occupancy linear programming trackletbased intertwined flows figure transition graph utilized formulate integer linear programming. node location state time instant black solid arrows indicate possible transitions state. dashed arrows indicate possible transitions different states. threshold threshold tracklets similarity threshold contained distance threshold width container. appearance descriptors employ dense sampling colornames descriptor applies square root operator bag-of-word encoding original colornames descriptors. human skeleton estimation public implementation vehicle detection semantic part status estimation implementation provided default parameters mentioned paper. adopt widely used clear metrics measure performances tracking methods. includes four metrics i.e. multiple object detection accuracy detection precision multiple object tracking accuracy tracking precision take account three kinds tracking errors false positives false negatives identity switches. also report number false positives false negatives identity switches fragments higher value means better lower value means better frag. intersectionover-union ratio tracking results ground truth accept tracking result correct hit. datasets people-car dataset dataset consists sequences parking synchronized bird-view cameras length frames. dataset many instances people getting cars. dataset challenging frequent interactions light variation object resolution. dataset compare proposed method state-of-the-arts successive shortest path algorithm multiple hypothesis tracking distinctive appearance model markov decision processes reinforcement learning discrete-continuous energy minimization discretecontinuous optimization joint probabilistic data association public implementations methods. baseline our- analyze effectiveness different components. our- utilizes human data-likelihood term ourfull utilizes human vehicle data-likelihood terms. note also utilize estimated human joint key-points reﬁne detected people bounding boxes. report quantitative results comparisons table dataset. results observe method obtains superior performance methods metrics. validates proposed method track visible objects correctly also reason locations occluded contained objects. alternative methods work well mainly lack ability track objects long-term occlusion containment objects. based comparisons our- our-full also conclude type ﬂuent plays role improving ﬁnal tracking results. qualitative results visualized fig. figure sampled qualitative results proposed method dataset people-car dataset. color represents object. solid bounding means visible object. dash bounding denotes object contained scene entities. best viewed color zoom method successfully reason visibility status subjects. note precision containment estimation high since people in/out vehicle opposite side towards camera shown fig. situation multi-view setting might better paper propose causal and-or graph model represent causal-effect relations object visibility ﬂuents various human interactions. jointly modeling short-term occlusions long-term occlusions method explicitly reason visibility subjects well locations videos. method clearly outperforms alternative methods complicated scenarios frequent human interactions. work focus humaninteractions running-case proposed technique easily extended types objects", "year": 2017}