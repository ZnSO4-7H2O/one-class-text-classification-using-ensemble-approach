{"title": "Modeling Missing Data in Clinical Time Series with RNNs", "tag": ["cs.LG", "cs.IR", "cs.NE", "stat.ML"], "abstract": "We demonstrate a simple strategy to cope with missing data in sequential inputs, addressing the task of multilabel classification of diagnoses given clinical time series. Collected from the pediatric intensive care unit (PICU) at Children's Hospital Los Angeles, our data consists of multivariate time series of observations. The measurements are irregularly spaced, leading to missingness patterns in temporally discretized sequences. While these artifacts are typically handled by imputation, we achieve superior predictive performance by treating the artifacts as features. Unlike linear models, recurrent neural networks can realize this improvement using only simple binary indicators of missingness. For linear models, we show an alternative strategy to capture this signal. Training models on missingness patterns only, we show that for some diseases, what tests are run can be as predictive as the results themselves.", "text": "demonstrate simple strategy cope missing data sequential inputs addressing task multilabel classiﬁcation diagnoses given clinical time series. collected pediatric intensive care unit children’s hospital angeles data consists multivariate time series observations. measurements irregularly spaced leading missingness patterns temporally discretized sequences. artifacts typically handled imputation achieve superior predictive performance treating artifacts features. unlike linear models recurrent neural networks realize improvement using simple binary indicators missingness. linear models show alternative strategy capture signal. training models missingness patterns only show diseases tests predictive results themselves. admitted patient hospital intensive care units record large amounts data electronic health records clinical staﬀ routinely chart vital signs hourly rounds patients unstable. ehrs record test results medications ordered delivered physicians nurses. result ehrs contain rich sequences clinical observations depicting patients’ health care received. would like mine time series build accurate predictive models diagnosis applications. recurrent neural networks well-suited learning sequential temporal relationships time series. rnns oﬀer unprecedented predictive power myriad sequence learning domains including natural language processing speech video handwriting. recently lipton demonstrated eﬃcacy rnns multilabel classiﬁcation diagnoses clinical time series data. however medical time series data present modeling problems found clean academic datasets research focuses. clinical observations recorded irregularly measurement frequency varying patients across variables even time. common modeling strategy represent observations sequence discrete ﬁxed-width time steps. problematically resulting sequences often contain missing values values typically missing random reﬂect decisions caregivers. thus pattern recorded measurements contain potential information state patient. however often researchers missing values using heuristic unsupervised imputation ignoring potential predictive value missingness itself. work extend methodology lipton rnn-based multilabel prediction diagnoses. focus data gathered children’s hospital angeles pediatric intensive care unit unlike lipton approach missing data heuristic imputation directly model missingness feature achieving superior predictive performance. rnns realize improvement using simple binary indicators missingness. however linear models unable indicator features eﬀectively. rnns learn arbitrary functions capturing interactions missingness indicators sequence observation inputs linear models learn substitution values. linear models introduce alternative strategy capture signal using small number simple hand-engineered features. experiments demonstrate beneﬁt modeling missing data ﬁrst-class feature. methods improve performance rnns multilayer perceptrons linear models. additionally analyze predictive value missing data information training models missingness indicators only. show several diseases tests predictive actual measurements. focus classifying diagnoses methods applied predictive modeling problem involving sequence data missing values early prediction sepsis real-time risk modeling ence treatment protocols shifting distribution future data thus invalidating predictions. nonetheless doctors present often utilize knowledge past care treatment signal leak actual measurements ways suﬃciently powerful models exploit. ﬁnal contribution paper present critical discussion practical philosophical issues. dataset consists patient records extracted system chla part irb-approved study. dataset contains picu episodes. episode describes stay patient picu period least hours. addition patient record contains static diagnostic codes annotated physicians either picu visit. rawest representation episodes consist irregularly spaced measurements variables diastolic systolic blood pressure peripheral capillary reﬁll rate end-tidal fraction inspired total glascow coma scale blood glucose heart rate respiratory rate blood oxygen saturation body temperature urine output. render data suitable learning rnns convert discrete sequences hourly time steps time step covers interval hours closed left open right. actual admission times recorded reliably time ﬁrst recorded observation time step combine multiple measurements variable within hour window taking mean. vital signs heart rate typically measured hour tests requiring blood draw measured order addition timing time observations varies across patients time. resulting sequential representation many missing values variables missing altogether. note methods sensitive duration discrete time step. example halving duration would double length sequences making learning backpropagation time challenging data cost would justiﬁed frequently measured variables recorded hour. higher frequency recordings variables faster dynamics shorter time step might warranted. better condition inputs scale variable interval using expertdeﬁned ranges. additionally correct diﬀerences heart rate respiratory rate blood pressure gender using tables normal values large population studies. work formulate phenotyping multilabel classiﬁcation sequences. labels include distinct diagnosis codes in-house taxonomy chla similar icd- codes commonly used medical informatics research. labels include wide range acute conditions acute respiratory distress congestive heart failure sepsis. full list given appendix focus frequent least positive examples dataset. naturally diagnoses mutually exclusive. data average patient associated diagnoses. additionally base rates diagnoses vary widely focus paper missing data completeness review lstm architecture performing multilabel classiﬁcation diagnoses introduced lipton formally given series observations desire classiﬁer generate hypotheses true labels input output here denotes input dimension denotes number labels proposed uses lstm memory cells forget gates without peephole connections output fully connected layer followed element-wise logistic activation function apply loss loss function output node. overcome diﬃculty learning pass information across long sequences target replication strategy proposed lipton replicate static targets sequence step providing local error signal. technique also motivated problem desire make accurate predictions even sequence address missing data problem consider diﬀerent imputation strategies well direct modeling indicator variables. imputation direct modeling mutually exclusive also evaluate combination. suppose missing. zero-imputation strategy simply follows least previously recorded measurement variable time strategy motivated intuition clinical staﬀ record measurements intervals proportional rate believed observed change. heart rate change rapidly monitored much frequently blood thus seems reasonable assume value changed little since last time measured. indicator variable approach missing data consists augmenting inputs binary variables imputed otherwise. hidden state computations rnns indicators learn arbitrary functions past observations missingness patterns. however given data linear models learn hard substitution rules. consider linear model indicator variables might weights whenever feature missing impact output exactly equal contribution θi/wi. words linear model indicator depends neither previously observed values testing. train epochs retaining parameters corresponding epoch lowest validation loss. compare performance rnns logistic regression multilayer perceptrons apply regularization logistic regression model. hidden layers nodes each rectiﬁed linear unit activations dropout choosing number layers nodes validation performance. train using stochastic gradient descent momentum. evaluate baseline sets features hand-engineered. note baselines cannot applied directly variable-length inputs. features concatenate three -hour subsequences beginning middle time series. shorter time series intervals overlap. thus combinations inputs measurements zero-ﬁlling measurements forward-ﬁlling measurements zero-ﬁlling missing data indicators forwardﬁlling missing data indicators missing data indicators only. hand-engineered features capture central tendencies variability extremes trends. include ﬁrst last measurements diﬀerence maximum minimum values mean standard deviation median percentiles slope intercept least squares line also computed missing data features described section improve upon baselines lipton computing hand-engineered features diﬀerent windows time giving access greater temporal information enabling better model patterns missingness. extract hand-engineered features entire time series three possibly overlapping intervals ﬁrst last hours interval score report micro-averaged macro-averaged measures mitigate weaknesses finally also report precision whose maximum average diagnoses patient. metric seems appropriate could imagine technology would integrated diagnostic assistant. case role might suggest likely diagnoses best overall model metrics lstm zeroimputation missing data indicators. outperforms strongest baseline lstms absent missing data indicators. lstms using either imputation strategy adding missing data indicators improves performance metrics. models improve access missing data indicators information confers less beneﬁt input linear baselines consistent theory discussed subsection results achieved logistic regression hand-engineered features indicates simple hand-engineered missing data features reasonably good capturing important information neural networks able mine automatically. also lstms appear perform better zero-ﬁlling imputed values. suggests lstm learning recognize missing values implicitly recognizing tight range value zero inferring missing value. true perhaps imputation interferes lstm’s ability implicitly recognize missing values. overall ability implicitly infer missingness broader implications. suggests might never completely hide information suﬃciently powerful model. work builds upon research relating missing values machine learning medical informatics. basic methodology phenotyping derives lipton addressing dataset problem described methods rely upon lstm rnns trained backpropagation time comprehensive perspective history modern applications rnns provided lipton lipton list many previous works applied neural networks digital health data. long rich literature addresses pattern recognition missing data literature addresses ﬁxed-length feature vectors indicator variables missing data ﬁrst proposed cohen cohen could papers combine missing data indicators rnns. handful papers address missing data context rnns. bengio gingras demonstrate scheme learns missing values ﬁlled-in values minimize output error. parveen green built upon method improve automatic speech recognition. barker suggests using mask indicators scheme weighting contribution reliable corrupted data ﬁnal prediction. tresp briegel address missing values combining linear state space model handle uncertainty. paper ﬁrst engineer explicit features missingness patterns order improve discriminative performance. also knowledge ﬁrst harness patterns missing data improve classiﬁcation critical care phenotypes. data processing discriminative learning often regarded separate disciplines. separation concerns complementarity missing data indicators training rnns classiﬁcation overlooked. paper proposes patterns missing values underutilized source predictive power rnns unlike linear models eﬀectively mine signal sequences indicator values. hypotheses conﬁrmed empirical evidence. additionally introduce conﬁrm utility simple features engineered sequence missingness indicators improve performance linear models. techniques simple implement broadly applicable seem likely confer similar beneﬁts sequential prediction tasks data missing random. example might include ﬁnancial data failures report accounting details could suggest internal problems company. medical applications predictive power missing data raises important philosophical concerns. train models supervised learning verify utility assessing accuracy classiﬁcations hold-out test data. however practice hope make treatment decisions based predictions exposing fundamental incongruity problem models trained ultimately deployed. articulated lipton supervised models trained oﬄine cannot account changes deployment might confer upon real world possibly invalidating predictions. caruana present compelling case pneumonia risk model predicted lower risk death patients also asthma. better outcomes asthma patients turns owed aggressive treatment received. model deployed might used choose less aggressive treatment patients pneumonia asthma clearly sub-optimal course action. hand degree learning treatment signal inevitable. imputation might leak information values likely imputed not. thus suﬃciently powerful supervised model might catch amount missingness signal case experiments lstm using zeroﬁlled missing values. even physiologic measurements contain information owing patterns treatment possibly reﬂecting medications patients receive procedures undergo. sometimes patterns treatments reasonable valuable source information. doctors already rely kind signal habitually read charts noting doctors seen patient inferring opinions might tests ordered. while circumstances problematic learning models rely signal removing entirely diﬃcult undesirable. work also shows using simple features rnns achieve state performance classifying clinical time series. rnns outperform linear models. still experience strong bias among practitioners toward familiar models even require substantial feature engineering. experiments undertook extensive eﬀorts engineer features boost performance linear models mlps. ultimately rnns performed best data could approach performance signiﬁcantly improve linear model using hand-engineered features windowing. question emerges evaluate trade-oﬀ complex models complex features? extent linear models believed interpretable neural networks popular notions interpretability hinge upon intelligibility features performance linear model comes price intelligibility might trade-oﬀ undermines linear model’s chief advantage. additionally model still inferior relies applicationcontrast rnns speciﬁc features less likely useful datasets tasks. seem better equipped generalize diﬀerent tasks. model complex inputs remain intelligible opening possibility various post-hoc interpretations several promising next steps following work. first would like validate methodology tasks immediate clinical impact predicting sepsis mortality length stay. second we’d like extend work towards predicting clinical decisions. called policy imitation reinforcement literature work could pave providing real-time decision support. finally machine learning cooperating human decision-maker. thus machine learning model needn’t always make prediction/classiﬁcation; could also abstain. hope make latest advances mining uncertainty information neural networks make conﬁdence-rated predictions. zachary lipton supported division biomedical informatics university california diego training grant nih/nlm. david kale supported alfred mann innovation engineering doctoral fellowship. vpicu supported grants laura leland whittier foundation. acknowledge nvidia corporation tesla hardware donation professors charles elkan greg steeg support advice.", "year": 2016}