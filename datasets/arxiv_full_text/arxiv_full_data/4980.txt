{"title": "Similarity Search Over Graphs Using Localized Spectral Analysis", "tag": ["cs.AI", "cs.LG"], "abstract": "This paper provides a new similarity detection algorithm. Given an input set of multi-dimensional data points, where each data point is assumed to be multi-dimensional, and an additional reference data point for similarity finding, the algorithm uses kernel method that embeds the data points into a low dimensional manifold. Unlike other kernel methods, which consider the entire data for the embedding, our method selects a specific set of kernel eigenvectors. The eigenvectors are chosen to separate between the data points and the reference data point so that similar data points can be easily identified as being distinct from most of the members in the dataset.", "text": "abstract—this paper provides similarity detection algorithm. given input multi-dimensional data points additional reference data point similarity ﬁnding algorithm uses kernel method embeds data points dimensional manifold. unlike kernel methods consider entire data embedding method selects speciﬁc kernel eigenvectors. eigenvectors chosen separate data points reference data point similar data points easily identiﬁed distinct members dataset. recent years on-going interest ﬁnding efﬁcient solutions discover similarity data points. measuring similarity plays central role computer vision speech recognition text analysis anomaly detection name some. problem deﬁned follow given reference data point collection data points n-dimensional metric space want similar data points respect reference data point. interest solving similarity search problem accurately always important goal rapid growth amount collected data raises need solving problem efﬁciently well. work propose robust method similarity detection using notion localized spectral methods graphs main advantage method lies fact many algorithms nearest-neighbors variants search similarity feature space method searches similarity intrinsic characteristics. done looking eigenvectors enable separate relevant data points rest data. methodology consists steps decomposition graph represents imposed similarity metric data points. search resemblance relevant space separation exists following apply method synthetic real datasets compare obtained results known methods. similarity search role many applications involving high-dimensional data. extensive research done achieve efﬁcient accurate similarity search results. nearest-neighbors search approximated variants hashing methods popular solutions widely used achieve fast approximate similarity search. others like implement robust efﬁcient methodologies. similarity search task done redeﬁning feature space local intensity histograms. used attributes image matching. another construct eigenvectors pixel geometrical moments based local histogram automatically detect corresponding landmark brain images methods address similarity search problem feature space using either original feature space alternative representation including hashing dimensionality reduction techniques. work address problem using intrinsic characteristics data feature space commonly used. data analysis often involves non-linear relations data points harder extract conventional linear methods. example well known methods lack ability handle relations data points linear nature. direct result would like choose method allows data points mapped higher dimensional space exploiting non-linear properties relations. kernel methods enable operate analyze data high-dimensional environment extracting non-linear properties relations different scenarios data analyzed similarities data points exploiting non-linearity important therefore kernel methods useful. important examples area kernel methods diffusion maps laplacian eigenmaps diffusion maps show eigenvectors markovian matrix considered coordinates dataset represented data points euclidean space. procedure captures original geometry data. laplacian eigenmaps show neighborhood-information-based graph considered discrete approximation low-dimensional manifold high-dimensional space. usefulness kernel methods relation dimensionality reduction classiﬁcation anomaly detection described method relies main assumptions. low-dimensional space separates data points speciﬁcally separates reference data point rest data points. data point belongs high-dimensional space characterized lower dimensional space original space choosing appropriate kernel. ﬁrst assumption maps data low-dimensional space common since cases strong dependency different coordinates. results lower dimensional space ambient space. data points inseparable data assumed homogeneous. hence notion similarity meaningless. choice appropriate kernel second assumption uncover hidden relations data points. approach rely prior knowledge assumptions regarding data/paramters distribution. data points mapped low-dimensional embedding space utilizing largest eigenvalues corresponding eigenvectors. process captures geometry data. using successfully small number eigenvalues demonstrated classical spectral methods suggest largest eigenvalues corresponding eigenvectors. contrast commonly eigenvalues according methods characterize accurately reference point similar data points. suggest method classiﬁed localized spectral methods graphs. method proposes intrinsic characteristics reference data point measured mostly eigenvectors values. deﬁne eigenvectors largest absolute value coordinate reference data point. moreover data points similar eigenvectors shared characteristics. similarity deﬁned norm localized spectral reconstruction error. test method synthetic real datasets provide comparable results. data points reference data point. looking identify data points similar build graph normalized diagonal matrix kernel kij. summed consists real entries therefore matrix viewed markov transition matrix. deﬁne matrix symmetric matrix positive eigenvalues viewed graph laplacian matrix. eigenvalue decomposition donated matrix coordinates embedded axes. absolute values vector sorted descending order. denote matrix contains eigenvectors sorted descending signiﬁcance reference data point truncated matrix consists ﬁrst columns practice since large usually impractical compute full kernel therefore compute ﬁrst largest eigenvectors done example using power iterations randomized algorithms generated surface image size surface ﬁrst experiment injected abnormal data points hovered surface. point selected reference data point test data point. selection data points random. second experiment mona lisa’s painting image rearranged series columns sliding blocks size selected reference patch size mona lisa’s skin randomly chosen. experiments locate resembling data points meaning ﬁgure would like second abnormal data points mona lisa’s photo would like recognize patches skin. experiment) algorithm perform well. choosing values construct space respect full data reference point similar data points result poor performance similarity detection. method outperforms kernel-nn. alternative methods difﬁculty matching data point consistent matter compare method different locations reference matching data along terrain. presented experiment kerenel-knn ranks matching data point similar regular data points. method ranks correctly similar data point. surface generated data abnormal data points marked green reference data point desired matching point accordingly. proposed method relevant data point quite easily alternative methods suggest incorrect data points similar ones. reconstruction magnitude data points using three singular vectors reference data point corresponding singular values. easily seen last data points dataset located rows known reference data point matching point distinctively high reconstruction compared rest data points. data points form surface generated data points observations outside terrain injected data apart each. data points located dataset numbers goal match similar observation reference data point. comparison purposes nearest neighbor kernel nearest neighbor algorithms chosen gaussian kernel selected experiment suggested algorithm kernel-nn. figure shows terrain generated. original data points belong surface colored blue abnormal data points artiﬁcially injected data marked green red. data points chosen reference data point chosen matching data point algorithms locate. reference data point chosen randomly repeated experiment different data point locations surface. figure shows reconstruction magnitude data points using three singular vectors reference data point corresponding singular values. note taking singular vectors instead choosing ones pixels mona-lisa gray level image divided sliding blocks size later transformed data matrix size corresponds image patch. next arbitrary patch mona lisa’s skin patches chosen indicated green figure algorithm applied data matrix building gaussian kernel size computing ﬁrst eigenvectors. figure shows magnitude ﬁrst eigenvector. seen ﬁgure dark regions correspond patches similar reference patch skin neck. paper presented algorithm detecting similarities within given dataset. algorithm based localized spectral analysis. method characterizes reference data point looking signiﬁcant eigenvectors embedding kernel. signiﬁcant eigenvectors form basis enables differentiate similar data points rest data. numerical results algorithms presented. exhibit potential method. gionis indyk motwani similarity search high dimensions hashing vldb vol. song yang huang yang robust hashing local models approximate similarity search ieee transactions cybernetics vol. kraus carmel keidar orenbach nearbucket-lsh efﬁcient similarity search networks international conference similarity search applications. springer shen image registration local histogram matching pattern feng eigenvector-based corresponding points auto-detection algorithm non-rigid registration brain images bioinformatics biomedical engineering icbbe international conference zhang zhang chen discriminative manifold learning based dimension reduction method hyperspectral classiﬁcation international journal fuzzy systems vol. halko p.-g. martinsson tropp finding structure randomness probabilistic algorithms constructing approximate matrix decompositions siam review vol. woolfe liberty rokhlin tygert fast randomized algorithm approximation matrices applied computational harmonic analysis vol.", "year": 2017}