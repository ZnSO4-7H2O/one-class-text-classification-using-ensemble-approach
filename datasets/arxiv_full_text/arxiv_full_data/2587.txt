{"title": "Non-linear Label Ranking for Large-scale Prediction of Long-Term User  Interests", "tag": ["cs.AI", "cs.LG", "stat.ML"], "abstract": "We consider the problem of personalization of online services from the viewpoint of ad targeting, where we seek to find the best ad categories to be shown to each user, resulting in improved user experience and increased advertisers' revenue. We propose to address this problem as a task of ranking the ad categories depending on a user's preference, and introduce a novel label ranking approach capable of efficiently learning non-linear, highly accurate models in large-scale settings. Experiments on a real-world advertising data set with more than 3.2 million users show that the proposed algorithm outperforms the existing solutions in terms of both rank loss and top-K retrieval performance, strongly suggesting the benefit of using the proposed model on large-scale ranking problems.", "text": "consider problem personalization online services viewpoint targeting seek best categories shown user resulting improved user experience increased advertisers’ revenue. propose address problem task ranking categories depending user’s preference introduce novel label ranking approach capable efﬁciently learning non-linear highly accurate models large-scale settings. experiments real-world advertising data million users show proposed algorithm outperforms existing solutions terms rank loss top-k retrieval performance strongly suggesting beneﬁt using proposed model large-scale ranking problems. personalization online content become important topic recent years. deﬁned ability proactively tailor products product purchasing experiences tastes individual consumers based upon personal preference information lead improved user experience directly translate ﬁnancial gains online businesses addition personalization fosters stronger bond users companies help increasing user loyalty retention reasons recognized important strategic goal major internet companies focus signiﬁcant research efforts. personalized content already become integral part many popular online services trend likely continue future consider content personalization viewpoint targeted advertising increasingly important aspect online businesses. here individual user task best matching displayed improves user’s online experience lead increased revenue advertisers large impact many open research questions targeted advertising popular approaches present-day targeting particularly brand awareness campaigns assign categories display sports ﬁnance separately learn predict user interest categories using historical records typically taxonomy used decide categories depending detailed hundreds separate category qualiﬁcation tasks need solved. thus category separate predictive model trained able estimate probability click entire user population. then category users highest click probability selected exposure. known issues approach include overexposure single user among users many categories starvation users qualify categories. alternative avenue known industry userinterest model sort user outputs predictive models qualify users based categories. approach guarantees user qualiﬁed several categories eliminating overexposure starvation issues. however method still suboptimal predictive models trained isolation consider relationships different categories. paper explore methods capable capturing complex class dependencies consider user-interest model label ranking standpoint however sheer scale targeting problems data sets comprising millions users features hundreds categories renders many existing label ranking approaches intractable presenting challenges researchers. address issue propose novel label ranking algorithm suitable large-scale settings. method lends ideas state-of-the-art classiﬁers efﬁciently learning accurate non-linear models limited resources. empirical evaluation performed real-world targeting setting using best knowledge largest dataset considered thus label ranking literature. results show algorithm signiﬁcantly outperformed existing methods indi authors propose ranking training examples ﬁrst clustered according feature vectors centroid mean ranking found cluster used inference. idea extended authors feature vectors supervise clustering resulting improved performance. apart prototype-based methods often considered approaches include learning scoring function class sorting output order infer label ranking number binary classiﬁcation models pairwise output h¨ullermeier vanderlooy adaptive multi-hyperplane machine algorithm budgeted multi-class method suitable svm-like algorithm formulates non-linear model assigning number linear hyperplanes class order capture data non-linearity. given d-dimensional example possible classes following form numbers weights assigned classes block class-speciﬁc weights. thus predicted label example class weight vector achieves maximum value trained minimizing following convex section present works ideas proposed algorithm. ﬁrst discuss label ranking setting describe adaptive multi-hyperplane machine non-linear multi-class model used develop novel large-scale label ranking approach introduced paper. label ranking unlike standard machine learning problems multiclass multi-label classiﬁcation label ranking relatively novel topic involves complex task label preference learning. speciﬁcally rather predicting class labels newly observed example seek strict ranking classes importance relevance given example. instance consider targeted advertising domain assume examples internet users class labels user preferences {sports travel ﬁnance}. then instead simply inferring user sports person would result user shown sports-related informative know user prefers sports ﬁnance travel resulting diverse effective targeting. note label ranking problem differs learning-to-rank setup task rank examples labels also seen generalization classiﬁcation multi-label problems formally label ranking scenario input deﬁned feature vector output deﬁned ranking class labels. here labels originate predeﬁned label permutations. denote class label position label ranking position label ranking instance example would then label preferred label equivalently moreover case incomplete order label preferred missing ones. further assume given sample underlying distribution vector containing either total partial order class labels learning goal model maps input examples total ordering labels sort function returns indices sorted scores. training amm-rank resembles training multi-class model described previous section. learning initialized zero-matrix comprising inﬁnite number zero-vectors class followed iteratively observing examples modifying weight matrix. training iteration minimize following regularized instanteneous rank loss predeﬁned importance assigned rank function returns evaluates true otherwise. label ranking setting need keep track predicted scores classes note introduced vector instead scalar whose element determines weight belonging label used compute example. depending problem hand using function modeler emphasize importance ranks others. example assume then ranking loss deﬁned factor enforces higher penalty misranking topranked topics mistakes made lower-ranked topics incur progressively smaller costs. approach explored previously information retrieval setting however also applicable context targeted advertising lower-ranked classes progressively lower relevance publisher higher-ranked ones. furthermore penalty incurred whenever lower-ranked label either predicted preferred higher-ranked score preferred label higher margin smaller update step summarized follows. every training round model weights reduced towards zero multiplying addition weight class used compute score label equals pushed towards whenever uses stochastic gradient descent solve initialized zero-matrix comprises inﬁnite number zerovectors class. followed iterative procedure training examples observed weight matrix modiﬁed accordingly. upon receiving example round loss iteration positive class weight true class indexed moved towards maximum update class weight prediction remaining classes pushed away. updated weight zero-weight becomes non-zero thus increasing weight count class one. complexity model adapts complexity data learned training. shown existing label ranking methods achieve good performance many tasks however large-scale setting considered paper might effective. faced non-linear problems comprising millions examples features proposed methods either costly train expressive enough learn complex problems. address issue section present novel ranking algorithm called amm-rank extends idea adaptability online learning label ranking setting allowing large-scale training accurate ranking models. amm-rank algorithm detailing training procedure amm-rank ﬁrst consider predictive label ranking model. discussed previously assume training example associated incomplete label ranking length given trained amm-rank model test example score class found using equation predicted label ranking obtained sorting scores descending order label either wrongly predicted less preferred correctly predicted margin smaller moreover weight pushed away whenever score class preferred class either lower higher margin less similarly model complexity amm-rank ranking model automatically learned training adapts complexity considered label ranking problem. dataset addressing problem display advertising domain consists several players advertisers companies want advertise products; publishers websites host advertisements online users. environment provides publishers means track user behavior much greater detail ofﬂine setting including capturing user’s registered information activity logs comprise search queries page views email activity clicks purchases. brings ability target users based past behavior typically referred targeting mind main motivation following experimental setup task estimating user’s click interests using past activities. idea that sort interests descending order preference attempt predict ranking task formulated label ranking problem. data used empirical evaluation generated using information users’ online activities collected yahoo servers. activities temporal sequences events extracted server logs represented tuples user generated tuple event type timestamp total number recorded tuples. user considered events belonging following groups page views website pages user visited; search queries user-generated search queries; search link clicks user clicks search links; sponsored link clicks user clicks search views display user viewed; clicks display user clicked events groups categorized inhouse hierarchical taxonomy automatic categorization system human editors. event assigned category leaf taxonomy propagated upwards toward parent categories. considering server logs user retained several months recorded events used capture users’ interests categories long periods time. following categorization step compute intensity recency measures considered categories groups. dugct denote tuples generated user belongs group labeled category timestamp then intensity recency deﬁned follows intensity exponentially time-decayed count intensity recency measures used generate features label ranks user. particular ﬁrst chose timestamps month apart eatures tlabels eatures tlabels. then timestamp eatures used compute intensity recency categories groups separately which together user’s gender used feature vector resulting input space dimensionality addition order evaluate inﬂuence user views clicks also considered case intensity recency categories group appended feature vector increasing dimensionality quantify user interests generate ground-truth ranks considered events between eatures tlabels computed intensity categories timestamp tlabels. consider level interest user category equal intensity group preference ranking categories obtained simply sorting intensities. note ground-truth ranking cases incomplete users usually interact categories taxonomy. considered second-level categories taxonomy collected data comprising anonymous users clicked categories. category distribution ground-truth ranks given fig. large fraction clicks would missed users targeted clicked categories directly results lost revenue publishers advertisers. females aged retail/apparel technology/internet services telecommunications/cellular wireless travel/destinations consumer goods/beauty personal care technology/consumer electronics consumer goods/contests sweepstakes travel/vacations travel/non life stages/education males aged technology/internet services retail/apparel telecommunications/cellular wireless travel/destinations technology/consumer electronics travel/non travel/vacations consumer goods/contests sweepstakes retail/home entertainment/games females aged consumer goods/beauty personal care retail/apparel life stages/education finance/loans finance/insurance finance/investment technology/internet services entertainment/television retail/home telecommunications/cellular wireless males aged finance/investment finance/loans retail/apparel life stages/education technology/internet services finance/insurance consumer goods/beauty personal care retail/home telecommunications/cellular wireless technology/computer software used vowpal wabbit package logistic regression budgetedsvm also modiﬁed implement amm-rank. used default parameters budgetedsvm package amm-rank exception parameter which together competitors’ parameters egory used true class output scores categories sorted obtain ranking used na¨ıve baseline; central-mal always predicts central ranking training computed using mallows model ag-mal computes central-mal users grouped different gender buckets; ibmal computes central-mal nearest neighbors logistic regression binary models trained sorted outputs obtain ranking; pairwise approach binary models trained sorted soft votes towards label obtain ranking amm-rank pw-lr ib-mal time complexity remaining methods approaches. central-mal simple efﬁcient baseline often-used method basic content personalization. method simply predicts population’s mean ranking improve performance considered ag-mal method commonly used practice ﬁrst compute mean rank age-gender group group’s mean rank prediction qualiﬁed users. further ib-mal instance-based method extremely competitive state-of-the-art approaches ﬁrst nearest neighbors considering feature vectors predict mallows mean ranking neighbors lastly considered since represents industry standard targeting tasks pw-lr shown achieve state-of-the-art performance number large scale problem consider state-of-the-art methods mixture models require also consider logsmall margin using ag-mal. ib-mal resulted signiﬁcant performance improvement however large-scale online setting inefﬁcient. logistic regression commonly used method targeting tasks obtained error improved using pairwise approach. however state-of-the-art pw-lr signiﬁcantly outperformed proposed amm-rank achieved better result. note that ib-mal methods efﬁcient obtaining training test times less minutes regular machine. however main goal targeting campaigns infer complete list preferences user. instead preferred categories constraint limited budget display terms time space. therefore importance less preferred categories misranked second experiments explore label ranking methods perform setting. considered showing display ranks measure precision recall score categories user clicked testing period. results obtained label ranking algorithms illustrated figure amm-rank outperformed competitors achieving better performance values becomes even relevant consider even small improvement web-scale setting targeted advertising result signiﬁcant revenue increase publisher. conclude results strongly suggest advantages proposed approach competing algorithms large-scale label ranking tasks. order address challenges brought scale online advertising tasks renders many state-of-theart methods inefﬁcient introduced amm-rank novel non-linear algorithm large-scale label ranking. evaluated performance real-world targeting data comprising million users thus largest label ranking data considered literature. results show method outperformed competing approaches large margin terms rank loss retrieval measures indicating amm-rank algorithm suitable method solving large-scale label ranking problems.", "year": 2016}