{"title": "Regularization for Deep Learning: A Taxonomy", "tag": ["cs.LG", "cs.AI", "cs.CV", "cs.NE", "stat.ML", "62M45", "I.2.6; I.5"], "abstract": "Regularization is one of the crucial ingredients of deep learning, yet the term regularization has various definitions, and regularization methods are often studied separately from each other. In our work we present a systematic, unifying taxonomy to categorize existing methods. We distinguish methods that affect data, network architectures, error terms, regularization terms, and optimization procedures. We do not provide all details about the listed methods; instead, we present an overview of how the methods can be sorted into meaningful categories and sub-categories. This helps revealing links and fundamental similarities between them. Finally, we include practical recommendations both for users and for developers of new regularization methods.", "text": "regularization crucial ingredients deep learning term regularization various deﬁnitions regularization methods often studied separately other. work present systematic unifying taxonomy categorize existing methods. distinguish methods aﬀect data network architectures error terms regularization terms optimization procedures. provide details listed methods; instead present overview methods sorted meaningful categories sub-categories. helps revealing links fundamental similarities them. finally include practical recommendations users developers regularization methods. regularization elements machine learning particularly deep learning allowing generalize well unseen data even training ﬁnite training imperfect optimization procedure. traditional sense optimization also older neural networks literature term regularization reserved solely penalty term loss function recently term adopted broader meaning goodfellow loosely deﬁne modiﬁcation make learning algorithm intended reduce test error training error. deﬁnition slightly restrictive present working deﬁnition regularization since many techniques considered regularization reduce training error include various properties loss function loss optimization algorithm techniques. note deﬁnition line machine learning literature inverse problems literature latter using restrictive deﬁnition. proceed presentation taxonomy revisit basic machine learning theory section provide justiﬁcation level taxonomy. sections continue ﬁner division individual classes regularization techniques followed practical recommendations section aware many research works discussed taxonomy cannot summarized single sentence. sake structuring multitude papers decided merely describe certain subset properties according focus taxonomy. central task interest model ﬁtting ﬁnding function well approximate desired mapping inputs desired outputs given input associated target dictates desired output directly typical example available targets supervised learning. data samples follow ground truth probability distribution many applications neural networks proven good family functions choose from. neural network function trainable weights training network means ﬁnding weight conﬁguration minimizing loss function follows identify parts error function regularization term error function depends targets assigns penalty model predictions according consistency targets. regularization term assigns penalty model based criteria. depend anything except targets example weights expected risk cannot minimized directly since data distribution unknown. instead training sampled distribution given. minimization expected risk approximated minimizing empirical risk minimal background formalize division regularization methods systematic taxonomy. minimization empirical risk identify following elements responsible value learned weights thus contribute regularization quality trained model depends largely training data. apart acquisition/selection appropriate training data possible employ regularization data. done applying transformation training resulting transformations perform feature extraction pre-processing modifying feature space distribution data representation simplifying learning task. methods allow generating samples create larger possibly inﬁnite augmented dataset. principles somewhat independent combined. goal regularization data either them other both. rely transformations parameters context consider operate network inputs activations hidden layers targets. example transformation stochastic parameters corruption inputs gaussian noise stochasticity transformation parameters responsible generating samples i.e. data augmentation. note term data augmentation often refers speciﬁcally transformations inputs hidden activations also list transformations targets completeness. exception stochasticity follows delta distribution case transformation parameters become deterministic dataset size augmented. random draw random speciﬁed distribution adaptive value result optimization procedure usually objective maximizing network error transformed sample minimizing diﬀerence network prediction predeﬁned fake target representation-modifying transformations data diﬀerent representation disentangle underlying factors original representation make learning problem easier review existing methods generic transformations found table dropout original form popular methods generic group also several variants dropout proposed provide additional theoretical motivation improved empirical results random dropout probability bayesian dropout test-time dropout target-preserving data augmentation following discuss important group methods target-preserving data augmentation. methods stochastic transformations input hidden-feature spaces preserving original target seen respective columns tables listed methods exactly properties. methods transform training distribution used training instead. words training samples replaced empirical risk loss function augmented training samples randomly sampling transformation parameters thus creating many samples original training sample data augmentation attempts bridge limited-data expected empirical risk eqs. unlimited sampling provides data original dataset usually merely approximations ground truth data distribution ideal training dataset; distinct biases advantages disadvantages. example elastic image deformations result images perfectly realistic; necessarily disadvantage bias compared ground truth data distribution; case advantages often prevail. cases even desired deliberately diﬀerent ground truth data table existing domain-speciﬁc data-based methods classiﬁed according taxonomy. table columns described section note methods never applied hidden features domain knowledge cannot applied them. distribution. example case class imbalance common regularization strategy undersample oversample data sometimes leading less realistic better models. ideal training dataset diﬀerent ground truth data distribution. transformation additionally representation-preserving distribution created transformation attempts mimic ground truth data distribution otherwise notion ground truth data distribution modiﬁed representation vague. provide details transition appendix summary data-based methods data-based regularization popular useful improve results deep learning. section formalized group methods showed seemingly unrelated techniques target-preserving data augmentation dropout batch normalization methodologically surprisingly close other. section discuss future directions promising. assumptions mapping input-output mapping must certain properties order data well. although intractable enforce precise properties ideal mapping possible approximate simpliﬁed assumptions mapping. properties assumptions imposed upon model ﬁtting hard soft manner. limits search space models allows ﬁnding better solutions. example decision number layers mapping complex decomposed composition simple nonlinear transformations e.g. aﬃne transformation followed simple nonlinearity multi-channel convolution followed simple nonlinearity etc. layer operation like convolutional networks. additionally sparse sampling wide local neighborhoods provides relevant information better preserves relevant high-resolution information architectures downscaling upsampling. layer operation mapping reliable reacting features vary abruptly space i.e. present several neighboring pixels detected even ﬁlter center skips pixels. output robust towards slight changes location features changes strength/presence spatially strongly varying features. extracting complementary features helpful. noncoadapted features informative better disentangle factors variation. interpreted ensemble learning usual assumptions ensemble learning learning additive diﬀerence mapping identity mapping easier learning itself. meaningful deep features composed lower-level intermediate-level features. similar dropout extracting complementary features across diﬀerent levels abstraction helpful; implicit model ensemble. similar residual learning meaningful deep features composed lower-level intermediate-level features intermediate-level ones optional leaving meaningful data augmentation. similar mollifying networks simplifying random parts mapping improves training. table methods based network architecture rough description assumptions encode. partial overlaps listed methods. example residual learning uses skip-connections. many noise-based methods also table units allows mapping neither simple complex another example certain invariances mapping locality shift-equivariance feature extraction hardwired convolutional layers. overall approach imposing assumptions input-output mapping discussed section selection network architecture choice architecture hand hardwires certain properties mapping; additionally interplay optimization algorithm certain weight conﬁgurations likely accessible optimization others limiting likely search space soft way. complementary imposing certain assumptions mapping regularization terms well invariances present data section data mentioned regularization methods transform data hidden-feature space. considered part architecture. words sections methods listed table hidden features transformation space. weight sharing reusing certain trainable parameter several parts network referred weight sharing. usually makes model less complex using separately trainable parameters. example convolutional networks weight sharing merely reduce number weights need learned; also encodes prior knowledge shift-equivariance locality feature extraction. another example weight sharing autoencoders. activation functions choosing right activation function quite important; example using rectiﬁed linear units improved performance many deep architectures sense training times accuracy success relus attributed fact help avoiding vanishing gradient problem also fact provide expressive families mappings aﬃne extrapolation unknown regions data space seems provide better generalization practice stagnating extrapolation sigmoid units. activation functions designed explicitly regularization. dropout maxout units allow precise approximation geometric mean model ensemble predictions test time. stochastic pooling hand noisy version max-pooling. authors claim allows modelling distributions activations instead taking maximum. noisy models stochastic pooling example stochastic generalization deterministic model. models stochastic injecting random noise various parts model. frequently used noisy model dropout multi-task learning special type regularization multi-task learning combined semi-supervised learning utilize unlabeled data auxiliary task similar concept sharing knowledge tasks also utilized meta-learning multiple tasks domain learned sequentially using previously gained knowledge bias tasks transfer learning knowledge domain transferred another domain model selection best among several trained models selected evaluating predictions validation set. noted holds selecting best combination techniques architecture; validation used model selection outer loop diﬀerent validation used e.g. early stopping diﬀerent test however also model selection methods speciﬁcally target selection number units speciﬁc network architecture e.g. using network growing network pruning additionally require validation e.g. network information criterion compare models based training error second derivatives loss function ideally error function reﬂects appropriate notion quality cases assumptions data distribution. typical examples mean squared error cross-entropy. error function also regularizing eﬀect. example dice coeﬃcient optimization robust class imbalance. moreover overall form loss function diﬀerent example certain loss functions robust class imbalance taken pairwise combinations training samples rather training samples. alternatives rather rare similar principles apply. additional tasks added regularizing eﬀect targets modiﬁed consist several tasks mapping modiﬁed produce according output modiﬁed account modiﬁed besides regularization terms depend ∂e/∂x. depend thus deﬁnition considered part rather listed section among better overview. regularization achieved adding regularizer loss function. unlike error function regularization term independent targets. instead used encode properties desired model provide inductive bias value thus computed unlabeled test sample whereas value cannot. independence important implication allows additionally using unlabeled samples improve learned model based compliance desired properties example semi-supervised learning ladder networks combines supervised task unsupervised auxiliary denoising task multi-task learning fashion. unlabeled samples extremely useful labeled samples scarce. bayesian perspective combination labeled unlabeled data semi-supervised manner oﬀered lasserre weighting term controlling importance regularization consistency. bayesian perspective weight decay corresponds using symmetric multivariate normal distribution prior weights indeed exp− weight decay gained popularity successfully used; krizhevsky even observe reduction error training set. k·kf denotes frobenius norm jacobian neural network input-to-output mapping ﬁxed network weights term penalizes mappings large derivatives used contractive autoencoders domain loss regularizers heterogeneous. propose natural categorize dependence. weight decay depends only whereas jacobian penalty depends precisely jacobian penalty uses derivative ∂y/∂x output w.r.t. input jacobian ﬁxed weights identify following dependencies dependence network output dependence derivative ∂y/∂w output w.r.t. weights dependence derivative ∂y/∂x output w.r.t. input dependence derivative ∂e/∂x error term w.r.t. input review existing methods found table weight decay seems still popular regularization terms. methods equivalent nearly equivalent methods diﬀerent taxonomy branches. example tangent prop simulates minimal data augmentation injection small-variance gaussian noise approximation jacobian penalty fast dropout deterministic approximation dropout. indicated equivalence column table last class regularization methods according taxonomy regularization optimization. stochastic gradient descent frequently used optimization algorithm context deep neural networks center attention. also list alternative methods below. gradient loss evaluated mini-batch training frequently used combination momentum tweaks improving convergence speed moreover noise induced varying mini-batches helps algorithm escape saddle points reinforced adding supplementary gradient noise algorithm reaches training error reasonable time solution generalizes well certain mild assumptions; sense works implicit regularizer short training time prevents overﬁtting even without additional regularizer used line series experiments regularization neither necessary suﬃcient good generalization. norm network weights favors smaller weights thus usual architectures tends make mapping less extreme robust noise input. penalizes norm gradients learned ﬁlters making smooth. beneﬁcial practice. penalty sharp minima i.e. weight conﬁgurations small weight perturbation leads high error increase. flat minima minimum description length thus generalize better penalty directional derivative mapping predeﬁned tangent directions correspond known input-space transformations. penalty jacobian network mapping— smoothness prior. norm gradient loss w.r.t. input. changes mapping loss becomes rather invariant changes input. norm directional derivative mapping w.r.t. input direction causing largest increase loss. table regularization terms dependencies marked methods depend ∂e/∂x implicitly depend targets thus considered part error function rather regularization term initialization warm-start methods methods aﬀect initial selection model weights. currently frequently used method sampling initial weights carefully tuned distribution. multiple strategies based architecture choice aiming keeping variance activations layers around thus preventing vanishing exploding activations deeper layers another option pre-training diﬀerent data diﬀerent objective partially diﬀerent architecture. prime learning algorithm towards good solution ﬁne-tuning actual objective starts. pre-training model diﬀerent task domain lead learning useful features making primary task easier. however pre-trained models also often misused lazy approach problems training scratch using thorough domain adaptation transfer learning multi-task learning methods would worth trying. hand pre-training similar techniques useful part methods. update methods class methods aﬀects individual weight updates. complementary subgroups update rules modify form update formula; weight gradient ﬁlters methods aﬀect value gradient weights used update formula e.g. injecting noise gradient again entirely clear methods speed optimization actually help generalization. wilson show methods adagrad adam even lose regularization abilities sgd. figure eﬀect dropout weight optimization. starting current weight conﬁguration weights certain neurons zero descent step performed subspace discarded weight-space coordinates restored termination methods numerous possible stopping criteria selecting right moment stop optimization procedure improve generalization reducing error caused discrepancy minimizers expected empirical risk network ﬁrst learns general concepts work samples ground truth distribution ﬁtting speciﬁc sample noise successful popular termination methods portion labeled data aside validation evaluate performance prominent example early stopping scenarios training data scarce possible resort termination methods validation set. simplest case ﬁxing number passes training set. main beneﬁts taxonomy two-fold firstly provides overview existing techniques users regularization methods gives better idea choose ideal combination regularization techniques problem. secondly useful development methods gives comprehensive overview main principles exploited regularize models. summarize recommendations following paragraphs recommendations users existing regularization methods overall using information contained data well prior knowledge much possible primarily starting popular methods following procedure helpful deep learning disentangling factors variation. appropriate data representation chosen; known meaningful data transformations outsourced learning. redundantly providing information several representations okay. often helpful start simpliﬁed dataset simple network obtaining promising results gradually increasing complexity data network tuning hyperparameters trying regularization methods. optimizers trying diﬀerent ones including advanced ones lead improved results. correctly chosen parameters learning rate usually make diﬀerence. recommendations developers novel regularization methods getting overview understanding reasons success best methods great foundation. promising empty niches exist addressed. assumptions imposed upon model strong impact elements taxonomy. data augmentation expressive loss terms data loss terms impose assumptions invariances rather soft manner inﬂuence tuned whereas hardwiring network architecture harsher impose assumptions. diﬀerent assumptions options impose diﬀerent advantages disadvantages. future directions data-based methods several promising directions opinion require investigation adaptive sampling might lead lower errors shorter training times also section secondly learning class-dependent transformations opinion might lead plausible samples. furthermore ﬁeld adversarial examples gaining increased attention recently sparked discussion real-world adversarial examples robustness/invariance transformations change camera position countering strong adversarial examples require better regularization techniques. summary work proposed broad deﬁnition regularization deep learning identiﬁed main elements neural network training described regularization them including further ﬁner taxonomy each presented example methods subcategories. instead attempting explain referenced works detail merely pinpointed properties relevant categorization. work demonstrates links existing methods. moreover systematic approach enables discovery improved regularization methods combining best properties existing ones.", "year": 2017}