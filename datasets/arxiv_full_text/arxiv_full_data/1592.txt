{"title": "Character-Level Question Answering with Attention", "tag": ["cs.CL", "cs.AI", "cs.LG"], "abstract": "We show that a character-level encoder-decoder framework can be successfully applied to question answering with a structured knowledge base. We use our model for single-relation question answering and demonstrate the effectiveness of our approach on the SimpleQuestions dataset (Bordes et al., 2015), where we improve state-of-the-art accuracy from 63.9% to 70.9%, without use of ensembles. Importantly, our character-level model has 16x fewer parameters than an equivalent word-level model, can be learned with significantly less data compared to previous work, which relies on data augmentation, and is robust to new entities in testing.", "text": "show character-level encoderdecoder framework successfully applied question answering structured knowledge base. model singlerelation question answering demonstrate effectiveness approach simplequestions dataset improve state-of-the-art accuracy without ensembles. importantly character-level model fewer parameters equivalent word-level model learned significantly less data compared previous work relies data augmentation robust entities testing. single-relation factoid questions common form questions found search query logs community question answering websites knowledge-base freebase dbpedia wikidata help answer questions users reformulate queries. instance question where barack obama born? answered issuing following query three issues make learning mapping non-trivial. first many paraphrases question. second many entries unseen training time; however still need correctly predict test time. third freebase typically contains millions entities thousands predicates making difﬁcult system predict entities scale paper address three issues character-level encoder-decoder framework signiﬁcantly improves performance state-of-the-art word-level neural models also providing much compact model learned less data. first long short-term memory encoder embed question. second make model robust unseen entries extract embeddings questions predicates entities purely character-level representations. characterlevel modeling previously shown generalize well words seen training makes ideal task. third scale model handle millions entities thousands predicates instead using large output layer decoder directly predict entity predicate general interaction function question embeddings embeddings measures semantic relevance determine output. combined characterlevel modeling semantic relevance function allows successfully produce likelihood scores figure encoder-decoder architecture generates query structured knowledge base. encode question long short-term memory network attention mechanism produce context vector. decoding time step feed current context vector embedding english alias previously generated knowledge base entry attention-based decoding lstm generate candidate entity predicate. encoder-decoder model compact requires signiﬁcantly less data train previous work able generalize well unseen entities test time. particular without ensembles achieve accuracy freebasem setting accuracy freebasem setting simplequestions dataset outperforming previous state-of-arts respectively. moreover training questions provided simplequestions train model cover words entity aliases test set. demonstrates robustness character-level model unseen entities. contrast data augmentation usually necessary provide coverage unseen entities predicates done previous work semantic parsing open-domain question answering translates question structured query component question answering early approaches relied building high-quality lexicons domain-speciﬁc databases geoquery recent work focused building semantic parsing frameworks general knowledge bases freebase large-scale knowledge bases able successfully generate queries millions entities thousands predicates many unseen training. address issue recent work relies producing embeddings predicates entities based textual descriptions general interaction function used measure semantic relevance embedded entries quesapproaches word-level embeddings encode entities predicates therefore might suffer out-of-vocabulary problem encounter unseen words test time. consequently often rely significant data augmentation sources paralex contains million question-paraphrase pairs scraped wikianswers sufﬁcient examples word encounter opposed word-level modeling characterlevel modeling used handle issue. character-level modeling applied factoid question answering before successfully applied information retrieval machine translation sentiment analysis classiﬁcation named entity recognition moreover chung demonstrate gated-feedback lstms character-level embeddings capture longterm dependencies language modeling. lastly encoder-decoder networks applied many structured machine learning tasks. first introduced sutskever encoder-decoder network source sequence ﬁrst encoded recurrent neural network ﬁxed-length vector intuitively captures meaning decoded desired target sequence. approach related memorybased attention-based approaches successfully applied diverse domains speech recognition machine translation image captioning parsing executing programs conversational dialogues unlike previous work formulate question answering problem decoding query given question entries encoded embedding spaces. therefore integrate learning question embeddings uniﬁed encoder-decoder framework since focus single-relation question answering work model decodes every question query consists exactly elements–the topic entity predicate. formally model function takes input question candidate entities candidate predicates produces likelihood score generating entity predicate given question ...n ...m. character-level convolutional neural network -based encoder predicates/entities knowledge base produces single embedding vector predicate entity ﬁrst extract one-hot encoding vectors characters question represents one-hot encoding vector character question. keep space punctuation original cases without tokenization. attention-based lstm decoder uses similar architecture described bahdanau time step feed context vector input vector lstm. time feed special input vector v<s> lstm. time training input vector embedding true entity testing embedding likely entity determined previous time step. describe produce context vector hidden state lstm time question character embedding number characters question size hyperparameter. context vector represents attentionweighted content question recomputed time step follows unlike machine translation language modeling vocabulary relatively small millions entries directly predict entries decoder need output layer millions nodes computationally prohibitive. therefore resort relevance function measures semantic similarity decoder’s hidden state embeddings entries. semantic relevance function takes vectors returns distance measure similar feed temporal alternating convolutional fullyconnected layers followed fullyconnected layer tanh))))) embedding vector size size rn×h conv represents temporal convolutional neural network represents pooling layer temporal direction. opposed lstm embed entries primarily computational efﬁciency. also different cnns encode entities predicates typically signiﬁcantly different styles pairwise semantic relevance function measures similarity hidden units lstm embedding entity predicate candidate. returns mostly likely entity predicate based similarity score. table experimental results simplequestions dataset. memnn results bordes stand webquestions simplequestions extracted paraphrases wikianswers respectively. constant hidden states lstm times entity embeddings predicate embeddings. similar likelihood function used train semantic similarity modules proposed inference embeddings candidate entities predicates. training embeddings true entity randomly-sampled entities true predicate randomlysampled predicates respectively. predicates {p}. namely take entities whose english alias substring question remove entities whose alias substring another entity. english alias sort entity alias number facts append entities list candidate entities. predicates entity candidate entity become candidate predicates. learning goal learning maximize joint likelihood predicting correct entity predicate pair randomly sampled entities predicates. back-propagation learn weights model. parameters model learned jointly without pre-training. parameters include weights character-level embeddings cnns lstms. weights randomly initialized training. layer network weight sampled uniform distribution evaluate proposed model simplequestions dataset dataset consists single-relation questions corresponding triples freebase. split train validation test questions. unique words entity aliases unique predicates test present train set. proposed dataset evaluation settings called respectively. former uses candidate generation subset freebase contains entities latter uses subset freebase entities. experiments memory neural networks proposed bordes serve baselines. training addition questions training memnns training questions webquestions paraphrases wikianswers automatically generated questions settings respectively. contrast models trained questions training set. model layers lstm-based question encoder size hidden layers lstm-based decoder size cnns entity predicate embeddings hidden layer size output layer size cnns entity predicate embeddings receptive ﬁeld size train models using rmsprop learning rate order make input character sequence long enough receptive ﬁelds multiple layers predicate entity using three padding symbols special start symbol special symbol. instance obama would become sstartp obamap send. consistency apply padding questions. end-to-end results simplequestions following bordes report results simplequestions dataset terms accuracy settings table accuracy deﬁned percentage questions model generates correct query single character-level model achieves accuracies settings outperforming previous state-of-art results respectively. compared character-level model parameters word-level model parameters achieves best accuracy addition contrast previous work issue much severe word-level model since data augmentation cover entities unseen train set. ablation embedding experiments carry ablation studies sections random-sampling experiments. experiments question randomly sample entities predicates test noise samples. gold entity predicate negative samples evaluate accuracy model predicting gold predicate entity mixed set. word-level character-level models perform comparably well predicting predicate reaching accuracy around however word-level model considerable difﬁculty generalizing unseen entities able predict entities accurately mixed set. results clearly demonstrate issue much severe entities predicates difﬁculty word-level models generalizing entities. contrast character-level models issues achieve accuracy predicting correct entity mixed set. demonstrates character-level models encode semantic representation entities match entity aliases mentions natural language questions. also study impact depth neural networks model. results presented table ablation experiments compare performance single-layer lstm twolayer lstm encode question singlelayer two-layer encode entries. table results random sampling experiment varied number layers used convolutions question-encoding lstm. terminated training models epochs days gpu. two-layer lstm boosts joint accuracy majority accuracy gains result improved predicate predictions possibly entity accuracy already saturated experimental setup. attention mechanisms order understand model performs question answering visualize attention distribution question characters decoding process. sub-ﬁgure figure x-axis character sequence question yaxis attention weight distribution {αi}. blue curve attention distribution generating entity green curve attention distribution generating predicate. interestingly examples show attention distribution typically peaks empty spaces. indicates character-level model learns space deﬁnes ending point complete linguistic unit. hidden state lstm encoder space likely summarizes content character sequence space therefore contains important semantic information decoder needs attend also observe entity attention distributions usually less sharp span longer portions words john rutters predicate attention distributions entities semantic information accumulate gradually seeing characters predicates semantic information become clear seeing complete word. example clear characters song refer predicate space opposed name song song love contrast sequence characters starts become likely entity seeing incomplete name rutt. addition character-level model identify entities whose english aliases never seen training phrenology model apparently learns words ending sufﬁx nology likely entity mentions interesting reads input character time. furthermore observed figure attention model capable attending disjoint regions question capture mention predicate interrupted entity mentions. also note predicate attention often peaks padding symbols last character question possibly sentence endings carry extra information help disambiguate predicate mentions. certain scenarios network sufﬁcient information build semantic representation predicate ensured reached sentence. finally certain words question help identify entity predicate. example consider word university question what type educational institution eastern mexico university although part entity mention also helps disambiguate predicate. however previous semantic parsing-based approaches assume clear separation predicate entity mentions question. contrast proposed model need make hard categorization attends word university predicting entity predicate. randomly sampled questions best-performing model generated wrong query categorized errors. examples model predicted predicate similar alias true predicate i.e. /music/release/track /music/release/track list. examples model predicted wrong entity e.g. album still here question what type album still here?. finally examples model predicted wrong entity predicate i.e. question which instrument amapola cabase play? training data augmenting negative sample words question entity mention examples disambiguate similar predicates ameliorate many errors. paper proposed character-level attention-based encoder-decoder model question answering. approach embeddings questions entities predicates jointly learned directly optimize likelihood generating correct query. approach improved stateof-the-art accuracy simplequestions benchmark signiﬁcantly using much less data previous work. furthermore thanks character-level modeling compact model robust unseen entities. visualizations attention distribution reveal model although built character-level inputs learn higher-level semantic concepts required answer natural language question structured future would like extend system handle multirelation questions.", "year": 2016}