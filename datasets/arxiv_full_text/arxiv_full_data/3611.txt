{"title": "Deep BCD-Net Using Identical Encoding-Decoding CNN Structures for  Iterative Image Recovery", "tag": ["stat.ML", "cs.CV", "cs.LG"], "abstract": "In \"extreme\" computational imaging that collects extremely undersampled or noisy measurements, obtaining an accurate image within a reasonable computing time is challenging. Incorporating image mapping convolutional neural networks (CNN) to iterative image recovery has great potential to resolve this issue. This paper 1) incorporates image mapping CNN using identical convolutional kernels in both encoders and decoders into block coordinate descent (BCD) optimization method -- referred to BCD-Net using identical encoding-decoding CNN structures -- and 2) applies alternating direction method of multipliers to train the proposed BCD-Net. Numerical experiments show that, for a) denoising moderately low signal-to-noise-ratio images and b) extremely undersampled magnetic resonance imaging, the proposed BCD-Net achieves (significantly) more accurate image recovery, compared to BCD-Net using distinct encoding-decoding structures and/or the conventional image recovery model using both wavelets and total variation.", "text": "coordinate descent optimization method; referred bcd-net. however encoding ﬁlters sufﬁciently capture rich information training data limit signal recovery performance bcd-net. paper proposes bcd-net using image mapping cnns identical convolutional kernels encoders decoders—we refer identical encoding-decoding structure—and applies alternating direction method multipliers train proposed bcd-net. numerical experiments show that denoising moderately signal-to-noise-ratio images extremely undersampled magnetic resonance imaging proposed bcd-net improves image recovery accuracy compared bcd-net using distinct encoding-decoding structure and/or image recovery model using wavelets total variation data ﬁtting term signal denoised regularizer imaging problems relates physical imaging models noise statistics; e.g. image denoising noisy image corrupted additive white gaussian noise pωfx k-space measurement undersampled fourier operator examples include learned convolutional operators e.g. convolutional dictionary convolutional analysis operator bcdnet incorporates iteration-wise trained image mapping abstract—in extreme computational imaging collects extremely undersampled noisy measurements obtaining accurate image within reasonable computing time challenging. incorporating image mapping convolutional neural networks iterative image recovery great potential resolve issue. paper incorporates image mapping using identical convolutional kernels encoders decoders block coordinate descent optimization method—referred bcd-net using identical encoding-decoding structures— applies alternating direction method multipliers train proposed bcd-net. numerical experiments show that denoising moderately signal-to-noise-ratio images extremely undersampled magnetic resonance imaging proposed bcd-net achieves accurate image recovery compared bcd-net using distinct encoding-decoding structures and/or conventional image recovery model using wavelets total variation. index terms—convolutional neural network convolutional operator learning block coordinate descent method deep learning magnetic resonance imaging image denoising using learned convolutional operators iterative signal/image recovery growing trend computational imaging outperforming signal recovery performances conventional non-trained regularizers iterative image recovery approaches using learned convolutional operator convolutional neural network closely relate challenging block optimization. authors proposed fast convergence-guaranteed block proximal gradient method using majorizer quickly stably recover images aforementioned image recovery approaches. nonetheless corresponding iterative algorithm needs several hundreds iterations converge detracting practical use. exist several works combining neural network approaches optimizing image mapping networks— consisting encoding decoding kernels thresholding operators etc.—at iteration methods moderate aforementioned convergence issue aiming give best signal estimates layer. authors incorporated iteration-wisely optimized image mapping networks block indicator function deﬁned otherwise. descend/ascend augmented lagrangian using following iterative updates primal auxiliary dual variables—d respectively signal recovery performance bcd-net largely depends performance mapping) algorithm goal reduce number layers designing better image mapping networks achieve accurate image recovery. motivated designing learned convolutional operators particularly interested following image mapping using identical encoding-decoding structures sign sign denotes thresholding value function layer cr×r ﬂips column vector vertical direction size ﬁlters number ﬁlters indicates complex conjugate. expect that different distinct encodingdecoding structure mapping structure capture rich information training data encoders decoders—see fig. later. reformulating convolutional operators local approach section proposes algorithm training image mapping bcd-net training process requires high-quality training images {xtrain training measurements simulated imaging physics considered {ytrain layer train mapping follows fig. examples trained ﬁlters bcd-net initial ﬁlters encoding decoding ﬁlters trained image mapping module filters trained proposed image mapping module using identical encoding-decoding structure. imaging image recovery image denoising experiments contaminated slices xcat phantom awgn moderately large standard deviation used four training remaining testing. image reconstruction experiments simulated extremely undersampled k-space data sets optimal multi-level sampling compressed sensing ﬁeld-of-view cartesian grid avoiding inverse crime complex-valued phantoms used training another testing. regularization parameter follows image denoising scaled considering maximum value xcat phantom; image reconstruction evaluated quality recovered images peak training bcd-nets trained ﬁlters size randomly extracted image patches layer. training bcd-net using distinct encodingdecoding used parameter training proposed bcd-net using identical encoding-decoding used parameter default. parameters related admm section iii-b given follows used admm iterations inner subgradient descent iterations updating applied residual balancing scheme adaptively control terminated iterations training mapping) relative difference stopping criterion training costs increase reaching maximum number iterations. relative difference tolerance maximum number iterations image denoising image reconstruction respectively. using apply accelerated newton’s method efﬁciently obtain optimal solution problem considering quadratically constrained quadratic program. note closed form solution applicable solving additional quadratic term e.g. second term c−eh solve subgradient descent method backtracking line search real-valued complexvalued cases apply lemma lemma respectively. lemma gradient given fig. comparison image denoising accuracy different encoding-decoding structures bcd-net noise levels denotes termination point). psnr gaps bcd-nets give follows fig. comparison reconstructed images bcd-nets using different image mapping modules sparse reconstruction compared sparse reconstruction proposed bcd-net improves psnr ﬁlters trained identical encoding-decoding structure capture diverse features training data. rich features captured ﬁlters useful better image mapping corrupted noiseless images i.e. lower cost value figs. hand ﬁlters trained distinct encoding-coding structure sufﬁciently capture features training data. fig. corresponds moderately images extremely undersampled extremely undersampled experiment psnr increases increase number layers. fig. compared conventional reconstruction using wavelets proposed bcd-net signiﬁcantly improves reconstruction accuracy layers improves pnsr db—see fig. drawback using bcd-nets bcd-nets applicable imaging models training testing identical; meanwhile iterative signal recovery using learned cnns free limitation promoting better image mapping corrupted proposed bcd-net noiseless images training improves image recovery accuracy compare bcd-net psnr gaps bcdnets across layers given follows denoising proposed bcd-net useful achieving accurate image recovery within reasonable computing time extreme computational imaging. identical encoding-decoding structure give better image mapping distinct structure better capturing rich information training convergent convolutional dictionary learning using adaptive contrast enhancement application image denoising proc. sampling theory appl. tallinn estonia jul. chen pock trainable nonlinear reaction diffusion ﬂexible framework fast effective image restoration ieee trans. pattern anal. mach. intell. vol. jun. ravishankar chun fessler physics-driven deep training dictionary-based algorithms image reconstruction proc. asilomar conf. signals syst. comput. paciﬁc grove nov. boyd parikh peleato eckstein distributed optimization statistical learning alternating direction method multipliers found. trends machine learning vol. jan. data. future works include deriving closed-form solutions faster training proposed bcd-net testing image mapping performances structured artifacts", "year": 2018}