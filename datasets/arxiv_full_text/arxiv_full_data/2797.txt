{"title": "Theoretical Impediments to Machine Learning With Seven Sparks from the  Causal Revolution", "tag": ["cs.LG", "cs.AI", "stat.ML"], "abstract": "Current machine learning systems operate, almost exclusively, in a statistical, or model-free mode, which entails severe theoretical limits on their power and performance. Such systems cannot reason about interventions and retrospection and, therefore, cannot serve as the basis for strong AI. To achieve human level intelligence, learning machines need the guidance of a model of reality, similar to the ones used in causal inference tasks. To demonstrate the essential role of such models, I will present a summary of seven tasks which are beyond reach of current machine learning systems and which have been accomplished using the tools of causal modeling.", "text": "current machine learning systems operate almost exclusively statistical model-free mode entails severe theoretical limits power performance. systems cannot reason interventions retrospection therefore cannot serve basis strong achieve human level intelligence learning machines need guidance model reality similar ones used causal inference tasks. demonstrate essential role models present summary seven tasks beyond reach current machine learning systems accomplished using tools causal modeling. examine information drives machine learning today almost entirely statistical. words learning machines improve performance optimizing parameters stream sensory inputs received environment. slow process analogous many respects natural selection process drives darwinian evolution. explains species like eagles snakes developed superb vision systems millions years. cannot explain however super-evolutionary process enabled humans build eyeglasses telescopes barely thousand years. humans possessed species lacked mental representation blue-print environment could manipulate imagine alternative hypothetical environments planning learning. anthropologists like harari mithen general agreement decisive ingredient gave homo sapiens ancestors ability achieve global dominion years ability choreograph mental representation environment interrogate representation distort mental acts imagination ﬁnally answer what kind questions. examples interventional questions what act? retrospective explanatory questions what acted diﬀerently? learning machine operation today answer questions interventions encountered before what cigarettes. moreover learning machines today provide representation answers questions derived. postulate major impediment achieving accelerated learning speeds well human level performance overcome removing barriers equipping learning machines causal reasoning tools. postulate would speculative twenty years prior mathematization counterfactuals. today. advances graphical structural models made counterfactuals computationally manageable thus rendered model-driven reasoning promising direction base strong next section describe impediments facing machine learning systems using three-level hierarchy governs inferences causal reasoning. ﬁnal section summarizes impediments circumvented using modern tools causal inference. symptom tell disease? survey tell election results? take aspirin headache cured? cigarettes? stopped headache? would kennedy alive oswald shot him? smoking past years? classiﬁcation causal information terms kind questions class capable answering. classiﬁcation forms -level hierarchy sense questions level answered information level available. figure shows -level hierarchy together characteristic questions answered level. levels titled association intervention counterfactual. names layers chosen emphasize usage. call ﬁrst level association invokes purely statistical relationships deﬁned naked data. instance observing customer buys toothpaste makes likely he/she buys ﬂoss; association inferred directly observed data using conditional expectation. questions layer require causal information placed bottom level hierarchy. second level intervention ranks higher association involves seeing changing see. typical question level would happens double price? questions cannot answered sales data alone involve change customers behavior reaction pricing. choices diﬀer substantially taken previous price-raising situations. finally level called counterfactuals term goes back philosophers david hume john stewart mill given computer-friendly semantics past decades. typical question counterfactual category what acted diﬀerently thus necessitating retrospective reasoning. associational questions. model answer counterfactual queries also answer questions interventions observations. example interventional question happen double price? answered asking counterfactual question would happen price twice current value? likewise associational questions answered answer interventional questions; simply ignore action part observations take over. translation work opposite direction. interventional questions cannot answered purely observational information counterfactual question involving retrospection answered purely interventional information acquired controlled experiments; cannot re-run experiment subjects treated drug behave given drug. hierarchy therefore directional level powerful one. other names used inferences layer model-free model-blind black-box data-centric. darwiche used function-ﬁtting amounts ﬁtting data complex function deﬁned neural network architecture. civil court example defendant considered culprit injury defendant’s action likely injury would occurred. computational meaning calls comparing real world alternative world defendant action take place. layer. example association layer characterized conditional probability sentences e.g. stating that probability event given observed event equal large systems evidential sentences computed eﬃciently using bayesian networks neural networks support deep-learning systems. denotes probability event given intervene value subsequently observe event expressions estimated experimentally randomized trials analytically using causal bayesian networks child learns eﬀects interventions playful manipulation environment planners obtain interventional knowledge exercising designated sets actions. interventional expressions cannot inferred passive observations alone regardless data. probability event would observed given actually observed example probability joe’s salary would ﬁnished college given actual salary years college. sentences computed possess functional structural equation models properties models systems prevented reasoning actions experiments explanations. also informs extra-statistical information needed format order support modes reasoning. learning level association side side textbook curve-ﬁtting exercises. popular stance comparison argues that whereas objective curve-ﬁtting maximize deep learning minimize over unfortunately theoretical barriers separate three layers hierarchy tell nature objective function matter. long system optimizes property observed data however noble sophisticated making reference world outside data back level- hierarchy limitations level entails. recognize words preventing cause attributed discrimination should words common everyday language society constantly demands answers questions. recently science gave means even articulate them alone answer them. unlike rules geometry mechanics optics probabilities rules cause eﬀect denied beneﬁts mathematical analysis. scientists unable write mathematical equation obvious fact cause rain. even today echelon scientiﬁc community write equation formally distinguish causes rain rain causes mud. would probably even surprised discover favorite college professor among them. developed managing causes eﬀects accompanied tools turn causal analysis mathematical game unlike solving algebraic equations ﬁnding proofs high-school geometry. tools permit express causal questions formally codify existing knowledge diagrammatic algebraic forms leverage data estimate answers. moreover theory warns state existing knowledge available data insuﬃcient answer questions; suggests additional sources knowledge data make questions answerable. causal inference last decades total everything learned prior recorded history call transformation causal revolution mathematical framework call structural causal models graphical models serve language representing know world counterfactuals help articulate want know structural equations serve together solid semantics. figure illustrates operation form inference engine. engine accepts three inputs assumptions queries data produces three outputs estimand estimate indices. estimand mathematical formula that based assumptions provides recipe answering query hypothetical data whenever available. receiving data engine uses estimand produce actual estimate answer along statistical estimates conﬁdence answer finally engine produces list indices measure compatible data assumptions conveyed model. encoded graph below third variable aﬀecting finally data sampled random joint distribution estimand calculated engine formula deﬁnes property that estimated would provide correct answer query. answer itself estimate produced number techniques produce consistent estimate ﬁnite samples example sample average cases satisfying speciﬁed conditions would consistent estimate. eﬃcient estimation techniques devised overcome data sparsity deep learning excels work machine learning focused albeit guidance model-based estimand. finally index example null. words examining structure graph engine conclude assumptions encoded testable implications. therefore veracity resultant estimate must lean entirely assumptions encoded graph refutation corroboration obtained data. discussed before. also permit data arrive controlled experiments would take form case controlled variable. role estimand would remain converting query syntactic format available data then guiding choice estimation technique ensure unbiased estimates. needless state conversion task always feasible case query declared non-identiﬁable engine exit failure. fortunately eﬃcient complete algorithms developed decide identiﬁability produce estimands variety counterfactual queries variety data types task encoding assumptions compact usable form trivial matter take seriously requirement transparency testability. transparency enables analysts discern whether assumptions encoded plausible whether additional assumptions warranted. testability permits determine whether assumptions encoded compatible available data identify need repair. fact assumptions encoded graphically mirroring researchers perceive cause-eﬀect relationship domain; judgments counterfactual statistical dependencies required since read structure graph. testability facilitated graphical criterion called d-separation provides fundamental connection causes probabilities. tells given pattern paths model pattern dependencies expect data assumptions encoded graph conveyed missing arrows. example inﬂuence inﬂuence importantly variable aﬀecting assumptions lack testable implications concluded fact graph complete i.e. edges missing. confounding presence unobserved causes variables long consider major obstacle drawing causal inference data obstacle demystiﬁed deconfounded graphical criterion called back-door. particular task selecting appropriate covariates control confounding reduced simple roadblocks puzzle manageable simple algorithm models back-door criterion hold symbolic engine available called do-calculus predicts eﬀect policy interventions whenever feasible exits failure whenever predictions cannot ascertained speciﬁed assumptions counterfactual analysis deals behavior speciﬁc individuals identiﬁed distinct characteristics example given joe’s salary went years college would joe’s salary year education. crown achievements causal revolution formalize counterfactual reasoning within graphical representation representation researchers encode scientiﬁc knowledge. every structural equation model determines truth value every counterfactual sentence. therefore determine analytically probability sentence estimable experimental observational studies combination thereof mediation analysis concerns mechanisms transmit changes cause eﬀects. identiﬁcation intermediate mechanism essential generating explanations counterfactual analysis must invoked facilitate identiﬁcation. graphical representation counterfactuals enables deﬁne direct indirect eﬀects decide eﬀects estimable data experiments typical queries answerable analysis fraction eﬀect mediated variable validity every experimental study challenged disparities experimental implementational setups. machine trained environment cannot expected perform well environmental conditions change unless changes localized identiﬁed. problem various manifestations well recognized machine-learning researchers enterprises domain adaptation transfer learning life-long learning explainable subtasks identiﬁed researchers funding agencies attempt alleviate general problem robustness. unfortunately problem robustness requires causal model environment cannot handled level association remedies tried. associations suﬃcient identifying mechanisms aﬀected changes occurred. do-calculus discussed oﬀers complete methodology overcoming bias environmental changes. used re-adjusting learned policies circumvent environmental changes controlling bias non-representative samples problems missing data plague every branch experimental science. respondents answer every item questionnaire sensors fade environmental conditions change patients often drop clinical study unknown reasons. rich literature problem wedded model-blind paradigm statistical analysis accordingly severely limited situations missingness occurs random independent values taken variables model. using causal models missingness process formalize conditions causal probabilistic relationships recovered incomplete data whenever conditions satisﬁed produce consistent estimate desired relationship d-separation criterion described enables detect enumerate testable implications given causal model. opens possibility inferring mild assumptions models compatible data represent compactly. systematic searches developed which certain circumstances prune compatible models signiﬁcantly point causal queries estimated directly philosopher stephen toulmin identiﬁes model-based model-blind dichotomy understanding ancient rivalry babylonian greek science. according toulmin babylonians astronomers masters black-box prediction surpassing greek rivals accuracy consistency science favored creative-speculative strategy greek astronomers wild metaphysical imagery circular tubes full small holes celestial visible stars hemispherical earth riding turtle backs. wild modeling strategy babylonian rigidity jolted eratosthenes perform creative experiments ancient world measure radius earth. would never occurred babylonian curve-ﬁtter. coming back strong seen model-blind approaches intrinsic limitations cognitive tasks perform. described tasks demonstrated accomplished framework model-based approach essential performing tasks. general conclusion human-level cannot emerge solely model-blind learning machines; requires symbiotic collaboration data models.", "year": 2018}