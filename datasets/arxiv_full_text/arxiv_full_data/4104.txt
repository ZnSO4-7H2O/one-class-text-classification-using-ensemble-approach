{"title": "Detecting events and key actors in multi-person videos", "tag": ["cs.CV", "cs.AI"], "abstract": "Multi-person event recognition is a challenging task, often with many people active in the scene but only a small subset contributing to an actual event. In this paper, we propose a model which learns to detect events in such videos while automatically \"attending\" to the people responsible for the event. Our model does not use explicit annotations regarding who or where those people are during training and testing. In particular, we track people in videos and use a recurrent neural network (RNN) to represent the track features. We learn time-varying attention weights to combine these features at each time-instant. The attended features are then processed using another RNN for event detection/classification. Since most video datasets with multiple people are restricted to a small number of videos, we also collected a new basketball dataset comprising 257 basketball games with 14K event annotations corresponding to 11 event classes. Our model outperforms state-of-the-art methods for both event classification and detection on this new dataset. Additionally, we show that the attention mechanism is able to consistently localize the relevant players.", "text": "multi-person event recognition challenging task often many people active scene small subset contributing actual event. paper propose model learns detect events videos automatically attending people responsible event. model explicit annotations regarding people training testing. particular track people videos recurrent neural network represent track features. learn time-varying attention weights combine features time-instant. attended features processed using another event detection/classiﬁcation. since video datasets multiple people restricted small number videos also collected basketball dataset comprising basketball games event annotations corresponding event classes. model outperforms state-of-the-art methods event classiﬁcation detection dataset. additionally show attention mechanism able consistently localize relevant players. event recognition detection videos hugely beneﬁted introduction large-scale datasets models. however mainly conﬁned domain single-person actions videos contain actor performing primary activity. another equally important problem event recognition videos multiple people. work present model dataset speciﬁc setting. figure looking wrong people multi-person event uninformative seen basketball video ﬁrst row. however observing correct people video easily identify event -pointer success based shooter player throwing ball play. intuition recognize players event recognition. outdoor areas typically contain multiple people interacting other. people something involved main event. main event dominated smaller subset people. instance shot game determined people addition recognizing event also important isolate actors. signiﬁcant challenge differentiates multi-person videos single-person videos. identifying people responsible event thus interesting task right. however acquiring annotations expensive therefore desirable models require annotations identifying actors training. also viewed problem weakly supervised person identiﬁcation. paper propose method classify events using recently several papers proposed attention models aligning elements ﬁxed input ﬁxed output. example translate sentences language another language attending different words input; generate image-caption attending different regions image; generate video-caption attending different frames within video. work attention decide several people relevant action performed; attention mask change time. thus combining spatial temporal attention. note person detections vary frame another associated across frames tracking. show recurrent neural network represent information track; attention model tasked selecting relevant track frame. addition able isolate actors show attention model results better event recognition. order evaluate method need large number videos illustrating events involving multiple people. prior activity event recognition datasets focus actions involving people. multiperson datasets like usually restricted fewer videos. therefore collected dataset. particular propose dataset basketball events time-stamp annotations occurrences different events across videos hours long length. dataset comparable thumos detection dataset terms number annotations contains longer videos multi-person setting. summary contributions paper follows. first introduce large-scale basketball event dataset dense temporal annotations long video sequences. second show method outperforms state-of-the-art methods standard tasks classifying isolated clips temporally localizing events within longer untrimmed videos. third show method learns attend relevant players despite never told players relevant training set. related work action recognition videos traditionally well engineered features proved quite effective video classiﬁcation retrieval tasks improved dense trajectory features achieve competitive results standard video datasets. last years end-to-end trained deep network models shown comparable times better features various video tasks. works like explore methods pooling features better performance. recent works using achieved state-of-the-art results event recognition caption-generation tasks follow line work addition attention mechanism attend event participants. another related line work jointly identiﬁes region interest video recognizing action. gkioxari raptis automatically localize spatio-temporal tube video. merge super-voxels action localization. methods perform weakly-supervised action localization target single actor videos short clips action centered around actor. methods like require annotations training localize action. muti-person video analysis activity recognition models events well deﬁned group structures parades presented utilize structured layout participants identify group events. recently context recognizing interaction-based group activities. work multi-person events methods restricted smaller datasets ut-interaction collective activity nursing home. attention models itti explored idea saliency-based attention images works like using eye-gaze data means learning attention. mnih attend regions varying resolutions image framework. along similar lines attention used image classiﬁcation detection well. showed attention-based models effectively align input words output words machine translation. following this used attention image-captioning videocaptioning respectively. methods attention aligns sequence input features words output sentence. however work attention identify relevant person overall event different phases event. action recognition datasets action recognition videos evolved introduction sophisticated datasets starting smaller hmdb larger trecvid-med sportsm datasets. recently thumos activitynet also provide detection setting temporal annotations actions untrimmed videos. also ﬁne-grained datasets speciﬁc domains mpii cooking breakfast however datasets focus single-person activities hardly need recognizing people responsible event. hand publicly available multi-person activity datasets like restricted small numfigure densely annotate every instance different basketball events long basketball videos. shown here collected event time-stamps event labels task. videos. contributions work multi-player basketball dataset dense temporal event annotations long videos. person detection tracking. large literature person detection tracking. also speciﬁc methods tracking players sports videos mention methods. person detection cnn-based multibox detector person tracking tracker also work player identiﬁcation work attempt distinguish players. event -point succ. -point fail. free-throw succ. free-throw fail. layup succ. layup fail. -point succ. -point fail. slam dunk succ. slam dunk fail. steal table number videos event dataset along average number people video corresponding events. number people higher existing datasets multi-person event recognition. natural choice collecting multi-person action videos team sports. paper focus basketball games although techniques general purpose. particular subset ncaa games available youtube. games played different venues different periods time. consider recent games since older games used slightly different rules modern basketball. videos typically hours long. manually identiﬁed event next launched amazon mechanical turk task annotators asked annotate end-point events occur videos; endpoints usually well-deﬁned determine starting time assumed event seconds long since hard raters agree event started. gives enough temporal context classify event still fairly well localized time. videos randomly split training validation test videos. split videos second clips subsampled fps. ﬁlter clips proﬁle shots using separately trained classiﬁer; excludes close-up shots players well shots viewers instant replays. resulted total training validation test clips labels. note comparable size thumos’ detection challenge distribution annotations across different events shown tab. best knowledge ﬁrst dataset dense temporal annotations long video sequences. addition annotating event label start/end time collected annotations video clips test annotators asked mark position ball frame shooter attempts shot. also used annotate bounding boxes players subset frames training videos. trained multibox detector annotations trained detector videos dataset. retained detections conﬁdence frame; resulted person detections clip listed tab. multibox model achieves spatial information i’th player bounding frame similar rcnn object detector appearance features extracted feeding cropped resized player region frame inception network spatially pooling response lower layer. spatial feature corresponds spatial histogram combined spatial pyramid indicate bounding location multiple scales. used static representations work features also easily extended information suggested first compute global context feature frame derived bidirectional lstm applied frame-level feature shown blue boxes fig. concatenation hidden states forward reverse lstm components blstm compactly represented feature vector derived players describe below. this predict class label clip using weight vector corresponding class denoted measure squared-hinge loss follows figure model player track ﬁrst processed corresponding blstm network i-blstm corresponds i’th player. blstm hiddenstates used attention model identify player instant. thickness blstm boxes shows attention weights attended person change time. variables model explained methods section. blstm stands bidirectional long short term memory. events team sport performed scene players. basis differentiating events action performed small subset people given time. instance steal event basketball completely deﬁned action player attempting pass ball player stealing him. understand event sufﬁcient observe players participating event. motivates build model reason event focusing speciﬁc people different phases event. section describe uniﬁed model classifying events simultaneously identifying players. video-frame represented dimensional feature vector activation last fully connected layer inception network addition compute spatially localized features person frame. particular compute dimensional feature vector contains appearance issues mind ﬁrst present model uses player tracks learns blstm based representation player track. also present simple tracking-free baseline model. attention model tracking. ﬁrst associate detections belonging player tracks using standard method. tracker combined bipartite graph matching perform data association. player tracks used incorporate context adjacent frames computing representation. separate blstm learns latent representation player given time-step. latent representation player frame given hidden state number detections frame multi layer perceptron similar softmax temperature parameter. attended player representation input unidirectional event recognition lstm model illustrated figure attention model without tracking. often tracking people crowded scene difﬁcult occlusions fast movements. settings beneﬁcial tracking-free model. could also allow model ﬂexible switching attention players event progresses. motivated this present model detections frame considered independent frames. section present three sets experiments ncaa basketball dataset event classiﬁcation event detection evaluation attention. implementation details used hidden state dimension lstm blstm rnns embedding layer relu non-linearity dimensions embedding player features frame features feeding rnns. used bins spatial pyramid pooling player location feature. event videos clips four seconds long subsampled fps. value attention softmax weighting. used batch size learning rate reduced factor every iterations rmsprop. models trained cluster gpus iterations day. hyperparameters chosen cross-validating validation set. event classiﬁcation section compare ability methods classify isolated video-clips classes. additional negatives parts basketball videos. compare results different control settings baseline models explained below lrcn lrcn model frame-level features. however blstm place lstm. found improve performance. also back-propagate extracting frame-level features consistent model. multi-instance learning method learn labels player features. player player features mean average precision setting shown tab. method uses global information local player information outperforms model using local player information using global information event -point succ. -point fail. fr-throw succ. fr-throw fail. layup succ. layup fail. -point succ. -point fail. dunk succ. dunk fail. steal mean event -point succ. -point fail. free-throw succ. free-throw fail. layup succ. layup fail. -point succ. -point fail. slam dunk succ. slam dunk fail. steal mean also show combining player information using weighted better uniform averaging tracking based version attention slightly better track-free version. also standard weakly-supervised approach seems less effective modeling variants. performance varies class. particular performance much poorer classes slam dunk fail little data. however performance better shot-based events like freethrow layups -pointerswhere attending shot making person defenders useful. section evaluate ability methods temporally localize events untrimmed videos. sliding window approach slide second window basketball videos classify window negative class event classes. stride length seconds. treat windows overlap second annotated events negatives. setting training test validation. leads negative examples across videos. compare baselines before. however unable train model computational limitations. detection results presented tab. that before attention models beat previous state methods. surprisingly methods slightly worse temporal localization classifying isolated clips. also note signiﬁcant difference classiﬁcation detection performance steal methods. explained large number negative instances introduced detection setting. negatives often correspond players passing ball other. steal event quite similar pass except ball passed player opposing team. makes steal detection task considerably challenging. evaluate attention models labeled player closest ball shooter. used annotations evaluate attention scores capable classifying shooter correctly frames. event -point succ. -point fail. free-throw succ. free-throw fail. layup succ. layup fail. -point succ. -point fail. slam dunk succ. slam dunk fail. mean table mean average precision attention evaluation. mean shooter classiﬁcation listed tab. results show track-free attention model quite consistent picking shooter several classes like free-throw succ./fail layup succ./fail. slam dunk succ.. promising result shows attention player detections alone capable localizing player making shot. could useful providing detailed event descriptions including identity position shooter well. figure distribution attention model tracking beginning free-throw success. unlike fig. attention concentrated speciﬁc defender’s position. free-throws distinctive defense formation observing defenders helpful shown sample images row. addition quantitative evaluation wanted visualize attention masks visually. figure shows sample videos. order make results comparable across frames annotated points court aligned attended boxes event canonical image. fig. shows heatmap visualizing spatial distributions attended players respect court. interesting note model consistently focuses basket layup free-throw line freethrows outside -point ring -pointers. attention scores tracking based model less selective focusing shooter. observed tracking model often reluctant switch attention frames focuses single player throughout event. biases model towards players present throughout video. instance free-throws model always attends defender speciﬁc position visible throughout entire event unlike shooter. conclusion introduced attention based model event classiﬁcation detection multi-person videos. apart recognizing event model identify people responsible event without explicitly trained annotations. method generalize multi-person setting. however purpose paper introduced dataset basketball videos dense event annotations compared performance state-of-the-art methods dataset. also evaluated ability model recognize shooter events visualizations spatial locations attended model.", "year": 2015}