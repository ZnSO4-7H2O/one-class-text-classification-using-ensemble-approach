{"title": "NiftyNet: a deep-learning platform for medical imaging", "tag": ["cs.CV", "cs.LG", "cs.NE"], "abstract": "Medical image analysis and computer-assisted intervention problems are increasingly being addressed with deep-learning-based solutions. Established deep-learning platforms are flexible but do not provide specific functionality for medical image analysis and adapting them for this application requires substantial implementation effort. Thus, there has been substantial duplication of effort and incompatible infrastructure developed across many research groups. This work presents the open-source NiftyNet platform for deep learning in medical imaging. The ambition of NiftyNet is to accelerate and simplify the development of these solutions, and to provide a common mechanism for disseminating research outputs for the community to use, adapt and build upon.  NiftyNet provides a modular deep-learning pipeline for a range of medical imaging applications including segmentation, regression, image generation and representation learning applications. Components of the NiftyNet pipeline including data loading, data augmentation, network architectures, loss functions and evaluation metrics are tailored to, and take advantage of, the idiosyncracies of medical image analysis and computer-assisted intervention. NiftyNet is built on TensorFlow and supports TensorBoard visualization of 2D and 3D images and computational graphs by default.  We present 3 illustrative medical image analysis applications built using NiftyNet: (1) segmentation of multiple abdominal organs from computed tomography; (2) image regression to predict computed tomography attenuation maps from brain magnetic resonance images; and (3) generation of simulated ultrasound images for specified anatomical poses.  NiftyNet enables researchers to rapidly develop and distribute deep learning solutions for segmentation, regression, image generation and representation learning applications, or extend the platform to new applications.", "text": "gibsonab wenqi lia∗ carole sudreb lucas fidona dzhoshkun shakira guotai wanga zach eaton-rosenb robert grayc doela yipeng whyntieb parashkev nachevc marc modatb dean barrattab s´ebastien ourselina jorge cardosob vercauterena background objectives medical image analysis computer-assisted intervention problems increasingly addressed deep-learning-based solutions. established deep-learning platforms ﬂexible provide speciﬁc functionality medical image analysis adapting domain application requires substantial implementation eﬀort. consequently substantial duplication eﬀort incompatible infrastructure developed across many research groups. work presents opensource niftynet platform deep learning medical imaging. ambition niftynet accelerate simplify development solutions provide common mechanism disseminating research outputs community adapt build upon. range medical imaging applications including segmentation regression image generation representation learning applications. components niftynet pipeline including data loading data augmentation network architectures loss functions evaluation metrics tailored take advantage idiosyncracies medical image analysis computer-assisted intervention. niftynet built tensorflow framework supports features tensorboard visualization images computational graphs email wenqi.liucl.ac.uk mailing address wellcome epsrc centre interventional surgical sciences university college london gower street london united kingdom results present three illustrative medical image analysis applications built using niftynet infrastructure segmentation multiple abdominal organs computed tomography; image regression predict computed tomography attenuation maps brain magnetic resonance images; generation simulated ultrasound images speciﬁed anatomical poses. conclusions niftynet infrastructure enables researchers rapidly develop distribute deep learning solutions segmentation regression image generation representation learning applications extend platform applications. computer-aided analysis medical images plays critical role many stages clinical workﬂow population screening diagnosis treatment delivery monitoring. role poised grow analysis methods become accurate cost eﬀective. recent years driver improvements adoption deep learning convolutional neural networks many medical image analysis computer-assisted intervention tasks. deep learning refers deeply nested composition many simple functions parameterized variables. particular composition functions called architecture deﬁnes parametric function optimized minimize objective ‘loss’ function usually using form gradient descent. although ﬁrst neural networks medical image analysis dates back twenty years usage increased orders magnitude last years. recent reviews highlighted deep learning applied wide range medical image analysis tasks across wide range anatomical sites although applications speciﬁcities substantial overlap software pipelines implemented many research groups. deep-learning pipelines medical image analysis comprise many interconnected components. many common deep-learning pipelines separation data training testing validation sets; randomized sampling training; image data loading sampling; data augmentation; network architecture deﬁned composition many simple funcmedical image analysis many components domain speciﬁc idiosyncrasies detailed section example medical images typically stored specialized formats handle large images anisotropic voxels encode additional spatial information and/or patient information requiring diﬀerent data loading pipelines. processing large volumetric images high memory requirements motivates domain-speciﬁc memory-eﬃcient networks custom data sampling strategies. images often acquired standard anatomical views represent physical properties quantitatively motivating domain-speciﬁc data augmentation model priors. additionally clinical implications certain errors warrant custom evaluation metrics. independent reimplementation custom infrastructure results substantial duplication eﬀort poses barrier dissemination research tools inhibits fair comparisons competing methods. work presents open-source niftynet platform facilitate efﬁcient deep learning research medical image analysis computer-assisted intervention; reduce duplication eﬀort. niftynet platform comprises implementation common infrastructure common networks used medical imaging database pre-trained networks speciﬁc applications tools facilitate adaptation deep learning research clinical applications shallow learning curve. development common software infrastructure medical image analysis computer-assisted intervention long history. early eﬀorts included development medical imaging formats analyze dicom minc nifti toolsets solve common challenges registration ants elastix segmentation biomechanical modeling available part image analysis pipelines. pipelines speciﬁc research applications functional analysis freesurfer structural neuroimaging reached widespread use. general toolkits oﬀering standardized implementations algorithms application frameworks mitk slicer enable others build pipelines. common software infrastructure supported accelerated medical image analysis computer-assisted intervention research across hundreds research groups. however despite wide availability general purpose deep learning software tools deep learning technology limited support current software infrastructure medical image analysis computer-assisted intervention. software infrastructure general purpose deep learning recent development. high computational demands training deep learning models complexity eﬃciently using modern hardware resources numerous deep learning libraries platforms developed widely adopted including cudnn tensorflow theano caﬀe torch cntk matconvnet platforms facilitate deﬁnition complex deep learning networks compositions simple functions hide complexities diﬀerentiating objective function respect trainable parameters training execute eﬃcient implementations performance-critical functions training inference. frameworks optimized performance ﬂexibility using directly challenging inspiring development platforms simplify development process common usage scenarios keras tensorlayer tensorflow lasagne theano. however avoiding assumptions application remain general platforms unable provide speciﬁc functionality medical image analysis adapting domain application requires substantial implementation eﬀort. aims support fast prototyping reproducibility implementing deep learning methods modules medical image analysis. still preliminary development appears focus deep learning building blocks rather analysis pipelines. niftk slicerd plugin) provide infrastructure distribution trained deep learning pipelines. although address substantial infrastructure needed training deep learning pipelines integration existing medical image analysis infrastructure modular design makes platforms promising routes distributing deep-learning pipelines. simple phases lies substantial complexity illustrated figure obvious complexity implementing network studied. deep neural networks generally simple functions compose complex hierarchies; researchers must implement network tested well previous networks comparison. train evaluate distribute networks however requires infrastructure. data sets must correctly partitioned avoid biassed evaluations sometimes considering data correlations data must sampled loaded passed network diﬀerent ways depending phase pipeline. algorithms tuning hyper-parameters within family models optimizing model parameters training data needed. logging visualization needed debug dissect models training. applications limited data data sets must augmented perturbing training data realistic ways prevent over-ﬁtting. deep learning common practice adapt previous network architectures trained untrained part full similar diﬀerent tasks; requires community repository storing models parameters adaptable format. much infrastructure recreated researcher research group undertaking deep learning project much depends application domain addressed. medical image analysis diﬀers domains deep learning applied characteristics data itself applications used. section present domain-speciﬁc requirements driving design niftynet. acquiring annotating distributing medical image data sets higher costs many computer vision tasks. many medical imaging modalities generating image costly. annotating images many applications requires high levels expertise clinicians limited time. additionally privacy concerns sharing data sets institutions alone internationally logistically legally challenging. although recent tools deepigeos semi-automated annotation gift-cloud data sharing beginning reduce barriers typical data sets remain small. using smaller data sets increases importance data augmentation regularization cross-validation prevent over-ﬁtting. additional cost data annotation also places greater emphasis semiunsupervised learning. including spect capture volumetric images. longitudinal imaging typical interventional settings well clinically useful measuring organ function disease progression time capturing high-resolution data multiple dimensions often necessary detect small clinically important anatomy pathology. combination factors results large data sizes sample impact computational memory costs. deep learning medical imaging uses various strategies account challenge. many networks designed partial images slices sampled along axis images subvolumes anisotropic convolution wang combinations subvolumes along multiple axes networks multi-scale representations allowing deeper wider networks lower-resolution representations third approach uses dense networks reuse feature representations multiple times network smaller batch sizes reduce memory cost rely diﬀerent weight normalization functions batch renormalization weight normalization layer normalization data sets medical imaging typically stored diﬀerent formats many computer vision tasks. support higher-dimensional medical image data specialized formats adopted formats frequently also store metadata critical image interpretation including spatial information patient information acquisition information medical imaging speciﬁc data formats typically supported existing deep learning frameworks requiring custom infrastructure loading images. characteristic properties medical image content pose opportunities challenges. medical images obtained controlled conditions allowing predictable data distributions. many modalities images calibrated spatial relationships image intensities directly physical quantities inherently normalized across subjects. given clinical workﬂow image content typically consistent potentially enabling characterization plausible intensity spatial variation data augmentation. however clinical applications introduce additional challenges. because small image features large clinical importance pathology rare life-threatening medical image analysis must deal large class imbalances motivating special loss functions furthermore diﬀerent types error diﬀerent clinical impacts motivating specialized loss functions evaluation metrics applications computer-assisted intervention analysis results used real time garcia-peraza-herrera additional constraints analysis latency. niftynet platform aims augment current deep learning infrastructure address ideosyncracies medical imaging described section lower barrier adopting technology medical imaging applications. niftynet built using tensorflow library provides tools deﬁning computational pipelines executing eﬃciently hardware resources provide speciﬁc functionality processing medical images high-level interfaces common medical image analysis tasks. niftynet provides high-level deep learning pipeline components optimized medical imaging applications speciﬁc interfaces medical image segmentation classiﬁcation regression image generation representation learning applications. support wide variety application types medical image analysis enable research aspect deep learning pipeline without simple common cases ﬂexible enough complex support built-in tensorflow features support best practices support model distribution adaptation. niftynet platform comprises several modular components. niftynet applicationdriver deﬁnes common structure across applications responsible instantiating data analysis pipeline distributing computation across available computational resources. niftynet application classes encapsulate standard analysis pipelines diﬀerent medical image analysis applications connecting four components reader load data ﬁles sampler generate appropriate samples processing network process inputs output handler sampler includes sub-components data augmentation. network includes sub-components representing individual network blocks larger conceptual units. components brieﬂy depicted figure detailed following sections. concrete illustration instantiation segmentationapplication could following modules. training could uniformsampler generate small image patches corresponding labels; vnet network would process batches images generate segmentations; dice lossfunction would compute loss used backpropagation using adam optimizer. inference could gridsampler generate non-overlapping patches cover image segment network generate corresponding segmentations gridsamplesaggregator aggregate patches ﬁnal segmentation. niftynet applicationdriver deﬁnes common structure niftynet pipelines. responsible instantiating data application objects distributing workload across recombining results computational resources also responsible handling variable initialization variable saving restoring logging. implemented template design pattern applicationdriver delegates application-speciﬁc functionality separate application classes. applicationdriver conﬁgured command line programmatically using human-readable conﬁguration ﬁle. contains data deﬁnitions settings deviate defaults. applicationdriver saves progress full conﬁguration also saved analysis pipeline recreated continue training carry inference internally distributed model. medical image analysis encompasses wide range tasks diﬀerent parts pre-clinical clinical workﬂow segmentation classiﬁcation detection registration reconstruction enhancement model representation generation. diﬀerent applications diﬀerent types inputs outputs diﬀerent networks diﬀerent evaluation metrics; however common structure functionality among applications supported niftynet. niftynet currently supports application class deﬁnes required data interface network loss facilitates instantiation appropriate sampler output handler objects connects needed application speciﬁes training regimen. example segmentationapplication speciﬁes networks accept images generate corresponding labels losses accept generated reference segmentations optional weight optimizer trains trainable variables iteration. contrast ganapplication speciﬁes networks accept noise source samples real data optional conditioning image losses accept logits denoting sample real generated optimizer alternates training discriminator sub-network generator sub-network. complex composition simple functions comprise deep learning architecture simpliﬁed typical networks repeated reuse conceptual blocks. niftynet conceptual blocks represented encapsulated layer classes inline using tensorflow’s scoping system. composite layers even entire networks constructed simple compositions niftynet layers tensorflow operations. supports reuse existing networks clearly demarcating conceptual blocks code reused assigning names corresponding sets variables reused networks also enables automatic support visualization network graph hierarchy diﬀerent levels detail using tensorboard visualizer shown figure following model used sonnet layer objects deﬁne scope upon instantiation reused repeatedly allow complex weight-sharing without breaking encapsulation. reader class responsible loading corresponding image ﬁles medical formats speciﬁed data applying image-wide preprocessing. simple cases niftynet automatically identify corresponding images data searching speciﬁed path matching user-speciﬁed patterns names also allows explicitly tabulated comma-separated value ﬁles complex data structures input output medical formats already supported multiple existing python libraries although library supports diﬀerent sets formats. facilitate wide range formats niftynet uses nibabel core dependency fall back libraries installed format supported nibabel. pipeline image-wide preprocessing functions described section applied image samples taken. figure tensorboard visualization niftynet generative adversarial network. tensorboard interactively shows composition conceptual blocks interconnections color-codes similar blocks. above generator discriminator blocks discriminator’s residual blocks expanded. font block sizes edited readability. assisted intervention niftynet provides ﬂexibility mapping input data packets data processed processed data useful outputs. former encapsulated sampler classes latter encapsulated output handlers. sampling output handling tightly coupled depend action performed instantiation matching sampler objects output handlers delegated application class. sampler objects generate sequence packets corresponding data processing. packet contains data independent computation including images labels classiﬁcations noise samples data needed processing. training samples taken randomly training data inference evaluation samples taken systematically process whole data set. feed samples tensorflow niftynet automatically takes advantage tensorflow’s data queue support data loaded sampled multiple threads combined mini-batches consumed gpus. niftynet includes sampler classes sampling image patches sampling whole images rescaled ﬁxed size sampling noise; supports composing multiple sampler objects complex inputs. output handlers take diﬀerent forms training inference. during training output handler takes network output computes loss gradient loss respect trainable variables uses inlinecodeoptimizer iteratively train model. inference output handler generates useful outputs aggregating network outputs performing necessary postprocessing niftynet currently supports aggregator objects combining image patches resizing images computing evaluation metrics. data normalization augmentation approaches compensating small training data sets medical image analysis wherein training data sparse represent variability distribution images. data normalization reduces variability data transforming inputs speciﬁed invariant properties ﬁxed intensity histograms moments data augmentation artiﬁcially increases variability training data introducing random perturbations during training example applying random spatial transformations adding random image noise. niftynet data augmentation normalization implemented layer classes applied sampler plausible data transformations vary applications. layers histogram normalization data dependent; layers compute parameters data training begins. niftynet currently supports mean variance summarizing comparing performance image analysis pipelines typically rely standardized descriptive metrics error metrics surrogates performance. individual metrics sensitive diﬀerent aspects performance multiple metrics reported together. reference implementations metrics reduce burden implementation prevent implementation inconsistencies. niftynet currently supports calculation descriptive error metrics segmentation. descriptive statistics include spatial metrics intensity metrics error metrics computed respect reference segmentation include overlap metrics boundary distances region-wise errors support reuse network architectures trained models many deep learning platforms host database existing trained untrained networks standardized format called model zoo. trained networks used directly ﬁne-tuned diﬀerent data distributions used initialize networks applications untrained networks conceptual blocks used within networks. niftynet provides several mechanisms support distribution reuse networks conceptual blocks. trained niftynet networks restored directly using conﬁguration options. trained networks developed outside niftynet adapted niftynet encapsulating network within network class derived trainablelayer. externally trained weights loaded within niftynet using restore initializer adapted sonnet complete network individual conceptual blocks. restore initializer initializes network weights stored speciﬁed checkpoint supports variable scope renaming checkpoints incompatible scope names. smaller conceptual blocks encapsulated layer classes reused way. trained networks incorporating previous networks saved self-contained form minimize dependencies. niftynet model contains untrained networks vnet segmentation) well trained networks tasks multiorgan abdominal segmentation wnet brain tumor segmentation simulator generating ultrasound images). model entries follow standard format comprising python source code deﬁning components included niftynet example conﬁguration deﬁning default settings data documentation describing network assumptions input data addition implementation common functionality niftynet development adopted good software development processes support ease-of-use robustness longevity platform well creation vibrant community. platform supports easy installation installation tool provides analysis pipelines part command line interface. examples demonstrating platform multiple cases included reduce learning curve. niftynet repository uses continuous integration incorporating system unit tests regression testing. niftynet releases follow semantic versioning standard ensure clear communication regarding backwards compatibility. segmentations anatomy pathology medical images support image-guided interventional workﬂows enabling visualization hidden anatomy pathology surgical navigation. present example based simpliﬁed version illustrates niftynet train dense v-network segmentation network segment organs abdominal important pancreatobiliary interventions gastrointestinal tract pancreas anatomical landmark organs data used train network comprised abdominal manual segmentations publicly available data sets additional manual segmentations performed centre. network trained evaluated -fold cross-validation using network implementation available niftynet. brieﬂy network available dense vnet niftynet uses v-shaped structure downsampling stage dense feature figure reference standard niftynet multi-organ abdominal segmentation subject dice scores closest median. segmentation shown surface rendering view posterior direction organ labels overlaid transverse slice. stack upsampling bilinear upsampling skip connections convolutions. loss modiﬁed dice loss implemented external niftynet included reference conﬁguration ﬁle. network segmentation metrics computed using niftynet’s evaluation action aggregated folds given table segmentation dice scores closest median shown figure image regression speciﬁcally ability predict content image given diﬀerent imaging modality object paramount importance real-world clinical workﬂows. image reconstruction quantitative image analysis algorithms commonly require minimal inputs often available every patient presence imaging artefacts limitations patient workﬂow image harmonization ionising radiation exposure minimization. example application image regression process generating synthetic images data enable attenuation correction pet-mri images regression problem historically solved patch-based multi-atlas propagation methods class models robust computationally complex dependent image registration. process solved using deep learning architectures similar ones used image segmentation. demonstration application neural network trained evaluated -fold cross-validation setup using regress application niftynet. brieﬂy network available highresnet niftynet uses stack residual dilated convolutions increasingly large dilation factors root mean square error used loss function implemented part niftynet rmse. network trained shown promise generating plausible photographic images recent work spatially-conditioned gans suggests conditional gans could enable software-based simulation place costly physical ultrasound phantoms used training. present example illustrating pre-trained ultrasound simulation network ported niftynet inclusion niftynet model zoo. network originally trained outside niftynet platform described brieﬂy conditional network trained generate ultrasound images speciﬁed views fetal phantom using frames optically tracked ultrasound. image sampled generative model based conditioning image model parameter network ported niftynet inclusion model zoo. network weights transferred niftynet network using niftynet’s restore initializer adapted sonnet enables trained variables loaded networks diﬀerent architectures naming schemes. network evaluated multiple times using linear interpolation inference niftynet wherein samples taken generative model based conditioning image sequence model parameters evenly interpolated random samples. illustrative results shown figure ﬁrst shows anatomy smooth transition between diﬀerent levels ultrasound shadowing artifacts. second shows sharp transition interpolation suggesting presence mode collapse figure interpolated images generative model space based linearly interpolated model parameters. shows smooth variation diﬀerent amounts ultrasound shadow artefacts. bottom shows sharp transition suggesting presence mode collapse generative model. niftynet development guided several core principles impacted implementation. maximizing simplicity simple cases motivated many implementation choices. envisioned three categories users novice users comfortable running applications writing python code intermediate users comfortable writing code modifying niftynet libraries advanced users comfortable modifying libraries. support installation simpliﬁes niftynet novice intermediate users. context enabling experimental manipulation individual pipeline components intermediate users downloadable model entries modiﬁed components novice users required modular approach plugin support externally deﬁned components. accordingly plugins networks loss functions even application logic speciﬁed python import paths directly conﬁguration ﬁles without modifying niftynet library. intermediate users customize pipeline components writing classes functions python embed model entries distribution. although initially motivated simplifying variable sharing within networks niftynet’s named conceptual blocks also simpliﬁed adaptation weights pre-trained models tensorboard-based hierarchical visualization computation graphs. scope conceptual blocks maps meaningful subgraph computation graph associated variables meaning weights conceptual block loaded model single scope reference. furthermore conceptual blocks constructed hierarchically composition layer objects scopes naturally encode hierarchical structure tensorboard visualization applications application logic varies applications. facilitated rapid development application types. early inclusion image segmentation/regression image generation motivated ﬂexible speciﬁcation number type semantic meaning inputs outputs encapsulated sampler aggregator components. niftynet platform available http//niftynet.io/. source code accessed repository installed python library using install niftynet. niftynet licensed open-source apache license. niftynet consortium welcomes contributions platform seeks inclusion community members consortium. active niftynet development roadmap focused three areas application types larger model advanced experimental design. niftynet currently supports image segmentation regression generation representation learning applications. future applications development include image classiﬁcation registration enhancement well pathology detection. current niftynet model contains small number models proof concept; expanding model include state-of-the-art models common tasks public challenges models trained large data sets transfer learning critical accelerating research niftynet. finally niftynet currently supports simpliﬁed machine learning pipeline trains single network relies users data partitioning model selection infrastructure facilitate complex experiments built-in support cross-validation standardized hyper-parameter tuning will future reduce implementation burden users. work presents open-source niftynet platform deep learning medical imaging. modular implementation typical medical imaging machine learning pipeline allows researchers focus implementation eﬀort speciﬁc innovations leveraging work others remaining pipeline. niftynet platform provides implementations data loading data augmentation network architectures loss functions evaluation metrics tailored idiosyncracies medical image analysis computerassisted intervention. infrastructure enables researchers rapidly develop authors would like acknowledge contributors niftynet platform. work supported wellcome/epsrc wellcome department health wellcome trust epsrc national institute health research university college london hospitals biomedical research centre cancer research royal society overseas research scholarship graduate research scholarship. authors would like acknowledge work presented made emerald gpu-accelerated high performance computer made available science engineering south consortium operated partnership stfc rutherford-appleton laboratory; hardware donated nvidia.", "year": 2017}