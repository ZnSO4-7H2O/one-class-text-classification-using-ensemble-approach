{"title": "Crafting a multi-task CNN for viewpoint estimation", "tag": ["cs.CV", "cs.LG", "cs.NE"], "abstract": "Convolutional Neural Networks (CNNs) were recently shown to provide state-of-the-art results for object category viewpoint estimation. However different ways of formulating this problem have been proposed and the competing approaches have been explored with very different design choices. This paper presents a comparison of these approaches in a unified setting as well as a detailed analysis of the key factors that impact performance. Followingly, we present a new joint training method with the detection task and demonstrate its benefit. We also highlight the superiority of classification approaches over regression approaches, quantify the benefits of deeper architectures and extended training data, and demonstrate that synthetic data is beneficial even when using ImageNet training data. By combining all these elements, we demonstrate an improvement of approximately 5% mAVP over previous state-of-the-art results on the Pascal3D+ dataset. In particular for their most challenging 24 view classification task we improve the results from 31.1% to 36.1% mAVP.", "text": "convolutional neural networks recently shown provide state-of-theart results object category viewpoint estimation. however different ways formulating problem proposed competing approaches explored different design choices. paper presents comparison approaches uniﬁed setting well detailed analysis factors impact performance. followingly present joint training method detection task demonstrate beneﬁt. also highlight superiority classiﬁcation approaches regression approaches quantify beneﬁts deeper architectures extended training data demonstrate synthetic data beneﬁcial even using imagenet training data. combining elements demonstrate improvement approximately mavp previous state-of-the-art results pascald+ dataset particular challenging view classiﬁcation task improve results mavp. joint object detection viewpoint estimation long-standing problem computer vision. initially tackled single objects known models progressively investigated complete object categories. interest problem recently increased availability pascald+ dataset provides standard compare algorithms diverse classes improved performance object detection encouraged researchers focus extracting complex information images position objects. convolutional neural networks recently applied successfully task object category pose estimation leading large improvements state-of-the-art results pascald+ benchmark. however many elements play important role quality results fully analyzed. particular several approaches proposed regression approach joint training detection direct viewpoint classiﬁcation geometric structure aware ﬁne-grained viewpoint classiﬁcation authors modify classiﬁcation objective take account copyright document resides authors. distributed unchanged freely print electronic forms. uncertainty annotations encode implicitly topology pose space. papers however differ number ways training data network architecture making difﬁcult compare performances. explore systematically essential design choices cnn-based approach pose estimation demonstrate number elements inﬂuence performance ﬁnal algorithm important way. paper study several factors affect performance task joint object detection pose estimation cnns. using best design options rationally deﬁne effective method integrate detection viewpoint estimation quantify beneﬁts well boost given deeper networks training data including data imagenet synthetic data. demonstrate combination elements leads important improvement state-of-the-art results pascald+ case challenging viewpoints classiﬁcation. several elements employ used previous work know systematic study respective combined effect resulting absence clear good practices viewpoint estimation sub-optimal performances. code available http//imagine.enpc.fr/~suzano-f/bmvc-pose/. related work convolutional neural networks. convolutional neural network long history computer vision generalized demonstration beneﬁts krizhevsky imagenet large-scale visual recognition challenge since then used increase performances many vision tasks. true particular object detection r-cnn technique girshick provided important improvement previous methods pascal dataset relying independent method provide bounding proposals objects image r-cnn ﬁne-tunes network pre-trained imagenet classify proposal objects background. method improved several ways particular using better network architectures better bounding proposals better sharing computations inside image viewpoint estimation. rigid object viewpoint estimation ﬁrst tackled case object instances known models together detection approaches extended object categories detection using either extensions deformable part models parametric models large instances collections advent pascald+ dataset extends pascal dataset aligning models rigid object classes learning-based approaches using example images became possible proved superior performance. example xiang extended method uses adaptation constraints estimate pose. cnn-based approaches availability pascald+ data limited special cases faces small datasets also began applied problem larger scale. explored different pose representations showed interest joint training using alexnet pascal data. used simple classiﬁcation approach network annotations imagenet objects established current state-of-the-art pascald+. introduced discrete ﬁne-grained formulation pose estimation takes account geometry pose space demonstrate using alexnet adding rendered models could improve results using pascal data alone. overview focus problem detecting estimating pose objects images deﬁned pascald+ challenge average viewpoint precision metric. particular focus estimation azimuthal angle. object detection standard fast r-cnn framework relies region proposal signiﬁcantly faster original r-cnn addition associate viewpoint bounding object class. indeed since viewpoint conventions coherent different classes learn different estimator class. however avoid learn network class share last layer network different classes. section ﬁrst discuss different approaches viewpoint prediction cnns particular differences regression classiﬁcation approaches. section introduce different ways integrate viewpoint estimation detection problem. finally section present results different methods well detailed analysis different factors impact performance. notations. call number training samples number object classes. ...ns} associate i-th training sample azimuthal angle viewpoints often discretized call number bins ...nv} includes subscripts denote elements tensor; example element tensor approaches viewpoint estimation section assume bounding class objects known focus different approaches estimate pose. section ﬁrst discusses design regression approaches. section presents variants classiﬁcation approaches. intuition behind different approaches visualized figure azimuth angle viewpoint continuous quantity natural tackle pose estimation regression problem. choice pose representation azimuthal angle course crucial effectiveness regression. indeed simply consider periodicity pose taken account. thus highlighted good pose representation satisﬁes following properties invariant periodicity angle analytically invertible. figure different approaches orientation prediction discussed paper. target approach visualized red. regression approaches possible values targets line. classiﬁcation approaches predictions correspond probability distributions discrete set. representations different output dimensionality respectively designate associated regressions regression regression respectively. since treat regression independently class outputs network train pose estimation values rnc×nd designate angular element output class training regression representations used huber loss component pose representation known robust outliers euclidean loss provides much better results experiments. regression loss written huber loss. given output network sample class estimate pose simply computing pose closest point curve described regression approaches loss discussed lead lower performances. pointed main limitation regression approach viewpoint estimation cannot represent well ambiguities exist different viewpoints. indeed objects table symmetries near symmetries make viewpoint estimation problem intrinsically ambiguous ambiguity well handled representations discussed previous paragraph. solution problem discretize pose space predict probability orientation thus formulating problem classiﬁcation. note similar difﬁculty found problem keypoint prediction similar solution predicting heat keypoint instead predicting directly position proven successful case classiﬁcation approach output network belongs rnc×nv value interpreted log-probability. write value corresponding orientation input class approach successfully applied simply predict class independently orientation object falls. classiﬁcation problem addressed object class standard cross-entropy loss drawback previous classiﬁcation approach learns predict poses without using explicitly continuity close viewpoints. neighboring bins indeed common. geometrical information especially important ﬁne-grained orientation prediction examples available. solution problem proposed authors ﬁnely discretize orientations bins consider angle estimation classiﬁcation problem adapt loss include structured relation neighboring bins penalize less angle errors smaller methods presented previous section assume object detector already trained kept independent pose estimator. since object detection pose estimation relies related information expect beneﬁt training jointly. thus present extensions methods section perform joint training. main approaches considered extend regression approach section jointly perform detection. ﬁrst described encode respectively presence absence object point close regression line described space regression performed. alternative approach discussed output regression network speciﬁcally dedicated detection. loss used train network decomposed terms classiﬁcation loss ldet independent pose regression loss lreg takes account pose estimation. since state-of-the-art performance detection obtained using classiﬁcation loss selected second option following. wdet rnc+ detection part wpose rnc×nd pose estimation part. multi-task loss joint classiﬁcation regression-based pose estimation writes follows deﬁne lreg exactly equation using pose estimation output network wpose. detection loss ldet standard cross-entropy loss detection using detection part network output wdet. balancing parameter experiments. also share weights detection pose estimation network pool layer. essential obtain good performance regression classiﬁcation losses different enough sharing weights leads much worse results. similar approach separating branches network applied classiﬁcation. however introduce simpler parameter-free perform jointly detection pose estimation classiﬁcation setup. indeed simply component associated background patches output vector pose estimation setup section normalize globally rather class independently equation value interpreted probability object class given orientation rather conditional probability object given orientation knowing class. obtain probability object belong class simply probabilities corresponding bins class. similar section write wobjcv rnc×nv value network output corresponding orientation input class additionally write value corresponding background associate class elements background. loss derives cross-entropy writes present experiments comparing different approaches pose estimation presented previous sections. experiments based fast r-cnn object detection framework deep mask bounding boxes proposals. trained evaluated models using pascald+ dataset contains pose annotations training validation images pascal rigid classes well subset imagenet also extended training data adding synthetic images evaluation metric used average viewpoint precision associated pascald similar standard average precision metric used detection tasks considers positive detections viewpoint estimate correct. precisely viewpoints discretized bins viewpoint estimate considered correct falls ground-truth annotation. focus metric discretizes orientation bins ﬁne-grained pascald+ challenge also consider mean mean classes. ﬁne-tuned networks starting network trained imagenet classiﬁcation using stochastic gradient descent momentum weight decay augment datasets horizontally-ﬂipped versions image ﬂipping target orientations accordingly. training joint detection pose estimation models mini-batches consist positive examples. mini-batches size except using synthetic images. using synthetic images randomly create montages rendered views montage containing objects total mini-batch size allows efﬁcient training setup fast r-cnn. initialized learning rate divided convergence training error. number iterations depends amount training data using pascal data decrease learning rate iterations continue train adding imagenet data decrease learning rate iterations continue train ﬁnally adding synthetic data decrease learning rate iterations continue train ﬁrst compare different approaches pose estimation section ﬁxed object detector based alexnet architecture trained detection pascal training report results table ﬁrst observe regression pose representation higher dimensionality performs better using smaller dimensionality believe redundancy representation helps better handle ambiguities estimation. classiﬁcation approach however signiﬁcantly outperforms regressions interestingly simplest classiﬁcation approach section performs slightly better geometryaware method. think main reason difference simple classiﬁcation optimize exactly objective evaluated thus result seen artefact evaluation. note results could different even ﬁnegrained estimation less examples class available. nevertheless since complex geometric structure aware approach performed worse direct classiﬁcation baseline focus rest paper simplest direct classiﬁcation approach. evaluate beneﬁts jointly training model detect objects predict orientation. beneﬁts kinds. first order detections candidates given detector favor conﬁdent orientations thus increase avp. second pose estimates better given object. evaluate effects independently report table results using order given detector used previous section order given joint classiﬁer. experiments performed above alexnet architecture pascal training data. comparing table table shows main effects. first mavp improved even using classiﬁer demonstrating improved viewpoint estimation joint training. second decreased showing detection performs worse trained jointly. however also notice best mavp still obtained joint classiﬁer. shows pose estimation better joint model also case classiﬁcation order learned training jointly detector favours conﬁdent poses. case regression approaches best results obtained using independent detector jointly-learned pose estimation. section consider joint classiﬁcation approach performs best evaluations previous section study performance varies using different architectures training data. comparison left right columns table shows unsurprisingly network instead alexnet consistently improves performances. improvement slightly less mavp hinting mavp boost mainly improved detection performances. training data ﬁrst progressively training images imagenet training images pascal voc. full subset imagenet dataset annotated pascald+ contains average approximately images class strongly unbalanced different classes. analysis results shows consistent improvements training includes data. interestingly mavp improved showing additional data useful pose estimation detection. addition synthetic data improves results even more demonstrating amount training data still limiting factor even uses alexnet architecture includes imagenet images fact demonstrated note joint approach signiﬁcantly outperforms state-of-theart results without using synthetic data synthetic data alexnet architecture. table provides details performance improvements classes well comparison three baselines dpm-voc+vp uses modiﬁed version also predict poses render uses real images pascal well renders training based alexnet uses architecture imagenet data classify orientations object category. seen improve consistently baselines except chair class. detailed analysis shows exception related difference imagenet pascal chairs. indeed adding imagenet data pascal data detection performance chairs drops similarly difference different appearance rendered models real images responsible fact synthetic training data decreases performance boats motorbikes trains. average still found synthetic images boost results mavp. combining joint classiﬁcation approach improvements provided deep architecture additional training data increase state-of-the-art performance pose estimation mavp. think highlighting different factors improvement setting baseline help stimulate work viewpoint estimation.", "year": 2016}