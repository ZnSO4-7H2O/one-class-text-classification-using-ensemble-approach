{"title": "Chained Multi-stream Networks Exploiting Pose, Motion, and Appearance  for Action Classification and Detection", "tag": ["cs.CV", "cs.AI", "cs.HC", "cs.MM", "cs.NE"], "abstract": "General human action recognition requires understanding of various visual cues. In this paper, we propose a network architecture that computes and integrates the most important visual cues for action recognition: pose, motion, and the raw images. For the integration, we introduce a Markov chain model which adds cues successively. The resulting approach is efficient and applicable to action classification as well as to spatial and temporal action localization. The two contributions clearly improve the performance over respective baselines. The overall approach achieves state-of-the-art action classification performance on HMDB51, J-HMDB and NTU RGB+D datasets. Moreover, it yields state-of-the-art spatio-temporal action localization results on UCF101 and J-HMDB.", "text": "general human action recognition requires understanding various visual cues. paper propose network architecture computes integrates important visual cues action recognition pose motion images. integration introduce markov chain model adds cues successively. resulting approach efﬁcient applicable action classiﬁcation well spatial temporal action localization. contributions clearly improve performance respective baselines. overall approach achieves state-of-the-art action classiﬁcation performance hmdb j-hmdb rgb+d datasets. moreover yields state-of-the-art spatio-temporal action localization results j-hmdb. human action recognition complex task computer vision variety possible actions large multiple visual cues play important role. contrast object recognition action recognition involves detection multiple persons also awareness objects potentially involved action pose person motion. actions span various time intervals making good videos temporal context prerequisite solving task full extent success convolutional networks recognition also inﬂuenced action recognition. importance multiple visual cues shown jhuang multistream architectures popular. trend initiated simonyan zisserman proposed simple fusion action class scores obtained separate convolutional networks trained images optical ﬂow. relative success strategy shows deep networks action figure chained multi-stream d-cnn sequentially reﬁnes action class labels analyzing motion pose cues. pose represented human body parts detected deep network. spatio-temporal capture temporal dynamics pose. additional losses used training. ﬁnal output network yrgb provided chain. paper propose three-stream architecture also includes pose figure existing approaches model temporal dynamics human postures hand-crafted features. rather propose compute position human body parts fast convolutional network. moreover network architecture spatio-temporal convolutions combination capture temporal dynamics body parts time valuable improve action recognition performance show dedicated experiments. pose network also yields spatial localization persons allows apply approach spatial action localization straightforward manner. second contribution combination multiple streams also illustrated figure combination typically done summation scores linear classiﬁer early late concatenation features within network. paper propose integration different modalities markov chain leads sequential reﬁnement action labels. show sequential reﬁnement beneﬁcial independent training streams. time sequential chain imposes implicit regularization. makes architecture robust over-ﬁtting major concern jointly training large networks. experiments multiple benchmarks consistently show beneﬁt sequential reﬁnement approach alternative fusion strategies. since actions span different temporal resolutions analyze videos multiple temporal scales. demonstrate combining multiple temporal granularity levels improves capability recognizing different actions. contrast state-of-the-art strategies analyze videos longer time spans e.g. temporal segmentation networks architecture still allows temporal localization actions providing actionness scores frames using sliding window video. demonstrate ﬂexibility applying approach also temporal spatio-temporal action detection. compared previous spatio-temporal action localization methods typically based region proposals action tubes pose network approach directly provides accurate person localization additional computational costs. therefore consistently outperforms previous methods terms speed mean average precision. feature based approaches. many traditional works ﬁeld action recognition focused designing features discriminate action classes features encoded high order encodings e.g. words fisher vector based encodings produce global representation video train classiﬁer action labels. recent research showed approaches computationally expensive also fail capturing context high-level information. based approaches. deep learning enabled replacement hand-crafted features learned features learning whole tasks end-to-end. several works employed deep architectures video classiﬁcation thanks hiearchical feature representation deep networks learn capture localized features well context cues exploit high-level information large scale video datasets. baccouche ﬁrstly used learn spatio-temporal features video next step employed lstm classify video sequences. recently several based works presented efﬁcient deep models action recognition tran employed architecture learn spatio-temporal features videos. fusion multiple modalities. zisserman proposed two-stream capture complementary information appearance motion modality independent stream. feichtenhofer investigated optimal position within convolution network detail combine separate streams. park proposed gated fusion approach. similar spirit wang presented adaptive fusion approach uses regularization terms learn fusion weights. addition optical works made modalities like audio warped object information capture complementary information video classiﬁcation. present work introduce ﬂexible fusion technique early late fusion markov chain show outperforms previous fusion methods. pose feature based methods. temporal dynamics body parts time provides strong information performing action. thus information employed action recognition several works cheron used pose information extract high-level features appearance optical ﬂow. showed using pose information video classiﬁcation highly effective. wang used data mining techniques obtain representation video ﬁnally using bag-of-words model classify videos. present work compute human body layout efﬁciently deep network learn relevant spatio-temporal pose features within streams action classiﬁcation network. rely three input cues images optical human pose form human body part segmentation. inputs provided spatio-temporal inputs covering multiple frames. optical flow compute optical method zach reliable variational method runs sufﬁciently fast. convert x-component ycomponent optical channel image stacking components magnitude magnitude values image multiplied quantized interval body part segmentation figure human body part segmentation architecture. convolutions shown green pooling blue feature dropout brown up-convolutional layers softmax yellow. estimation work make fast-net network human body part segmentation provide action recognition network body pose information. figure illustrates architecture fastnet. encoder part network initialized network skip connections encoder decoder part ensure reconstruction details output original input resolution. trained fast-net architecture j-hmdb mpii action recognition datasets. j-hmdb provides body part segmentation masks joint locations mpii provides joint locations. make body part masks compatible across datasets apply following methodology requires annotation joint locations. first derive polygon torso joint locations around area. secondly approximate parts ellipses scaled consistently based torso area distance respective joints; second column fig. convert body part segmentation channel image mapping label correspondent pre-deﬁned value. best knowledge ﬁrst trained convolutional network body part segmentation purpose action recognition. figure shows exemplary results body part segmentation technique j-hmdb mpii datasets. clearly network provides good accuracy part segmentation capable handling images multiple instances. pose estimation network resolution runs fps. action recognition network multi-stream fusion markov chain integrate information different inputs rely model multi-stream architecture i.e. input separate convolutional network stream trained action classiﬁcation. innovation approach combine streams. contrast previous works combine features different streams sequentially. starting human body part stream reﬁne evidence action class figure qualitative results j-hmdb mpii datasets first column input image. second column ground truth. third column result predicted fast-net. first rows correspond results j-hmdb last ones mpii. assumption class predictions conditionally independent different input modalities. consequently joint probability input streams factorizes conditional probabilities separate input streams. markov chain given sequence inputs wish predict output sequence maximized. proposed model stage next prediction made conditioned previous predictions input. therefore training network prediction output class label depend input also previous state. thus network stream learn complementary features reﬁne class labels previous streams. chaining joint training information previous stages serve present belief predictions current stage shown figure -right. sequential improvement class label enables combination multiple cues within large network keeping risk over-ﬁtting low. contrast fusion approaches combine features different independently trained streams. case different streams enforced learn complementary features. extreme approaches train streams jointly sequentially prone over-ﬁtting network large case lacks regularization separate streams additional losses. expected ordering sequence plays role ﬁnal performance. compared different ordering options experiments report following section. ordering starts pose input ends image yielded best results. worth noting concept sequential fusion could applied layer network. placed fusion ﬁrst fully-connected layer fusion could also applied earlier convolutional layers. streams architecture base architecture parameters. network three-dimensional convolution layers kernel size stride three-dimensional pooling layers kernel size stride fully connected layers followed softmax; figure stream connected next stream layer figure -right. stream takes frames input. non-linearity unit denotes hidden state previous stream prediction stream dcnn convolutional part network presented figure encapsulate information input modality nets fully connected part figure fusion stage concatenate output function dcnn hidden state outputs previous stream apply non-linearity feeding nets. output part nets predict action labels softmax function convert scores probabilities. using notation consider input modalities {xpose xrgb} {xt}t t-th frame total number frames stage considering xpose start initial hidden state obtain initial prediction figure base architecture used stream action recognition network. convolutional part dcnn architecture. deﬁne remaining fully connected layers ets. network weights learned using mini-batch stochastic gradient descent momentum weight decay jointly optimize whole network without truncating gradients update weights stream based full gradient including contribution following stream. initialize learning rate decrease factor every j-hmdb multiple steps hmdb. maximum number iterations j-hmdb hmdb datasets. initialize weights streams network pre-trained large-scale sports-m dataset split video clips frames overlap frames feed clip individually network stream size apply corner cropping form data augmentation training data. corner cropping extracts regions corners center image. helps prevent network bias towards center area input. finally resize cropped regions size iteration streams take clip video augmentation different modalities input. test time feed architecture temporal window frames. stride video inputs randomly selected cropping operations corners center crop original image horizontal ﬂipping counterpart. extract scores softmax normalization last stream poral windows across video crop scores clip. apart averaging also tested multi-resolution approach call multi-granular trained separate networks three different temporal resolutions. assembled consecutive frames frames temporal window frames sample rate frames sampled randomly entire video. ﬁnal score take average scores produced temporal resolution networks. approach extends temporal context network useful complex actions longer duration. case temporal action detection localize action time thresholding score provided frame. clearly approach applicable here. addition action score also human body part network helps temporal localization detect action long human detected. details spatio-temporal action detection provided experimental section supplemental material. ucf- contains million frames videos divided human action classes. dataset split three folds split contains videos training. dataset also comes subset spatiotemporal action detection. j-hmdb contains subset videos hmdb dataset provides additional annotation particular optical joint localization thus well-suited evaluating contribution optical body part segmentation fusion cues table value different cues integration action recognition hmdb jhmdb datasets adding optical pose always beneﬁcial. integration proposed markov chain clearly outperforms baseline fusion approach. cases accuracy achieved estimated optical body parts almost reaches upper bound performance providing ground truth values inputs. markov chain. dataset comprises human actions. complete dataset clips frames. folds training testing dataset. videos j-hmdb trimmed come bounding boxes. thus used also benchmark spatial action localization. rgb+d recent action recognition dataset quite large provides depth pose ground truth contains sequences million frames. provides action classes coordinates joints. additionally high intra-class variations make challenging datasets. table shows fusion sequential markov chain model outperforms baseline fusion consistently across datasets. baseline fusion shown figure considered strong baseline. consists fusing multiple modalities feature concatenation followed fully connected layers. network trained jointly. adding pose leads substantial improvement two-stream version. conﬁrms pose plays important role complementary modality action recognition tasks. again markov chain fusion advantageous large margin. j-hmdb dataset ground truth optical pose available provided method. relevant practice running recognition ground truth shows much performance lost erroneous optical pose estimates. surprisingly difference results rather small showing network suffer much imperfect estimates. conclusion drawn independently fusion method. table compares proposed network state action classiﬁcaation. contrast table comparison show direct inﬂuence single contributions anymore since table compares whole systems based quite different components. many systems also features extraction approaches improved dense trajectories generally positive inﬂuence results also make system complicated harder control. network outperforms state j-hmdb hmdb. also dataset approach current state rely additional hand-crafted features. stream case replace dcnn network approach obtain classiﬁcation accuracy state also dataset. however approach allow action detection anymore. finally network recent rgb+d dataset larger challenging previous datasets. dataset popular evaluation methods based human body pose. clearly result network shown table compares favorably existing methods. result used pose estimation network competitive pose estimates using depth images integrate information images optical advantageous. table shows analysis order modalities affects ﬁnal classiﬁcation accuracy. clearly ordering effect. proposed ordering starting pose adding optical images performed best alternative orders perform much worse. principle chained fusion applied layer network. studied effect choice. contrast large scale evaluation feichtenhofer tested locations table shows clear difference j-hmdb dataset. seems earlier fusion level features abstract advantageous. similar analyzed effect size temporal window action recognition performance. larger windows clearly improve accuracy datasets; table j-hmdb dataset temporal window ranging frames every frames. highest accuracy obtained frames clip size. based j-hmdb minimum video size highest possible time frame explored. also tested multiple temporal resolutions dataset again obtained best results network larger clip length input. conducted experiments conﬁrm increasing length clip decrease chance getting unrelated parts action video. addition longer sequences convolutions better exploit ability capture abstract spatio-temporal features recognizing actions. demonstrate generality approach show also results action detection j-hmdb. many performing methods action classiﬁcation applicable action detection integrate information time complex manner slow unable spatially localize action. different approach efﬁcient sliding window manner time provides good spatial localization human body part segmentation. order create temporally consistent spatial detections link action bounding boxes time profigure scheme spatio-temporal action detection. chained network provides action class scores body part segmentations frame. compute action tubes actionness scores; supplemental material details. duce action tube supplemental material details. frame level action classiﬁcation scores make predictions tube level. figure schematically outlines detection procedure. also present qualitative action detection experiments j-hmdb datasets. figure shows several examples robustly localize action even unusual pose illumination viewpoints motion blur presented. additional results exploring failure cases provided supplementary material. following recent works action detection report video-ap. detection considered correct intersection union ground-truth threshold action label predicted correctly. tubes deﬁned temporal domain multiplied average between boxes averaged overlapping frames. videoap measures area precision-recall curve action tube predictions. table table show video results spatial spatio-temporal action detection different thresholds j-hmdb datasets respectively. although optimize approach action detection obtain state-of-the-art results datasets. moreover approach fast spatial detection runs rate spatio-temporal detection fps. compared recent works detection framework desirable properties pose network directly provides single detection person causes large speed-up; classiﬁcation figure qualitative results action detection task. ﬁrst rows correspond detections last ones j-hmdb. ground truth bounding boxes shown green detections red. spatial localization accurate robust unusual pose. proposed network architecture integrates multiple cues sequentially markov chain model. shown sequential fusion clearly outperforms ways fusion consider mutual dependencies cues training avoiding overﬁtting large network models. approach provides state-of-the-art performance four challenging action classiﬁcation datasets hmdb j-hmdb rgb+d using additional handcrafted features. moreover demonstrated value reliable pose representation estimated fast convolutional network. finally shown approach generalizes also spatial spatio-temporal action detection obtained state-of-the-art results well.", "year": 2017}