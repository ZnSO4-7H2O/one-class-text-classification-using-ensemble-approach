{"title": "Transforming Graph Representations for Statistical Relational Learning", "tag": ["stat.ML", "cs.AI", "cs.LG", "cs.SI", "I.2; I.2.6; H.2.8; H.3.3"], "abstract": "Relational data representations have become an increasingly important topic due to the recent proliferation of network datasets (e.g., social, biological, information networks) and a corresponding increase in the application of statistical relational learning (SRL) algorithms to these domains. In this article, we examine a range of representation issues for graph-based relational data. Since the choice of relational data representation for the nodes, links, and features can dramatically affect the capabilities of SRL algorithms, we survey approaches and opportunities for relational representation transformation designed to improve the performance of these algorithms. This leads us to introduce an intuitive taxonomy for data representation transformations in relational domains that incorporates link transformation and node transformation as symmetric representation tasks. In particular, the transformation tasks for both nodes and links include (i) predicting their existence, (ii) predicting their label or type, (iii) estimating their weight or importance, and (iv) systematically constructing their relevant features. We motivate our taxonomy through detailed examples and use it to survey and compare competing approaches for each of these tasks. We also discuss general conditions for transforming links, nodes, and features. Finally, we highlight challenges that remain to be addressed.", "text": "department computer science purdue university west lafayette department computer science u.s. naval academy annapolis navy center applied research artiﬁcial intelligence naval research laboratory washington e-mail {rrossi neville}cs.purdue.edu lmcdowelusna.edu david.ahanrl.navy.mil relational data representations become increasingly important topic recent proliferation network datasets corresponding increase application statistical relational learning algorithms domains. article examine range representation issues graph-based relational data. since choice relational data representation—for nodes links features—can dramatically aﬀect capabilities algorithms survey approaches opportunities relational representation transformation designed improve performance algorithms. leads introduce intuitive taxonomy data representation transformations relational domains incorporates link transformation node transformation symmetric representation tasks. particular transformation tasks nodes links include predicting existence predicting label type estimating weight importance systematically constructing relevant features. motivate taxonomy detailed examples survey compare competing approaches tasks. also discuss general conditions transforming links nodes features. finally highlight challenges remain addressed. majority research machine learning assumes independently identically distributed data. independence assumption often violated relational data encode dependencies among data instances. instance people often linked business associations information person highly informative prediction task involving associate person. generally relational data described nodes connected types relations relational information seemingly ubiquitous; present domains internet worldwide scientiﬁc citation collaboration epidemiology communication analysis metabolism ecosystems bioinformatics fraud terrorist analysis many others. links data represent citations friendships associations metabolic statistical relational learning methods developed address problems reasoning learning domains complex relations probabilistic structure particular algorithms leverage relational information attempt learn models higher predictive accuracy. characteristic many relational datasets correlation statistical dependence values attribute across linked instances relational autocorrelation provides unique opportunity increase accuracy statistical inferences similarly relational information exploited many reasoning tasks identifying useful patterns optimizing systems representation issues—including knowledge model data representation—have heart artiﬁcial intelligence community decades important focus data representation issues simple examples include choices whether discretize continuous features higher-order polynomial features. decisions signiﬁcant eﬀect accuracy eﬃciency algorithms. especially critical performance algorithms because relational domains even larger space potential data representations consider. complex structure relational data often represented variety ways choice speciﬁc data representation impact applicability particular models/algorithms performance. speciﬁcally categories decisions need considered context relational data representation. first consider type data representation instance relational data propositionalized application standard non-relational learning algorithms. often order fully exploit relational information researchers chosen represent data either using attributed graph relational database logic programs choice diﬀerent strengths. article focus graph-based representation common choice addressing growing interest network data applications analyzing electronic communication online social networks facebook twitter flickr linkedin speciﬁcally next given type representation must consider speciﬁc content data representation large space choices. instance features nodes links graph constructed using wide range aggregation functions based multiple kinds links paths. researchers already recognized importance data representation choices many separate studies examined techniques feature construction node weighting link prediction etc. however article ﬁrst comprehensively survey assess approaches relational representation transformation graph-based data. given relational data deﬁne relational representation transformation links nodes and/or features used represent data. change space typically goal transformation improve performance subsequent application. instance figure original graph representation transformed representation links nodes features figure example transformation subsequent analysis original relational representation transformed dotted lines represent predicted links squares represent predicted nodes bold links represent link weighting. changes based link structure link features node features analysis applied representation. example analysis produces label node example task discussed section article focuses representation transformation subsequent analysis. added links removed. algorithm analysis applied representation instance classify nodes identify anomalous links. particular transformations used produce vary depending upon intended application sometimes substantially improve accuracy speed complexity ﬁnal application. instance gallagher found adding links similar nodes could increase node classiﬁcation accuracy tasks. similarly neville jensen demonstrated adding nodes represent underlying groups enabled simpler inference increased accuracy. article focuses examining categorizing various techniques changing representation graph-based relational data. shown figure typically view changes pre-processing step enables increased accuracy speed task object classiﬁcation. however output techniques valuable. instance administrators social network interested link prediction predicted links presented users potential friendship links. alternatively techniques also applied improve comprehensibility model. example prediction protein-protein interactions provides insights protein function thus techniques survey used multiple purposes relevant publications used diﬀerent contexts. regardless original context examine general applicability beneﬁts technique. techniques applied transformed data used examined greater understanding used task used recursively input another representation change attempt survey many methods could used analysis although relevant methods analysis overlaps methods facilitate transformations consider. instance collective classiﬁcation important application deﬁne section running example analysis task. output classiﬁcation could also used create attributes nodes discuss possibility section focus cases node labeling particularly useful pre-processing step rather surveying wide range possible classiﬁcation algorithms whether collective not. likewise survey issues model knowledge representation whether statistical dependencies nodes links features modeled structural logistic regression markov logic network consider issues brieﬂy section furthermore focus transformations graph-based data modify links nodes modify features. consider changing graph-based data diﬀerent type representation e.g. propositionalizing data changing logic program. however transformations discuss node link feature aggregation form propositionalization. addition section describes number techniques structure learning logic programs techniques closely related analogous problem feature construction graph-based representations. finally many techniques discuss also applicable logical representations. instance link weighting could applied weight known relations using logic program detect anomalous objects. focus however methods useful transforming graph-based representations. many dimensions relational data transformation complicate task understanding selecting appropriate techniques. assist process introduce simple intuitive taxonomy representation transformation identiﬁes link transformation node transformation symmetric representation tasks. speciﬁcally transformation tasks nodes links include predicting existence predicting label type estimating weight importance constructing relevant features. addition propose taxonomy constructing link node features consists non-relational features topology features relational node-value features relational link-value features. relational transformation task survey applicable techniques examine necessary conditions provide detailed examples comparisons. article organized follows. next section presents taxonomy relational representation transformation discusses motivating example. section review algorithms link prediction section examines task link interpretation sections consider corresponding prediction interpretation tasks nodes instead links. section summarize algorithms jointly transform nodes links. section discusses methods evaluating representation transformations challenges future work section concludes. section ﬁrst introduce running example based classiﬁcation data facebook describe relational algorithms could used perform task. next introduce taxonomy relational representation transformation explain type transformation could facebook classiﬁcation task. finally formally deﬁne type relational representation transformation. nodes users links represent friendships facebook. features users gender relationship status school favorite movies musical preference likewise features provides information friendship links time formation possibly contents message sent link formation requested users. example analysis task predict political aﬃliation every node assume aﬃliation call class label node known people moreover assume user’s political aﬃliation likely correlated characteristics user user’s friends. next section summarizes correlations used classiﬁcation. example assume links simple binary friendship connections. however link types could used represent kinds relationships. instance link might indicate people communicated wall-post message people chosen join facebook group. addition notion friendship facebook weak thus signiﬁcant portion person’s friends often casual acquaintances. thus representation changes link deletion weighting signiﬁcant impact classiﬁcation accuracy. notational purposes tilde graph component’s symbol indicate undergone transformation predict political aﬃliation facebook users conventional classiﬁcation approaches would ignore links classify user using information known user gender location. assume information represented form nonrelational features features computed directly without considering links refer classiﬁcation based features non-relational classiﬁcation. alternatively relational classiﬁcation links explicitly used construct additional relational features capture information user’s friends. instance relational feature could compute user proportion friends male live particular region. using relational information potentially increase classiﬁcation accuracy though sometimes decrease accuracy well finally even greater increases occur class labels linked users used instead derive relevant features instance class-label relational feature could compute user proportion friends liberal views. however using features challenging since labels initially unknown thus typically must estimated iteratively reﬁned way. process jointly inferring labels interrelated nodes known collective classiﬁcation requires models inference procedures inferences user aﬀect inferences related users. many algorithms considered including gibbs sampling relaxation labeling belief propagation weighted neighbor techniques survey. general type node. instance nodes citation network represent papers authors. later discuss representation change node labeling also constructs estimated label every node. discussed section representation changes sometimes resemble output analysis focus changes particularly useful pre-processing subsequent analysis. concrete example analysis explain many techniques survey terms facebook classiﬁcation task special emphasis however features transformation techniques apply many tasks data sets relationship classiﬁcation anomalous link detection entity resolution group discovery figure shows proposed taxonomy relational representation transformation. main tasks taxonomy link transformation node transformation.we powerful elegant symmetry tasks. particular link node representation transformation tasks decomposed prediction interpretation tasks. former task involves predicting existence nodes links. latter task interpretation involves three parts constructing weights labels features nodes links. together yields eight distinct transformation tasks shown leaves taxonomy figure underneath eight tasks ﬁgure list primary graph component modiﬁed task followed illustration possible representation change task. text below summarize figure organized around four larger categories link prediction link interpretation node prediction node interpretation. first link prediction adds links graph. sample graph task shows link predicted similarity nodes used predict link them. intuitively facebook users share values many non-relational features also share political aﬃliation. thus adding links people increase autocorrelation improve accuracy collective classiﬁcation. many simple link prediction algorithms based similarity neighbor properties shortest path distances inﬁnite sums paths strategies. section provides detail techniques. second several types link interpretation involves constructing weights labels features existing links. instance many graphs links equal importance. thus figure shows result performing link weighting. case weights based similarity feature values pair linked nodes assumption high similarity indicate stronger relationships. alternatively link labeling used assign kind discrete label link. instance figure shows links might labeled either personal work related e.g. based known feature values analysis communication events linked users. finally figure shows link feature construction used general kinds feature values link. instance link feature might count number communication events occurred people number friends common. link weighting labeling could perhaps viewed special cases link feature construction separate later sections show useful techniques task diﬀer. three link interpretation tasks could help example classiﬁcation problem. particular model learned predict political aﬃliation might choose place special emphasis links highly weighted labeled personal. link features might used represent complex dependencies instance modeling inﬂuence user’s work friendships friendship links nodes large number friends common. details techniques provided section areshownundertheleavesofthetaxonomy.intheseexamplegraphsnodeswithsimilarshadingshavesimilarfeaturevalues. respectively.interpretationisfurtherdividedintoweightinglabelingorconstructingfeatures.examplesofeachofthetasksinrelationalrepresentationtransformation transformationtaskslinkpredictionlinkinterpretationnodepredictionandnodeinterpretation.eachtaskyieldsamodiﬁedgraphcomponent˜e˜xe˜vor˜xv figurerelationalrepresentationtransformationtaxonomylinkandnodetransformationareformulatedassymmetrictasksleadingtofourmain latent groups graph user connected latent group node. discovered node facebook might represent types social processes inﬂuences tightly knit group friends. clustering techniques used identify nodes could designed identify people particularly similar respect relevant characteristic political aﬃliation. nodes associated links could used several ways. instance though present small example figure nodes away original graph much closer graph. thus links latent node allow inﬂuence propagate eﬀectively algorithm applied. alternatively identiﬁcation distinct latent groups even enable eﬃcient accurate algorithms applied separately group node prediction discussed section finally several types node interpretation involves constructing weights labels feature values existing nodes. instance links nodes inﬂuential others thus weight. figure demonstrates node weighting weights might assigned based numbers friends pagerank/eigenvector techniques. section details. alternatively figure shows example node labeling. graph represents training graph node given estimated label conservative liberal moderate labels might estimated using non-relational features textual analysis. classiﬁcation algorithms learn model based true labels training graph approaches instead ﬁrst compute estimated labels learn model representation section discusses simplify inference. finally figure shows result node feature construction arbitrary feature values added node. instance suppose users relatively facebook friends often moderate many friends often liberal. case feature counting number friends node would useful. directly exploit autocorrelation diﬀerent feature might count proportion user’s friends conservative common political aﬃliation user’s friends. feature correlated political aﬃliation could used improve performance classiﬁcation algorithm example problem. identifying and/or computing features essential performance algorithms challenging; section considers process. table summarize prominent techniques performing tasks link prediction link interpretation node prediction node interpretation. sections provide detail category turn. relational representation transformation deﬁnitions terminology assume initial relational data represented graph corresponds node edge corresponds link nodes features nodes feature. likewise features links feature. features could refer link weights distances types among possibilities. preceding notation lets identify instance values particular feature nodes. alternatively refers vector containing feature values particular node contains feature values particular edge eij. table summarizes notation. process nodes links weights labels general features added nodes links removed. theory transformation seeks optimize objective function although practice objective function table summary techniques summary prominent graph transformation techniques tasks predicting existence nodes links interpreting weighting labeling constructing general features. deﬁnition given nodes observed links and/or feature link prediction task deﬁned creation modiﬁed link usually involves adding links present links deﬁnition given nodes observed links and/or feature link interpretation task deﬁned creation link feature values values additional links also introduced link prediction. deﬁnition given nodes links and/or feature node transformation deﬁned creation modiﬁed node addition many node prediction tasks simultaneously create links e.g. table summary notation used survey half table shows symbols sometimes written tilde symbol indicating result transformation. conciseness table demonstrates notation deﬁnition given nodes observed links and/or feature node interpretation task deﬁned creation node feature estimated nodes. node feature could represent node weights labels general features. constructed without making links features sometimes referred articles attributes intrinsic features. important terms also referred multiple diﬀerent ways. reader table summarizes synonyms terms found often literature. tation. given initial graph interested creating modiﬁed link usually prediction links present task motivated several ways. instance need predict missing links present incomplete data collection problems. similarly interested predicting hidden links assume exists unobservable interactions goal discover model interactions. example network representing criminals terrorist activity seek predict link people directly connected whose actions share common motivation cause. missing hidden links predicting links improve accuracy subsequent learned model. alternatively seek predict future links evolving network friendships connections formed next year. might also interested predicting links objects spatially related. finally wish figure summarizes general approach often used link prediction tasks. summary scores weights computed every pair nodes graph shown figure predicted links weight greater threshold along original links used create link ﬁnal step weights predicted links often discarded yielding graph uniform link weights shown figure challenge approach compute weight score possible link. information used computation provides natural categorize link prediction techniques. below section describes techniques non-relational features nodes section describes topology-based techniques graph structure finally section describes hybrid techniques exploit node features graph structure. section consider link predictors exploit graph structure relational features derived using graph structure. given arbitrary pair nodes graph node represented feature vector respectively. feature-based link prediction deﬁned using arbitrary similarity measure means estimate likelihood link exist typically link created similarity exceeds ﬁxed cut-oﬀ value; another strategy predict links among node pairs highest similarity. traditional approach simply deﬁne measure similarity objects possibly based knowledge application and/or problem-domain. many similarity metrics proposed mutual information cosine similarity many others instance macskassy represents textual content node feature vector uses cosine similarity create links nodes graph. macskassy showed combination initial links predicted text-based links increased classiﬁcation accuracy compared using initial links text-based links. addition leveraging textual information predict links might arbitrary features combined figure example demonstrating general approach link prediction initial graph used input link predictor yielding complete graph weights estimated pairs nodes. next step shows removal initial links consideration followed pruning predicted links weight cut-oﬀ value remaining predicted links combined initial links often estimated weights initial predicted links discarded leaving uniform weight graph proper measure similarity link prediction. instance many recommender systems implicitly predict link users based similarity ratings items movies books case cosine similarity correlation commonly used similarity metrics. alternatively similarity measure learned predicting link existence. link prediction problem transformed standard supervised classiﬁcation problem binary classiﬁer trained determine similarity nodes based feature vectors. approach hasan applied support vector machines found non-relational feature useful predicting links bibliographic network. many link prediction approaches apply traditional machine learning algorithms. however features based graph structure well non-relational features focus section. thus discuss techniques section latent topics document. inter-document topic similarity used similarity metric link prediction however many topic models capable performing joint transformation nodes links defer full discussion techniques section topology-based link prediction uses local relational neighborhood and/or global graph structure predict existence unobserved links. table summarizes common metrics used task. below discuss many approaches starting simplest local metrics moving complex techniques based global measures and/or supervised learning. systematic study many approaches applied social network data liben-nowell kleinberg metrics based local neighborhood nodes simplest approaches local neighborhood nodes graph devise measure topology similarity pairwise similarities nodes predict likely links. shown table numerous metrics often based number neighbors nodes share common varying strategies normalization. zhou compares nine local similarity measures datasets ﬁnds simplest link predictor common neighbors performs best overall. also propose metric outperforms initial nine metrics datasets. metric similar adamic/adar metric uses diﬀerent normalization factor yields better performance networks higher average degree. also propose method uses additional two-hop information avoid degenerate cases links assigned similarity score. results highlight importance selecting appropriate metrics speciﬁc problems datasets. another related investigation clauset evaluates hierarchical random graph predictor local topology metrics common neighbors jaccard’s coeﬃcient degree product three types networks metabolic ecology social network. baseline measure based shortest paths performs best metabolic network relationships homogeneous hierarchical metric performs best links create complex relationships predator-prey relationships found ecology network. proposed local random-walk algorithm eﬃcient alternative global random-walk predictors large networks. method evaluated alongside metrics shown perform better networks eﬃciently global random-walk models. metrics based global graph structure sophisticated similarity metrics based global graph properties often involving weighted computation based number paths pair nodes. instance katz measure counts number paths pair nodes shorter paths count computation. rattigan jensen demonstrated even fairly simple metric could eﬀective task anomalous link prediction identiﬁcation statistically unlikely links among links initial graph. related measure hitting time metric average number steps required random walk starting node reach node gallagher random walks restart estimate similarity every pair nodes. focus sparsely labeled networks unlabeled nodes labeled nodes support learning and/or inference relational classiﬁcation. prediction links improves information labeled unlabeled nodes leading increase classiﬁcation accuracy note adding teleportation probabilities random walk approach roughly simrank metric proposes nodes similar linked neighbors similar. interestingly show approach equivalent metric based time required backwards random walks starting arrive node. approaches based random walks metric could computed repeated simulations eﬃciently computed recursive set-point approach. meta-approaches supervised learning approaches metrics modiﬁed combined multiple ways. liben-nowell kleinberg consider several metaapproaches local global similarity metric subroutine. instance metrics discussed deﬁned terms arbitrary adjacency matrix given formulation imagine ﬁrst computing low-rank approximation matrix using technique singular value decomposition computing local global graph metric using modiﬁed idea retains structure original matrix noise reduced. liben-nowell kleinberg also propose meta-approaches based removing spurious links suggested ﬁrst round similarity computation based augmenting similarity scores node based scores nodes similar compare performance three meta-approaches multiple local global metrics task predicting future links social network. katz measure meta-approaches based clustering low-rank approximation perform best three arxiv datasets simple local measures common neighbors adamic/adar also perform surprisingly well. supervised learning methods also used combine augment similarity metrics discussed. instance lichtenwalter investigate several supervised methods link prediction sparsely labeled networks using many metrics table metrics used features simple classiﬁers naive bayes. supervised approach leads improvement simple unsupervised link prediction metrics. similarly kashima propose supervised probabilistic model assumes biological network evolved time uses topological features estimate model parameters. evaluate proposed method proteinprotein metabolic networks report increased precision compared simpler metrics adamic/adar preferential attachment katz. discussion general local topology metrics sacriﬁce amount accuracy computational gains global graph metrics perform better costly estimate infeasible huge networks. appropriate supervised methods combine multiple local metrics oﬀer promising alternative. next subsection discusses additional work link prediction used supervised methods. link prediction using metrics especially sensitive characteristics domain application. instance many networks biology identiﬁcation links costly contain missing incomplete links removal insigniﬁcant links signiﬁcant issue social networks. reason researchers analyzed proposed many diﬀerent metrics working domains analysis social network analysis citation analysis ecology communities biological networks many others subsection examine approaches perform link prediction using attributes graph topology. approaches questions. first kinds features used? second information multiple features combined single measure probability used prediction? ﬁrst consider non-relational relational features used. expected best features vary based domain speciﬁc network. instance taskar studied link prediction network pages found simple local topology metrics important nonrelational features based words presents pages. similarly hasan found single metric/feature hitting time used link prediction must ensure metric works well nodes yields consistent ranking. however multiple feature values combined acceptable wider range features especially supervised learner later select weight important features based training data. thus hybrid systems link prediction tend diverse feature set. instance zheleva propose features based combining diﬀerent kinds networks features based groups topology constructed combined network used along descriptive non-relational features yielding improvement compared system without combined-network features. second example complex features provided ben-hur noble design pairwise kernel predicting links proteins pairwise kernel tensor-product linear kernels original feature space especially useful domains nodes might common features. approach also applied user preference prediction recommender systems vert yamanishi propose related approach supervised learning used create mapping original nodes euclidean space simple distance metrics used link prediction. given great diversity possible features link prediction interesting approach system automatically searches relevant features use. example popescul propose unique link prediction approach systematically generates searches space relational features learn potential link predictors. logistic regression link prediction consider search space covering equi-joins equality selections aggregation operations. approach model selection algorithm continues feature time model long bayesian information criterion score training improved. search algorithm discovers number useful topology-based features co-citation bibliographic coupling well complex features. however complexity searching large feature space avoiding overﬁtting present challenges. next consider second question information multiple features combined single measure used link prediction? prior work taken supervised learning approach non-relational topology-based metrics used features describe possible link. supervised techniques discussed section model learned training data used predict unseen links. supervised approaches apply classiﬁer separately possible link using classiﬁer support vector machine decision tree logistic regression approaches feature representation link created prediction made possible link independent predictions. contrast early work relational bayesian networks relational markov networks involved joint inference computation link prediction prediction could inﬂuenced nearby link predictions using webpage network social network taskar demonstrated joint inference using belief propagation could improve accuracy compared independent inference approach. however approach computationally intensive noted getting belief propagation algorithm converge signiﬁcant problem. possible solution computational challenge simpler approach presented bilgic method involved repeatedly predicting labels node predicting links nodes using available features re-predicting labels links forth. link prediction based independent inference step using logistic regression simpler approaches discussed above. however repeated application step allows possibility link feature values changing iterations based intermediate predictions thus allowing link predictions inﬂuence other. recently backstrom leskovec proposed novel approach supervised ﬁnal predictions based random walk rather directly output learned classiﬁer. given particular target node social network along nodes known link study predict links likely arise future deﬁne simple link features based node proﬁle similarity messaging behavior features estimate initial link weights. show learn weights manner optimizes likelihood subsequent random walk starting arrive nodes already known link random walk thus guided links already known exist call process supervised random walk. argue learning process greatly reduces need manually specify complex graph-based features show outperforms supervised approaches well unsupervised approaches adamic/adar measure. ﬁnal approach link prediction kind unsupervised dimensionality reduction yields matrix reveals possible links. instance propose latent space approach initial link information projected low-dimensional space. link existence predicted based spatial representation nodes latent space. models perform kind factorization link adjacency matrix thus often referred matrix factorization techniques. advantage models spatial representation enables simpler visualization human interpretation. related approaches also proposed temporal networks mixed-membership models situations latent vector representing node usefully constrained binary typically models capability including attributes covariates aﬀect link prediction directly part latent space representation. however demonstrated attributes also represented related distinct latent space. recently menon elkan showed matrix factorization technique link prediction scale much larger graphs training stochastic gradient descent instead mcmc. link prediction remains challenge part large number possible links widely varying data characteristics. depending domain best approach single non-relational metric topology metric richer features evaluated learned model. future work also wish consider using ensemble link predictors yield even better accuracy. discussion link prediction focused predicting links based existing links properties nodes. context however link prediction sometimes taken forms. instance sarukkai server traces predict next page user visit given recent browsing history. particular markov chains related random walks discussed section task also call link prediction. recently dubois smyth model relational events using latent classes event/link arises latent class properties event chosen distributions nodes conditioned assigned class. work local community node inﬂuences distribution computed node related computations stochastic block modeling dubois smyth’s task also form link prediction goal predict presence absence static link frequency occurrence possible event/link. might also interested deleting pruning away noisy less informative links. instance friendship links facebook usually extremely noisy since cost adding friendship links insigniﬁcant. techniques used section could also used remove existing links wherever link prediction algorithm yields score observed link original graph. indeed since link prediction algorithms eﬀectively assign score every possible link could also used assign weight initial links link weighting three subtasks link interpretation shown taxonomy figure however practice weights needed initial links diﬀerent features algorithms often possible and/or eﬀective. next section discusses link weighting algorithms well link interpretation general. also section discuss additional methods link prediction seek jointly transform nodes links. link interpretation process constructing weights labels general features links. three tasks link interpretation related somewhat overlapping. first link weighting task assigning weight link. weights represent relevance importance link typically expressed continuous values. thus weights provide explicit order links. second link labeling similar except usually assigns discrete values link. could represent positive negative relationship could used instance assign topics email communication ﬂows. finally link feature construction process generating discrete continuous features links. instance features might count frequency particular words appeared messages nodes connected link simply count number messages. sense link feature construction subsumes link weighting labeling since weights labels viewed simply possible link features discovered. however many tasks makes sense compute particular feature summarizes relevance link and/or particular feature summarizes type link weights labels especially useful later processing example collective classiﬁcation. moreover techniques used general feature construction tend toward simpler approaches aggregation discretization whereas best techniques computing weights labels involve much complexity including global path computations supervised learning. reason treat link weighting link labeling separately general link feature construction existing link representing importance inﬂuence link. previously discussed link weighting could potentially accomplished applying link prediction technique simply retaining computed scores link weights. instance lassez perform link prediction weighting applying singular value decomposition adjacency matrix retaining signiﬁcant singular-vectors show querying resultant weighted graph yield relevant results compared unweighted graph. unlike link prediction however link weighting techniques designed work links already exist graph. techniques don’t work predicting unseen links weight links based known properties/features existing links compute additional link features yield sensible results links already exist. simplest case link weighting aggregating intrinsic property links. example onnela deﬁnes link weights based aggregated duration phone calls individuals mobile communication network. cases simply counting number interactions nodes appropriate. thus link features like duration direction frequency known aggregated generate link weights. actual link weights already known links supervised methods used weight prediction using known weights training data. instance kahanda neville predict link strength within facebook dataset stronger relationships identiﬁed based user’s explicit identiﬁcation friends popular facebook application. gilbert karahalios also predict link strength facebook form training data survey data collected participants algorithms generate large number features link network learn predictive model regression technique bagged decision trees kahanda neville ﬁnds performs best among several alternatives. gilbert karahalios generate features based proﬁle similarity based user interactions interaction features helpful especially feature based number days since last communication event. kahanda neville similar kinds features term attribute-based transactional features also topological features networktransactional features. features based communications users moderated larger network context. moderation often takes form normalization instance dampen inﬂuence node sent large number messages many diﬀerent friends. features helpful prediction many features also contribute overall predictive accuracy. training data sample link weights available approaches based parameterized probabilistic model still possible. however since candidate link features longer evaluated training data approaches must choose features much carefully. instance xiang examine link weight prediction social network datasets features link. hypothesize relationship strength hidden cause user interactions propose link-based latent variable model capture dependence. inference coordinate ascent optimization procedure predict strength link. since actual strength link known prediction tasks domain cannot directly evaluate accuracy. however xiang demonstrate using link strengths produced method leads higher autocorrelation higher collective classiﬁcation accuracy predicting user attributes gender relationship status. number researchers considered importance recency evaluating link weight assumption events interactions occurred recently weight. instance roth propose interactions rank metric weighting link based messages nodes. formula separately weights incoming outgoing messages link imposes exponential decay importance message based roth metric weight links call implicit social network node represents group users. demonstrate interactions rank metric weights link heavily connects nodes frequently and/or recently communicated. alternatively sharan neville considered weight links graph links appear disappear time. particular construct summarized graph nodes links ever existed past present. link graph weighted based kernel function provide weight links present often recently past. explain modify standard relational classiﬁers weighted links demonstrate variety kernels produce weighted links yield higher classiﬁcation accuracy compared non-weighted graph. recently rossi neville extended work handle time-varying attribute values serve basis incorporating temporal dynamics additional tasks. links labels used describe type relationship link represents. instance facebook example link labeling algorithm create labels representing work personal relationships. labels would enable subsequent classiﬁcation models separately account inﬂuence diﬀerent kinds relationships. prior work link labeling assumed text describes link based unsupervised textual analysis techniques latent dirichlet allocation latent semantic analysis probabilistic latent semantic analysis traditionally techniques used assign latent topics document collection documents. topics formed deﬁned implicitly probability distribution likely word appear given topic associated document. topics always semantically meaningful often manual inspection reveals prominent topics represent sensible concepts advertising government relations. however even semantic associations obvious inferring topics links still analysis since topics identify links represent similar kinds relationships. textual analysis techniques developed independent documents mind inter-linked nodes adapted label links several ways. instance rossi neville examined messages developers contributing open-source software project. treat message separate document infer single likely latent topic message technique could used graph textual content associated links. rossi neville also further consider impact time-varying topics time-varying topic/word associations running multiple iterations time epoch. using model study problem predicting eﬀectiveness diﬀerent developers network. demonstrate accuracy predictions signiﬁcantly improved modeling temporal evolution communication topics. mccallum describe alternative extending lda-like approaches link labeling. essentially bayesian network models probabilistic dependencies documents associated topics words associated topics. propose extend model author-recipient-topic model choice topic document depends author recipient message. parameters learned model inference used infer supervised techniques also used link labeling. instance taskar study academic webpage network consider predict node labels simultaneously predicting link labels given labeled training graph learn complex relational markov network predict labels existence links. make link prediction tractable candidate links considered links suggested textual reference inside page entity graph. utilizes text-based features instance based anchor text known links heading html section possible link reference found. demonstrate rmn’s joint inference nodes links improves performance compared separate inference. however learning inference rmns often signiﬁcant challenge practice limits number types feature considered. approach learns training data uses joint inference entire graph. simpler supervised approach create features link features learning inference arbitrary classiﬁer treats link separately. leskovec study particular form approach link labels representing positive negative relationship create link features based degree nodes involved link also based transitivity-like properties computed known labels nearby links. demonstrate approach using data epinions wikipedia slashdot users manually indicated positive negative relationships users. given network almost edges labeled label classiﬁer able predict label single unlabeled edge high accuracy. interestingly show classiﬁer’s predictive accuracy particular dataset decreases slightly classiﬁer trained diﬀerent dataset trained dataset used predictions. argue theories balance status social psychology partially explain ability predictive models generalize across datasets. unlike techniques discussed section work make text-based features. however general problem predicting sign link related sentiment analysis natural language processing sentiment analysis algorithms could reformulated predict label link given associated text. link nodes established based many diﬀerent kinds relationships many types algorithms could potentially used labeling links even original algorithm designed purpose. instance markov logic networks used extract semantic networks text yielding graph nodes represent objects concepts process produces relations teaches that written nodes could used link labels analysis. another example group-topic model proposed mccallum which like previously mentioned model bayesian network. model intended graphs nodes become connected participate event voting political bill. rather directly labeling links model clusters nodes latent groups based textual descriptions events/votes. however model also simultaneously infers likely topics event could used label implicit links nodes. results model could also used nodes graph represent latent groups discovered. figure link feature aggregation example ﬁgure demonstrates unknown link feature value computed aggregating link feature values surrounding links. aggregation operator mode. link feature construction systematic construction features links typically purpose improving accuracy understandability algorithms. link feature construction important many prediction tasks received considerably less attention node feature construction literature. fortunately many computations developed node feature construction also apply link features. avoid redundancy defer analysis feature construction discussion node feature construction section section brieﬂy discusses techniques node feature construction applied links summarizes major types link features computed. section later describe feature values relational data often based aggregating values multiple nodes. instance feature might compute average common feature value among neighbors particular node. aggregationbased features help account varying number neighbors node have. links aggregation less essential since link precisely endpoint nodes. however aggregation still useful computing features collect information larger area graph. instance figure link feature value computed link center subgraph computation considers feature values links adjacent target link. case aggregation operator mode result link feature value. example used link features input node feature values could also aggregated form link feature. aggregation operators discussed nodes section also applied links. figure summarizes kinds features constructed link. ﬁgure organized around sources information computing single link feature rather details feature computation bottom ﬁgure shows four types link features represented subgraph. case emphasized link bottom subgraph target link feature value computed. subgraphs shows varying amounts information displays features nodes and/or links used inputs kind link feature. simplest type non-relational link feature computed link solely information already known link. thus figure shows feature values already known target link used construct feature value. instance message associated link link feature could count number times certain word occurs number distinct words. alternatively date associated link feature might compute number months since link formed. onnela computed kind feature aggregated figure link feature taxonomy link feature classes non-relational features topology features relational link-value features relational node-value features. subgraphs bottom information potentially used class link feature shown. emphasized link represents feature value computed remaining feature types relational meaning depend graph first topology features computed using topology graph. feature might instance compute total number links adjacent target link. likewise kahanda neville computed clustering coeﬃcient pair linked nodes measures extent nodes neighbors common well topological features adamic/adar measure discussed section used link features help predict link strength could also used tasks. next relational link-value features computed using feature values nearby links. instance figure shows link labels personal work might identiﬁed links adjacent target link. link feature could formed representing distribution labels taking common label averaging. leskovec used link-value features working graphs link sign feature positive negative computed features based signed-degree nodes connected target link well complex measures based paths nodes node labels conservative liberal might identiﬁed nodes close target link. link-value features labels could used create feature value summarization aggregation. often nodes directly attached target link used. instance gilbert karahalios kahanda neville construct link features based similarity nodes’ social network proﬁles. however feature values distant nodes could also used instance compute link feature based similar friends people are. given graph existing nodes node prediction used distinct ways. first node prediction algorithm could used discover additional nodes type already present instance given people communicate email simple algorithm might used create nodes represent email recipients implied messages explicitly represented original graph. alternatively supervised unsupervised machine learning techniques could used discover instance research papers people information available techniques valuable certainly used nodes graph. however work examined context general knowledge base construction rather relational learning. focus second type node prediction involves predicting nodes diﬀerent type already present graph. nodes might represent locations communities shared characteristics social processes functions kind relationship. instance running facebook example newly discovered node represent common interest hobby multiple people share. nodes usually referred latent nodes meaning nodes depend upon features and/or links included input node prediction algorithm. instance including work-based friendships lead diﬀerent groups personal friendships considered. many advantages type representation change regards accuracy understandability. instance nodes directly connected original graph similar become links nodes closer graph space. intuitively nodes connected high level concept share latent properties representing latent structure directly impact classiﬁcation network analysis many tasks. instance reducing path length similar nodes enables inﬂuence nodes propagate eﬀectively collective classiﬁcation performed nodes. model still learn exploit nodes relationships even semantic meaning nodes precisely understood. popular methods predicting nodes based clustering context means grouping nodes nodes within group similar nodes groups. typically node created group links added existing node corresponding group node recent work leskovec exception. technique uses infer existence missing nodes links based known topology graph. prior work sometimes refers nodes hidden nodes especially thought represent concrete characteristics geographic location could measured were reason observed data. figure alternative representations newly predicted groups left ﬁgure shows feature could added node right ﬁgure demonstrates creation nodes represent groups. groups discovered whether clustering technique alternative creating nodes links simply feature node represent group information. left side figure demonstrates alternative. instance node feature might represent running hobby simply represent belonging discovered group unknown meaning. popescul ungar citeseer dataset demonstrate technique derive features improve predictive accuracy. advantage approach opposed adding nodes potentially enables simpler non-relational algorithms make information. potential disadvantage though also allow algorithms propagate inﬂuence newly connected nodes discussed above. however methods general strategy generate much larger numbers latent features used classiﬁcation tang demonstrate that cases resultant large number link-based features make collective inference unnecessary obtaining good accuracy. naturally whether information discovered clusterings best represented nodes features depend upon dataset inference task. section simplicity discuss algorithm assuming nodes created discussion link prediction organize discussion around kinds information used prediction. section discusses non-relational node prediction section discusses topology-based node prediction section discusses hybrid approaches node feature values topology graph. many clustering algorithms used cluster existing nodes using non-relational features used nodes graph. primary types hierarchical clustering algorithms partitioning algorithms k-means k-medoids em-based algorithms self-organizing maps discuss algorithms since well studied non-relational data easily applied relational data clustering based attribute values desired. techniques described section link existing nodes nodes based original link structure graph. cases ﬁnding grouping depends upon computing kind similarity metric every pair nodes. questions thus serve identify techniques. first kind similarity metric used? second metric used predict groupings? address question turn. types metrics group prediction type topology-based link weighting metric could conceivably used latent node prediction. metric suitable long produces high values pairs nodes belong group lower values pairs. instance high value katz metric indicates nodes many short paths them thus belong group. metrics representing distance rather similarity also used negating metric. instance girvan newman focus detecting community structure extending concept node-betweenness links. intuitively network contains latent groups loosely connected intergroup links shortest paths diﬀerent groups must along links. links connect diﬀerent groups assigned high link-betweenness value underlying group structure trivially revealed removing links highest betweenness. idea using link-betweenness relational clustering extended number directions. instance newman girvan introduced random-walk betweenness expected number times random walk pair nodes pass particular link. addition radicchi proposed using link-based clustering coeﬃcient metric. showed metric performs comparably original link-betweenness metric girvan newman much faster local graph measure instead global graph measure. zhou describes metric dissimilarity index computed follows. node compute vector value represents distance node node nodes similar similar distance vectors. thus dissimilarity index nodes deﬁned based euclidean-like distance computation vectors zhou demonstrates technique outperforms link-betweenness approach girvan newman random modular networks. relatively simple metrics often lead useful results. instance ravasz used simple clustering coeﬃcient metric study metabolic networks. study reveals metabolic networks forty-three organisms organized many small highly-connected modules. furthermore coli hidden hierarchical modularity closely overlaps known metabolic functions. using metrics group prediction simplest techniques identifying groups perform kind hierarchical clustering. instance similarities weights computed every pair nodes links removed graph. next weighted links placed nodes ordered weights. intuition varying degrees clusters formed links added. particular approach forms hierarchical tree leaves represent ﬁnest granularity clustering every node separate cluster. move tree larger clusters formed reach nodes joined large cluster. type hierarchical approach used zhou girvan newman similar strategy start instead original graph iteratively remove less similar links graph reveal underlying community structure. challenge approaches clustering spectral clustering also used group identiﬁcation. spectral clustering relies upon computing similarity matrix describes data points transforming matrix yields matrix clustering rows using simple clustering algorithm trivially identify interesting groups data. matrix transformation several variants involves computing kind laplacian computing eigenvectors resultant matrix using eigenvectors represent original data. motivation transformation seen identifying good graph cuts original graph identifying nodes closely related terms random walks; luxburg overview. spectral clustering originally applied non-relational data hierarchical techniques described above applied relational data using link-based metrics computing similarity matrix. instance neville jensen node adjacency matrix spectral clustering technique described malik identify latent groups graphs. show technique enables simpler inference ultimately yields accurate classiﬁcation compared approaches ignore group structure. tang also spectral clustering link graph order create much larger number latent features used learn supervised classiﬁer. unlike latent groups neville jensen technique allows node associated cluster output spectral clustering tang claim leads improved classiﬁcation accuracy. spectral clustering also used complex similarity metrics described next subsection. techniques borrowed search also useful node prediction. instance given adjacency matrix webpage graph hits algorithm computes ﬁrst eigenvectors represent authoritative nodes well prominent nodes point normally algorithm used single prominent community authorities hubs secondary communities discovered also considering non-principal eigenvectors node prediction algorithm could treat community latent group node links represent group. techniques especially useful detecting patterns inﬂuence graph adding explicit links represent inﬂuence. techniques previous section added nodes graph often based clustering using topology graph. principle technique also used nodes’ attributes produce meaningful latent groups/nodes. section considers attribute information techniques node prediction. simple approach deﬁne kind similarity metric combines non-relational topology-based similarity single value provide similarity metric previously mentioned clustering algorithms. instance neville weighted combination attribute link information metric nodes value attribute link exists constant controls relative importance attributes links. metric ncut spectral clustering technique nodes graph demonstrate additional nodes increase performance attribute-based information also incorporated ad-hoc basis. instance adibi describe group ﬁnding algorithm initial seed clusters formed based handcrafted logical rules clusters reﬁned using probabilistic system based mutual information. system logic-based component primarily uses attributes node probabilistic system primarily uses links describe connections people. however components make attributes links. principled approach deﬁne kind generative model represents dependence observed attributes links latent group nodes model estimate group membership. instance kubica deﬁne generative model node belongs groups group members tend link other. particular group membership chart track whether node belongs group local search possible states chart identify membership changes would better explain known data. step maximum likelihood used estimate parameters model. demonstrate usefulness technique news articles webpages synthetic data. generative models also used sophisticated inference. example taskar treats group membership latent variable uses loopy belief propagation implicitly perform clustering nodes. likewise mixed membership relational clustering uses variants estimate group memberships. particular uses ﬁrst round hard clustering following round soft clustering continuous strength values associated membership assignment. mixed membership stochastic blockmodels also assign continuous group membership values node topological information group assignments variational inference techniques generative model. finally long demonstrates node clustering performed instead using spectral clustering focuses particularly simultaneously cluster multiple types nodes group prediction algorithms assume links likely connect nodes belong group. exception anthony desjardins also uses generative model links attributes depend latent group memberships types links likely occur nodes belong group. instance note groups social network deﬁned gender link representing dating likely connect nodes diﬀerent groups. techniques described produce single clustering nodes usually based assigning every node single group. contrast multi-clustering emerging research area aims provide multiple orthogonal clusterings complex data instance individuals facebook might clustered multiple ways latent node types might represent friend groups work relations socioeconomic status locations family circles. type multi-clustering performed mccallum latent nodes created based roles topics. addition domingos propose statistical predicate invention node transformation approach based markov logic networks clusters nodes features links forming basis prediction predicates considers multiple relational clusterings based observation multiple distinct clusterings necessary instance group individuals based friendships work relationships. figure lifted graph representation initial graph clustered transformed lifted graph representation lifted graph representation created clustering nodes links both. demonstrate inference estimate clusters improves performance compared simpler baselines. similar node prediction approach applies mlns role labeling node deletion also useful cases. instance node deletion might beneﬁcial removing outdated spurious nodes graph. alternatively multiple nodes represent real-world object concept case deletion purposes entity resolution important finally node representation changes used improve accuracy also yield graphs processed eﬃciently desirable properties. section already discussed neville jensen used addition latent nodes enable simpler inference. another possibility creation super-nodes represent original nodes. instance figure demonstrates original nodes clustering collapsed three super-nodes yielding lifted graph representation. kind representation change used eﬃcient inference markov logic networks network anonymization node interpretation process constructing weights labels general features nodes. symmetric tasks link interpretation node weighting seeks assign continuous value node representing node’s importance node labeling seeks assign discrete value link representing type group class node. likewise node feature construction process systematically generating general-purpose node features based instance aggregation dimensionality reduction subgraph patterns. discussed section links node feature construction could viewed subsuming node weighting node labeling since general feature construction could always used construct feature values treated weights labels nodes. practice however techniques used tend rather diﬀerent. instance pagerank often used node weighting supervised classiﬁcation often used node labeling techniques rarely used general feature construction. nonetheless node interpretation substantial overlap techniques actually used weighting labeling used general feature construction. below ﬁrst discuss node weighting section labeling section section discusses node feature construction mentioning brieﬂy relevant techniques previously discussed weighting labeling. existing node representing importance inﬂuence node. node weighting techniques used information retrieval search engines social network analysis many domains discover important nodes respect deﬁned measure. node prediction classiﬁed based whether node attributes graph topology construct weighting. non-relational node weighting simplest node weighting techniques node features instance nodes representing documents might weighted based number query-relevant words contain nodes representing companies might ranked based gross annual sales. many sophisticated strategies also considered. instance latent semantic indexing used identify important semantic concepts corpus text nodes ranked based connection concepts. methods extensively applied quantify rank importance scientiﬁc publications however techniques extensively studied elsewhere also ignore graph structure discuss here. topology-based node weighting several node weighting algorithms topology graph developed support early search engines. examples kind algorithm include pagerank hits salsa algorithms rank relative importance sites conceptually based kind eigenvector analysis though practice iterative computation used. instance pagerank models markov chain implemented systematically computing principal eigenvector limk→∞ adjacency matrix unit vector. hits previously described instead computes principal eigenvectors algorithms continue important webpage ranking also applied many kinds graphs social network analysis objective topology-based node weighting typically identify inﬂuential signiﬁcant individuals social network. variety centrality measures devised local global network structure characterize importance individuals examples metrics include node degree clustering coeﬃcient betweenness closeness eigenvector centrality many others addition white smyth considered compute relative node rankings i.e. rankings relative particularly interesting nodes. show compute relative rankings metrics based shortest paths well markov chain-based techniques addition similarity metrics described table alternatively formulated computing weights nodes. recently node weighting techniques extended measure relative importance nodes temporally-varying data. instance kossinets tang deﬁne notions temporal distance based analysis frequently information exchanged nodes. information used deﬁne range graph metrics global temporal eﬃciency local temporal eﬃciency temporal clustering coeﬃcient recently tang deﬁne notions temporal betweenness temporal closeness. argue incorporating temporal information metrics provides better understanding dynamic processes network accurately identiﬁes important nodes metrics primarily concern networks time-varying interactions could also applied types data intermittent interactions nodes nodes/link join leave network time. metrics also apply links could possibly used improve link prediction algorithms. hybrid node weighting also hybrid node weighting approaches attributes graph topology instance various approaches modify hits pagerank construct node weights based content links. topic-sensitive pagerank seeks compute biased pagerank vectors using representative topics. alternatively kolda propose tophits hybrid approach adds anchor text adjacency matrix representation used hits. higher-order analogue known parallel factors decomposition identify topics graph well important nodes. hybrid approaches proposed simrank topical methods probabilistic hits many others section discusses relevant work context joint node link transformation techniques. recently node weighting approaches applied adversarial information retrieval detect moderate inﬂuence spam sites. typically techniques produce weights using topology graph information necessarily kind attribute information used techniques discussed above. instance trustrank based pagerank uses trusted sites evaluated humans propagate trust locally reachable sites. hand spamrank measures amount undeserved pagerank analyzing backlinks site. algorithms identify link farms link spam alliances given seed known link farm pages. among methods trustrank widely known suﬀers biases human-selected trustworthy sites favor certain communities others. many cases node labeling considered itself. instance running facebook example stated goal predict political aﬃliation node label already known. cases however node labeling properly understood representation change supports desired task. instance deﬁnitions anomalous link detection estimated node labels would allow identify links nodes whose labels indicate rarely ever connected. alternatively datasets estimating node labels enable subsequently partition data based node type enabling learn accurate models type node. even node labeling ﬁnal goal facebook example intermediate label estimation still useful representation change. particular cohen describe stacked model relational classiﬁcation relabels training estimated node labels using non-relational classiﬁer. estimated labels learn classiﬁer classiﬁer perform relational classiﬁcation test graph. approach yields high accuracy comparable much complex algorithms collective classiﬁcation fast jensen analyze result discuss explained natural bias algorithms training performed given node labels inference depends part estimated labels stacked models compensate bias instead training relabeled training set. addition inference classiﬁer needs single pass test graph yielding much faster inference techniques like gibbs sampling belief propagation. recently maes extend ideas node relabeling order generate larger training multiple simulated iterations classiﬁcation. show cases approach outperform stacked models algorithms like gibbs sampling. thus multiple reasons creating labels nodes graph. labeling accomplished relational-aware algorithms like described well earlier algorithms used relational collective classiﬁcation node labeling course also done traditional non-relational algorithms decision trees logistic regression naive bayes among various others methods simply features exploit topology link-structure. techniques assign labels supervised learning. labels also assigned unsupervised techniques textual analysis. many networks real-world contain textual content social networks email/communication networks citation networks many others. traditional textual analysis models plsa used assign node topic representing abstraction textual information. recent techniques link-lda link-plsa incorporate link structure traditional techniques order accurately discover node’s type. particular cohn hofmann demonstrate technique produce accurate node labels techniques node attributes link topology. also sophisticated topic models developed speciﬁc tasks social tagging temporal data node feature construction systematic construction features nodes typically purpose improving accuracy understandability algorithms. feature construction common relational representation change frequently done performing task classiﬁcation. instance performing classify nodes example facebook political aﬃliation task likely compute features representing information node known information node’s neighbors diﬀerent techniques node feature construction described many previous investigations though feature construction necessarily focus many investigations. section summarize explain diﬀerent aspects feature construction. particular section presents discusses taxonomy features based kinds inputs topology information link feature values computing feature values. next section describes possible operators aggregation discretization applied inputs. finally section examines perform automatic feature search selection support desired computational task. relational feature inputs node feature categorized according types information uses computing feature values. possible information includes nodes links node figure node features taxonomy based inputs used classes node features nonrelational features topology features relational link-value features relational node-value features. classes deﬁned respect relational information used construction features double-lined target node represents feature value computed. parts show single feature value link node simplicity general feature exist used. features link features figure shows taxonomy node features based sources information use. taxonomy consistent distinctions previously made literature best knowledge complete taxonomy never previously described. taxonomy consists four basic types non-relational features three types relational features describe give examples each. value feature particular node computed using non-relational features node ignoring link-based information. instance figure shows node corresponding node’s feature vector. feature value might constructed vector using kind dimensionality reduction adding together several feature values thresholding particular value etc. feature computed using nodes links ignoring existing node link feature values. instance figure feature value computed node bottom left ﬁgure using topological information shown. particular feature value might count number adjacent nodes count many shortest paths graph pass target node. feature values links adjacent target node used computing feature. typically kind aggregation operator applied values count mode average proportion etc. instance figure values links shown represent communication topics link-value feature might compute mode values usually computation include links directly connected target node links hops away could also used. feature values nodes linked target node used construction. links used identifying nodes although nodes away target node also included. instance figure shows feature values adjacent nodes could instance used compute node-value feature based mode values. alternatively feature might count number adjacent nodes another might count number adjacent nodes. feature computation also applied recursively. instance refex system ﬁrst computes features every node based degree considers recursive combinations features henderson show recursive features often improve classiﬁcation accuracy datasets network structure predictive. alternatively topology-based feature betweenness might computed relational node-value feature might compute average betweenness nodes neighbors target label example hybrid feature uses node-value topology-based information. feature value recomputation. particular many techniques collective classiﬁcation involve computing node feature feature depends feature values estimated thus change addition mcdowell describe features similar need recomputation meta-features depend upon estimated label probabilities node neighborhood target node. contrast kind feature re-computation much less applicability non-relational data nodes assumed independent other. however occur techniques semi-supervised learning co-learning. relational feature operators previous section described features according diﬀerent kinds inputs feature value computation whereas section describes diﬀerent operators used computation. table summarizes operators. cases operator used many diﬀerent types relational input. instance aggregation operators computed using graph topology relational node-value inputs and/or relational linkvalue inputs indicated appropriate checkmarks table contrast path walk-based operators generally graph topology; operators lighter colored checkmarks table indicate path/walk-based operators could sensibly used conjunction relational link-value node-values inputs rarely ever done. discuss operators table detail. relational aggregates aggregation refers function returns single value collection input values list. classical statistical aggregation operators average mode exists count another frequent operator proportion computes table relational feature operators summary popular types relational feature operators. check used indicate classes inputs operator naturally uses constructing feature values lighter check indicates operator could sensibly used input combination rarely ever used. instance fraction node’s neighbors meet criteria label operators also combined thresholds e.g. evaluate whether count node’s neighbors labeled least thresholding turns numerical aggregate boolean feature needed tree-based algorithms perlich provost describe complex relational aggregates depend distribution attribute values associated node instance aggregates function edit distance compare node’s distribution reference distribution computed training data. perlich provost demonstrate aggregations cases improve performance compared simpler alternatives. also aggregate operators topology-based information. instance operator degree simply counts number adjacent links predictive feature applied carefully relational data avoid bias temporal aggregates relational information might also contain temporal information form timestamps durations links node features. general data handled deﬁning special temporal-aggregation features computed data deﬁning graph summarizes temporal information rossi neville discuss example latter approach explore impact using various temporal-relational information various kernels summarization. operators traditional domain-independent operators union intersection diﬀerence applied construct features instance attributes represent presence word page feature might represent case page contains words relational data complex set-based features possible. instance feature collective classiﬁcation might represent union class labels nodes adjacent target node. neville propose complex approach feature value multiset represents complete distribution adjacent nodes’ labels showed that multiset approach usually outperformed types features proportion count-based aggregates discussed above. relational markov networks clique potentials probabilistic models perform inference related nodes without computing aggregates. instead clique-speciﬁc potential functions represent probabilistic dependencies product term probability computation naturally expands accommodate varying number neighbors node. sense featureless approach since need choose relational aggregation function. however diﬀerent kinds dependencies still represented diﬀerent cliques. instance taskar consider diﬀerent sets cliques webpage classiﬁcation based hyperlinks including information based links appear within page. likewise later work added additional types cliques enable link prediction thus even models remain important feature choices made. probabilistic models also link-based information without computing explicit features random walk-based classiﬁer cohen weighted-neighbor approach macskassy provost even cases however choices remain types links use. instance webpage graphs co-citation links predictive class labels direct links subgraph patterns subgraph pattern feature based existence particular pattern graph adjacent target node. feature might count many times particular pattern exists target node produce value true least pattern exists. simplest pattern called reciprocity; true target node links node links back cases however patterns complex involve nodes. robins deﬁne many patterns including two-star three-star triangle subgraph patterns probabilistically modeling graphs. argue using complex patterns alternating k-triangle help avoid degeneracy might otherwise arise graph generation. furthermore subgraph patterns also extended exploit labels links and/or nodes. instance assume links labeled links labeled plus minus sign figure demonstrates three possible subgraph patterns based diﬀerent link labelings relative target node shown bottom left subgraph. subgraph feature could compute node number matches patterns feature could used later analysis. information original data captured according criterion. many dimensionality reduction methods principal component analysis principal factor analysis independent component analysis dimensionality reduction techniques applied adjacency matrix graph create low-dimensionality graph representation; section explained used link prediction. techniques also useful feature computation. instance bilgic investigate active learning improve accuracy collective classiﬁcation. technique involves non-relational relational features demonstrate ﬁrst applying dimensionality reduction non-relational features simpliﬁes learning leading substantial gains accuracy. operators mention brieﬂy operators already discussed extensively elsewhere. path-based measures walkbased measures discussed sections types measures used features classiﬁer predict links well validating relational sampling techniques measures typically topology could easily imagine computing metrics based instance paths edge particular label type. textual analysis techniques discussed sections relational clustering techniques discussed section operators used speciﬁcally node/link prediction weighting labeling also used general feature construction. finally operators based similarity measures. similarity nodes often computed instance link prediction weighting computations easily lead feature value link since link obviously refers endpoint nodes compared. however computing node feature value usually obvious node comparison similarity measures typically used node feature values. measures however used node prediction section discusses cases newly discovered nodes/groups used create node features. particular instance relational similarity functions graph kernels structured data also used. kernels used either nodes single graph compute similarity graphs instance former type kernel another technique could also used link group prediction. discussion many feature operators discussed naturally used compute feature values links additions nodes. instance textual analysis applied links text associated link node-centered path-based measures analogous formulations links. diﬀerence nodes naturally link many nodes whereas assume links endpoints. thus relational aggregates count initially seem useful computing link features. however figure previously demonstrated link-aggregation accomplished broadening computation include multiple links nodes logically connected endpoint node target link. naturally feature inputs operators better suited computing node features computing link features. next section examines select appropriate features given task. given large number possible features could used task features actually used learn model? cases selection done manually based prior experience trial error. many situations though automatic feature selection desirable. non-relational data widely studied topic machine learning selecting relational features received considerably less attention. given large number possible features eﬃcient strategies searching evaluating possible features needed. section ﬁrst summarize problems feature search feature evaluation give examples issues resolved actual systems. search ﬁrst step searching relational features deﬁne possible relational feature space specifying possible feature inputs operators consider. possible operators include domain-independent operators and/or problem-speciﬁc operators domain-independent operators obviously general easier apply problem-speciﬁc operators reduce number possibilities must considered require eﬀort expert knowledge. however approaches vulnerable selection biases second step pick appropriate search strategy usually either exhaustive random guided. exhaustive strategy consider features possible given speciﬁed inputs operators random strategy consider fraction space. guided strategy heuristic sub-system identify features considered. three cases feature considered subjected evaluation strategy assesses usefulness; strategies described next. evaluation selection feature considered must evaluated determine retained ﬁnal model. instance candidate feature evaluated adding current classiﬁcation model; improves accuracy holdout immediately added retained features cases every candidate feature assigned score best scoring feature retained features added model based decreasing score long features continue improve model simpler techniques require evaluating overall model also used. instances metrics correlation mutual information used estimate useful feature desired task. metrics strategies could used include akaike’s information criterion mallows bayesian information criterion many others frequently possible feature particular parameter whose value must selecting best value given feature evaluation metrics simpler estimation technique e.g. based maximum likelihood. table systems searching selecting node features summary systems used automatically search select appropriate features given task. note that depending context papers describe function terms learning best rules system learning structure mln-based systems described; these wpll weighted pseudo log-likelihood. examples table summarizes strategies used number systems automatically search features. columns table describe system searches features features evaluated. instance relational probability trees extension probability estimation trees relational data exhaustive search strategy feature selection. particular learning involves automatically searching space possible features using aggregation functions mode average count proportion exists degree. aggregations involve node link feature values topology information features used classiﬁcation tasks predicting class label document. feature evaluated based using chi-square statistic measure correlation feature class label; yields feature score associated p-value. features pvalues level statistical signiﬁcance discarded remaining feature highest score chosen inclusion model. selection process also extended randomization tests adjust biases common relational data rpts also extended temporal domains rpts represent conditional probability distributions using single tree. contrast natarajan propose using gradient boosting conditional probability distribution represented weighted regression trees grown stage-wise optimization. features tree selected depth-limited exhaustive search though note domain knowledge could also used guide search. natarajan argue resultant multiple relatively shallow trees allows eﬃcient learning another system uses exhaustive search refex uses aggregates mean operators recursively generate features based degree node local neighborhood. prune resultant large refex uses logarithmic binning feature values clusters features based similarity binned space retains feature cluster. logarithmic binning chosen favors features discriminative high-degree nodes. recursive approach also modiﬁed constructing features dynamic networks alternatively spatiotemporal rpts random search strategy. particular rpts temporal spatial-based features possible features. resultant feature space large exhaustive search instead random sampling used. pre-deﬁned number features considered best scored feature added model. remaining systems discuss guided search strategy heuristic sub-system provides candidate features considered. instance several systems system generate candidate features evaluate features select ultimate use. particular sayu uses system aleph generate candidate feature aleph creates candidates features based positive examples training data concept predicted. proposed feature evaluated learning model includes feature computing area precision-recall curve feature improves auc-pr score permanently added model feature search continues. sayu-vista retains general approach extends types features considered particular adding ability dynamically link together objects diﬀerent types recursively build features constructed features. davis demonstrate link connections especially helpful improving performance compared original sayu system. landwehr describe nfoil system similar sayu developed independently raedt thon describe probfoil upgrades deterministic rule learner like foil probabilistic. landwehr describes related kfoil system integrates foil kernel methods. also consider impact several diﬀerent feature scoring functions. number systems considered perform structure learning probabilistic relational models markov logic networks general case feature selection problems described above. instance weighted ﬁrst-order formulas; structure learning corresponds learning formulas weight learning corresponds learning associated weights. ﬁrst structure learning approaches systematically construct candidate clauses starting empty clause greedily adding literals testing resulting clauses training data using statistical measure however top-down approaches ineﬃcient initial proposal clauses ignores training data resulting large number possible features considered possible problems local minima. response number bottom-up approaches proposed. particular mihalkova mooney uses propositional markov network structure learner construct template networks guide construction features based training data. recent work examined enable bottom-up approaches learn longer clauses based constraining search consider features consistent certain patterns motifs clustering input nodes create lifted graph representation enabling feature search smaller graph khosravi perform structure learning ﬁrst learning structure simpler parametrized bayes converting result mln. data contains signiﬁcant number descriptive attributes show approach dramatically improves runtime structure learning also improves predictive accuracy. schulte given theoretical justiﬁcation approach. another alternative proposed khot extend previously mentioned work natarajan gradient boosting mlns. essentially problem learning mlns transformed series relational regression problems functional gradients represented clauses trees. several datasets demonstrate faster structure learning accurate better baselines including algorithms mihalkova mooney domingos techniques mlns seek learn network structure best explains training data whole. contrast situations prediction speciﬁc predicate desired huynh mooney biba propose discriminative approaches structure learning. instance huynh mooney modiﬁed version aleph compute large number candidate clauses form l-regularization force weights subsequently learned clauses zero clause helpful predicting predicate. regularization conjunction appropriate optimization function eﬀectively leads selecting smaller features useful desired task. discussion focus article graph-based data representations however many examples discussed logical representation instead. include section techniques used constructing searching features rules similar settings. instance rpts rdn-boosting exhaustive search probabilistic decision trees diﬀerent feature scoring strategies. popescul examine automatically learn relational features links techniques could also applied constructing node features. particular treat feature relational database query concept reﬁnement graphs consider reﬁning initial query equijoins equality selections statistical aggregates. reﬁnement reﬁnements considered; search guided sampling possible reﬁnements proceeding results particular reﬁnement type seems promising. features chosen combined logistic regression classiﬁer. evaluation speciﬁc features bayesian information criterion includes term penalizes feature complexity reduce danger overﬁtting. discussed multiple systems include notions aggregation including rpts sayuvista work popescul discussed above. also aggregatebased learning approaches crossmine clamf multi-relational decision trees conﬁdence-based concept discovery many others also possibilities feature evaluation. instance gleanersrl uses aleph search previous sections primarily discussed relational representation transformation techniques applied independently another. instance technique might used predict links another builds transformed representation applying node labeling technique. section instead examines joint transformation tasks combine node link transformation instance label nodes weight links table summary joint transformation models middle section table indicates types graph features used inputs model right side table indicates types link node transformation performed model. lighter checkmarks indicate output model transformed perform particular transformation task task primary goal speciﬁed model. simultaneously. techniques enable subtask inﬂuence helpful ways avoids bias might introduced requiring serialization tasks might usefully performed jointly. recent approach proposed namata collectively performs link prediction node labeling entity resolution present iterative algorithm solves three tasks simultaneously propagating information among solutions three tasks. particular introduce notion inter-relational features relational features task depend upon predicted values another. results show using features improve accuracy inferring predicted values three tasks simultaneously signiﬁcantly improve accuracy compared performing three tasks sequence even possible orderings considered. techniques model full distribution across links attributes rmns prms mlns also used scenario instance jointly predict node link labels. section however focus particularly recent techniques presume existence textual content associated nodes links graph consider three types techniques based kind input text stand-alone text documents text documents connected links entities connected links associated text table lists prominent models grouped according three types. columns table indicate kinds input models types transformation perform text documents corresponds node features table text associated links yields link features. discuss three types techniques detail. using text documents links first many techniques used assign topics labels nodes nodes associated text. instance ﬁrst table indicates plsa nodes node features perform node prediction weighting labeling. section already mentioned techniques used label node discovered topics typical use. however techniques also perform node weighting and/or node prediction table lighter checkmarks represent kind situations transformation task could performed particular model primary use/output. plsa treat document words seek assign topics document based words. contrast nubbi designs approach based graph deﬁned based objects referenced documents links predicted based relationships implied text documents. addition nodes links associated likely topic based relationships. thus model simultaneously performs link prediction link labeling node labeling. similar result produced semantic network extraction domingos discussed section using text documents links second type joint transformation also uses text documents adds known links documents model. instance section discussed link-lda link-plsa link modeling plsa order perform node labeling; discussed plsa modiﬁed also achieve node prediction weighting. shown table link-lda link-plsa also used link prediction weighting learning model training graph using predict unseen links test graph link-lda link-plsa model links similar model presence words document instance link lda’s generative model generate word document chooses topic chooses word topic-speciﬁc multinomial. identical process used generate particular document target document link thus link-lda link-plsa directly extend original plsa models links. nallapati argue link-lda’s link-plsa’s extensions links pragmatic adequately capture topical relationship documents linked together. instead propose alternatives. ﬁrst pairwise link-lda replaces link model link-lda model based mixed membership stochastic blockmodels possible link modeled bernoulli variable conditioned topic chosen based topic distributions endpoints link. second approach link-plsa-lda retains link generation model link-lda changes word generation model documents words document depend topics documents link downside latter approach works nodes divided outgoing links incoming links. however nallapati argue limitation largely overcome duplicating nodes incoming outgoing links. moreover approach much faster scalable pairwise link-lda. nallapati demonstrate models outperform link-lda likelihood ranking task link-plsa-lda also outperforms link-lda link prediction task. also show link-plsa-lda link-lda comparable terms execution time pairwise link-lda much slower. changes generative model used approaches encode diﬀerent assumptions data lead signiﬁcant performance diﬀerences. instance chang blei introduce relational topic model compare pairwise link-lda model discussed above. models allow similar ﬂexibility terms links deﬁned chang blei argue model forces topic assignments used generate words documents also generate links true pairwise linklda. demonstrate provides accurate predictions link suggestions pairwise link-lda several baselines. another possible change model types objects. instance topic-link models documents links likely topics associated document also explicitly considers author document clusters authors multiple communities. creating clustering equivalent ﬁnding per-document topics author associated document. argue approach analogous unifying separate tasks assigning topics documents analyzing social network authors. show approach cases outperform link-lda. using text associated links ﬁnal type joint transformation techniques form link features based text associated links text email messages scientiﬁc abstracts relate particular protein-protein interaction several techniques discussed previously context link interpretation. instance section discussed models author-recipienttopic model group-topic model extend perform link labeling; strength predicted labels also used weight links. addition model directly assigns nodes groups labels associates link could also used label associated nodes. rart model extends allowing node multiple roles. recently block-lda merges ideas latent variables models stochastic blockmodels. speciﬁcally block-lda shares information three components link model shares information block structure shared topic model. unlike however blocklda focuses labeling nodes rather links. balasubramanyan cohen evaluate block-lda protein dataset enron email corpus demonstrate outperforms link-lda several baselines task protein functional category prediction. discussion techniques discussed variants latent group models focus node and/or link label prediction also used node prediction nodes represent newly discovered topics latent groups. models also extended incorporate notions time topic hierarchies correlations topics addition links usually assumed generated based overall topic node link. contrast latent topic hypertext model models link originating speciﬁc word document. somewhat surprisingly show approach leads model fewer parameters models like linklda demonstrate approach outperforms link-lda link-plsa evaluated link prediction task. nodes added graph represent discovered topics links invariably added connect existing nodes nodes. however models also learn information discovered topics related other. instance figure figure example joint transformation example adapted results nallapati latent nodes added represent discovered topics weighted links added original node latent node. addition weighted links added latent nodes representing connection strength topics. finally links original nodes also predicted. shows topics discovered graph connected existing nodes. addition topics connected links weight link represents frequently document topic cites document representing diﬀerent topic. adding additional links graph lets original nodes connected closely primary topics also related topics. goal representation transformation often improve data representation leads better results subsequent task possibly understandable representation. evaluate whether particular transformation technique accomplished goal? ﬁrst address question consider ﬁnal goal used directly guide initial transformation. tasks representation evaluation straightforward provided ground truth values known hold-out data set. instance test technique link prediction eﬀective accuracy measured links predicted hold-out particular evaluation metric modiﬁed appropriate domain. instance chang blei evaluate precision twenty highest-ranked links suggested document nallapati consider custom metric called measures rank last true link suggested model. likewise desired task involves classiﬁcation classiﬁcation algorithm hold-out data without representation change change increases classiﬁcation accuracy. cases diﬃcult directly measure well representation change performed classiﬁcation used surrogate measure accuracy increases change assumed beneﬁcial. instance classiﬁcation used evaluate link prediction link weighting link labeling node prediction addition node techniques used direct evaluation feasible exists metric believed related. instance higher autocorrelation graph associated presence sensible links algorithms collective classiﬁcation typically perform better level autocorrelation higher. thus xiang demonstrate success technique estimating relationship strengths based part showing increase autocorrelation measured several attributes social network. likewise increased information gain attributes could used demonstrate improved representation link perplexity could used assess topic labelings naturally appropriate evaluation techniques vary based upon task comparison transformation techniques yield diﬀerent results depending upon metric chosen. ideally representation transformation would guided directly ﬁnal goal executed rather evaluated transformation complete. often case feature selection structure learning algorithms discussed section task accuracy evaluated particular feature added retained accuracy improved. cases transformation even directly speciﬁed desired goal. instance supervised random walk approach discussed section uses gradient descent method obtain link weights links predicted subsequent random walk accurate. likewise menon elkan show supervision methods generating latent features features learned would relevant ﬁnal classiﬁcation task. show however adding supervision always helpful. ﬁnal example quadratic program optimize linear combination link weights ﬁnal link weights lead directly accurate classiﬁcation label propagation algorithm. general ensuring particular transformation improve performance ﬁnal task remains challenging. many transformations cannot directly guided ﬁnal goal either suitable supervised data available clear modify transformation algorithms information causal discovery refers identifying cause-and-eﬀect relationships either online experimentation observational data. challenge distinguish true causal relationships mere statistical correlations. approach quasi-experimental designs take advantage circumstances non-experimental data identify situations provide equivalent experimental control randomization. jensen propose system discover knowledge applying qeds discovered automatically. recently oktay applies three diﬀerent qeds demonstrate gain causal understanding social media system. also another causal discovery technique linear models proposed wang chan challenge remains extend techniques apply broader range relational data. majority article focused transformation tasks centered around nodes links graphs. however also useful tasks subgraph transformation seek identify frequent/informative substructures graphs create features classify subgraphs instance kong consider semi-supervised techniques perform feature selection subgraph classiﬁcation given labeled subgraphs. nodes links subgraphs tasks prediction labeling weighting feature generation described. many techniques described node-centered features also used context full discussion subgraph transformation beyond scope article. recently graph generation algorithms attracted signiﬁcant interest. algorithms model represent family graphs present generate multiple samples family. prominent models kronecker product graph models based preferential attachment graph generation methods take advantage global local graph properties generate distribution graphs potentially include attributes. sampling models useful creating robust algorithms instance training classiﬁer family related graphs instead single graph. newman surveys additional network models properties relevant graph generation. also notion model representation kind statistical model learned represent relationship nodes links features? prominent models probabilistic relational models relational markov networks relational dependency networks structural logistic regression conditional random fields markov logic networks full discussion models beyond scope article. many cases techniques relational representation transformation link prediction performed regardless kind statistical model subsequently used. however choice statistical model strongly interact kinds node link features useful section describes connections. number relevant comparisons already published work needed evaluate interaction choice statistical model feature selection evaluate statistical models work best domains certain characteristics. appropriate already discussed multiple techniques incorporate temporal information graph data techniques focused solving particular problems node classiﬁcation dealing data invariably requires studying represent time-varying elements. however work needed examine general tradeoﬀs involved diﬀerent temporal representations. instance hill provide generic framework modeling temporal dynamic network central goal build approximate representation satisﬁes pre-speciﬁed objectives. focus summarization simpliﬁcation eﬃciency predictive performance work provides number useful building blocks comparisons needed instance evaluate merits using summarized networks general-purpose algorithms using specialized algorithms data maintains temporal distinctions. temporal data particular kind data represented relational sequence. kersting surveys area relational sequence learning explains multiple tasks related data sequence mining alignment. tasks often involve need identify relevant features structure identifying frequent patterns useful similarity functions. thus useful techniques feature construction search domain overlap discussed section sometimes desire make private graph-based data publicly available preserves privacy individuals described data. goal privacy preserving representation transform data minimizes information loss maximizing anonymization e.g. prevent individuals anonymized network identiﬁed. naive approaches anonymization operate simply replacing individual’s name arbitrary meaningless unique identiﬁers. however social networks many adversarial methods true identity user often discovered anonymized network. particular adversarial methods network structure and/or remaining attributes discover identities users within network early approach zheleva getoor examines graph modiﬁed prevent sensitive relationships disclosed. describe approach terms node anonymization edge anonymization. node anonymization clusters nodes equivalence classes based node attributes only edge anonymization approaches based cleverly removing sensitive edges. backstrom address related family attacks adversary able learn whether edge exists targeted pairs nodes. recently study privacy issues graphs contain attributes. goal prevent structural re-identiﬁcation anonymizing graph creating aggregate network model allows samples drawn model. approach generalizes graph partitioning nodes summarizing graph partition level. approach diﬀers approaches described drastically changes representation opposed making incremental changes. however method enforces privacy still preserving enough network properties allow wide variety network analyses performed. investigations factors information available graph resources attacker type attacks must defended against. addition attacker possibly obtain additional information related graph sources challenges even diﬃcult. work needed provide strong privacy guarantees still enabling partial public release graph-based information. given increasing prevalence importance relational data article surveyed signiﬁcant issues relational representation transformation. presenting taxonomy representation transformation tasks section next discussed four primary tasks link prediction link interpretation node prediction node interpretation. section considered tasks accomplished simultaneously techniques joint transformation. finally section considered perform representation evaluation challenges future work. also suggests areas techniques developed entities used analogous task other. instance liben-nowell kleinberg reformulated traditional node weighting algorithms weight links. likewise topic discovery techniques based used node labeling link labeling. finally many techniques used create node features also used create link features vice versa although node features studied much thoroughly. discussed section remains much work instance link prediction remains diﬃcult problem especially general case arbitrary nodes might connected together. even signiﬁcantly described wide range techniques address transformation tasks practitioner left wide range choices without many guarantees might work best. instance node weighting improve classiﬁcation accuracy dataset decrease another. challenge made diﬃcult techniques described come wide range areas including graph theory social network analysis matrix factorization metric learning information theory information retrieval inductive logic programming statistical relational learning probabilistic graphical models. breadth techniques relevant relational transformation wonderful resource also means evaluating representation change techniques relevant particular task time-consuming technically challenging incomplete process. therefore much work needed establish theoretical understanding diﬀerent representation changes aﬀect data diﬀerent data characteristics interact process combination techniques data characteristics aﬀect ﬁnal results analysis relational data.", "year": 2012}