{"title": "Study on Feature Subspace of Archetypal Emotions for Speech Emotion  Recognition", "tag": ["cs.LG", "cs.AI"], "abstract": "Feature subspace selection is an important part in speech emotion recognition. Most of the studies are devoted to finding a feature subspace for representing all emotions. However, some studies have indicated that the features associated with different emotions are not exactly the same. Hence, traditional methods may fail to distinguish some of the emotions with just one global feature subspace. In this work, we propose a new divide and conquer idea to solve the problem. First, the feature subspaces are constructed for all the combinations of every two different emotions (emotion-pair). Bi-classifiers are then trained on these feature subspaces respectively. The final emotion recognition result is derived by the voting and competition method. Experimental results demonstrate that the proposed method can get better results than the traditional multi-classification method.", "text": "feature subspace selection important part speech emotion recognition. studies devoted ﬁnding feature subspace representing emotions. however studies indicated features associated different emotions exactly same. hence traditional methods fail distinguish emotions global feature subspace. work propose divide conquer idea solve problem. first feature subspaces constructed combinations every different emotions bi-classiﬁers trained feature subspaces respectively. ﬁnal emotion recognition result derived voting competition method. experimental results demonstrate proposed method better results traditional multi-classiﬁcation method. emotion recognition plays important role many applications especially human-computer interaction systems increasingly common today. main communication media human beings voice received widespread attention researchers speech contains wealth emotional information extract information original speech signal great importance speech emotion recognition. important part speech emotion recognition selection feature subspace attracted research interests. existing researches feature subspace selection divided three categories including artiﬁcial selection emotion related features automatic feature selection algorithms select feature subset large numerous feature candidates transformation method original feature space favor emotion recognition. researches devoted ﬁnding common global feature subspace represent kinds emotions. however studies already indicated features associated different emotions exactly same. words divide whole emotions space several subspaces features distinguishable subspace separately emotion recognition performance whole space might boosted. motivated this propose divide conquer idea emotion recognition leveraging feature subspaces. feature subspaces ﬁrst constructed every different emotions bi-classiﬁer used distinguish emotions emotion-pair feature subspace; ﬁnal emotion recognition result derived voting competition method. reset paper organized follows. section summarizes previous related work feature selection. proposed method detailed section experiments results presented section section concludes paper. common issue many classiﬁcation problems feature selection aims pick subset features relevant target concept reduce dimension features reducing computational time well improving performance many studies feature selection speech emotion recognition. prosody-based acoustic features including pitchrelated energy-related timing features widely used recognizing speech emotion. spectral-based acoustic features also play important role emotion recognition linear predictor coefﬁcients linear predictor cepstral coefﬁcients mel-frequency cepstral coefﬁcients voice quality features also shown related emotions. besides manual selection also many automatic feature selection algorithms proposed. example sequential floating forward selection iterative method subset features near optimal one. evolutionary algorithms genetic algorithm often used feature selection. feature space transformation another type method including principal component analysis neural network dominance model besides discrete emotional labels so-called archetypal emotions common used speech emotion recognition. different archetypal emotions located different locations dimensional space. proposed hierarchical approach classify speech emotions dimensional model. however selection emotions different stages subjective used feature sets good match psychological emotional model. study based archetypal emotions. emotionpair composed different kinds archetypal emotion like anger happiness. possible combinations archetypal emotion-pairs bi-classiﬁcation voting method used distinguish every emotion-pairs derive ﬁnal emotion recognition result shown figure whole method involves four steps feature extraction feature subspace selection emotion classiﬁcation voting decision. used acoustic features include following low-level descriptors intensity loudness mfcc pitch probability voicing envelope zero-crossing rate. delta regression coefﬁcients computed llds following statistical functionals applied llds delta coefﬁcients max./min. value respective relative position within input range arithmetic mean linear regression coefﬁcients linear quadratic error standard deviation skewness kurtosis quartile inter-quartile ranges. features utterance-level features. feature selection stage relevant feature subset relevant feature space derived large feature set. different traditional methods distinguish emotions global feature subspace work selects different feature subspaces different combination emotion-pairs. speciﬁc emotion-pair corresponding feature subspace best power distinguishing emotions pair. order verify generality idea methods feature subset selection feature space transformation considered. genetic algorithm used feature subset selection neural network used feature space transformation. kind stochastic searching optimizing algorithm simulates natural evolution process. ﬁxed number features form vector ﬁxed number individuals form ﬁrst population. crossover mutation operation used generate individual. population selected comparing ﬁtness. wrapper method used calculate ﬁtness individuals i.e. accuracy classiﬁer used ﬁtness. procedures repeated average ﬁtness population reaches threshold evolutionary generation reaches threshold. compared heuristic searching algorithm sequential floating forward selection ﬂexible control computing time especially feature relatively large. using feature subspace obtained previous step particular classiﬁer trained speciﬁc emotion-pair designated distinguish emotions emotionpair. classiﬁer related speciﬁc emotionpair call bi-classiﬁer. feature subset selection basic classiﬁcation algorithms used including logistic regression support vector machine feature space transformation neural network used classiﬁer. getting emotion distinguishing result emotion-pair previous emotion classiﬁcation step voting competition method ﬁnally used integrate emotion classiﬁcation results emotion-pairs derive ﬁnal emotion recognition result. voting decision process summarized algorithm proved ﬁnal emotion recognition result correctly derived voting decision algorithm given bi-classiﬁers give correct distinguishing result emotion-pair. theorem proof procedure described theorem feature space associated emotion-pairs better feature space associated emotions using feature space transformation method. experimental settings neural network -unit input layer corresponding dimensionality original feature vector -unit hidden layer corresponding dimensionality feature subset feature selection method. batch gradient descend method used learn weights activation function sigmoid function. learning rate ﬁrst conduct feature selection experiment comparing similarity degree feature subspace emotion-pair global feature subspace emotions. figure depicts number common features shared feature subspace speciﬁc emotion-pair global feature subspace emotions horizontal axis represents different emotion-pairs noted feature subspaces contain selected features described section ﬁgure seen number common features emotion-pair emotions indicates feature subspace emotion-pair quite different global feature space emotions. conﬁrms necessity perform pair-wised emotion classiﬁcation feature subspace related emotion-pairs. study used well known berlin emotional database actors simulated emotions producing german sentences emodb comprises utterances cover archetypal emotions neutral emotion everyday communication namely anger fear happiness sadness disgust boredom neutral. work focuses speaker independent emotion recognition hence samples actors used training samples actors used test set. -fold-cross-validation method used conduct experiments. opensmile toolkit used extract acoustic features total features obtained. experiment conducted. ﬁrst used select feature subset emotion-pair. emotion classiﬁcation emotion classiﬁer used emotion-pairs trained different features subsets associated different emotion-pairs. furthermore classiﬁer also used recognize emotions feature subsets associated emotions. experiment verify selecting feature subset associated emotion-pairs better feature subset associated emotions using classiﬁer. details parameter setting follows individual size population size two-point crossover crossover probability substitution mutation mutation probability generation number reaches ﬁtness value improve last generation algorithm stops. experiment representative features selected algorithm form feature subset every emotion-pair also emotions. furthermore different classiﬁers tested. method bi-classiﬁcation voting also effective feature space transformation. conﬁrms generality proposed method. details experiment please refer code document github. paper present bi-classiﬁcation voting method distinguishing different emotion-pairs different feature space. experimental results proved method better result compared traditional multi-classiﬁcation method. addition method kind divide conquer algorithm converts complex multi-classiﬁcation problem many simple bi-classiﬁcation problems. idea makes possible boost multi-class emotion recognition performance optimizing emotion classiﬁcation performance emotion-pair. hence future work devoted classiﬁer optimization different emotion-pairs. traditional method. experimental results shown table bi-classiﬁcation voting proposed method multi-classiﬁcation traditional method using global feature subspace emotions. seen recognition accuracy obtained bi-classiﬁcation voting signiﬁcantly higher using multiclassiﬁcation method emotion recognition accuracy different emotions computed shown figure bi-clf voting represents bi-classiﬁcation voting multi-clf represents multi-classiﬁcation. noted result disgust depicted quite utterances disgust emotion. experimental results indicate biclassiﬁcation voting method achieve better performance multi-classiﬁcation method emotions using classiﬁers result proves priori information emotion-pair helpful feature selection bring performance improvements emotion recognition. similarly also conduct experiments feature space transformation scenario validate efﬁciency proposed divide conquer idea emotion recognition. emotion recognition accuracy using different classiﬁcation criterions withe feature space transformation shown table recognition different emotions showed figure work supported national high technology research development program china national natural science foundation china joint fund nsfcrgc major program national social science foundation china lugger yang psychological motivated multistage emotion classiﬁcation exploiting voice quality features speech recognition france mihelic janez zibert intech recent developments opensmile munich open-source multimedia feature extractor proceedings international conference multimedia. york isbn ---- doi./.. j.p. hespanha p.n. belhumeur d.j. kriegman eigenfaces ﬁsherfaces recognition using class speciﬁc linear projection ieee transactions pattern analysis machine intelligence vol. kortelainen vayrynen seppanen classiﬁer-based learning nonlinear feature manifold visualization emotional speech prosody ieee transactions affective computing vol. b.s. atal effectiveness linear prediction characteristics speech wave automatic speaker identiﬁcation veriﬁcation journal acoustical society america vol. davis mermelstein effectiveness linear prediction characteristics speech wave automatic speaker identiﬁcation veriﬁcation comparison parametric representations monosyllabic word recognition continuously spoken sentences ieee transactions acoustics speech signal processing vol. ververidis kotropoulos fast accurate sequential ﬂoating forward feature selection bayes classiﬁer applied speech emotion recognition signal processing vol.", "year": 2016}