{"title": "A Multi-layered Acoustic Tokenizing Deep Neural Network (MAT-DNN) for  Unsupervised Discovery of Linguistic Units and Generation of High Quality  Features", "tag": ["cs.CL", "cs.LG", "cs.NE"], "abstract": "This paper summarizes the work done by the authors for the Zero Resource Speech Challenge organized in the technical program of Interspeech 2015. The goal of the challenge is to discover linguistic units directly from unlabeled speech data. The Multi-layered Acoustic Tokenizer (MAT) proposed in this work automatically discovers multiple sets of acoustic tokens from the given corpus. Each acoustic token set is specified by a set of hyperparameters that describe the model configuration. These sets of acoustic tokens carry different characteristics of the given corpus and the language behind thus can be mutually reinforced. The multiple sets of token labels are then used as the targets of a Multi-target DNN (MDNN) trained on low-level acoustic features. Bottleneck features extracted from the MDNN are used as feedback for the MAT and the MDNN itself. We call this iterative system the Multi-layered Acoustic Tokenizing Deep Neural Network (MAT-DNN) which generates high quality features for track 1 of the challenge and acoustic tokens for track 2 of the challenge.", "text": "overview proposed framework framework approach shown fig. left part multi-layered acoustic tokenizer produces many sets acoustic tokens using unsupervised hmms describing different aspects given corpus. tokens speciﬁed hyperparameters describing conﬁgurations. acoustic tokens obtained conﬁguration iteratively optimizing token models token labels given acoustic corpus. multiple pairs hyperparameters selected producing multi-layered token labels given corpus used training targets multi-target deep neural network right part fig.. mdnn right learns parameters based multi-layered token labels given corpus targets left knowledge carried different token sets different layers fused. bottleneck features extracted mdnn. ﬁrst iteration initial acoustic features used mdnn. gives ﬁrst bottleneck features. bottleneck features used feedback mdnn second iteration. feedback continued iteratively. complete framework referred multi-layered acoustic tokenizing deep neural network paper. output mdnn evaluated track challenge time intervals acoustic token labels output evaluated track challenge. multi-layered acoustic tokenizer goal step obtain multiple sets acoustic tokens deﬁned hyperparameters capture complementary aspects corpus. knowledge regarding corpus process completely unsupervised. unsupervised token discovery layer using unsupervised hmms straight forward discover acoustic tokens corpus chosen hyperparameter pair determines conﬁguration achieved ﬁrst ﬁnding initial label based assumed tokens features corpus iteration parameters trained label obtained previous iteration label obtained token decoding obtained parameters paper summarizes work done authors zero resource speech challenge organized technical program interspeech goal challenge discover linguistic units directly unlabeled speech data. multi-layered acoustic tokenizer proposed work automatically discovers multiple sets acoustic tokens given corpus. acoustic token speciﬁed hyperparameters describe model conﬁguration. sets acoustic tokens carry different characteristics given corpus language behind thus mutually reinforced. multiple sets token labels used targets multi-target trained low-level acoustic features. bottleneck features extracted mdnn used feedback mdnn itself. call iterative system multi-layered acoustic tokenizing deep neural network generates high quality features track challenge acoustic tokens track challenge. index terms zero resource unsupervised learning human infants acquire knowledge language mere immersion language speaking community. process completely understood difﬁcult reproduced current automatic speech recognition technologies dominant paradigm supervised learning large human-annotated data sets. idea behind zero resource speech challenge inspire development speech recognition extreme situation whole language learned scratch. goal challenge linguistic units directly audio knowledge language speaker supplementary information. challenge includes tracks focuses subword units word units respectively. ﬁrst track unsupervised subword modeling construct framewise feature representation speech sounds robust within-speaker across-speaker variation. dynamic time warping performed sequences features predeﬁned phone pair intervals extract warping distance. performance feature evaluated using discriminability within across-speaker phone pairs. second track focuses discovery word units extract timing information word units hypothesized vocabularies derived speech corpus. intervals word unit appears corpus evaluated parsing clustering matching quality paper serves documentation work team organized national taiwan university submitted challenge within interspeech technical program. work propose completely unsupervised framework multi-layered acoustic tokenizing deep neural network task. multi-layered acoustic tokenizer used generate multiple sets acoustic tokens. acoustic token speciﬁed pair hyperparameters representing model granularities tokens. naming convention call acoustic token obtained hyperparameter pair layer. layer carries complementary knowledge corpus language behind. since well known speech signals multi-level structures including least phonemes words helpful analysing decoding speech sets acoustic tokens mutually reinforced. multi-layered token labels generated used training targets multi-target deep neural network learn framewise bottleneck features bnfs used feedback training process repeated enough number iterations converged token hmms obtained. processes referred token model optimization token label optimization left part fig.. process explained performed different conﬁgurations characterized hyperparameters number states acoustic token total number distinct acoustic tokens initialization transcription signal decoded tokens considered temporal segmentation signal length represents temporal granularity. distinct acoustic tokens considered segmentation phonetic space total number distinct acoustic tokens represents phonetic granularity. gives two-dimensional representation acoustic token conﬁgurations terms temporal phonetic granularities fig.. point two-dimensional space fig. corresponds acoustic token conﬁguration. acoustic tokens different layers different model granularities extract complementary characteristics corpus language behind jointly capture knowledge corpus. although selection hyperparameters arbitrary two-dimensional space select temporal granularities phonetic granularities forming two-dimensional array hyperparameter pairs granularity space. token boundary fusion fig. shows token boundary part utterance segmented acoustic tokens different layers different hyperparameter pairs deﬁne boundary function layer possible boundary every pair adjacent frames within utterance time index possible boundaries. layer bmn= boundary token boundary otherwise. boundary functions different layers weighted averaged give joint boundary function weights consider fact smaller shorter hmms generate boundaries. peaks selected based second derivatives ﬁltering thresholding process. gives segmentation utterance shown bottom fig.. lda-based token label re-initialization shown fig. segment obtained usually consists sequence acoustic tokens layer based tokens deﬁned layer. consider tokens words i.e. words i-th layer total layers. segment thus considered document composed words collected different layers. latent dirichlet allocation preformed topic modeling document labeled probable topic. topic characterized word distribution token distribution across different layers also represent certain acoustic characteristics certain acoustic token. setting number topics number distinct tokens subsection initial label subsection segment obtained acoustic token whose topic obtained lda. initial label used re-train acoustic tokens layers layers obtained learned unsupervised fashion precise. many layers corresponding different pair hyperparameters mutually reinforced. explained shown fig. including token boundary fusion ldabased token label re-initialization fig.. figure mutual reinforcement multi-layered tokens block diagram token boundary fusion segment considered document token word based token label re-initialization. multi-target shown right part fig. token label sequence layer valid target supervised framewise training although obtained unsupervised way. initial work here states target simply take token label training target. shown fig. multi-layered token labels different hyperparameter pair utterance jointly consider multi-layered token labels learning parameters single uniformly weighted cross-entropy objective output layer. result bottleneck feature extracted automatically fuse knowledge corpus language behind learned different sets acoustic tokens. iterative learning framework mat-dnn bnfs extracted mdnn iteration taken input left fig. replacing initial acoustic features. generates updated sets multi-layered token labels updated sets multilayered token labels used updated training objective mdnn. input features mdnn also updated concatenating initial acoustic features newly extracted bnfs tandem features. process repeated several iterations satisfactory results obtained. tandem feature used input mdnn augmented concatenating unsupervised features obtained systems deep boltzmann machine posteriorgrams longshort term memory recurrent neural network autoencoder bottleneck features i-vectors trained mfcc. although different conventional recurrent neural network recurrent structure included back propagation training concatenation bottleneck features features next iteration mdnn kind recurrent structure. general framework mat-dnn presented allows several ﬂexible conﬁgurations. however work train matdnn following manner. states token distinct tokens gives total layers. ﬁrst iteration dimension mel-frequency cepstral coefﬁcients energy delta double delta initial acoustic features input mdnn. tandem mfcc window frames i-vector trained mfcc evaluation interval input mdnn. topology hidden layers. even without feedback tandem features mat-dnn powerful self-contained unsupervised feature extractor. compared extracted ﬁrst iteration deep boltzmann machine posteriorgrams mentioned section mfcc input. make comparison fair keep dimensionality features deep boltzmann machine used -dimension mfcc window frames input. conﬁguration used ---. originally second iteration tandem original mfcc extracted ﬁrst iteration posteriorgrams ivector forming dimension input mdnn. used updated transcriptions target extracted features. trained using zrst python wrapper toolkit srilm developed training unsupervised hmms varying model granularity. tool used mutual reinforcement done mallet. mfcc extracted using toolkit. i-vectors extracted using kaldi. posteriorgram extracted using libdnn. mdnn trained using caffe. track ofﬁcial corpora buckeye corpus nchlt xitsonga speech corpus english tsonga respectively. used evaluation based discriminability test including across within speaker tests. ﬁnal results error percentage means lower better. results track presented table rows ofﬁcial baseline mfcc features ofﬁcial topline supervised phone posteriorgrams provided challenge organizers respectively. baseline mfcc features initial acoustic features used train systems work. posteriorgrams extracted mfcc serving strong unsupervised baseline. results rows performance bottleneck features extracted ﬁrst iteration mat-dnn without applying mutual reinforcement applying twice respectively. similar except wider bottleneck layer dimensions instead rows performance bottleneck features extracted second iteration mat-dnn without applying applying mat-dnn trained using row. similar except mfcc i-vectors tandemed input without features. features except conﬁned dimensions. allows fast fair comparison different algorithms. observe stand-alone feature extractor withiterations mat-dnn outperforms baseline effect mutual reinforcement seen improvement row. observe single iteration mutual reinforcement target mat-dnn enough bring huge improvement system. effect iterations mat-dnn seen comparing rows respectively corresponding iterations. although performance improvement notable dropped second iteration investigate reasons performance drop widened bottleneck feature dimensions observed dramatic improvement performance. possible explored full potential mat-dnn comparison algorithms original goal designed experiments. better tuned parameters improvement following iterations expected track nonetheless beneﬁt second iteration better observed track track evaluation tool track provided challenge organizers gives main metrics plus scores coverage. fig. shows results english tsonga well f-measures main metrics matching grouping type token boundary subgraph. omit coverage almost cases. subﬁgures fig. subﬁgure results four cases shown correspond four targets used mdnn bottleneck features listed rows table token sets three groups bars correspond different values group four bars correspond values parameters token sets. bars blue better baseline white worse. results jointly considering within across talker conditions shown. fig. english seen proposed token sets perform well type token boundary scores although much worse matching grouping. many cases beneﬁts brought type fig.) second iteration boundary fig.) especially small values many groups given smaller values seemed better probably close total number phonemes language. also general trend larger values figure results track english tsonga. subgraph evaluation measure four cases token sets used train bottleneck features listed four rows table shown bottom. four bars group value left right parameters token sets. blue yellow white bars correspond better equal worse compared baseline upper left corner subgraph. coverage shown almost cases. similar observations made tsonga fig. overall performance seemed even better proposed token sets perform well even matching scores. improvements brought bottleneck features second iteration better observed here gives best cases main scores. probably fact sets tokens available mat-dnn tsonga english. conclude observation token sets introduces robustness leads better token sets next iteration. goes without fig.) almetrics degrade except matching scores almost scores consistently increases becomes larger. suggests also prevent degradation happening detecting relatively long units. also selected three typical example token sets many proposed shown fig. compared baseline table including precision recall f-scores three example sets also marked fig.. table better baseline bold. much higher coverage scores suggest proposed approach highly permissive matching algorithm. much higher parsing scores especially recall f-scores imply proposed approach successful discovering word-like units. however matching grouping scores much worse probably discovered tokens cover almost whole corpus including short pauses silence therefore many tokens actually noises. another possible reason might values used much smaller size real word vocabulary making token label used signal segments varying characteristics degenerated grouping qualities. paper summarizes preliminary work done zero resource speech challenge interspeech propose matdnn generate multi-layer token sets fuse various knowledge different token sets bottleneck features. present complete results evaluations tested submission deadline hope results serve good references future investigations. hinton deng dahl a.-r. mohamed jaitly senior vanhoucke nguyen sainath deep neural networks acoustic modeling speech recognition shared views four research groups signal processing magazine ieee vol. c.-y. glass nonparametric bayesian approach acoustic model discovery proceedings annual meeting association computational linguistics long papers-volume association computational linguistics m.-h. gish chan belﬁeld lowe unsupervised training hmm-based self-organizing unit recognizer applications topic classiﬁcation keyword discovery computer speech language vol. schatz peddinti bach jansen hermansky dupoux evaluating speech features minimalpair task analysis classical mfc/plp pipeline interspeech annual conference international speech communication association ludusan versteegh jansen gravier x.-n. johnson dupoux bridging speech technology natural language processing evaluation toolbox term discovery systems language resources evaluation conference c.-t. chung c.-a. chan l.-s. unsupervised spoken term detection spoken queries multi-level acoustic patterns varying model granularity acoustics speech signal processing ieee international conference y.-c. l.-s. performance analysis latticebased speech indexing approaches using words subword units audio speech language processing ieee transactions vol. c.-t. chung w.-n. c.-y. l.-s. enhancing automatically discovered multi-level acoustic patterns considering context consistency applications spoken term detection acoustics speech signal processing ieee international conference ieee weiner schultz investigating learning effect multilingual bottle-neck features fifteenth annual conference international speech communication association m.-h. gish chan belﬁeld improved topic classiﬁcation keyword discovery using hmmbased speech recognizer trained without supervision. interspeech c.-t. chung c.-a. chan l.-s. unsupervised discovery linguistic structure including two-level acoustic patterns using three cascaded stages iterative optimization acoustics speech signal processing ieee international conference ieee hochreiter schmidhuber long short-term memory neural computation vol. kanagasundaram vogt dean sridharan mason i-vector based speaker recognition short utterances proceedings annual conference international speech communication association. international speech communication association c.-t. chung zrst https//github.com/ctao/zrst young evermann gales hain kershaw moore odell ollason povey book. entropic cambridge research laboratory cambridge vol. povey ghoshal boulianne burget glembek goel hannemann motlicek qian schwarz silovsky stemmer vesely kaldi speech recognition toolkit ieee workshop automatic speech recognition understanding. ieee signal processing society dec. ieee catalog cfpsrwusb. pitt dilley johnson kiesling raymond hume fosler-lussier buckeye corpus conversational speech columbus department psychology ohio state university", "year": 2015}