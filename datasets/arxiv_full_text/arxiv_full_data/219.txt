{"title": "Pixel Deconvolutional Networks", "tag": ["cs.LG", "cs.CV", "cs.NE", "stat.ML"], "abstract": "Deconvolutional layers have been widely used in a variety of deep models for up-sampling, including encoder-decoder networks for semantic segmentation and deep generative models for unsupervised learning. One of the key limitations of deconvolutional operations is that they result in the so-called checkerboard problem. This is caused by the fact that no direct relationship exists among adjacent pixels on the output feature map. To address this problem, we propose the pixel deconvolutional layer (PixelDCL) to establish direct relationships among adjacent pixels on the up-sampled feature map. Our method is based on a fresh interpretation of the regular deconvolution operation. The resulting PixelDCL can be used to replace any deconvolutional layer in a plug-and-play manner without compromising the fully trainable capabilities of original models. The proposed PixelDCL may result in slight decrease in efficiency, but this can be overcome by an implementation trick. Experimental results on semantic segmentation demonstrate that PixelDCL can consider spatial features such as edges and shapes and yields more accurate segmentation outputs than deconvolutional layers. When used in image generation tasks, our PixelDCL can largely overcome the checkerboard problem suffered by regular deconvolution operations.", "text": "deconvolutional layers widely used variety deep models up-sampling including encoder-decoder networks semantic segmentation deep generative models unsupervised learning. limitations deconvolutional operations result so-called checkerboard problem. caused fact direct relationship exists among adjacent pixels output feature map. address problem propose pixel deconvolutional layer establish direct relationships among adjacent pixels up-sampled feature map. method based fresh interpretation regular deconvolution operation. resulting pixeldcl used replace deconvolutional layer plug-and-play manner without compromising fully trainable capabilities original models. proposed pixeldcl result slight decrease efﬁciency overcome implementation trick. experimental results semantic segmentation demonstrate pixeldcl consider spatial features edges shapes yields accurate segmentation outputs deconvolutional layers. used image generation tasks pixeldcl largely overcome checkerboard problem suffered regular deconvolution operations. deep learning methods shown great promise variety artiﬁcial intelligence tasks image classiﬁcation semantic segmentation natural image generation network layers convolutional layers pooling layers fully connected layers deconvolutional layers frequently used create deep models different tasks. deconvolutional layers also known transposed convolutional layers initially proposed primarily used deep models require up-sampling feature maps generative models encoder-decoder architectures although deconvolutional layers capable producing larger feature maps smaller ones suffer problem checkerboard artifacts greatly limits deep model’s capabilities generating photo-realistic images producing smooth outputs semantic segmentation. date little efforts devoted improving deconvolution operation. work propose simple efﬁcient effective method known pixel deconvolutional layer address checkerboard problem suffered deconvolution operations. method motivated fresh interpretation deconvolution operations clearly pinpoints root checkerboard artifacts. up-sampled feature generated deconvolution considered result periodical shufﬂing multiple intermediate feature maps computed input feature independent convolutions. result adjacent pixels output feature directly related leading checkerboard artifacts. overcome figure comparison semantic segmentation results. ﬁrst second rows images ground true labels respectively. third fourth rows results using regular deconvolution proposed pixel deconvolution pixeldcl respectively. problem propose pixel deconvolutional operation used pixeldcl. layer intermediate feature maps generated sequentially feature maps generated later stage required depend previously generated ones. direct relationships among adjacent pixels output feature established. sequential generation intermediate feature maps pixeldcl result slight decrease computational efﬁciency show largely overcome implementation trick. experimental results semantic segmentation image generation tasks demonstrate proposed pixeldcl effectively overcome checkerboard problem improve predictive generative performance. work related pixel recurrent neural networks pixelcnns generative models consider relationship among units feature map. belong general class autoregressive methods probability density estimation using masked convolutions training training time pixelrnns pixelcnns comparable generative models generative adversarial networks variational autoencoders however prediction time pixelrnns pixelcnns slow since generate images pixel pixel. contrast pixeldcl used replace deconvolutional layer plug-and-play manner slight decrease efﬁciency largely overcome implementation trick. introduce deconvolutional layers analyze cause checkerboard artifacts section. propose pixel deconvolutional layers implementation trick improve efﬁciency. deconvolutional networks deconvolutional layers proposed widely used deep models applications semantic segmentation generative models many encoder-decoder architectures deconvolutional layers decoders up-sampling. understanding deconvolutional operations up-sampled output feature obtained periodical shufﬂing multiple intermediate feature maps obtained applying multiple convolutional operations input feature maps figure illustration deconvolutional operation. deconvolutional layer feature up-sampled feature map. left ﬁgure shows input unit passes kernel. output feature obtained values column. seen ﬁgure purple outputs related entries kernel orange outputs related entries kernel. therefore deconvolution decomposed convolutional operations shown right ﬁgure. intermediate feature maps generated convolutional operations dilated combined obtain ﬁnal output. indicates standard deconvolutional operation decomposed multiple convolutional operations. figure illustration deconvolutional operation. deconvolutional layer feature up-sampled feature map. four intermediate feature maps generated using four different convolutional kernels. four intermediate feature maps shufﬂed combined produce ﬁnal feature map. note four intermediate feature maps rely input feature direct relationship among them. interpretation deconvolution illustrated figures respectively. clear illustrations standard deconvolutional operation decomposed several convolutional operations depending up-sampling factor. following assume up-sampling factor though deconvolution operations applied generic settings. formally given input feature deconvolutional layer used generate up-sampled output fout follows denotes convolutional operation denotes periodical shufﬂing combination operation figure intermediate feature generated corresponding convolutional kernel clear interpretation deconvolution direct relationship among intermediate feature maps since generated independent convolutional kernels. although pixels position intermediate feature maps depend receptive ﬁeld input feature directly related other. periodical shufﬂing operation adjacent pixels output feature different intermediate feature maps. figure illustration checkerboard problem semantic segmentation using deconvolutional layers. ﬁrst second rows original images semantic segmentation results respectively. implies values adjacent pixels signiﬁcantly different other resulting problem checkerboard artifacts illustrated figure alleviate checkerboard artifacts apply post-processing smoothing adds additional complexity network makes entire network fully trainable. work propose pixel deconvolutional operation direct dependencies among intermediate feature maps thereby making values adjacent pixels close effectively solving checkerboard artifact problem. addition pixel deconvolutional layers easily used replace deconvolutional layers without compromising fully trainable capability. solve checkerboard problem deconvolutional layers propose pixel deconvolutional layers dependencies among intermediate feature maps. adjacent pixels different intermediate feature maps pixeldcl build direct relationships among them thus solving checkerboard problem. method intermediate feature maps generated sequentially instead simultaneously. intermediate feature maps generated later stage required depend previously generated ones. primary purpose sequential generation dependencies among intermediate feature maps thus adjacent pixels ﬁnal output feature maps. finally intermediate feature maps shufﬂed combined produce ﬁnal output feature maps. compared eqn. fout obtained follows denotes juxtaposition feature maps. note eqn. denotes kernels involves convolution juxtaposition multiple feature maps. since intermediate feature maps eqn. depend input feature previously generated ones term input pixel deconvolutional layer process pixels output feature maps conditioned input feature maps also adjacent pixels. since direct relationships among intermediate feature maps adjacent pixels ipixeldcl expected solve checkerboard problem extent. note relationships among intermediate feature maps ﬂexible. intermediate feature maps generated later rely part previously generated intermediate feature maps. depends design pixel dependencies ﬁnal output feature maps. figure illustrates speciﬁc design sequential dependencies among intermediate feature maps. ipixeldcl dependencies among generated intermediate feature maps thereby making adjacent pixels ﬁnal output feature maps directly related other. process information input feature repeatedly used generating intermediate feature maps. generating intermediate feature maps information input feature previous intermediate feature maps used. since previous intermediate feature maps already contain information input feature dependencies input feature removed. figure illustration ipixeldcl pixeldcl described section ipixeldcl additional dependencies among intermediate feature maps. speciﬁcally four intermediate feature maps generated sequentially. purple feature generated input feature orange feature conditioned input feature purple feature generated previously. green feature relies input feature purple orange intermediate feature maps. feature generated based input feature purple orange green intermediate feature maps. also propose move step allow ﬁrst intermediate feature depend input feature map. gives rise pixeldcl. connections indicated dashed lines removed avoid repeated inﬂuence input feature map. ﬁrst feature generated input feature maps directly rely input. pixeldcl orange feature depends purple feature map. green feature relies purple orange feature maps. feature conditioned purple orange green feature maps. information input feature delivered intermediate feature maps ﬁrst intermediate feature simpliﬁed pixel deconvolutional layer ﬁrst intermediate feature depend input feature map. intermediate feature maps generated afterwards depend previously generated intermediate feature maps. simplify dependencies among pixels ﬁnal output feature map. work pixeldcl denote simpliﬁed design. experimental results show pixeldcl yields better performance ipixeldcl regular deconvolution. compared eqn. fout pixeldcl obtained follows pixeldcl illustrated figure removing connections denoted dash lines. analyzing relationships pixels output feature maps clear pixel still rely adjacent pixels. therefore checkerboard problem solved even better computational efﬁciency. meanwhile experimental results demonstrate performance models simpliﬁed dependencies even better complete connections. demonstrates repeated dependencies input necessary. pixel deconvolutional layers applied replace deconvolutional layers various models involving up-sampling operations u-net vaes gans replacing deconvolutional layers pixel deconvolutional layers deconvolutional networks become pixel deconvolutional networks u-net semantic segmentation pixel deconvolutional layers used upsample low-resolution feature maps high-resolution ones. vaes applied decoders image reconstruction. generator networks gans typically deep model thus employ pixel deconvolutional layers generate large images. layer figure efﬁcient implementation pixel deconvolutional layer. feature up-sampled feature map. purple feature generated convolutional operation input feature that another convolutional operation applied purple feature produce orange feature purple orange feature maps dilated added together form larger feature since relationship last intermediate feature maps apply masked convolutional operation instead separate convolutional operations finally large feature maps combined generate ﬁnal output feature experiments evaluate pixel deconvolutional layers u-net vaes. results show performance pixel deconvolutional layers outperforms deconvolutional layers networks. practice frequently used up-sampling operation increase height width input feature maps factor e.g. case pixels output feature maps divided four groups eqn. dependencies deﬁned figure implementing pixel deconvolutional layers design simpliﬁed version reduce sequential dependencies better parallel computation training efﬁciency illustrated figure design four intermediate feature maps. ﬁrst intermediate feature depends input feature map. second intermediate feature relies ﬁrst intermediate feature map. third fourth intermediate feature maps based ﬁrst second feature maps. simpliﬁed relationships enable parallel computation third fourth intermediate feature maps since dependency them. addition masked convolutional operation used generate last intermediate feature maps. mentioned already variety different dependencies relations imposed intermediate feature maps. simpliﬁed design achieves reasonable balance efﬁciency performance. code publicly available section evaluate proposed pixel deconvolutional methods semantic segmentation image generation tasks comparison regular deconvolution method. results show pixel deconvolutional layers improves performance consistently supervised unsupervised learning settings. experimental setup pascal segmentation dataset mscoco detection dataset evaluate proposed pixel deconvolutional methods semantic segmentation tasks. datasets images resized batch training. models directly predict label pixel without post-processing. examine models ways training scratch ﬁne-tuning state-of-art model deeplab-resnet. figure sample segmentation results pascal segmentation dataset using training scratch models. ﬁrst second rows original images corresponding ground truth respectively. third fourth ﬁfth rows segmentation results models using deconvolutional layers ipixeldcl pixeldcl respectively. network consists four blocks encoder path four corresponding blocks decoder path. within decoder block deconvolutional layer followed convolutional layers. ﬁnal output layer adjusted based number classes dataset. pascal segmentation dataset classes mscoco detection dataset classes. mscoco detection dataset classes pascal segmentation dataset number feature maps layer dataset doubled accommodate output channels. baseline u-net model employs deconvolutional layers within decoder path up-sample feature maps. replace deconvolutional layers proposed pixel deconvolutional layers simpliﬁed version keeping variables unchanged. kernel size number parameters ipixeldcl sets kernels parameters pixeldcl sets kernels. enable evaluate pixel deconvolutional layers regular deconvolutional layers controlling factors. ﬁne-tuning experiments ﬁne-tune models based architecture deeplabresnet deeplab-resnet model ﬁne-tuned resnet also external data training. strategy using external training data ﬁnetuning classic resnet greatly boosts performance model accuracy mean iou. output deeplab-resnet eight times smaller input image height width dimensions. order recover original dimensions three up-sampling blocks up-samples feature maps factor up-sampling block deconvolutional layer followed convolutional layer. employing strategy replace deconvolutional layer pixeldcl ipixeldcl using kernels size training scratch experiments. analysis results sample segmentation results u-net using deconvolutional layers ipixeldcl pixeldcl pascal segmentation dataset mscoco detection dataset given figures respectively. u-net models using ipixeldcl pixeldcl better capture local information images base model using regular deconvolutional layers. using pixel deconvolutional layers spacial features edges shapes considered predicting labels adjacent pixels. moreover semantic segmentation results demonstrate proposed models tend produce smoother outputs model using deconvolution. also observe that training epoch small model employs pixeldcl better segmentation outputs model using ipixeldcl. training epoch large enough similar performance though pixeldcl still outperforms ipixeldcl cases. indicates pixeldcl efﬁcient effective since much fewer parameters learn. figure sample segmentation results mscoco detection dataset using training scratch models. ﬁrst second rows original images corresponding ground truth respectively. third fourth ﬁfth rows segmentation results models using deconvolutional layers ipixeldcl pixeldcl respectively. table semantic segmentation results pascal segmentation dataset mscoco detection dataset. compare base u-net model ﬁne-tuned deeplab-resnet using three different up-sampling methods decoders; namely regular deconvolution layer proposed input pixel deconvolutional layer pixel deconvolutional layer pixel accuracy mean used performance measures. model u-net u-net ipixeldcl u-net pixeldcl u-net u-net ipixeldcl u-net pixeldcl deeplab-resnet deeplab-resnet ipixeldcl deeplab-resnet pixeldcl model using regular deconvolution. model using pixeldcl slightly outperforms model using ipixeldcl. models ﬁne-tuned deeplab-resnet models using ipixeldcl pixeldcl better performance model using ipixeldcl performs best. semantic segmentation mean accuracy evaluation measure pixel accuracy models using pixel deconvolution better evaluation results mean base model using deconvolution. experimental setup dataset used image generation celebfaces attributes dataset avoid inﬂuence background images preprocessed facial information retained. image generation task reconstruct faces excluding backgrounds training images. size images standard variational auto-encoder base model image generation. decoder part standard employs deconvolutional layers up-sampling. apply proposed pixeldcl replace deconvolutional layers decoder keeping components same. kernel size parameters pixeldcl sets kernels. analysis results figure shows generated faces using vaes regular deconvolution pixeldcl decoders. images generated baseline model suffer figure sample face images generated vaes trained celeba dataset. ﬁrst rows images generated standard deconvolutional layers up-sampling. last rows generated model using pixeldcl up-sampling. table training prediction time semantic segmentation using pascal segmentation dataset tesla gpu. compare training time epochs prediction time images base u-net model using three different methods up-sampling decoders; namely ipixeldcl pixeldcl. apparent checkerboard artifacts none found images generated model pixeldcl. demonstrates proposed pixel deconvolutional layers able establish direct relationships among adjacent pixels generated feature maps images thereby effectively overcoming checkerboard problem. results demonstrate pixeldcl useful generative models since consider local spatial information produce photo-realistic images without checkerboard problem. table shows comparison training prediction time u-net models using ipixeldcl pixeldcl up-sampling. u-net models using ipixeldcl pixeldcl take slightly time training prediction model using since intermediate feature maps generated sequentially. model using pixeldcl efﬁcient reduced dependencies efﬁcient implementation discussed section overall increase training prediction time dramatic thus expect major bottleneck proposed methods. work propose pixel deconvolutional layers solve checkerboard problem deconvolutional layers. checkerboard problem caused fact direct relationship among intermediate feature maps generated deconvolutional layers. pixeldcl proposed direct dependencies among generated intermediate feature maps. pixeldcl generates intermediate feature maps sequentially intermediate feature maps generated later stage required depend previously generated ones. establishment dependencies pixeldcl ensure adjacent pixels output feature maps directly related. experimental results semantic segmentation image generation tasks show pixeldcl effective overcoming checkerboard artifacts. results semantic segmentation also show pixeldcl able consider local spatial features edges shapes leading better segmentation results. future plan employ pixeldcl broader class models generative adversarial networks references liang-chieh chen george papandreou iasonas kokkinos kevin murphy alan yuille. deeplab semantic image segmentation deep convolutional nets atrous convolution fully connected crfs. arxiv. mark everingham gool christopher williams john winn andrew zisserman. pascal visual object classes challenge. international journal computer vision goodfellow jean pouget-abadie mehdi mirza bing david warde-farley sherjil ozair aaron courville yoshua bengio. generative adversarial nets. advances neural information processing systems karol gregor danihelka alex graves danilo rezende daan wierstra. draw recurrent neural network image generation. proceedings international conference machine learning kaiming xiangyu zhang shaoqing jian sun. deep residual learning image recognition. proceedings ieee conference computer vision pattern recognition matthew johnson david duvenaud alex wiltschko ryan adams sandeep datta. composing graphical models neural networks structured representations fast inference. advances neural information processing systems alex krizhevsky ilya sutskever geoffrey hinton. imagenet classiﬁcation deep convolutional neural networks. advances neural information processing systems augustus odena vincent dumoulin chris olah. deconvolution checkerboard artifacts. distill ./distill.. http//distill.pub// deconv-checkerboard. scott reed zeynep akata xinchen lajanugen logeswaran bernt schiele honglak lee. generative adversarial text image synthesis. proceedings international conference machine learning volume scott reed a¨aron oord kalchbrenner sergio g´omez colmenarejo ziyu wang belov nando freitas. parallel multiscale autoregressive density estimation. arxiv preprint arxiv. danilo jimenez rezende shakir mohamed daan wierstra. stochastic backpropagation approximate inference deep generative models. proceedings international conference machine learning wenzhe jose caballero ferenc husz´ar johannes totz andrew aitken bishop daniel rueckert zehan wang. real-time single image video super-resolution using efﬁcient sub-pixel convolutional neural network. proceedings ieee conference computer vision pattern recognition aaron oord kalchbrenner lasse espeholt oriol vinyals alex graves conditional image generation pixelcnn decoders. advances neural information processing systems matthew zeiler graham taylor fergus. adaptive deconvolutional networks high level feature learning. computer vision ieee international conference ieee", "year": 2017}