{"title": "Fully Convolutional Multi-Class Multiple Instance Learning", "tag": ["cs.CV", "cs.LG", "cs.NE"], "abstract": "Multiple instance learning (MIL) can reduce the need for costly annotation in tasks such as semantic segmentation by weakening the required degree of supervision. We propose a novel MIL formulation of multi-class semantic segmentation learning by a fully convolutional network. In this setting, we seek to learn a semantic segmentation model from just weak image-level labels. The model is trained end-to-end to jointly optimize the representation while disambiguating the pixel-image label assignment. Fully convolutional training accepts inputs of any size, does not need object proposal pre-processing, and offers a pixelwise loss map for selecting latent instances. Our multi-class MIL loss exploits the further supervision given by images with multiple labels. We evaluate this approach through preliminary experiments on the PASCAL VOC segmentation challenge.", "text": "multiple instance learning reduce need costly annotation tasks semantic segmentation weakening required degree supervision. propose novel formulation multi-class semantic segmentation learning fully convolutional network. setting seek learn semantic segmentation model weak image-level labels. model trained endto-end jointly optimize representation disambiguating pixel-image label assignment. fully convolutional training accepts inputs size need object proposal pre-processing offers pixelwise loss selecting latent instances. multi-class loss exploits supervision given images multiple labels. evaluate approach preliminary experiments pascal segmentation challenge. convolutional networks achieving state-of-the-art performance many computer vision tasks require costly supervision. following ilsvrc-winning image classiﬁer krizhevsky progress detection segmentation demonstrates convnets likewise address local tasks structured output. deep learning methods tasks rely strongly annotated data highly timeconsuming collect. learning weak supervision though hard would sidestep annotation cost scale learning available image-level labels. work propose novel framework multiple instance learning fully convolutional network task learn pixel-level semantic segmentation weak imagelevel labels signal presence absence object. images centered labeled object contain multiple objects make problem difﬁcult. insight work drive joint learning convnet representation pixel classiﬁer multiple instance learning. fully convolutional training learns model end-to-end pixel. learn segmentation model image labels cast image pixel-level-instances deﬁne pixelwise multi-class adaptation loss. reduce need bounding annotations rarely attempted segmentation. oquab improve image classiﬁcation inferring latent object location evaluate localization. hoffman train ﬁne-tuning rely bounding supervision proposals representation learning. problems framed max-margin learning approaches boosting noisy-or models approaches limited ﬁxed representations sensitivity initial hypotheses latent instance-level labels. counter shortcomings simultaneously learning representation maximize conﬁdent inferred instances. incorporate multi-class annotations making multi-class inferences image. image contains multiple classes competition pixelwise models help better infer latent instance-level classes. perform jointly end-to-end representation learning fully convolutional network. eliminates need instantiate instance-label hypotheses. learning inference process images different sizes without warping object proposal pre-processing. makes training simple fast. propose multi-class pixel-level loss inspired binary scenario. tries maximize classiﬁcation score based pixel-instance simultaneously taking advantage inter-class competition narrowing instance hypotheses. target under-studied problem weakly supervised image segmentation. belief pixel-level consistency cues helpful disambiguating object presence. weak segmentation incorporate image structure bounding boxes. fully convolutional network model designed spatial prediction problems. every layer computes local operation relative spatial coordinates. take input size produce output corresponding dimensions. weakly supervised learning allows efﬁcient selection training instances. predicts output pixels corresponding loss pixels. loss masked re-weighted otherwise manipulated choose select instances computing loss back-propagation learning. -layer cast fully convolutional form suggested long semantic segmentation replacing fully connected layers corresponding convolutions. network ﬁne-tuned pre-trained ilsvrc classiﬁer weights i.e. pre-trained predict image-level labels. experiment without initializing last layer weights i.e. classiﬁer layer. initializations without ﬁnetuning baselines image-level pretraining model quickly converges background. semantic segmentation requires background class classiﬁcation task none; simply zero initialize background classiﬁer weights. deﬁne multi-class loss multi-class logistic loss computed maximum predictions. selection enabled output produced i.e. image size outputs heat-map class corresponding size. identify scoring pixel coarse heat-maps classes present image background. loss computed coarse points back propagated network. alternating optimization binary problem inspires ignoring loss nonmaximally scoring points. background class analogous negative instances competing positive object classes. input image label output heat-map label location loss deﬁned ignoring loss non-maximally scoring points avoid biasing learning background. simultaneous training exploits multi-label images inter-class confusion help reﬁne intra-class pixel accuracy. inference time mil-fcn takes class prediction every point coarse prediction bilinearly interpolates image resolution obtain pixelwise segmentation. test set. evaluation metric intersection union deﬁned class percentage pixels intersection ground truth segmentation mask predicted mask number pixels union. mil-fcn model initialized -layer ilsvrc classiﬁer ﬁne-tuned loss. long ﬁne-tune output layer access complete supervision. setting however transferring output layer parameters classes common pascal ilsvrc improves results. including classiﬁer parameters helps prevent degenerate solutions predicting background. train model learning rate momentum weight decay training quick network converges less iterations. table shows quantitative intersection-over-union scores example outputs milfcn shown figure mil-fcn achieves relative improvement baseline results classiﬁer ﬁne-tuned common classes. preliminary encouraging results. propose novel model joint multiple instance representation learning multi-class pixelwise loss inspired binary mil. model learned end-to-end fully convolutional network task weakly supervised semantic segmentation. precludes need kind proposal instance hypothesis mechanisms. inference fast results encouraging improved further. currently coarse output merely interpolated; conditional random ﬁeld regularization super-pixel projection could reﬁne predictions. grouping methods could likewise drive learning selecting whole segments instead single points training. moreover controlling convnet learning manipulating loss could uses encouraging consistency across images co-segmentation hard negative mining. references achanta radhakrishna shaji appu smith kevin lucchi aurelien pascal susstrunk sabine. slic superpixels compared state-of-the-art superpixel methods. pattern analysis machine intelligence ieee transactions hariharan bharath arbel´aez pablo bourdev lubomir maji subhransu malik jitendra. semantic contours inverse detectors. computer vision ieee international conference ieee", "year": 2014}