{"title": "Lipschitz-Margin Training: Scalable Certification of Perturbation  Invariance for Deep Neural Networks", "tag": ["cs.CV", "cs.LG", "stat.ML"], "abstract": "High sensitivity of neural networks against malicious perturbations on inputs causes security concerns. We aim to ensure perturbation invariance in their predictions. However, prior work requires strong assumptions on network structures and massive computational costs, and thus their applications are limited. In this paper, based on Lipschitz constants and prediction margins, we present a widely applicable and computationally efficient method to lower-bound the size of adversarial perturbations that networks can never be deceived. Moreover, we propose an efficient training procedure to strengthen perturbation invariance. In experimental evaluations, our method showed its ability to provide a strong guarantee for even large networks.", "text": "high sensitivity neural networks malicious perturbations inputs causes security concerns. ensure perturbation invariance predictions. however prior work requires strong assumptions network structures massive computational costs thus applications limited. paper based lipschitz constants prediction margins present widely applicable computationally eﬃcient method lower-bound size adversarial perturbations networks never deceived. moreover propose eﬃcient training procedure strengthen perturbation invariance. experimental evaluations method showed ability provide strong guarantee even large networks. deep neural networks highly vulnerable intentionally created small perturbations inputs called adversarial perturbations cause security concerns applications self-driving cars. image recognition systems intensively studied. kurakin showed adversarial perturbations indeed cause misclassiﬁcations real-world applications. papernot demonstrated adversarial perturbations created without knowing classiﬁers’ structures. many heuristics developed improve robustness neural networks perturbations. however recent work repeatedly succeeded create adversarial perturbations networks protected heuristic defenses literature indicates even protected networks unexpectedly vulnerable. crucial problem speciﬁc line research primary concern studies security threats. tackle crucial problem develop defense methods theoretical guarantees. goal ensure lower bounds size adversarial perturbations networks never deceived input. refer lower bounds certiﬁed invariant radii simply invariant radii. make available broad applications fundamental requirements calculation methods however many existing approaches require strong assumptions massive computational costs. example could ensure perturbation invariance network structures wide residual networks commonly used evaluations defense methods. work tackled problem provide widely applicable highly scalable method ensure large invariant radii. basic idea bound size adversarial perturbations networks never deceived even though concept using lipschitz constant already appeared szegedy much certiﬁcations provide studied well. show ensure signiﬁcantly larger invariant radii compared recent computationally eﬃcient counterpart however size certiﬁed invariant radii still insuﬃcient practically meaningful cases. addressed issue novel training procedure strengthen perturbation invariance. experimental evaluations proposed training procedure dramatically increased invariant radii. also observed could improve robustness networks current attacking methods. severe security concerns number defense methods adversarial perturbations proposed. approach regularize mask gradients. defensive distillation distills networks themselves prominent methods. however carlini wagner showed adversarial perturbations created deceive networks trained defensive distillation. input transformations detections defense strategies although also bypassed adversarial training injects adversarially perturbed data training data promising approach. however certain risk overﬁtting attacks existing literature indicates diﬃculty evaluating robustness networks. several studies addressing diﬃculty. major table comparison prior work. columns denote ability ensure absence adversarial perturbations ability improve certiﬁcation empirical robustness scalability applicability networks consisting activation functions relu applicability non-smooth networks. approaches restricting discussion networks using exclusively relu activation functions reduce veriﬁcation problem well-studied problems. bastani encoded networks linear programs katz reduced problem satisﬁability modulo theory raghunathan encoded networks semideﬁnite programs. however formulations demand prohibitive computational costs applications limited small networks. relatively tractable method kolter wong bounded inﬂuence ∞-norm bounded perturbations using convex outer-polytopes. however still hard scale method deep wide networks. another approach assuming smoothness networks losses. hein andriushchenko focused local lipschitz constants neural networks around input. however guarantee provided networks hidden layer. peck bounded size adversarial perturbations networks never deceived layer-wise manner. sinha proposed certiﬁable procedure adversarial training. however cannot ensure invariant radii exactly within framework. work extension szegedy subsequent work parseval networks summarized related work table sample image data distribution true label attackers create data point similar deceives defenders’ classiﬁers. similarity measure data points p-norms commonly used. paper solely consider -norm metric. positive constant classiﬁer. assume output section ﬁrst describe basic concepts calculation invariant radii deﬁned sec. next outline training procedure enlarge invariant radii. detailed proofs inequalities mathematical statements sec. sec. found appendix supplementary material. explain calculate invariant radii using lipschitz constant. notation sec. lipschitz constant neural network bounded following deﬁnition lipschitz constant lipschitz constant discussed szegedy cisse absence adversarial perturbations. since continuity assumption holds many network structures applying simple framework address ﬁrst requirement minimality assumptions. address second requirement computational tractability provide eﬃcient method calculate sec. ensure large invariant radii propose training procedure enlarges invariant radii. first provide method calculate diﬀerentiable manner respect network parameters. allows direct regularization lipschitz constants networks. however based discussion sec.. regularizing lipschitz constant insuﬃcient. instead keep large enough compared training procedure user speciﬁes constant represents required invariant radius training data. training elements output vector calculating loss except element corresponding class call training procedure lipschitz-margin training given sec. long original training procedure performs maximization accuracy makes invariant radii larger training data. details training procedure interpretation variants described sec. describe method calculate lipschitz constants neural networks. bounds lipschitz constant component recursively calculate overall bound. similar szegedy provide comprehensive bounds. moreover bounds calculated diﬀerentiable manner respect network parameters. describe bounds basic components neural networks below. describe relationships lipschitz constants functionals frequently appears deep neural networks composition addition concatenation. functions lipschitz constants bounded respectively. lipschitz constant output functional bounded follows describe bounds lipschitz constants major layers commonly used image recognition tasks. notation summarized table note ignore bias parameters change lipschitz constants layer. fully-connected layer lipschitz constant fully-connected layer calculation inference singular value decomposition. convolutional layer following cisse decompose convolution linear operator repeats inputs multiplication matrix here application reshaping multiplication aﬀect bound. obtained bound improvement cisse pooling layers consider operation splits input apply function concatenate them pooling layers since lipschitz constant taking mean bounded normalization layers ﬁrst consider batch normalization layers scaling parameter running average variance i-th dimension respectively. batch normalization layer essen+ lipschitz constant common batch normalization layer follows immediately fullyconnected convolutional layer case calculate preprocessing mean-subtraction random crop lipschitz constant equal divide pixel constant lipschitz constant division consider normalize channel standard deviation. smallest standard deviation. then lipschitz constant bounded /σi. recursive computation using bounds described previous sections calculate upper bound lipschitz constants whole networks diﬀerential manner respect network parameters. described sec. division prediction margins gives invariant radii. inference time calculation lipschitz constant required once. thus calculation lower bounds needs almost computational overheads compared usual evaluation processes. calculations training time notable diﬀerences lipschitz constants. example batch normalization layer depends input drop regularization usually rescales inputs. however consistently calculate lipschitz constants using bound inference time simplicity. computational cost discussed sec. example assume neural classiﬁer fully-connected layer last layer. lsub lipschitz constant subnetwork input input fully-connected layer. weight matrix fully-connected layer corresponding class case following value even though provides better bounds sec. store patterns calculate input number class labels. applications limited resources embeded systems small devices bound sec. better option. peck calculated invariant radii layer-wise manner. interpreted bounding lipschitz constant layer. exception analysis fully-connected layers requires smoothness assumption additional computation inference time. work provides diﬀerent view work also tighter bounds. furthermore provide comprehensive bounds various components. signiﬁcant diﬀerence tightness bounds experimentally conﬁrmed sec. since proposed calculation method invariant radii imposes almost computational overhead inference time property various potential applications. first note real-world applications even though true labels available calculate lower bounds size perturbations needed change predictions. primary balancing computational costs performance. invariant radii suﬃciently large weak computationally cheap detectors perturbations detectors need large perturbations. small invariant radii resort computationally heavy options e.g. strong detectors denoising networks ensure larger invariant radii propose training method encourages small lipschitz constants large prediction margins. speciﬁcally given constant present method encourages networks larger invariant radii training data. thus procedure lipschitz-margin training empirically found applying addition prediction correct stabilizes training. thus training scale addition refer lmt++. long original loss training procedure work maximize training accuracy clear encourages achieve required robustness perturbations training data. generalization test data experimentally evaluated sec. formulation highly ﬂexible consider extended versions. first consider applications require invariant radii diﬀerent classes. example distinguish humans cats important classify angora cats persian cats. knowledge combined specifying diﬀerent hyperparameter pair classes. second consider combination adversarial trainings. reasonable require smaller margins inputs large perturbations. incorporate intuition changing according size perturbations merely zero perturbed data. ability easily combined notions advantages lmt. here discuss diﬀerence work cisse formulation parseval networks goal limit change lipschitz continuous loss reducing lipschitz constant. however since existence adversarial perturbations corresponds loss continuous discussion applicable. example scaling layer output network without changing parameters control lipschitz constant network. however change prediction irrelevant existence adversarial perturbations. therefore considering solely lipschitz constant insuﬃcient. observation combined training invariant radii described sec. sec. additionally point three diﬀerences. first parseval networks upper bound component restricted smaller one. makes theoretical framework incompatible frequently used layers batch normalization layer. since ignore eﬀects layers parseval networks cannot control lipschitz constant networks normalization layers. hand calculation method invariant radii handle layers without problems. second parseval networks force singular values weight matrices close meaning parseval networks prohibit weight matrices dump unnecessary features. wang pointed learning unnecessary features cause adversarial perturbations indicates orthonormality condition adverse eﬀects encourage existence adversarial perturbations. since penalize small singular values suﬀer problem. third requires diﬀerentiable bounds lipschitz constants. lets easily extended networks various components. hand framework parseval networks requires special optimization techniques component. major overhead lmt++ calculation spectral norm weight matrix. spectral norm regularization requires matrix-vector products. hand parseval networks regularize weight matrices orthonormal require multiplications large matrices. even apply sub-sampling reduce computation time proposed cisse computational complexity larger takes longer. weight matrices used networks become larger along improvement computation hardwares diﬀerence becomes signiﬁcant. proposed calculation technique invariant radii ensures absence adversarial perturbations signiﬁcantly larger regions compared another computationally eﬃcient method also evaluated robustness trained networks current attacks calculation invariant radii used method described sec. test data negative prediction margins invariant radii calculated zero. consistently calculated invariant radii usual scale images whose elements values range also used invariant radii calculate upper bounds error ratio size perturbations. detailed experimental setups available appendix supplementary material. codes available https//github.com/ytsmiling/lmt. calculated mean median normalized invariant radii test data. normalization invariant radii divided input size. used lenet mnist cifar datasets following peck table summarizes results. reference median tens thousand times larger. table also listed invariant radii networks trained lmt++. hyperparameters used mnist cifar respectively. lmt++ eﬀectively increased invariant radii made times larger. since input dimension mnist cifar times larger invariant radius corresponds times larger certiﬁed region mnist times larger region cifar. supports eﬀectiveness lmt++. evaluated eﬀects lmt++ mnist dataset following experimental setups kolter wong used network consists convolutional layers fully connected layers. optimizers hyperparameters kolter wong general performance figure shows relationship size perturbations upper bounds error ratio test data diﬀerent hyperparameter lmt++. table shows median invariant radii. derivation lmt++ expected invariant radii larger table statistics invariant radii divided input dimension. invariant radii calculated networks trained usual procedure signiﬁcantly higher previous work. moreover lmt++ eﬀectively enlarges them. notation except extreme case lmt++ worked expected. natural behavior lmt++ notable property makes easy tune hyperparameter. using lmt++ trained network could never cause error perturbations norm bounded respectively. moreover trained network could ensure accuracy one-pixel attacks results fundamentally diﬀerent evaluation speciﬁc attacks. even though size certiﬁed invariant radii directly comparable kolter wong whose goal certiﬁcation perturbations lmt++ clear advantage running time. lmt++ took less four munites single geforce training kolter wong reported took hours titan moreover work requires almost computational overhead calculate invariant radii standard evaluation processes. gain better insight tightness guarantee also calculated lower bounds error ratio using adversarial attacks deepfool attack figure shows result deepfool. lmt++ enlarged invariant radii also robustiﬁed networks. precisely evaluation deepfool naive network dropped figure relationship upper bounds error ratio test data size perturbations. perturbations cause errors beyond bound. term hyperparameter lmt++ indicates required size invariant radii corresponds usual training procedure. accuracy attacks smaller respectively. hand networks trained lmt++ kept accuracy cases. results attack similar. figures available appendix supplementary material. adversarial perturbations found using deepfool three times larger invariant radii average networks trained lmt++ empirically shows certiﬁcation based lipschitz constant loose lmt++. comparison lipschitz regularization evaluate framework compared lmt++ direct regularization lipschitz constants. precisely vector i-th element sec. added regularization term loss. note lipschitz constant regularization within scope work. fair comparison searched larger hyperparameter lmt++ lipschitz constant regularization kept error less figure shows diﬀerence eﬀects upper bounds error ratio. even though regularizing lipschtz constant greatly improved certiﬁcation lmt++ achieved larger invariant radii. explain eﬀectiveness lipschitz constant regularization fact log-loss encourages larger margins even without lmt. objective minimizing lipschitz continuous loss reasonable regularization instead lmt. however lmt++ showed could ensure larger invariant radii. empirically supports lmt++ tackles targeted problem directly. figure comparison direct regularizations lipschitz constant lmt++. small upper bound indicates method eﬀectively increases invariant radii. lmt++ lipschitz regularization cause error clean data lipschitz regularization did. evaluated method larger complex network conﬁrm broad applicability scalability. used -layered wide residual networks width factor svhn dataset following cisse best knowledge largest network concerned certiﬁcation. compared lmt++ naive counterparts spectral norm regularization parseval networks. used lmt++ decreased hyperparameter value weight decay. table shows median invariant radii setting. lmt++ increased invariant radii billions times naive counterparts. diﬀerence parseval networks spectral norm regularization also dramatically large. especially networks trained lmt++ succeeded ensure accuracy even test images pixels perturbed margins already discussed sec. second deal normalization layers. since spectral norm regularization parseval networks consider eﬀects normalization layers speciﬁcally batch-normalization failed control lipschitz constants. note weight decay eﬀective measure regularize lipschitz constant batch-normalization. weight decay regularized. hand lmt++ lipschitz constant regularization regularized. observation suggests alternative regularization batch-normalization layer applying weight decay instead even though regularization improve performance spectral norm regularization parseval networks investigation possibility beyond scope paper. also evaluated robustness trained networks adversarial perturbations created current attacks. used deepfool evaluation. table summarizes results. methods except lmt++ kept comparable accuracy clean data state-of-the-art performance. observed parseval networks spectral norm regularization make networks rather vulnerable deepfool. possible explanation phenomenon well-conditioned networks make easier deepfool small adversarial perturbations. expected since lmt++ similar properties might become vulnerable deepfool. however lmt++ showed improved robustness especially large perturbations. indicates eﬀect signiﬁcantly diﬀerent controlling distributions singular values weight matrices. diﬀerence lmt++ notable. indicates regularizing upper bound lipschitz constant suﬃcient defending current attacking methods weight decay important complement this. investigation possibility left future work. ensure perturbation invariance broad range networks computationally eﬃcient procedure provided scalable certiﬁcation method uses lipschitz constant networks prediction margins. method ensure absence adversarial perturbations regions many orders magnitude larger previous computationally eﬃcient method. moreover proposed training procedure makes certiﬁcation signiﬁcantly better. evaluations robustness networks trained using method combinations heuristic defenses left future work.", "year": 2018}