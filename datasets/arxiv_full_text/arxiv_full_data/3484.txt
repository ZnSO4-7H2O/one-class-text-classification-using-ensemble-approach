{"title": "Imbalanced Malware Images Classification: a CNN based Approach", "tag": ["cs.CV", "cs.LG", "stat.ML"], "abstract": "Deep convolutional neural networks (CNNs) can be applied to malware binary detection through images classification. The performance, however, is degraded due to the imbalance of malware families (classes). To mitigate this issue, we propose a simple yet effective weighted softmax loss which can be employed as the final layer of deep CNNs. The original softmax loss is weighted, and the weight value can be determined according to class size. A scaling parameter is also included in computing the weight. Proper selection of this parameter has been studied and an empirical option is given. The weighted loss aims at alleviating the impact of data imbalance in an end-to-end learning fashion. To validate the efficacy, we deploy the proposed weighted loss in a pre-trained deep CNN model and fine-tune it to achieve promising results on malware images classification. Extensive experiments also indicate that the new loss function can fit other typical CNNs with an improved classification performance.", "text": "abstract—deep convolutional neural networks applied malware binary detection images classiﬁcation. performance however degraded imbalance malware families mitigate issue propose simple effective weighted softmax loss employed ﬁnal layer deep cnns. original softmax loss weighted weight value determined according class size. scaling parameter also included computing weight. proper selection parameter studied empirical option given. weighted loss aims alleviating impact data imbalance end-to-end learning fashion. validate efﬁcacy deploy proposed weighted loss pre-trained deep model ﬁne-tune achieve promising results malware images classiﬁcation. extensive experiments also indicate loss function typical cnns improved classiﬁcation performance. malware binary usually name extension .exe .bin malicious program could harm computer operating systems. sometimes many variations highly reused basic pattern. implies malware binaries could categorized multiple families variation inherits characteristics family. therefore important effectively detect malware binary recognize possible variations however non-trivial challenging. malware binary visualized digital gray image visualization malware binary detection turns multi-class image classiﬁcation problem well studied deep learning. manually extract features malware images feed classiﬁers detect malware binaries classiﬁcation. discriminative utilize automatically extract features razavian perform classiﬁcation end-to-end fashion. however deep cnns trained properly designed balanced data malware images dataset highly imbalanced malware many variations variations. instance dataset used paper contains classes class contains images images result even reputed pre-trained models perform poorly senario. furthermore pre-trained models originally designed speciﬁc vision tasks cannot applied malware binary detection directly. argue data augmentation could possible approach balance data oversampling minority classes and/or down-sampling majority classes. however suitable problem reasons. first down-sampling miss many representative malware variations. second simply jittering data cannot generate images corresponding real malware binaries. therefore investigate train model imbalanced data hand. solve challenges inspired work designed loss function improve training performance propose weighted softmax loss deep malware images classiﬁcation. based error rate given softmax loss weight misclassiﬁcations different values corresponding class size. intuitively misclassiﬁcation minority class ampliﬁed majority class needs suppressed. weighted loss achieve goal guide update ﬁlters proper direction. adopt pre-trained verydeep model family retrain achieve promising result malware images classiﬁcation. proposed loss proven feasible models extended models googlenet resnet word contributions work two-fold. first propose weighted softmax loss address data imbalance issue training. second apply proposed loss pre-trained model tune solve malware images classiﬁcation problem. rest paper organized follows. related work discussed section section introduces proposed weighted softmax loss. section describe deploy proposed loss ﬁne-tune deep malware images classiﬁcation. evaluate method section conclude paper section typical manner end-to-end learning process. huang proposed quintuplet based triple header hinge loss extracting discriminative features imbalanced data nonetheless work requires features extracted advance hand-crafted manner another pre-trained model. meanwhile clustering algorithm k-means needed prior training. steps integrated end-to-end fashion like typical cnns. recently applied deep learning medical physics consider scatter correction also designing loss function. softmax loss combination softmax regression entropy loss used multi-class classiﬁcation problems. given k-classes training containing images image ground truth label output unit last fully connected layer probability label given batchsize total number classes dataset. indicator function. gives gives typical cnns convolutional ﬁlters updated stochastic gradient descent algorithm. traditional softmax loss treats misclassiﬁcation class equally reasonable balanced data lead poor performance imbalanced data classiﬁcation malware images. weighted softmax loss proposed address issue. created classes malware images highly imbalanced. sample malware images ‘adialer.c’ class ‘skintrim.n’ class shown fig. microsoft malware classiﬁcation challenge also provides imbalanced training testing data includes classes only. therefore task challenging terms malware diversity deep learning deep learning recently gained remarkable success computer vision tasks. krizhevsky work opened deep application image classiﬁcation. many works inspired. simonyan zisserman proposed deep signiﬁcantly improved performance increasing depth using small convolutional ﬁlters size szegedy designed layers googlenet increased width network achieved stateof-the-art performance image classiﬁcation. eased training layers deep presenting residual learning framework. besides image classiﬁcation deep learning also applied fundamental image processing tasks denoising contour detection saxe berlin discussed feasibility using deep malware detection. hand-crafted features import’ extracted prior model training empirical preference extensive experiments parameter shown section worth noting minority classes assigned larger weight value whereas majority classes lightly weighted. weight value dramatically affect loss thus regarded subtle ﬁne-tuning boosts classiﬁcation performance well avoids overﬁtting. practice training procedure needs choose according ground truth label sample mini-batch. simonyan zisserman proved classiﬁcation accuracy improved going deep network. vgg-f model contains layers whereas vgg-verydeep model contains layers. convolutional ﬁlters size used vgg-verydeep- model. correspond smaller receptive ﬁelds still able extract discriminative features. ﬁne-tune vgg-verydeep- model since outperforms methods family classiﬁcation task. pre-trained models ‘vgg-face’ ‘fcn’ ‘fast-rcnn’ designed tasks including face recognition semantic segmentation object detection. therefore availability methods problem exploited work. addition simonyan zisserman argued local response normalization ignored cnn. order boost classiﬁcation performance batch normalization layer convolutional layer relu layer. however ﬁrst convolutional layer followed relu layer directly fully connected layer directly followed relu layer well. potential threat deep learning overﬁtting especially training large. srivastava invented ‘dropout’ simple powerful approach avoid overﬁtting cnn. units layers randomly dropped corresponding connections also removed temporarily. works randomly training different networks multiple rounds. place dropout layers three fully connected layers prevent overﬁtting testing phase dropout layers removed. layer model. ﬁnal structure contains layers including added dropout layers layers. purpose simpliﬁcation fully connected layers added dropout layers weighted loss layer shown fig. section describes experiments showing effectiveness proposed loss malware images classiﬁcation. vgg-fms models also used validate general loss function. also analyze value selection scaling parameter recommend empirical option. top- validation error utilized evaluate classiﬁcation performance. experiments conducted matconvnet framework open source library deep learning matlab. nvidia geforce titan used accelerate mini-batch processing. dataset used work contains classes highly imbalanced. name size class listed table partition data follows ﬁrst images class used training following validation last testing. additional data augmentation method except mean value subtraction applied image. validate general deploy proposed loss pre-trained models vgg-fms. default structures entirely preserved number ﬁlters last fully connected layer changed corresponds classes malware dataset. retrain three networks top- validation errors without weighted loss shown fig. seen method effectively decreases top- validation error keeps curves stable. test performances illustrated table fine-tune vgg-verydeep- model weighted loss order achieve better result ﬁne-tune vggverydeep- model discussed section initialize ﬁlter weights using msra momentum training regularized weight decay penalty multiplier suggested simonyan zisserman learning rate empirical best option. dynamic adjusting considered since data size require many epochs converge. ﬁne-tuned model -dimensional feature vector arbitrary image captured layer generate feature malware class extracting features images class combining feature vectors form matrix visualizing therefore dimension feature class size. feature reﬂect characteristics corresponding malware class. give feature maps malware classes fig. since classes highly imbalanced different class. attain best display effect ‘imagesc‘ command matlab visualize feature automatically scale map. batch size compare top- validation error models without weighted loss fig. seen weighted loss effectively decreases validation error compared original loss. testing remove added dropout layers results listed table dataset ‘autorun.k’ ‘malex.genj’ ‘rbotgen’ ‘vb.at’ ‘yuner.a’ classes pack however treat individual families. otherwise test error decreased. parameter needed compute weighted loss value. empirically best option show inﬂuence parameter investigate three values ﬁne-tuned vgg-verydeep- model report top- validation error fig. seen curve smoother others also converges lower error rate. indicates appropriate selection also critical network training. olga russakovsky deng jonathan krause sanjeev satheesh sean zhiheng huang andrej karpathy aditya khosla michael bernstein alexander berg fei-fei. imagenet large scale visual recognition challenge. international journal computer vision christian szegedy yangqing pierre sermanet scott reed dragomir anguelov dumitru erhan vincent vanhoucke andrew proceedings rabinovich. going deeper convolutions. ieee conference computer vision pattern recognition pages kaiming xiangyu zhang shaoqing jian sun. deep proceedings ieee residual learning image recognition. conference computer vision pattern recognition pages chen huang yining chen change xiaoou tang. learning deep representation imbalanced classiﬁcation. proceedings ieee conference computer vision pattern recognition pages tianyang wang mingxuan kaoning dilated residual network image denoising. arxiv preprint arxiv. gedas bertasius jianbo lorenzo torresani. deepedge multi-scale bifurcated deep network top-down contour detection. proceedings ieee conference computer vision pattern recognition pages joshua saxe konstantin berlin. deep neural network based malware detection using dimensional binary program features. malicious unwanted software international conference pages ieee sergey ioffe christian szegedy. batch normalization accelerating deep network training reducing internal covariate shift. arxiv preprint arxiv. nitish srivastava geoffrey hinton alex krizhevsky ilya sutskever ruslan salakhutdinov. dropout simple prevent neural journal machine learning research networks overﬁtting. proposed weighted softmax loss convolutional neural networks imbalanced malware images classiﬁcation. imposing weight classiﬁcation error different classes treated unequally. principle weighting loss clear intuition experiments shown feasibility working existing models. also ﬁne-tuned vgg-verydeep- model proposed loss achieve satisfactory classiﬁcation result. addition experimentally given option scaling parameter computing weighted loss. indicates appropriate selection parameter indispensable training success. john demme matthew maycock jared schmitz adrian tang adam waksman simha sethumadhavan salvatore stolfo. feasibility online malware detection performance counters. sigarch computer architecture news volume pages clemens kolbitsch paolo milani comparetti christopher kruegel engin kirda xiao-yong zhou xiaofeng wang. effective efﬁcient malware detection host. usenix security symposium pages lakshmanan nataraj karthikeyan gregoire jacob manjunath. malware images visualization automatic classiﬁcation. proceedings international symposium visualization cyber security page sharif razavian hossein azizpour josephine sullivan stefan carlsson. features off-the-shelf astounding baseline recognition. proceedings ieee conference computer vision pattern recognition workshops pages", "year": 2017}