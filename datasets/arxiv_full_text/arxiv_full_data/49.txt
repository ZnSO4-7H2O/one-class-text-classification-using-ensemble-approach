{"title": "Text Compression for Sentiment Analysis via Evolutionary Algorithms", "tag": ["cs.NE", "cs.AI", "cs.CL", "stat.ML"], "abstract": "Can textual data be compressed intelligently without losing accuracy in evaluating sentiment? In this study, we propose a novel evolutionary compression algorithm, PARSEC (PARts-of-Speech for sEntiment Compression), which makes use of Parts-of-Speech tags to compress text in a way that sacrifices minimal classification accuracy when used in conjunction with sentiment analysis algorithms. An analysis of PARSEC with eight commercial and non-commercial sentiment analysis algorithms on twelve English sentiment data sets reveals that accurate compression is possible with (0%, 1.3%, 3.3%) loss in sentiment classification accuracy for (20%, 50%, 75%) data compression with PARSEC using LingPipe, the most accurate of the sentiment algorithms. Other sentiment analysis algorithms are more severely affected by compression. We conclude that significant compression of text data is possible for sentiment analysis depending on the accuracy demands of the specific application and the specific sentiment analysis algorithm used.", "text": "abstract—can textual data compressed intelligently without losing accuracy evaluating sentiment? study propose novel evolutionary compression algorithm parsec makes partsof-speech tags compress text sacriﬁces minimal classiﬁcation accuracy used conjunction sentiment analysis algorithms. analysis parsec eight commercial non-commercial sentiment analysis algorithms twelve english sentiment data sets reveals accurate compression possible loss sentiment classiﬁcation accuracy data compression parsec using lingpipe accurate sentiment algorithms. sentiment analysis algorithms severely affected compression. conclude signiﬁcant compression text data possible sentiment analysis depending accuracy demands speciﬁc application speciﬁc sentiment analysis algorithm used. sentiment analysis automated detection emotions attitudes towards particular subject event entity received increasing amount interest since year sentiment analysis applied many problem domains; instance determining sentiments consumers towards products mining social media gain understanding public’s opinion matters corruption study propose novel evolutionary algorithm tasked compressing text whereby objective retain correct sentiment classiﬁcation compressed text. achieve this makes determine removed text without hindering classiﬁcation performance. inspired nature make population individuals evolved several iterations solve optimisation problems. illustrate idea consider sentence went home yesterday opened door immediately faced terrible shock. sentiment-encoding phrase terrible shock. thus want propose algorithm learn evolve rules effectively compression. remaining words sentence contain useful information determining sentiment expressed thus rules discard words. feng proposed chinese text compression method objective preserving opinions expressed text compressed sentence grammatically correct. authors propose score function takes consideration three primary functions; namely word signiﬁcance linguistic opinion scoring function. word signiﬁcance function makes word frequency properties allocate score word. scores obtained processing corpus containing documents. linguistic score obtained using n-gram probabilistic function made google search results. opinion score made opinion lexicon allocate value word based frequency word. authors created lexicon three different sources resulting lexicon contained words sentiment known. dynamic programming algorithm used order determine many words present compressed sentence evaluating several candidate compressed sentences. score function applied candidate sentence result divided number words compressed sentence. compressed sentence highest value operator deemed ﬁnal compressed sentence given uncompressed sentence. chinese data compressed sentences manually created evaluate proposed approach. study revealed proposed approach able outperform traditional sentence compression method sentences evaluated terms opinion grammar human. also proposed text compression method sentiment analysis. study make features perform compression. features grouped basic sentiment related semantic syntactic features. basic features include words word features constructed for; also include tags words. sentiment features namely binary ﬁeld denoting word perception word polarity word. words obtained existing lexicon. semantic features include preﬁx sufﬁx characters also brown word features helps identify words written differently represent thing. also include word embedding makes wordvec determine words similar meaning. syntactic feature makes single feature indicates relationship words sentence. sentence compression conducted prior sentiment analysis. languages deﬁned primary groups words grammatically similar. common include limited adjective verb noun. example words house student examples nouns. study stanford log-linear part-of-speech tagger used convert original data sets corresponding tags. thus word dataset converted length sentence original dataset identical tagged dataset. example following sentence found original dataset this great product would converted tagged dataset. study proposes type individual referred compressor reduces length sentences applied dataset. compressor made several rules turn rule made sequence tags decision. decision applied whenever it’s sequence tags matches tags data. decisions represent indices words removed matched sequence. figure illustrates example compressor. compressor ﬁgure rules denoted ﬁrst rule tags represented sequence rule decision delete word index implies particular compressor applied rule tags corresponding sequence ylm+ denote consecutive words sequence decision delete index thus delete consequently delete xlm. thus size reduced one. time ﬁnds exact sequence word corresponding deleted. rule processed punctuation mark occurs rule evaluation immediately stops. mechanism incorporated sequence tags encapsulated rule applied single sentence applied across separate sentences. example consider following sentences this book really funny. great tomorrow friday. corresponds nnp. assume rule following tags decision delete indices. punctuation marks taken consideration rule match words funny great. result this book really tomorrow friday. consequently sentiments sentences longer positive. however punctuation taken consideration rule delete words since full stop separates sentences. study deﬁne term ‘wildcard’ represents notion ‘any pos’ denoted symbol. thus rule evaluated wildcard match dataset. example rule following tags sequence ‘jj’ followed followed ‘nnp’ cause rule match sequence. algorithm presents generalized pseudocode match tags rule tags dataset. algorithm also presents delete words original dataset rule matches sequence. pseudocode creating initial population compressors presented algorithm several individuals created based predeﬁned user parameter namely population size. several rules created compressor. must least rule user-deﬁned algorithm pseudocode apply compressor sentence compress text. input compressor compressor evaluate input original sentence original sentence input sentence sentence input length sentence length sentence parameter namely maxrules implemented restrict total number rules. creating rules algorithm iterates reached maxrules probability value determine rule created seen line algorithm rule consists primary parts namely tags decisions pseudocode creation respective parts presented algorithms pseudocode ﬁtness evaluation compressor presented algorithm instance dataset considered turn. sentiment instance original dataset computed using algorithm compressor evaluated applied instance compressed sentence created. sentiment compressed sentence computed using algorithm compressed sentiment compared original sentiment. compressed sentence effect sentiment compared original. conversely values different possibilities. either compressed sentiment equal correct sentiment labelled training data thus ﬁtness function takes algorithm pseudocode baseline evaluation. input sentence sentence evaluated input dictionary dictionary sentiment words input negation words list negation words output sentiment evaluated sentence multi-objective ﬁtness function created combine ﬁtness average reduction terms length sentences compression size compressor terms number rules. thus objective maximize ﬁtness average reduction sentences minimize size compressor. twelve data sets created randomly selecting reviews corresponding amazon review datasets created data positive negative reviews randomly selected larger corresponding amazon data set. larger amazon data sets obtained data sets were amazon instant video apps android automotive baby beauty digital music health personal care musical instruments patio lawn propose experiments whereby compression rate user parameter parsec must generate compressors compress original datasets reach speciﬁed compression rate. achieve this lower upper user-deﬁned compression bound deﬁned. lower compression bound implemented ensure compressors result compression ratio less speciﬁed value. similarly upper compression bound ensured compressors result compression ratio greater speciﬁed value. thus every compressor population compression rate ucb. furthermore additional user-deﬁned parameters implemented ensure total number rules within compressor remained within certain bound. parameters named compressionrulesmin lower upper compression bound constrain algorithm ensuring compression rate compressor values respectively. table presents values along minimum maximum number rules used experiments. compression rates enforced performance parsec measured several datasets. values compressionrulesmax. compressionrulesmax parameter prevents compressors extremely large number rules. parameters restricting search space terms number rules create maintain compressor evolutionary process. initial population generation respect respect minimum maximum number rules. mutation operator also respect constraints. several sentiment analysis algorithms applied original compressed datasets determine difference accuracy investigate performance parsec. following algorithms used sentistrength meaningcloud vivek stanford uclassify sentiment intellexer lingpipe ﬁrst applied sentiment analysis algorithms described section iv-b original datasets record test accuracy. then parsec using baseline evaluation create compressor rules. compressors created applied compressors original datasets generate compressed data. applied sentiment analysis algorithms compressed data recorded test accuracy. following section report change accuracy compressed original data. parsec evolved population compressors generations crossover rate mutation rate figure shows average change test accuracy across different methods based compression rates. general trend decrease performance largest decrease performance observed sentiment. lingpipe sentistrength methods achieved positive change performance compression rates respectively. experimenting parsec posed following question. predetermined drop accuracy much compression achievable parsec? threshold compression vivek lingpipe able achieve compression. threshold methods could achieve compression rate. regardless compression rate used stanford sentiment obtain result less algorithms produced weakest performance parsec. fig. change average test accuracy across different sentiment analysis algorithms different text compression rates enforced parsec averaged across data sets. higher positive value indicates better result. various sentiment analysis technologies denoted follows refer intellexer lingpipe meaningcloud sentiment sentistrength stanford uclassify vivek respectively. accuracy obtained lingpipe outperformed methods. furthermore lingpipe obtained average positive change accuracy compression. compression rate lingpipe obtained change accuracy averaged datasets illustrating works well parsec. additionally wanted determine change test accuracy much larger compression rate used. table presents results compression rate used. certain algorithms tested limited access sentiment analysis algorithms. results reveal large compression rate achievable without example parsec compression follows. original sentence this wonderful movie involve fascinating people great actor actress. event interesting never tire watch episode. keep life inhabitant lark rise candleford. mrs. hamlin. compressed sentence this wonderful movie involve fascinating people actress. tire. keep rise candleford. mrs. hamlin. four rules randomly selected parsec model illustrate evolved rules. model total rules. tags presented order appearance square brackets. indices start zero. rule denotes followed delete words. rule denotes followed followed delete word index study empirically demonstrates machine learning reduce amount data needed determine sentiments within sentences little loss accuracy. achieve this proposed evolutionary algorithm parsec evolves population chromosomes encode rules compression based removal pos. studied test accuracies achieved eight algorithms compression rate thresholds enforced. algorithms showed marginal improvements accuracy several data sets compression rate additionally data sets whereby algorithms able yield improvement accuracy compression rate threshold sentiment accuracy loss methods able achieve compression methods compression methods compression. best performing algorithm lingpipe showed modest losses accuracy even high compression four-fold data compression. would interest incorporate parsec algorithm directly sentiment analysis algorithm instead simple dictionary approach. could achieve replacing ﬁtness function used evolutionary phase sophisticated sentiment analysis algorithm. would allow emergence algorithm compression sentiment analysis mutually optimised best performance. ﬁnancial assistance national research foundation towards research hereby acknowledged. opinions expressed conclusions arrived authors necessarily attributed nrf. toutanova klein manning singer featurerich part-of-speech tagging cyclic dependency network proceedings conference north american chapter association computational linguistics human language technology volume ser. naacl stroudsburg association computational linguistics mcauley pandey leskovec inferring networks substitutable complementary products proceedings sigkdd international conference knowledge discovery data mining ser. york thelwall buckley paltoglou kappas sentiment short strength detection informal text soc. inf. sci. technol. vol. dec. narayanan arora bhatia fast accurate sentiment classiﬁcation using enhanced naive bayes model proceedings international conference intelligent data engineering automated learning ideal volume ser. ideal york springer-verlag york inc. socher perelygin chuang manning potts recursive deep models semantic compositionality sentiment treebank proceedings conference empirical methods natural language processing tables viii present difference test accuracy results various compression rates. various sentiment analysis algorithms abbreviated follows refer intellexer lingpipe meainingcloud sentiment sentistrength stanford uclassify vivek respectively. compression rate best worst change accuracy obtained lingpipe sentiment respectively. based ﬁndings cent compression cases across methods data sets whereby change accuracy greater zero. compression rate number cases whereby lingpipe obtained best average change accuracy value best change accuracy compression rate obtained uclassify value data sets. data sets uclassify reduced data test accuracy compressed data better original data. additionally cases total across algorithms whereby change accuracy greater zero compression. ﬁndings revealed compression rate cases change greater zero best change average accuracy obtained lingpipe value -.%. reduction performance terms number cases change greater zero compression used; notably cases. uclassify however datasets test accuracy greater zero. finally algorithms able obtain improvements terms changes compression rate namely uclassify lingpipe changes data sets respectively.", "year": 2017}