{"title": "Is a Picture Worth Ten Thousand Words in a Review Dataset?", "tag": ["cs.CV", "cs.CL", "cs.IR", "cs.LG", "cs.NE", "H.2.8; H.3.3; I.2.6"], "abstract": "While textual reviews have become prominent in many recommendation-based systems, automated frameworks to provide relevant visual cues against text reviews where pictures are not available is a new form of task confronted by data mining and machine learning researchers. Suggestions of pictures that are relevant to the content of a review could significantly benefit the users by increasing the effectiveness of a review. We propose a deep learning-based framework to automatically: (1) tag the images available in a review dataset, (2) generate a caption for each image that does not have one, and (3) enhance each review by recommending relevant images that might not be uploaded by the corresponding reviewer. We evaluate the proposed framework using the Yelp Challenge Dataset. While a subset of the images in this particular dataset are correctly captioned, the majority of the pictures do not have any associated text. Moreover, there is no mapping between reviews and images. Each image has a corresponding business-tag where the picture was taken, though. The overall data setting and unavailability of crucial pieces required for a mapping make the problem of recommending images for reviews a major challenge. Qualitative and quantitative evaluations indicate that our proposed framework provides high quality enhancements through automatic captioning, tagging, and recommendation for mapping reviews and images.", "text": "viewers. heterogeneous nature materials provides tremendous possibility enhance user experience. example text reviews images shared many reviewers used create snippets users quickly obtain feeling business. karvonen show visually prominent elements images play important role review-based decision making. however production mixtures text images diﬃcult task review dataset colloquial language incorrect captioning images insuﬃcient labels images. moreover images captured cameras unknown conﬁguration uncontrolled environments thus making extraction image-features mapping features textual units challenging kind enhancement. propose framework composed palette deep learning data mining techniques recommend images review even review originally submitted picture. predict tags image generate captioning phrases images ﬁnally reviews relevant images. challenge scope paper limited review photo datasets pertaining restaurants. dataset contains restaurants reviews restaurants images. many images labels captions primary links connect reviews images dataset provide existing mapping them. framework consists three main components image classiﬁer textual reviews become prominent many recommendation-based systems automated frameworks provide relevant visual cues text reviews pictures available form task confronted data mining machine learning researchers. suggestions pictures relevant content review could signiﬁcantly beneﬁt users increasing eﬀectiveness review. propose deep learning-based framework automatically images available review dataset generate caption image enhance review recommending relevant images might uploaded corresponding reviewer. evaluate proposed framework using yelp challenge dataset. subset images particular dataset correctly captioned majority pictures associated text. moreover mapping reviews images. image corresponding business-tag picture taken though. overall data setting unavailability crucial pieces required mapping make problem recommending images reviews major challenge. qualitative quantitative evaluations indicate proposed framework provides high quality enhancements automatic captioning tagging recommendation mapping reviews images. usefulness review-based website largely depends quality materials produced repermission make digital hard copies part work personal classroom granted without provided copies made distributed proﬁt commercial advantage copies bear notice full citation ﬁrst page. copyrights components work owned others must honored. abstracting credit permitted. copy otherwise republish post servers redistribute lists requires prior speciﬁc permission and/or fee. request permissions permissionsacm.org. used predict label image captioning algorithm generates possible captions images captioned reviewer mechanism review number relevant images. outcome proposed framework able recommend images review shown figure paper contributes literature describing systematic approach image recommendation textual reviews minimal information available create mapping types. section outlines problem section describes overall framework. section lists evaluation techniques used. section provides descriptions experiments performed. related literature described section conclude paper section deployed django-based website visualize outcomes. related review establish mapping rely relationships caption image review thus major task proposed framework generate caption image case exist used relate review turn generating caption performed using probabilities belonging diﬀerent possible categories summary three subtasks generate label images none label generate caption-words based labels subset images captions review relevant images topically comparing review image captions. framework solves problem recommending images review three major steps. first image classiﬁer predict label images categorized none. second captioning algorithm image features existing captions inputs. generates caption-words images captions. finally apply topic modeling reviews captions separately able create probabilistic mapping. following subsections describe steps. ﬁrst step framework categorize images labeled none following categories food inside outside drink menu. preliminary data analysis reveals restaurant images labeled none. convolutional neural convolutional neural network algorithms require images dimension shaped square. resized images smallest dimension image pixels cropped image dimension obtain -by--pixel -by--pixel image. tested implemented models using python libraries based theano deep-learning library keras lasagne keras lasagne provide high-level functions deep learning algorithms including convolution pooling fullyconnected layers well backpropagation optimization routines whereas theano provides back-end computation includes support. used number diﬀerent models evaluate accuracy. models based cifar data others designed work imagenet data vgg- vgg- googlenet cifar model relatively simple layers. vgg- model adds four convolutional layers fully-connected layer signiﬁcantly increases complexity model. vgg- googlenet models even larger number layers consisting respectively. also used bag-of-features classiﬁcation algorithm baseline. used six-fold cross validation evaluation approaches. leverage lasagne-based implementation neural image caption generator predict captions images caption. generator uses special form recurrent neural network called longshort term memory network sequentially create ﬁxed-dimensional vector required variable length input output sentences. lstm nets special type capable learning long-term dependencies. lstm nets apply weighted layered gates input output previous hidden states. assigning diﬀerent magnitudes every gate information modiﬁed previous information useful model model forgets information. lstm nets able train gates automatically backpropagation obtaining robust lstm uses information image input. obtain lower-dimensional representation image using convolutional neural network several models described section chose googlenet model trained -by- images feed image features lstm googlenet’s ﬂexible compatibility lstm. captioning results presented paper resultant image features generated googlenet. complete model outlined figure ﬁgure represents word sentence represents trained parameters probability distribution words vocabulary log-likelihood correct word step. captions generated maximizing log-likelihood probability obtaining correct caption given image. lstm trained sequentially takes account image well previously seen words infer next word output sentence. position output sentence word highest probability selected disadvantage providing globally optimal solution. detailed sampling method required inference model described prediction caption-words learning relationships using existing captions seems logical direction target problem correcting captions case appropriate. based study reported paper many captions describe relevant image well. example caption hurrah it’s birthday picture pasta dish increases noise-level rather providing informative features. possible solution crowdsourcing subset data obtain accurate training set. however aspect scope current paper. figure shows screenshot website picture glass margarita. suggested caption-words include margarita well another cocktail bloody mary. sample indicates proposed system able closely predict content image textual snippets. leverage latent dirichlet allocation model topics reviews. review select best topic select representative terms topic regardless appear review not. review recommend images based presence representative terms review captions images available business review written. image ranked higher particular review representative term present image caption review compared image contains representative term caption. start selecting images using representative terms present review image caption. images cannot found select images captions contain representative terms review not. process ensures image selection solely driven overlaps review caption rather reviews image captions without overlap become candidates potential mapping topical terms ranking. figure shows sample recommended images text review written burger. diﬀerent metrics evaluate quality results main components framework image classiﬁcation image captioning topic modeling. image classiﬁcation top- accuracy percentage test images classiﬁed correctly vector per-word topic assignments words document dictionary topics variational distribution indexed free parameters ntest number times word appears holdout document changing model hyperparameters generator aﬀect results terms conﬁdence bleu- score? relationship conﬁdence score bleu score generated captions? focused restaurants detected yelp dataset. restaurant image dataset contains images average images restaurant; images contain caption labeled none. total number reviews restaurants deep neural networks cnns lstm nets require large memory computing-power. used diﬀerent devices experiments asus laptop griﬃn computing cluster university texas paso. asus laptop intel core processor memory nvidia gtxm video card. memory capacity nvidia gtxm laptop limited training images pixels. table provides conﬁguration griﬃn computing cluster. tested diﬀerent architectures compare accuracy obtained image classiﬁcation problem. architectures include simple cifar model vgg- googlenet bag-of-features-based classiﬁer baseline verify gain accuracy obtained using neural network versus simpler method. evaluation quality image captioning results performed using combination diﬀerent metrics bilingual evaluation understudy conﬁdence score. bleu method proposed panineni computes geometric mean n-gram precisions. since training consists mostly short sentences removed brevity penalty typically used prevents short sentences high scores words match. obtained range bleu- bleu- scores using corpus_bleu function nltk python library focused natural language processing. bleu metric shortcomings particularly take account probability caption generated. limitation designed metric measures conﬁdence score generated caption. caption generated take candidate words position sentence. position equation measure non-uniformity probabilities candidates normalized probability distribution candidates uniform probability distribution size ideally would like high non-uniformity value means conﬁdent word next. uniform distribution would indicate random selection words. compute conﬁdence generated caption following equation representing generated sentence normalized truncated probability distribution words position sentence highest probability probability word original distribution. metric range higher conﬁdence better. evaluation topics performed using perplexity measures model unseen documents value decreases function log-likelihood holdout documents. model lower perplexity better. following bounded deﬁnition perplexity presented hoﬀman ntest total word count holdout documents posterior parametrization dirichlet parameter ntest word count holdout document vector topic weights document accuracy obtained model. results indicate using neural networks improves signiﬁcantly accuracy image classiﬁcation models. models using -by--pixel images trained scratch using keras models using -by--pixel images trained lasagne initializing model weights ones obtained using imagenet dataset. this along smaller learning rate higher number epochs trained might explain higher accuracy models trained -by--pixel images. table presents details results models images pixels. models trained epochs. vgg- model obtained accuracy test data cifar model obtained accuracy. observation diﬀerence accuracy training data signiﬁcantly larger error dataset vgg- model took signiﬁcantly longer train compared simple model hours hours cifar model required. result difference number layers particular number convolution operations required model. cifar model convolutional layer ﬁve. figure shows accuracy models changes number epochs increases. seen cifar model outperforms vgg- ﬁrst epochs. sixth iteration vgg- model appears consistently better cifar albeit small margin. graph also shows accuracy classiﬁer seems reach steady state accuracy still varies epoch epoch indicates training reduced around epochs. evaluate model used image captioning component framework googlenet performed participant-based evaluation predicted labels randomly selected images originally labeled none. images predicted labels given participant evaluation. participant asked mark predicted labels correct incorrect comment anything observed. based participant’s comments images belong classes lack relevance image contents labels. images include phone numbers face images group photos irrelevant images. remaining images according participant images labeled correctly observation study model perform good attempting distinguish inside outside labels particularly dark settings. proceed results obtained googlenet model provides decent level accuracy average compatible neural image caption generator. iterations select hyperparameters resulted best conﬁdence bleu- score created initial suite experiments setting max_seq_len batch_sz iters figure depicts maximum value across iterations model adding median conﬁdence scores generated sentences corpus-level bleu- score. thus hypothetical maximum value dimension case clear optimal result obtained embedding_sz bleu- score obtained corpus generated captions bleu- score latter value signiﬁcantly lower obtained using microsoft coco dataset could explained quality many captions used. unconventional style colloquial language captions eﬀect bleu score score highly dependent sequence selected words. conﬁdence score described section measure strength bleu value. allows isolate high quality bleu scores. figure shows bleu-n scores change increasing conﬁdence score captions. point ﬁgure compute bleu-n score using samples conﬁdence score greater value x-axis. generated captions exhibit conﬁdence level higher obtain corpus-level bleu- score bleu- score evaluation using bleu score appropriate study given captions generally small frequent larger-grams scarce. qualitatively evaluate generated captions asked participants manually assign score generated caption hundred images. image presented participant captions generated generator captions evaluated using score scale meaning captions terms related image meaning caption term related image. baseline participants asked rate image captioning score caption contained exactly term related image. hundred images used evaluation ﬁrst hundred images appear website. subset images contains images labeled predictor food images labeled drink images outside images menu images labeled inside. table presents summary scores provided participants. general average scores median indicates that average least half captions generated image terms related image content. based overcalculation scores provided participants images score higher. indicates images least predicted caption containing terms related image. result demonstrates high quality prediction given tremendous amount possible word combinations captioning. gensim implementation latent dirichlet allocation used framework following parameters number topics words topic iterations experiments used words topic. mentioned section lower perplexity expected better model. section shown certain hyperparameters signiﬁcant impact perplexity model. observation choosing wrong values result times increase perplexity modiﬁcation result times increase perplexity. changes number topics iterations demonstrate times increase perplexity. thus careful optimization parameters required obtain optimal model terms perplexity. subsection describe review-to-image recommendations obtained framework. provided sample figure section illustrates framework able recommend relevant images review burger-meal. another review topical words recommended images shown figure review taken yelp’s entry gabi restaurant vegas. example shows recommended contains images fountains bellagio hotel across street described review. summaries reviews three recommended images provided table table shows framework able recommend images main dishes well outside features bellagio review patio sits facing bellagio. didn’t almost fountains putting show every minutes giving little extra atmosphere... weather right would recommend sitting patio. combination fountains decor able watch people walking strip made evening. yelp introduced images yelp challenge recently. best knowledge previous publications focused enhancing yelp reviews recommending related images. literature associated tasks involved paper described below. problem image classiﬁcation studied least half century initial approaches focusing manual extraction textural features diﬃculty manual feature extraction several automatic algorithms developed including histogram-based classiﬁcation well pyramid matching sparse coding locality-constrained linear coding methods bag-of-features approach followed classiﬁer recently interest deep neural networks. area image classiﬁcation surge observed convolutional neural networks cnns neural networks formed three diﬀerent types layers convolutional layers pooling layers fully-connected layers. layers stacked many diﬀerent ways research advancing direction deeper networks. relevant models include alexnet googlenet resnet image captioning algorithm used paper based work vinyals combines convolutional neural network special form recurrent neural network called long short-term memory alternatives using lstm include primitive rulebased systems object detection combined templates language models caption generation. heavily hand-designed alternatives would laborious implement. analternative method captioning ranking captions co-embedding images text vector space topic modeling also widely used text mining past decade. particular interest latent semantic indexing probabilistic documents latent semantic space. latent dirichlet allocation used work probabilistic approach generalizes plsi. variations algorithm include dynamic topic modeling online neural networks also used topic modeling framework designed enhance yelp reviews recommending images requires supervision. training samples gathered existing information pieces available data. part proposed methodology focuses enhancing improving existing data providing additional information i.e. categorizing images predicting caption-words them. future directions work provide enhancements multi-label classiﬁcation existing caption-words used labels. another future goal develop models track performance business sentiment detected review caption texts. t.-y. maire belongie hays perona ramanan doll´ar zitnick. microsoft coco common objects context. proc. european conf. comp. vision pages springer berg yamaguchi berg stratos daum´e iii. midge generating image descriptions computer vision detections. proc. conf. european chapter assoc. comp. ling. pages kuznetsova ordonez berg berg choi. collective generation natural image descriptions. proc. annu. meeting assoc. comp. ling. long papers-volume pages", "year": 2016}