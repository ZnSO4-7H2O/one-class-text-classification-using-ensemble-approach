{"title": "Fully DNN-based Multi-label regression for audio tagging", "tag": ["cs.CV", "cs.AI"], "abstract": "Acoustic event detection for content analysis in most cases relies on lots of labeled data. However, manually annotating data is a time-consuming task, which thus makes few annotated resources available so far. Unlike audio event detection, automatic audio tagging, a multi-label acoustic event classification task, only relies on weakly labeled data. This is highly desirable to some practical applications using audio analysis. In this paper we propose to use a fully deep neural network (DNN) framework to handle the multi-label classification task in a regression way. Considering that only chunk-level rather than frame-level labels are available, the whole or almost whole frames of the chunk were fed into the DNN to perform a multi-label regression for the expected tags. The fully DNN, which is regarded as an encoding function, can well map the audio features sequence to a multi-tag vector. A deep pyramid structure was also designed to extract more robust high-level features related to the target tags. Further improved methods were adopted, such as the Dropout and background noise aware training, to enhance its generalization capability for new audio recordings in mismatched environments. Compared with the conventional Gaussian Mixture Model (GMM) and support vector machine (SVM) methods, the proposed fully DNN-based method could well utilize the long-term temporal information with the whole chunk as the input. The results show that our approach obtained a 15% relative improvement compared with the official GMM-based method of DCASE 2016 challenge.", "text": "acoustic event detection content analysis cases relies labeled data. however manually annotating data time-consuming task thus makes annotated resources available far. unlike audio event detection automatic audio tagging multi-label acoustic event classiﬁcation task relies weakly labeled data. highly desirable practical applications using audio analysis. paper propose fully deep neural network framework handle multilabel classiﬁcation task regression way. considering chunk-level rather frame-level labels available whole almost whole frames chunk perform multi-label regression expected tags. fully regarded encoding function well audio features sequence multi-tag vector. deep pyramid structure also designed extract robust high-level features related target tags. improved methods adopted dropout background noise aware training enhance generalization capability audio recordings mismatched environments. compared conventional gaussian mixture model support vector machine methods proposed fully dnn-based method could well utilize long-term temporal information whole chunk input. results show approach obtained relative improvement compared ofﬁcial gmm-based method dcase challenge. smart mobile devices recent years huge amounts multimedia data generated uploaded internet everyday. data music ﬁeld sounds broadcast news television shows contain sounds wide variety sources. need analyzing sounds increased useful e.g. automatic tagging audio indexing automatic sound analysis audio segmentation audio context classiﬁcation. although supervised approaches proved effective many applications effectiveness relies heavily quantity quality training data. moreover manually labeling large amount data time-consuming. handle problem types methods developed. convert low-level acoustic features audio words using unsupervised learning methods second type ∗this work supported engineering physical sciences re†the ﬁrst author second author equal contribution methods based weakly labeled data e.g. audio tagging. clear tagging audio chunks needs much less time compared precisely locating event boundaries within recordings. certainly improve tractability obtaining manual annotations large databases. paper focus audio tagging task. overcome lack annotated training data multiple instance learning proposed variation supervised learning problems incomplete knowledge laaims classify sets instances bels training examples. instead recognizing single instances. following work andrews proposed formulation maximum margin problem work audio video processing using weakly labeled data. mandel ellis used clip-level tags derive tags track album artist granularities formulating number music information related multiple-instance learning tasks evaluated based algorithms them. phan used event-driven learn evidences event detection. recently also presented based system audio tagging event detection. common model used ofﬁcial baseline method dcase audio tagging. details found although methods mentioned useful results detection analysis audio data ignored possible relationships contextual information focused training model single event class independently. better data weak labels work utilize whole almost whole frames observed chunk input fully deep neural network make mapping audio feature sequence multi-tag vector. recently deep learning technologies obtained great successes speech image video ﬁelds since hinton salakhutdinov showed insights using greedy layerwise unsupervised learning procedure train deep model deep learning methods also investigated related tasks like acoustic scene classiﬁcation acoustic event detection better performance could obtained tasks. music tagging task also demonstrated superiority deep learning methods. however best knowledge deep learning based methods used environmental audio tagging newly proposed task dcase challenge based chime-home dataset audio tagging task chunk-level instead framelevel labels available. furthermore multiple instances could happen simultaneously example child speech could exist sound several seconds. hence good feed whole frames chunk predict multiple tags output. non-linear multi-layer model extracting robust features related speciﬁc classiﬁcation regression task. objective audio tagging task perform multi-label classiﬁcation audio chunks chunk utterance-level labels without frame-level labels. multiple events happen many particular frames. hence common frame-level cross entropy based loss function adopted. propose method encode whole almost whole chunk. fig. shows proposed fully dnn-based audio tagging framework using deep pyramid structure. proposed framework whole almost whole audio features chunk encoded vector values regression way. sigmoid used activation function output layer learn presence probability certain events. minimum mean squared error adopted objective function. stochastic gradient descent algorithm performed mini-batches mulwell utilize long-term temporary information whole sequence audio features multi-tag vector. fully neural network structure also successfully used image segmentation better prediction tags deep pyramid structure designed gradually shrinked size layers. deep pyramid structure reduce non-correlated interferences whole audio features focusing extracting robust high-level features related target tags. dropout background noise aware training adopted improve tagging performance dnn-based framework. rest paper organized follows. section introduce related work using based detail depict based framework section data description experimental setup given section show related results discussions section ﬁnally draw conclusion section implement multi-label classiﬁcation simple event tags binary classiﬁer built associating audio event class training step. speciﬁc event class audio frames audio chunk labeled event categorized positive class whereas remaining features categorized negative class. classiﬁcation stage given audio chunk likelihoods audio frame calculated class models respectively. given audio event class chunk classiﬁcation score scik obtained log-likelihood ratio multiple instance learning described terms bags instance deﬁned {··· number instances bi’s label least instance positive example underlying concept background noise ﬁxed utterance estimated using ﬁrst frames. although noise estimator simple similar idea shown effective dnn-based speech enhancement data used evaluation dataset task dcase audio recordings made domestic environment. audio data provided -second chunks sampling rates data stereo data mono. recordings obtained downsampling right-hand channel recordings. audio corresponds single chunk chunk multi-label annotations ﬁrst obtained annotators. annotations based label classes. detailed description annotation procedure provided reduce uncertainty test data evaluation based chunks annotators agreed label presence across label classes. moreover approximating typical recording capabilities commodity hardware monophonic audio data sampled used test. pre-process audio chunk segmenting using sliding window size converting segment mfccs. -second chunk frames mfccs obtained. -frame expansion input instead total frames found better relaxed input scheme increase total training samples. hence input size -frame mfccs also appended noise vector. hidden layer units second hidden layer units used construct pyramid structure. seven sigmoid outputs adopted predict seven tags. learning rate momentum dropout rates input layer hidden layer respectively. mini-batch size equation noted remaining chunks without ‘strongly agreement’ labels development dataset also added training considering better fault-tolerant capability. meanwhile chunks without ‘strongly agreement’ labels also added training data training. comparison also baselines using gmms mi-svm mentioned section based method number mixture components since based baseline focuses computing frame-level likelihoods mi-svm prefers instance-level scores sliding window size baselines different. based baseline uses sliding window size sliding window size mi-svm learning process regarded encoding function audio tags automatically predicted. hence multi-label regression rather classiﬁcation conducted. additional methods given improve dnn-based audio tagging performance. deep learning architectures natural tendency towards overﬁtting especially little training data. audio tagging task four hours training data imbalanced training data distribution type tag. dropout simple effective alleviate problem training iteration feature value every input unit activation every hidden unit randomly removed predeﬁned probability random perturbations effectively prevent learning spurious dependencies. decoding stage discounts weights involved dropout training regarded model averaging process mismatch problem also exist task testing audio segments could totally different existed training audio segments presence lots background noise. thus dropout adopted improve robustness generalize variation testing segments. different types background noise different recording environments could lead mismatch problem testing chunks training chunks. alleviate this propose simple background noise aware training enable noise awareness primary audio features augmented estimate background noise. additional on-line background noise information better predict expected tags. background noise estimated follows respectively. handle audio tagging mi-svm audio recording viewed shorter segments obtained sliding window treated instance. accelerate computation linear function kernel experiments. evaluate effectiveness approach compared baselines equal error rate metric. deﬁned point graph false negative rate versus false positive rate comparison table shows detailed performances obtained using approach baselines audio tag. easily fully-dnn based approach yields great improvements baselines across seven audio tags. compared method proposed fully method could similar performance signiﬁcantly outperform competing counterparts difﬁcult tags. average proposed method could relative improvement contrasting baseline. figure shows results obtained using approach baselines. fully dnn-based approach outperforms baselines across ﬁve-fold evaluations. following main reasons first proposed approach well utilize long-term temporary information instead treating information independently. second whole audio features sequence multi-tag vector working encoding function. however based methods build models single instances. contextual information potential relationship among different tags well utilized. based method yields close performance proposed method third evaluation. audio event classes namely adult male’s speech identiﬁable sounds well identiﬁed fold evaluation. case probably acoustic characteristics variations event classes evaluation data match trained models. mi-svm yield competitive performances comparison proposed approach gmm-based baseline. mi-svm actually working discriminative learning sensitive quantity quality used training data. furpaper presented fully-dnn based approach handle audio tagging weak labels sense chunk-level instead frame-level labels available. fully regarded encoding function audio features sequence multi-tag vector regression way. extract robust high-level features deep pyramid structure designed reduce non-correlated interfering features keeping highly related features. dropout background noise aware training methods adopted improve generalization capacity recordings unseen environments. tested approach dataset task dcase challenge obtained signiﬁcant improvements baselines namely mi-svm. compared ofﬁcial gmm-based baseline system given dcase challenge proposed system could reduce average. future work fully convolutional neural network extract robust high-level features audio tagging task. chen improve k-means clustering audio data exploring reasonable sampling rate seventh international conference fuzzy systems knowledge discovery sainath kanevsky ivengar unsupervised audio segmentation using extended baum-welch transformations proceedings international conference acoustic speech signal processing briggs lakshminarayanan neal fern raich acoustic classiﬁcation multiple simultaneous bird species multi-instance multi-label approach journal acoustic society america vol. ulges schulze breuel multiple instance learning weakly labeled videos proceedings workshop cross-media information analysis extraction management hinton deng dahl a.-r. mohamed jaitly senior vanhoucke nguyen sainath deep neural networks acoustic modeling speech recognition shared views four research groups ieee signal processing magazine vol. krizhevsky sutskever hinton imagenet classiﬁcation deep convolutional neural networks advances neural information processing systems cakir heittola huttunen virtanen polyphonic sound event detection using multi label deep neural networks international joint conference neural networks foster sigtia krstulovic barker plumbley chime-home dataset sound source recognition domestic environment ieee workshop applications signal processing audio acoustics dahl sainath hinton improving deep neural networks lvcsr using rectiﬁed linear units dropout ieee international conference acoustics speech signal processing hinton srivastava krizhevsky sutskever salakhutdinov improving neural networks preventing co-adaptation feature detectors arxiv preprint arxiv.", "year": 2016}