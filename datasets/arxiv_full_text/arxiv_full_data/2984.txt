{"title": "Action-Affect Classification and Morphing using Multi-Task  Representation Learning", "tag": ["cs.CV", "cs.AI", "cs.HC", "cs.LG"], "abstract": "Most recent work focused on affect from facial expressions, and not as much on body. This work focuses on body affect analysis. Affect does not occur in isolation. Humans usually couple affect with an action in natural interactions; for example, a person could be talking and smiling. Recognizing body affect in sequences requires efficient algorithms to capture both the micro movements that differentiate between happy and sad and the macro variations between different actions. We depart from traditional approaches for time-series data analytics by proposing a multi-task learning model that learns a shared representation that is well-suited for action-affect classification as well as generation. For this paper we choose Conditional Restricted Boltzmann Machines to be our building block. We propose a new model that enhances the CRBM model with a factored multi-task component to become Multi-Task Conditional Restricted Boltzmann Machines (MTCRBMs). We evaluate our approach on two publicly available datasets, the Body Affect dataset and the Tower Game dataset, and show superior classification performance improvement over the state-of-the-art, as well as the generative abilities of our model.", "text": "abstract. recent work focused aﬀect facial expressions much body. work focuses body aﬀect analysis. aﬀect occur isolation. humans usually couple aﬀect action natural interactions; example person could talking smiling. recognizing body aﬀect sequences requires eﬃcient algorithms capture micro movements diﬀerentiate between happy macro variations diﬀerent actions. depart traditional approaches time-series data analytics proposing multi-task learning model learns shared representation well-suited action-aﬀect classiﬁcation well generation. paper choose conditional restricted boltzmann machines building block. propose model enhances crbm model factored multi-task component become multi-task conditional restricted boltzmann machines evaluate approach publicly available datasets body aﬀect dataset tower game dataset show superior classiﬁcation performance improvement state-of-the-art well generative abilities model. much activity ﬁeld aﬀective computing already contributed creation research directions aﬀect analysis multiple research directions analyzing human aﬀect including face data audiovisual data body data main challenges aﬀect analysis occur isolation. humans usually couple aﬀect action natural interactions; example person could talking smiling knocking door angrily shown fig. able recognize body action-aﬀect pairs eﬃcient temporal algorithms needed capture micro movements diﬀerentiate happy well capture macro variations diﬀerent actions. focus work single-view multi-task action-aﬀect recognition skeleton data fig. examples body aﬀect dataset person knocking various aﬀects neutral angry happy sad. trajectory color corresponds time black beginning sequence reddish-black middle sequence. captured motion capture kinect sensors. work leverages knowledge work done graphics animation community uses machine learning enhance make accessible wide variety applications. body aﬀect dataset produced tower game dataset test cases novel multi-task approach. time series analysis diﬃcult problem requires eﬃcient modeling large amounts data introduces. multiple approaches designed features reduce data dimensionality using mid-level features simpler model classiﬁcation depart methods proposing model learns shared representation using multi-task learning. paper choose conditional restricted boltzmann machines non-linear generative models modeling time series data building block. undirected model binary latent variables connected number visible variables. crbm-based generative model enables modeling short-term phenomenon. propose hybrid model enhances crbm model multi-task discriminative components based work work leads superior classiﬁcation performance also allowing model temporal dynamics eﬃciently. evaluate approach body aﬀect tower game datasets show results superior state-of-the-art. paper organization sec. discuss prior work. sec. give brief background similar models motivate approach followed description model. sec. describe inference algorithm. sec. specify learning algorithm. sec. show quantitative results approach followed conclusion sec. section ﬁrst review literature activity recognition rgb-d motion capture sequences; second review multi-task learning approaches; ﬁnally review temporal energy-based representation learning. body aﬀect analysis initial work activity recognition rgb-d sequences popular recent years availability cheap depth sensors. since initial work increasing number approaches addressing problem activity recognition using skeletal data prior activity recognition rgb-d sequences datasets captured using motion capture sensors. time research focused graphics applications generating animation transitions animations using signal processing techniques rather machine learning computer vision. main goal generate natural looking skeletons animation. methods used knowledge signal processing transform neutral skeleton pose reﬂect certain emotion methods constrained type motion engineered reproduce motions. work used language based modeling aﬀect modeled actions aﬀect using graph. able produce results using combination level functions interpolate example motions. recent work modeling non-stylized motion aﬀect communication used segmentation techniques divided complex motions motion primitives used dynamic features. unlike approach mid-level features hand engineered rather learned limited scale prone feature design ﬂaws. recent work collected natural body aﬀect datasets varied identity gender emotion actions actors used classiﬁcation. multi-task learning multi-task learning natural approach problems require simultaneous solutions several related problems multi-task learning approaches grouped main sets. ﬁrst focuses regularizing parameter space. main assumption optimal shared parameter space tasks. approaches regularize parameter space using speciﬁc loss methods manually deﬁne relationships automatic ways estimate latent structure relationships tasks second focuses correlating relevant features jointly work focused schedule tasks learned multi-task learning achieved good results vision problems person re-identiﬁcation multiple attribute recognition tracking recently deep multi-task learning emerged rise deep learning. deep neural networks used address multi-task learning applied successfully facial landmark detection scene classiﬁcation object localization segmentation attribute prediction work used multi-task autoencoders object recognition generalized domain tasks different domains. work used multi-task rnns interaction prediction still images deep multi-task learning approaches focused using dnn-based models applied still images. approach ﬁrst dmtl temporal multimodal sequence analysis. representation learning deep learning successfully applied many problems restricted boltzmann machines form building blocks energy-based deep networks networks trained using contrastive divergence algorithm demonstrated ability deep networks capture distributions features eﬃciently learn complex representations. rbms stacked together form deeper networks known deep boltzmann machines capture complex representations. recently temporal models based deep networks proposed capable modeling rich time series analysis problems. include conditional rbms temporal rbms crbms successfully used visual audio domains. used modeling human motion tracking human pose phone recognition trbms applied transferring point clouds polyphonic music generation rather immediately deﬁning multi-task crbm model discuss sequence models gradually increasing complexity diﬀerent components ﬁnal model understood isolation. start basic model extend crbm model extend crbm discriminative model extend d-crbm main multi-task model ﬁnally deﬁne multi-task multimodal model rbms shown figure deﬁne probability distribution gibbs distribution vector visible nodes vector hidden nodes energy function partition function. parameters learned biases respectively weights case binary valued data deﬁned logistic function. case real valued data deﬁned multivariate gaussian distribution unit covariance. binary valued hidden layer deﬁned logistic function hidden layer becomes sparse probability distributions deﬁned sidering time done treating previous time instances additional inputs. complicate inference. approximations made facilitate eﬃcient training inference details available extend crbms d-crbms shown figure d-crbms based d-rbm model presented generalized account temporal phenomenon using crbms. d-crbms deﬁne probability distribution gibbs distribution probability distribution visible layer follow distributions hidden layer deﬁned function labels visible nodes probability distribution classiﬁer deﬁned relate label hidden nodes fig. models described sections mt-crbms mtm-crbms. mt-crbms learn shared representation layer tasks. addition shared layer mtm-crbms learn extra representation layer modalities learn modality-speciﬁc representations. crbms extended dc-rbms adding discriminative term model extend crbms multi-task mt-crbms figure mtcrbms deﬁne probability distribution gibbs distribution mt-crbms learn shared representation layer tasks. probability distribution visible layer follow distributions hidden layer deﬁned function multi-task labels visible nodes probability distribution multitask classiﬁer deﬁned relate multi-task labels hidden nodes naturally extend mt-crbms mtm-crbms. mtm-crbms combines collection unimodal mt-crbms visible modality. hidden representations produced unimodal mt-crbms treated visible vector single fusion mt-crbms. result mtmcrbm model relates multiple temporal modalities multi-task classiﬁcation labels. mtmcrbms deﬁne probability distribution pmtm gibbs distribution mtm-crbms learn extra representation layer modalities learns modality speciﬁc representation well shared layer tasks. similar mt-crbms hidden layer deﬁned function labels visible nodes probability distribution classiﬁer deﬁned relate label hidden nodes deﬁned ﬁrst discuss inference mtm-crbm since general case. perform classiﬁcation time mtm-crbm given bottom-up approach computing mean node given activation coming nodes compute mean using compute mean task using obtaining classiﬁcation probabilities task. figure illustrates inference approach. inference mt-crbm mtm-crbm except modality inference d-crbm mt-crbm except task. fig. ﬁgure speciﬁes inference algorithm. ﬁrst classify unimodal data activating corresponding hidden layers shown followed classifying multimodal data activating fusion layer shown tation respect reconstruction. learning done using steps bottom-up pass top-down pass using sampling equations d-crbm mt-crbm mtm-crbm. bottompass reconstruction generated ﬁrst sampling unimodal layers hidden nodes parallel. followed sampling fusion layer top-down pass unimodal layer generated using activated fusion layer ti|hm followed sampling visible nodes visible nodes parallel. gradient updates described similarly learning d-crbm mt-crbm could done. recon data recon data hnrecon hndata krecon kdata itdata itrecon) pi<t k<tvm jtrecon) jtdata pj<t i<thm j<thntdata hntrecon) rn<t data recon hndata hnrecon recon data khnrecon. khndata problem particular focus multi-task learning body aﬀect. literature datasets either single task activity recognition publicly available instances rgb-d without skeleton. found available datasets evaluate approach multi-task. ﬁrst dataset body aﬀect dataset collected using motion capture sensor consists actors performing several actions diﬀerent aﬀects. second dataset tower game collected using kinect sensor consists interaction humans performing cooperative task goal classifying diﬀerent components entrainment. following subsections describe datasets. body aﬀect dataset dataset consists library human movements captured using motion capture sensor annotated actor action aﬀect gender. dataset collected studying human behavior personality properties human movement. data consists actors performing four actions four aﬀect styles actor data instances instances walking instances knocking instances lifting instances throwing instances sequences knocking lifting throwing repetitions data instances. thus records knocking lifting throwing contain separate instances yielding total instances actor total instances. split dataset training using actors testing using actors. tower game dataset dataset simple game tower building often used social psychology elicit diﬀerent kinds interactive behaviors participants. typically played people working small ﬁxed number simple blocks stacked form various kinds towers. data consists videos divided -second segments indicating presence absence behaviors segment. entrainment alignment behavior individuals involves simultaneous movement tempo similarity coordination. measure rated medium high entire seconds segment. data used training used testing. dataset call person’s skeletal data modality goal model mocap-mocap representations. pre-processing tower game dataset followed approach forming body centric transformation skeletons generated kinect sensors. joints upper body players since tower game almost entirely involves upper body actions gestures done using upper body. used joint locations normalized respect selected origin point. descriptor provided descriptor consists dimensions based normalized joints location inclination angles formed triples anatomically connected joints azimuth angles projections second bone vector plane perpendicular orientation ﬁrst bone bending angles basis vector perpendicular torso joint positions. body aﬀect dataset decided full body centric representation motion capture sensors resulting dimensions frame. training consisting instances test consisting remaining tower game dataset trained three-task model following tasks tempo similarity coordination range well auto-regressive nodes range resulting total trained models. best performing best performing model tower game dataset following conﬁguration modalities fusion layer tower game dataset note mt-crbm model tasks assumed conditionally independent given hidden representation. thus number parameters dimensionality hidden layer number classes task contrast number parameters needed instead tasks ﬂattened cartesian factored representation multiple tasks uses linearly many parameters instead exponentially many parameters needed ﬂattened representation. fig. deep variants models presented sections mt-crbmsdeep mtm-crbms-deep. deep variants extra representation layer tasks learns task speciﬁc representation. baselines variants since compare approach results presented decided baselines used. used classiﬁers combination features. svm+raw ﬁrst features consisted ﬁrst order static dynamic handcrafted skeleton features. static features computed frame. features consist relationships between pairs joints single actor relationships pairs joints actors. dynamic features extracted window window compute ﬁrst second order dynamics joint well relative velocities accelerations pairs joints actor across actors. dimensionality static dynamic features svm+bow svm+bow reduce dimensionality used bag-of-words also evaluate approach using hcrf deﬁne model’s variants d-crbms single-task model presented section mt-crbms multi-task model presented section mtm-crbms multi-modal multi-task model presented section dm-crbms extension d-crbms multimodal similar mtm-crbms. also variants mt-crbms-deep mtm-crbms-deep shown fig. classiﬁcation body aﬀect dataset table shows results baselines well model variants. tower game dataset table shows average classiﬁcation accuracy using diﬀerent features baselines combinations well results models. mt-crbms-deep model outperforms models cases thereby demonstrating eﬀectiveness predicting multi-task labels correctly. furthermore mtm-crbms-deep model outperforms variants used high dimensional handcrafted features demonstrating ability learn rich representation starting skeleton features. note mtm-crbms mtm-crbms-deep performed well predicting diﬀerent tasks simultaneously relatively large margin better models using shared representation uses less parameters d-crbms model treats labels ﬂat. morphing besides classifying action aﬀect mt-crbms model trained body aﬀect dataset also capable generation. demonstrate morphing motion capture sequence aﬀect sequence diﬀerent aﬀect. example could morph neutral walk happy walk. morph sequence sweeping frames updating vector frame order. update ﬁrst compute expected value given compute expected value given used linear blend original sequence newly generated sequence generated sequence retains general shape original sequence. evaluate morphing process take neutral sequence action actor; morph happy angry sequence action type; compare classiﬁer probability target aﬀect original neutral sequence generated happy angry sequence. average classiﬁer probabilities morphing process action target aﬀect shown table classiﬁcation probabilities target aﬀects increased result morphing neutral sequences toward them means model able morph sequences successfully. proposed collection hybrid models discriminative generative model relationships distributions temporal multimodal multi-task data. extensive experimental evaluation models diﬀerent datasets demonstrates superiority approach stateof-the-art multi-task classiﬁcation temporal data. improvement classiﬁcation performance accompanied generative capabilities eﬃcient model parameters factorization across tasks. generative capabilities approach enable interesting applications demonstrated sequence morphing. future direction work explore improve generative applications models. factorization tasks used approach means number parameters grows linearly number tasks classes. seen signiﬁcant contrasted single-task model uses ﬂattened cartesian product tasks number parameters grows exponentially number tasks. factorized approach makes adding additional tasks trivial matter.", "year": 2016}