{"title": "Null Dynamical State Models of Human Cognitive Dysfunction", "tag": ["cs.AI", "cs.LG", "cs.NE"], "abstract": "The hard problem in artificial intelligence asks how the shuffling of syntactical symbols in a program can lead to systems which experience semantics and qualia. We address this question in three stages. First, we introduce a new class of human semantic symbols which appears when unexpected and drastic environmental change causes humans to become surprised, confused, uncertain, and in extreme cases, unresponsive, passive and dysfunctional. For this class of symbols, pre-learned programs become inoperative so these syntactical programs cannot be the source of experienced qualia. Second, we model the dysfunctional human response to a radically changed environment as being the natural response of any learning machine facing novel inputs from well outside its previous training set. In this situation, learning machines are unable to extract information from their input and will typically enter a dynamical state characterized by null outputs and a lack of response. This state immediately predicts and explains the characteristics of the semantic experiences of humans in similar circumstances. In the third stage, we consider learning machines trained to implement multiple functions in simple sequential programs using environmental data to specify subroutine names, control flow instructions, memory calls, and so on. Drastic change in any of these environmental inputs can again lead to inoperative programs. By examining changes specific to people or locations we can model human cognitive symbols featuring these dependencies, such as attachment and grief. Our approach links known dynamical machines states with human qualia and thus offers new insight into the hard problem of artificial intelligence.", "text": "hard problem artiﬁcial intelligence asks shuﬄing syntactical symbols program lead systems experience semantics qualia. address question three stages. first introduce class human semantic symbols appears unexpected drastic environmental change causes humans become surprised confused uncertain extreme cases unresponsive passive dysfunctional. class symbols pre-learned programs become inoperative syntactical programs cannot source experienced qualia. second model dysfunctional human response radically changed environment natural response learning machine facing novel inputs well outside previous training set. situation learning machines unable extract information input typically enter dynamical state characterized null outputs lack response. state immediately predicts explains characteristics semantic experiences humans similar circumstances. third stage consider learning machines trained implement multiple functions simple sequential programs using environmental data specify subroutine names control instructions memory calls drastic change environmental inputs lead inoperative programs. examining changes speciﬁc people locations model human cognitive symbols featuring dependencies attachment grief. approach links known dynamical machines states human qualia thus oﬀers insight hard problem artiﬁcial intelligence. artiﬁcial intelligence seeks understand machine interacting environment processing syntactical symbols changing causal dynamical state another generate semantic symbols meaning intentionality understanding. hard problem artiﬁcial intelligence contrasting approaches modeling artiﬁcial intelligence grounded work turing. ﬁrst approach turing deﬁned universal computer computable functions which beneﬁt hindsight raises question whether intelligence computable function however rather addressing question turing settled simpler claim merely simulating intelligent behaviour computable function proposed imitation game called turing test practical approach discerning intelligence whether natural artiﬁcial hypothesis intelligence computable strongly presented physical symbol systems hypothesis holding syntactical symbol manipulations necessary suﬃcient explain reproduce human machine intelligence approach posits system symbol structures consisting many atomic symbols processed according creation reproduction modiﬁcation destruction rules. system inhabits world external objects symbols designate object symbol inﬂuence inﬂuenced object symbols interpreted designate process system carry out. many decades approach interpreted extremely narrow limited terms. however broadly interpreted pssh subsumes many subsequent research programs invocative poetic treatment potential symbolic approach sees future conscious programs based active symbols equivalent self-contained programs possessing multiple simultaneous interpretations many diﬀerent levels symbols pssh approach critiqued many argued however accurately thors. syntactical symbol system modeled human physiology system would never feel pain afterwards searle introduced human syntactical symbol system chinese room show amount syntactical symbol processing would ever lead semantic meaning qualia experienced human cognition subsequent widespread ongoing debate argued consciousness doesn’t exist consciousness explained extensions currently understood physics systems reply chinese room holds perceived limitations reﬂect failure human intuition syntactical symbolic programs achieve. instance simple dynamical systems three degrees freedom simple train networks implement undecidable computations hence totally unpredictable outcomes. boden noted intuitions capacities computer programs couldn’t trusted argued computer programs merely formal systems syntax alone given suitable hardware context cause procedures implemented builds activates symbols alter external objects creating causal semantics exactly syntactical symbols grounded sensory inputs combine form higher level semantic symbols still open symbol grounding problem. argued latter statements problem essentially reprise designated interpreted symbols physical symbol systems hypothesis researchers building understandings formulate models human level artiﬁcial general intelligence progress lately artiﬁcial intelligence systems. massive data tables number crunching allowed deep blue crowned world chess champion watson employed data natural language processing defeat human jeapardy champions deep learning neural networks deep neural networks undertaking partially unsupervised reinforcement learning seen computers master video games atari seen alphago alphago zero alphazero achieve superhuman performance chess shogi neuroscience increasingly optimistic locating neural correlates consciousness growing power computers exploited implement cortical simulators leading whole brain emulators elegans mouse eventually hoped human. interestingly ability visualize reconstructed human visual brain experiences demonstrated would argue programs possess understanding experience qualia. further size complexity programs suggests putative artiﬁcial intelligence program able mimic full range human capacities enormous complex. turn need complex programs model artiﬁcial intelligence implies nothing learned small systems lacking size complexity code. paper wish present approach artiﬁcial intelligence exploits small systems lacking code capacity able generate dynamical states whose characteristics predict explain semantic experiences particular class human semantic symbols. class humans become cognitively dysfunctional faced radical environmental change disaster. humans largely dysfunctional accurate model human cognition circumstances require large complex code. class semantic symbols claim simple learning machine models predict explain aspects human semantic experience. make claims simple models semantic experiences. turn consider approach implemented here. paper introduce class cognitive semantic symbols humans typically experience faced radical unexpected environmental change disaster. class introduced sect. disaster humans continue experience semantics qualia many become cognitively unaware passive unmotivated unresponsive. unable access pre-existing pre-learned functional capacities noted above pre-learned capacities cannot source human qualia need included small models. approach breaks linkage syntax semantics. also relatively straightforward model dysfunctional human response disaster using learning machine. particular every learning machine presented input data well outside previous training generally become dysfunctional—an example garbage garbage out. interestingly suﬃciently complicated learning machine generally enter particular dynamical state presented novel inputs. machine can’t extract information unknown input machine ends processing zero information exhibits null dynamical state. null dynamical state serves close model unresponsive cognitive state humans similar circumstances. show characteristics null dynamical state used predict explain characteristics human semantic symbols similar circumstances. learning machine model used explain shocked confused behaviour searle’s chinese room placed disaster scenario. objectively observable dynamical null state room predict explain subjective experience room humans disaster situations. ﬁnish section discussing dynamical null state model addresses subjective-objective explanatory between computational state semantic experiences properties qualia experienced humans. sect. provide mathematical speciﬁcation dynamical null state typically exhibited learning machines presented data well outside training sets. focus principally artiﬁcial neural networks dynamics reasonably well understood. result mathematically speciﬁed dynamical null state whose characteristics predict explain semantic cognitive experiences humans similar situations. apply dynamical null states model human semantic symbols sect. happens large percentage learning machine’s functional capacities learned presence single teacher single location lack variation environment learning period makes likely environmental information unique teacher location deeply embedded within machine’s learned functions—rather learning generic good morning function machine might learn speciﬁc good morning alice function. consequently alice absent says good morning machine unable respond learned function speciﬁc bob. approach consider learning machine build environmental location person dependencies functionality drastic changes environment cause dysfunction. apply approach model number human cognitive semantic symbols. idea even begin coding program understand intend instance experience redness observing photons. however might possible make progress considering class human cognitive symbols arise humans face unexpected radical environmental change generate qualia like surprise confusion. changed environment unexpected claim qualia don’t result pre-existing programs arise altered dynamical state underlying cognitive architecture. responses people unexpected drastic environmental change often cool calm collected would hope panicked might suspect. disaster response organizations labeled many common beliefs people respond myths. particular most disaster victims psychologically resilient engage socially integrative—rather destructive—responses however small percentage population display disaster shock respond docility disoriented thinking apathy confusion disbelief facing sudden onset forewarning events involving widespread physical destruction anthropological studies disasters wallace summarize typical human response unexpected sudden overpowering trauma disaster syndrome large proportion persons impact area appear observer ‘dazed’ ‘stunned’ ‘apathetic’ ‘passive’ ‘immobile’ ‘aimlessly puttering around’. wallace concluded determinants syndrome opinion primarily physical injuries physical shock psychological person displays syndrome whether injured. wallace felt precipitating factor disaster syndrome seems perception practically entire visible community ruins. response realization victims exhibit withdrawal perceptual contact grim reality regression almost infantile level adaptive behavior characterized random movement relative incapacity evaluate danger institute protective action inability concentrate attention remember follow instructions. nowadays seen part broader suite including disaster response psychological shock physiological conservation-withdrawal syndrome victims disaster exhibit shock stupor dazed stunned numb exhibit immobility quiescence unresponsiveness constricted attention detachment. paper emphasizing importance psychological factors sudden disasters victims glimpse part human condition never factors clearly indicated ﬁrst-person report evacuee towers attacks. elia zede˜no felt plane impact tower even colleague screamed still found herself collecting belongings wandering circles desk feeling trance. roughly survivors gathered belongings evacuating. zede˜no’s later reported response seeing bodies lying motionless outside building lobby illustrates human mind processes overwhelming peril like trying keep information out. eyes allowing understand. couldn’t aﬀord ﬁnally realized meant wrong color wrong shape that’s realized seeing bodies. that’s froze. similar responses disaster collated leach. engine aboard boeing- airliner manchester airport resulted deaths found passengers sitting immobile seats overtaken smoke toxic fumes similar passivity substantially increased death toll piper alpha platform large number people apparently made attempt leave accommodation even prepared people suﬀer unexpected passivity stress—% parachuting fatalities result no-pull events failure main chute reserve chute pulled leach concluded victim passivity results difﬁculty integrating information survival environment multimodal systems information stored long-term memory victims perish unnecessarily threat environment restricts storage processing capacities working memory coupled form temporary environmentally induced dysexecutive syndrome subsequent investigations leach found victim immobility freezing common response unfolding emergencies resulting impaired response delays evacuation establishing closed-loop process leads fatalities otherwise survivable situations examples cited included victims estonia ferry sinking passive stiﬀ despite reasonable possibilities escaping many apparently perished simply nothing save themselves. survivors reported victims were standing still apparently shock some paralyzed exhausted passengers standing staircase sitting corners incapable anything people beyond reach react passengers tried guide them even used force shouted them. survivor reported didn’t think. shock disorienting doesn’t allow think clearly. people sitting complete shock understanding they’re something help themselves. swamped water came another survivor reported seeing around persons lying deck near bulkhead. seemed apathetic threw life jackets them. react lifejackets. leach concluded people disaster remain relatively calm able collect thoughts judgment reasoning abilities remain relatively unimpaired. second group stunned bewildered showing impaired reasoning sluggish thinking. behave reﬂexive almost automatic manner. ﬁnal group population will tend show high degree counterproductive behavior adding danger uncontrolled weeping confusion screaming paralyzing anxiety. seeking explain behaviours leach proposed model human working memory limited capacity maximum rate novel information processed. helps explain slowing absence response critical impact phase disaster. addition leach proposes time people learn complex behaviours pre-learned behavioural responses schemas. emergency however pre-learned schema exists temporary schema created take longer duration emergency. result behavioral schema triggered schemata database temporary schema created within time available. produces cognitively induced paralysis ‘freezing’ behavior leach later developed theoretical models explain maladaptive behaviour human responses disaster widely studied view ﬁnding adaptive explanation disaster response instance adaptive acute stress response danger sees animals ﬁrst freezing hide assess situation ﬂeeing danger possible ﬁghting fainting play dead exhibit tonic immobility caught predator added fainting stages feature dissociative shut-down exhibiting partial complete loss normal integration immediate sensations control bodily movements losses function hysterical blindness evident organic basis tonic immobility linked rape-induced paralysis wherein high percentage victims feel paralyzed unable despite loss consciousness experiments tonic immobility ongoing people experience major disaster associated response many experience range lesser events involving unexpectedly changed environment. lesser shocks spectrum involve response sudden environmental change. changes range severity grief bereavement shame humiliation simply surprised startled. innocuous spectrum surprise startle become pleasurable sought amusement parks form basis humour depends punch line introducing sudden unexpected setting changes joke. sponses bereavement described assault blow face head guts overwhelmed able take world shattering around sinking black hole defenses including disbelief dissociation feeling numb general grief symptoms include fear losing one’s mind hallucinations feeling hopeless fatigue loss interest ability concentrate people suﬀer complicated grief overwhelmed thoughts deceased disbelief feeling stunned lack acceptance death; enduring functional impairments suﬀerers experience persistent disturbing sense disbelief regarding death resistance acceptance painful reality everyday life acute stress response caused situations featuring shame humiliation embarrassment. victims humiliation report they felt wiped helpless confused sick paralyzed ﬁlled rage stabbed heart solar plexus much wished could disappear hasn’t experienced mind-numbing eﬀects unwanted center attention humiliating situation. sensation surprise results mismatch between ones mental expectations perceptions ones environment causes something similar ﬂight ﬁght reaction interruption ongoing information processing reallocation processing resources unexpected event order update relevant schemas instance pilots lulled sense security modern aircraft reliability when unexpected critical events occur pilots often genuinely surprised don’t readily accessible action plans deal them surprise events lead startle response even acute stress pilots sometimes taken action signiﬁcant impairment cognitive psychomotor performance investigation responses showed third pilots ﬂight simulator experiments exhibited pathological reactions startled froze unable respond unfolding events however noted previously surprise startle sometimes pleasurable sought seek amusement parks arrange surprise friends order please them—many adults played peek-a-boo child enjoyed happy response. everyone enjoys pleasure humour based human surprise startle reactions. incongruity-resolution model humour audience initially interprets joke using mental schema disrupted punchline presents incongruity whose resolution requires mental shift re-evaluation previously assumed knowledge approach widely applied example children’s humour advertising deeper explanations incongruity-resolutions found pleasant based locating neural correlates neural pattern unexpectedly replaced another broader evolutionary models cognitive approaches faced drastic unexpected environmental change humans sometimes cannot process novel environmental information cannot access pre-learned programming cannot invent responses time available. cognition eﬀectively cease become passive unresponsive unaware. design chinese room react like human disaster also become unresponsive. section present learning machine model disaster response chinese room humans. disaster humans lose access pre-existing prelearned functionalities still experience semantic content prelearned functionalities cansource human semantic content disaster. consequently modeling human disaster response artiﬁcial intelligence need include unused functionalities. similarly artiﬁcial intelligence model need include syntactical programs learned functions uncalled disaster scenario. small scale model suﬃces model human disaster response allowing break link syntactical code semantic symbols drastically simplify approach artiﬁcial intelligence. simplify approach noting essentially suﬃciently complicated learning machines generate passive unresponsive state faced novel radically changed environment well outside prior training sets. takes long time learning machines master training sets learning machine instantly master training corresponding radically altered environment. consequently learning machines ﬂounder faced novel inputs well outside existing training set. paper using broad deﬁnition learning machine machine optimized particular environment whether evolutionary selection training learning iterated human design generalized darwinian algorithm incorporating replication variation selection increasingly machine environment learning machine ﬁtted environment training radical changes training prevent extracting information training set. nothing pass later information processing stages machine generally output null vectors. hence simple learning machine model predicts radically changed environments cause learning machine continually output null vectors exhibit dynamical state essentially appears machine fully operational; cannot process information radically changed environment. dynamical null state learning machine becomes passive unresponsive unaware surroundings. immediately apparent dynamical state learning machine radically changed environment closely mimics predicts explains semantic content human learning machines similar situations. emphatically writing subroutines simulate passivity ﬁnding circumstances render learning machines passive using learning machine response model passivity human learning machines. using dynamical state machine system state predictor semantic content experienced humans similar situations. approach supports systems reply chinese room argument. another important aspect approach human brains learn without external designers optimizing details neural architecture. humans designer chooses number neural modules used number neural layers neurons activation functions network data representations used learn function. network architectural choices radically eﬀect operation neural network—an unstructured learning task backing lorry learned signiﬁcantly faster smaller network using external programmers decompose task subproblems also possibly formation appropriate representations lies heart human high-level cognitive abilities understanding draw meaning world external designers impose high level representations network might well prevent modeling high level cognitive abilities. paper model learning machines trainers lack external designers. machines determine modular structures decide number neural layers neurons devote task formulate high level data representations. likely make mistakes mistakes used model mistakes made development human neural networks. neurons assigned machine unable either learn task generalize many neurons assigned machine overﬁt task also unable generalize. speciﬁc example consider learning machine human must learn acquire data environment developing application programming interfaces read today’s temperature machine human might learn move visual input system certain position locate particular rectangular shape correlate mark number. apis generally speciﬁc particular hardware environment implying radical environmental change render apis inoperative destroy machine’s input output channels. also task machines learning multiple functions simultaneously recurrently passing information function another implement sequential processing. accomplish this machine must environmental information deﬁne equivalents subroutine names function names variable names memory data addressing schemes usual control structures like conditional tests loop counters. essentially learning machine must invent computational architecture dedicated programming language solely interactions trainer environment. diﬃcult task expected environmental data inappropriately populate aspects learned architecture. means radically changed environment expected destroy learned computer architecture programs. approach learning machine faced radical environmental change attempting barely functional program code exhibit passivity hesitations repeated loops glitches stutters humans. generated null dynamical state never learned pre-programmed humans state provides model semantic experiences humans situations. ﬁnal part modeling approach notes learning machines respond radically altered environments three main ways. first learning machine might seek restore environment original condition. second learning machine might embark lengthy diﬃcult retraining environment. finally machine might adopt easier approach changing input data coming altered environment back form suitable processing original network. words machine might spoof alter input data allow processing changed environment original network paper three possible responses initial stimulus unexpected environmental change used predict explain semantic experiences humans similar circumstances. considering chinese room responds radically changed environment worthwhile examining simpler systems. consider model learning machines receive input data packets environment process recurrently address across network diﬀerent functional modules sequential program complete. ﬁrst example consider post oﬃce often used introduction packet switched computer networking post oﬃce using optical sensors sort envelopes might well stop working spectrum room lighting changed. machines internally fully functional unable work changed environment system stop enter null dynamical state. restarting system involve either ﬁxing room lighting return environment original state changing machine’s optical sensors suit environment spooﬁng sensors using ﬁlters allow original machine process information environment. internet undergoing designed shift addressing protocol e.g. ...) internet protocol parts internet using older protocol operate environment either forcing entire internet return protocol updating protocol spoofing incoming outgoing packets either using dual stack routers capable handling protocols using network address translation tunneling embedding schemes third example considers cellular signal transduction network uses many molecular interactions implement combinatorial logic functions alter protein production dynamics change cell salinity might alter eﬃcacy signaling pathway repaired either returning salinity normal re-evolving entire pathway suit changed salinity perhaps introducing medicine molecules alter existing molecular binding sites suit changed salinity conditions restore function. ﬁnal example consider bureaucracy exchanging memos information packets across network. every large organization history faced challenge authenticating memos detecting forgeries including modern internet based commerce forged information packet uses spoofed authentication codes subvert normal operation network illicit gain. interesting example occurred last days ching dynasty mother child emperor fooled council regents passing requiring future oﬃcial edicts needed stamp held mother. that regents could issue oﬃcial edicts rescind previous decision return environment initial state could alter state gaining access required stamp could legally spoof forge stamp. result lost power. based discussion possible consider unexpected radical environmental change might chinese room chinese nation simulated nervous system unplanned dynamical state characterized null outputs. systems design respond humans likely exhibit disaster response. applying traditional ideas might presume room encodes syntactical code which implemented within fully functional room causes internally fully functional room externally simulate dysfunctional cognition. starkly conﬁrms merely simulated behaviours carry implications whatsoever internal computational states contrast approach seeks actually duplicate human cognitive dysfunction learning machine model human cognition. chinese room faces disaster pre-existing syntactical code either irrelevant becomes dysfunctional room likely enters null dynamical state. characteristics null state diﬃcult precise short story situation might useful. ﬁrst note program encoded book room would designed ﬁnite possible environments would include fraction possible chinese characters suppose chinese room located within sinking burning ship consequently input slot chinese characters partially ﬁlls water smoke input symbols coming slot burnt smudged unclear entirely chinese characters unknown book program. characters cannot identiﬁed room cannot match characters book left fruitlessly leaﬁng book looking hint symbols process. database still fully functional output symbols produced. alteration input data causes room cease operate separately enter dynamical null state. fully operational cognitively aware instructions anything becomes passive unresponsive. combined man-book system fully operational changed input symbols cannot processed entire system freezes. part frozen dynamical state experience qualia associated state—likely bored. however man’s qualia related qualia experienced chinese room. whether room experiences anything complain boredom. like humans disaster situation chinese room unable process respond meaningfully changed environmental symbols. characteristics room’s dynamical null state suggest room displaying typical disaster response outside observers room appear cognitively impaired dysfunctional lacking direction unresponsive shocked confused. anyone making objective observations components within room i.e. book able make inferences predict explain semantic experiences might experienced chinese room capable. objectively observable dynamical state characteristics also used predict explain subjective semantic experiences humans similar disaster situations. approach agree searle’s claim syntax suﬃcient semantics contend however programs syntax suggested systems reply chinese room. justify claims focusing class human semantic symbols invoked disasters prelearned pre-programmed syntactical programs uncalled. situations humans chinese room exhibit similar dynamical null state whose objectively observed characteristics reminiscent subjective semantic experiences humans situations. goal throughout support systems response chinese room argument non-syntactical non-preprogrammed dynamical states arise unexpectedly within chinese room environment radically changes states give insight human experienced qualia. nagel held every subjective phenomenon essentially connected single point view seems inevitable objective physical theory abandon point view. implication presently available conception gives clue physical theory mind account subjective character experience later levine argued that psycho-physical identity statements leave signiﬁcant explanatory corollary don’t determining exactly psychophysical identity statements true. consequently there seems nothing makes naturally ‘ﬁt’ phenomenal properties pain would phenomenal properties searle raised similar concerns inability bridge subjectiveobjective divide approach argued radically changed environment place learning machine dynamical null state fully functional components become quiescent. argued characteristics dynamical null state predict explain cognitive response humans similar circumstances passive unaware unresponsive cognitively impaired. explicit throughobjectively observable characteristics null dynamical state either machine human used predict explain subjective experience humans similar disaster response circumstances. thus argue objectively observable facts learning machine’s dynamical state used predict explain subjective content humans similar circumstances. thus take steps partially close subjective-objective divide explanatory gap. finally arguing eliminativist materialism dennett summarized normally understood properties qualia ineﬀable intrinsic private directly apprehensible consider model might explain properties. first subjective experiences considered ineﬀable hard describe. person experiencing null dynamical state impaired functionality diﬃcult describe experiences. external observers observing passive unaware disaster response victim non-null states neural networks. observations made external observers richer semantic experiences less replicate victim. observers wish experience null dynamical state alter environment suﬃciently generate null states unfortunately impair ability describe experience. essentially learning list syntactical symbols describing null dynamical state generates diﬀerent non-null dynamical second qualia considered intrinsic atomic unanalyzable. example null dynamical state made concatenation superposition several states rather absence dynamical states. also noted above null state inactivates analytical capabilities. third qualia supposed private. discussed above making observations characteristics null state duplicate experience running null state. learning like null state requires running null state neural system. others observing null state would learn objective facts dynamical state would learn subjective experiences. finally qualia supposed directly immediately apprehensible. cognitive system running null state many aspects operation degraded degradation immediately aﬀects remaining functional units units read syntactical symbols registers compare symbols lookup tables call subroutine mimics certain behaviours. indeed presence null state precludes normal computational steps occurring. cognitive system running null state immediately displays degraded performance associated subjective experience would also immediate. faced radical unexpected environmental change humans become cognitively quiescent— apathetic passive non-responsive forgetful unable process information. model response using learning machines unable process data changed environment likely generate null dynamical states. examine diﬀerent ways generate null dynamical states neural network learning machines ﬁrst part section. second part section enrich model examining neural networks learn implement multiple functions simple programmed sequences speciﬁed environmental data eﬀectively require neural network develop internal computer architecture scratch naturally incorporate environmental data naming addressing conventions control-ﬂow sequencing commands. approach useful humans likewise incorporate environmental information internal computer architecture simple programmed sequenced actions. modeling network’s programming depends environmental factors better able model sophisticated range human responses environmental change. books artiﬁcial neural networks deep learning networks implicitly include dynamical equation governing semi-recurrent feed forward perceptron network something like here show network layers layer taking input environment also possibly recurrently layer assume layer contains neurons. neuron layer output neuron previous layer weighted values input neuron assume implied summation repeated indices. usual neuron’s total input exceeds bias value neuron ﬁre. bias values folded weight matrices usual process adding extra weight neuron equal negative bias assuming additional neuron every layer always active general desire neurons quiescent absence input achieved setting bias values positive absence input neuron remains quiescent. total input neuron nonlinear sigmoid function would generally considered impossible analytically solve dynamical equation interesting networks hundreds millions parameters. argued however even largest sophisticated networks enter known state null dynamical state faced radically changed environment well outside previous training set. novel data cause network like untrained network faced unlearned data produce random noise. unable extract information novel data pass subsequent layers turn layers unable extract process useful information. consequently network enters null dynamical state subsequent layer neurons switches other. irrespective complex network well trained solve network dynamics. mathematically speciﬁed objectively known dynamical state predicts explains subjective cognitive sensations experienced people similar circumstances. generate general dynamical null state downstream regions. zero vector region humans experience dynamical state closing eyes listening silence. seem overly simple ﬁrst analytic models human experience simple. region network untrained weights close zero layer outputs region zero zeros propagate. humans generate experience state simply listening unknown language. humans experience qualia associated absence information processing semantic experience predicted null dynamical state. null states design also seems possible human cognitive system deliberately process information number situations. example vision system doesn’t process data saccades dream experiences fade memory generally unavailable later processing attentional spotlight focused stream data means many streams unattended zeroed. further cognitive system suﬀers limitations impact cognitive processing. example humans fail process environmental information cases information either arrives fast averages zero slowly many neural layers trained identify novelty change cease generate output. either case humans experience ﬁrst case playing fast-paced video game high level experience second case becoming bored perhaps. novel inputs outside training main focus interest humans learning machines fail process novel inputs well outside previous training sets. cannot extract information inputs generate zero output zeros propagate throughout network. generated null dynamical state predicts cognitive experiences humans situations. example process given examine networks implement multiple functions simple programmed sequences speciﬁed environmental information. suppose researchers denoted alice training high capacity recurrent deep neural networks many layers layer consisting many neurons. network eventually required learn implement multiple functions programmed sequences normally requires relatively sophisticated computer architecture control-ﬂow capabilities. human children take years learn enact programmed sequences actions. like human child network sealed black meaning alice unable specify aspect design neural network. instance cannot shrink size particular hidden layer force data compression cost slower learning conversely expand hidden layer size improve learning cost greater chance overﬁtting. researchers cannot specify modular structure connectivity network data encoding formats network sequence control data modules functional units. black alice must face fact network many learning diﬃculties humans learning diﬃculties used model human learning disabilities. required computer architecture designed hardware network learned network software emulation embedded within functions learned network. emulated computer architecture alongside data processed requires addition identiﬁcation sequencing addressing looping control tags processed data vector. illustrate now. first network tasked learn many functions simultaneously. suppose network embodied many input channels machine ability speak write outputs. within machine diﬀerent input data streams addressed software control many diﬀerent functional modules processing combination. layer processing interprets data higher higher level adds information data stream accompanied control tags ensure appropriate downstream processing. embedded control tags within alice’s machine might indicate data stream sourced reality received current time shows alice laboratory holding card containing symbols case network learn process input answer example input-output pairs involving four functions might include second machine need learn implement simple sequential programs. presume machine learned four functions alice start teaching simple mathematical functions e.g. well implement simple sequenced operations speciﬁed input programs e.g. accomplish sequential processing machine need recognize order operator precedence recurrently route input expression machine multiple times order complete evaluation. accomplish this machine need control instructions input data expression ensure appropriate addressing looping termination procedures. human children initially diﬃcult initially trained paper pencil implement controls. association input data control codes essentially data packets containing data processing addressing instructions leads naturally packet-switched network architecture. hypothesizing packet switched learning machine model human cognition follow ref. third presume network associative memory eﬃciently store previous learning sessions recall simultaneous multiple sessions demand assist solving current problems. instance later time machine’s memory generate data stream encodes earlier real input-output packet pattern fourth expect network able apply broad range analytical functions input. instance machine might learn respond questions like alice visible? polling input vision data streams packets time stamped embed alice’s code questions like present? machine might poll processed data streams packets like answer packets exist. questions like alice present time machine might present string like memory trigger associations return packets like packets exist machine might answer yes. seen above machine makes extensive data packets containing data function names control tags though interpreting bits belong category ﬂuid. input packets given above bits could interpreted either plain input data function names control tags specifying later sequential machine operations. number diﬀerent viewpoints possible examining turn suggest embed sequential program within data packets processed neural network diﬃculties arise. ﬁrst viewpoint pattern natural interpretation multi-component function name applied data function name comes directly environment environmental change corrupt learned function names hence machine operation. second viewpoint takes single four-input function learned network four inputs applies currying operation reduce dimensionality fsay+. alternative inputs generate diﬀerent reduced functions becoming fsay−. noted ref. weights neural network normally considered encode single function using currying operators weights instead encode interpreter able reconﬁgure network implement diﬀerent operations control diﬀerent control codes input data like stored program computer. viewpoint makes evident environmental change altering input data packets disrupt machine processing. third viewpoint sees control codes implementing combinatorial logic combining multiple functions learned network selecting example alternatives like incorporating combinatorial logic within function names allows leap computational complexity network—a similar idea used explain increased eukaryotic multicellular complexity single-celled prokaryotes again machine’s controlling combinatorial logic sourced environment makes natural expect environmental change disrupt machine operations. ﬁnal fourth viewpoint recognizes embedding control codes data within single data packet introduces data architecture currently posited pathway exascale computing data packets seen combine operands data packets actioned operands present correct. self-evidently unexpected environmental change mean operands absent incorrect machine become dysfunctional. approaches multitasked neural networks include refs. viewpoints make clear data packets combining data instructions allow complex sequential programming. parsing input data packets machine must learn input data relevant irrelevant task hand. making decisions spectrum possible choices machine might make choice deﬁnitively better others every circumstance. particular machine might assume learned function high generality wide applicability high transferability achieve shortest name possible. given input machine learns ignore inputs give shortest possible name learned function achieve greatest generality. conversely machine could assume learned function highly speciﬁc current locality current teacher achieves longest name possible. given input machine might name learned function function activated alice present laboratory. humans routinely face choice. learning function human students must likewise choose generality speciﬁcity learned functions highly general others speciﬁc location time person. general rule learning machine human often choose incorrectly. again choice lead dysfunctionality topic interest paper. goal examine neural network become dysfunctional facing environmental change. illustrate process considering alice might teach network implement function applied digits inputs like illustrative purposes suppose pattern decimal binary pattern input output decimal binary write decimal binary pattern decimal assume input output numbers standard binary encodings. altogether patterns mappings learned might something like obviously eﬃcient mapping would simply identity input verb write directly output another function input number output number however network large powerful performing random walk around weight space might efﬁcient maps might instead incorporate unnecessary information learned mappings. instance verb mapping might incorporate value input suppose alice trained network personally tested within laboratory shown able write square numbers accuracy. unfortunately learned mappings fail soon location person input strings changed illustrate suppose original altered inputs encodings here note output verb code well formed unable activate output mechanism. naming addressing codes absent formed information subsequent layers. humans learning machines incorporate environmental information within learned functions environmental change destroy learned mappings drive outputs out-of-range functional processes called. human learning machine enter null dynamical state. path forward clear—we suggested multifunctional learning machines often learn functions speciﬁc particular individuals places unexpected environmental change destroy previously learned functions generate dynamical null states. consequently learning machines respond either seeking repair environment relearning changed environment spooﬁng original network addressing schemes allow continued operation altered environment. seek model situations human learning dependent people places environmental change causes cognitive dysfunction leading attempts either repair environment retrain suit environment spoof network. turn model human experiences cognitive symbols transference attachment grief human response grief. example students might diﬃcult transfer trigonometric techniques learned mathematics classroom science classroom fail even recognize trigonometry basis navigation construction methods used outside classroom. suppose that unbeknownst alice many learned functions incorporated location code naming addressing schemes. however never becomes apparent alice testing occurs within laboratory machine fully functional. soon alice takes machine location though many functions could become dysfunctional causing network enter something like dynamical null state. trying understand this alice might return machine original laboratory instantly recovers full capabilities. learning machine duplicates learning transfer diﬃculties faced humans improperly unknowingly incorporated location information function names. environmental alteration invalidate calling functions learning machine enter null dynamical state equivalent blank state experienced humans situations. example student pass trigonometry test within classroom become completely blank asked determine navigational bearing outside classroom. characteristics machine’s dynamical null state predict explain sensations experienced people situations. further model suggests remedies commonly used educators enable learning transfer—alice teachers vary location during learning enable students broadly apply learning. model duplicates human responses situations like classrooms readily generalized cases like culture shock future shock varying locations machine eventually learns location code unrelated function name domain applicability. unfortunately training still leaves machine function names remain dependent code alice result alice absent conducting tests discovered machine’s performance depends alice present. particular suppose alice present machine fully functional machine’s input packets leading bits equivalent bits incorporated many function deﬁnitions. contrast testing machine input packets leading bits equivalent shown previously lead inoperative functions. suppose network’s learned function names incorporated alice code consequently alice present functions called correctly produce correct outputs absent machine’s functionality reduced machine mainly generates dynamical null states. previously machine’s learned functions hardware perfectly operational; environmental change destroys learned machine naming addressing architecture generates dysfunctional null states. sense machine become attached alice. explore idea further suppose alice programmed machine optimize score points awarded correct answer questions. suppose machine noted keeping alice centered ﬁeld view maximizes score learns rotate cameras keep alice centered moves around laboratory. occasions alice asked questions ducking sight behind partition machine noted declining performance learned activating wheel motors keep view resulted increased score. machine might generalize learn wheel motors follow alice leaves room order increase score. might reasonable predict machine seek follow alice everywhere goes extent possible order maintain functionality. machine become overly attached alice stalk alice extent possible. network experience feel nothing lacks capacities. further model leaves complex interplay diﬀerent drivers—the drive attraction attachment—and diﬀerent emotion systems associated speciﬁc hormones neural structures humans however machine attached allowing prediction that attached machine human perform perfectly presence signiﬁcant other exhibit null state signiﬁcant absent. might also predicted machine human might choose perform certain functions partner present avoid activities absent. predicted behaviours routinely observed attached mammals humans prefer company conspeciﬁcs maintain close body contact display separation anxiety attempt restore close contact separation report feelings comfort reduced anxiety contact partner lives deeply interestingly bowlby’s attachment theory models organisms cybernetically controlled complexity ranging primitive organisms possessing reﬂex-like ﬁxed action patterns organisms behaviourally ﬂexible able adapt changes environment. bowlby noted however adaptability exacts price complex organisms easily subverted optimality paper precisely networks suﬃcient complexity learn naming addressing architecture become dysfunctional architecture. alice note network appears attached alice knowing linkages attachment theory bereavement theory decide investigate whether machine might also used model grief. engender state alice hands machine never enters laboratory teach machine. suppose learning machine functionality dependent alice present visible machine becomes largely dysfunctional non-responsive alice permanently absent. bob’s anthropomorphized description grieving learning machine might appears vague vacant undirected unmotivated unable concentrate hopeless impaired. based observations alice able make accurate predictions human response grief loss. might predict grieving humans could experience numbness lack energy emptiness heaviness disorganization withdrawal absentmindedness forgetfulness lack concentration; symptoms noted sect. paper. network exhibit null dynamical state characteristics predict explain qualia experienced grieving humans. ﬁnally note humans never trained grieve—grief arises naturally spontaneously. similarly network never trained programmed grieve symptoms likewise appeared naturally spontaneously. because claim network accurately models duplicates human learning mechanisms rather merely simulating human behaviours. turn model suggests humans learn multiple functions parent partner learning naming addressing architecture incorporates environmental information partners within internal addressing schemes. alice decide machine responds altered environment grieving dynamical state response predict explain aspects human response grief. alice might well reason learning machine might seek restore functionality three diﬀerent ways. either return environment original state replaced alice retrain network functions operate present spoof altered input packets look like original allowing correctly processed unchanged machine. last option merely involves rewriting bits feasible. regard ﬁrst option noted machine indeed maintain alice within environment extent possible perhaps stalking alice maximize score. however alice permanently departed machine cannot avail option. researchers might still predict though based machine’s desire alice return humans suﬀering grief might also pine loved desire return. regard second retraining option alice aware retraining inoperative functions machine take long original training perhaps many months. based this might predict human recovery grief might also involve months slow retraining. finally third option involve making changes either altered environment many functions learned machine. rather option seeks simply spoof altered input packets original processed existing machine without training. alice interested exploring option potentially could save months work. spoof input packets needs provide another source input code learning machine. might ﬁrst photographs alice perhaps causes machine perceive input bits little closer desired might guess machine’s functions become operational— rather dysfunctional machine might dysfunctional. based this alice might predict grieving humans would photographs departed loved ones comforting partial return functionality. refusing give researchers might realize network contains source give high ﬁdelity copy alice’s pattern perceived machine. network’s memory asked recall alice provides memory-tagged time-stamped packets like indicate memory packet contains exact copy string generated alice reality. possible network’s trained functions able access embedded string recover functionality. leads prediction grieving humans might also take comfort remembering departed loved ones memories ease symptoms grief partially restore function. finally alice might consider teaching network single function spoof packets regain functionality. functions learned network readily read write delete alter control tags attached input output data packets. spooﬁng function simply needs strip memory control tags memory packets generate packets memory packets encode memory alice reality altered packets indicate alice present reality. soon packets present within network functionality widely restored approach machine perceives alice present reality. course altering memory tags reality tags something want machine often—if happened routinely wouldn’t able distinguish real remembered. however costs dysfunctional high retraining times long might well beneﬁcial occasionally alter memory reality tag. network internal data packets giving evidence alice currently present room invisible cannot touched. eﬀect network believes presence invisible people i.e. spirits. spoofed network’s perception reality diﬀers reality. machine cannot feel think experience sensations develop dynamical states containing information invisible people exist present room dynamical state instantly allows machine resume full functionality. alice position able predict grieving humans might also learn functions spoof memory data packets come believe invisible immaterial people cannot seen heard nonetheless present. function learned might predicted human achieve almost instantaneous restoration functionality restoration might taken ample justiﬁcation validity learned function. paper modeled class human semantic symbols experienced humans become dysfunctional extreme environmental change. rather fully functional machine merely simulate dysfunctional behaviour duplicated mechanism causing human dysfunctionality. human children don’t spend months learning become attached grieve machines don’t taught functions called attachment grief. rather neural network uses environmental inputs learn computer architecture able implement multiple functions simple sequential programs. environmental information deeply embedded within learned computer architecture natural environmental change disrupts machine operation argued typically generates null dynamical state. characteristics null state predict explain characteristics human experiences environmental change. simplest representation machine learns apply function environmental inputs generate desired output unexpected environmental change moves input well outside machine’s prior training disrupts internal operations suﬃciently generate null dynamical state argued three main ways machine recover. ﬁrst take physical steps restore changed environment back original state regain machine functionality second spend time teaching network function suit altered environment third approach machine learn internal function preprocess convert altered environmental input back original form means internal machine perception environment diﬀers actual environment restores machine operation something like approach relating dynamical state rather syntactical program code cognitive semantic symbols provides concrete example systems reply searle’s chinese room argument. approach symbols static neuron ﬁring patterns dynamical states entire learning machine. this hope partially captured hofstadter’s idea active dynamical symbols underlying aunt hillary’s cognition dynamical state observable mathematically deﬁned objective observations subjective experience partially closed. lastly recognizing learned computer architecture likely exploits packets information containing data control tags able consider diﬀerent changes environment might affect network thus able develop models range human cognitive symbols including transference attachment grief typical responses grief. accomplished small simple model lacking complex abilities mimic humans unable access prior learning facing environmental change. long assumed human cognition complex diﬃcult understand successful artiﬁcial intelligence approach likewise complex diﬃcult understand. assumption reinforces prejudices suspiciously well. however success extremely simple approach implies human cognition simple core moments thought suggests reasonable assumption make. people could design function mappings emulate computer architecture neural networks must learn short years. human cognition likely based simplest possible computer architecture capable implementing multiple functions sequential programs. needless architecture likely highly error prone errors model many aspects human cognition. modeling approach retrodict ﬁrst approximation development human cognitive capacities evolutionary timescales. simple neural networks apply function data need control tags combinatorial logic learned environment. based this would predict simple animals neither exhibit experience attachment grief. complex machines might possess control tags implement simple sequential programs learned environment control tags incorporate enough environmental information machines display attachment grief behaviours. allows prediction animals learn extensively families environment exhibit attachment grief mourning behaviours. expectations seem reasonable. indeed appear simple animals lack complex cognition show attachment grief behaviours complex animals appear possess mind chimpanzees appear exhibit grief mourning behaviours show preliminary indications beginning ritual further archeological evidence appears show small brained hominins going great lengths bury dead showing little indicaeventually however animals become complex oﬀspring learn vast numbers functions capacities families grief might become debilitating evolutionary pressures could favour development spooﬁng ability. predict highly complex machines animals might aﬀected grief becomes beneﬁcial learn spooﬁng functions relieve symptoms grief. machines animals capable control rewriting come believe spirits develop sense spirituality. delinking perceived reality actual reality might allow development enriched symbology feature human cognition. rewrite reality truly creative—an imagined story becomes reality reality becomes imaginary actual histories reimagined stone becomes jewelry becomes love many speculated homo sapiens undertook great leap forward cognitive revolution became behaviourally modern years ago. hypothesized homo sapiens share ﬁctive language ﬁctional stories—money religion political legal structures—become reality possible machine develop illusions mismatch perception reality ﬁrst step developing ability experience qualia here model cognitive leap stemming development spooﬁng ability equivalent control rewrite architecture human cognitive system complement approaches merolla arthur alvarez-icaza cassidy sawada akopyan jackson imam nakamura science towlson vertes ahnert schafer bullmore journal neuroscience wallace tornado worcester exploratory study individual community behavior extreme situation. distaster study number national research council", "year": 2017}