{"title": "Visual-Semantic Scene Understanding by Sharing Labels in a Context  Network", "tag": ["cs.CV", "cs.LG", "stat.ML"], "abstract": "We consider the problem of naming objects in complex, natural scenes containing widely varying object appearance and subtly different names. Informed by cognitive research, we propose an approach based on sharing context based object hypotheses between visual and lexical spaces. To this end, we present the Visual Semantic Integration Model (VSIM) that represents object labels as entities shared between semantic and visual contexts and infers a new image by updating labels through context switching. At the core of VSIM is a semantic Pachinko Allocation Model and a visual nearest neighbor Latent Dirichlet Allocation Model. For inference, we derive an iterative Data Augmentation algorithm that pools the label probabilities and maximizes the joint label posterior of an image. Our model surpasses the performance of state-of-art methods in several visual tasks on the challenging SUN09 dataset.", "text": "consider problem naming objects complex natural scenes containing widely varying object appearance subtly different names. informed cognitive research propose approach based sharing context based object hypotheses visual lexical spaces. present visual semantic integration model represents object labels entities shared semantic visual contexts infers image updating labels context switching. core vsim semantic pachinko allocation model visual nearest neighbor latent dirichlet allocation model. inference derive iterative data augmentation algorithm pools label probabilities maximizes joint label posterior image. model surpasses performance stateof-art methods several visual tasks challenging dataset. human visual system expert parsing complex scene naming objects within human mind navigate complex visual layout objects using lexical semantic knowledge environment precisely identify objects scene? exact mechanisms unknown sharing context based object hypotheses across visual lexical spaces known guiding principles cognition consider famous nighthawks painting figure ﬁrst glance scene hypothesized individual objects person street etc. objects cohere semantically create scene context roadside people effect conﬁdence objects reduce categories become speciﬁc objects appear repeat process updating object hypotheses iterating visual semantic contextual knowledge base. inference conceptualize scene understanding top-down integration lexical visual spaces object names. lexical space vocabulary object names knowledge base visual space maps visual appearances object names. space different contextual relationship objects. lexical space related objects typically appear together given environment visual space related objects visually similar appearance present visual semantic integration model connects semantic visual contexts shared object names. vsim models scene interpretation top-down approach semantically contextual labels ﬁrst created represent coherent scene composition. labels reinterpreted visually contextual counterparts appearance space. speciﬁcally vsim probabilistic hierarchical model latent context observed features. ﬁrst level image modeled distribution latent semantic contexts determines semantic labels compose scene. next level semantic label’s visual context determines appearance features ﬁnally observed variables model. inference vsim initiated bottommanner observed image regions cues used infer semantic visual object labels image. i.e. goal vsim infer semantic object labels image given appearance features. general overview main contributions follows. representing complex scene semantics introduce pachinko allocation model effectively capture semantic hierarchy concepts natural images directed graphical structure. representing visual context propose nearest neighbor based latent dirichlet allocation ﬁnds discriminative visual concepts. nnlda exploits strength nearest neighbor decisions within structured generative approach. infer labels image derive iterative data augmentation algorithm alternates between context spaces correctly pool label probabilities inferred space maximize label posterior image. cess shared context represents novel algorithmic formulation process. mimics cognitive process representing object labels entities shared semantic visual contexts infering image updating labels context switching. signiﬁcant contribution paper conceptually different previous approaches context used mostly ﬁlter reduce false detections. novel approach combined appropriate probabilistic technique inference able surpass stateof-the-art approaches identifying diverse object categories natural scenes. context cognition studied psychophysics linguistics. particularly studies found evidence interactive context network brain facilitates object prediction so-called context frames reference bind visually semantically related objects. swinney’s cross-modal priming task proved lexical access follows multiple hypothesis model listeners accessed multiple meanings ambiguous words even faced strong biasing contexts. ﬁndings provide strong motivation towards modeling interactive context network integrating visual lexical spaces. mapping images related text gaining importance large scale learning images. strand research aimed generating natural language sentences objects inter-relations problem related joint image word sense discrimination encountered image retrieval tasks. works analyzed polysemy images returned keyword searches terms visual senses keywords. however ambiguity tasks lies mostly visual domain since keywords usually static sparse well-deﬁned. hence sense mapping keywords images either abstracted single latent sense picked knowledge sources e.g. wikipedia image text words jointly modeled single latent variable shown results simple correlations effective complex natural scene composed multiple sub-scenes distinct coherency objects within them. thus scene context established hierarchy semantics. single level topic models like latent dirichlet allocation commonly used modeling context images cannot encode relationships. vsim complexity semantic context encoded probabilistic directed acyclic graph topics known pachinko allocation model unlike single level models explicitly models relations among words topics arbitrary nested possibly sparse dependencies. natural scenes enables discovery ﬁne-grained tightly coherent subscenes. figure shows subset semantic context network supertopics subtopics. topics learnt co-occurrence statistics object labels images dataset. labels occur together frequently form strong clusters subtopic space also related subtopics learnt higher level supertopic without explicit hierarchy topic ontologies encoded relations would captured nonsensical topics. figure illustration discovery visual topic manifold {sea river snow water swimpool} nnlda. nearest neighbors capture dense matchings topic manifold captures implicit spatially extended sparse relations labels. hierarchical context networks provide nice framework scene understanding modular separation concepts different granularities. mostly previous work used semantic networks ﬁlters remove incompatible object detections scene visual hierarchy object classes proposed work related topic modeling algorithms scene understanding however models capture overlapping information images text reinforce other. contrast method captures complementary information contexts exploits improve quality inferred labels. best knowledge previous work considered joint inference framework across dichotomous information spaces. given image wish predict objects best image content. vsim models object labels connection different context networks. semantic context labels modeled pachinko allocation model hierarchy semantic supertopics subtopics. visual context labels established visual topics nearest neighbor latent dirichlet allocation intuitively topic distributions encode grouping between labels contexts. brieﬂy give overview approach. figure left predicted object labels using visual context alone right maximum aposteriori labels joint inference middle initial ﬁnal predicted semantic subtopic distribution. latent variable models quantize rich image features visual words facilitate multinomial modeling image data. avoid lossy quantization keeping convenience multinomial inference represent images supervised feature space using bag-of-labels formulation. here feature space spatially clustered using nearest neighbor groupings features bag-of-labels constructed grouping. nearest neighborhood effective ﬁnding dense similarities within geometrically constrained location. however capture implicit spatially extended sparse relations labels. learn relations construct bag-of-labels region perform topic model formulation enables rich feature space projected arbitrary topic manifolds sparse strong visual similarity labels discovered. topic distributions shown figure labels inferred vsim joint inference semantic visual space. derive iterative data augmentation algorithm alternates spaces arrive joint inference. room view illustrates functioning algorithm. left panel shows regions along initial most-likely labels using visual context alone. right panel shows ﬁnal maximum aposteriori labels regions joint inference. middle panel shows initial ﬁnal distributions inferred semantic subtopics. joint inference shows behavior quite similar cognitive process described introduction. labels show increase beliefs cushion curtain. labels updated speciﬁc class e.g. water relabeled sea. ambiguity visually similar labels reduced contextually appropriate labels enhanced. example changed boat since boat visually similar better sea. label probabilities regions don’t context become diffused e.g. hence thresholded out. label probabilities image regions converge semantic subtopic distribution becomes peaky. alternating spaces scene ﬁnally converges bedroom seaview related concepts number images corpus variable number regions image number \u0001-nearest labels image region number semantic supertopics number semantic subtopics number visual topics number object labels semantic super subtopic visual topic sample semantic observed label sample fig. shows plate notation vsim graphical model. core vsim cascade models model generates semantic labels followed nnlda model generates observed labels. context represented topics dirichlet-multinomial distributions labels. hence semantic topic learnt probabilistic group labels co-occur frequently images. visual topic learnt labels similar appearance features thus grouped frequently different bags labels. finally structural hierarchy supertopics subtopics also probabilistically estimated adapting scale parameters subtopic dirichlets based likely paths discovered model. inference derive iterative data augmentation algorithm alternates context spaces correctly pool label probabilities inferred space maximizes label posteriors. concisely inference seeded likely labels based image features alone. achieved passing labels nnlda inference. within iteration label samples drawn current distribution used estimate scene multinomials pam. then semantic multinomials update label distribution. information propagated where distance norm feature space. thus semantic label associated observed labels {l}. induces many-to-many bipartite relation semantic labels observed labels modeled effectively using lda. speciﬁcally topic multinomials capture visual polysemous relation semantic label multiple topics label mixing multinomials capture visual synonymous relation multiple topics observed label generative process follows. learning parameters model annotated images hence known. groundtruth labels ground semantic labels learning semantic visual models become conditionally independent. collapsed gibbs sampling estimating topic distributions context space. back visual model update normalize observed labels image location. collapsed gibbs sampling estimating topic distributions iteration. following provide details parameter estimation inference vsim. model co-occurrence context object labels using three-level pachinko allocation model given image corpus size labels image generated sampling topics levels. per-image supertopic multinomials sampled symmetric dirichlet hyperparameter subtopic multinomials sampled supertopic asymmetric dirichlet hyperparameter role crucial since establishes sparse structure super subtopics. label mixing multinomials subtopic sampled corpus-wide symmetric dirichlet hyperparameter finally label image sampled topic path refer object labels semantic labels. formulate appearance context bag-of-labels representation. achieve this ﬁrst project image regions corresponding labels supervised feature space nearest labels neighborhood. thus groundtruth corresponds observed labels based image features. f··· features image regions feature space corresponding semantic labels lz··· lzr}. bag-of-labels visual topic semantic label number times topic sampled semantic label denotes count observed label assigned topic across entire corpus. intuitive insight counts relate topics labels consider pair labels topic topics would assigned random. means topic consistent observed outlier. high observed label generic appearance matched many objects. signal relevant peaky high implies topic would consistently sampled pair would grouped together. given image vsim model needs compute posterior probabilities semantic labels image region conditioned observed labels distribution containing latent variables follows. second equation ﬁrst term denotes conditional probability given augmented data second term gives predictive likelihood latent data given observations. based dependencies graphical model computed marginalizing follows. formulation leads coupled inference problem. solving need predictive topic probabilities however since link between semantic topics observed passes needs marginalized out. supertopic subtopic assignments zs∼i zt∼i topic assignments remaining labels image. excluding current token count topic image number times subtopic sampled sund pertopic within image denotes number times label assigned subtopic entire corpus. estimating topic hierarchy estimate within gibbs iteration pam. hyperparameter values capture structural links supertopics subtopics. therefore strength connections need estimated data-driven manner. co-occurrence counts super subtopics estimate speciﬁcally moment matching estimate approximate technique model mean variance αsst computed matching sample mean variance topics’ co-occurrence counts across images. step start semantic model. imputed topic samples alongwith learnt semantic parameters {˜θs used generatively draw semantic labels image. average multiple samples used update distribution. semantic label distribution used modulate observed label distribution image region. step return data imputation observed label probabilities. dataset experiment settings evaluate proposed vsim model performing different visual tasks dataset collection natural indoor outdoor images. image contains average different annotated objects average occupancy object image size. frequencies object categories follow power distribution. consider categories. images considered learning models images used testing. learning model annotated ground-truth locations labels provided dataset. test images bounding boxes detected detector image regions decisions. image regions. feature representation image region represented using three types features described color represented normalized histograms means variances length vector. texture captured using -ﬁlter bank textons. codebook textons texton histogram. dense sift features used discriminative patterns using expectation maximization applies posterior sampling. general framework consists iterative sampling framework steps data imputation step current guess posterior distribution used generate multiple samples hidden variables predictive distribution posterior sampling step posterior updated mixture augmented posteriors approximated average thus stationary posterior distribution achieved successive substitution. formally steps represented step begin visual model. create labels image region perform nnlda inference. gibbs proposal inference updates topic assignments labels keeping counts obtained learning phase ﬁxed. region computed number iterations topic sampling completed learnt topic proportions label estimated topic proportions image region corpus wide counts label topic resp. multinomial distribution draw samples used observations semantic model. gibbs proposal inference similar form however topic assignments compare scene detection performance model vis-a-vis groundtruth. ground-truth scene multinomial computed grounding semantic labels groundtruth labels inferring super subtopics. estimate multinomials image regions. symmetric kullback-leibler divergence subtopic multinomials evaluate closely joint inference true distribution. also compare performance baselines correspondence total scene understanding model corrlda models visual words lexical words children topic. implies lexical labels visual features must display similar contextual groupings. models single semantic topic image assumes one-to-one correspondence object labels visual words. implemented supervised versions models compare performance. divergence measures lowest joint vsim model conceptually means model accurately maps visual-semantic space therefore generalizes better test set. algorithmically implies labels predicted joint inference technique closely match groundtruth labels. look conﬁdent labels predicted models verify presence groundtruth. results shown figure performance improves hcontext initial stage joint inference. because unlike hcontext relies outputs ﬁlters incompatible detections tree context able retrieve missed detections visual processing reinforcing later semantics. table shows results baseline generative models. qualitative results shown supplemental material. model representation learnt supertopics subtopics. supertopic dirichlet uniform value subtopic dirichlet learnt parameter estimation. nnlda choose neighborhood radius empirically feature space visual topics learnt. parameter estimation gibbs sampling iterations model. posterior inference topics iterations. imputation step samples generated average distribution. algorithm iterations. ﬁnal label posterior distributions thresholded label retrieval. compare nnlda average precision gain label retrieval table mean gain across object categories objects show positive gain. interesting note objects maximum gain categories training examples dataset e.g. pillow text visually similar frequent categories. contrast objects maximum loss categories distinct appearances e.g. shoes ingots might losing distinctiveness contextual groupings. results highlight nnlda better handling data imbalance problem visually ambiguous objects. figure mean precision object categories sorted training size. precisions every consecutive objects averaged. compared felzenswalb’s detector method much less sensitive training size. table model comparisons showing kullbackleibler divergence estimated groundtruth scene parameters. average accuracy prediction conﬁdent label image. object categories least frequent precisions averaged every objects precision falls quickly size training reduces. contrast method generalizes better performs favorably across object categories. advantage impoverished data richer constraints prevents overﬁtting model. show vsim better handles data-imbalance problem frequently seen many learning problems natural categories follow power distribution. also show precisions objects compare hcontext detector table report precisions false positives image. since model handle fewer training examples consider larger number object categories blanks table correspond objects hcontext gives response. paper presented vsim scene understanding system captures semantics scene visual ambiguities arise mapping image space within single model. explain vsim biologically sound show statistically performs well variety visual tasks. believe vsim maps lexical-visual space accurately sharing label hypotheses semantic appearance contexts hence able generalize well images. future want develop method identify objects learn contexts wild.", "year": 2013}