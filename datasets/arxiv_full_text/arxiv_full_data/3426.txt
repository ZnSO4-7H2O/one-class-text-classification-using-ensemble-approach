{"title": "Knowledge distillation using unlabeled mismatched images", "tag": ["cs.CV", "cs.LG", "stat.ML"], "abstract": "Current approaches for Knowledge Distillation (KD) either directly use training data or sample from the training data distribution. In this paper, we demonstrate effectiveness of 'mismatched' unlabeled stimulus to perform KD for image classification networks. For illustration, we consider scenarios where this is a complete absence of training data, or mismatched stimulus has to be used for augmenting a small amount of training data. We demonstrate that stimulus complexity is a key factor for distillation's good performance. Our examples include use of various datasets for stimulating MNIST and CIFAR teachers.", "text": "mandar kulkarni kalpesh patil shirish karande innovation labs pune india bombay mumbai india {mandar.kulkarnishirish.karande}tcs.com kalpeshpatiliitb.ac.in current approaches knowledge distillation either directly training data sample training data distribution. paper demonstrate effectiveness ’mismatched’ unlabeled stimulus perform image classiﬁcation networks. illustration consider scenarios complete absence training data mismatched stimulus used augmenting small amount training data. demonstrate stimulus complexity factor distillation’s good performance. examples include various datasets stimulating mnist cifar teachers. knowledge distillation process transferring generalization ability teacher model student model hinton demonstrated student network trained using input data combination hard labels well soft labels. hard labels ground truth labels available training data soft labels output teacher network input data. distillation approaches either directly training data device strategy learn training data distribution sample however assumption availability labeled training data always hold true various reasons. paper investigate effectiveness ’mismatched’ unlabeled stimulus training data teacher available. speciﬁcally mnist teacher utilize mismatched stimulus cifar) stl) shape) noise. cifar teacher stimulus tiny imagenettin) mnist shape svhn dtd-texture observe architectures stimuli provide surprisingly efﬁcient distillation student networks. study effect complexity stimulus dataset distillation performance using stimulus varied complexity. experimental results clearly demonstrate complexity stimulus plays important role distillation complex dataset appear give better generalization performance. also consider scenario small labeled training available. cases unlabeled stimulus effective data augmentation. indicates weights student network indicates cross entropy relative weights terms. second term equation corresponds traditional cross entropy loss output student network labels denotes data used distillation. posterior output teacher network posterior output student. ﬁrst term equation attempts make posterior student similar teacher input data training data available second term cannot used. student trained optimize ﬁrst term case availability small labeled training combination labeled unlabeled stimulus train student. unlabeled stimulus assume uniform distribution classes using second term trained dataset approx. params. experiment student architectures. ﬁrst experiment student architecture teacher. second experiment attempt distill teacher network relatively smaller student cnn. student network approx. less parameters teacher. details teacher student architectures provided appendix. mnist teacher mismatched stimulus cifar- stl- shape dataset uniform random noise case cifar data images converted grayscale resized appropriately. train layer cifar dataset approx.m params. well experiment student architectures teacher smaller approx. times less parameters teacher. cifar teacher mismatched stimulus mnist svhn shape texture uniform noise slightly similar dataset tinyimagenet. pointed reviewer subset unlabeled tinyimagenet used cifar distillation caruana however demonstrate result tinyimagenet contain labeled examples belonging classes. observe signiﬁcant overlap classes cifar tinyimagenet. fig. shows performance mismatched stimulus student network architecture teacher. teacher accuracy test best accuracy obtained cifar random stimulus respectively. result seems interesting because though mnist digit dataset mismatched object dataset cifar works well stimulus. fig. shows test accuracy performance smaller student network. shape dataset previously used demonstrating effectiveness curriculum learning bengio dataset consist examples simple shape images. small variability dataset simpler cifar stl. plots fig. seen shape stimulus performs inferior cifar stl. fig. shows result teacher student identical. teacher accuracy best accuracy tinyimagenet stimulus fig. shows performance smaller student cnn. maximum accuracy tinyimagenet cifar teacher additionally perform experiment mnist shape svhn texture datasets smaller student cnn. samples dataset stimulus. table shows result experiment. datasets varied ’complexity’ visually order complexity mnist shape svhn texture tiny imagenet. trend similar figure distillation result mnist cifar teachers. mnist test accuracy teacher student architectures identical mnist test accuracy student smaller teacher cifar test accuracy student teacher cifar test accuracy student times smaller teacher. mnist observed complex dataset performs better relatively less complex stimulus. explored quantiﬁcation approach complexity results reported appendix. though shown results assumption training data mismatched stimulus also effective data augmentation. validate this performed following experiments. mnist teacher used labeled samples mnist augmented unlabeled samples various stimuli. results given table cifar teacher used labeled samples cifar dataset augmented samples various stimuli. table shows results. seen that cases data augmentation helps student generalize better. mentioned bucilu bucilu though collecting synthetic stimulus easy images crucial data match training data distribution. training data available mismatched images surprisingly turn good stimulus. experimental results demonstrate complexity stimulus plays major role complex dataset provides better performance. explored quantiﬁcation approach dataset complexity. small training available unlabeled stimulus also effective data augmentation yoshua bengio j´erˆome louradour ronan collobert jason weston. curriculum learning. proceedings annual international conference machine learning cristian bucilu rich caruana alexandru niculescu-mizil. model compression. proceedings sigkdd international conference knowledge discovery data mining yuval netzer wang adam coates alessandro bissacco andrew reading digits natural images unsupervised feature learning. nips workshop deep learning unsupervised feature learning volume antonio torralba fergus william freeman. million tiny images large data nonparametric object scene recognition. ieee transactions pattern analysis machine intelligence architecture teacher network -maxpool-conv-maxpoolfc-softmax]. architecture smaller student network conv-conv-maxpool-conv-maxpool-fc-softmax]. architecture conv-maxpoolconvconvmaxpool-convconv-maxpoolfc-fc-softmax]. architecture smaller student network conv-maxpool-convmaxpool-convconv-maxpoolconvfc-softmax]. experimented teacher-dnn student scenario similar papamakarios train single teacher mnist data dense softmax]. student hidden nodes compared teacher. perform distillation using cifar normal gaussian noise stimulus. fig. shows result experiment. note that though natural image stimulus works better noise difference performance signiﬁcant case dnn. known initial layers learn generic features edges blobs yosinski since features easily found natural images compared noise images natural images turn better stimulus noise. however since employs full connection hidden layers hidden nodes activated even random noise hence noise performing well teacher reported papamakarios objective function minimize cross entropy loss soft targets teacher student unlabeled stimulus. terminate iterations cross entropy loss cease change. visualize possibility overﬁtting plotted cross entropy loss test accuracy cases mnist teacher using cifar stimulus cifar teacher using texture stimulus. plots shown below. note that test accuracy cross entropy loss settles iterations. even small training size overﬁtting observed. could soft labels used optimization. explored quantiﬁcation approach complexity. suspect stimulus dataset matches convolution ﬁlters well variations work better distillation. validate this performed experiment cifar teacher various stimulus datasets. ﬁrst convolution layer feature maps calculate mean across dataset. also calculate average feature map-wise std. dev. dataset. higher mean value indicates convolution ﬁlters better match dataset high value std.dev. indicates variations.", "year": 2017}