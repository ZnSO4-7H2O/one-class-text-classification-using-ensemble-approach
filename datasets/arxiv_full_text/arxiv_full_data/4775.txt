{"title": "Selective Greedy Equivalence Search: Finding Optimal Bayesian Networks  Using a Polynomial Number of Score Evaluations", "tag": ["cs.LG", "cs.AI"], "abstract": "We introduce Selective Greedy Equivalence Search (SGES), a restricted version of Greedy Equivalence Search (GES). SGES retains the asymptotic correctness of GES but, unlike GES, has polynomial performance guarantees. In particular, we show that when data are sampled independently from a distribution that is perfect with respect to a DAG ${\\cal G}$ defined over the observable variables then, in the limit of large data, SGES will identify ${\\cal G}$'s equivalence class after a number of score evaluations that is (1) polynomial in the number of nodes and (2) exponential in various complexity measures including maximum-number-of-parents, maximum-clique-size, and a new measure called {\\em v-width} that is at least as small as---and potentially much smaller than---the other two. More generally, we show that for any hereditary and equivalence-invariant property $\\Pi$ known to hold in ${\\cal G}$, we retain the large-sample optimality guarantees of GES even if we ignore any GES deletion operator during the backward phase that results in a state for which $\\Pi$ does not hold in the common-descendants subgraph.", "text": "introduce selective greedy equivalence search restricted version greedy equivalence search sges retains asymptotic correctness unlike polynomial performance guarantees. particular show data sampled independently distribution perfect respect deﬁned observable variables then limit large data sges identify equivalence class number score evaluations polynomial number nodes exponential various complexity measures including maximum-number-of-parents maximum-cliquesize measure called v-width least small as—and potentially much smaller than—the two. generally show hereditary equivalenceinvariant property known hold retain large-sample optimality guarantees even ignore deletion operator backward phase results state hold commondescendants subgraph. greedy equivalence search score-based search algorithm searches equivalence classes bayesian-network structures. algorithm appealing ﬁnite data explicitly tries maximize score interest data grows large guaranteed—under suitable distributional assumptions—to return generative structure. although empirical results show algorithm efﬁcient realworld domains number search states needs evaluate worst case exponential number domain variables. paper show assume generative distribution perfect respect deﬁned observable variables known constrained various graph-theoretic measures complexity disregard polynomial number backward search operators considered retaining large-sample guarantees algorithm; call variant selective greedy equivalence search sges. complexity results consequence understanding backward phase edges greedily deleted current state local minimum reached. show hereditary equivalenceinvariant property known hold generative model remove consideration edge-deletion operator property hold resulting induced subgraph common descendants. example know node parents remove consideration deletion operator results common child parents. deﬁne notion complexity call v-width. given generative structure v-width necessarily smaller maximum clique size necessarily smaller equal maximum number parents node. casting limited v-width complexity constraints graph properties show enumerate directly polynomial number edge-deletion operators step show need polynomial number calls scoring function complete algorithm. main contributions paper theoretical. deﬁnition sges algorithm deliberately leaves unspeciﬁed details implement forward phase; prove results sges given implementation phase completes polynomial number calls scoring function. naive implementation immediately return complete graph using calls scoring function choice unlikely reasonable practice particularly discrete domains sample complexity initial model likely problem. whereas believe important direction paper explore practical alternatives forward phase polynomial-time guarantees. paper expanded version chickering meek includes proofs organized follows. section describe related work. section provide notation background material. section present sges algorithm show optimal large-sample limit provide complexity bounds given equivalence-invariant hereditary property holds generative structure. section present simple synthetic experiment demonstrates value restricting backward operators sges. conclude discussion results section useful distinguish approaches learning structure graphical models constraint based score based hybrid. constraint-based approaches typically independence tests eliminate potential models whereas score-based approaches typically penalized likelihood marginal likelihood evaluate alternative model structures; hybrid methods combine approaches. score-based approaches driven global likelihood less susceptible constraint-based approaches incorrect categorical decisions independences. polynomial-time algorithms learning best model node parent. particular chow-liu algorithm used equivalence-invariant score identify highest-scoring tree-like model polynomial time; scores equivalence invariant polynomial-time maximum-branching algorithm edmonds instead. gaspers show learn k-branchings polynomial time; models polytrees differ branching constant number edge deletions. without additional assumptions results learning non-tree-like models negative. meek shows ﬁnding maximum-likelihood path np-hard despite special case tree-like model. dasgupta shows ﬁnding maximum-likelihood polytree np-hard even bounded indegree every node. general directed acyclic graphs chickering shows ﬁnding highest marginallikelihood structure particular prior np-hard even node parents. chickering extend result large-sample researchers often assume training-data generative distribution perfect respect model class order reduce complexity learning algorithms. geiger provide polynomial-time constraint-based algorithm recovering polytree under assumption generative distribution perfect respect polytree; analogous score-based result follows paper. constraint-based algorithm sprites identify equivalence class bayesian networks polynomial time generative structure model observable variables node bounded degree; paper provides similar result score-based algorithm. kalish buhlmann show gaussian distributions algorithm identify right structure even number nodes domain larger sample size. chickering uses dagperfectness-over-observables assumption show greedy algorithm optimal large-sample limit although branching factor worst-case exponential; main result paper shows limit branching factor without losing large-sample guarantee. chickering meek show identiﬁes minimal model large-sample limit less restrictive assumptions. hybrid methods learning models constraintbased algorithm prune large portion search space score-based algorithm select among remaining ordyniak szeider give positive complexity results case remaining dags characterized structure constant treewidth. many researchers turned exhaustive enumeration identify highest-scoring model many complexity results model classes. karger srebro show ﬁnding optimal markov network np-complete treewidth narasimhan bilmes shahaf chechetka guestrin show learn approximate limited-treewidth models polynomial time. abeel koller show learn factor graphs polynomial time. following syntactical conventions paper. denote variable upper case letter state value variable letter lower case denote variables bold-face capitalized letter letters corresponding bold-face lower-case letter letters denote assignment state value variable given bayesian-network model variables pair directed acyclic graph—or short—consisting nodes one-to-one correspondence variables directed edges connect nodes. parameter values specify conditional probability distributions. bayesian network represents joint distribution factors according structure structure bayesian network represents independence constraints must hold distribution. independence constraints implied structure characterized markov conditions constraints variable independent non-descendants given parents. independence constraints follow properties independence. distribution deﬁned variables perfect respect independences distribution equal independences implied structure dags equivalent—denoted g—if independence constraints dags identical. equivalence reﬂexive symmetric transitive relation deﬁnes equivalence classes network structures. denote equivalence class dags belongs. equivalence class dags independence another equivalence class dags independence constraints implied also implied dags denote imap shown verma pearl dags equivalent skeleton v-structures result partially directed acyclic graph— pdag short—to represent equivalence class dags pdag equivalence class dags share skeleton v-structures extend notation equivalence imap relation include general pdag structure. particular pdag denote corresponding equivalence class dags. pair pdags q—where dag—we make standard conditional-distribution assumptions multinomials discrete variables gaussians continuous variables dags independence constraints also model distributions. deﬁnitions skeleton v-structures pdag obvious extensions deﬁnitions dags. denote denote imap avoid confusion remainder paper reserve symbols dags. pdag subset nodes denote subgraph induced nodes edges connect nodes naxy denote within pdag nodes neighbors also adjacent edge compelled exists every equivalent edge compelled reversible. completed pdag pdag additional properties every directed edge corresponding edge compelled every undirected edge corresponding edge reversible. unlike non-completed pdags cpdag representation equivalence class unique. denote parents node edge covered parents exception parent itself. algorithm shown figure performs twophase greedy search space equivalence classes. represents search state cpdag performs transformation operators representation traverse states. operator corresponds edge modiﬁcation scored using scoring function assume three properties. first assume scoring function score equivalent means assigns score equivalent dags. second assume scoring function locally consistent means that given enough data current state imap score prefers edge additions remove incorrect independences current state imap score prefers edge deletions remove incorrect dependences. finally assume scoring function decomposable means cpdag operators scored using differences scoring function limit large data scores positive precisely operators remove incorrect independences incorrect dependences. ﬁrst phase ges—called forward equivalence search fes—starts empty cpdag greedily applies insert operators operator positive score; operators correspond precisely union single-edge additions members current state. after reaches local maximum switches second phase—called backward equivalence search bes— greedily applies delete operators operator positive score; operators correspond precisely union single-edge deletions members current state. theorem cpdag results applying algorithm records sampled distribution perfect respect limit large role large-sample limit identify state theorem holds implementation results imap implementation details important practice because constitutes large amount data depends number parameters model. theory however could simply replace algorithm sets no-independence equivalence class. focus analysis next section modiﬁed version details delete operator used phase important. detail preconditions scoring function transformation algorithm delete operator figure note need make cpdag transformations scoring operators; identiﬁed highest-scoring delete need make transformation shown ﬁgure. applying edge modiﬁcations described foreach loop resulting pdag necessarily completed hence convert corresponding cpdag representation. shown chickering conversion accomplished easily using structure extract section deﬁne variant algorithm called selective ges—or sges short—that uses subset operators. subset chosen based given property known hold generative structure like sges—shown figure —has forward phase backward phase. forward phase sges sufﬁces theoretical analysis method returns imap using polynomial number insert-operator score calls. reason call phase poly-fes. simple implementation poly-fes return no-independence cpdag implementations likely useful practice. backward phase sges—which call selective backward equivalence search —uses subset delete operators. subset must necessarily include π-consistent delete operators—deﬁned below— order maintain large-sample consistency subset include additional operators sake efﬁcient enumeration. either property holds holds neither them. thus equivalence-invariant property makes sense either holds hold pdag. shown chickering property equivalence invariant invariant covered-edge reversals; follows property node parents equivalence invariant whereas property length longest directed path least not. furthermore properties sges must also hereditary means holds pdag must also hold induced subgraphs example max-parent property hereditary whereas property node least parents not. property refer property equivalence invariant hereditary. deﬁnition π-consistent delete delete operator delete consistent cpdag common descendants resulting cpdag property holds induced subgraph postpone proof theorem appendix. result consequence explicit characterization given pair dags edge either reverse delete resulting theorem cpdag results applying sges algorithm records sampled distribution perfect respect property holds limit large proof scoring function locally consistent know poly-fes must return imap sbes includes π-consistent delete operators theorem guarantees that unless positive-scoring operator. section discuss number distributional assumptions theorem limit number operators sges needs score. discussed section assume generative distribution perfect respect graph-theoretic assumptions lead efﬁcient training algorithms. common assumptions used include maximum parent-set size node maximum-clique size among nodes maximum treewidth. treewidth important complexity exact inference exponential measure. associate property assumptions holds precisely satisﬁes assumption. consider constraint maximum number parents node constant then using denote parent size deﬁne property true precisely dags node parents. similarly deﬁne imum treewidth respectively. properties write every holds also holds. words constraining property lowest node clique nodes clique parents easy treewidth deﬁned size largest clique minus graph whose cliques least large also chickering characterizes reverse transformation reversals/additions provides implicit characterization reversals/deletions consider complexity measure called v-width whose corresponding property less constraining previous three somewhat remarkably leads efﬁcient implementation sges. v-width deﬁned maximum pairs nonadjacent nodes size largest clique among common children words v-width similar maximum-clique-size bound except bound applies cliques nodes shared children pair non-adjacent nodes. understanding easy that property corresponding bound v-width illustrate difference v-width complexity measures consider dags figure figure clique size consequently maximum-clique size maximum parent-set size thus large graph nodes algorithm exponential measures efﬁcient. v-width however zero dag. figure hand v-width order property sges need establish eih. equivalenceinvariance follows fact three properties covered-edge invariant hereditary follows corresponding measures cannot increase remove nodes edges dag. although establish treewidth property work omit consideration treewidth sake space. section show generate deletion operators sbes π-consistent deletion operators included furthermore total number deletion operators generate polynomial number nodes domain exponential approach restrict delete operators based sets resulting cpdag particular rule candidate sets hold induced subgraph nodes common children c—and thus subset common descendants know deﬁnition none dropped operators πconsistent. presenting restricted-enumeration algorithm discuss enumerate delete operators withrestrictions. shown andersson cpdag chain graph whose undirected components chordal. means induced sub-graph deﬁned nayx—which subset neighbors undirected chordal graph. useful property chordal graphs identify polynomial time maximal cliques nodes; denote nodes contained within maximal cliques nayx complement shared neighbors respect candidate recall figure preconditions delete include requirement clique. means valid must maximal clique contains entirety thus generate operators stepping maximal clique turn initializing nodes generating operator corresponding expanding subsets nodes note nayx clique enumerating |nayx| operators. show below three properties interest impose bound maximum clique size among nodes given bound know expansion subset clique size greater result operator valid. thus implement operator-enumeration approach efﬁciently generating subsets within clique size allows process clique calls scoring function. addition need enumerate subsets removing clique graph remains clique size greater deﬁne function iltercliques subset cliques remain imposing constraint. function deﬁne selective-generateops shown figure leverage max-clique-size constraint generating operators; algorithm turn used generate cpdag operators sbes. example figure show example cpdag selective-generate-ops various values example single clique nayx thus outer foreach loop initialized empty set. subset size zero empty added algorithm returns. addition empty singleton subsets subsets discuss three properties impose constraint maximum clique among nodes consequently selective-generation algorithm figure used given appropriate bound given imposes explicit bound clique size result member resulting equivalence class node clique least parents argue running sbes domain variables using algorithm selective-generate-ops bound requires polynomial number calls scoring function. clique inner loop algorithm contain nodes therefore generate score operators requiring calls scoring function. cliques maximal considered outer loop. never edges cpdag delete them conclude even decided rescore every operator every edge deletion make polynomial number calls scoring function. discussion fact sbes completes using polynomial number calls scoring function following result full sges algorithm. proposition sges algorithm domain variables given {πs+ runs completion using number calls scoring function polynomial exponential section present simple synthetic experiment comparing sbes demonstrates value experiment used oracle pruning operators. scoring function. particular given generative model scoring function computes minimum-descriptionlength score assuming data size billion records without actually sampling data instead exact inference compute conditional probabilities needed compute expected loss. allows near-asymptotic behavior without need sample data. evaluate cost running algorithm counted number times scoring function called unique node parent-set combination; cached scores away needed multiple times algorithm computed once. figure show average number scoringfunction calls required complete sbes starting complete graph domain binary variables varying values average taken trials corresponding random generative models. variables domain binary. generated structure generative model follows. first enumerated node pairs randomly permuting nodes taking node turn predecessors turn. node pair turn chose attempt edge insertion probability half. attempt added edge create cycle result node parents; edge could added either direction chose direction random. sampled conditional distributions node parent conﬁguration uniform dirichlet distribution equivalent-sample size one. sbes note realize large savings practice runs instead starting dense graph generative distribution must lead equivalence class containing undirected clique subsequently thinned bes. synthesize challenging grid distributions force states clear realistic distributions practice. re-run clique experiment above instead start sbes model results running savings sbes selective greedy equivalence search algorithm sges demonstrated leverage graph-theoretic properties reduce need score graphs score-based search equivalence classes bayesian networks. furthermore shown graph-theoretic complexity properties including maximum-clique size maximum number parents v-width guarantee number score evaluations polynomial number nodes exponential complexity measures. fact approach selectively choose operators hereditary equivalence invariant graph-theoretic property provides opportunity explore alternative complexity measures. another candidate complexity measure maximum number vstructures. although corresponding property limit maximum size clique limits directly size every operator. thus would easy enumerate operators efﬁciently. another complexity measure interest treewidth fact exact inference bayesian-network model takes time exponential measure. results presented general bayesiannetwork learning problem. interesting consider implications results problem learning particular subsets bayesian networks. natural class discussed section polytrees. assume generative distribution perfect respect polytree know v-width generative graph one. implies limit large data recover structure generative graph polynomial number score evaluations. provides scorebased recovery algorithm analogous constraint-based approach geiger presented simple complexity analysis purpose demonstrating sges uses polynomial number calls scoring function. leave future work careful analysis establishes useful constants polynomial. particular derive tighter bounds total number node-and-parent-conﬁgurations needed score operators cpdag caching conﬁguration scores take advantage fact operators remain valid score transformation. express sets variables compactly often comma denote union also sometimes remove comma consists singleton variable often variable name shorthand containing variable node descendant directed path h-descendant refer descendant particular node proper descendant descendant nondeh denote non-descendants node ↓xx...xn shorthand xn}. example denote parpah ents except independence constraints implied structure characterized d-separation criterion. nodes said d-separated given nodes active path given standard deﬁnition active path simple path node along path either converging arrows descendant converging arrows simple mean path never passes node twice. simplify proofs equivalent deﬁnition active path—that need simple—where node along path either converging arrows converging arrows words instead allowing segment included path virtue descendant belonging require path include sequence edges descendant back again. readers familiar celebrated bayes ball algorithm shachter testing d-separation expanded deﬁnition active path simply valid path ball take x⊥⊥gy|z denote assertion imposes constraint variables independent variables given variables z.when node along path direction terminal edge active path—that ﬁrst last edge encountered traversal path other—is important determining whether append active paths together make third active path. path terminal edge incident oriented toward similarly path terminal edge incident oriented toward path endpoint path using following result chickering combine active paths together. lemma s-active path s-active path either path concatenation s-active path given imap d-separation criterion general ways proofs. first identify d-separation facts hold conclude must also hold second identify active paths conclude must corresponding active paths many proofs would like reason independence facts hold without knowing structure makes using d-separation criterion problematic. described pearl independence facts characterized d-separation criterion also respect independence axioms shown figure axioms allow take independence facts unknown derive independence facts know must also hold throughout proofs often symmetry axiom implicitly. example a⊥⊥b might claim b⊥⊥a|c follows weak union opposed concluding a⊥⊥b|c weak union applying symmetry. frequently identify independence constraints conclude hold without explicitly justifying example composition axiom states independent individually given independent jointly. sets independent apply composition axiom repeatedly combine together. simplify combination implicitly assume composition axiom deﬁned generally. thus example might have x⊥⊥y every conclude composition axiom x⊥⊥y|z. intermediate result deletion lemma given dags edge deletable respect results removing edge deletable simply deletable dags respectively clear context. following lemma establishes necessary sufﬁcient conditions edge deletable. lemma dags edge deletable respect ⊥⊥gx|pah proof resulting removing edge. only follows immediately given independence implied show every node every node nondeh indeholds need conpendence a⊥⊥gb|pah sider pairs descendant descendant relationship changed know independence holds virtue fact deleting edge results strictly independence constraints. induction step assume lemma holds nodes whose longest path consider longest path consider parent node descendant longest path must else path longer descendant also descendant else would descendant thus every parent conclude intermediate result deletion theorem deﬁne pruned variables h—denoted prune– subset variables remain repeatedly remove graphs common sink nodes parents graphs. prune denote complement note every node parents children g-leaf denote node children. g-leaf h-lowest g-leaf proper descendant g-leaf note discussing dags case leaf nodes leaves lowest avoid ambiguity often preﬁx common graph concepts emphasize speciﬁc referring. thus vastly simplify notation remainder proof assume case therefore leaf node highest child restriction vacuous. case know else would edge adjacent contradicting leaf non-parents must also non-descendants hence l⊥⊥gx|pag follows every deletable must {pah exist else would prune. case show least properties must hold. assume ﬁrst property hold demonstrate properties must hold. ﬁrst property hold know either exists edge parent exists edge parent thus pre-conditions least remaining properties must hold. suppose contains edge parent conclude immediately corollary either deletable suppose contains edge parent containing parents parents non-empty. shared parents a↓rl remaining non-l parents node child descendant lest contains cycle know contains following independence constraint must hold intuition behind following lemma h-lowest g-leaf v-structure real terms dependences independent node remain independent condition singleton descendant even also descendant lemma stated somewhat complicated manner want adjacent edge known deletable adjacent. also convenient include addition non-x parents arbitrary additional nondescendants lemma h-descendant h-lowest g-leaf nondeh proper h-descendant proof simplify notation assume lemma hold thus ⊥⊥gx|r consider -active path because ⊥⊥gx|r path cannot active without conditioning means must path must collider every position occurs. without loss generality assume occurs exactly collider along path sub-path along sub-path along proper descendant descendant h-lowest g-leaf know cannot g-leaf else would lower means directed path consisting least edge g-leaf node along path else could splice path resulting path would remain active withz conditioning set. note means similarly path cannot cannot belong reach else could combine out-of-z path respectively r-active path know must non-descendant else would lower g-leaf contains parents none descendants cannot know contains independence ⊥⊥hl|x argued path pass means constitutes out-of -active path combined produce -active path yielding contradiction. next lemma considers collider either edge edge deletable. lemma states remain independent conditioning common child—where non{x parents three nodes also conditioning set—then edges must deletable. lemma edges z↓xy x⊥⊥gy |pah z↓xy least following must hold z⊥⊥gx|pah proof {pah z↓xy parents parents z↓xy parents using notation re-write conditions lemma proof highest common descendant lowest descendant parent descendant parent know either adjacent directed path connecting them; case contained path would higher common descendant means either case case case given explicitly statement lemma case thus independence holds markov conditions non-descendant cases know directed path know dx↓dy non-descendants thus conditioning equation given equation equation apply lemma conclude either z⊥⊥gdy |pah z↓dy hence deletable z⊥⊥gdx|pah z↓dx hence deletable corollary h-lowest g-leaf h-highest child exists edge adjacent either deletable proof equal h-lowest g-leaf satisﬁes requirement statement lemma highest child cannot descendant thus satisﬁes requirement statement lemma proof lemma choose highestcommon descendant corollary follows noting highest h-child must lowest parent thus choose proof common descendant know lemma must another deletable edge proper descendant thus satisfy conditions respectively statement lemma lower before. acyclic repeatedly apply argument must reach edge endpoints common descendants. proof consider theorem know exists either covered edge deletable edge reverse covered edge resulting closer terms total edge differences therefore must eventually reach theorem identiﬁes deletable edge edge satisﬁes preconditions corollary thus know must also exist deletable edge common descendants prune. results deleting edge delete operator corresponding every edge deletion every know must operator delete—when applied c—results deletable operator satisﬁes imap requirement theorem. remainder proof demonstrate πconsistent. directed edges compelled edges must exist orientation dags follows subset common descendants must also common descendants common descendants pruned subgraph know contained entirely complement means except edge conclude consider induced subgraph expanding graph include adjacent because acyclic edge must directed either node descendant nodes complement edges must also exist conclude complete proof note hereditary must hold proposition know therefore equivalence invariant holds", "year": 2015}