{"title": "Cyclic Causal Discovery from Continuous Equilibrium Data", "tag": ["cs.LG", "cs.AI", "stat.ML"], "abstract": "We propose a method for learning cyclic causal models from a combination of observational and interventional equilibrium data. Novel aspects of the proposed method are its ability to work with continuous data (without assuming linearity) and to deal with feedback loops. Within the context of biochemical reactions, we also propose a novel way of modeling interventions that modify the activity of compounds instead of their abundance. For computational reasons, we approximate the nonlinear causal mechanisms by (coupled) local linearizations, one for each experimental condition. We apply the method to reconstruct a cellular signaling network from the flow cytometry data measured by Sachs et al. (2005). We show that our method finds evidence in the data for feedback loops and that it gives a more accurate quantitative description of the data at comparable model complexity.", "text": "propose method learning cyclic causal models combination observational interventional equilibrium data. novel aspects proposed method ability work continuous data deal feedback loops. within context biochemical reactions also propose novel modeling interventions modify activity compounds instead abundance. computational reasons approximate nonlinear causal mechanisms local linearizations experimental condition. apply method reconstruct cellular signaling network cytometry data measured sachs show method ﬁnds evidence data feedback loops gives accurate quantitative description data comparable model complexity. central question arises many empirical sciences discover cause-eﬀect relationships between variables measured data. knowledge causal relationships essential order predict system react interventions perturb system natural state useful many practical applications. example biology problem predicting silico signaling pathway cell react vitro treated certain chemical compound. ability reliably make causal predictions concrete example multivariate proteomics data measured analyzed sachs using cytometry abundances biochemical compounds measured single human immune system cells various experimental perturbations. sachs reconstructed underlying signaling network learning bayesian networks data. reconstruction turned close well-established consensus network obtained manually combining results many diﬀerent experiments eﬀort taken decades. consensus network contains expected causal relationships. sachs found unexpected causal relations obtained reversed relationship. however recover three expected causal relationships. sachs hypothesized three missing causal relationships involved feedback loops. bayesian networks acyclic deﬁnition could explain found method. additional support hypothesis found simple inspection data already shows strong evidence presence feedback loops. later work authors proposed heuristic method causal discovery takes account possibility feedback. alternative approach dealing cycles proposed schmidt murphy common feature causal discovery methods applied protein data work discretized data although measurements continuous-valued data preprocessed discretization three coarse categories argue discretization data preprocessing step avoided possible throws away much information data could useful causal discovery. recently several methods proposed causal discovery continuous-valued observational data exploiting independence estimated noise input similar ideas also studied cyclic case recently cyclic methods deal hidden common causes combination observational experimental data proposed however none methods directly applicable data among others model interventions diﬀerent way. interventions performed sachs change activity compound abundance therefore standard formalism interventions applicable. sachs itani propose diﬀerent ways modeling interventions exploit fact data discretized. eaton murphy consider diﬀerent possible intervention types learn interventions data instead using biological background knowledge eaton murphy conclude data best explained assuming interventions speciﬁc originally assumed sachs multiple compounds simultaneously work oﬀer alternative explanation assume interventions speciﬁc interventions change activity compound addition feedback loops increase impact intervention. goal work develop practical method analyzing data sets protein data collected sachs method propose start throwing away information works directly original continuous-valued measurements. expect feedback loops play prominent role biological networks also drop assumption acyclicity. another feature method distinguishes many existing approaches assume linearity causal mechanisms allow nonlinearities. finally propose natural opinion realistic modeling activity interventions. section describe modeling assumptions detail. first data form snapshot dynamical process individual cell multivariate measurement done single point time. therefore assume cells reached equilibrium measurements performed approximation necessary light absence time-series data. assume equilibrium data described structural causal model also known structural equation model particular observed variables model consists structural equations parents causal mechanism determining value eﬀect terms direct causes disturbance variable representing unobserved causes addition speciﬁes joint probability density disturbance variables following sachs make assumption causal suﬃciency means exclude possibility confounders words assume disturbance variables jointly independent without loss generality additionally assume structure causally suﬃcient visualized directed graph vertices edges depends i.e. exclude possibility feedback loops graph necessarily acyclic contain directed cycles. assume joint value disturbance variables exists unique solution structural equations note assumption automatically satisﬁed acyclic case induces additional constraints cyclic case. assumption implies distribution induces distribution observed variables. induced distribution called observational distribution scm. addition literature typically considers perfect interventions modeled follows intervention forces variable attain value adapted replacing structural equation equation leaving aspects invariant. particular distribution disturbance variables stays same; however structural equations changed induced distribution observed variables changes interventional distribution denperfect interventions correspond case signaling network data interventions change abundance compound. however many interventions actually performed directly change abundance rather activity i.e. extent inﬂuences abundances compounds. original paper model activity interventions following activity compound inhibited actual measurements replaced value whereas compound activated actual measurements replaced value high. approach throw away data also depends discretization data. later work model interventions diﬀerent split variable parts xint assigned value corresponding intervention represents abundance compound measured interventional experiment. modiﬁed graph corresponding intervention outgoing arrows become outgoing arrows xint instead incoming arrows approach longer throws away data still requires coarse discretization data. causal mechanism diﬀerent function whereas aspects remain invariant. context causal mechanism unknown learn data. particular background knowledge provided sachs speciﬁes whether activity intervention inhibitor activator. assumed linearity theory could proceed modeling causal mechanisms nonparametric nonlinear functions e.g. gaussian processes computational reasons however linearize causal mechanisms locally around average figure even though causal mechanism stays invariant linearization around equilibrium changed. case even nonlinear causal mechanism cannot data well. another structure assigning diﬀerent causal mechanisms conditions better data. subset parameters corresponding causal mechanism i’th compound using bayesian approach multi-task learning couple learning problems imposing prior causal structure scm. hypothetical structure always constrains structure sense consider various choices couple nonzero parameters location scale parameters across experimental conditions. compound prior introduces couplings conditions causal mechanism intervention change another function ˜fi; whether mechanism change happens depends experimental condition hypototal number diﬀerent causal mechanisms compound needed account experimental conditions. take prior couples parameters corresponding causal mechanisms solution propose compromise replaces hard equality constraints prior section soft constraints. idea gaussian process interpret parameters pseudo-data note gaussian process regression necessarily restricted using pairs input output combine data data regarding derivative output respect input dimension given input location. case data actually linearized parameters coupled real data likelihood isotropic squared exponential covariance function small jitter term numerical stability purposes similar prior prior couples diﬀerent determinant factor likelihood couples diﬀerent cannot simply trick solak apply global approximation scheme prior deals well situation figure pseudo-data corresponding local linear models would high probability prior. hand prior strongly penalizes situations figure line intuition causal mechanism cangood model data condition case. given data prior assumptions. principle exact bayesian scoring would yield automatic regularization however posterior distribution intractable approximate given hypoprior assumes relinearizations descendants intervention node required. words causal mechanisms change result intervention input distributions descendant variables assumed change much linearization remains approximately same. hard equality constraints previous prior deal well situation figure here condition could baseline condition could intervention changes something upstream keeps mechanism unchanged. upstream intervention lead change input distribution parents relinearization around average input desirable general. therefore introduce prior allows downstream relinearizations. tried prior allows descendants intervention target independent condition pick parameters baseline parameters observational setting prior yield better results acyclic case prior section cyclic case leads cheating sense prior strongly encourages introduce directed cycle connects variables. then variable descendant variable rected graphs. even though calculating evidence single structure doable exhaustive enumeration scoring clearly hopeless. therefore greedy optimization methods hope important modes posterior causal structures. simple priors structures prior directed graphs prior acyclic graphs priors graphs edges. exact bayesian inference feasible could either select best scoring structure average structures according evidence order obtain predictions. however using approximate inference also stability selection assess stability posterior edge probabilities. data published sachs good test case causal discovery methods several reasons. first high quality data sample multivariate measurement single cell number data points large measurement noise seems relatively low. furthermore knowledge ground truth available helps veriﬁcation results. finally good results already demonstrated acyclic causal discovery methods data interesting purposes shows evidence feedback relationships. figure shows subset data heat map. table describes biological background knowledge diﬀerent experimental conditions reagent added known eﬀect reagent? used subset availhowever discover error published data ﬁrst measurements third experimental condition identical seventh condition informed authors decided ignore issue here. able experimental conditions. figure shows whether interventional distributions signiﬁcantly diﬀerent observational distribution variable experimental condition. figure shows scatter plots data diﬀerent experimental conditions. note almost perfect linear relationship log-abundance condition implies measurement noise must relatively small. also shows strong dependence expected consensus network hand note absence dependence erk. assuming consensus true example faithfulness violation. data actually shows faithfulness violations makes causal discovery challenging furthermore note intervention changes concentration. assuming consensus causes true example feedback. another example feedback changing activity results change abundance itself. finally ﬁgure shows aspect data censored detection limit measurement device table experimental metadata conditions used inferring causal structure. information type intervention used background knowledge causal discovery. intervention none inhibits activity inhibits activity inhibits abundance inhibits activity changes pip/pip mechanisms activates activity activates activity figure consensus network according sachs reconstruction signaling network sachs comparison consensus network; best acyclic reconstruction edges. black edges expected. blue edges unexpected novel ﬁndings. dashed edges missing. figure subset data sachs color corresponds log-abundance columns correspond compounds numbered subsets correspond diﬀerent experimental conditions lines within correspond data samples negative p-value kolmogorov-smirnov two-sample test comparing data condition observational data color indicates signiﬁcantly diﬀerent distributions mechanisms prior σjitter using smaller values jitter yield signiﬁcantly diﬀerent results increased computation time considerably. figure shows logevidence depends maximum number edges. point plot result greedy optimization diﬀerent random starting point. especially higher numbers edges local maxima structures present often seem global maximum restarts local search procedure. stability selection results constraint maximum number edges shown figure figure strongly regularized acyclic case precise form multitask prior relevant almost identical results obtained linear prior and/or gaussian noise selected edges robust. notice reconstruction shows less similarity consensus network reconstruction sachs however looking closely unexpected edges acyclic reconstruction sees actually explain data quite well. example ﬁnding causes consistent strong change abundance inhibitor similarly unexpected edges reconstruction understood qualitatively combining information figure table figure stability selection results constraint number edges various priors. edge thickness intensity reﬂect probability selecting edge stability selection procedure. table negative log-evidences estimated structures various structure parameter priors comparison negative logevidences consensus structure optimal structure found sachs parameter prior. values units structure parameter prior acyclic linear gaussian cyclic linear gaussian acyclic nonlinear gaussian cyclic nonlinear gaussian cyclic nonlinear non-gaussian acyclic case parameter estimates conditional graph structure robust. cyclic case longer holds parameters often estimated reliably data empirically observed structure estimated graph much robust though. table compare scores structures score consensus structure reconstruction sachs unsurprisingly scores always least good cases improvement considerable. confounders feedback loops expected present. interventions cannot appropriately modeled standard formalism dooperator need modeled anway. furthermore assumptions speciﬁcity interventions unrealistic. finally several strong faithfulness violations seem present. work addresses several issues. analysis conﬁrms hypothesis several feedback loops present underlying system. showed method gives accurate quantitative description data comparable model complexity compared existing methods. interesting question causal point view whether method also gives accurate predictions eﬀects unseen interventions. hope address question future. however likely answered deﬁnately carrying additional validation experiments. observed empirically cyclic case parameters often identiﬁable even though structure observation important implications ability make predictions unseen interventions even though reliable qualitative predictions seem possible eﬀect quantitative predictions depend strongly parameter estimates. parameters cannot estimated reliably data quantitative predictions unreliable well. mean making quantitative predictions hopeless principle though. indeed alternative conclusion could simply experimental data needed order reliably. future work plan compare local linearization approach approximations e.g. fitc also take account information sign activity intervention improve results. finally hope collaborators experimental thank bram thijssen tjeerd dijkstra claassen stimulating discussions. also thank karen sachs kindly answering questions data. supported netherlands organization scientiﬁc research", "year": 2013}