{"title": "When Computer Vision Gazes at Cognition", "tag": ["cs.AI", "cs.CV"], "abstract": "Joint attention is a core, early-developing form of social interaction. It is based on our ability to discriminate the third party objects that other people are looking at. While it has been shown that people can accurately determine whether another person is looking directly at them versus away, little is known about human ability to discriminate a third person gaze directed towards objects that are further away, especially in unconstraint cases where the looker can move her head and eyes freely. In this paper we address this question by jointly exploring human psychophysics and a cognitively motivated computer vision model, which can detect the 3D direction of gaze from 2D face images. The synthesis of behavioral study and computer vision yields several interesting discoveries. (1) Human accuracy of discriminating targets 8{\\deg}-10{\\deg} of visual angle apart is around 40% in a free looking gaze task; (2) The ability to interpret gaze of different lookers vary dramatically; (3) This variance can be captured by the computational model; (4) Human outperforms the current model significantly. These results collectively show that the acuity of human joint attention is indeed highly impressive, given the computational challenge of the natural looking task. Moreover, the gap between human and model performance, as well as the variability of gaze interpretation across different lookers, require further understanding of the underlying mechanisms utilized by humans for this challenging task.", "text": "bstract joint attention core early-developing form social interaction. based ability discriminate third party objects people looking shown people accurately determine whether another person looking directly versus away little known human ability discriminate third person gaze directed towards objects away especially unconstraint cases looker move head eyes freely. paper address question jointly exploring human psychophysics cognitively motivated computer vision model detect direction gaze face images. synthesis behavioral study computer vision yields several interesting discoveries. human accuracy discriminating targets visual angle apart around free looking gaze task; ability interpret gaze different lookers vary dramatically; variance captured computational model; human outperforms current model significantly. results collectively show acuity human joint attention indeed highly impressive given computational challenge natural looking task. moreover human model performance well variability gaze interpretation across different lookers require understanding underlying mechanisms utilized humans challenging task. joint attention core early-developing form social interaction. based ability discriminate third party objects people looking shown people accurately determine whether another person looking directly versus away little known human ability discriminate third person gaze directed towards objects away especially unconstraint cases looker move head eyes freely. paper address question jointly exploring human psychophysics cognitively motivated computer vision model detect direction gaze face images. synthesis behavioral study computer vision yields several interesting discoveries. human accuracy discriminating targets visual angle apart around free looking gaze task; ability interpret gaze different lookers vary dramatically; variance captured computational model; human outperforms current model significantly. results collectively show acuity human joint attention indeed highly impressive given computational challenge natural looking task. moreover human model performance well variability gaze interpretation across different lookers require understanding underlying mechanisms utilized humans challenging task. social species humans remarkably good understanding other's mental states based visual perception alone. recent work social perception done world cartoon like characters meanwhile growing interest understanding non-verbal social interactions real scenes. many developmental studies demonstrated even young infant understand others' mental states observing non-verbal actions nevertheless type visual social understanding poses challenge cognitive sciences computer vision. reason human social interactions occur real scenes agents freely. however complex interactions environment human actions analyzing scenes extremely challenging. addressing challenge encourages inter-disciplinary research cognitive science computer vision. cognitive science perspective advances stateof-the-art computer vision techniques facilitate rigorous studies human's spontaneous social behaviors. importantly \"grounding\" social process onto real images force researchers consider computational challenges absent cartoon worlds. computer vision perspective working cognitively motivated questions lead field move toward human-like rich scene understanding beyond object recognition achieve long-term goal understanding social agency real scenes initial step interpret person's gaze direction window one's mental states. ability foundation human’s joint attention many important social interactions. infants begin develop ability plays important role development communication language early months gaze perception extensively studied human perception since however several interesting contrasts scope existing behavioral studies understanding gaze perception real scenes. first behavioral studies focusing judging whether gaze directly towards observers acuity detecting direct eye-contact high visual angle studies gaze away observers' head possible directions still surrounding close vicinity centered around observer circle visual angle around observer) covers small space scene. secondly almost studies imposed strong constraints looker's gaze behavior fixing head certain pose allowing rotation eyes. certainly helps isolate effects head orientations unclear apply results natural looking scenes looker moves head gaze freely thirdly developmental studies shown gazing towards object important source infant's learning. however research discriminating gaze perception threshold measured asking looker look empty space again different natural realistic situations person's gaze typically oriented object scene. field computer vision head pose gaze estimation studied long time vast majority studies addressed either head pose estimation problem gaze tracking disjoint problems. research areas demonstrate impressive performance separate tasks little done addressing problem detecting direction gaze natural unconstrained scenes observed humans look freely different targets. natural looking settings gaze events towards different targets share head poses different poses share gaze towards target. recent work suggested estimate gaze free-head movements combining depth visual data microsoft kinect sensor. order reduce complexity gaze problem images rectified seen frontal view registering person -specific face model tracking head different poses. however eyes rectification procedure less likely cognitively plausible sets limitation range supported head poses approach also suitable predict direction gaze given images requires head pose information testing. threshold number acuity human’s gaze following skill certainly important also hope evaluate human performance contrasting state-of-the-art computer vision models. critical component study eager know challenging perception natural gaze actually researchers usually good intuition difficulty cognitive process starts reverse-engineer instance people street feel solving differential equation remarkably intelligent acquiring common-sense knowledge -years girl. actually latter much challenging machines learn perspective figure experimental settings. layout experiments consists objects arranged table concentric arcs relative looker position. microsoft kinect rgb-d sensor command screen aligned in-front looker. human subjects positioned side table facing looker noting best guesses looker’s gaze target. kinect sensor provides color image depth image. kinect’s face tracking algorithm provides additional information head pose orientation facial feature locations. cognitive studies would like focus aspects social perception machine still cannot reach human-level performance. addition previous studies employed highly-constrained settings avoid variance experiment. exploring socia perception natural scenes inevitably introduce larger variance results. hope computational models provide explanations variance. perspective machine intelligence computer vision would like model underlying mechanisms gaze following order reach human performance task. provide systems powerful human-like ability scene social understanding. rest paper laid-out follows section describe free-looking task human observers computational models. section introduce appearance-based model able predict gaze direction image. section compare human model performance side side provides valuable data cognitive sciences computer vision. section discuss implications results human machine gaze perception general. free-looking task looker sits chair facing array objects. side table four human observers chairs facing looker trial looker gazes object following command presented monitor laptop located behind observers. action scene recorded microsoft kinect sensor cameras setup looker center object array kinect sensor screen command computer aligned order looker face directly camera every trials. observers' task follow looker’s gaze write best guesses looker's target. object array laid concentric configuration columns consisting objects color number pain object represent object’s column respectively. radius respectively. configuration visual angles every rows given center eyes table. angular difference columns table surface. corresponding visual angle practice visual angles varies given position head computed trial-by-trial basis. left observer position away looker. angle looker's resting face direction direction position position away looker angular distance position position mirror reflections position position center table respectively. figure computational appearance-based model. gaze trials appear-face-eyes model associates face appearance head pose orientation eyes appearance eye-gaze correction offset ground truth gaze direction direction center eyes towards target extracted nearest neighbors face eyes query event. neighbor associated orientation final direction termined weighted average orientations weights correspond neighbors’ similarity query appearance. rendered images histogram gradients descriptors used represent face eyes appearance. robust general purpose image descriptors capture edge texture properties allow spatial tolerance. experiment asian lookers asian observers participated. normal corrected-to-normal vision. observers evenly assigned sections containing blocks. estimate relative contribution head eyes types blocks eyes-visible eyes-invisible looker wore pair sunglasses. block looker gazed object random order trial lasted seconds. looker kept staring target ring sound indicating trial. looker returned resting state watching command computer’s screen. observers rotated positions experiment combination looker -condition position balanced. experiment identical experiment except eyes-visible condition included. caucasian lookers caucasian african-american observers assigned three sections. blocks section. addition formal experiments also invited lookers perform free looking task blocks also recorded rgb-d camera. training data computational models. construct computational model infer gaze direction given image. model rgb-d data used training purposes prediction images given. real world look single point infinite head-eye combinations. final direction gaze determined head orientation correction eyes-gaze. setup final gaze direction known given position trial target head orientation provided sensor. therefore eyes-gaze direction deducted subtracting head-orientation final gaze direction. appear-face-eyes model first associates whole face appearance head orientation corrects final direction gaze associating appearance eyes eyes-gaze offset. compare appear-face-eyes model additional models appear-face model associates whole face appearance directly final gaze direction. model information head pose orientation eyes-gaze appearance disregarded. model capture role whole face appearance detecting final direction gaze; kinect-linear model linear regression model kinect’s head pose orientation final gaze direction. model information face eyes appearance disregarded. model provides reference performance appear face-eyes model trained kinect’s head pose orientation data. appear-face-eyes model based gaze detection method used grayscale image patches faces associated direction vector gaze training face image patches observed associated direction gaze corresponding faces. detect direction gaze query image small similar faces face query image extracted training set. direction gaze estimated weighted average gaze directions associated query face neighbors training set. approach demonstrated full generalization across faces directions gaze. model extends model cope direction gaze associating head orientation eyes-gaze direction image face eyes. kinect’s rgb-d sensor combined microsoft’s face tracking method provides required information need supervised training phase. utilize microsoft kinect’s face tracker extract position orientation head well position several face features whenever human actor looking given target. position target also extracted kinect’s depth image. head target positions calculate eyes -gaze correction difference head orientation final direction regard face center target kinect rgb-d sensor also provides color image extract image patches whole face eyes region. model face appearance associated head orientation eyes region appearance associated eyes-gaze correction target. histograms gradients descriptors representation face eyes appearance quaternions representing orientations. descriptors robust general-purpose image descriptors capture edge texture properties allow spatial tolerance. detecting query gaze event model applied query image follows first image patches around face eyes region extracted appearance descriptors computed. model searches nearest neighbors training face eyes appearances. face orientation estimated weighted average head orientations associated face neighbors weights proportional neighbors’ similarity query face. eyes-gaze correction estimated similarly using neighbors eyes region. note model similar eyes-gaze corrections associated different eyes region appearances relate different face orientations rectify eyes appearance back frontal figure accuracy graphs. horizontal axis represents four different lookers. different bars represent human models’ results. accuracy getting exact column right. accuracy allowing column off. view different head orientations. realistic cognitively plausible approach similar humans experiencing different face appearances different poses observing humans around them. overall performance humans models shown figure performance measured percentage trials humans models correct target column positions. figure presents percentage trials errors larger column row. corresponds visual angle range around true target. results reflect several interesting patterns humans outperform models suggesting humans' gaze perception indeed highly efficient. significant amount across-looker variance. human models much better reading jp's gaze rest lookers showing models actually capture intrinsic variances human performance. humans models errors within range. models performance good compared current reported accuracy similar task contrast eyes-visible eyes-invisible conditions also reveals importance eyes gaze. performance much lower eyes invisible interesting performance difference change suggesting spurious performance reading jp's gaze primarily head -pose instead eyes. addition humans' eye-invisible performance much similar models' performance. using kinect head pose tracking performance eaches human level. challenging appearance-based models using head pose alone using head eyes makes little difference suggesting descriptors used indeed able capture important visual information head pose eyes. figure plots overall accuracy observer s-visible condition. reveals remarkable individual difference varying individual difference gaze perception emphasized previous studies. interesting explore difference impact subsequent social processes. modeling purpose range performance also indicates optimal performance task much higher averaged human performance. figure position effects. averaged accuracy getting column right looker gazes target left column. observes sitting position left side table much accuracy discriminating columns rows. averaged column accuracy looker gazes target right column. observers siting position right side table much accurate discriminating column row. table bias standard deviation. colbias represents bias column direction. colstd represents standard deviation column direction. rowbias represents bias direction. rowstd represents standard deviation dimension. clear models’ standard deviation comparable even smaller human. however bias models much larger inconsistent. positions. figure shows accuracy getting accuracy getting column right target left column right column across different observer positions. observers performs best looker gazing towards direction column accuracy drops significantly viewing direction looker getting towards side view. drop performance occur accuracy. explored results analyzing distributions humans models responses given target. summary statistics chosen bias standard deviation humans models poor performance could large systematic bias large variance. bias measures mean response relative true position. column dimension positive bias defined mean biased toward peripheral looker's visual field dimension positive bias means perceived gaze direction moves downward table depicts bias variance along left-right up-down dimension. really strikes models’ almost good humans. relatively small indicates given actor he/she looks object different blocks models' predictions consistent. makes models' perform worse lack small bias across lookers dimensions bias variances discussed previous studies however since then much attention given small variance gaze perception. contrast human perception computer vision suggests least context free looking small bias difficult achieve. paper explored acuity reading others' gaze free looking task human participants computer vision models. guid lines study keep ecological validity high possible maintaining quantitative precision. ecological validity emphasized results serve understanding social interactions real scenes. straightforward result human accuracy discriminating targets visual angle apart around free looking gaze task. however challenging part project obtain accuracy interpret comparing several computer vision models turns human visual perception achieve remarkable level performance considering computational challenge involved. interestingly comparing model performance eyes-visible eyes-invisible conditions found general-purpose appearance descriptor captures useful information head pose processing eyes region makes little additional contributions. result indicate free-looking paradigm appearance eyes region varies dramatically observer better representation eyes required. representation still capture inter-pose variations since assuming eyes appearance always represented analyzed rectified frontal head pose less likely cognitively plausible. addition also observed significant across-looker variance. humans models much better reading looker gaze. since models good detecting head poses suggests across-looker variance primarily head pose associated target. consistent behavioral data showing difference still present looker's eyes invisible experiment taken together current research shows computational cess human social perception analyzed depth combining cognitive paradigms computer vision. newman scholl psychophysics chasing case study perception animacy. cogn. psychol. vol. sep. baker saxe tenenbaum action understanding inverse planning. cognition vol. dec. tomasello cultural origins human cognition. harvard university press scaife bruner capacity joint visual attention infant nature vol. d’entremont hains muir demonstration gaze following month-olds infant behav vol. premack woodruff does chimpanzee theory mind? behav. brain sci. saxe carey kanwisher understanding minds linking developmental psychology functional neuroimaging. annu. rev. psychol. vol. jan. flom muir gaze-following it’s development significance. mahwah lawrence erlbaum associates gibson pick perception another person’s looking behavior psychol. symons cedrone nishimura what looking acuity triadic gaze gen. vol. schweinberger kloth jenkins looking neural correlates gaze adaptation. neuroreport vol. todorović geometrical basis perception gaze direction. vision res. vol. oct. stiel clifford mareschal adaptation vergent averted gaze vis. bock dicke thier precise gaze following humans? vision res. vol. mar. carpenter movements eyes. london pion limited murphy-chutorian trivedi head pose estimation computer vision survey pattern anal. mach. intell. ieee trans. vol. hansen beholder survey models eyes gaze. ieee trans. pattern anal. mach. intell. vol. mar. cipolla determining gaze faces images image vis. comput. vol. dec. odobez mora person independent gaze estimation remote rgb-d cameras int. conf. image process. russell norvig canny malik edwards artificial intelligence modern approach. ullman harari dorfman from simple innate biases complex visual concepts proc. natl. acad. sci. vol. sep. dalal triggs histograms oriented gradients human detection proceedings computer vision pattern recognition odobez mora person independent gaze estimation remote rgb-d cameras int. conf. image process.", "year": 2014}