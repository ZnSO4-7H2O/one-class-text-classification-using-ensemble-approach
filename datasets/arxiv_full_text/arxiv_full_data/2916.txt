{"title": "Explaining the Unexplained: A CLass-Enhanced Attentive Response (CLEAR)  Approach to Understanding Deep Neural Networks", "tag": ["cs.CV", "cs.AI", "cs.LG", "cs.MM"], "abstract": "In this work, we propose CLass-Enhanced Attentive Response (CLEAR): an approach to visualize and understand the decisions made by deep neural networks (DNNs) given a specific input. CLEAR facilitates the visualization of attentive regions and levels of interest of DNNs during the decision-making process. It also enables the visualization of the most dominant classes associated with these attentive regions of interest. As such, CLEAR can mitigate some of the shortcomings of heatmap-based methods associated with decision ambiguity, and allows for better insights into the decision-making process of DNNs. Quantitative and qualitative experiments across three different datasets demonstrate the efficacy of CLEAR for gaining a better understanding of the inner workings of DNNs during the decision-making process.", "text": "figure examples handwritten digits mnist shown along with decision made dcnn heatmaps used existing visualization methods proposed classenhanced attentive response maps interpreted based heatmaps proposed clear maps. heatmaps used existing approaches show information image works particular decision made proposed clear allows visualization attentive regions interest corresponding attentive levels well dominant class attentive region interest dcnn uses decision-making process. individual color clear represents corresponding dominant attentive class location. correspondence colors dominant classes derived color given bottom. examples evident heatmaps insufﬁcient fully interpret explain decision made dcnn whereas proposed clear maps explain decision-making process effectively multi-factor visualization approach. work propose class-enhanced attentive response approach visualize understand decisions made deep neural networks given speciﬁc input. clear facilitates visualization attentive regions levels interest dnns decision-making process. also enables visualization dominant classes associated attentive regions interest. such clear mitigate shortcomings heatmap-based methods associated decision ambiguity allows better insights decision-making process dnns. quantitative qualitative experiments across three different datasets demonstrate efﬁcacy clear gaining better understanding inner workings dnns decision-making process. recent years seen tremendous success ﬁeld artiﬁcial intelligence particular many recent advances related particular area machine learning deep neural networks dnns shown outperform previous machine learning techniques variety tasks ﬁne-grained classiﬁcation self-driving cars captioning answering questions images even defeating human champions although dnns demonstrated tremendous effectiveness wide range tasks fail often fail spectacularly producing unexplainable incoherent results leave wonder caused make decisions. lack transparency interpretability dnns during decision-making process largely complex nature dnns individual neural responses unlike interpretable decision-making processes decision trees provide little insight actually going adoption industry healthcare defence cybersecurity etc. error tolerance ability interpret understand trust decisions critical. such peer inside made decision tremendous potential pushing towards explainable human expert gains ability understand interpret verify decisions made. recently number researchers exploring understanding interpretation decisions made dnns particular deep convolutional neural networks asking following question based information image dcnn making decision? tackle question much recent work focused understanding decision-making process networks leveraging heatmaps provide information areas image used dcnn make particular decision. approaches produced promising results revealing important decision made dcnn. details regarding relevant works provided section common limitation heatmap-based approaches understanding decision-making process dcnns decision ambiguity gain insight regions interest important making decisions gives insight regions interest important. result methods leave thought process dcnn largely ambiguous. attempt mitigate problem decision ambiguity take step towards explaining unexplained regards decision-making process dcnns introduction class-enhanced attentive response maps beyond existing heatmap-based approaches provide. proposed clear maps allow visualization attentive regions interest corresponding attentive levels dcnns decision-making process also corresponding dominant classes associated attentive regions interest. such compared heatmaps clear maps much effective conveying certain regions interest inﬂuence decision-making process. example shown fig. demonstrate effectiveness proposed clear maps quantitatively qualitatively conducting number experiments using three different publicly available datasets. signiﬁcant body work recent years domain visualizing understanding dcnns. literature broadly divided groups ﬁrst approaches focus understanding global structure trained network second approaches mainly focus understanding decision-making process trained networks speciﬁc instance present work considered belonging second category. relevant work pertaining group explained below global understanding-based methods many methods domain understand decision-making process deep network measuring operating characteristics; example ﬁnding input maximizes response particular neuron measuring network’s invariance certain kinds data augmentation determining global decision structure methods seek image instances database maximally activate particular neurons posterior class probability given network instance-based methods methods based interpreting individual decisions made dcnn particular image instance. speciﬁc instance-based method proposed simonyan using backpropagated partial derivatives class score respect pixel values used create class saliency maps. zeiler fergus proposed deconvolution-based method project activations feature space back input space recursively. however method provide meaning assignments form coherent interpretable pixels. springenberg provided another gradientbased visualization method restricts negative gradients ﬂowing backwards towards input layer leading sharper visualization still without attributing meaning obtained visualization. however study strongly showed efﬁcacy networks global average pooling image classiﬁcation visualization. visually discern unique features particular category image zhou created class activation using dcnns global average pooling layers. class activation also used localising objects within image. bach montavon aimed ﬁnding general approach visualize non-linear classiﬁers leading interesting heatmap generation. recently similar occlusion-based methodology creating heatmaps zintgraf proposed method based multivariate conditional sampling image patches visualize interpret individual decisions dcnns binary saliency maps represent information contributes decision. work instead obtaining feature maps attribute meaning pixel back-projected response input space using class-based approach. also unlike provide heatmaps binary heatmaps correctly classiﬁed samples create clear maps interpretable correctly misclassiﬁed cases. finally compared figure procedure generating class-enhanced attentive response maps. first individual attentive response maps computed class based last layer dcnn. based attentive response maps different types maps computed dominant attentive response shows dominant attentive level location image dominant class attentive shows dominant class involved decision-making process location. finally dominant attentive response dominant attentive class combined produce ﬁnal clear given image. section explains procedure generating proposed class-enhanced attentive response maps. main goal clear maps convey following information attentive regions interest image responsible decision made dcnn; attentive levels regions interest understand level inﬂuence decision made dcnn; dominant class associated attentive regions interest better understand decision made. procedure generating clear maps summarized follows first individual attentive response maps computed kernel associated class backprojecting activations output layer dcnn. based attentive response maps different types maps computed dominant attentive response shows dominant attentive level location image; dominant class attentive shows dominant class involved decision-making process location. finally dominant attentive response dominant attentive class combined visually using color intensity produce ﬁnal clear given image. inspired effectiveness all-cnn different datasets leveraged similar network architecture building dcnn used classiﬁcation paper. while clarity describe procedure computing individual attentive response maps based all-cnn architecture procedure generalize dcnns provided class-speciﬁc responses computed input space. all-cnns composed primarily convolutional relu max-pooling layers. towards output dcnn last convolutional layer contains kernels equal number classes global averaging performed passing energy values softmax output layer represents categories. such kernel thought associated particular class. ﬁrst step clear compute individual attentive response maps classes learned dcnn denote number classes. achieved current realization clear back-propagating responses kernel last section illustrate efﬁcacy clear maps understanding interpreting decision-making dcnns. conducted qualitative quantitative experiments three different datasets commonly used benchmarks mnist street view house numbers stanford dataset following section explain experimental setup. setup conduct experiments three different datasets trained three different dcnn architectures convolutional layers. training mnist svhn network architecture similar shown perform effectively variety datasets. train networks used default train test split. achieved accuracy mnist svhn datasets respectively. training stanford dataset used layer pretrained imagenet. modiﬁed slightly removing last fully-connected layers augmenting convolutional layers end. ﬁne-tuned last layers using stanford dataset. mnist svhn default train test split applied dataset instead took different classes training. made decision would arduous task interpret classes. ﬁne-grained classiﬁcation task achieved accuracy classes whereas state-of-the dataset classes three networks last layer linearly connected softmax activation function kernel considered represent separate class. important note understand interpret decision trained network; hence strive achieve best architecture state-of-the results dataset. using previously mentioned setup conducted following experiments. convolutional layer feature space input space form attentive response thus extending upon idea ﬁrst introduced explain formulation formation clear maps ﬁrst consider single layer dcnn. deconvolved output response single layer kernel weights deconvolution output response layer obtained convolving feature maps kernels summing represents convolution operation. notational brevity combine convolution summation operation layer single convolution matrix hence equation denoted glzl. multi-layered dcnns extend formulation adding additional un-pooling operation described thus calculate deconvolved output response feature space input space layer multi-layer network clear maps speciﬁcally calculate output responses individual kernels last layer network. hence given network last layer containing kernels calculate attentive response map; class-speciﬁc kernel last layer given individual attentive response maps compute dominant attentive class ﬁnding class pixel maximizes attentive response level across classes given dominant attentive class compute dominant attentive response selecting attentive response level pixel based identiﬁed dominant class expressed follows figure example images mnist dataset. represents sets examples digit correctly classiﬁed example misclassiﬁed example example consists original image heatmap results clear maps. color shows associations different colors respective classes clear map. experiments ﬁrst create binary heatmaps proposed clear maps individual images three different datasets. binary heatmaps represent information image used true class versus image classes classiﬁcation. binary heatmaps formed overlaying output response kernel representing true class regions response rest kernels last layer represented green regions. response rest kernels formed performing operation across individual output responses. thus binary heatmaps regions green regions represent information actual class respectively used decision-making network. binary heatmaps constructed similarly clear formation explained section fig. svhn stanford datasets also create additional binary map. replaces varying values binary heatmaps constant value. binary blue regions represent information used class respectively. create maps visual clarity sometimes harder visualize green regions binary heatmaps. mnist randomly chosen results mnist dataset shown fig. ﬁgure shows examples correctly classiﬁed misclassiﬁed examples network. results observations made looking example sets digit although positive support contributed bottom curved features examples case image correctly identiﬁed zero. looking clear maps dominant activations correctly classiﬁed example corresponds class whereas misclassiﬁed case correspond class similarly digit difﬁcult interpret decision output dcnn looking clear maps make interpretable. svhn presented similarly mnist dataset results obtained svhn dataset shown fig. interesting observations follows misclassifed digit heatmap overwhelmingly focuses correct curves; network still misclassiﬁes counterintuitive human interpretation. observing clear maps almost strong activations classes digit difﬁcult interpret binary heatmaps positive kernel focuses digit still correctly classiﬁes digit high conﬁdence. observing clear maps dominant activation focus areas belong digit including ones digit stanford dataset results stanford dogs shown fig. observations following binary heatmaps used strong identifying features different classes shown fig. ﬁgure rightmost misclassifed cases present interesting observation. observe network misclassiﬁes chihuahua breed shiz-tzu ridgefigure correctly classiﬁed misclassiﬁed images svhn dataset. represents sets examples digit example consists original image heatmap results binary clear respectively. color shows associations different colors respective classes clear map. back breed afghan hound. happens even positive kernels associated respective true class focus strong discriminating features identiﬁed correctly classiﬁed images left. fig. clear maps show chihuahuas strong activations shih-tzu whereas ridgeback activations stronger afghan hounds. based results observations evident binary maps enough interpreting explaining individual decision outputs network. strong motivation class-based maps clear maps effective understanding interpreting classiﬁcation decisions made dcnn. periments. ﬁrst experiment removed parts image except regions responsible activations kernel associated class image call regions strong features associated class. mnist dataset replace digit background svhn dataset replace region gray patch. second experilearning case possible fully convolutional nets approach extended used different network architectures different response methods layer-wise relevance propagation deep taylor decomposition prediction differential analysis work novel approach better understanding visualizing decision-making process dnns introduced form class-enhanced attentive response maps. clear maps designed enable visualization areas interest predominantly inﬂuence decision-making process also degree inﬂuence well dominant class inﬂuence areas. multi-faceted look decision-making process allows better understanding certain decisions made dcnns compared existing heatmap-based approaches. experiments using three different publicly available datasets performed show efﬁcacy clear maps quantitatively qualitatively. furthermore demonstrated strong areas interest identiﬁed clear maps play pivotal role correct classiﬁcation class. future work explore extending clear facilitate scenarios characterized large number classes well exploring clear different network architectures.", "year": 2017}