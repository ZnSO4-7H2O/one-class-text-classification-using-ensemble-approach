{"title": "One-Shot Generalization in Deep Generative Models", "tag": ["stat.ML", "cs.AI", "cs.LG"], "abstract": "Humans have an impressive ability to reason about new concepts and experiences from just a single example. In particular, humans have an ability for one-shot generalization: an ability to encounter a new concept, understand its structure, and then be able to generate compelling alternative variations of the concept. We develop machine learning systems with this important capacity by developing new deep generative models, models that combine the representational power of deep learning with the inferential power of Bayesian reasoning. We develop a class of sequential generative models that are built on the principles of feedback and attention. These two characteristics lead to generative models that are among the state-of-the art in density estimation and image generation. We demonstrate the one-shot generalization ability of our models using three tasks: unconditional sampling, generating new exemplars of a given concept, and generating new exemplars of a family of concepts. In all cases our models are able to generate compelling and diverse samples---having seen new examples just once---providing an important class of general-purpose models for one-shot machine learning.", "text": "humans impressive ability reason concepts experiences single example. particular humans ability one-shot generalization ability encounter concept understand structure able generate compelling alternative variations concept. develop machine learning systems important capacity developing deep generative models models combine representational power deep learning inferential power bayesian reasoning. develop class sequential generative models built principles feedback attention. characteristics lead generative models among state-of-the density estimation image generation. demonstrate one-shot generalization ability models using three tasks unconditional sampling generating exemplars given concept generating exemplars family concepts. cases models able generate compelling diverse samples— seen examples once—providing important class general-purpose models one-shot machine learning. consider images ﬁgure concepts once understand structure able imagine generate compelling alternative variations concept similar drawn rows beneath box. figure given ﬁrst model generates exemplars. *equal contributions. proceedings international conference machine learning york jmlr w&cp volume copyright author. ability humans one-shot generalization ability generalize concepts given examples. paper develop models possess capacity one-shot generalization—models allow one-shot reasoning data streams likely encounter practice limited forms domain-speciﬁc knowledge applied diverse sets problems. notable approaches incorporate one-shot generalization. salakhutdinov developed probabilistic model combines deep boltzmann machine hierarchical dirichlet process learn hierarchies concept categories well provide powerful generative model. recently lake presented compelling demonstration ability probabilistic models perform one-shot generalization using bayesian program learning able learn hierarchical non-parametric generative model handwritten characters. approach incorporates speciﬁc knowledge strokes formed ways combined produce characters different types exploiting similar strategies used humans. lake capacity one-shot generalization demonstrated bayesian programming learning challenge neural models’. combining representational power deep neural networks embedded within hierarchical latent variable models inferential power approximate bayesian reasoning show challenge overcome. resulting deep generative models general-purpose image models accurate scalable among state-of-the-art possess important capacity one-shot generalization. deep generative models rich class models density estimation specify generative process observed data using hierarchy latent variables. models directed graphical models risen popularity include discrete latent variable models sigmoid belief networks deep auto-regressive networks continuous latent variable models non-linear gaussian belief networks deep latent gaussian models models deep networks speciﬁcation conditional probability distributions allow rich non-linear structure learned. models shown number desirable properties inference latent variables allows provide causal explanation data used explore underlying factors variation exploratory analysis; analogical reasoning related concepts e.g. styles identities images naturally possible; missing data imputed treating additional latent variables capturing full range correlation missing entries missingness pattern; models embody minimum description length principles used compression; models used learn environment-simulators enabling wide range approaches simulation-based planning. principles central approach feedback attention. principles allow models develop reﬂect principles analysis-by-synthesis analysis observed information continually integrated constructed interpretations analysis realized attentional mechanisms allow selectively process route information observed data model. interpretations data obtained sets latent variables inferred sequentially evaluate probability data. construction introduce internal feedback model allows ‘thinking time’ information extracted data point effectively leading improved inference generation generalization. shall refer models sequential generative models. models draw composited variational auto-encoders existing models class develop general class sequential generative models incorporates latent variable models variational auto-encoders. contributions develop sequential generative models provide generalization existing approaches allowing sequential generation inference multi-modal posterior approximations rich class deep generative models. demonstrate clear improvement combination attentional mechanisms powerful models inference advancing state-of-the-art deep generative models. importantly show generative models ability perform one-shot generalization. explore three generalization tasks show models imagine generate compelling alternative variations images seen once. attending parts scene ignoring others analyzing parts focus sequentially building interpretation understanding scene natural parts human cognition. successful strategy reasoning also important part many machine learning systems. repeated process attention interpretation analysis synthesis important component generative models develop. general form mechanism allows selectively route information part model another regarded attentional mechanism. attention allows wide range invariances incorporated additional parameters computational cost. attention widely used classiﬁcation tasks shown improve scalability generalization attention used discriminative tasks ‘reading’ attention transforms image representation canonical coordinate space parameters controlling attention learned gradient descent. attention unsupervised learning much recent latent variable models processes—inference generation—that attention though slightly different ways. generative process makes writing generative attention implements selective updating output variables e.g. updating small part generated image. inference process makes reading attention like used classiﬁcation. although conceptually different forms attention implemented computational tools. focus image modelling make spatial attention. types attention randomized error-based discussed appendix spatially-transformed attention. selecting patch image methods powerful approach mechanism provides invariance shape size objects images tang take approach similarity transforms provide basic afﬁne invariance. spatial transformers general method providing invariance preferred attentional mechanism. spatial transformers process input image using parameters generate output aware generative models make spatial transformers way. used reading attention spatial transformers allow model observe input image canonical form providing desired invariance. used writing attention allows generative model independently handle position scale rotation parts generated image well content. direct extension multiple attention windows simultaneously generative models latent variables describe probabilistic process observed data point generated. simplest formulations factor analysis gaussian latent variables combined linearly generate gaussian distributed data points complex models probabilistic description consists hierarchy layers latent variables layer depends layer non-linear deep generative models specify non-linear dependency using deep neural networks. compute marginal probability data must integrate unobserved variables deep latent gaussian models prior distribution gaussian distribution likelihood function distribution appropriate observed data gaussian bernoulli categorical distribution dependent non-linear latent variables. models marginal likelihood intractable must instead approximate popular approximation technique based variational inference transforms difﬁcult integration optimization problem typically scalable easier solve. using variational inference approximate marginal likelihood lower bound objective function optimization objective function negative free energy allows trade-off reconstruction ability model complexity posterior distribution variational inference approximates true posterior distribution known family approximating posteriors variational parameters learning involves optimization variational parameters model parameters instead optimization variational algorithm take amortized inference approach represent distribution recognition inference model also parameterize using deep neural network. inference models amortize cost posterior inference makes efﬁcient allowing generalization across inference computations using global variational parameters framework think generative model decoder latent variables inference model inverse encoder observed data latent description. result speciﬁc combination deep latent variable model variational inference implemented using inference model referred variational auto-encoder vaes allow single computational graph constructed straightforward gradient computations latent variables continuous gradient estimators based pathwise derivative estimators used discrete score function estimators used generative models described thus characterized single-step models since models i.i.d data evaluate likelihood functions transforming latent variables using nonlinear feed-forward transformation. sequential generative model natural extension latent variable models used vaes. instead generating latent variables model step models sequentially generate groups latent variables i.e. using computational steps allow later groups latent variables depend previously generated latent variables non-linear way. general form sequential generative models describe observed data time steps using latent variables step. generative model shown stochastic computational graph ﬁgure described step generates independent k-dimensional latent variables wish condition model external context piece sideinformation deterministic function used read context-images using attentional mechanism. deterministic transition function introduces sequential dependency latent variables incorporating context exists allows transition mechanism used figure stochastic computational graph showing conditional probabilities computational steps sequential generative models. represents attentional mechanism uses function writings function reading. transition speciﬁed long short-term memory network explicitly represent creation hidden variables hidden canvas model canvas function allows many different transformations generative attention used; describe number choices function section generated image sampled using observation function maps last hidden canvas parameters observation model. parameters generative model θo}. free energy objective smaller size number channels consider ways update hidden canvas additive canvas. name implies additive canvas updates canvas simply adding transformation hidden state previous canvas state ct−. simple effective update rule gated recurrent canvas. canvas function updated using convolutional gated recurrent unit architecture provides non-linear recursive updating mechanism canvas simpliﬁed versions convolutional lstms canvas update given probabilistic model obtain objective function inference parameter learning using variational inference. applying variational principle obtain free energy objective indicates collection latent variables step optimize objective function variational parameters model parameters stochastic gradient descent using minibatch data. vaes single sample latent variables generated computing monte carlo gradient. complete speciﬁcation specify hidden-canvas functions approximate posterior distribution hidden canvas functions canvas transition function updates hidden canvas ﬁrst non-linearly transforming current hidden state lstm fuses result existing canvas ct−. work hidden canvases size original images though could either larger cases function writing generative attention function implement spatial transformer; inputs spatial transformer afﬁne parameters image transformed provided lstm output. ﬁnal phase generative process transforms hidden canvas last time step parameters likelihood function using output function since hidden canvas size original images different number ﬁlters implement output function convolution. hidden canvas different size convolutional network used instead. structured posterior approximation auto-regressive form i.e. implement distribution inference network parameterized deep network. speciﬁc form every step computation form low-dimensional representation input image using non-linear transformation input image hidden state model.this function reading recognition attention using spatial transformer whose afﬁne parameters given lstm output. result reading sprite combined previous state non-linear function produce mean variance k-dimensional diagonal gaussian distribution. denote parameters inference model φσ}. although conditional distributions gaussian joint posterior posp non-gaussian multimodal non-linearities used enabling accurate inference. sequential generative model inference generalization existing models draw composited vaes generalization number differences important properties. largest deviations introduction hidden canvas generative model provides important richness model since allows pre-image constructed hidden space ﬁnal corrective transformation using function used. generative process important property allows model sampled without feeding-back results canvas hidden state ht—such connection needed provides efﬁciency reducing number model parameters. inference network framework also similarly simpliﬁed. separate recurrent function within inference network instead share parameters lstm prior—the removal additional recursive function effect performance. another important difference framework existing frameworks type attention used. gregor generative attention based gaussian convolutions parameterized location scale tang similarity transformations. much powerful general attention mechanism based spatial transformers overall complexity algorithm described matches typical complexity widely-used methods deep learning. images size spatial transformer complexity linear number pixels attention window. attention window spatial transformer complexity sequential steps data points. components standard quadratic complexity layer size hence layers average size gives complexity image generation analysis ﬁrst show models state-of-the-art obtaining highly competitive likelihoods able generate high-quality samples across wide range data sets different characteristics. experiments data consists binary images bernoulli likelihood model probability pixels. models lstm hidden units. kernels spatial transformer whether used recognition generative attention. latent variable -dimensional gaussian distributions number steps vary hidden canvas dimensions size images four channels. present main results additional results appendix models trained approximatively iterations mini-batches size reported likelihood bounds training computed averaging last iterations training. reported likelihood bounds test computed averaging bound random samples error bars standard-deviations mean. highlight behaviour models using data sets based mnist benchmark. ﬁrst experiment uses binarized mnist data salakhutdinov murray consists binary images training test images. table compares log-likelihoods binarized mnist data using existing models well models developed paper sequential generative model uses spatiallytransformed attention cgru hidden canvas provides best performance among existing work data set. show samples model ﬁgure form multi-mnist data images consists mnist digits placed random locations image procedurally generate data). compare performance table show samples model ﬁgure data much harder mnist learn much slower convergence. additive canvas spatially-transformed attention provides reliable learn data. importance step results also indicate longer sequences lead better performance. every step taken model adds term objective function corresponding kl-divergence prior distribution contribution approximate posterior distribution step. figure shows kl-divergence iteration models mnist steps. kldivergence decays towards sequence indicating latent variables diminishing contribution model number steps grow. unlike vaes often many dimensions contribute little likelihood bound sequential property allows efﬁciently allocate decide number latent variables means deciding terminate sequential computation. unlike mnist small number classes many images class large amount data omniglot data consists binary images across classes images class. data allows demonstrate attentional mechanisms better generative models allow perform well even regimes larger images limited amounts data. versions omniglot data previously used evaluation generative models. data used burda consists images different lake compare available methods dataset burda table sequential models perform better competing approaches establishing effectiveness models. second evaluation uses dataset lake downsampled using max-pooling. compare different sequential models table spatially-transformed attention powerful general purpose attention additive hidden canvas performs best. multi-pie dataset consists face images various viewpoints. converted images grayscale trained model subset comprising -viewpoints illumination conditions. simpliﬁcation results training samples test samples. samples model shown ﬁgure highly compelling showing faces different orientations different genders representative data. model trained using logit-normal likelihood rezende mohamed one-shot generalization lake introduce three tasks evaluate one-shot generalization testing weaker stronger forms generalization. three tasks unconditional generation generation novel variations given exemplar generation representative samples novel alphabet. lake conduct human evaluations part assessment important contrasting performance models cognitive ability humans; conduct human benchmarks paper focus machine learning one-shot generalization computational challenges associated task. unconditional generation. generation task reported data sets previous section. figure shows samples reﬂect characteristics omniglot data showing variety styles including rounded patterns line segments thick thin strokes representative data set. likelihoods reported tables quantitatively establish model among state-of-the-art. novel variations given exemplar. task corresponds ﬁgure lake test time model presented character type never seen asked generate novel variations character. this conditional generative model equation context image wish model generate exemplars expose boundaries approach test weak strong one-shot generalization tests data whose training data consists available alphabets three character types alphabet removed form test weak one-shot generalization test where although model never seen test characters seen related characters alphabet expected transfer knowledge generation task. exactly data split used lake consists alphabets training remaining alphabets test set. strong one-shot generalization test since model seen neither test character alphabets family. hard test model since split provides limited training data making overﬁtting easier generalization harder. figure generated samples multi-pie using model spatial transformer additive canvas video generation process including boundaries writing attention grid https//www.youtube.com/watch?v=stx_otvna show model’s performance weak generalization test ﬁgure ﬁrst shows exemplar image subsequent rows show variations image generated model. show generations strong generalization test ﬁgure model also generates visually similar reasonable variations image case. unlike model lake uses human stroke information model structured around humans draw images model applicable image data domain speciﬁc information used data spatially arranged test also exposes difﬁculty model coping small amounts data. compare difference train test log-likelihoods various data splits ﬁgure small training test likelihoods regime data indicating overﬁtting. large splits hence greater tendency overﬁtting data regime. interesting observation even cases large train test likelihood bounds examples generated model still generalize unseen character classes. data-efﬁciency important challenge large parametric models hope address future. figure generating examplars given character strong generalization test models trained different amounts data. left samples model trained train-test split; middle split; right split representative samples novel alphabet. task corresponds ﬁgure lake conditions model anywhere samples novel alphabet asks model generate characters consistent novel alphabet. show hardest form test using context image. test highly subjective model generations ﬁgure show able pick common features generations. emphasized usefulness deep generative models scalable general-purpose tools probabilistic reasoning important property one-shot generalization. models limitations. already pointed need reasonable amounts data. another important consideration that models perform one-shot generalization perform one-shot learning. one-shot learning requires model updated presentation input e.g. like non-parametric models used lake salakhutdinov parametric models require gradient update parameters instead model performs type one-shot inference test time perform inferential tasks data points missing data completion exemplar generation analogical sampling learn points. distinction one-shot learning inference important affects models used. extend approach online one-shot learning setting future. developed class general-purpose models ability perform one-shot generalization emulating important characteristic human cognition. sequential generative models natural extensions variational auto-encoders provide state-of-the-art models deep density estimation image generation. models specify sequential process groups latent variables allows compute probability data points number steps using principles feedback attention. spatial attention mechanisms substantially improves ability model generalize. spatial transformer highly ﬂexible attention mechanism reading writing default mechanism attention generative models. highlighted one-shot generalization ability model range tasks showed model able generate compelling diverse samples seen examples once. however limitations approach e.g. still needing reasonable amount data avoid overﬁtting hope address future work. netzer wang coates bissacco reading digits natural images unsunips workshop deep pervised feature learning. learning unsupervised feature learning gregor danihelka mnih blundell wierstra deep autoregressive networks. icml gregor danihelka graves rezende wierstra draw recurrent neural network image generation. icml model attention mechanism. type hardattention policy need learned since obtained every step based reconstruction error effectively allows every step work efﬁciently towards reducing reconstruction error. also overcomes problem limited gradient information large sparse images since form attention saccadic behaviour since able jump part image high error. multiple spatial attention. simple generalization using single spatial transformer multiple additively combined cgru) cgru tanh symbols indicates element-wise product size-preserving convolution stride sigmoid function. matrices kernels. number ﬁlters used hidden canvas speciﬁed section types attention randomized attention. simplest attention randomly selects patches input image simplest implementing sparse selection mechanism. applying dropout regularisation input layer deep models would effectively implement type attention data sets like mnist attention allows competitive learning generative model model allowed attend large number patches; video https//www.youtube. com/watch?v=wrweuqq. error-based attention. difﬁculties attention mechanisms large sparse images little gradient information available cause attentional selection become stuck. address issue previous approaches used particle methods exploration techniques reinforcement learning infer latent variables control attentional allow jump easily relevant parts input. simple realizing this decide attend jumping places model made largest reconstruction errors. this convert element-wise reconstruction error every step probability locations attend next iteration ˆxt−k reconstruction error pixel ˆxt− reconstructed image iteration current target image spatial average spatial standard deviation attention suited models sparse images video https//www.youtube.com/watch?v=qb-ohuwa example", "year": 2016}