{"title": "Asymptotic Model Selection for Naive Bayesian Networks", "tag": ["cs.AI", "cs.LG"], "abstract": "We develop a closed form asymptotic formula to compute the marginal likelihood of data given a naive Bayesian network model with two hidden states and binary features. This formula deviates from the standard BIC score. Our work provides a concrete example that the BIC score is generally not valid for statistical models that belong to a stratified exponential family. This stands in contrast to linear and curved exponential families, where the BIC score has been proven to provide a correct approximation for the marginal likelihood.", "text": "develop mula compute marginal data given naive bayesian hidden states formula deviates score. score generally statistical exponential linear score proven provide correct lihood. averaged data number examples model recall prior parameter density average simply samples joint states. counts possible prior assumed equal models model selection formed maximizing resented bayesian model many types models asymptotic integral laplace dure. evaluation exponential curved exponential ditional shown uat.ion bayesian open problem resented bayesian significantly richer falls class stratified models models effective longer heckerman moreover marginal imum likelihood points crossing achieved grals here another multiplicity theory comes rescue. ematical continuous algebraic singularities tegral variable dfj-l case calculation d-d' dimensional locally equivalent classical case. hardest happen cases evaluate self-crossings. contains variety advanced fortunately method mathematical approximating type integrals machine community watanabe learning enables main theorem introduce compute asymptotic neighborhood maximum likelihood point. applying theorem classical single maximum strictly convex case gives largest pole multiplicity confirming ;l�ko;n find poles transform lj<l<n ufu� function dinates near transformation invertible study independent compose integral easily one-dimensional changing coor­ computed. process resolution dinates obtain needed transformations called study apply technique integral quadratic consists series introduction accessible concepts taking positive quadrant change poles yields fo<utu<u<l o<uu<u< model discrete naive bayesian variables joint distributions depicted tree structure factor according fig­ belongs probability distribution model naive bayesian n-dimensional binary vector values denotes number hidden states particular state intuitively model data comes scribes sources naive bayesian models sub­ class bayesian binary feature variables defin­ denote parameters parameters defining rameters model parameters. denote joint space parameters lowing mapping relates model parameters defined section geiger classify points classes holds intuitively cept indices point represents probability distribution model links removed except two. points represented naive bayesian model does links removed; distribution variables mutually class node well. clearly present result. theorem approximation score formula tually variable namely links present. states hidden variable interpreted tells features guish correct prescribed provides strength model. assume models true data comes model falls close points full model even evaluate uniform range near singular limit per. careful negligible datasets least tion. phenomenon happens graphical common practice paper attempts", "year": 2012}