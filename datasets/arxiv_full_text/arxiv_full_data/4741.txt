{"title": "POWERPLAY: Training an Increasingly General Problem Solver by  Continually Searching for the Simplest Still Unsolvable Problem", "tag": ["cs.AI", "cs.LG"], "abstract": "Most of computer science focuses on automatically solving given computational problems. I focus on automatically inventing or discovering problems in a way inspired by the playful behavior of animals and humans, to train a more and more general problem solver from scratch in an unsupervised fashion. Consider the infinite set of all computable descriptions of tasks with possibly computable solutions. The novel algorithmic framework POWERPLAY (2011) continually searches the space of possible pairs of new tasks and modifications of the current problem solver, until it finds a more powerful problem solver that provably solves all previously learned tasks plus the new one, while the unmodified predecessor does not. Wow-effects are achieved by continually making previously learned skills more efficient such that they require less time and space. New skills may (partially) re-use previously learned skills. POWERPLAY's search orders candidate pairs of tasks and solver modifications by their conditional computational (time & space) complexity, given the stored experience so far. The new task and its corresponding task-solving skill are those first found and validated. The computational costs of validating new tasks need not grow with task repertoire size. POWERPLAY's ongoing search for novelty keeps breaking the generalization abilities of its present solver. This is related to Goedel's sequence of increasingly powerful formal theories based on adding formerly unprovable statements to the axioms without affecting previously provable theorems. The continually increasing repertoire of problem solving procedures can be exploited by a parallel search for solutions to additional externally posed tasks. POWERPLAY may be viewed as a greedy but practical implementation of basic principles of creativity. A first experimental analysis can be found in separate papers [53,54].", "text": "computer science focuses automatically solving given computational problems. focus automatically inventing discovering problems inspired playful behavior animals humans train general problem solver scratch unsupervised fashion. consider inﬁnite computable descriptions tasks possibly computable solutions. given general problem solving architecture given time novel algorithmic framework powerplay searches space possible pairs tasks modiﬁcations current problem solver ﬁnds powerful problem solver provably solves previously learned tasks plus unmodiﬁed predecessor not. newly invented tasks require achieve wow-effect making previously learned skills efﬁcient require less time space. skills re-use previously learned skills. greedy search typical powerplay variants uses time-optimal program search order candidate pairs tasks solver modiﬁcations conditional computational complexity given stored experience far. task corresponding task-solving skill ﬁrst found validated. biases search towards pairs described compactly validated quickly. computational costs validating tasks need grow task repertoire size. standard problem solver architectures personal computers neural networks tend generalize solving numerous tasks outside self-invented training set; powerplay’s ongoing search novelty keeps breaking generalization abilities present solver. related g¨odel’s sequence increasingly powerful formal theories based adding formerly unprovable statements axioms without affecting previously provable theorems. continually increasing repertoire problem solving procedures exploited parallel search solutions additional externally posed tasks. powerplay viewed greedy practical implementation basic principles creativity ﬁrst experimental analysis found separate papers implementing task invention example pattern recognition tasks example general decision making tasks dynamic environments implementing solver modification implementing correctness demonstration general proof search keeping track components solver affect tasks advantages preﬁx code-based problem solvers implementation based optimal ordered problem solver oops building existing oops source code alternative problem solvers based recurrent neural networks existing theoretically optimal universal problem solvers connection traditional active learning greedy implementation aspects formal theory creativity beyond algorithmic zero-sum games opposing forces improving generalization compression breaking generaliza. given realistic piece computational hardware speciﬁc resource limitations devise software solve least many priori unknown tasks principle easily solvable architecture? words build practical general problem solver given computational restrictions? need universal asymptotically optimal like recent general problem solvers discussed section instead take account constant architecture-speciﬁc slowdowns ignored asymptotic optimality notation theoretical computer science generally useful real-world applications. draw inspiration biology. initially helpless human babies become rather general problem solvers time? apparently playing. example even absence external reward hunger curious happens move eyes ﬁngers particular ways creating little experiments lead initially novel surprising eventually predictable sensory inputs also learning motor skills reproduce outcomes. section previous artiﬁcial systems type.) infants continually seem invent tasks become boring soon solutions become known. easy-to-learn tasks preferred unsolvable hard-to-learn tasks. eventually numerous skills acquired creative self-supervised re-used facilitate search solutions external problems ﬁnding food hungry. kids keep inventing problems themselves move remarkable developmental stages introduce novel unsupervised algorithmic framework training computational problem solver scratch continually searching simplest combination task corresponding task-solving skill growing repertoire without forgetting previous skills least without decreasing average performance previously solved tasks skills re-use previously learned skills. every task added repertoire essentially deﬁned time required invent solve demonstrate previously learned skills lost. search takes account typical problem solvers learn solve tasks outside growing self-made training generalization properties architectures. framework called powerplay continually aims boosting computational prowess problem solving capacity reminiscent humans human societies trying boost general power/capabilities/knowledge/skills playful ways even absence externally deﬁned goals although skills learned type pure curiosity later help solve externally posed tasks. unlike ﬁrst implementations curious/creative/playful agents powerplay provably problems online learning—it cannot forget previously learned skills automatically segmenting life sequence clearly identiﬁed tasks explicitly recorded solutions. unlike task search theoretically optimal creative agents powerplay’s task search greedy least practically feasible. claim scientists often invent appropriate problems methods rather inventing methods solve given problems. present paper formalizes convenient implement previous work describes simple practical framework building creative artiﬁcial scientists explorers design continually come fastest initially novel eventually solvable problems. traditional computer science given formally deﬁned task search algorithm used search space solution candidates solution task found veriﬁed. task hard search take long. automatically construct increasingly general problem solver expand traditional search space unusual includes possible pairs computable tasks possibly computable solutions problem solvers. given problem solver already solve ﬁnite known previously learned tasks search algorithm used pair provably following properties task cannot solved problem solver. task solved pair found cycle repeats itself. result continually growing known tasks solvable increasingly powerful problem solver. solutions tasks reuse solutions previously learned tasks. smart search orders candidate pairs type computational complexity using concepts optimal universal search bias towards pairs described additional bits information validated quickly. ﬁrst glance might seem harder search pairs tasks solvers instead solvers only apparently larger search space. however additional freedom inventing tasks solved actually greatly reduce time intervals problem solver advances system often option inventing rather simple task easy-to-ﬁnd solution. task simplifying solver still solve tasks learned less computational resources time storage space since pair ﬁrst found validated search automatically trades time-varying efforts required either invent completely previously unsolvable problems compressing/speeding previous solutions. sometimes easier reﬁne simplify known skills sometimes invent skills. typical problem solver architectures personal computers neural networks limited known number previously learned tasks become solvable large number unknown never-tested tasks powerplay’s ongoing search continually testing generalization abilities recent solver instance; search time spent demonstrating self-invented tasks already solvable. often however much time spent making sure newly modiﬁed solver forget possibly many previously learned skills. problem solver modularization greatly reduce time though making powerplay prefer pairs whose validation require re-testing many previously learned skills thus decomposing least part search space somewhat independent regions realizing divide conquer strategies by-products built-in drive invent validate novel tasks/skills quickly possible. biologically inspired hope problem solver becoming general easier easier solve externally posed tasks like growing infants often seem re-use playfully acquired skills solve teacher-given problems. section introduce basic notation variant algorithmic framework powerplay invokes essential procedures task invention solver modification correctness demonstration. section discuss details procedures. mentioned above skills acquired solve self-generated tasks later greatly facilitate solutions externally posed tasks like numerous motor skills learned babies curious exploration world often re-used later maximize external reward. sections discuss variants framework tasks deﬁned externally. section also describe natural variant framework explicitly penalizes solution costs allows forgetting aspects previous solutions provided average performance previously solved tasks decrease. denotes ﬁnite sequences bitstrings binary alphabet empty string strings natural numbers real numbers positive constant non-negative integers number bits functions mapping integers integers. write exist positive computational architecture problem solver deterministic universal computer limited device ﬁnite state automaton feedforward neural network problem solvers uniquely encoded implemented universal computers universal turing machines therefore without loss generality remainder paper assumes ﬁxed universal reference computer whose input programs outputs elements user-deﬁned subset deﬁnes possible problem solvers. example problem solver’s architecture binary universal standard computer represents possible programs limited subset thereof—compare sections feedforward could highly restricted subset programs encoding nn’s possible topologies weights —compare section original slim paper follows convenience often identify bitstrings things encode integers real-valued vectors weight matrices programs—the context always make clear meant. problem solver’s initial program called possible task descriptions inﬁnite possible computable descriptions tasks possibly computable solutions small subset thereof. example simple task require solver answer particular input pattern particular output pattern require solver steer robot towards goal sequence actions particular sequence task descriptions unique chosen invented search method described solutions computed i-th instance program consists unique problem identiﬁer read built-in input processing mechanism unique description deterministic procedure determining whether problem solved. denote ti}; ti−}. valid task require solving least previously solved task efﬁciently using less resources storage space computation time energy etc. thus achieving wow-effect. section tasks problem solver modiﬁcations computed validated elements another appropriate programs programs contain instructions reading executing code present problem solver reading recorded history race previous events present solver. algorithmic framework incrementally trains problem solver ﬁnding increase solvable tasks. program tested alg. allocate runtime solve three main jobs namely task invention solver modification correctness demonstration. examples listed. part compute consume total computation time allocated examples given pattern recognition tasks treated section sequential decision making tasks section search algorithm create candidate program give limited time task invention compute task section solver modification compute value variable computing modiﬁcation si−. section correctness demonstration show cannot solved solved section context learning recognize analyze patterns could -tuple solved satisﬁes needs discrete time steps read compute halt. pair image addressed contains least black pixel image shows cow. since deﬁnition task includes bounds computational resources solving least efﬁciently corresponding wow-effect. turn also yield efﬁcient solutions tasks practical applications insist efﬁciency gains must exceed certain threshold avoid task series causing sequences minor improvements. note unnecessary special cases problem solver ﬁxed topology feedforward whose input target patterns constant size whose computational efforts pattern need constant time space resources. general context general problem solving/sequential decision making/reinforcement learning/reward optimization unknown environments possible task identiﬁcation patterns programs test properties bitstrings. could encode -tuple ﬁnite bitstrings following interpretation must satisfy spend discrete time steps ﬁrst reading interacting environment sequence perceptions actions achieve computable goal deﬁned precisely solved within time steps given time internal state problem solver time denoted initial default value example encode current contents internal tape certain addresses dynamic storage area present activations lstm recurrent time spend constant number elementary computational instructions copy task dscription present allows programs dynamically acquire additional physical computational resources additional cpus storage constant number elementary computational instructions replaced constant amount real time measured reliable physical clock. sequence -tuples gets recorded so-called trace racei interaction desirable computable property satisﬁed deﬁnition task solved. possible represent inﬁnite computable tasks solutions computable given hardware. practical reasons however possible also restricted sequences encoding possible goals. example encode goals form robot steered program policy reached certain target recorded racei) without measurably bumping obstacle along negative rewards environment deterministic e.g. digital physics simulation robot current state encoded part straight-forward correctness demonstration test whether still solve previously solved task however environment partially observable like real world non-stationary changing unknown ways? correctness demonstration must check whether still produces action sequence response input sequence recorded racej achieving goal changed environment must considered different task even changes noise environmental inputs. might actually achieve faster given description correctness demonstration general cannot know whether acceleration plain luck—it must stick reproducing racej make sure forget anything.) section however less strict powerplay variant whose correctness demonstration directly interacts real world collect sufﬁcient problem-solving statistics repeated trials making certain assumptions probabilistic nature environment repeatability experiments. part also compute possibly proﬁting access changes necessary come goes beyond si−. example problem solver standard bits previous software need changed. practical reasons possible greatly restricted sequences encoding programs obey syntax standard programming language lisp java. turn programming language describing greatly restricted produce syntactically correct problem solver feedforward pre-wired unmodiﬁable topology restricted sequences encoding valid weight matrices encode i-th weight matrix restricted produce depending user-deﬁned programming language invoke complex pre-wired subprograms primitive instructions—compare separate experimental analysis general demonstrating correctness encode axiomatic system formally describes computational properties problem solver possible allow search space possible proofs derivable using proof searcher subroutine systematically generates proofs ﬁnds theorem stating solves could done like g¨odel machine uses online extension universal search systematically test proof techniques proof-generating programs invoke special instructions generating axioms applying inference rules prolong initially empty proof theorems either axioms inferred previous theorems rules modus ponens combined uniﬁcation e.g. easily limited programs generating syntactically correct proofs subsume axioms describing instruction invoked change state problem solver step next axioms encode knowledge arithmetics often possible partition components individual bits software weights k-th component denoted variable list whose current solutions need least solution-computing process deleting whose current solutions more. powerplay’s correctness demonstration thus test tasks union recent task require changes many components changed bits affect many previous tasks correctness demonstration efﬁcient. since every task added repertoire essentially deﬁned time required invent solve show previous tasks became unsolvable process powerplay generally motivated invent tasks whose validity check require much computational effort. powerplay often generate si−-modiﬁcations don’t affect many previous tasks thus decomposing least part spaces tasks solutions less independent regions realizing divide conquer strategies by-products. compare recent experimental analysis effect restrict tested cannot change components solver modification create adding components si−. restricting self-delimiting preﬁx codes like generated optimal ordered problem solver proﬁt sometimes particularly efﬁcient type correctness demonstration ensuring differences cannot affect solutions certain conditions. precisely obtain half search time spent trying process ﬁrst extending prolonging ongoing computation requests components special instructions —then correctness demonstration less guaranteed remain solvable induction. part half time spent processing sub-program components simple general something similar interleave task invention solver modification correctness demonstration follows restrict must deﬁne unique task identiﬁer restrict read input automatically invokes sub-program invoke parts sub-programs solve ti). restrict subset acceptable computational outcomes halts computed novel output acceptable different outputs computed solutions t<i; novel output becomes ti’s goal. induction since previously used components remain unmodiﬁed correctness demonstration previous tasks guaranteed remain solvable matter becomes trivial. however simple setup immediate generalization across tasks like oops previous paragraph trivial task identiﬁer always ﬁrst invoke different candidate program executed given discrete time step internal state dynamical storage time denoted section ..). initial default value e.g. could encode current contents internal tape certain cells dynamic storage area found racei saved unmodiﬁable readstorage possibly together data observed search far. greatly facilitate search since contain instructions addressing reading racej copying read code modiﬁable storage edit code execute result useful subprogram oops keeps doubling time limit sufﬁcient runtime sufﬁciently likely program compute novel previously unsolvable task plus solver provably forget previous solutions. oops allocates time programs according asymptotically optimal universal search method problems easily veriﬁable solutions solutions whose validity quickly tested. given problem class unknown optimal program requires steps solve problem instance size demonstrate correctness result search method need steps—the constant factor large depend since oops re-use previously generated solutions solution-computing programs however possible greatly reduce constant factor associated plain universal search difference previous implementations oops powerplay additional freedom deﬁne tasks. always every task added repertoire essentially deﬁned time required invent solve demonstrate previously learned skills lost. existing oops source code uses forth-like universal programming language deﬁne already contains framework testing code previously solved tasks efﬁciently undoing -modiﬁcations tested program. source code require changes implement additional task search described above. recurrent general computers allow sequential parallel computations unlike strictly sequential forth-like language section compute function computable standard original report used fully connected called deﬁne real-valued weight directed connection l-th k-th neuron. program means weight matrix hwlki. given enough neurons appropriate activation functions appropriate hwlki algorithm used train weight matrices separate called computing tasks modiﬁcations using techniques network-modifying networks described previous work ﬁrst experiments particularly suited called self-delimiting slim used. program execution activation spreading slim lists used trace neurons connections used least once. also allows efﬁcient resets large small fraction weights task. unlike standard rnns slim easily combined techniques asymptotically optimal program search address overﬁtting instead depending pre-wired regularizers hyper-parameters slim principle learn select runtime numbers free parameters becoming fast slim necessary. efﬁcient slim learning algorithms track weights used tasks greatly speed performance evaluations response limited weight changes. penalize task-speciﬁc total length connections used slim implemented straightforward extension works follows whenever found updated make either likely. simple ways described previous work justiﬁed extent future successful programs turn similar previous ones. possibly simpler less general approach evolutionary algorithm produce s-modifying task-generating program requested powerplay according algorithm refers recurrent problem solver section prevents powerplay inventing trivial tasks forever extreme modularization simply allocating previously unused solver part task thus becomes rather quickly veriﬁable solution affect solutions previous tasks realistic general architectures rnns least upper storage size limit reached powerplay start compressing previous solutions making generalize sense relatively short piece code helps solve different tasks. many computational architectures type compression start much earlier though because tasks solvable partial reuse earlier discovered code often easier tasks solvable previously unused parts also holds growing architectures potentially unlimited storage space. general however time system difﬁcult invent novel tasks without forgetting previous solutions like humans harder harder learn truly novel behaviors leaving behind initial rapid exploration phase typical babies. experiments various problem solver architectures needed analyze effects detail. growing repertoire problem solver facilitate learning solutions externally posed tasks. example modify powerplay certain deﬁned externally instead invented system itself. general resulting contain externally inserted bias form code make future self-generated tasks easier others. possible push system human-understandable otherwise useful direction regularly inserting appropriate external goals. algorithm another exploiting growing repertoire simply copy starting point search solution externally posed task without insisting modiﬁed also solve much faster trying solve scratch extent solutions self-generated tasks reﬂect general knowledge re-usable hand real world beneﬁts curious exploration seem obvious. analyze theoretically experimentally conditions creation self-generated tasks accelerate solution externally generated tasks—see previous simple experimental studies vein. powerplay’s i-th goal creates shows solve t≤i. becoming general problem solver help many ways achieve goals self-referential fashion. example solver able read unique formal description powerplay’s i-th goal viewing external task produce output unambiguously describing candidate theorem prover component might even output full proof validity; alternatively could possibly suboptimal suggestions narrow speed search reasons section already mentioned programs contain instructions reading code present problem solver. powerplay variants insist solve tasks expense forgetting solve previously solved task within previously established time space bounds. example consider sequential decision-making tasks section suppose problem solver already solve task similar admissible task would solve substantially faster long already solvable solution forgotten process. discuss variants powerplay soften acceptance criteria tasks various ways example allowing computations solutions previous non-external tasks slow certain amount time provided runtimes decrease. also permits system invent previously unsolved tasks expense slightly increasing time bounds certain already solved non-external tasks without decreasing average performance latter. course powerplay modiﬁed accordingly updating average runtime bounds necessary. alternatively allow trading space time constraints reasonable ways e.g. style asymptotically optimal universal search essentially trades additional space complexity runtime speedup factor remove time space bounds task deﬁnitions section since modiﬁed costbased powerplay framework handle computational costs directly. present section encodes tuple interpretation must ﬁrst read interact environment sequence perceptions actions achieve computable goal deﬁned within certain maximal time interval tmax tmax cannot solve task otherwise time needed solve positive constant lmax cannot solve otherwise number components needed solve task non-negative real-valued reward solving positive constant rnew self-deﬁned previously unsolvable user-deﬁned external task solved real-valued cost cost solving tasks task real-valued function example cost function cost encourages compact fast solvers solving many different tasks components real-valued positive parameter weighs space costs time costs rnew exceed tmax encourage solutions novel self-generated tasks whose cost contributions zero always environment unknown possibly changing time test performance solver previous task racek necessary—see section always denote containing tasks deﬁne what’s acceptable progress search algorithm candidate program. give limited time task invention unless user speciﬁes solver modification computing modiﬁcation correctness demonstration compute cost cost algorithm forget certain abilities provided overall performance measured cost improved either task became solvable previous tasks became solvable efﬁciently. contains previously learned tasks whose solutions depend used determine current value cost. simple exercise invent less strict variant powerplay however simply make certain assumptions probabilistic nature environment repeatability trials assuming limited algorithm ﬁxed number interactions real world sufﬁcient estimate costs another probabilistic softening powerplay tasks without proof won’t forget solutions previous tasks provided correctness demonstration least show probability forgetting previous solution real-valued positive constant threshold. first experiments reported separate papers standard well slim rnns used computational problem solving architectures. weights slim rnns encode essentially arbitrary computable tasks well arbitrary self-delimiting halting non-halting programs solving tasks. programs affect environment internal states encoding abstractions event sequences. open-ended fashion powerplay-driven learn become increasingly general solvers selfinvented problems continually adding problem solving procedures growing repertoire sometimes compressing/speeding previous skills sometimes preferring invent tasks corresponding skills. exhibit interesting developmental stages. also shown powerplay-driven slim automatically self-modularizes frequently re-using code previously invented skills always trying invent novel tasks quickly validated require many weight changes affecting many previous tasks. discuss related research particular present work interest despite recent advent theoretically optimal universal problem solvers viewed greedy feasible sound implementation formal theory creativity millennium brought universal problem solvers theoretically optimal certain sense. fully self-referential g¨odel machine interact initially unknown partially observable environment maximize future expected utility reward solving arbitrary user-deﬁned computational tasks. initial algorithm hardwired; completely rewrite without essential limits apart limits computability proof searcher embedded within initial algorithm ﬁrst prove rewrite useful according formalized utility function taking account limited computational resources. self-rewrites approach shown globally optimal relative g¨odel’s well-known fundamental restrictions provability make sure g¨odel machine least asymptotically optimal even ﬁrst self-rewrite initialize hutter’s non-self-referential asymptotically fastest algorithm well-deﬁned problems hsearch uses hardwired brute force proof searcher ignores costs proof search. assuming discrete input/output domains formal problem speciﬁcation particular hsearch orders proofs appropriate axiomatic system size programs provably compute within time bound simultaneously spends time executing best currently proven time bound hsearch fast fastest algorithm provably computes save constant factor smaller -speciﬁc x-independent additive constant given problem g¨odel machine decide replace hsearch faster method suffering less large constant overhead even doesn’t performance won’t less asymptotically optimal. doesn’t everybody universal problem solvers computational real-world problems? real-world problems small ominous constant slowdowns large enough prevent universal methods feasible. powerplay hand designed incrementally build practical general problem solver solve numerous tasks quickly asymptotic sense exploiting given particular search algorithm computational architecture space time limitations including reﬂected constants ignored asymptotic optimality notation. traditional active learning methods adaboost totally different set-up purpose user provides samples learned classiﬁer series classiﬁers focuses samples badly classiﬁed previous classiﬁers. open-ended powerplay however considers arbitrary computational problems self-invent computational tasks. need pre-deﬁned global tasks solver tries solve better instead task continually grows based task easy invent validate given already known. formal theory creativity considers agents living initially unknown environments. given time agent uses reinforcement learning method maximize expected future external reward achieving certain goals also intrinsic reward improving internal model environmental responses actions learning better predict compress growing history observations inﬂuenced behavior thus achieving wow-effects actively learning skills inﬂuence input stream contains previously unknown learnable algorithmic regularities. argued theory explains essential aspects intelligence including selective attention curiosity creativity science music humor e.g. compare recent related work e.g. like powerplay creative agent produces sequence self-generated tasks solutions task still unsolvable learning becoming solvable learning. costs learning well learning progress measured enter reward function. thus absence external reward reaching user-deﬁned goals given time agent motivated invent series additional tasks maximize future expected learning progress. example restricting input stream self-generated pairs like section limiting predict given pairs previous ones general agent would motivation actively generate sequence pairs ﬁrst subjectively unpredictable become predictable little effort given limitations whatever learning algorithm used. instead maximizing future expected reward powerplay greedy always trying simplest task repertoire simplest improving efﬁciency compressibility previous solutions instead looking ahead universal method would powerplay potentially sacriﬁce large long-term gains small short-term gains discovery many easily solvable tasks least temporarily prevent learning solve hard tasks. general creative agent motivated improve performance entire history previous still unsolved tasks powerplay discard much history keeping selective list previously solved tasks. however system interacting environment could store entire continually growing history make sure always allows deﬁning task better compressing history far. powerplay section binary criterion adding knowledge general agent uses informative information-theoretic measure. cost-based powerplay framework section however offers similar ﬂexible options rewarding compression speedup solutions previously solved tasks. previous approximative implementations used traditional methods theoretically unlimited look-ahead guaranteed work well partially observable and/or non-stationary environments reward function changes time won’t necessarily generate optimal sequence future tasks experiments. hence powerplay viewed greedy feasible implementation certain basic principles creativity powerplay-based systems continually motivated invent tasks solvable formerly unknown procedures compress speed problem solving procedures discovered earlier. unlike previous implementations powerplay extracts lifelong experience history sequence clearly identiﬁed separated tasks explicitly recorded solutions. design cannot suffer online learning problems affecting solver’s performance previously solved problems. guaranteed robustness forgetting previous skills also represents difference closely related previous work there address computational costs learning costs measuring learning progress computationally powerful encoders problem solvers implemented general co-evolving symmetric opposing modules called right brain left brain. able construct self-modifying probabilistic programs written universal programming language. internal storage temporary computational results programs viewed part changing environment. module suggest experiments form probabilistic algorithms executed make predictions effects betting intrinsic reward outcomes. opposing module accept zero-sum game making contrary prediction reject case acceptance winner determined executing experiment checking outcome; intrinsic reward eventually gets transferred surprised loser conﬁrmed winner. modules maximize reward using rather general algorithm designed complex stochastic policies thus modules motivated discover novel algorithmic patterns/compressibility subjective baseline novelty given opponent already knows world’s repetitive patterns. since execution computational physical action costs something modules motivated focus parts dynamic world currently make surprises learning progress easy minimize costs identifying promising experiments executing them. system learns partly hierarchical structure complex skills programs necessary solve growing sequence self-generated tasks reusing previously acquired simpler skills beneﬁcial. experimental studies exhibit several sequential stages emergent developmental sequences without external reward analyze novel framework’s consequences practical settings experiments currently conducted various problem solver architectures different generalization properties. separate papers section opposing forces work powerplay. hand system continually tries improve previously learned skills speeding compressing used parameters problem solver reducing effective size. compression drive tends improve generalization performance according principles occam’s razor minimum description length minimum message length hand system also continually tries invent tasks break generalization capabilities present solver. powerplay’s time-minimizing search tasks automatically manages trade-off opposing forces. sometimes easier invent solve completely previously unsolvable problem. sometimes easier compress solutions previously invented problems. kurt g¨odel showed sufﬁciently powerful consistent axiomatic system statement must true cannot proven axioms algorithmic theorem-proving procedure unprovable statement added axioms obtain powerful formal theory formerly unprovable theorems become provable without affecting previously provable theorems. sense powerplay something similar. assume architecture solver universal computer software viewed theorem-proving procedure implementing certain enumerable axioms computable inference rules. powerplay continually tries modify previously proven theorems remain provable within certain time bounds previously unprovable theorem becomes provable. behavior powerplay determined nature limitations algorithm searching includes computable task descriptions allow implementing arbitrary programs search algorithm general method search program space limits powerplay advisable general variant powerplay loose uncontrolled situation e.g. multi-computer network internet possibly access control physical devices potential acquire additional computational physical resources programs executed powerplay. unlike traditional virus programs powerplay-based systems continually change hard predict incessantly inventing solving novel self-generated tasks driven desire increase general problem-solving capacity perhaps like many humans seek increase power basic needs satisﬁed. type artiﬁcial curiosity/creativity however conﬂict human intentions occasion. hand unchecked curiosity sometimes also harmful fatal learning system —curiosity kill cat.", "year": 2011}