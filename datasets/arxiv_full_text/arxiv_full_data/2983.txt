{"title": "Suppressing the Unusual: towards Robust CNNs using Symmetric Activation  Functions", "tag": ["cs.CV", "cs.AI", "cs.LG"], "abstract": "Many deep Convolutional Neural Networks (CNN) make incorrect predictions on adversarial samples obtained by imperceptible perturbations of clean samples. We hypothesize that this is caused by a failure to suppress unusual signals within network layers. As remedy we propose the use of Symmetric Activation Functions (SAF) in non-linear signal transducer units. These units suppress signals of exceptional magnitude. We prove that SAF networks can perform classification tasks to arbitrary precision in a simplified situation. In practice, rather than use SAFs alone, we add them into CNNs to improve their robustness. The modified CNNs can be easily trained using popular strategies with the moderate training load. Our experiments on MNIST and CIFAR-10 show that the modified CNNs perform similarly to plain ones on clean samples, and are remarkably more robust against adversarial and nonsense samples.", "text": "many deep convolutional neural networks make incorrect predictions adversarial samples obtained imperceptible perturbations clean samples. hypothesize caused failure suppress unusual signals within network layers. remedy propose symmetric activation functions non-linear signal transducer units. units suppress signals exceptional magnitude. prove networks perform classiﬁcation tasks arbitrary precision simpliﬁed situation. practice rather safs alone cnns improve robustness. modiﬁed cnns easily trained using popular strategies moderate training load. experiments mnist cifar- show modiﬁed cnns perform similarly plain ones clean samples remarkably robust adversarial nonsense samples. simpler method fast gradient sign proposed compute adversarial samples effectively. recently complicated method proposed construct adversarial sample prediction internal features similar anarbitrary sample nonsense samples another challenge robustness cnns. generated noise arbitrary images using fgs-like methods nonsense samples totally unrecognizable popular cnns typically predict high conﬁdence belong category. references argue adversarial nonsense samples arise unknown popular deep cnns either structure training methods although deep cnns delivered state-of-the-art performance several major computer vision challenges pooly understood aspects. particular shown easily construct adversarial sample imperceptible perturbation clean sample using box-constrained limited-memory bfgs method samples perceptually similar original ones predicted different categories even generalize well across different models train sets units. nonlinear transduction units suppress exceptional signals. incorporate safs cnns addition replacement layers standard models. resulting cnns easily trained using standard approaches give error rates clean perturbed samples. unlike cnns linear classiﬁcation models local models based radial basis functions intrinsically immune abnormal samples high-density regions always output conﬁdence scores such. furthermore rbfs robust tiny perturbations input. suggests possibility improving robustness cnns using units. rbfs used several ways within networks e.g. hidden layer mixture experts layer units lenet- implementations attempt multiple layers reason avoiding multiple layers high-dimensionality parameter space unit together need many units. high-dimensionality makes hard train deep networks involving units achieve acceptable accuracies argued powerful optimization methods needed make work considered whether feasible rbfs instead high-dimension ones. assess this lenet- model mnist test show histograms joint distributions features second convolutional layer fig. empirical distributions features approximately gaussian. experiments effective distinguish abnormal samples normal ones exploiting observation. second fig. show feature pair values nonsense samples pure gaussian noise squares. although lenet- model incorrectly assigns nonsense samples meaningful categories high conﬁdence ﬁgure shows features usually deviate high-density regions clean samples. higher layer distinct deviation. versarial samples constructed according current model utilized subsequent training epochs. cnns trained vulnerable adversarial samples; repeated rounds adversarial training eventually lead improved robustness price increased training load. unfortunately ﬁnal error rates newest adversarial samples scheme remain large interesting adversarial training understood regularization method training cnns; example virtual adversarial samples constructed force model distributions supervised learning process smooth. adversarial samples also used establish unsupervised and/or semi-supervised representation learning methods autoencoders different approach adversary problem modify structure cnn. autoencoders added denoise input samples improve local stability feature spaces individual layers contractive penalty terms designed punish unexpected feature changes caused small perturbations. idea similar however method cannot achieve good robustness moderately large perturbations keeping high accuracies clean samples another interesting idea proposed identify features causally related rather merely correlated categories. thus possible predict semantic categories according causal features improve robustness. however would large burden integrate idea popular models. gaussian distributions instead high-dimension ones model feature statistics clean samples. rbfs used within networks multi-dimensional rbfs been. potential advantage obvious possible much fewer units high-dimensional ones therefore fewer parameters train. pointed approximate traditional network single hidden layer using rbfs. instead propose integrate units popular models. integration neither pure ‘local’ model networks pure ‘distributed’ model cnns. models diverse features ‘locally’ rbfs combines ‘distributed’ give ﬁnal representation. figure statistics four feature channels convolutional layer lenet- mnist. rows histograms feature values. bottom rows joint distributions feature values. note feature values center entry squares nonsense samples pure gaussian noise. conﬁdence produced layer. inspired relu propose mirrored rectiﬁed linear unit paper call mrelu symmetric activation functions since reﬂectional symmetry. radial basis function adopted paper derivative although parameter-free needed ﬂexibility achieved argument rescaling shifting preceding convolutional layer. requires exponential square calculations. considerable load training test stages. inspired simplicity relu propose mrelu composed basic arithmetic logic calculations compared commonly-used activation functions rectiﬁed linear units sigmoid well known rbfs localizing property. rbfs suppress signals deviate normal either direction counterparts suppress signals unilaterally. suppressing signals abnormal samples ensure strong prediction figure using units build classiﬁcation networks. basic block using layers judge whether input hypersphere approximately. network using basic blocks perform classiﬁcation task. example approximate unit disk three units fig. basic block proof lemma build classiﬁcation network. shown fig. basic block template sample choose maximum ymax across basic blocks. ymax larger threshold proof lemma output category chosen basic block otherwise give nonsense prediction. interestingly allowed units basic block output increasingly similar high-dimension shown fig. .b-c. limit using inﬁnite number units network high-dimension rbfs approximate function arbitrary precision products rbfs exactly mimic high-dimensional therefore construct network function approximation. however product-of-units scheme compatible popular cnns work mrelus. establish property weaker function approximation closer ties problem sample classiﬁcation. express problem geometric form. suppose template samples uniform data space ﬁdelity threshold input sample certain classify category otherwise regard nonsense sample. assume problem selfconsistent i.e. template samples different categories overlapping radius-r hyperspheres. sufﬁcient method judge whether sample radius-r hypersphere centered given sample first lemma given hypersphere build network layers judge whether given sample hypersphere arbitrary precision. carefully chosen parameter sk’s output ﬁrst layer single output second layer. achieve given error rate sufﬁcient threshold holds volume closed subspace popular cnns convolutional layers cascaded learn increasingly abstract features empirical distributions features fairly compact symmetric thus feasible suppress unusual signals using safs similarly shaped. insert additional layers immediately convolutional layers suppress unusual signals shown fig. relu activation layers discarded since outputs non-negative. thing sigmoid activation layers. also layer fully-connected layer ﬁnal layer insert layers fully-connected layers. remainder call modiﬁed models robust cnns original ones plain cnns. correct label {yi} prediction robust parameter amount categories weighting parameters. designed prefer large relatively absolutely. necessary involve p-order errors sufﬁciently large thus recognize nonsense samples would small y’s. experiments. figure perturbing samples plain robust cnns. clean sample conﬁdence score category. xadv−robust xadv−plain adversarial samples robust plain cnns respectively. ...→ path crossing layers words indices cells whose receptive ﬁeld contain unusual signals away high-density regions considerably small. consequently according derivatives safs shown fig. also small nearly zero implying unlikely large. norm gradient respect small make large perturbation achieve noticeable change shown fig. conclusion achieve adversarial sample successfully perturbation robust would larger plain cnn. adversarial training requires repeated generations adversarial samples increases training load signiﬁcantly. paper also training data additional clean samples; instead adversarial samples random perturbation mean training data. mean sample might easily mis-classiﬁed generate nonsense samples perturbing slightly. therefore typical hard instance train robust cnns produce high conﬁdence nonsense however mean sample thus little effect training process. perturb gaussian noise certain number noisy copies. call trick mean training short. suggested randomly perturbed samples little signiﬁcance. interestingly effective network especially adopted together mean training. generate perturbed samples adding perturbations randomly drawn w×h×c original samples. perturb fraction train leave others untouched. call trick random training short. standard stochastic gradient descent method train robust cnns. unnecessary pretraining stage centers rbfs parameter-free. batch normalization trick necessary accelerate training robust cnns prevent gradient vanishing. well-studied datasets mnist cifar- experiments. following ﬁgures tables plain mrelu refer respectively plain cnns robust cnns using robust cnns using mrelus. ﬂags indicate adversarial random mean training. plain cnns typical models implemented default settings train them except whitening normalization. plan release source code data upon acceptance. related literature cnns expected robust three kinds sample adversarial nonsense noisy. proposals safs correct robust cnns accurate plain cnns; adversarial/noisy samples tiny perturbations classiﬁcation accuracy drop remarkably; severely perturbed samples pure noise images classiﬁed nonsense. nonsense case little different models without explicit nonsense category consider predict sample nonsense conﬁdence scores meaningful categories threshold e.g. gradient towards smaller loss certain incorrect category strength parameter xadv original adversarial/nonsense samples respectively. nonsense samples generated stationary gaussian noise shifted scaled cover range noisy samples generated perturbing clean samples stationary gaussian noise. collect classiﬁcation accuracies varying perturbation strength rather single strength value better understand robustness cnns. meanwhile present lenet- plain mnist please table structure. clean samples follow train test set. groups nonsense samples. cnns trained epochs. hybrid loss functions robust cnns. present accuracies error rates fig. table clear cnns using safs much robust plain cnn. best mrelu-r-m makes marginally errors plain clean samples adversarial samples perturbation strength noisy samples greatly superior performance adversarial noisy samples large perturbation nonsense samples. particularly accuracy mrelu-r-m adversarial perturbations strength much lower maxout trained using adversarial training random training effective improving robustness cnns adversarial noisy samples. opinion random perturbations train samples make large-output/non-zero widths safs effectively broader improving robustness perturbations moderate strength. using training tricks improve cnns considerably robust nonsense noisy samples even plain cnn. adversarial training recommended previous literatures much less effective improving robustness adversarial nonsense samples. probably insufﬁcient number adversarial training rounds. sec. train cnns combination random mean training. show examples mrelu-r-m classiﬁcations fig. robust gives correct predictions even severe distorted samples. make incorrect predictions samples bounded color boxes images hard even human being. case green boxes different predictions wrong sensible classify samples nonsense category. table structures plain robust cnns mnist. parameters convolutional layers number hidden units fully-connected layers max-max pooling. sloss-softmaxloss. hloss-hrbridloss. figure accuracies cnns mnist test set. accuracies adversarial nonsense noisy samples respectively. horizontal axes perturbation strength β’s. figure examples mrelu-r-m classiﬁcations mnist test set. prediction conﬁdence individual samples. ns-nonsense. rows adversarial samples. nonsense samples. noisy samples. training augmented randomly reﬂecting samples vertical mid-line. groups nonsense samples. robust cnns trained epochs twice plain cnn. hybrid loss functions robust cnns. present accuracies error rates fig. table since cifar- images colored perturbation much easier perceive. therefore perturbations smaller magnitude mnist. mnist robust cnns much robust plain cnn. best mrelu-r-m makes marginally errors plain clean samples noisy samples greatly superior performance noisy samples large perturbation adversarial samples nonsense samples. however improvement cifar- large mnist. reason sufﬁcient training samples cifar- train perfect classiﬁer thus lots samples close decision boundaries easy perturb adversary. robustness plain-r-m nonsense samples good mnist curves fig. seem odd. leave future work. though believe plain perform better advanced training tricks hypothesize connection robustness generalization capability. thus using mrelus generalize slightly better test set. show examples mrelu-r-m classiﬁcations fig. model makes correct predictions samples makes incorrect predictions samples squares severest perturbation. experiments show effective safs improve robustness cnns. without substantial changes accuracies clean samples obtain remarkably better robustness adversarial nonsense noisy samples. supports proposal safs improve robustness cnns suppressing unusual signals. since change activation functions cnns leaving structure training strategies optimization methods untouched implies severe weaknesses existing frameworks. nevertheless contrast popular activation functions including sigmoid relu safs less documented support neuroscience research. furthermore remains question accommodate safs better ﬁne-tuning structure training strategies better table structures plain robust cnns cifar-. parameters convolutional layers number hidden units fully-connected layers max-max pooling. avg-average pooling. sloss-softmaxloss. hloss-hrbridloss. figure accuracies cnns cifar- test set. accuracies adversarial nonsense noisy samples respectively. horizontal axes perturbation strength β’s. figure examples mrelu-r-m classiﬁcations cifar- test set. prediction conﬁdence individual samples. sp-ship. bd-bird. fr-frog. ap-airplane. ns-nonsense. rows adversarial samples. nonsense samples. noisy samples.", "year": 2016}