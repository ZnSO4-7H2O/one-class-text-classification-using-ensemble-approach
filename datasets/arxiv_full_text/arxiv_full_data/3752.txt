{"title": "CBinfer: Change-Based Inference for Convolutional Neural Networks on  Video Data", "tag": ["cs.CV", "cs.AI", "cs.LG", "cs.PF", "eess.IV"], "abstract": "Extracting per-frame features using convolutional neural networks for real-time processing of video data is currently mainly performed on powerful GPU-accelerated workstations and compute clusters. However, there are many applications such as smart surveillance cameras that require or would benefit from on-site processing. To this end, we propose and evaluate a novel algorithm for change-based evaluation of CNNs for video data recorded with a static camera setting, exploiting the spatio-temporal sparsity of pixel changes. We achieve an average speed-up of 8.6x over a cuDNN baseline on a realistic benchmark with a negligible accuracy loss of less than 0.1% and no retraining of the network. The resulting energy efficiency is 10x higher than that of per-frame evaluation and reaches an equivalent of 328 GOp/s/W on the Tegra X1 platform.", "text": "compute infrastructure energy. furthermore collecting large amounts data central site raises privacy concerns required high-bandwidth communication channel causes additional reliability problems potentially prohibitive cost deployment operation alternative on-site near sensor embedded processing largely solves aforementioned issues transmitting less sensitive condensed information—potentially security alerts case smart surveillance camera—but imposes restrictions available computation resources power. push evaluation networks real-time semantic segmentation object detection reach even powerful embedded platforms available today high-resolution video data however exactly systems required wide range applications limited cost latency large efforts thus already taken develop optimized software heterogeneous platforms design specialized hardware architectures adapt networks avoid expensive arithmetic operations however either provide strong enough performance boost already theoretical limit achieved given platform inflexible commercially available incur considerable accuracy loss. thus essential extend available options efficiently perform inference cnns. paper propose novel method perform inference convolutional neural networks video data static camera limited frame-to-frame changes. evaluations nvidia tegra show average speed-up possible negligible accuracy loss cudnn-based per-frame evaluation urban video surveillance dataset. pushes real-time inference high-resolution frames within computation power budget current embedded platforms. organization paper. next section discuss related work proposing change-based convolution algorithm section present experimental results discuss section conclude paper section related work section first discuss available datasets cnns evaluate proposed algorithm. describe existing optimized implementations inference existing approximations trading accuracy throughput. finally survey related approaches exploiting limited changes video data reduce computational effort required perform inference. abstract extracting per-frame features using convolutional neural networks real-time processing video data currently mainly performed powerful gpu-accelerated workstations compute clusters. however many applications smart surveillance cameras require would benefit on-site processing. propose evaluate novel algorithm changebased evaluation cnns video data recorded static camera setting exploiting spatio-temporal sparsity pixel changes. achieve average speed-up cudnn baseline realistic benchmark negligible accuracy loss less retraining network. resulting energy efficiency higher per-frame evaluation reaches equivalent gop/s/w tegra platform. introduction computer vision technology become ingredient automatized data analysis broad range real-world applications smart cameras video surveillance robotics industrial quality assurance medical diagnostics advanced driver assistance systems recently become popular rising reliability algorithms industry interest fostered procedure wealth research projects yielding fierce competition many benchmarks datasets imagenet/ilsvrc coco cityscapes benchmarks scientists academia industry players evaluate latest algorithms. recent years competitive approaches address many challenges relied machine learning complex multi-layered trained feature extractors commonly referred deep learning frequently used flavor deep learning techniques convolutional neural networks since landslide success ilsvrc competition hand-crafted features accuracy improved year-over-year even exceeding human performance complex dataset cnns keep expanding areas computer vision data analytics general unfortunately high accuracy cnns comes high computational cost requiring powerful servers train networks several weeks using hundreds gigabytes labeled data. effort costly one-time endeavour done offline many applications. however inference state-of-the-art cnns also requires several billions multiplications additions classify even resolution images today’s standards cases offloading centralized compute centers powerful servers also possible inference deployment extremely costly terms suitable datasets neural networks evaluations interested performing object detection semantic segmentation often applied high-resolution images video streams frame rates frame/s meaningful applications. still image object classification considered solved achieved beyond human accuracy rapidly increasing interest extracting information video data e.g. video tagging action recognition datasets recently become available youtube-m specifically interested video sequences obtained static camera. dataset exist specifically targeted person tracking and/or re-identification provide labeled data multi-class object detection segmentation. however dataset used provides ground truth labels -class semantic segmentation urban street surveillance perspective work individual images several surrounding unlabeled frames trained convolutional network available. example image labeled provided shown figure sample sequence images visualized figure latest wave interest neural networks attributed sudden success driven availability large datasets increasingly powerful computing platforms. economical practicable solutions training medium-sized cnns workstation gpus. available software frameworks implement train cnns provide strong support kind platform. massive amounts compute time spent training cnns spurred development highly optimized implementations. first widely used frameworks relied custom implementations converged methods relying matrix-multiplications leveraging availability highly optimized code blas libraries fact gpus capable achieving throughput within percent peak performance type workload. specialized libraries nvidia’s cudnn nervana systems’ neon provide additional performance gains assembly-level implementations additional algorithmic improvements winograd fft-based convolution specific implementation nonbatched inference embedded platform building matrix multiplication documented also showing time spent computing convolutions. admitting limited accuracy losses order gain higher throughput approximating existing networks inference algorithms arithmetic operations help overcome computational obstacles preventing widespread adoption cnn-based algorithms embedded mobile platforms. analysis retraining networks adapt quantized weights activations exist. fixed-point methods limited many off-the-shelf software programmable platforms benefit vectorization lower-precision operations extreme methods enforce binary weights cases also binary activations means multiplications dropped entirely case binary activations even collapse add/subtract operations xnor count operations. many networks quantized without increase error rate trade-off between precision accuracy methods reducing computational effort pruning many small weights zero making possible skip operations sophisticated quantization schemes vector quantization exist compress trained model require specialized hardware bring improvement energy efficiency focusing application-specific accelerators also approximate arithmetic inaccurate multipliers considered research focused optimizing semantic segmentation object detection algorithms better reuse already computed features eliminating non-convolutional elements network simplifying operations network low-rank approximations convolutions simply designing smaller networks state-of-the-art methods evaluated video-based computation reduction obtaining per-frame features naturally seems like easier task frames belong video sequence rather random collection images. limited movement objects frame exploited object tracking working limited search window within frame reducing problem size also simplifying regression task—up tracked target occluded large object. object detection semantic segmentation available work direction limited clockwork cnns authors extended work fully convolutional networks semantic segmentation presents skip connections deconvolution layers refine lower-resolution feature maps obtained deep within network using features extracted early network. exploit fact lowerresolution feature maps within network stable time full-resolution input. thus propose reevaluate first layers last affected skip connections frequently coarse grained feature maps. strong limitation cnns method applied present evaluations based static well dynamic content-adaptive reevaluation schedule showing reduce number full-frame convolutions accuracy starts drop youtube-objects dataset. changing pixels input based threshold difference previous frame update pixels affected them increasing number pixels updated layer-after-layer convolution operations. thus e.g. convolution one-pixel change triggers update pixels next layer pixels another convolution. strided operations reduce effect prevent issue might seem prohibitive multi-layer cnns particularly considering individual pixels might keep exceeding threshold noise. however change spatially local input also output. furthermore noise-like changes likely strong impacts feature maps deeper within network. thus propose perform change-detection input convolution layer—relative previous input—and compute updated value affected output pixels. done without modifications training applied existing pre-trained networks specific evaluate proposed algorithm. propose replace spatial convolution layers change-based spatial convolution layers means adapting widely used simple well-performing matrix-generation matrix-multiplication sequence operations convolution layer computes indexes output channels cout indexes input channels cin. pixel identified tuple denotes support filters kernels computed performing matrix multiplication image matrix constructed yowo |cin| filter matrix given |cout |cin| result matrix stored zero-padding applied construction matrix efficient strided convolution computed dropping unused rows. replace matrix multiplication following sequence processing steps thereby drastically reducing size matrix used main computation step. figure sample video sequence dataset showing frame-by-frame changes overlaying sequence length moving objects small part overall scene affect small share pixels. however approach limited updating entire frames whereas exploit often small parts scene change need reevaluated. aware existing methods exploiting limited changes frames show allow much larger gains throughput. methodology differently previous work looking reevaluating entire frames exploit limited number pixels changing frame-toframe increase throughput without loss classification accuracy. straight-forward pixel-level approach detect processing steps modify standard approach sequence processing steps change detection change indexes extraction matrix generation matrix multiplication output update. following explain individual steps. change detection. step changed pixels detected. define changed pixel absolute difference current previous input feature map/channel exceeds threshold i.e. computation effort step crucial since executed independently whether pixel changed. changes affects region equal filter size output pixels marked updating wheresk filter kernel support e.g.sk filter. implemented clearing change all-zero thread pixel which—if change detected—sets pixels filter support neighborhood resulting change map. count number changed pixels. cannot easily performed parallel implementation split change blocks pixels compute result blocks parallel reassemble result. computed index list later needed access right pixels assemble matrix convolution. matrix generation matrix multiplication. matrix multiplications used many applications highly optimized implementations gemm function provided nvidia cublas library come within percent peak flops capable provide. matrix multiplication-based implementations convolution layer relying widely available highly efficient described earlier section. matrix generated full-sized instead columns corresponding relevant output pixels assembled resulting reduced width equal number output pixels affected changes input image. matrix made filters trained using normal convolution layers keeps dimensions computation effort step proportional number changed pixels matrix multiplication worst case time consuming full-frame convolution. output updating. previously stored results newly computed output values along change indexes list provide updated output feature maps. maximize throughput also include relu activation affected pixels step. memory requirements memory requirements frameworks known high point becomes limiting factor increasing mini-batch size learning thus reducing throughput parallelizing across multiple gpus. requirements different looking embedded inference-only systems inference typically done single frames creating mini-batches would introduce often unacceptable latency benefit limited percent additional performance keep high modularity memory keep matrix often shared among layers although values never reused finishing convolution computation. batch normalization layers considered independent layers output buffer absorbed convolution layer inference. obtain baseline memory requirement compute required memory common frameworks performing convolutions using matrix multiplication batch size assume optimized network minimizing number layers e.g. absorbing batch normalization layers convolution layers using in-place activation layers. values need stored intermediate results values matrix values parameters. optimized sharing among convolution layers keeping memory allocated storing output layers switching back-and-forth them layer-by-layer. reduces memory footprint values total values baseline. applying algorithm requires little memory need store additional intermediate results change matrix changed indexes list matrix shared layers. also need store previous output basis updated output previous input subsequent layer. sample network required another values total values acceptable increase limitation considering modern graphics cards typically come memory even gpu-accelerated embedded platforms nvidia jetson module provide memory. threshold selection proposed algorithm adds parameter convolution layer detection threshold. fixed offline training based sample video sequences. threshold zero yield identical results non-change-based implementation used functional verification. evaluations used following procedure select thresholds start setting thresholds zero. iteratively step figure processing flow change-based convolution algorithm. custom processing kernels shown blue processing steps using available libraries shown green variables sharable among layers shown yellow variables stored per-layer colored orange. size data type tensor storing intermediate results indicated variable name. first last layer sweeping threshold parameter layer keeping maximum value clear performance degradation became noticeable evaluating entire validation set. following evaluations show thresholds need re-calibrated video sequence neither accuracy speed-up overly sensitive them. results discussion section first present evaluation environment analysis baseline compute time breakdown. show threshold parameters selected discussing throughput measurements accuracy-throughput trade-off. finally discuss compute time breakdown changes propagate network confirm quality implementation justify design choices made construction algorithm. evaluation environment algorithm limited scene labeling/semantic segmentation perform evaluations urban surveillance dataset described using corresponding scene labeling using multispectral imaging data. dataset provides training images validation images pixel corresponding ground-truth scene labeling classifying pixel following classes building road tree tram car/truck water distant background. validation labeled images part short video sequences additional frames available frame ground truth labeling available. trained network data described parameters reused unaltered evaluations. procedure perform evaluation visualized figure implemented proposed algorithm using cuda wrapped modules torch framework evaluated performance jetson board jetpack performance baseline entire change-based implementation pixel-wise classification relying nvidia’s cudnn includes optimizations discuss performance proposed algorithm analyze baseline throughput compute time breakdown table clearly time spent performing convolutions layers performing convolutions belonging feature extraction part network dominant overall computation time thus specifically focus analyses layers replacing cbconv layer. threshold selection algorithm introduces threshold parameter layer outline selection process section might want leave variable investigate throughput accuracy trade-off also want ensure single layer’s threshold limiting overall accuracy aligning tipping point accuracy starts drop. choose thresholds conservatively accepting little accuracy drop since classification error focused around moving objects area interest. sweep parameters layer determine increase error first layer select repeating layers using already chosen thresholds previous layers selecting selection thresholds scale jointly analyze trade-off classification accuracy concisely accuracy individual test sequences visualized clearly show similar behavior plateau clear point steep increase error rate. figure analysis increase pixel classification error rate selecting certain change detect threshold. analysis conducted layer-by-layer error increase layer includes error introduced previous layers’ threshold choice accuracy-throughput trade-off scenarios drop accuracy unacceptable many applications allow trade-off accuracy throughput—after choosing specific already implies selecting network associated accuracy computational cost. show performance gain figure indicated baseline analyzing entire frame network using cudnn. extreme case setting thresholds zero entire frame updated results clear performance loss change detection overhead well fewer optimization options less cache-friendly access patterns generating matrix. increasing threshold factor throughput increases rapidly frame/s starts saturating change detection step well non-varying components like pooling pixel classification layers becoming dominant number detected changed pixels decrease. almost reach plateau already threshold factor construction almost accuracy loss. average frame rate different sequences near frame/s point—an improvement cudnn baseline frame/s. has—while still close faster baseline—a significantly lower throughput sequences. show typical scenarios shown figure sequences shows busy situation entire road full vehicle moving. aggregate number changed pixels across layers visualized figure sequences trigger less maximum possible number changes aforementioned exceptional case significantly higher share around throughput accuracy full-frame inference. increasing threshold factor steps immediately results significant throughput gain sequences trade-off starts frame rates close saturation frame/s. frame sequence already deviate norm behaves differently well. however adaptive selection threshold factor simple control loop getting feedback number changed pixels could allow guaranteed throughput reducing accuracy cases left explored future work. compute time breakdown section specifically table already discussed compute time breakdown entire network using frameby-frame analysis. gain in-depth understanding limiting factors proposed algorithm show detailed compute time breakdown change-based convolution layers figure time spent change detection similar across conv layers aligns well expectations since feature volume input values identical smaller step already makes overall time underlines importance simple change detection function increase compute time change detection offset time savings steps reducing number changes significantly. change indexes extraction effort linear number pixels clear drop expected. however since well parallelizable much additional gain comparing effort generate matrix dependent number changed pixels number feature maps filter size. however mostly important time spent shuffling data around generate significantly smaller actual matrix multiplication clearly makes largest share. subsequent update output values including activation uses negligible part overall processing time. important aspect directly visible overall compute time critical part convolution activation shrunk tremendously remaining steps like polling pixel-wise classification take compute time move target future optimizations. figure analysis change propagation. shows changes detected layer using thresholds determined section upper part image several single-pixel changes noise. show changed pixels layer based worst-case propagation assumed dropping layer change detection step applying change detection instead change propagation construction algorithm argued change detection performed every convolution layer modularity also justifying worst-case change propagation assume otherwise would result higher computational effort. experimentally verified show example case figure layer number changes reduced layer clearly pays layer analyze situation layer closely. previous section know change detection makes overall compute time layer scaling time generate matrix perform matrix multiplication update output clearly exceeds overhead introduced change detection step. change extraction step cannot dropped fact change detection replaced change propagation kernel. energy efficiency measured current consumption entire jetson board ethernet connection off-board peripherals running continuous workload. average current running baseline cudnn-based implementation measured power consumption dropped running cbinfer. idling measured normal conditions raised enforcing maximum clock frequency done maximize throughput earlier measurements. used computational complexity gop/frame number operations additions multiplications required convolution layers. thus obtain gop/s gop/s/w cudnn baseline. proposed cbinfer procedure obtain per-frame inference equivalent throughput gop/s energy efficiency boost gop/s/w. conclusion proposed evaluated novel algorithm changebased evaluation cnns video recorded static camera setting exploiting spatio-temporal sparsity pixel changes. results clearly show even choosing change detection parameters conservatively introduce significant increase misclassified pixels semantic segmentation average speed-up cudnn baseline achieved using optimized implementation. in-depth evaluation throughput-accuracy trade-off shows aforementioned performance jump without loss shows throughput increased expense accuracy. analysis compute time split-up individual steps algorithm show despite overhead fully loaded performing multiply-accumulate operations update changed pixels using highly optimized cublas matrix multiplication. analysis changes propagate underline optimality structure proposed algorithm. resulting boost energy efficiency per-frame evaluation average equivalent gop/s/w tegra platform. alessandro aimar hesham mostafa others. nullhop flexible convolutional neural network accelerator based sparse representations feature maps. ieee transactions large scale integration systems renzo andri lukas cavigelli others. yodann ultra-low power convolutional neural network accelerator based binary weights. proc. ieee isvlsi. lukas cavigelli dominic bernath others. computationally efficient target classification multispectral image data deep neural networks. proc. spie security defence vol. yu-hsin chen tushar krishna others. eyeriss energy-efficient reconfigurable accelerator deep convolutional neural networks. proc. ieee isscc. matthieu courbariaux yoshua bengio jean-pierre david. binaryconnect training deep neural networks binary weights propagations. adv. nips. deng dong others. imagenet large-scale hierarchical image database. proc. ieee cvpr. philipp gysel mohammad motamedi soheil ghiasi. hardwareoriented approximation convolutional neural networks. iclr workshops. song xingyu others. efficient inference engine feature embedding. http//caffe.berkeleyvision.org jonghoon vinayak gokhale others. efficient implementation deep convolutional neural networks mobile coprocessor. proc. ieee mwscas’. objects context. proc. eccv. jonathan long evan shelhamer trevor darrell. fully convolutional networks semantic segmentation. proc. ieee cvpr. woon-sung park munchurl kim. cnn-based in-loop filtering coding efficiency improvement. proc. ieee image video multidimensional signal processing workshop. adam paszke abhishek chaurasia others. enet deep neural network architecture real-time semantic segmentation. arxiv.. fatih porikli francois bremond others. video surveillance past present future ieee signal processing magazine mohammad rastegari vicente ordonez others. xnor-net imagenet classification using binary convolutional neural networks. arxiv.. joseph redmon santosh divvala others. look once unified real-time object detection. chen zhang zhenman fang others. caffeine towards uniformed representation acceleration deep convolutional neural networks. proc. iccad. york usa.", "year": 2017}