{"title": "Ranking Algorithms by Performance", "tag": ["cs.AI", "cs.LG"], "abstract": "A common way of doing algorithm selection is to train a machine learning model and predict the best algorithm from a portfolio to solve a particular problem. While this method has been highly successful, choosing only a single algorithm has inherent limitations -- if the choice was bad, no remedial action can be taken and parallelism cannot be exploited, to name but a few problems. In this paper, we investigate how to predict the ranking of the portfolio algorithms on a particular problem. This information can be used to choose the single best algorithm, but also to allocate resources to the algorithms according to their rank. We evaluate a range of approaches to predict the ranking of a set of algorithms on a problem. We furthermore introduce a framework for categorizing ranking predictions that allows to judge the expressiveness of the predictive output. Our experimental evaluation demonstrates on a range of data sets from the literature that it is beneficial to consider the relationship between algorithms when predicting rankings. We furthermore show that relatively naive approaches deliver rankings of good quality already.", "text": "abstract. common algorithm selection train machine learning model predict best algorithm portfolio solve particular problem. method highly successful choosing single algorithm inherent limitations choice remedial action taken parallelism cannot exploited name problems. paper investigate predict ranking portfolio algorithms particular problem. information used choose single best algorithm also allocate resources algorithms according rank. evaluate range approaches predict ranking algorithms problem. furthermore introduce framework categorizing ranking predictions allows judge expressiveness predictive output. experimental evaluation demonstrates range data sets literature beneﬁcial consider relationship algorithms predicting rankings. furthermore show relatively na¨ıve approaches deliver rankings good quality already. algorithm selection problem select appropriate algorithm solving particular problem. especially relevant context algorithm portfolios single solver replaced solvers mechanism selecting subset particular problem. common approach building selector machine learning induce model algorithms portfolio. models take many different shapes forms. common ones include classiﬁcation clustering approaches select single solver regression approaches predict performance portfolio solver independently choose several according predictions. approaches implicitly compute ranking algorithms portfolio almost none make explicit paper investigate approaches explicitly rank portfolio algorithms according performance. instead predicting best algorithm compute ranking them. several advantages approach. information algorithms several solving problem problems. algorithm chosen initially performs worse expected next best chosen without make another prediction. processor available several parallel. limits impact predictions. techniques could also used derive performance ranking algorithms abundant literature researchers investigated extent performance rankings predicted practice. shows prediction performance target algorithms makes incorrect predictions often proposes means mitigating this best algorithm. suggests sophisticated means predicting complete rankings required. paper propose evaluate range different approaches including ones commonly used literature similar purposes data sets also take literature. evaluation ﬁlls much-needed addressing issue predict complete performance rankings algorithms portfolio context. complete ranking required algorithm selection beneﬁcial. predictions algorithm performance always degree uncertainty associated able choose among portfolio algorithms meaningful used mitigate effect this. however order exploited must able predict rankings used reliably know techniques available core contribution paper. furthermore propose framework categorization types predictions rankings derived. framework serves means clarifying formalising problem. particular allows researchers access type ranking predictions making respect ﬁne-grained decisions taken based upon ranking predicting ranking entities problem. machine learning problem known label ranking large body literature related exists. review literature beyond scope paper; interested reader referred recent survey paper focus problem ranking algorithm selection context. therefore approaches investigated based existing techniques algorithm selection rather label ranking. many approaches believe ones presented make sense context familiar algorithm selection researchers. exist many approaches solving algorithm selection problem different means various contexts even cursory survey beyond scope paper. interested reader referred recent survey presented focus approaches immediately relevant paper. propose evaluate framework generate rankings machine learning algorithms. approach predicts compound measure takes accuracy time account derives ranking directly this. later work propose evaluate method retrieve combine rankings training data. recently proposed approach ranking algorithms explicitly uses label ranking techniques machine learning. authors neural network output neuron algorithm portfolio identiﬁes rank. contrast this voting-based approach derive ranking algorithms. k-nearest neighbour model identify cases similar solve. instead predicting score ranking count best algorithm retrieved case vote rank algorithms according that. derive ranking making pairwise comparisons algorithms focus reducing number comparisons made using active learning techniques. ranking based partial order computed using comparisons. statistical relational learning predict complete ranking directly algorithms problem. however select single best algorithm report particular approach competitive. number algorithm selection approaches compute schedules running algorithms portfolio. implicitly allocating resources algorithms determine explicit schedules. cases rankings used implicitly explicitly arrive schedule. examples closest problem solve case base compute schedule solvers based performance problems. predict ranking compute based observed performance. compute schedules algorithms similar focus problem computing schedule ranking known. also determine ranking based observed performance training problems. approaches compute rankings purpose determining long algorithms include machine learning models capable making different types predictions depending leaner used induce model. classiﬁcation models predict labels whereas regression models predict numbers. statistical relational learning relatively area machine learning allows make complex predictions. different types predictions turn used different ways obtain rankings. propose following levels categorise predictive output model respect ranking obtained model heavily inspired theory scales measurement levels proposed correspond types scales. level prediction output single label best algorithm. approach standard classiﬁcation takes. possible construct ranking consider paper. level corresponds nominal scale theory scales measurements. level prediction output ranking algorithms. ranking derived intermediate predictions. relative position algorithms ranking gives indication difference performance. performance difference algorithms rank much higher difference algorithms rank three computing this. statistical relational learning approaches capable making predictions. level corresponds ordinal scale. level prediction output ranking associated scores. ranking derived intermediate predictions. example approach would predict performance algorithm individually construct ranking predictions. difference ranking scores indicative difference performance. level corresponds interval scale. theory scales measurements proposes ratio scale additional level. required framework information would useful purpose ranking algorithms portfolio. ratio scale would example correspond ratio ranking scores baseline e.g. performance model always chooses single overall best algorithm. remainder paper denote framework level within note higher levels strictly dominate lower levels sense predictive output used ends predictive output lower levels. context algorithm selection portfolios examples different levels follows. prediction suitable selecting single algorithm. allows select best solvers running parallel processor machine. allows compute schedule algorithm allocated resources according rank score. note possible compute schedule given ranking associated scores much ﬁne-grained schedule usually computed scores. empirical investigation identify approaches methods predicting rank algorithms problem likely achieve good performance. investigate performance number different approaches several data sets algorithm selection literature. order ranking algorithms predicted directly label. label consists concatenation ranks algorithms. approach conceptually similar approach compute ranking single prediction step. order score training example algorithms portfolio ranked according performance. rank algorithm quantity predict. used regression classiﬁcation approaches. ranking derived directly predictions. approaches solve time time solve problem predicted ranking derived directly this. addition predicting time itself also predicted log. approaches numerous approaches predict solve time identify best algorithm example faster majority vote algorithms ranked number times predicted faster another algorithm. approach used identify best algorithm recent versions satzilla approach individual predictions simple labels aggregation able provide ﬁne-grained scores. evaluate approaches based statistical relational learning predict rankings directly without intermediate predictions. report results competitive using approach. statistical relation learning relatively area machine learning number available implementations limited unable suitable approach. evaluate performance four data sets taken literature. take sets training data satzilla data consists instances categories hand-crafted industrial. contain instances denoted sat-han sat-ind respectively. attributes satzilla authors describe instance select solver portfolio solvers sat-han solvers sat-ind. adjusted timeout values reported training data available website seconds consultation satzilla team reported timeout values incorrect. random tracks. denoted qbf. attributes calculated instance select portfolio solvers. solver instance seconds. solver memory unable solve instance assumed timeout value runtime. experiments machine dual four core intel processor ram. last data denoted taken selects portfolio solvers total constraint problem instances problem classes attributes each. weka machine learning toolkit train models make predictions. obvious machine learning algorithms perform well evaluated approaches using adaboostm bayesnet decisiontable neighbours jgraft jrip libsvm radial basis function kernel multilayerperceptron oner part randomforest randomtree reptree simplelogistic algorithms classiﬁcation additiveregression gaussianprocesses libsvm kernels linearregression mrules reptree smoreg algorithms regression. algorithms used standard parameters weka. approaches agnostic underlying machine learning algorithm used make particular prediction required. chose include large number different machine learning algorithms evaluation able judge objectively performance particular approach rather performance combination approach underlying machine learning algorithm. averaging number machine learning algorithms mitigate distorting effects individual combinations have. experiments include total classiﬁcation regression algorithms. rank prediction approaches necessary several layers machine learning algorithms. example faster difference classiﬁcation approach regression algorithm used predict performance difference pair algorithms classiﬁcation algorithm combine predictions. several layers machine learning algorithms required stacked follows. ﬁrst layer trained original training features original problems. prediction models ﬁrst layer used train model second layer takes predictions earlier layer input. output ﬁnal prediction compute ranking. evaluated possible combinations machine learning algorithms approaches. case layer models required considered combinations algorithms several layers. total combinations considered. practice memory took long complete data sets. performance approach data evaluated using stratiﬁed tenfold cross-validation. entire data partitioned subsets roughly equal size roughly distribution best performing algorithms. nine sets combined training remaining used testing. process assess quality predicted ranking comparing actual ranking using spearman correlation test. returns measure association indicating predicted ranking equal inverse actual ranking actual ranking itself respectively. record quartiles association scores problem instances particular data rank prediction approach combination machine learning algorithms. present summary results best worst machine learning algorithms prediction approach. determined follows. prediction type quartiles ranking scores machine learning algorithm summed data sets. machine learning algorithms ranked higher values better. algorithm highest aggregate ranking score best lowest score worst. note best/worst algorithm approach necessarily best/worst approaches. figures give results best worst algorithms respectively. ﬁrst observation rank prediction approaches data sets large spread quality predicted rankings. however time majority predictions best algorithm closer meaning good rankings achieved average. particular median values often close algorithms data thus ranking quality score always worse score occurs cases even worst machine learning algorithm approaches perform consistently well. unfortunately give information approach better. data sets however larger number algorithms thus much richer possible rankings. results achieved data sets informative. presenting results best worst machine learning algorithm rank prediction approach. provide picture overall performance approach regardless underlying machine learning algorithm. approaches presented paper agnostic predictions require achieved. real portfolio setting performance machine learning algorithm underlying approaches would need tuned best performance. paper tuning focus absolute performance performance differences approaches everything else equal. results shown ﬁgures immediately conclusive respect rank prediction approaches provide best performance. present results aggregate form tables tables show quartiles spearman correlation scores data sets rank prediction approaches. show numbers best worst machine learning algorithm. decided comparison order order score order score faster classiﬁcation faster difference classiﬁcation solve time solve time probability best faster majority vote faster difference table ranking quality scores quartiles data sets rank prediction approaches best machine learning algorithm particular prediction approach. higher scores better. numbers rounded three decimal places. order order score order score faster classiﬁcation faster difference classiﬁcation solve time solve time probability best faster majority vote faster difference table ranking quality scores quartiles data sets rank prediction approaches worst machine learning algorithm particular prediction approach. higher scores better. numbers rounded three decimal places. results demonstrate approaches susceptible others performance underlying machine learning algorithms. becomes clear spread best worst algorithm cases almost difference whereas cases signiﬁcant difference. overall best approach faster classiﬁcation approach closely followed order approach. faster majority vote order score approaches exhibit good performance well. looking results worst machine learning algorithm best approach order closely followed order score faster classiﬁcation faster majority vote. performed kruskal-wallis rank test across different approaches. differences series quartiles data sets statistically signiﬁcant. wilcoxon signed-rank test pairs approaches suggest statistically signiﬁcant differences though. suggests enough data draw statistically signiﬁcant conclusions entire approaches differences. results clearly demonstrate relationship portfolio algorithms important take account predicting ranking algorithms. general approaches consider algorithms isolation perform worse approaches consider portfolio whole pairs algorithms. exception rule order score approach consistently performs well. result intuitively plausible unexpected paper ﬁrst investigate rigorous empirical evaluation. similar approach considers pairs algorithms compare approaches. show conclusively beneﬁcial terms similarity derived ranking actual ranking. mildly surprised good performance order approach. conceptually simplest approaches evaluated rationale including provide comparison approaches. nevertheless turns simple approach capable producing good rankings even portfolios relatively large number solvers space possible labels large. performance depends course also number rankings actually going predicted potentially large subset rankings never occur training data. caveat mind order approach provide reasonable starting point. performance overall approaches perform better approaches level features overall four approaches. level also contains overall worst approach. especially apparent tables half table contains approaches bottom half ones tables half consistently better bottom half. reason predictions approaches make inherently complex margin error. statistically approaches make simple predictions better chance correct simply luck. machine learning approach would ideally able identify exploit relationship problem features ranking portfolio algorithms statistical approaches ones used beneﬁt higher chance correct pure luck. noted criteria evaluating quality approach computed ranking itself. approaches provide information importantly evaluated according different objective criteria training. however different objectives closely linked. evaluation puts approaches slight disadvantage still demonstrate good performance overall. machine learning literature great care usually taken train evaluate according objective criteria. consciously restrict approaches facilitate this include approaches well give better picture performance wider variety methods. seem strange machine learning researchers common practice algorithm selection original satzilla example trained models predict performance algorithms evaluated terms often algorithm best predicted performance actual best performance. fig. results best machine learning algorithm data rank prediction approach. prediction approach best algorithm data sets shown. thick line center corresponds median bottom ends percentile respectively bottom whiskers maximum minimum respectively. fig. results worst machine learning algorithm data rank prediction approach. prediction approach worst algorithm data sets shown. thick line center corresponds median bottom ends percentile respectively bottom whiskers maximum minimum respectively. presented evaluated several approaches predicting ranking algorithms portfolio particular problem. vast number publications propose evaluate methods choosing best algorithm concerned predicting complete ranking algorithms. information becoming increasingly relevant many applications however example increase number processors thus potential running several algorithms time. many approaches reported literature rely least implicitly rankings algorithms example computing schedules according algorithms portfolio. despite this study make prediction practice presented far. literature addressed paper. addition empirical evaluation range approaches presented framework assess power predictions respect deriving ranking. allows classify approaches evaluated compare predictive output. framework inspired theory scales measurement. main important conclusions paper rank prediction approaches consider algorithms isolation perform worse approaches consider combination. surprising given ranking intrinsically concerned relationship algorithms. identiﬁed faster classiﬁcation faster majority vote order approaches deliver best overall performance. complex rely layers machine learning models order approach actually simplest evaluated here. simplicity makes easy implement ideal starting point researchers planning predict rankings algorithms. addition approaches named above predicting order ranking score predicted regression algorithm achieved good performance. proposed framework approaches deliver good performance level provides simpler predictions. many applications desirable however additional information approaches higher level provides. developing approaches able deliver provide good performance possible avenue future work. question predict ranking algorithms ﬁrst step putting approach practical use. future would like evaluate different practical approaches using rankings example running algorithms parallel computing explicit schedule based ranking scores. using predicted rankings practice poses additional challenges overall quality ranking matters also whether algorithms best performance actually ranking. investigating question many possible avenues future work. believe current explosion number processors available even consumer-grade machines thus increased ability", "year": 2013}