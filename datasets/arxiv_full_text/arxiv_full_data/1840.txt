{"title": "Retrofitting Distributional Embeddings to Knowledge Graphs with  Functional Relations", "tag": ["stat.ML", "cs.CL", "cs.LG"], "abstract": "Knowledge graphs are a versatile framework to encode richly structured data relationships, but it not always apparent how to combine these with existing entity representations. Methods for retrofitting pre-trained entity representations to the structure of a knowledge graph typically assume that entities are embedded in a connected space and that relations imply similarity. However, useful knowledge graphs often contain diverse entities and relations (with potentially disjoint underlying corpora) which do not accord with these assumptions. To overcome these limitations, we present Functional Retrofitting, a framework that generalizes current retrofitting methods by explicitly modeling pairwise relations. Our framework can directly incorporate a variety of pairwise penalty functions previously developed for knowledge graph completion. We present both linear and neural instantiations of the framework. Functional Retrofitting significantly outperforms existing retrofitting methods on complex knowledge graphs and loses no accuracy on simpler graphs (in which relations do imply similarity). Finally, we demonstrate the utility of the framework by predicting new drug--disease treatment pairs in a large, complex health knowledge graph.", "text": "figure knowledge graph diverse relation types connect treatments diseases persons known unknown relations. traditional methods assume relations imply similarity would retroﬁt aragorn nazgˆul toward similar embeddings. method ﬁrst learns entity representations based solely distributional data applies retroﬁtting step update representations based structure knowledge graph. modular approach conveniently separates distributional data entity representation learning knowledge graph retroﬁtting model allowing ﬂexibly combine reuse adapt existing representations tasks. however core assumption faruqui al.’s retroﬁtting model connected entities similar embeddings. assumption often fails hold large complex knowledge graphs variety reasons. first subgraphs knowledge graph often contain distinct classes entities naturally embedded disknowledge graphs versatile framework encode richly structured data relationships always apparent combine existing entity representations. methods retroﬁtting pre-trained entity representations structure knowledge graph typically assume entities embedded connected space relations imply similarity. however useful knowledge graphs often contain diverse entities relations accord assumptions. overcome limitations present functional retroﬁtting framework generalizes current retroﬁtting methods explicitly modeling pairwise relations. framework directly incorporate variety pairwise penalty functions previously developed knowledge graph completion. present linear neural instantiations framework. functional retroﬁtting significantly outperforms existing retroﬁtting methods complex knowledge graphs loses accuracy simpler graphs finally demonstrate utility framework predicting drug–disease treatment pairs large complex health knowledge graph. introduction distributional representations concepts often easy obtain unstructured data sets tend provide blurry picture relationships exist concepts. contrast knowledge graphs directly encode relational information difﬁcult summarize graph structure single representation entity. retroﬁtting models primary introduction retroﬁtting faruqui authors showed value retroﬁtting semantic embeddings according minimization weighted least squares problem embedding {ˆqi learned distributional data relative weighting type data. degree model assigns equal weight distributional data structure knowledge graph. recently hamilton presented graphsage two-step method learns aggregation function rd×n condense representations neighbors single point update function rk+d combine aggregation central vertex. here embedding dimensionality aggregation dimensionality number neighbors vertex. note permitted allowing aggregation concatenation. method extremely effective learning representations simple knowledge graphs formulated knowledge graphs multiple types relations. furthermore representation relation known priori useful explicitly penalty function aggregating neighbors point estimate calculating relationship likelihoods graphsage makes difﬁcult encode learn extract representation pairwise relation. relational penalty functions functional retroﬁtting framework models relation penalty function rdi+dj acting pair entities embedding dimensionalities respectively. explicitly modeling relations beconnected vector spaces. extreme case representations entities might derive different underlying data sets. example health knowledge graph subgraphs containing diseases drugs allowed form disjoint vector spaces might even want derive initial representations radically different underlying data sets. second many knowledge graphs contain diverse relationships whose semantics different perhaps even conﬂict similarity. instance knowledge graph figure model faruqui would model embeddings qaragorn qathelas qblackbreath problematic aragorn semantically similar nazgˆul address limitations present functional retroﬁtting retroﬁtting framework explicitly models pairwise relations functions. framework supports wide range different instantiations simple linear relational functions complex multilayer neural ones. here evaluate linear neural instantiations functional retroﬁtting variety diverse knowledge graphs. benchmarking existing approaches framenet wordnet. move medical domain knowledge graphs play important role knowledge accumulation discovery. experiments show even simple instantiations functional retroﬁtting signiﬁcantly outperform baselines knowledge graphs semantically complex relations sacriﬁce accuracy graphs faruqui al.’s assumptions similarity hold. finally model identify promising disease targets existing drugs. notation knowledge graph composed vertices relation types edges edge tuple relationship holds vertices goal learn representations contain information encoded distributional data knowledge graph structure used downstream analysis. throughout paper refer scalar refer propose framework functional retroﬁtting incorporate relationspeciﬁc penalty functions rdi+dj penalizes embeddings entities dimensionalities respectively. gives optimization observed distributional data βijr relative strengths distributional data knowledge graph structure regularizes strength here negative space knowledge graph potential edges annotated knowledge graph. uses penalize relations implied representations annotated graph. populate sample single negative edge outgoing vertex true edge user calibrate trust completeness knowledge graph hyperparameter. contrast prior retroﬁtting work explicitly encodes directed relations. allows model graphs contain diverse relation types entities embedded disconnected vector spaces. here compare performance instantiations linear relations neural relations show even simple models provide signiﬁcant performance improvements. practice recommend users select relation-speciﬁc functions accordance semantics graph’s relations. tween pairs entities functional retroﬁtting supports wide array scoring functions previously developed knowledge graph completion. here present brief review scoring functions; extensive review nickel underlying penalty function faruqui cannot consider multiple types relations. addition models -to- relations well struggles model multivalued relations. transh proposed address limitation using multiple representations single entity relation hyperplanes. relation transh models relation vector hyperplane deﬁned normal vector triple entity embeddings ﬁrst projected hyperplane constraining penalty function transr embeds relations separate space entities relation-speciﬁc matrix rd×k projects entity space relation space shared relation vector translates relation space element-wise tanh operation rdi×dj initialize weights similar manner linear relations update stochastic gradient descent. experiments sample number non-neighbors true neighbors. out-degree vertex relation type hyperparameter trade distributional data structural data sets trust completeness knowledge graph structure. experiments straightforward comparison method faruqui optimize cross-validation. given prior knowledge semantic meaning relations could initialize relations respect meanings test four knowledge graphs. ﬁrst standard lexical knowledge graphs signiﬁcantly improves retroﬁtting quality complex graphs loses accuracy simple graphs. ﬁnal graphs large healthcare ontologies demonstrate scalability framework utility embeddings. graph successively evaluate link prediction accuracy retroﬁtting links relation types. speciﬁcally relation type retroﬁt edges relations type removed. retroﬁtting train random forest classiﬁer predict presence relation entities balanced class labels sample equivalent number non-edges thus random baseline classiﬁcation rate framenet linguistic knowledge graph containing information lexical predicate argument semantics english language. framenet contains distinct entity classes frames lexical units frame meaning lexical unit single meaning word. create graph framenet connect lexical unit frame occurs denote relation frame inverse lexical unit. finally connect frames structure framenet distributional embeddings google news pre-trained wordvec model counts entity type also found distributional corpus shown table wordnet wordnet lexical database consisting words grouped unordered sets synonyms examine performance knowledge graphs predominately satisfy assumptions faruqui extract simple knowledge graph lemmas connections between lemmas annotated wordnet. connections dominated hypernymy hyponymy correlate similarity expect baseline retroﬁtting method perform well. results seen table increased ﬂexibility framework degrade embedding quality even extra ﬂexibility intuitively necessary. here evaluate standard lexical metrics word embeddings word similarity syntatic relations. word similiarity tasks evaluation metric spearman correlation predicted annotated similarities; syntatic relation evaluation metric mean cosine similarity learned representation correct answer prediction vector offset method contrast experiments stochastic behavior stochastic gradient descent training sampling evaluation samples. even though wordnet knowledge graph largely satisﬁes basic assumptions na¨ıve retroﬁtting model ﬂexible framework achieves sustained improvements word similarity datasets syntatic relations snomed-ct snomed-ct ontology clinical healthcare terms concepts including diseases treatments anatomical terms many types entities. publicly available snomedct knowledge graph extracted entities edges different types create distributional embeddings table retroﬁtting framenet. reported values mean standard deviation link prediction accuracies three experiments. number edges used shown edge type. table retroﬁtting snomed-ct. reported values mean standard deviation link prediction accuracies three experiments. number edges used shown edge type. table retroﬁtting roam health knowledge graph. reported values mean standard deviation link prediction accuracies three experiments. number edges used shown edge type. ﬁrst link snomed-ct concept wikipedia articles indexing associated search terms wikidata. aggregate article method arora performs tf-idf weighted aggregation pre-trained term embeddings create sophisticated distributional embeddings snomed-ct concepts. snomed-ct ontology dominated synonymy-like relations expect simple retroﬁtting methods perform well. nevertheless minimal loss link prediction performance using ﬂexible framework implementation supports different function classes represent different relation types; practice recommend users select function classes accordance relation semantics. finally investigate utility novel graph. roam health knowledge graph rich picture world healthcare connections numerous data sources diverse medical ontologies provider proﬁles networks product approvals recalls population health statistics academic publications ﬁnancial data clinical trial summaries statistics many others. june rhkg contains vertices edges attributes. here build instance rhkg using public data sources involving drugs diseases. structure knowledge graph summarized table total select disease–disease relations drug–drug relations drug–disease relations used retroﬁtting. separate drug–disease relations reserved evaluation. different distributional corpora available type entity. first mine clinical texts co-occurrence counts physician notes. counting co-occurrences pertype diabetes mellitus essential hypertension pauciarticular juvenile rheumatoid arthritis cause diseases classiﬁed elsewhere cerebral infarction form pointwise mutual information transform normalization generate embeddings entity. drug embeddings supplement embeddings physician prescription habits. extract prescription counts providers centers medicare medicaid datasetand providers dataset. aggregating prescriptions counts across provider specialty produce -dimensional distributional embeddings drug. finally retroﬁt distributional embeddings structure knowledge graph results shown table framework significantly improves prediction ‘treats’ relations. hypothesize separable nature graph; seen figure retroﬁtting framework linear penalty function learns disease drug subgraphs nearly separable. contrast retroﬁtting methalso investigate predictions induced retroﬁtted representations. interesting healthcare knowledge graphs predict drug retargets diseases annotated treatment relationship drug relationship exist medically. shown table retargets predicted linear retroﬁtting model medically plausible. particular model conﬁdently predicts kenalog would treat contact dermatitis effect also found clinical trial second conﬁdent prediction kenalog would treat pemphigus indicated kenalog’s drug label previously included knowledge graph. third prediction methylprednisolone acetate would treat nephrotic syndrome reasonable drug labelled treat idiopathic nephrotic syndrome. interestingly distributional data embeddings produced baseline identity retroﬁtting model make nonsensical prediction latanoprost medication used treat intraocular pressure would also treat superﬁcial ankle foot injuries. accuracy predictions complex models underscores utility framework retroﬁtting distributional embeddings knowledge graphs relations imply similarity. presented functional retroﬁtting framework post-hoc retroﬁtting entity embeddings structure knowledge graph. explicitly modeling scoring pairwise relations framework allows users encode learn extract information relation semantics simultaneously updating entity representations. framework extends popular concept retroﬁtting knowledge graphs diverse entity relation types. functional retroﬁtting especially beneﬁcial graphs distinct distributional corpora available different entity classes loses accuracy applied simpler knowledge graphs. future work would like explore dynamic updates parameters increase trust graph structure relation functions learned. references sanjeev arora yingyu liang tengyu simple tough-to-beat baseline sentence eminternational conference learning bedtdings. representations collin baker charles fillmore john lowe. berkeley framenet project. proceedings annual meeting association computational linguistics international conference computational linguisticsvolume association computational linguistics pages antoine bordes nicolas usunier alberto garciaduran jason weston oksana yakhnenko. translating embeddings modeling multirelational data. advances neural information processing systems. pages manaal faruqui jesse dodge sujay kumar jauhar chris dyer eduard hovy noah smith. retroﬁtting word vectors semantic lexicons. proceedings conference north american chapter association computational linguistics human language technologies. association computational linguistics pages finkelstein evgeniy gabrilovich yossi matias ehud rivlin zach solan gadi wolfman eytan ruppin. placing search context concept revisited. proceedings international conference world wide web. pages tomas mikolov ilya sutskever chen greg corrado jeff dean. distributed representations words phrases compositionality. advances neural information processing systems. pages tomas mikolov wen-tau geoffrey zweig. linguistic regularities continuous space proceedings word representations. conference north american chapter association computational linguistics human language technologies. volume pages nikola mrkˇsic diarmuid os´eaghdha blaise thomson milica gaˇsic lina rojas-barahona pei-hao david vandyke tsung-hsien steve young. counter-ﬁtting word vectors linguistic constraints. proceedings conference north american chapter association computational linguistics human language technologies. pages richard socher danqi chen christopher manning andrew reasoning neural tensor networks knowledge base completion. advances neural information processing systems. pages zhen wang jianwen zhang jianlin feng zheng chen. knowledge graph embedding translating hyperplanes. twenty-eighth aaai conference artiﬁcial intelligence. token frame frame frame token lexical unit frame frame inheritance frame frame using reframing mapping frame frame frame frame persepctive frame frame precedes frame frame also frame frame causative frame frame inchoative frame frame metaphor child associated morphology interprets direct procedure site pathological process causative agent direct substance occurs active ingredient interpreted occurs subject relationship context associated associated ﬁnding component ﬁnding context replaces associated procedure procedure context access onset associated clinical finding method causative agent part intent direct morphology indirect procedure site ﬁnding method direct device procedure site associated morphology uses device uses uses substance specimen associated ﬁnding course measured component ﬁnding informer plain text form form plain text form indirect procedure site access instrument associated procedure cause method procedure morphology direct morphology used occurs device used temporally followed instrumentation access instrument episodicity associated etiologic ﬁnding subject relationship context procedure device direct substance revision status direct device specimen procedure extent procedure device surgical approach referred priority specimen procedure substance used specimen source identity subject information scale type route administration specimen indirect device course dose form ﬁnding site component possibly equivalent deﬁnitional manifestation interpretation temporal context part measured component focus temporally follows direct procedure site laterality clinical course approach specimen source topography priority focus uses access device indirect morphology communication wound specimen substance uses energy dose form associated etiologic ﬁnding specimen source topography severity deﬁnitional manifestation property specimen source morphology specimen substance recipient category approach interpretation indirect morphology ingredient ingredient descendent treats active ingred. child active ingred. tradename tradename inverse symptom part part precise ingred. precise ingred. possibly equiv. causative agent form form component includes dose form", "year": 2017}