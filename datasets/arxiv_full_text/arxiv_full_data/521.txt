{"title": "Learning linearly separable features for speech recognition using  convolutional neural networks", "tag": ["cs.LG", "cs.CL", "cs.NE"], "abstract": "Automatic speech recognition systems usually rely on spectral-based features, such as MFCC of PLP. These features are extracted based on prior knowledge such as, speech perception or/and speech production. Recently, convolutional neural networks have been shown to be able to estimate phoneme conditional probabilities in a completely data-driven manner, i.e. using directly temporal raw speech signal as input. This system was shown to yield similar or better performance than HMM/ANN based system on phoneme recognition task and on large scale continuous speech recognition task, using less parameters. Motivated by these studies, we investigate the use of simple linear classifier in the CNN-based framework. Thus, the network learns linearly separable features from raw speech. We show that such system yields similar or better performance than MLP based system using cepstral-based features as input.", "text": "dimitri palaz idiap research institute martigny switzerland ecole polytechnique f´ed´erale lausanne lausanne switzerland dimitri.palazidiap.ch automatic speech recognition systems usually rely spectral-based features mfcc plp. features extracted based prior knowledge speech perception or/and speech production. recently convolutional neural networks shown able estimate phoneme conditional probabilities completely data-driven manner i.e. using directly temporal speech signal input. system shown yield similar better performance hmm/ann based system phoneme recognition task large scale continuous speech recognition task using less parameters. motivated studies investigate simple linear classiﬁer cnn-based framework. thus network learns linearly separable features speech. show system yields similar better performance based system using cepstral-based features input. state-of-the-art automatic speech recognition systems typically divide task several sub-tasks optimized independent manner ﬁrst step data transformed features usually composed dimensionality reduction phase information selection phase based task-speciﬁc knowledge phenomena. phases carefully hand-crafted leading state-of-the-art features frequency cepstral coefﬁcients perceptual linear prediction cepstral features second step likelihood subword units phonemes estimated using generative models discriminative models. ﬁnal step dynamic programming techniques used recognize word sequence given lexical syntactical constraints. recently hybrid hmm/ann framework growing interests using intermediate representations like short-term spectrum instead conventional features cepstral-based features. representations ﬁlterbank output spectrum proposed context deep neural networks recent study shown possible estimate phoneme class conditional probabilities using temporal speech signal input convolutional neural networks system yielded similar better results timit phoneme recognition task standard hybrid hmm/ann systems. also showed system scalable large vocabulary speech recognition task case cnn-based system able outperform hmm/ann system less parameters. paper investigate features learning capability based system simple classiﬁers. speciﬁcally replace classiﬁcation stage based system non-linear multi-layer perceptron linear single layer perceptron. thus features learned cnns trained linearly separable. evaluate proposed approach phoneme recognition task timit corpus large vocabulary continuous speech recognition corpus. compare approach conventional hmm/ann system using cepstral-based features. studies show cnn-based system using linear classiﬁer yields similar better performance ann-based approach using mfcc features fewer parameters. remainder paper organized follows. section presents motivation work. section presents architecture proposed system. section presents experimental setup section presents results. section presents discussion conclude paper. speech recognition designing relevant features trivial task mainly fact speech signal non-stationary relevant information present different level namely spectral level temporal level. inspired speech coding studies feature extraction typically involves modeling envelop short-term spectrum. common features along line frequency cepstral coefﬁcient perceptual linear prediction cepstral coefﬁcient features based obtaining good representation short-term power spectrum. computed following series steps presented figure extraction process consists transforming temporal data frequency domain ﬁltering spectrum based critical bands analysis derived speech perception knowledge applying non-linear operation applying transformation reduced dimension decorrelated features. process models local spectral level information short time window. model temporal variation intrinsic speech signal dynamic features computed taking ﬁrst second derivative static features longer time window concatenate together. resulting features acoustic modeling part speech recognition system based gaussian mixture model artiﬁcial neural networks case neural networks classiﬁer outputs conditional probabilities denoting input feature class. recent years deep neural network based deep belief network based approaches proposed yield state-of-the-art results speech recognition using neural networks composed many hidden layers. case networks initialized unsupervised manner. original work relied mfcc features several approaches proposed ‘intermediate representations input. words approaches discard several operations extraction pipeline conventional features instance ﬁlterbank energies used input convolutional neural networks based systems deep proposed combination different features also investigated learning features directly speech signal using neural networks-based systems investigated. jaitly hinton learned features post-processed adding temporal derivatives used input another neural network. recent study investigated acoustic modeling using speech input t¨uske study showed speech based system outperformed spectral feature based system. recent studies showed possible estimate phoneme class conditional probabilities using temporal speech signal input convolutional neural networks system composed several ﬁlter stages performs features learning step implemented convolution max-pooling layers classiﬁcation stage implemented multi-layer perceptron. stages trained jointly. phoneme recognition large vocabulary continuous speech recognition task showed system able learn features speech signal yielded performance similar better conventional based system takes cepstral features input. proposed system needed less parameters yield similar performance conventional systems suggesting learned features seems somehow efﬁcient cepstral-based features. motivated studies goal present paper ascertain capability convolutional neural network based system learn linearly separable features data-driven manner. replace classiﬁer stage cnn-based system non-linear multi-layer perceptron linear single layer perceptron. objective show proposed approach yields state-of-the-art performance rather show learning features datadriven manner together classiﬁer leads ﬂexible features. using features input linear classiﬁer yields better performance slp-based baseline system almost reach performance mlp-based system. network given sequence input signal split frames outputs score classes frame. network architecture composed several ﬁlter stages followed classiﬁcation stage. ﬁlter stage involves convolutional layer followed temporal pooling layer non-linearity processed signal coming stages classiﬁcation stage case either multi-layer perceptron linear single layer perceptron outputs conditional probabilities class frame classical linear layers standard mlps accept ﬁxed-size input vector convolution layer assumed sequence vectors/frames xt}. convolutional layer applies linear transformation successive windows frames. example transformation frame formally written figure convolutional neural network based architecture estimates conditional probabilities class frame several stages convolution/pooling/tanh might considered. classiﬁcation stage multi-layer perceptron single layer perceptron. paper investigate using cnn-based approach phoneme recognition task large vocabulary continuous speech recognition task. section present tasks databases baselines hyper-parameters networks. ﬁrst experiment propose phoneme recognition study cnn-based system used estimate phoneme class conditional probabilities. decoder standard decoder constrained duration states considering phoneme equally probable. evaluate scalability proposed system large vocabulary speech recognition task corpus. cnn-based system used compute posterior probabilities contextdependent phonemes. decoder hmm. scaled likelihoods estimated dividing posterior probability prior probability class estimated counting training set. hyper parameters language scaling factor word insertion penalty determined validation set. phoneme recognition task timit acoustic-phonetic corpus. consists training utterances speakers excluding sentences. crossvalidation consists utterances speakers. core test used report results. contains utterances speakers excluding validation set. hand labeled phonetic symbols mapped phonemes additional garbage class presented large vocabulary speech recognition task wall street journal corpus formed combining data databases sampled khz. contains sequences representing around hours speech. percent taken validation set. nov’ selected test set. contains sequences speakers. dictionary based phoneme context-independent phonemes. tied-states used experiment. derived clustering context-dependent phones hmm/gmm framework using decision tree state tying. dictionary bigram language model provided corpus used. vocabulary contains words. also performed several baseline experiments mfcc input features. computed using hamming window speech signal shift signal represented using th-order coefﬁcients along ﬁrst second derivatives computed frames context. compare approach standard hmm/ann system using cepstral features. train multi-layer perceptron hidden layer referred linear single layer perceptron referred slp. system inputs mfcc several frames preceding following context. pre-train network. baseline performance consistent works hyper-parameters network input window size corresponding context taken along example kernel width shift number ﬁlters convolution layer pooling width kwmp. train based system several ﬁlter stages ﬁlter stages. case linear classiﬁer capacity system cannot tuned directly. depends size input classiﬁer adjusted manually tuning hyper-parameters ﬁlter stages. hyper-parameters tuned early-stopping frame level classiﬁcation accuracy validation set. ranges considered grid search reported table ﬁxed learning rate used. example duration experiments implemented using torch toolbox timit corpus using ﬁlter stages best performance found with context samples width ﬁrst convolution frames kernel width second convolution ﬁlters pooling width. using ﬁlter stages best performance found with context samples width ﬁrst convolution frames kernel width convolutions ﬁlters pooling width. using ﬁlter stages best performance found with context samples width ﬁrst convolution frames kernel width convolutions ﬁlters pooling width. also hyper-parameters ﬁxed classiﬁer input. presented table baselines uses nodes hidden layer frames context. based system uses frames context. corpus using ﬁlter stage best performance found with context samples width ﬁrst convolution ﬁlters pooling width. using ﬁlter stages best performance found with context samples width ﬁrst convolution frames kernel width convolutions ﬁlters pooling width. using ﬁlter stages best performance found with context samples width ﬁrst convolution frames kernel width convolutions ﬁlters pooling width. also experiments using hyper-parameters outside ranges considered previously using ﬁlter stages. experiment following hyper-parameters context samples width ﬁrst convolution frames kernel width convolutions ﬁlters pooling width. baselines uses nodes hidden layer frames context. based system uses frames context. results phoneme recognition task timit corpus presented table performance expressed terms phone error rate number parameters classiﬁer ﬁlter stages also presented. using linear classiﬁer proposed cnn-based system outperforms based baseline three ﬁlter stages. observed performance cnn-based system improves increase number convolution layers almost approaches case used classiﬁcation stages. furthermore observed complexity classiﬁcation stage decreases drastically increase number convolution layers. results proposed system ﬁxed output size presented table along baseline performance number parameters classiﬁer ﬁlter stages. proposed based system outperforms based baseline number parameters classiﬁer. fixing output size seems degrade performance compared table indicate better treat feature size also hyper-parameter learn data. results large vocabulary continuous speech recognition task corpus presented table performance expressed term word error rate observe similar trend timit results i.e. increase number convolution layers performance system improves. speciﬁcally observed convolution layers proposed system able achieve performance comparable slp-based system mfcc input. three convolution layers proposed system approaching mlp-based systems. four convolution layers system able yield similar performance baseline using mfcc input. overall observed cnn-based approach lead systems simple classiﬁers i.e. small number parameters thus shifting system capacity feature learning stage system. phoneme recognition study proposed approach even leads system parameters feature learning stage rather classiﬁcation stage. system yields performance similar better baselines system. continuous speech recognition study observed four convolution layers experiment times less parameters classiﬁer three layers experiment still yields better performance. four layers experiement also able yield similar performance mlp-based baseline times less parameters. traditionally speech recognition systems feature extraction acoustic modeling dealt separate steps feature extraction knowledge-driven classiﬁer training data-driven. cnn-based approach speech signal input feature extraction classiﬁer training data-driven. approach allows features ﬂexible learned along classiﬁer. also allows shift system capacity classiﬁer stage feature extraction stage system. studies indicate empirically learned features linearly separable could yield systems perform similar better standard spectral-based systems. potential implication resource speech recognition. part future investigation. work supported hasler foundation grant universal spoken term detection deep learning authors also thank colleague ramya rasipuram providing setup wsj. references abdel-hamid mohamed jiang penn applying convolutional neural networks concepts hybrid nn-hmm model speech recognition. proc. icassp bridle j.s. probabilistic interpretation feedforward classiﬁcation network outputs relationships statistical pattern recognition. neuro-computing algorithms architectures applications davis mermelstein comparison parametric representations monosyllabic word recognition continuously spoken sentences. ieee transactions acoustics speech signal processing hinton deng dahl mohamed jaitly senior vanhoucke nguyen sainath deep neural networks acoustic modeling speech recognition shared views four research groups. signal processing magazine ieee pham largman unsupervised feature learning audio classiﬁcation using convolutional deep belief networks. advances neural information processing systems", "year": 2014}