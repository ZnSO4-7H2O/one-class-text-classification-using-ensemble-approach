{"title": "Simple Image Description Generator via a Linear Phrase-Based Approach", "tag": ["cs.CL", "cs.CV", "cs.NE"], "abstract": "Generating a novel textual description of an image is an interesting problem that connects computer vision and natural language processing. In this paper, we present a simple model that is able to generate descriptive sentences given a sample image. This model has a strong focus on the syntax of the descriptions. We train a purely bilinear model that learns a metric between an image representation (generated from a previously trained Convolutional Neural Network) and phrases that are used to described them. The system is then able to infer phrases from a given image sample. Based on caption syntax statistics, we propose a simple language model that can produce relevant descriptions for a given test image using the phrases inferred. Our approach, which is considerably simpler than state-of-the-art models, achieves comparable results on the recently release Microsoft COCO dataset.", "text": "r´emi lebret∗ pedro pinheiro∗ idiap research institute martigny switzerland ecole polytechnique f´ed´erale lausanne lausanne switzerland remilebret.ch pedroopinheiro.com generating novel textual description image interesting problem connects computer vision natural language processing. paper present simple model able generate descriptive sentences given sample image. model strong focus syntax descriptions. train purely bilinear model learns metric image representation phrases used described them. system able infer phrases given image sample. based caption syntax statistics propose simple language model produce relevant descriptions given test image using phrases inferred. approach considerably simpler state-of-theart models achieves comparable results recently release microsoft coco dataset. able automatically generate description image fundamental problem artiﬁcial intelligent connecting computer vision natural language processing. problem particularly challenging requires correctly recognize different objects images also interact. convolutional neural networks achieved state results different computer vision tasks last years. recently different authors proposed automatic image sentence description approaches based deep neural networks. solutions representation images generated previously trained object recognition tasks start point. vinyals consider problem similar machine translation problem. authors propose encoder/decoder system trained maximize likelihood target description sentence given training image. kiros also consider encoder/decoder pipeline uses combination lstm networks encoding language model decoding. karpathy fei-fei propose approach combination bidirectional recurrent neural networks sentences structured objective responsible multimodal embedding. propose second recurrent neural network architecture generate sentences. similar previous works donahue propose system uses extract image features deep recurrent neural network sentences. networks interact multimodal common layer. fang propose different approach problem rely recurrent neural networks. solution divided three steps visual detector words commonly occur trained using multiple instance learning sentences generated using maximum-entropy language-model sentences re-ranked using sentence-level features proposed deep multimodal similarity model. paper proposes different approach problem. propose system time automatically generates sentence describing given scene relatively simpler recently proposed approaches. model shares similarities previously proposed deep approaches. instance also pre-trained extract image features also consider multimodal embedding. however thanks phrase-based approach complex recurrent network sentence generation. represent ground-truth sentences collection noun verb prepositional phrases. phrase represented mean vector representation words compose train simple linear embedding model transform image representation multimodal space common image phrases used describe them. automatically generate sentences inference time infer phrases correspond sample image simple language model based statistics ground-truth sentences present corpus. writing sentences vary according domain applied. reporting news reviewing item choice words might vary also general structure sentence. sentence structures used describing images therefore identiﬁed. possess distinct structure usually describing different objects present scene interact other. interaction among objects described actions relative position different objects. sentence short long generally respects process. statement illustrated ground-truth sentence descriptions image figure chunking-based approach elements given image usually described noun phrase interactions elements explained using prepositional phrases verb phrases describing image therefore matter identifying constituents describe images. propose train model predict phrases likely given image. phrase representations noun phrases verb phrases often combination several words. good word vector representations obtained quickly many different recent approaches mikolov also showed simple vector addition often produce meaningful results king woman queen. leveraging ability word vector representations compose representations phrases easily computed element-wise addition. phrases sentence identifying likely constituents image propose statistical language model combine generate proper description. general framework deﬁned reduce total number combination thus speed process generating sentences. constrained language model used illustrated figure general noun phrase always followed verb phrase prepositional phrase followed another noun phrase. process repeated times reaching sentence heuristic based analysis syntax sentences image representations representation images choose convolutional neural network. cnns widely used many different vision domains currently state-of-the-art many object recognition tasks. consider pre-trained task object classiﬁcation. solely purpose feature extraction learning done layers. learning common space image phrase representations training images sentence descriptions phrases occuring trainable parameters model. sentences describing given image phrases compose sentence description training objective phrases describe images maximizing probability image represented vector thanks pre-trained cnn. phrase composed words represented vector thanks another pre-trained model word representations. vector representation phrase calculated averaging word vector representations vector representations phrases thus obtained build matrix general encoding function therefore deﬁned image representations vector space phrase representations rn×m initialized randomly trained encode images vectorial space phrases used descriptions. representations images phrases common vector space similarities given image phrases calculated ﬁne-tuned incorporate features coming images. denoting score phrase score interpreted conditional probability applying softmax operation phrases practice formulation often impractical large possible phrases training negative sampling negative sampling approach instead minimize following logistic loss function respect dataset validate model recently proposed coco dataset contains complex images multiple objects. dataset contains total images human annotated sentences. testing images released. thus sets images validation images validation test karpathy fei-fei measure quality generated sentences using popular controversial bleu score feature selection following karpathy fei-fei image features extracted using model generates image representations dimension form input images. sentence features extract phrases training sentences senna software. statistics reported figure conﬁrm hypothesis image descriptions simple syntactic structure. large majority sentences contain four noun phrases. noun phrases interact using verb prepositional phrase. phrases occuring least times training considered. results noun phrases verb phrases prepositional phrases. phrase representations computed averaging vector representations words. obtained word vector representations hellinger word co-occurence matrix following method described lebret collobert word co-occurence matrix built entire english wikipedia symmetric context window words coming frequent words. words therefore also phrases represented -dimensional vectors. learning multimodal representation parameters latter initialized phrase representations. trained negative samples learning rate generating sentences predicted phrases according statistics ground-truth sentence structures nodes consider twenty predicted noun phrases predicted verb phrases predicted prepositional phrases. trigram language model used transition probabilities nodes. probability lexical phrase calculated using previous phrases constraint described figure order reduce number sentences generated consider transitions likely happen thresholding also helps discard sentences semantically incorrect. ranking generated sentences ﬁnal step consists ranking sentences generated choosing highest score ﬁnal output. test image generate sentence candidates using proposed language model. sentence compute vector representation averaging representation phrases make sentence. ﬁnal score sentence computed product sentence vector representation encoded representation sample image table show sentence generation results coco dataset. bleu scores reported -grams. human agreement scores computed comparing ground-truth description others. comparison include results recently proposed models. although test karpathy fei-fei slight variations test sets chosen papers. model gives competitive results n-gram levels. interesting note results close human agreement scores. examples full automatic generated sentences found figure paper propose simple model able automatically generate sentences image sample. model considerably simpler current state uses complex recurrent neural networks. predict phrase components likely describe given image simple statistical language model generate sentences. model achieves promising ﬁrst results. future works include apply model different datasets image-sentence ranking experiments improve language model used. figure quantitative results images coco dataset. ground-truth annotation predicted model generated annotation shown image. last failure samples. donahue jeff hendricks lisa anne guadarrama sergio rohrbach marcus venugopalan subhashini saenko kate darrell trevor. long-term recurrent convolutional networks visual recognition description. corr abs/. fang gupta saurabh iandola forrest srivastava rupesh deng doll´ar piotr jianfeng xiaodong mitchell margaret platt john zitnick lawrence zweig geoffrey. captions visual concepts back. corr abs/. tsung-yi maire michael belongie serge hays james perona pietro ramanan deva doll´ar piotr zitnick lawrence. microsoft coco common objects context. european conference computer vision papineni kishore roukos salim ward todd wei-jing. bleu method automatic evaluation machine translation. proceedings annual meeting association computational linguistics", "year": 2014}