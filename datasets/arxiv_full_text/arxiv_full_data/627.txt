{"title": "Mapping Temporal Variables into the NeuCube for Improved Pattern  Recognition, Predictive Modelling and Understanding of Stream Data", "tag": ["cs.NE", "cs.AI", "stat.ML"], "abstract": "This paper proposes a new method for an optimized mapping of temporal variables, describing a temporal stream data, into the recently proposed NeuCube spiking neural network architecture. This optimized mapping extends the use of the NeuCube, which was initially designed for spatiotemporal brain data, to work on arbitrary stream data and to achieve a better accuracy of temporal pattern recognition, a better and earlier event prediction and a better understanding of complex temporal stream data through visualization of the NeuCube connectivity. The effect of the new mapping is demonstrated on three bench mark problems. The first one is early prediction of patient sleep stage event from temporal physiological data. The second one is pattern recognition of dynamic temporal patterns of traffic in the Bay Area of California and the last one is the Challenge 2012 contest data set. In all cases the use of the proposed mapping leads to an improved accuracy of pattern recognition and event prediction and a better understanding of the data when compared to traditional machine learning techniques or spiking neural network reservoirs with arbitrary mapping of the variables.", "text": "spiking neural network architecture. neucube architecture consists encodes multivariable continuous temporal stream data spike trains; recurrent cube input data mapped learned unsupervised mode; classiﬁer learns supervised mode classify spatiotemporal patterns snncube activities represent patterns input data. effectiveness superiority neucube model brain data demonstrated previous works. studies modelling ability neucube electroencephalography spatiotemporal data measuring complex cognitive brain processes. neucube used modelling recognition complex spatiotemporal data related physical intentional movements. presents results using neucube classify/cluster fmri data uses neucube analysis data recorded person affected absence epileptic. studies neucube help understand brain functional changes better way. studies neucube used model brain data features manually mapped system according spatial location signals sampled from paper present fully automatic input mapping method based graph matching technique enables neucube model spatiotemporal data leads better spatiotemporal pattern recognition early event prediction model visualization understanding. main contributions paper follows propose graph matching algorithm optimize mapping input features arbitrary temporal stream data snncube goal achieve better pattern recognition accuracy earlier event prediction temporal data better understanding data model visualization. proposed graph based semi-supervised learning algorithm automatically analyse neuronal cluster structure inside trained snncube develop various dynamic functions visualization neuronal activity states synaptic evolving progress learning process prove convergence algorithm. present algorithms spike density correlation maximum spike coincidence spike trains similarity measure used graph matching algorithm commonly encountered types spike trains bipolar spike trains unipolar spike trains. abstract—this paper proposes method optimized mapping temporal variables describing temporal stream data recently proposed neucube spiking neural network architecture. optimized mapping extends neucube initially designed spatiotemporal brain data work arbitrary stream data achieve better accuracy temporal pattern recognition better earlier event prediction better understanding complex temporal stream data visualization neucube connectivity. effect mapping demonstrated three bench mark problems. ﬁrst early prediction patient sleep stage event temporal physiological data. second pattern recognition dynamic temporal patterns trafﬁc area california last challenge contest data set. cases proposed mapping leads improved accuracy pattern recognition event prediction better understanding data compared traditional machine learning techniques spiking neural network reservoirs arbitrary mapping variables. brain science ecology geophysics social sciences. temporal data contain complex temporal patterns would need learned extracted computational model. cases variables describing temporal data spatial attributes e.g. location channels data patterns need learned become spatiotemporal. learning dynamic patterns temporal spatiotemporal data challenging task temporal features manifest complex interaction also change dynamically time. time-windows important temporal spatiotemporal patterns change time seldom covered traditional machine learning methods regression techniques support vector machines multi-layer perceptrons many recurrent models proposed learn spatiotemporal relationship signal recursive selforganizing network models recurrent neural network recently neucube proposed capture time space characteristics spatiotemporal brain data introduce adaptive threshold based encoding algorithm using mean standard deviation information signal gradient calculate threshold thus make self-adaptive signal changes. develop optimization component using genetic algorithm automatically optimize neucube parameters thus enable users optimal parameters’ value easily achieve good results. remainder paper organized follows. section describes neucube architecture. section proposes method optimization mapping input temporal features snncube. experiments three benchmark data sets reported section followed conclusions discussions section main parts neucube input encoding module; three-dimensional recurrent reservoir/cube evolving classiﬁer. fig. shows block diagram neucube architecture. snncube scalable module. size controlled three parameters andnz representing neuron number along axes respectively. total number neurons snncube ﬁrst implementation here probabilistic leaky integrate model encoding module converts continuous data streams discrete spike trains suitable processed snncube spike neural networks process discrete spike trains. encoding information contained original continuous signal transformed forms spikes. neucube trained two-stage learning process. ﬁrst stage unsupervised learning makes snncube learn spatiotemporal relations input data adjusting connection weights snncube. second stage supervised learning aims learning class information associated training spatiotemporal sample. speciﬁc unsupervised learning stage intended encode hidden spatiotemporal relationships input data neuronal connection weights. according hebbian learning rule interaction neurons persistent connection strengthened. particular train snncube using spike-timing dependent synaptic plasticity learning rule neuron ﬁres neuron connection weight neuron neuron increase spikes reverse order connection neuron neuron decrease ensures time difference second training stage train output classiﬁer using class label information associated training temporal samples. dynamic evolving spike neural networks employed output classiﬁer desnn computationally efﬁcient emphasizes importance ﬁrst spikes arriving neuronal inputs following spikes neucube model trained connection weights snncube output classiﬁcation layer established. connections weights change based training evolvable characteristic architecture. given particular spatiotemporal data important optimise mapping data snncube optimal learning better understanding spatiotemporal patterns data. spatiotemporal data brain prior information location channel information readily utilized mapping temporal signal snncube common applications climate temporal data spatial mapping information. temporal data mapped snncube would signiﬁcantly impact results. introduce method temporal variables snncube better pattern recognition better earlier event prediction better visualisation model explain data. suppose temporal samples data measured temporal variables observed time length sample ﬁrst choose randomly input neurons snncube. variables snncube following principle input variables/features that input data transformation spike trains represent highly correlated spike trains mapped nearby input neurons. high correlation indicates variables likely time dependent other relationship also reﬂected connectivity snncube. spatially close neurons snncube capture connections temporal interactions input variables mapped neurons. principle mapping similar input vectors topologically close neurons known static vectors similarity measured euclidean distance. address problem mapping temporal sequences rather static vectors snn. speciﬁcally construct weighted graphs input neuron similarity graph time series/signals similarity graph input neurons spatial coordinates denoted ..v} graph edges determined following input neuron connected nearest input neurons edges weighted inverse euclidean distance them. construction graphs adopt graph matching technique powerful tool solve mapping problems widely used computer vision pattern recognition determine optimal mapping weighted graphs mapping rule. graphs compute adjacency matrices written graph matching method aimed permutation matrix minimizes following objective function ||·||f denotes frobenius matrix norm. solving problem exactly known hard problem combinatorial optimization property. many algorithms proposed approximated solution. among algorithms factor graph matching algorithm demonstrated produce state-of-art results. utilize algorithm solve matching problem equation suppose graph edge weights vertex vertex vertices similarly graph edge weights vertex issg vssg vertices difference normalized weight reﬂects similarity positions issg corresponding graphs dirac delta function. spike trains corresponding features vssg {si|i ..v} forms graph vertex set. graph edges constructed spike density function connected highest correlated neighbours edges weighted similarity them. measuring similarity spike trains important problem neural science studied long history propose simple effective spike trains similarity measuring algorithms commonly encountered spike train types respectively. ﬁrst spike density correlation suitable measuring unipolar spike trains state kind spike train commonly observed glutamatergic neurons produced spike encoding algorithms bens spiker algorithm maximum spike coincidence suitable measuring bipolar spike trains three state kind spike train commonly produced serotonergic neurons well encoding algorithms address event representation spike density correlation given unipolar spike train ﬁrst kernel density estimation method estimate spike density function input spike trains input mapping neurons construct graphs using euclidean distance construct graphs using equation compute vertex similarity using equation compute edge similarity using equation solve problem factor graph matching fig. shows matching results exemplar temporal data represented features left graph input right graph ssg. matching highly correlated features mapped nearby input neurons. many applications pest population outbreak prevention natural disaster warning ﬁnancial crisis forecasting important know risk event occurrence early possible order take actions prevent make adjustment time rather waiting whole pattern temporal data entered model. main challenge early event prediction task time length recall samples smaller training samples training samples collected past data already known. illustrated fig. traditional data modeling methods longer applicable early event prediction task require prediction sample training samples time length. furthermore traditional contrast neucube proposed mapping method would enable better early event prediction connectivity trained snncube would reﬂect temporal relationship temporal data. result part sample presented would chain activities snncube based established connections. speciﬁc consider mapping four features dimensional snncube. assuming feature correlated feature others feature dominant feature feature e.g. feature could radiation feature could temperature aphids study similarly assuming feature correlated feature feature dominant feature feature result optimal graph mapping given fig. highly correlated features mapped nearby less correlated features mapped away. recall stdp learning rule adjusts synaptic weight nearby neurons according ﬁring time difference. training process neurons around feature interaction neurons around feature features interactions cause unsymmetrical weight adjustment according stdp rule. training connection patterns neurons around features encode temporal characteristics training spike trains hence temporal relationship original signals. testing phase similar temporal pattern appears early ﬁring triggered propagated neuron population full data presented i.e. neurons connections form functional cluster becomes selective spatiotemporal pattern tend start signal pattern. demonstrated neurons equipped stdp learning rule learn unsupervisedly arbitrary spatiotemporal pattern embedded complex background spike trains preferred spike sequence appears neuron emit spike early start pattern. biologically population ﬁring snncube chain-ﬁre phenomenon observed zebra ﬁnches area control precise temporal structure birdsong neural activity propagated chain network form basic clock song rhythm. snncube also observed similar chain-ﬁre phenomenon spike trains presented network. features endow recall size three dimensional snncube nx×ny×nz. snncube powerful potential encode complex spatiotemporal patterns contained input spike trains used training respond early presence speciﬁc spatiotemporal pattern recall/prediction mode. especially important result consequence several highly correlated factors demonstrated study stroke occurrence phenomenon similar associative memories hopﬁeld networks deal temporal patterns rather static input vectors. fig. different spatial pattern input mapping. colored circles input neurons black dots normal neurons. color indicates correlation shape size indicates dominance. contrast fig. display non-optimal mapping uncorrelated features mapped together. neurons around uncorrelated features hardly learn original signal temporal relationship nearby neurons presented less even non-correlated signals. interactions nearby neurons much lower capture meaningful temporal correlation. result samples partially presented testing similar temporal pattern contained training samples cannot detected correctly demonstrated experimental results section optimal input mapping enables better network structure analysis visualization better data understanding trained snncube captured spatial temporal relationships temporal data. helpful know neurons snncube related input features patterns snncube learned input signals. information important understand model temporal data previous work neuronal clusters manually labeled according synaptic weights costs plenty time less accurate propose following algorithm unveil snncube structure automatically analysing neuronal clusters snncube. neurons cube indexed according ascendent order coordinates. mark input neurons information source snncube deﬁne source matrix fsrc rn×v follows neuron input neuron variable entry fsrc otherwise afﬁnity matrix rn×n snncube deﬁned following entry total spike amount transmitted neuron neuron note spike means stronger interaction compute d−/ad−/ evaluate irates fsrc converge normalize identity matrix irate diagonal matrix deﬁning propagation rates different directions. respectively. ﬁrst iteration fsrc. step computes normalized adjacency matrix fully encode connection information snncube square matrix according network theory step propagates information input neurons neurons iterative way. main principle behind algorithm information propagated network propagation process dominated network structure. imagining input neuron source kind information information type possessed different input neuron different information propagated sources neurons iteration propagation amount proportional connection weight pair neurons. beginning input neurons information neurons don’t information. propagation process continues neurons receive information input neurons information amount corresponding different input neurons different. amount particular type information received neuron reﬂects intimation relationship neuron input source neuron. amount information received closer input neuron. finally according network theory whole network reaches stable state entry represents relative information amount neuron received input neuron finally step normalizes information amount corresponding different input neurons facilitates classify neurons different input clusters ...n number input neuron number total neurons snncube. matrix basis extracting neuronal clusters. mean afﬁnity value neuron neighboring neurons information propagation strongly connected neurons large information propagated weakly connected neurons small. representing information amount acquired sources neighborhood respectively. random walk matrix graph. spectral radius similar since spectral radius therefore worth mentioning step also replaced equation since matrix highly sparse much efﬁcient evaluate equation step invert matrix equation regarding space time comsumption. another advantage using step iterative process interesting intuitive observe information propagated snncube rather jumping directly resultant clusters view given equation fig. left plot shows network structure unsupervised training study aphids data presented previous work solid dots represent input neurons neurons labeled intensity input neuron receives spikes. unconnected dots mean spike arrived neuron. fig. right pane spike number variable encoding bottom pane neuron number belonging input variable cluster. ﬁgure consistency input signal spike train snncube structure. note variable emphasized snncube suggests greater impact solar radiation aphid number. observed also work different traditional methods used tasks without offering facilities trace learning processes sake data understanding. worth mentioning spatial pattern input mapping e.g. fig. embedded source matrix fsrc direct inﬂuence visualization results interpretation results. mapping visualization demonstrated useful high level cause results interpretation studied signal study identifying differences people opiate addiction undertaking substitution treatment opiate addiction fmri data study brain activity subjects presented different pictures. important note input mapping neuronal clustering performed hand proposed graph mapping structure analysis algorithm enable ﬁnished automatically. prediction based temporal data spatiotemporal pattern recognition. ﬁrst case study conducted benchmark physiological data santafe demonstrate ability proposed method classiﬁcation temporal data make early event prediction. demonstrate validity mapping method early event prediction. second case study conducted spatiotemporal data pems downloaded california department transportation pems website perform pattern recognition feature sampled ﬁxed location. demonstrate proposed mapping section improves accuracy spatiotemporal pattern recognition. third case study carried contest physiological data challenge demonstrate superiority proposed graph mapping randomly mapping address event representation encoding ﬁxed threshold used threshold tuned manually time feature individually introduce self-adaptive bi-directional thresholding method adaptive threshold based encoding algorithm. simply self-adaptive features input time series/signal calculate mean standard deviation gradient threshold parameter controlling spiking rate encoding. this obtain positive spike train encodes segments time series increasing signal negative spike train encodes segments decreasing signal. neucube system complex system contains many tunable parameters manually tuning parameters might time consumption non-experienced user. implemented genetic algorithm optimization component optimize system parameters k-fold cross validation respect data set. objective function overall validation error rate. optimization component simultaneously optimize parameters neucube system table baseline algorithms consist multiply linear regression simple extensively studied achieve relative stable result many applications; support vector machine probably widely used demonstrated successful various applications; multilayer perceptron classic neural network model advantages processing multivariate data; nearest neighbors weighted nearest neighbors among popular classiﬁcation algorithms especially processing high-dimension data; ﬁnally global alignment kernel recently developed method process time series achieve stateof-art results many applications. baseline algorithms wknn gak. baseline algorithms process static vectors prepared data following way. concatenated temporal variables another form long feature vector sample shown fig. since baseline case study conduct experiments complex physiologic time series classiﬁcation santafe dataset. dataset contains three physiologic features heart rate respiration force blood oxygen feature measured twice second measurement lasted hours. case study predict sleep stage patient using collected http//www.kedri.aut.ac.nz/areas-of-expertise/data-mining-and-decisionsupport-systems/neucom. wknn implemented based matlab knnsearch function. available http//www.iip.ist.i.kyotou.ac.jp/member/cuturi/ga.html original dataset contains data points feature sleep stage labels sleep stage labeling interval varies seconds seconds. label indicates different sleep stage happening moment i.e. whenever patient transits sleep stage another different sleep stage corresponding label assigned time. signals recorded labeling interval reﬂect happening process next sleep stage. consequently classifying temporal data different classes actually predict next sleep stage patient. case study labeling data seconds time interval make sure feature length every sample fair comparison traditional methods cannot process data uneven feature length samples. case snncube desnn network weighted classiﬁer output layer build data matrix time length signal feature number sample number. fig. left pane gives mapping result found proposed input mapping algorithm. seen respiration force mapped blood oxygen heart rate much closer heart rate. indicates respiration signal correlates heart rate blood oxygen. result consistent actual observation described three major research questions raised dataset website also demonstrated fig. right plot clearly connections respiration force heart rate much denser connections places. indicates interaction respiration force heart rate active much stronger parts. therefore temporal relationship original data fully captured connections snncube training. currently determine reservoir size trying several different ones. general rule larger reservoir powerful computational ability reservoir thus complex patterns model learn recognize. however larger reservoir consumes longer time memory space needs training data training. fig. shows four consecutive snapshots instantaneous ﬁring state neurons training process. squares input neurons dots ﬁring neurons black dots unﬁring neurons. note ﬁring neuronal cluster grows small large propagation spike states trajectory snncube. meaning ﬁring pattern spreading trajectory reveal signiﬁcance snncube modelling ability questions answered study scope paper leave future papers. figure shows evolving process connections time training stage. different connections different neurons created dynamically spike trains input reservoir. beginning connections reservoir sparse nearly randomly distributed training process continues connections appear around input neuron blood oxygen input neuron interaction input neurons last half training process connections created interaction pair input neurons increases especially blood oxygen synaptic weight evolving process tightly connected physiological signal trend fig. clearly correlation blood oxygen signals last half signal segment. worth mentioning previous method study santafe dataset mainly focused analysis nonlinear dynamics respiration heart rate blood pressure hardly provide intuitive direct observe dynamics signals hence interaction physiological signals sleep stage. early model predict sleep stage using part data. experiments trained neucubes random mapping graph mapping using time length samples temporal data time length samples used predict sleep stage. experimental results early event prediction table iii. order comparing impact testing time length upon accuracy also include result full time length second column. neucube random mapping neucube graph mapping. neucube early prediction much lower snncube randomly mapping fails acquire temporal pattern data early ﬁring testing stage. furthermore realistic early event prediction time length observed data increases prediction accuracy also increase. table time length training data increases traditional modeling methods necessarily produce better results cannot model whole spatiotemporal relationship prediction task. model certain time segment. temporal data typically exhibits complex interrelationship interaction among different features traditional methods proposed process static vector data thus hardly model complex relationship contained temporal data. wknn produce better results accuracies still much lower neucube. neucube trained whole spatiotemporal relationship data even small amount input data trigger spiking activities snncube correspond learned full temporal pattern resulting better prediction. case study consider benchmark trafﬁc status classiﬁcation problem spatiotemporal data pems database. freeways vehicle monitored trafﬁc sensors ﬁxed spatial locations data collected sensors exhibit spatial temporal characteristics. discovering spatial-temporal patterns meaningful trafﬁc management city trafﬁc plan. study area francisco area shown fig. thousands sensors distributed road network sensors distribution indicated right plot black represents monitoring sensor. sensors monitor lane occupation rate -hourly every day. measurements taken every minutes normalized means occupation means full occupation lane monitoring region. data points day. case study collect trafﬁc data period months thus removing public holidays sensor maintenance days days classiﬁed. preprocessing data removed always hours sensors suddenly; nearby sensors produce almost data sequence combined sensor; total occupation rate sensor calculated measurements days; sensors corresponding largest occupation rate selected ﬁnal features represent data set. fig. shows samples spatial temporal distribution trafﬁc status road network monday thursday. fig. shows overall neuron ﬁring state matrix snncube corresponding four data samples bottom monday till thursday. ﬁgure horizontal axis neuron vertical axis time tick bottom. note plot seems ﬁring state matrix dense actually sparse. take thursday example. ﬁring entries ﬁring state matrix size ﬁring entries sparse ﬁring matrices different patterns related input data. meanwhile since size snncube speciﬁed according problem snncube highly sparse ﬁring rate great power encode input signals patterns thus potentially model complex spatial temporal relationship. obtaining ﬁring state matrix sample transmit output desnn layer creates output neuron sample connects output neuron neuron snncube. weights connections established rank order learning rule testing sample class label determined comparing output neuron weights training samples’ output neuron weights established training stage using weighted rule table compared -fold cross validation experimental result neucube baseline algorithms wknn global alignment kernels parameters’ values used classical machine learning methods ddegree polynomial kernel; number neurons hidden layer mlp; knumber nearest neighbors wknn; σgaussian kernel width. results proposed neucube model achieves better classiﬁcation results. traditional machine learning methods designed process static vector data limited ability model spatially correlated temporally varied data. meanwhile also show disadvantages modeling high-dimensionql data wknn widely used high-dimension data processing document classiﬁcation approximately reconstruct underlying manifold whose dimension usually much lower ambient space thus produce better results svm. recently proposed algorithm shown efﬁcient effective processing time series performance still lower neucube. mentioned although case study classifying weekday trafﬁc patterns obvious application situation pems database established benchmark data test algorithm’s ability spatiotemporal data processing predict mortality intensive care unit patients using physiological signals measured irregular time interval within total time length hours. irregularity measurement time interval complexity physiological signal make prediction task highly challenging. patient selection. original data contains records patients records divided parts training patients’ records testing patients’ records. testing doesn’t contain mortality state thus cannot calculate exactly classiﬁcation accuracy conduct experiments training patients several measurements example early in-hospital death. select patients records results subset contains patients. feature selection. original data contain features measurements observation period enable effective temporal encoding tropt tropi features measured several times hours. ﬁrst calculate overall measurement amount every feature select feature average measurements result features used experiments listed table fig. mean standard deviation ﬁrst four selected features in-hospital death survival patients.from left right diasabp map. note similar signals classes are. fully evaluate effect input mapping comparison experiments conduced challenge santafe data sets. different santafe data described section iv-a challenge complex challenging data set. goal challenge data figure displays mean standard deviation ﬁrst four selected features classes. ﬁgures physiological signals corresponding classes similar tends difference almost indistinguishable human eyes modes randomly mapping mode graph matching mapping. optimized parameters listed table parameters generation number population size crossover function scattered crossover fraction selection function roulette elite count results challenge santafe shown fig. horizontal axis represents generation vertical axis represents error rate results graph matching achieve lower error rate randomly mapping. generation number increases clearly decreasing trend graph based mapping trend random mapping curve obvious greater ﬂuctuation. mentioned ﬁtness value algorithm decreases monotonically optimizing deterministic system usually ﬂuctuation always decrease stochastic system. stochastic system even system parameters same different initial states yield different results. reason error rate neucube system dose monotonically decrease. compare performance fig. displays mean error rate standard deviation error rate times running challenge results performance graph based mapping method effective stable regarding lower mean error rate smaller standard deviation. highly challenges traditional classiﬁcation algorithms might interesting compare performance neucbe traditional methods. results shown table note highest accuracy baseline algorithms neucube achieve signiﬁcant state-of-art results. optimal values improvement paper proposed mapping method spatiotemporal input variables spiking neural network architecture called neucube enable neucube models spatiotemporal data. weighted undirect graph matching technique adopted similar input variables based temporal similarity mapped spatially closer neurons. closer neurons snncube temporal relationships learn data. automatic optimal mapping algorithm greatly reduces work load user optimal mapping hand previous system yield better results regarding spatiotemporal pattern recognition early event prediction. comparison study proposed mapping randomly mapping conducted popular contest physiological data challenge results demonstrated superiority proposed method randomly mapping method. better understanding snncube model data modelled also proposed algorithm based network activation spreading automatically reveal neuronal clusters previous system also determined hand according learnt connection weights thus costed lots time. algorithm divide snncube different neuronal clusters based either spike amount communication connection weight neurons. neuronal clusters help better understand learning mechanism modelling ability snncube well data. extension including semi-supervised learning ability neucube model semi-supervised learning demonstrated various applications useful basic ability human neural system experiments ecological- environmental ﬁnancialbusiness temporal data large scale snncube explore deep modelling deep prediction capability proposed neucube complex spatiotemporal data. work funded education zealand tripartite project auckland university technology zealand shanghai jiaotong university xinjiang university china. work initiated knowledge engineering discovery research institute visit enmei kedri continued shanghai jiaotong university collaborative way. kedri sjtu partially funded work. work partly supported nsfc china planchina mikolov kombrink burget ˇcernock`y khudanpur extensions recurrent neural network language model acoustics speech signal processing ieee international conference kasabov neucube evospike architecture spatiotemporal modelling pattern recognition brain signals artiﬁcial neural networks pattern recognition. springer kasabov capecci spiking neural network methodology modelling classiﬁcation understanding data measuring cognitive processes information sciences vol. taylor scott kasabov capecci saywell chen z.-g. feasibility neucube architecture detecting motor execution motor intention bciapplications neural networks international joint conference doborjeh capecci kasabov classiﬁcation segmentation fmri brain data neucube evolving spiking neural network model evolving autonomous learning systems ieee symposium doborjeh kasabov dynamic clustering spatio-temporal brain data neucube spiking neural network architecture case study fmri data neural information processing. springer espinosa-ramos mammone kasabov duun-henriksen kjaer campolo foresta morabito modelling absence epilepsy seizure data neucube evolving spiking neural network architecture neural networks international joint conference ieee capecci kasabov wang analysis connectivity neucube spiking neural network models trained data understanding functional changes brain case study opiate dependence treatment neural networks vol. kasabov spike spike probabilistic spiking neuron model neural networks vol. kasabov dhoble nuntalid indiveri dynamic evolving spiking neural networks on-line spatio-and spectro-temporal pattern recognition neural networks vol. dhoble nuntalid indiveri kasabov on-line spatiotemporal pattern recognition evolving spiking neural networks utilising address event representation rank oder-and temporal spike learning proc. wcci citeseer zhou torre factorized graph matching computer vision pattern recognition ieee conference ieee kasabov othman worner yang neucube spatio-temporal data predictive modelling case study ecological data neural networks international joint conference competitive stdp-based spike pattern learning neural computation vol. ikegaya aaron cossart aronov lampl ferster yuste synﬁre chains cortical songs temporal modules cortical activity science vol. worner lankin samarasinghe teulon zydenbos improving prediction aphid ﬂights temporal analysis input data artiﬁcial neural network zealand plant protection kasabov feigin z.-g. chen liang krishnamurthi othman parmar evolving spiking neural networks personalised modelling classiﬁcation prediction spatio-temporal patterns case study stroke neurocomputing vol. kumar quinlan ghosh yang motoda mclachlan philip algorithms data mining knowledge information systems vol. cuturi fast global alignment kernels proceedings international conference machine learning kor¨urek nizam clustering mit–bih arrhythmias colony optimization using time domain compressed wavelet coefﬁcients digital signal processing vol. skabardonis varaiya petty measuring trafﬁc congestion transrecurrent nonrecurrent portation research record journal transportation research board yang fang kasabov experimental comparison semi-supervised learning algorithms multispectral image classiﬁcation photogrammetric engineering remote sensing vol. yang kasabov zhang posterior distribution learning novel supervised learning framework using unlabeled samples improve classiﬁcation performance neurocomputing vol. enmei born anhui china. received b.sc. degree m.sc. degree university electronic science technology china respectively degree institute image processing pattern recognition shanghai jiao tong university china research fellow roll-roycentu corporate laboratory nanyang technological university. research interests machine learning computer vision neural information processing. nikola kasabov fellow royal society zealand zealand computer society institute electrical electronic engineers founding director chief scientist knowledge engineering discovery research centre personal chair knowledge engineering school computing mathematical sciences aut. main interests areas computational intelligence neuro-computing bioinformatics neuroinformatics speech image processing novel methods data mining knowledge discovery. published works international journals conferences well books/chapters. yang received bachelors degree masters degree shanghai jiao tong university respectively. received ph.d. university hamburg germany. professor director institute image processing pattern recognition shanghai jiao tong university. principal investigator nation ministry scientiﬁc research projects including national research plan projects three national research plan projects three national nature fundation projects international cooperative projects france korea japan zealand. published hundreds articles national international academic journals conferences.", "year": 2016}