{"title": "Evaluating Visual Conversational Agents via Cooperative Human-AI Games", "tag": ["cs.HC", "cs.AI", "cs.CL", "cs.CV"], "abstract": "As AI continues to advance, human-AI teams are inevitable. However, progress in AI is routinely measured in isolation, without a human in the loop. It is crucial to benchmark progress in AI, not just in isolation, but also in terms of how it translates to helping humans perform certain tasks, i.e., the performance of human-AI teams.  In this work, we design a cooperative game - GuessWhich - to measure human-AI team performance in the specific context of the AI being a visual conversational agent. GuessWhich involves live interaction between the human and the AI. The AI, which we call ALICE, is provided an image which is unseen by the human. Following a brief description of the image, the human questions ALICE about this secret image to identify it from a fixed pool of images.  We measure performance of the human-ALICE team by the number of guesses it takes the human to correctly identify the secret image after a fixed number of dialog rounds with ALICE. We compare performance of the human-ALICE teams for two versions of ALICE. Our human studies suggest a counterintuitive trend - that while AI literature shows that one version outperforms the other when paired with an AI questioner bot, we find that this improvement in AI-AI performance does not translate to improved human-AI performance. This suggests a mismatch between benchmarking of AI in isolation and in the context of human-AI teams.", "text": "figure human play proposed guesswhich game. start game alice provided image unknown human. alice human provided brief description image. human attempts identify secret image. subsequent round dialog human asks question unknown image receives answer alice makes best guess secret image ﬁxed pool images. rounds dialog human makes consecutive guesses secret image identiﬁed. fewer guesses human needs identify secret image better human-ai team performance. trained understand communicate contents scene natural language. example fig. visual conversational agent replies answers questions scene inferring context dialog history human what doing? agent playing continues advance human-ai teams inevitable. however progress routinely measured isolation without human loop. crucial benchmark progress isolation also terms translates helping humans perform certain tasks i.e. performance human-ai teams. work design cooperative game guesswhich measure human-ai team performance speciﬁc context visual conversational agent. guessinvolves live interaction human call alice provided image unseen human. following brief description image human questions alice secret image identify ﬁxed pool images. measure performance human-alice team number guesses takes human correctly identify secret image ﬁxed number dialog rounds alice. compare performance human-alice teams versions alice. human studies suggest counterintuitive trend literature shows version outperforms paired questioner improvement ai-ai performance translate improved human-ai performance. suggests mismatch benchmarking isolation context human-ai teams. artiﬁcial intelligence systems become increasingly accurate interactive human-ai teams inevitably going become commonplace. effective teammate must overcome challenges involved adapting humans; however progress routinely measured isolation without human loop. work focus speciﬁcally evaluation visual conversational agents develop human computation game benchmark performance members human-ai teams. frisbee. agents typically trained mimic large corpora human-human dialogs evaluated automatically well retrieve actual human responses novel dialogs. recent work evaluated models pragmatically evaluating well pairs visual conversational agents perform goal-based conversational tasks rather response retrieval ﬁxed dialogs. speciﬁcally train visual conversational agents questioning qbot answering abot image-guessing task. starting description scene qbot abot converse multiple rounds questions answers order improve qbot’s understanding secret image known abot. ﬁxed number rounds qbot must guess secret image large pool qbot abot evaluated based guess. compare supervised baseline models qbot-abot teams trained reinforcement learning based self-talk image-guessing task. ai-ai teams improve signiﬁcantly guessing correct image self-talk updates compared supervised pretraining. results indicate self-talk ﬁne-tuned agents better visual conversational agents crucially remains unclear agents indeed better task interacting humans. guesswhich. work propose evaluate progress ai-ai evaluation translates performance human-ai teams. inspired popular guesswhat -questions game design human computation game guesswhich requires collaboration human visual conversational agents. mirroring setting guesswhich image-guessing game consists participants questioner answerer. start game answerer provided image unknown questioner questioner answerer given brief description image content. questioner interacts answerer ﬁxed number rounds question-answer identify secret image ﬁxed pool images evaluate human-ai team performance guesswhich setting questioner human answerer speciﬁcally evaluate versions alice guesswhich alicesl trained supervised manner visual dialog dataset mimic answers given humans engaged conversation humans image important appreciate difﬁculty sensitivity guesswhich game evaluation tool agents understand human questions respond accurate consistent ﬂuent informative answers human-ai team well. furthermore robust mistakes i.e. agent makes error particular round error part conversation history must able correct rather consistently inaccurate. similarly human players must also learn adapt alice’s sometime noisy inaccurate responses. core guesswhich game-with-a-purpose leverages human computation evaluate visual conversational agents. traditionally gwap focused human-human collaboration i.e. collecting data making humans play games label images music movies extend human-ai teams best knowledge work ﬁrst evaluate visual conversational agents interactive setting humans continuously engaging agents succeed cooperative game. contributions. concretely make following contributions work design interactive image-guessing game evaluating human-ai team performance speciﬁc context visual conversational agents. guesswhich pairs humans alice capable answering sequence questions images. alice assigned secret image answers questions asked image human rounds help identify secret image evaluate human-ai team performance game supervised learning reinforcement learning versions alice. main experimental ﬁnding despite signiﬁcant differences agents reported previous work signiﬁcant difference performance alicesl alicerl paired human partners suggests self-talk interesting directions pursue building better visual conversational agents appears disconnect ai-ai human-ai evaluations progress former seem predictive progress latter. important ﬁnding guide future research. given goal evaluate visual conversational agents human computation game draw connections relevant work visual conversational agents human computation games dialog evaluation below. visual conversational agents. agents visual conversational models recently emerged popular research area visually-grounded language modeling introduced task visual dialog collected visdial dataset pairing subjects amazon mechanical turk chat image pre-trained questioner answerer agents visdial dataset supervised learning ﬁne-tuned self-talk observing rl-ﬁne-tuned qbot-abot better image-guessing interacting other. however described section evaluate change qbot-abot performance translates human-ai teams. human computation games. human computation games shown timecost-efﬁcient reliable intrinsically engaging participants hence effective method collect data annotations. long line work designing games purpose data labeling purposes across various domains including images audio language movies etc. games traditionally focused human-human collaboration extend ideas human-ai teams. rather collecting labeled data game designed measure effectiveness context human-ai teams. evaluating conversational agents. goal-driven conversational models typically evaluated task-completion rate time-to-task-completion shorter conversations better. spectrum free-form conversation models often evaluated metrics rely n-gram overlaps bleu meteor rouge shown correlate poorly human judgment human evaluation conversations typically format humans rate quality machine utterances given context without actually taking part conversation best knowledge ﬁrst evaluate conversational models team performance humans continuously interacting agents succeed downstream task. turing test. finally guesswhich game line ideas re-imagining traditional turing test state-of-the-art systems taking pragmatic view effective teammate need appear humanlike mistaken provided behavior feel jarring bafﬂe teammates leaving wondering thinking whether recall section goal evaluate progress measured automatic evaluation translates performance human-ai teams context visual conversational agents. speciﬁcally considering question-answering agent abot abot agent likely deployed human partner real applications completeness review work section. sentence description image pair engage question answer based dialog ﬁxed number iterations qbot must select secret image pool. goal qbot-abot team two-fold qbot should build mental model unseen image purely dialog able retrieve image line-up images. qbot abot modeled hierarchical recurrent encoder-decoder neural networks encode round dialog independently recurrent neural network accumulating information time additional representation used input decoder produces agent’s utterance based dialog addition qbot includes image feature regression network predicts representation secret image based dialog history. refer complete model details. agents pre-trained supervised dialog data visdial dataset maximum likelihood estimation objective. pre-training ensures agents generally recognize objects/scenes utter english. following this models ﬁne-tuned ‘smoothly’ transitioning deep reinforcement learning framework directly improve image-guessing performance. annealed transition avoids abrupt divergence dialog face incorrect question-answer pair qbot-abot exchange. based self-talk agents’ parameters updated gradients corresponding rewards depending individual good exchanges. refer baseline supervised learning based abot alicesl ﬁne-tuned alicerl. found ai-ai pair succeeds retrieving correct image often ﬁne-tuned following section outline guesswhich game designed evaluate whether improvement between alicesl alicerl automatic metrics translates human-ai collaborations. begin describing game setting; outlining players gameplay mechanics. video example game played found https//vimeo.com/ players. replace qbot ai-ai dialog humans perform collaborative task identifying secret image pool. following refer abot alice human player evaluate versions alice alicesl alicerl correspond agents trained supervised setting ﬁnetuned reinforcement learning respectively. gameplay. game setting alice assigned secret image pool images taken coco dataset prior beginning dialog alice figure guesswhich interface user asks question alice round alice responds answer. user selects appropriate image think secret image round conversation. dialog user successively clicks best guesses correctly identify secret image. provided brief description generated neuraltalk open-source implementation makes guess secret image selecting pool based caption i.e. dialog begins. following rounds asks alice question secret image order better identify pool alice responds answer round must select image feel likely secret image pool based dialog far. rounds dialog asked successively click best guess. click interface gives feedback whether guess correct continues guesses true secret image. induces partial ranking pool secret image based mental model dialog. pool selection creating pool images ensure game challenging engaging easy hard. thus construct pool images steps ﬁrst choose secret image sample similar images distractors fig. shows screenshot game interface including sample image pool chat. secret image selection. visdial constructed coco images contain complex everyday scenes object categories. abot trained validated visdial train splits respectively. images select representative secret images diverse image pools following. image coco validation extract penultimate layer activations standard deep convolutational neural network categories average embedding vector images containing category. pick images closest mean embeddings yielding candidates. generating distractor images. distractor images designed semantically similar secret image candidate secret image created concentric hyper-spheres euclidean balls centered candidate secret image embedding space sampled images sphere ﬁxed proportion generate pool corresponding secret image. radius largest sphere varied manually validated ensure pool difﬁculty. sampling proportion varied generate pools varying difﬁculty. candidate pools picked medium difﬁculty based manual inspection. data collection player reward structure solicit human players game. human intelligence task consists games overall users started completed i.e. played games. note incomplete game data dispublished hits games alicesl alicerl completed. results total games split agents game consisting rounds dialog rounds guessing. workers paid base incentivize workers best guessing secret image workers paid two-part bonus based number times best guess matched true secret image round based rank true secret image ﬁnal sorting dialog ﬁnal ranking explicitly captures workers’ mental model secret image closer overall purpose game such ﬁnal sorting given higher potential bonus. evaluation since game structured retrieval task evaluate human-ai collaborative performance using standard retrieval metrics. note successive selection images dialog tells rank true secret image sorting image pool based mental model. example makes guesses correctly selecting secret image mental model ranked secret image within pool. evaluate human-ai collaboration following metrics mean rank mean rank secret image lower values indicate better performance. mean reciprocal rank mean reciprocal rank secret image. penalizes differences lower ranks greater higher ranks higher values indicate better performance. round makes best guess secret image. coarse estimate rank secret image round sort image pool based distance embedding space best guess. used assess accuracy mental model secret image round dialog brieﬂy outline backend architecture guesswhich section. unlike human-labeling tasks one-way static nature evaluating agents game requires live interaction agent human. develop robust workﬂow maintain queue workers pair real-time agent. deploy alicesl alicerl instance. django helps monitoring hits real-time. open source message broker queue inference jobs generate dialog responses model. backend figure outline backend architecture implementation guesswhich. since guesswhich requires live interaction human design workﬂow handle multiple queues quickly pair human agent. asynchronously connected client browser websockets whenever inference completed websocket polls response delivers human real-time. store fetch data efﬁciently postgresql database. fig. shows schematic diagram backend architecture. complete backend infrastructure code made publicly available others easily make human-ai game interface. alicesl alicerl compare performance agents alicesl alicerl guesswhich game. bots state-ofthe-art visual dialog agents respect emulating human responses generating visually discriminative responses ai-ai dialog. evaluate agents strong baselines report ai-ai team results signiﬁcantly better chance pool images addition evaluating context human-ai teams also report qbot-alice team performances reference. table compare performances humanalicesl human-alicerl teams according mean rank mean reciprocal rank secret image based guesses makes dialog. observe game human subjects correctly guessed secret image attempt alicesl teammate. alicerl teammate average number guesses required also observe alicerl outperforms alicesl metric. metrics however differences within standard error margins statisti alicesl alicerl perform same clearly outperform baseline model randomly chooses image. described sec. coarse estimate rank secret image round dialog. cally signiﬁcant. collected additional data error margins became smaller means also became closer. interesting ﬁnding stands stark contrast results reported alicerl found signiﬁcantly accurate alicesl evaluated ai-ai team. results suggest improvements seem translate agents paired human similar setting. varying number games. fig. plot mean rank secret image across different games. human-alice team performs alicesl alicerl except game alicesl seems marginally outperform alicerl. compare performance teams baseline model makes string random guesses game. human-alice teams outperforms random baseline relative improvement ai-alice teams versus human-alice teams. table compare team performances pairing three kinds questioners human qbot qbot alicesl alicerl gain insights questioner alice inﬂuence team performances. interestingly observe ai-alice teams outperform human-alice teams. average qbot -alicesl team takes guesses arrive correct secret image similarly qbot -alicerl team takes guesses opposed human-alicerl team takes guesses. compare ai-ai teams different settings observe teams having qbot questioner outperform qbot qualitatively found qbot tends repeating questions dialog questions qbot tend visually grounded compared qbot also note among four teams alice seem affect performance across since observe qbot tends better questioner average compared qbot future work interesting explore setting evaluate qbot similar game human playing role answerer qbot-human team. varying rounds dialog. fig. shows coarse estimate mean rank secret image across rounds dialog averaged across games workers. explained sec. image ranks computed distance embedding space guessed image human-alice team performs alicesl alicerl across rounds dialog game. compared baseline agent makes random guesses every round dialog human-alice team clearly performs better. figure worker ratings alicesl alicerl metrics. higher better. error bars conﬁdence intervals bootstrap samples. humans perceive signiﬁcant differences alicesl alicerl across feedback metrics. statistical tests. observe metrics differences performances alicesl alicerl within error margins. since standard error bootstrap based conﬁdence intervals overlap signiﬁcantly statistical tests. signiﬁcant difference mean ranks alicesl alicerl mann-whitney test human perception teammate asked workers feedback alice. speciﬁcally asked workers rate alice point scale along dimensions. shown fig. alice rated accurate thought consistent answers previous answers well understood secret image detailed answers well seemed understand questions ﬂuent answers questioning strategies fig. shows distribution questions human subjects alice guesswhich. akin format human-human guesswhat game observe binary questions overwhelmingly common question type instance there/the/he ...? ...? etc. next frequent question what color ...?. questions help human discriminate secret image best. could also humans attempting play perceived strengths alice. people play multiple games alice possible discover alice’s strengths learn questions play strengths. another common question type counting questions many ...?. interestingly workers adopt strategy querying alice single word phrase small fraction workers usually complete majority work. context evaluating based performance human-ai team poses challenge. recently showed human subjects predict responses accurately higher familiarity human’s knowledge gained familiarity teammate bias performance human-ai team knowledge previous tasks might leak later tasks. prevent biased evaluation team performance human subjects differing familiarity alice every person plays ﬁxed number games alice. thus human subject accept task involves playing games. downside ability conduct fair evaluation interactive game-like setting constrained number unique workers accept tasks. engagement fairness. order improve userengagement playing games offer subjects performance-based incentives tied success figure contrast games played different workers alicesl alicerl pool cases workers able secret image within three guesses. also interesting note answers provided alice different cases. human-ai team. potential issue however. owing inherent complexity visual dialog task alice tends inaccurate times. increases difﬁculty unpredictability game tends accurate certain types questions compared others. observe often leads unsuccessful game-plays sometimes errors accumulating successive incorrect responses alice questions human. cases human misled alice single wrong answer seed caption tends inaccurate times. would like keep subjects engaged game best extent possible providing performance-based incentives issuing performance bonus depends human alice dissatisfying. fair subjects performing task still rewarding good performance split overall budget suitable fraction base performance bonus. contrast common practice measuring progress isolation work proposes benchmarking agents interactive downstream tasks performed human-ai teams. particular evaluate visual conversational agents context human-ai teams. design cooperative game guesswhich involves human engaging dialog answerer-bot identify secret image known alice unknown human pool images. dialog human asked pick secret image image pool making successive guesses. alicerl found accurate literature it’s supervised learning counterpart evaluated questioner -alice team accurate evaluated human-alice team. suggests disconnect benchmarking isolation versus context human-ai interaction. interesting direction future work could evaluate qbot qbot-human teams. describe game structure backend architecture discuss unique computation infrastructure challenges arise designing live interactive settings relative static human-labeling tasks. code infrastructure made publicly available. acknowledgements. would like acknowledge effort provided workers amazon mechanical turk. grateful developers torch building excellent framework. work funded part career awards awards grant n--- grant sloan fellowship allen distinguished investigator award paul allen family foundation google faculty research awards amazon academic research awards education research grant nvidia donations partially supported bradley postdoctoral fellowship. views conclusions contained herein authors interpreted necessarily representing ofﬁcial policies endorsements either expressed implied u.s. government sponsor. rabbitmq. rabbitmq. rabbitmq.com. serban sordoni bengio courville pineau building end-to-end dialogue systems using generative hierarchical neural network models. aaai.", "year": 2017}