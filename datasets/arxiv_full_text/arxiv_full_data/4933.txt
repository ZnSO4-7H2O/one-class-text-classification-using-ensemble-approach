{"title": "Task-based End-to-end Model Learning in Stochastic Optimization", "tag": ["cs.LG", "cs.AI"], "abstract": "With the increasing popularity of machine learning techniques, it has become common to see prediction algorithms operating within some larger process. However, the criteria by which we train these algorithms often differ from the ultimate criteria on which we evaluate them. This paper proposes an end-to-end approach for learning probabilistic machine learning models in a manner that directly captures the ultimate task-based objective for which they will be used, within the context of stochastic programming. We present three experimental evaluations of the proposed approach: a classical inventory stock problem, a real-world electrical grid scheduling task, and a real-world energy storage arbitrage task. We show that the proposed approach can outperform both traditional modeling and purely black-box policy optimization approaches in these applications.", "text": "increasing popularity machine learning techniques become common prediction algorithms operating within larger process. however criteria train algorithms often differ ultimate criteria evaluate them. paper proposes end-to-end approach learning probabilistic machine learning models manner directly captures ultimate task-based objective used within context stochastic programming. present three experimental evaluations proposed approach classical inventory stock problem real-world electrical grid scheduling task real-world energy storage arbitrage task. show proposed approach outperform traditional modeling purely black-box policy optimization approaches applications. prediction algorithms commonly operate within larger process criteria train algorithms often differ ultimate criteria evaluate them performance full closed-loop system ultimate task hand. instance instead merely classifying images standalone setting want classiﬁcations within planning control tasks autonomous driving. typical image classiﬁcation algorithm might optimize accuracy likelihood driving task ultimately care difference classifying pedestrian tree classifying garbage tree. similarly probabilistic prediction algorithm generate forecasts upcoming electricity demand want forecasts minimize costs scheduling procedure allocates generation power grid. examples suggest instead using generic loss instead want learn model approximates ultimate task-based true loss. paper considers end-to-end approach learning probabilistic machine learning models directly capture objective ultimate task. formally consider probabilistic models context stochastic programming goal minimize expected cost models’ probabilistic predictions subject constraints. mentioned above common approach problems two-step fashion ﬁrst predictive model observed data minimizing criterion negative log-likelihood model compute approximate necessary expected costs stochastic programming setting. procedure work well many instances ignores fact true cost system beneﬁt model actually attains worse overall likelihood makes accurate predictions certain manifolds underlying space. propose train probabilistic model predictive accuracy that–when later used within loop stochastic programming procedure–it produces solutions minimize ultimate task-based loss. formulation seem somewhat counterintuitive given perfect predictive model would course also optimal model within stochastic programming framework. however reality models make errors illustrates indeed look ﬁnal task-based objective determine proper error tradeoffs within machine learning setting. paper proposes evaluate task-based tradeoffs fully automated fashion computing derivatives solution stochastic programming problem manner improve underlying model. begin presenting background material related work areas spanning stochastic programming end-to-end training optimizing alternative loss functions classic generative/discriminative tradeoff machine learning. describe approach within formal context stochastic programming give generic method propagating task loss problems manner update models. report three experimental evaluations proposed approach classical inventory stock problem real-world electrical grid scheduling task real-world energy storage arbitrage task. show proposed approach outperforms traditional modeling purely black-box policy optimization approaches. stochastic programming stochastic programming method making decisions uncertainty modeling optimizing objectives governed random process. applications many domains energy ﬁnance manufacturing underlying probability distributions either known estimated. common considerations include best model approximate underlying random variable solve resulting optimization problem assess quality resulting solution cases underlying probability distribution known objective cannot solved analytically common monte carlo sample average approximation methods draw multiple samples underlying probability distribution deterministic optimization methods solve resultant problems cases underlying distribution known common learn estimate model observed samples end-to-end training recent years seen dramatic increase number systems building so-called end-to-end learning. generally speaking term refers systems goal machine learning process directly predicted inputs context deep learning systems term traditionally refers architectures where example explicit encoding hand-tuned features data system directly predicts image text etc. inputs context term end-to-end similar slightly line older usage instead attempting learn output speciﬁcally attempting learn model based upon end-to-end task user ultimately trying accomplish. feel concept–of describing entire closed-loop performance system evaluated real task hand–is beneﬁcial notion end-to-end learning. also highly related work recent efforts end-to-end policy learning using value iteration effectively optimization procedure similar networks multi-objective optimization lines work pure end-to-end approach discuss later conceptually approaches similar motivations modifying typically-optimized policies address task directly. course actual methodological approaches quite different given speciﬁc focus stochastic programming black interest setting. optimizing alternative loss functions great deal work recent years using machine learning procedures optimize different loss criteria naturally optimized algorithm. example stoyanov hazan propose methods optimizing loss criteria structured prediction different inference procedure prediction algorithm; work also recently extended deep networks recent work also explored using auxiliary prediction losses satisfy multiple objectives learning dynamics models maximize control performance bayesian optimization learning adaptive predictive models differentiation meta-learning optimization objective work found literature closely resembles approach work bengio uses neural network model predicting ﬁnancial prices optimizes model based returns obtained hedging strategy employs view approach–of using model tuning model adapt procedure–as philosophical predecessor work. concurrent work elmachtoub grigas also propose approach tuning model parameters given optimization results context linear programming outside context deep networks. whereas bengio elmachtoub grigas hand-crafted algorithms approximately attain objective given predictive model approach tightly coupled stochastic programming explicit objective attempt optimize desired task cost exact optimization routine given underlying randomness. notions stochasticity thus naturally quite different work hope work bring back original idea task-based model learning. original paper nearly years virtually follow-on work focused ﬁnancial application feel core idea using surrogate model within task-driven optimization procedure.) ﬁrst formally deﬁne stochastic modeling optimization problems concerned. denote standard input-output pairs drawn distribution also consider actions incur expected loss exy∼d]. instance power systems operator allocate power generators given past electricity demand future electricity demand allocation’s loss corresponds overunder-generation penalties incurred given future demand instantiations. knew could select optimal actions argminz however practice true distribution unknown. paper interested modeling conditional distribution using parameterized model order minimize real-world cost policy implied parameterization. speciﬁcally parameters parameterize determine optimal actions correspond observed input speciﬁc choice parameters probabilistic model. upon observing costs actions relative true instantiations update parameterized model accordingly calculate resultant repeat. goal parameters corresponding policy optimizes loss true joint distribution explicitly wish choose minimize task loss context i.e. setting speciﬁes using simple stochastic program reality decision subject probabilistic deterministic constraints. therefore consider general decisions produced generic stochastic programming problem standard presume stochastic programming equality constraints depend decision variables non-trivial random equality constraints typically possible satisfy. indicator function zero constraints satisﬁed inﬁnite otherwise). however basic intuition behind approach remains constrained unconstrained cases settings attempt learn parameters probabilistic model produce strictly accurate predictions resultant model within stochastic programming setting resulting decisions perform well true distribution. actually solving problem requires differentiate argmin operator stochastic programming problem. differentiation possible classes optimization problems show shortly many practical cases–including cases function constraints strongly convex–we indeed efﬁciently compute gradients even context constrained optimization. highlight approach contrast alternative existing methods traditional model learning model-free black-box policy optimization. traditional machine learning approaches common minimize log-likelihood observed data model method corresponds approximately solving optimization problem need conditional distribution determine actions within later optimization setting commonly predictive model obtained directly. approach obvious advantages model-learning phase well-justiﬁed independent future task. however also prone poor performance common setting true distribution cannot represented within class distributions parameterized i.e. procedure suffers model bias. conceptually log-likelihood objective implicitly trades model error different regions input/output space manner largely opaque modeler ultimately employ correct tradeoffs given task. contrast alternative approach solving describe model-free black-box policy optimization approach. here forgo learning model random variable instead attempt learn policy mapping directly inputs actions minimize loss presented model-free methods perform well many settings often data-inefﬁcient policy class must enough representational power describe sufﬁciently complex policies without recourse underlying model. algorithm task loss optimization approach offers intermediate setting input example still surrogate model determine optimal decision adapt initialize model based task loss instead model prediction accuracy. practice typically want minimize weighted combination log-likelihood task loss easily accomplished given approach. this distinction roughly analogous policy search model-based settings reinforcement learning. however purposes paper consider much simpler stochastic programs without multiple rounds occur extension techniques full setting remains future work. solve proxy stochastic programming problem obtain using distribution deﬁned current values then compute true loss using observed value inequality constraints violated take gradient step violated constraint; otherwise take gradient step optimization objective note inequality constraints probabilistic algorithm must adapted employ mini-batches order determine whether probabilistic constraints satisﬁed. alternatively even constraints probabilistic common practice simply move weighted version constraints objective i.e. modify objective adding appropriate penalty times positive part function λgi+ practice effect taking gradient steps jointly violated constraints objective case inequality constraints violated often resulting faster convergence. note need move stochastic constraints objective; deterministic constraints policy always satisﬁed optimizer independent model. presentation highlights simplicity proposed approach avoids issue chief technical challenge approach computing gradient objective depends upon argmin operation speciﬁcally need compute term involves jacobian jacobian optimal solution respect distribution parameters recent approaches looked similar argmin differentiations though methodology present general handles stochasticity objective. high level begin writing optimality conditions general stochastic programming problem differentiating equations applying implicit function theorem gives linear equations solve obtain necessary jacobians denoted vector inequality constraints) terms equations look somewhat complex fundamentally left side gives optimality conditions convex problem right side gives derivatives relevant functions achieved solution respect governing parameter practice calculate right-hand terms employing sequential quadratic programming optimal policy given parameters using recently-proposed approach fast solution argmin differentiation solve necessary linear equations; take derivatives optimum produced strategy. details approach described appendix. consider three applications task-based method synthetic inventory stock problem real-world energy scheduling task real-world battery arbitrage task. demonstrate task-based end-to-end approach substantially improve upon alternatives. source code experiments available https//github.com/locuslab/ee-model-learning. problem deﬁnition highlight performance algorithm setting true underlying model known consider conditional variation classical inventory stock problem problem company must order quantity product minimize costs stochastic demand whose distribution turn affected observed features linear quadratic costs amount product ordered plus different linear/quadratic costs over-orders under-orders objective given qh+) max{v speciﬁc choice probability model proxy stochastic programming problem written simplify setting assume demands discrete taking values probabilities thus stochastic programming problem written succinctly joint quadratic program experimental setup examine algorithm main conditions true model linear nonlinear. cases generate problem instances randomly sampling generating according either exp) rn×k. compare following approaches tasks allocation based upon true model approaches model data compute allocation solving pure end-to-end policy-optimizing models task-based learning models cases evaluate test performance running random examples evaluate performance folds different true parameters. figures show performance methods given linear true model linear nonlinear model hypotheses respectively. expected linear approach performs best true underlying model class distributions represent thus solving stochastic programming problem strong proxy solving true optimization problem real distribution. true model also contained within nonlinear mle’s generic nonlinear distribution class method requires data converge given less data makes error tradeoffs ultimately correct tradeoffs task hand; task-based approach thus outperforms approach. task-based approach also substantially outperforms policy-optimizing neural network highlighting fact data-efﬁcient learning process through reasonable model. note make difference whether linear nonlinear model task-based approach. figures show performance case nonlinear true model linear nonlinear model hypotheses respectively. case represents non-realizable case true underlying distribution cannot represented model hypothesis class. here linear expected performs poorly cannot capture true underlying distribution thus resultant stochastic programming solution would expected perform well. linear policy model similarly performs poorly. importantly task-based approach linear model performs much better here despite fact still misspeciﬁed model task-based nature learning process lets learn different linear model version this referred two-stage stochastic programming problem ﬁrst stage variables consist amount product observing demand second-stage variables consist much sell back additionally purchase true demand revealed. figure inventory problem results runs representative instantiation true parameters cost evaluated testing samples linear performs best true linear model. cases task-based models outperform policy counterparts. particularly tuned distribution loss task. finally also expected non-linear models perform better linear models scenario task-based non-linear model outperforming nonlinear end-to-end policy approaches. next consider realistic grid-scheduling task based upon years real electrical grid data. setting power system operator must decide much electricity generation schedule hour next hours based distribution electricity demand given particular realization demand impose penalties generation excess generation shortage also quadratic regularization term indicating preference generation schedules closely match demand realizations. finally impose ramping constraint restricting change generation consecutive timepoints reﬂecting physical limitations associated quick changes electricity output levels. reasonable proxies actual economic costs incurred electrical grid operators scheduling generation written stochastic programming problem max{v assuming gaussian random variable mean variance expectation closed form computed analytically integrating gaussian pdf. sequential quadratic programming iteratively approximate resultant convex objective quadratic objective iterate convergence compute necessary jacobians using quadratic approximation solution gives correct hessian gradient terms. details given appendix. develop predictive model make highly-tuned load forecasting methodology. speciﬁcally input past day’s electrical load temperature next day’s temperature forecast additional features non-linear functions temperatures binary indicators weekends holidays yearly sinusoidal features. predict electrical load part philosophy behind applying approach know gaussian assumption incorrect true underlying load neither gaussian distributed homoskedastic. however assumptions exceedingly common practice enable easy model learning exact analytical solutions. thus training system task-based loss retains computational tractability still allowing modify distribution’s parameters improve actual performance task hand. figure results runs generation-scheduling problem representative decision parameters expected rmse achieves lowest rmse predictions. however task outperforms rmse task loss cost-weighted rmse task loss hours next day. employ -hidden-layer neural network purpose additional residual connection inputs outputs initialized linear regression solution. illustration architecture shown figure train model minimize mean squared error predictions actual load compute empirical variance predicted actual values. cases years data train model subsequent years testing. using predictions base model obtain solving generator scheduling problem adjusting network parameters minimize resultant task loss. compare traditional stochastic programming model minimizes rmse well cost-weighted rmse periodically reweights training samples given task loss. figure shows performance three models. expected rmse model performs best respect rmse predictions however task-based model substantially outperforms rmse model evaluated task loss actual objective system operator cares about speciﬁcally improve upon performance traditional stochastic programming method cost-weighted rmse’s performance extremely variable overall task improves upon method finally consider battery arbitrage task based upon years real electrical grid data. here grid-scale battery must operate hour period based distribution future electricity prices hour operator must decide much charge discharge battery thus inducing particular state charge battery given particular realization prices operator optimizes over proﬁts ﬂexibility participate markets keeping battery near half capacity battery health discouraging rapid charging/discharging task-based method however accommodates general setting. table task loss results runs battery storage problem given lithium-ion battery attributes γeff cout task-based average somewhat improves upon rmse demonstrates reliable performance. assuming random variable mean expectation closed form depends mean. details given appendix. develop predictive model mean architecture similar described section case input past day’s prices temperature next day’s load forecasts temperature forecasts additional features non-linear functions temperatures temporal features similar section train model minimize mean squared error model’s predictions actual prices using years data train model subsequent year testing. using mean predictions base model solve storage scheduling problem solving optimization problem learning network parameters minimizing task loss. compare traditional stochastic programming model minimizes rmse. table shows performance models. energy prices difﬁcult predict numerous outliers price spikes models case well-tuned load forecasting experiment; thus performance relatively variable. even then cases task-based model demonstrates better average performance rmse model evaluated task loss objective important battery operator interestingly task-based method shows less variability performance rmse-minimizing method. qualitatively task-based method hedges perverse events price spikes could substantially affect performance battery charging schedule. task-based method thus yields reliable performance pure rmse-minimizing method case models inaccurate high level stochasticity prediction task. paper proposes end-to-end approach learning machine learning models used loop larger process. speciﬁcally consider training probabilistic models context stochastic programming directly capture task-based objective. preliminary experiments indicate task-based learning model substantially outperforms policy-optimizing approaches case model perfectly characterizes underlying distribution. method also achieves performance improvement highly-optimized real-world stochastic programming algorithm scheduling electricity generation based predicted load. case energy price prediction high degree inherent stochasticity problem method demonstrates reliable task performance traditional predictive method. task-based approach thus demonstrates promise optimizing in-the-loop predictions. future work includes extension approach stochastic learning models multiple rounds model predictive control full reinforcement learning settings. material based upon work supported national science foundation graduate research fellowship program grant department energy computational science graduate fellowship. ryan thomas daniel friend luiz dasilva allen mackenzie. cognitive networks adaptation learning achieve end-to-end performance objectives. ieee communications magazine kaiming xiangyu zhang shaoqing jian sun. deep residual learning image recognition. proceedings ieee conference computer vision pattern recognition pages wang david adam coates andrew end-to-end text recognition convolutional neural networks. pattern recognition international conference pages ieee dario amodei rishita anubhai eric battenberg carl case jared casper bryan catanzaro jingdong chen mike chrzanowski adam coates greg diamos deep speech end-toend speech recognition english mandarin. arxiv preprint arxiv. harada sakuma shigenobu kobayashi. local search multiobjective function optimization pareto descent method. proceedings annual conference genetic evolutionary computation pages veselin stoyanov alexander ropson jason eisner. empirical risk minimization graphical model parameters given approximate inference decoding model structure. international conference artiﬁcial intelligence statistics issn yang song alexander schwing richard zemel raquel urtasun. training deep neural networks direct loss minimization. proceedings international conference machine learning pages jaderberg volodymyr mnih wojciech marian czarnecki schaul joel leibo david silver koray kavukcuoglu. reinforcement learning unsupervised auxiliary tasks. arxiv preprint arxiv. stephen gould basura fernando anoop cherian peter anderson rodrigo santa cruz edison guo. differentiating parameterized argmin argmax problems application bi-level optimization. arxiv preprint arxiv. involves jacobian jacobian optimal solution respect distribution parameters recent approaches looked similar argmin differentiations though methodology present general handles stochasticity objective. begin writing optimality conditions general stochastic programming problem expectations taken respect modeled distribution further assuming problem convex means replace general equality constraints linear constraint point primal-dual optimal point satisﬁes denotes vector inequality constraints wrap dependence functions themselves. differentiating equations applying implicit function theorem gives linear equations solve obtain necessary jacobians terms left side optimality conditions convex problem terms right side derivatives relevant functions achieved solution respect governing parameter equations take slightly different forms depending stochastic programming problem solved usually fairly straightforward compute solution solved exact manner practice calculate right side equation employing sequential quadratic programming optimal policy given parameters using recently-proposed approach fast solution argmin differentiation solve necessary linear equations; take derivatives optimum produced strategy. qh+) amount product ordered; stochastic electricity demand max{v linear quadratic costs amount product ordered over-orders under-orders respectively. proxy stochastic programming problem written simplify setting assume demands discrete taking values probabilities thus stochastic programming problem written succinctly joint quadratic program denotes jacobian model probabilities respect parameters computed typical manner. note practice jacobians need computed explicitly computed efﬁciently backpropagation; recently-developed differentiable batch solver solve optimization problem form compute derivatives. generator schedule stochastic demand max{v over-generation penalty under-generation penalty ramping constraint. assuming gaussian random variable mean variance expectation closed form computed analytically integrating gaussian pdf. speciﬁcally closed form expectation convex function) thus optimize efﬁciently compute necessary jacobians. speciﬁcally sequential quadratic programming iteratively approximate resultant convex objective quadratic objective iterate convergence; speciﬁcally repeatedly solve compute necessary jacobians using quadratic approximation solution gives correct hessian gradient terms. furthermore differentiate gradient hessian respect underlying model parameters using recently-developed batch solver zout zstate decisions charge amount discharge amount resultant state battery respectively; stochastic electricity price battery capacity; γeff battery charging efﬁciency; cout maximum hourly charge discharge amounts respectively; hyperparameters related ﬂexibility battery health respectively. assuming random variable mean expectation closed form follows experiment assume lognormal random variable thus obtain predictions predict mean obtaining predictions solve compute necessary jacobians solution update underlying model parameter backpropagation using linear models one-layer linear neural network appropriate input output layer dimensions. nonlinear models two-hidden-layer neural network layer actually combination linear batch norm relu dropout layers dimension cases additional softmax layer cases probability distributions predicted. models implemented using pytorcha. employ adam optimizer solved using recently-developed differentiable batch solver jacobians also computed automatically using backpropagation same. source code experiments available https//github.com/locuslab/ ee-model-learning.", "year": 2017}