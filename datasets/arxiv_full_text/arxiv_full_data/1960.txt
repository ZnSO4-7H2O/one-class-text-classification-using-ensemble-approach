{"title": "Cross-Domain Visual Matching via Generalized Similarity Measure and  Feature Learning", "tag": ["cs.CV", "cs.AI", "stat.ML"], "abstract": "Cross-domain visual data matching is one of the fundamental problems in many real-world vision tasks, e.g., matching persons across ID photos and surveillance videos. Conventional approaches to this problem usually involves two steps: i) projecting samples from different domains into a common space, and ii) computing (dis-)similarity in this space based on a certain distance. In this paper, we present a novel pairwise similarity measure that advances existing models by i) expanding traditional linear projections into affine transformations and ii) fusing affine Mahalanobis distance and Cosine similarity by a data-driven combination. Moreover, we unify our similarity measure with feature representation learning via deep convolutional neural networks. Specifically, we incorporate the similarity measure matrix into the deep architecture, enabling an end-to-end way of model optimization. We extensively evaluate our generalized similarity model in several challenging cross-domain matching tasks: person re-identification under different views and face verification over different modalities (i.e., faces from still images and videos, older and younger faces, and sketch and photo portraits). The experimental results demonstrate superior performance of our model over other state-of-the-art methods.", "text": "abstract—cross-domain visual data matching fundamental problems many real-world vision tasks e.g. matching persons across photos surveillance videos. conventional approaches problem usually involves steps projecting samples different domains common space computing similarity space based certain distance. paper present novel pairwise similarity measure advances existing models expanding traditional linear projections afﬁne transformations fusing afﬁne mahalanobis distance cosine similarity data-driven combination. moreover unify similarity measure feature representation learning deep convolutional neural networks. speciﬁcally incorporate similarity measure matrix deep architecture enabling end-to-end model optimization. extensively evaluate generalized similarity model several challenging cross-domain matching tasks person re-identiﬁcation different views face veriﬁcation different modalities experimental results demonstrate superior performance model state-of-the-art methods. fundamental problems computer vision pattern recognition problem becomes challenging dealing cross-domain data. example still-video face retrieval newly rising task visual surveillance faces still images captured constrained environment utilized queries matches identity unconstrained videos. age-invariant sketch-photo face veriﬁcation tasks also examples cross-domain image matching. examples applications shown figure conventional approaches partial least square regression crossdomain matching usually follow procedure steps samples different modalities ﬁrst projected common space learning transformation. simplify computation assuming cross domain samples share projection. certain distance utilized measuring similarity/disimilarity projection space. usually euclidean distance inner product used. suppose samples different modalities projection matrices applied respectively. usually formulated linear similarity transformations mainly wang school data computer science yat-sen university guangzhou china. email linliangieee.org; wanggrunmail.sysu.edu.cn. school computer science technology harbin institute technology harbin china. email cswmzuogmail.com. feng school math. statistics xidian university xi’an fig. typical examples matching cross-domain visual data. faces still images vidoes. frontside-view persons. older younger faces. photo sketch faces. convenience optimization. similarity transformation good property preserving shape object goes transformation limited capturing complex deformations usually exist various real problems e.g. translation shearing compositions. hand mahalanobis distance cosine similarity combination widely studied research similarity metric learning remains less investigated unify feature learning similarity learning particular combine mahalanobis distance cosine similarity integrate distance metric deep neural networks end-to-end learning. fig. illustration generalized similarity model. conventional approaches project data simply using linear similarity transformations illustrated euclidean distance applied distance metric. illustrated improve existing models expanding traditional linear similarity transformation afﬁne transformation fusing mahalanobis distance cosine similarity. case simpliﬁed version model. please refer appendix section deduction details. deep architecture integrate similarity measure cnn-based feature representation learning. architecture takes images different modalities inputs automatically produce representations sequentially stacking shared sub-network upon domain-speciﬁc subnetworks. upon layers incorporate components similarity measure stimulating several appended structured neural network layers. feature learning similarity model learning thus integrated end-to-end optimization. cross-domain similarity measure learning. first presents generic similarity measure generalizing traditional linear projection distance metrics uniﬁed formulation. model viewed generalization several existing similarity learning models. second integrates feature learning similarity measure learning building end-to-end deep architecture neural networks. deep architecture effectively improves adaptability learning data different modalities. third extensively evaluate framework four challenging tasks cross-domain visual matching person re-identiﬁcation across views face veriﬁcation different modalities experimental results show similarity model outperforms state-of-the-arts three address issues work present general similarity measure unify deep convolutional representation learning. innovations generalize existing similarity models aspects. first extend similarity transformations afﬁne transformations adding translation vector them i.e. replacing respectively. afﬁne transformation generalization similarity transformation without requirement preserving original point linear space able capture complex deformations. second unlike traditional approaches choosing either mahalanobis distance cosine similarity combine measures afﬁne transformation. combination realized data-driven fashion discussed appendix resulting novel generalized similarity measure deﬁned figure intuitively explains idea. example observed euclidean distance linear transformation illustrates regarded special case model similarity model viewed generalization several recent metric learning models experimental results validate introduction ﬂexible setting improve matching performance signiﬁcantly. another innovation work unify feature representation learning similarity measure learning. literature existing models performed original data space pre-deﬁned feature space feature extraction similarity measure studied separately. methods several drawbacks practice. example similarity models heavily rely feature engineering thus lack generality handling problems different scenarios. moreover interaction feature representations similarity measures ignored simpliﬁed thus limiting performances. meanwhile deep learning especially convolutional neural network demonstrated effectiveness learning discriminative features data beneﬁted build end-to-end learning frameworks. motivated works build figure imply model geometrically aligns samples matched. using example emphasize superiority afﬁne transformation traditional linear similarity transformation capturing pattern variations feature space. person re-identiﬁcation arguably cross-domain matching problem. introduce experiments since problem receiving increasing attentions recently. rest paper organized follows. section reviews related work. section introduces generalized similarity model discusses connections existing works. section presents proposed deep neural network architecture learning algorithm section experimental results comparisons ablation studies presented section section concludes paper. related work literature cope cross-domain matching visual data learn common space different domains. learns common space maximizing cross-view correlation learned maximizing cross-view covariance. coupled information-theoretic encoding proposed maximize mutual information another conventional strategy synthesize samples input domain domain. rather learning mapping domains data space dictionary learning used alleviate cross-domain heterogeneity semi-coupled dictionary learning proposed model relationship sparse coding vectors domains. duan proposed another framework called domain adaptation machine multiple source domain adaption need pre-trained base classiﬁers. various discriminative common space approaches developed utilizing label information. supervised information employed rayleigh quotient treating label common space employing max-margin rule using scdl framework structured group sparsity adopted utilize label information generalization discriminative common space multiview also studied proposed multiview discriminant analysis method obtain common space multiple views optimizing inter-view intra-view rayleigh quotient. method learn shape models using local curve segments multiple types distance metrics proposed. moreover existing multiview analysis methods target deﬁned based standard inner product distance samples feature space. ﬁeld metric learning several generalized similarity distance measures studied improve recognition performance. generalized distance similarity measures formulated difference distance component similarity component take account cross inner product term norm terms. adopted second-order decision function distance measure without considering positive semi-deﬁnite constraint. chang yeung suggested approach learn locally smooth metrics using local afﬁne transformations preserving topological structure original data. distance similarity measures however developed matching samples domain cannot directly applied cross domain data matching. model learns domain-speciﬁc transformations based generalized logistic loss. zhai incorporated joint graph regularization heterogeneous metric learning model improve crossmedia retrieval accuracy. euclidean distance adopted measure dissimilarity latent space. instead explicitly learning domain-speciﬁc transformations kang learned rank matrix parameterize cross-modal similarity measure accelerated proximal gradient algorithm. however methods mainly based common similarity distance measures none addresses feature learning problem cross-domain scenarios. instead using hand-crafted features learning feature representations contextual relations deep neural networks especially convolutional neural network shown great potential various pattern recognition tasks object recognition semantic segmentation signiﬁcant performance gains also achieved face recognition person reidentiﬁcation mainly attributed progress deep learning. recently several deep cnnbased models explored similarity matching learning. example andrew proposed multi-layer model consisting several stacked nonlinear transformations. learned ﬁlter pairs deep networks handle misalignment photometric geometric transforms achieved promising results person re-identiﬁcation task. wang learned ﬁne-grained image similarity deep ranking model. presented deep metric learning approach generalizing siamese cnn. ahmed proposed deep convolutional architecture measure similarity pair pedestrian images. besides shared convolutional layers network also includes neighborhood difference layer patch summary layer compute cross-input neighborhood differences. chen proposed deep ranking framework learn joint representation image pair return similarity score directly similarity model replaced full connection layers. deep model partially motivated works target powerful solution crossdomain visual matching incorporating generalized similarity function deep neural networks. moreover network architecture different existing works leading state-of-the-art results several challenging person veriﬁcation recognition tasks. generalized similarity model section ﬁrst introduce formulation deep generalized similarity model discuss connections model existing similarity learning methods. model formulation according discussion section generalized similarity measure extends traditional linear projection integrates mahalanobis distance cosine similarity connection existing models generalized similarity learning model generalization many existing metric learning models treated special cases model imposing extra constraints proposed learn decision function jointly models distance metric locally adaptive thresholding rule so-called ladf formulated second-order large-margin regularization problem. specifically ladf deﬁned noted ladf treats using metrics i.e. xtax model reasonable matching samples modality unsuitable cross-domain matching different modalities. compared ladf model uses calculate xtax uses calculate making model effective crossdomain matching. moreover model extracts feature representation input data utilizing cnns. incorporating feature representation matrix factorization eqn. thus following similarity model regarded similarity components accordingly similarity components modeled weights connect neurons last layers. example portion output activations represents taking input multiplying corresponding weights following discuss formulation similarity learning. objective similarity learning seek function satisﬁes similarity/disimilarity constraints. instead learning similarity function handcrafted feature space take data input introduce deep similarity learning framework integrate nonlinear feature learning generalized similarity learning. recall deep generalized similarity model eqn. feature representations samples different modalities indicate parameters. denote similarity components sample matching. note asymmetric i.e. rea˜ sonable cross-domain matching similarity components domain-speciﬁc. training cross-domain sample pairs denotes pair denotes corresponding label indicating whether class fig. deep architecture similarity model. architecture comprised three parts domain-speciﬁc sub-network shared sub-network similarity sub-network. ﬁrst parts extract feature representations samples different domains built upon number convolutional layers max-pooling operations fully-connected layers. similarity sub-network includes structured fully-connected layers incorporate similarity components eqn. summary similarity model regarded generalization many existing cross-domain matching metric learning models ﬂexible suitable cross-domain visual data matching. joint similarity feature learning section introduce deep architecture integrates generalized similarity measure convolutional feature representation learning. deep architecture discussed above model deﬁned eqn. jointly handles similarity function learning feature learning. integration achieved building deep architecture convolutional neural networks illustrated figure worth mentioning architecture able handle input samples different modalities unequal numbers e.g. samples samples network batch processing. left right figure domain-speciﬁc subnetworks applied samples different modalities respectively. then outputs concatenated shared subnetwork make superposition feed output feature representations samples extracted separately indicated slice operator figure finally learned feature representations utilized structured fully-connected layers incorporate similarity components deﬁned eqn. following introduce detailed setting three sub-networks. branches neural networks handle samples different domains. network branch includes convolutional layer ﬁlters size stride step pixels. rectiﬁed nonlinear activation utilized. then follow max-pooling operation size stride step pixels. shared sub-network. component stack convolutional layer fully-connected layers. convolutional layer contains ﬁlters size ﬁlter stride step pixel. kernel size maxpooling operation stride step pixels. output vectors fully-connected layers dimensions. normalize output second fully-connected layer next subnetwork. similarity sub-network. slice operator ﬁrst applied sub-network partitions vectors groups corresponding domains. example figure vectors grouped sets i.e. size respectively. dimensions. then branches neural network branch includes fully-connected layer. divide activations layers parts according similarity components. shown figure branch neural layer connects outputs respectively. bottom branch layer outputs respectively connecting similarity measure tightly integrated feature representations jointly optimized model training. note parameter generalized similarity measure eqn. experiments show value affects learning convergence rather matching performance. thus empirically experiments. deep architecture observe similarity components interact factorization ﬁnal aggregation calculation computing components independent leads good property efﬁcient matching. particular sample stored database precomputed feature representation corresponding similarity components similarity matching testing stage fast. denotes learning rate. problem solving equation calculating discussed ways i.e. pairbased gradient descent sample-based gradient descent. adopt latter reduce requirements computation memory cost. mini-batch samples {zjx zjnxx zjny original following chain rule calculating gradient pairs samples equivalent summing gradient sample using zjix example ﬁrst introduce indicator function zjix calculating partial derivative output layer activation sample ∂˜zjix speciﬁcally deﬁne zjix {zjix zjiy} otherwise sample pair jixjiy zjix jixjiy indicating zjix zjiy class. zjix gradient ˜zjix written note three sub-networks deep architecture differentiable. easily backpropagation procedure compute partial derivatives respect hidden layers model parameters summarize overall procedure deep generalized similarity measure learning algorithm possible pairs used training samplebased form allows generate sample pairs mini-batch hand sample-pair-based form require nxny samples less generate sample pairs. gradient computation eqn. sample require calculating p˜zjiy times sample-based form. sample-pair-based form p˜zjiy computed section discuss learning method similarity model training. avoid loading images memory mini-batch learning approach training iteration subset image pairs neural network model optimization. summation term denotes hinge-like loss cross domain sample pair {˜xi ˜yi} total number pairs represents feature representation different domains represents similarity model. embedded weights connecting neurons layers deep neural network model figure illustrates. objective function eqn. deﬁned samplepair-based form. optimize using apply certain scheme generate mini-batches sample pairs usually costs much computation memory. note sample pairs training constructed original samples different modalities {{x}{y}} xmx} ymy}. superscript denotes sample index original training e.g. xmx} ymy} subscript denotes index sample pairs e.g. denote total number samples different domains. without loss generality deﬁne zmx+j pair also sample training pairs feed sampled images network; perform feed-forward pass samples compute activations sample compute partial derivative output layer’s activation sample algorithm compute partial derivatives hidden layers’ activations sample following chain rule; using compute desired gradients back-propagation procedure; batch process implementation. suppose training image divided categories contains images ﬁrst domain images second domain. thus obtain maximum number pairwise samples quadratically number source images real application since number stored images reach millions impossible load data network training. overcome problem implement learning algorithm batch-process manner. speciﬁcally iteration small subset cross domain image pairs generated network training. according massive experiments randomly generating image pairs infeasible cause image distribution special batch becoming scattered making valid training samples certain category degenerating model. besides images pair almost impossible come class making positive samples few. order overcome problem effective cross domain image pair generation scheme adopted train generalized similarity model. round ﬁrst second domain randomly selected. selected images ﬁrst domain randomly take samples second domain proportions positive negative samples equal. images distributed generated samples relatively centralized model effectively converge. experiments section apply similarity model four representative tasks matching cross-domain visual data adopt several benchmark datasets evaluation person re-identiﬁcation different views cuhk cuhk datasets; age-invariant face recognition morph cacd cacd-vs datasets; iii) sketch-to-photo face matching cufs dataset face veriﬁcation still-video domains face dataset tasks state-of-the-art methods employed compare model. experimental setting. mini-batch learning adopted experiments save memory cost. task randomly select batch sample original training generate number pairs initial parameters convolutional full connection layers zero-mean gaussian distributions whose standard deviations respectively. speciﬁc settings different tasks included following sub-sections. addition ablation studies presented reveal beneﬁt main component method e.g. generalized similarity measure joint optimization feature representation metric model. also implement several variants method simplifying similarity measures comparison. person re-identiﬁcation person re-identiﬁcation aiming matching pedestrian images across multiple non-overlapped cameras attracted increasing attentions surveillance. despite considerable efforts made still open problem dramatic variations caused viewpoint pose changes. evaluate task cuhk dataset cuhk dataset adopted experiments. cuhk dataset largest databases person re-identiﬁcation. contains images pedestrians collected different pairs camera views. person observed disjoint camera views average images view. follow tion handcrafted features dense color histograms dense sift uniformly sampled patches adopted. second three methods specially designed person reidentiﬁcation employed experiments sdalf kissme esdc moreover several recently proposed deep learning methods including drsch dfpnn idla also compared approach. drsch supervised hashing framework integrating feature hash code learning dfpnn idla introduced section results reported fig. encouraging approach signiﬁcantly outperforms competing methods .%). among competing methods itml lmnn rank sdalf kissme esdc based hand-crafted features. superiority approach attributed deployment deep features generalized similarity model. drsch dfpnn idla adopted feature representation matching metrics deﬁned based traditional linear transformations. results cuhk. fig. shows results method competing approaches cuhk. addition used cuhk method i.e. lmlf used comparison experiment. lmlf learns mid-level ﬁlters automatically discovered patch clusters. according quantitative results method achieves state-of-the-art rank- accuracy age-invariant face recognition invariant face recognition decide whether images different ages belong identity. challenge handle large intra-subject variations caused aging process distinguishing different identities. factors illumination pose expression make invariant face recognition difﬁcult. conduct experiments using three datasets i.e. morph cacd cacd-vs morph contains face images individuals whose ages range average number images individual training consists face images subjects subject images largest gap. test composed gallery probe remaining subjects. gallery composed youngest face images subject. probe composed oldest face images subject. experimental setting adopted cacd large scale dataset released contains images celebrities. adopt subset individuals whole database experiment manually remove noisy images. among individuals labels images individuals originally provided annotate rest data. cacd includes large variations pose illumination expression also ages. cuhk dataset contains individuals samples disjoint cameras. following setting partition dataset training testing individuals testing others training. evaluation benchmarks testing randomly divided gallery images probe without overlap times. cumulative matching characteristic evaluation metric task. model training images resized cropped size center small random perturbation. every round learning pairs samples constructed selecting persons constructing pairs person cuhk individual samples pairs individual contain duplicated pairs. results cuhk. compare approach several state-of-the-art methods grouped three categories. first adopt distance metric learning methods based ﬁxed feature representation i.e. information theoretic metric learning local distance metric learning large margin nearest neighbors learning-torank method kernel-based metric learning method following implementacomparison including carc deep learning based method deepface results carc borrowed papers. results deepface approach implemented based originally annotated individuals samples used model training. quantitative results reported figure model achieves superior performances competing methods. furthermore also report result method using images individuals training samples. that performance model improved increasing training data. results cacd-vs. following setting evaluate approach conducting general face veriﬁcation experiment. speciﬁcally competing methods train models cacd test cacd-vs optimal threshold value matching obtained exhaustive search. results produced methods others hdlbp deepface reported table worth mentioning method improves state-ofthe-art recognition rate thanks introduction generalized similarity measure approach achieves higher veriﬁcation accuracy deepface. note explicit face alignment adopted feature extraction framework. sketch-photo face veriﬁcation sketch-photo face veriﬁcation interesting challenging task aims verify whether face photo drawing face sketch belong individual. task important application assisting enforcement i.e. using face sketch candidate face photos. however difﬁcult match photos sketches different modalities. example hand-drawing bring unpredictable face distortion variation compared real photo face sketches often lack details important cues preserving identity. evaluate model task using cufs dataset face photos dataset selected training testing. face corresponding sketch drawn artist. face photos taken frontal view normal lighting condition neutral expression. photos/sketches resized cropped size center small random perturbation. pairs photos sketches constructed iteration model training. testing stage face photos form gallery treat sketches probes. employ several existing approaches comparison eigenface transformation based method multi-scale markov random ﬁeld based method mrf+ worth mentioning competing methods need ﬁrst synthesize face sketches photosketch transformation measure similarity between synthesized sketches candidate sketches based cacd veriﬁcation subset called cacd-vs developed contains positive pairs negative pairs. setting testing protocol cacd-vs similar well-known benchmark except cacd-vs contains much samples person. images resized data augmentation images cropped size center small random perturbation feeding neural network. sample-based mini-batch setting adopted pairs constructed iteration. results morph. compare method several state-of-the-art methods including topological dynamic bayesian network cross-age reference coding probabilistic hidden factor analysis multi-feature discriminant analysis aging model results reported table thanks representation generalized similarity measure method achieves recognition rate signiﬁcantly outperforms competing methods. results cacd. dataset protocol retrieve face images individual gallery sets using probe probe face images gallery face images large. following experimental setting gallery sets according years photos taken probe search matches rest three sets. introduce several state-of-the-art methods fig. results ablation studies demonstrating effectiveness main component framework. curve recognition rate used evaluation. results different similarity models shown using handcrafted features using deep features respectively. show performances without deep feature learning keeping similarity model. task large-scale still-video face recognition dataset namely face dataset released recently extension cox-sv dataset face dataset includes subjects high quality still image video cliques respectively captured cameras. since cameras deployed similar environments data captured ﬁrst camera experiments. following setting face dataset divide data training testing conduct experiments random splits. sub-tasks testing matching video frames still images matching still images video frames task video frames probes form gallery still images inversely task. split gallery/probe sets also consistent protocol required creator. image resized cropped size image-based veriﬁcation problems deﬁned point-to-set matching problem i.e. still image several video frames evaluation calculate distance still image video frame model output average value distances. comparison employ several existing point-to-set distance metrics dual-space linear discriminant analysis manifold-manifold distance hyperplane-based distance kernelized convex geometric distance covariance kernel based distance also compare point-to-set correlation learning method specially developed face dataset. recognition rates competing methods reported table method achieves excellent performances i.e. best second best experiments show approach generally improve performances applications image-to-image imageto-video video-to-image matching problems. ablation studies order provide insights performance approach conduct number ablation studies isolating main component besides also study effect using sample-pair-based samplebased batch settings term convergence efﬁciency. generalized similarity model. design experiments using handcrafted features deep features respectively justify effectiveness generalized similarity measure. test similarity measure using ﬁxed handcrafted features person re-identiﬁcation. experimental results cuhk cuhk clearly demonstrate effectiveness model similarity models without counting deep feature learning. following extract feature representation using patchbased color histograms dense sift descriptors. feature representation full connection layer dimensionality reduction obtain -dimensional vector. invoke similarity sub-network output measure. cuhk cuhk adopt several representative similarity metrics comparison i.e. itml lmnn rank using feature representation. quantitative curves recognition rates competing models shown fig. cuhk cuhk respectively generalized represents similarity measure. observed model outperforms others large margins e.g. achieving rank- accuracy cuhk. competing methods learn mahalanobis distance metrics. contrast metric model combines mahalanobis distance cosine similarity generic form leading general effective solution matching cross-domain data. hand incorporate several representative similarity measures deep architecture jointly optimize measures feature learning. speciﬁcally simplify network architecture removing layer measure similarity either euclidean embedding space inner-product space variants viewed degenerations similarity measure support discussions section adopt distance metric models ladf deep neural networks. speciﬁcally replace similarity model ladf model deﬁned eqn. model deﬁned eqn. respectively. moreover implement variant applies similarity transformation parameters separate linear transformations data modality. remove afﬁne transformation keeping separate linear transformation setting eqn. note incorporating metric models deep architecture analogously metric model. experiment conducted four benchmarks cuhk morph cox-vs cox-sv results shown figure respectively. method outperforms competing methods large margins morph face dataset. cuhk method achieves best rank identiﬁcation rate among methods. particular performance drops removing afﬁne transformation cuhk. interesting discover competing methods treated special cases model. generalized similarity model fully take advantage convolutional feature learning developing speciﬁc deep architecture consistently achieve superior performance variational models. deep feature learning. show beneﬁt deep feature learning adopt handcrafted features cuhk chuk benchmark. speciﬁcally extract feature representation based patches pedestrian images build similarity measure person re-identiﬁcation. results cuhk chuk reported fig. respectively. denote result using handcrafted features hand.fea gen.sim result end-to-end deep feature learning deep.fea gen.sim. obvious without deep feature representation performance drops signiﬁcantly e.g. cuhk cuhk. results clearly demonstrate effectiveness utilizing deep cnns discriminative feature representation learning. sample-pair-based sample-based batch setting. addition conduct experiment compare samplepair-based sample-based term convergence efﬁciency using cuhk dataset. speciﬁcally sample-based batch setting select images people construct pairs training iteration. sample-pair-based batch setting pairs randomly constructed. note person cuhk note afﬁne distance measure afﬁne similarity measure. analogous adopt combine parameters automatically learned learning algorithm. then matrix obtained fusing equations matrix variables i.e. represent parameters generalized similarity model generic form. hand given matrix variables directly determined using eqn. hand impose positive semi-deﬁnite constraint proved determined exist least solution respectively guaranteed decomposed weighted mahalanobis distance cosine similarity. therefore generalized similarity measure learned optimizing positive semi-deﬁnite constraint addition required satisfy positive semideﬁnite condition square matrix dimensions unequal. images. thus images included iteration training time iteration almost settings. experiment shows samplebased batch setting model achieves rank- accuracy iterations setting rank- accuracy iterations. results validate effectiveness sample-based form saving training cost. conclusion work presented novel generalized similarity model cross-domain matching visual data generalizes traditional two-step methods furthermore integrated model feature representation learning building deep convolutional architecture. experiments performed several challenging benchmark dataset cross-domain matching. results show method outperforms state-of-the-art approaches. several directions along intend extend work. ﬁrst extend approach larger scale heterogeneous data thereby exploring applications second plan generalize pairwise similarity metric triplet-based learning effective model training. discussed section extend linear projections afﬁne transformations apply samples different domains respectively. replace respectively. then afﬁne mahalanobis distance deﬁned work supported part guangdong natural science foundation grant part program guangzhou zhujiang star science technology grant part fundamental research funds central universities. work also supported special program applied research super computation nsfc-guangdong joint fund chen wang bayesian face revisited joint formulation proc. eur. conf. comput. vis. springer davis kulis jain dhillon informationtheoretic metric learning proc. intl conf. mach. learn. zhuang wang zhang supervised coupled dictionary learning group structures multi-modal retrieval twenty-seventh aaai conference artiﬁcial intelligence wang zhang liang semi-coupled dictionary learning applications image super-resolution photosketch synthesis proc. ieee conf. comput. vis. pattern recognit ramage hall nallapati manning labeled supervised topic model credit attribution multilabeled corpora proc. conf. empirical methods natural language processing. association computational linguistics mignon jurie cmml metric learning approach cross modal matching proc. asian conf. comput. zhai peng xiao heterogeneous metric learning joint graph regularization crossmedia retrieval twentyseventh aaai conference artiﬁcial intelligence june wang song leung rosenberg wang philbin chen learning ﬁne-grained image similarity deep ranking proc. ieee conf. comput. vis. pattern recognit b.-c. chen c.-s. chen face recognition retrieval using cross-age reference coding cross-age celebrity dataset ieee trans. multimedia vol. wang tang face photo-sketch synthesis recognition ieee trans. pattern anal. mach. intell. vol. gray brennan evaluating appearance models recognition reacquisition tracking proc. ieee intl conf. workshop performance evaluation tracking surveillance vol. citeseer farenzena bazzani perina murino cristani person re-identiﬁcation symmetry-driven accumulation local features proc. ieee conf. comput. vis. pattern recognit kostinger hirzer wohlhart roth bischof large scale metric learning equivalence constraints proc. ieee conf. comput. vis. pattern recognit zhao ouyang wang unsupervised salience learning person re-identiﬁcation proc. ieee conf. comput. vis. pattern recognit huang ramesh berg learned-miller labeled faces wild database studying face recognition unconstrained environments technical report university massachusetts amherst tech. rep. bouchaffra mapping dynamic bayesian networks to-shapes application human faces identiﬁcation across ages ieee trans. neural networks learn. syst. vol. huang shan zhang kuerban chen benchmarking still-to-video face recognition partial local linear discriminant analysis cox-sv dataset proc. asian conf. comput. vis. springer liang professor school computer science yat-sen university china. received b.s. ph.d. degrees beijing institute technology beijing china respectively. post-doctoral research fellow department statistics university california angeles ucla. worked visiting scholar department computing hong kong polytechnic university hong kong department electronic engineering chinese university hong kong. research focuses models algorithms systems intelligent processing understanding visual data images videos. published papers tier academic journals conferences. currently serves associate editor ieee tran. human-machine systems. received best paper runners-up award npar google faculty award best student paper award ieee icme hong kong scholars award guangrun wang received b.e. degree school information science technology yat-sen university guangzhou china currently pursuing m.e. degree school data computer science yat-sen university. research interests include computer vision machine learning. wangmeng received ph.d. degree computer application technology harbin institute technology harbin china research assistant department computing hong kong polytechnic university hong kong. visiting professor microsoft research asia. currently professor school computer science technology harbin institute technology. current research interests include image modeling low-level vision discriminative learning biometrics. authored papers areas. associate editor biometrics. xiangchu feng received b.e. degree computational mathematics xi’an jiaotong university m.s. ph.d. degree applied mathematics xidian university xi’an china respectively. currently professor department information computational science school math. statistics xidian university xi’an china. current research interests include advanced numerical analysis image restoration enhancement based pdes sparse zhang received b.sc. degree shenyang institute aeronautical engineering shenyang p.r. china m.sc. ph.d degrees control theory engineering northwestern polytechnical university xian p.r. china respectively research associate dept. computing hong kong polytechnic university. jan. jan. worked postdoctoral fellow dept. electrical computer engineering mcmaster university canada. joined dept. computing hong kong polytechnic university assistant professor. since july full professor department. research interests include computer vision pattern recognition image video processing biometrics etc. zhang published papers areas. publications cited times literature. zhang currently associate editor ieee trans. image processing ieee trans. csvt image vision computing. awarded faculty award research scholarly activities. information found homepage http//www.comp.polyu.edu.hk/∼cslzhang/.", "year": 2016}