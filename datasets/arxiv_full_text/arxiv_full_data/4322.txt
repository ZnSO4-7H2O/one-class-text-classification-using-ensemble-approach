{"title": "Cross-Domain Sparse Coding", "tag": ["cs.CV", "stat.ML"], "abstract": "Sparse coding has shown its power as an effective data representation method. However, up to now, all the sparse coding approaches are limited within the single domain learning problem. In this paper, we extend the sparse coding to cross domain learning problem, which tries to learn from a source domain to a target domain with significant different distribution. We impose the Maximum Mean Discrepancy (MMD) criterion to reduce the cross-domain distribution difference of sparse codes, and also regularize the sparse codes by the class labels of the samples from both domains to increase the discriminative ability. The encouraging experiment results of the proposed cross-domain sparse coding algorithm on two challenging tasks --- image classification of photograph and oil painting domains, and multiple user spam detection --- show the advantage of the proposed method over other cross-domain data representation methods.", "text": "studied classiﬁer transfer method learns classiﬁer target domain target domain samples help source domain samples cross domain data representation tries samples source target domains data representation space common distribution across domains could used train single domain classiﬁer target domain paper focus cross domain representation problem. works done ﬁeld various data representation methods. example blitzer proposed structural correspondence learning algorithm induce correspondence among features source target domains daume proposed feature replication method augment features cross-domain learning. proposed transfer component analysis learns transfer components across domains maximum mean discrepancy extended semi-supervised recently sparse coding attracted many attention eﬀective data representation method represent data sample sparse linear combination codewords codebook sparse coding algorithms unsupervised small number labeled samples. semi-supervised sparse coding methods proposed utilize labeled samples significant performance improvement reported case would interesting investigate cross-domain representation provide available labeled samples source domain. knowledge work done using sparse coding method solve cross-domain problem paper propose novel cross-domain sparse coding method combine advantages sparse coding crossdomain learning. learn common codebook sparse coding samples source target domains. utilize class labels semi-supervised regularization also introduced sparse codes. moreover reduce mismatch distributions sparse codes source target samples adapt rule sparse codes. remaining paper organized follows section introduce formulations proposed cross-domain sparse coding implementations. section reports experimental results section concludes paper. abstract sparse coding shown power eﬀective data representation method. however sparse coding approaches limited within single domain learning problem. paper extend sparse coding cross domain learning problem tries learn source domain target domain signiﬁcant diﬀerent distribution. impose maximum mean discrepancy criterion reduce cross-domain distribution diﬀerence sparse codes also regularize sparse codes class labels samples domains increase discriminative ability. encouraging experiment results proposed cross-domain sparse coding algorithm challenging tasks image classiﬁcation photograph painting domains multiple user spam detection show advantage proposed method cross-domain data representation methods. traditional machine learning methods usually assume suﬃcient training samples train classiﬁer. however many real-world applications number labeled samples always limited making learned classiﬁer robust enough. recently cross-domain learning proposed solve problem borrowing labeled samples called source domain learning problem target domain hand. samples domains diﬀerent distributions related share class label feature space. types domain transfer learning methods permission make digital hard copies part work personal classroom granted without provided copies made distributed proﬁt commercial advantage copies bear notice full citation ﬁrst page. copyrights components work owned others must honored. abstracting credit permitted. copy otherwise republish post servers redistribute lists requires prior speciﬁc permission and/or fee. request permissions permissionsacm.org. copyright x-xxxxx-xx-x/xx/xx ..... reducing mismatch sparse code distribution reduce mismatch distributions source domain target domain sparse code space adopt criterion based minimization distance means codes domains. problem reducing mismatch sparse code distribution source target domains could formatted follows denote training dataset samples {xi}n number data samples feature vector i-th sample feature dimensionality. also organized matrix rd×n training composed source domain target domain i.e. samples source target domain separatively. samples source domain labeled samples target domain labeled. labeled sample denote class label class label space. construct objective function consider following three problems sparse coding problem given sample codebook matrix rd×k k-th column k-th codeword number codewords codebook sparse coding tries reconstruct linear reconstruction vkiuk reconstruction coeﬃcient vector sparse possible thus also called sparse code. problem sparse coding formulated follows sparse code space intra-class variance minimized inter-class variance maximized samples labeled target source domains. ﬁrst deﬁne semi-supervised regularization matrix compare crodomsc several cross-domain data representation methods sstca boxplots classiﬁcation accuracies splits using photograph painting target domains reported figure figure proposed crodomsc outperforms four competing methods photograph painting domains. it’s also interesting notice classiﬁcation methods poor around sstca seems better still competitive crodomsc. email dataset inboxes diﬀerent users used experiment email samples inbox half spam half non-spam. signiﬁcant diﬀerences email source among diﬀerent users email diﬀerent users could treated diﬀerent domains. proposed cross domain sparse coding algorithm named crodomsc summarized algorithm applied original sparse coding methods samples source target domains initialization. collected image database photographs paintings. database contains totally images semantical classes. images class photographs remaining ones paintings. extracted concatenated color texture shape bag-of-words histogram features visual feature vector image. conduct experiment photograph domain painting domain source domain target domain turns. target domain randomly split training subset test subset images training subset randomly selected label samples source domain samples labeled. random splits repeated times. ﬁrst perform crodomsc training conduct experiment randomly select users’ inboxes source target domains. target domain split test training source domain emails labeled. word occurrence frequency histogram extracted email original feature vector. crodomsc algorithm performed learn sparse code source target domain samples used train semi-supervised classiﬁer. target domain test samples also represented sparse codes classiﬁed using learned classiﬁer. selection repeated times reduce bias selection. figure shows boxplots classiﬁcation accuracies spam detection task. observed ﬁgure proposed crodomsc always outperforms competitors. another solid evidence eﬀectiveness sparse coding method cross-domain representation problem. moreover sstca also semisupervised cross-domain representation method seems outperform methods cases. however differences performances ones signiﬁcant. paper introduce ﬁrst sparse coding algorithm cross-domain data representation problem. sparse code distribution diﬀerences source target domains reduced regularizing sparse codes criterion. moreover class labels source target domain samples utilized encourage discriminative ability. developed cross-domain sparse coding algorithm tested cross-domain learning tasks eﬀectiveness shown.", "year": 2013}