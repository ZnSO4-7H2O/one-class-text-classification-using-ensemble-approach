{"title": "Back to the Basics: Bayesian extensions of IRT outperform neural  networks for proficiency estimation", "tag": ["cs.AI", "cs.LG"], "abstract": "Estimating student proficiency is an important task for computer based learning systems. We compare a family of IRT-based proficiency estimation methods to Deep Knowledge Tracing (DKT), a recently proposed recurrent neural network model with promising initial results. We evaluate how well each model predicts a student's future response given previous responses using two publicly available and one proprietary data set. We find that IRT-based methods consistently matched or outperformed DKT across all data sets at the finest level of content granularity that was tractable for them to be trained on. A hierarchical extension of IRT that captured item grouping structure performed best overall. When data sets included non-trivial autocorrelations in student response patterns, a temporal extension of IRT improved performance over standard IRT while the RNN-based method did not. We conclude that IRT-based models provide a simpler, better-performing alternative to existing RNN-based models of student interaction data while also affording more interpretability and guarantees due to their formulation as Bayesian probabilistic models.", "text": "enables eﬃcient diagnosis remediation weaknesses eﬀective advancement knowledge frontier. proﬁciency estimates also provide student teacher actionable information improve student outcomes reported analytics classical families methods estimating proﬁciency item response theory bayesian knowledge tracing essentially amounts structured logistic regression estimating latent quantities corresponding student ability assessment properties diﬃculty. capture assessment properties employs dynamic representation student ability. growing body recent work focused modeling various structural properties students assessments attempt combine advantages instance recently proposed method known deep knowledge tracing recurrent neural network trained predict student responses shown outperform best published results publicly available assistments data percentage points respect metric described section investigate dkt’s advantage traditional models compared standard parameter model extensions model three data sets realistic online prediction task typically required computerbased learning systems consistent evaluation task employed reproduce results assistments data proper accounting duplicate data negates claimed performance gains. larger data sets computational tractability hampered ability train ﬁne-grained content labels training irt-based models scaled handle them. moreover irt-based models’ best tractable performance matches outperforms dkt’s best tractable performance data sets hierarchical extension performing best cases. conclude data sets irt-based models provide simple better-performing alternatives also aﬀording interpretability guarantees formulation bayesian probabilistic models. estimating student proﬁciency important task computer based learning systems. compare family irtbased proﬁciency estimation methods deep knowledge tracing recently proposed recurrent neural network model promising initial results. evaluate well model predicts student’s future response given previous responses using publicly available proprietary data set. irt-based methods consistently matched outperformed across data sets ﬁnest level content granularity tractable trained hierarchical extension captured item grouping structure performed best overall. data sets included non-trivial autocorrelations student response patterns temporal extension improved performance standard rnnbased method not. conclude irt-based models provide simpler better-performing alternative existing rnn-based models student interaction data also aﬀording interpretability guarantees formulation bayesian probabilistic models. many situations including data sets assessment items structure inform predictions student responses. example groups items assess topic resulting item properties similar within groups across alternatively items derived common templates. templates often found math courses look like what particular instantiation generated choosing values example assistments data contains several problems many template many turn assess single skill. augment model incorporate knowledge item groups resulting hierarchical model item associated group whose diﬃculty distributed normally around per-group mean hirt assume student’s knowledge state remains constant time. however setting student acquiring knowledge period time extend model modeling stochastic process varying time adopt approach described modeling student’s knowledge wiener process section notation describe models compare. throughout represent student response data tuples indicating student item correctness time response. paper time indexed interaction index item response theory standard framework modeling student responses dating back single number called proﬁciency ability represents student’s knowledge state course completing several assessments. assumed proﬁciency changing examination. logistic function corresponds logistic regression factors response item indicators students items. variant model known link function cumulative distribution function standard normal distribution. maximum likelihood solution underdetermined take bayesian approach regularize solution imposing independent standard normal prior learning train parameters student response data maximize posterior probability given response data assuming independent standard normal priors posterior depth discussion review related literature especially chapter ogive yields nearly identical results commonly used logistic link function allows closed-form posterior computation temporal model described sec. example response predictions invariant adding constant oﬀset {θs}’s {βi}’s. response student held-out validation population predict response according temporal model given student’s previous responses described below. details validation procedure section recently recurrent neural network used predict student responses architectures seen enormous success applications wide range domains speech recognition natural language processing model input vectors representations whether student answered particular question correctly incorrectly previous time step output vectors representations probability questions question bank student question correct following time step. authors propose model hidden layer dimension fully connected input output layers well recurrently itself. model able capture temporal eﬀects remains ﬂexible enough describe non-trivial relationships items. learning parameter choices order make learning tractable reduced dimensionality input projecting lower dimensional space using random projection matrix done used batch gradient order test models used three data sets publicly accessible proprietary. data sets comes system students interact computer-based learning system variety educational settings data comes assistments product online platform engages students formative assessments replete scaﬀolded hints. assessments templated problem aligned several none skills product attempting teach. data divided parts skill builder associated formative assessment skill builder associated summative assessment. results reported skill builder data expect stronger temporal signal formative assessment summative assessment. also evaluation data preprocessing data associated items aligned skill designated dummy skill done chose discard rows duplicating single interaction step believe taken duplicate rows arise single interaction aligned multiple skills. without removing duplicates models process skills simultaneously including variants used paper student interaction several times essentially providing models figure summary results across models metrics. error bars represent standard error measure metric across folds. tirt parameter selection yielded assistments knewton. hirt parameter selection yielded assistments knewton. probability dropout models. access ground truth making predictions. artiﬁcially boost prediction results signiﬁcant amount duplicate rows account approximately rows. indeed observed performance gains negated duplicates removed note typical bkt-based approaches susceptible artiﬁcial boost since usually split data skill train separate models. pslc datashop released several data sets derived carnegie learning’s cognitive tutor algebra years used largest development data sets labeled bridge algebra distinct diﬀerence carnegie learning’s product assistments carnegie learning provides much ﬁner representations concepts assessed individual item. particular carnegie learning built around scaﬀolded formative assessment step student takes answer problem counted separate interaction step potentially assessing diﬀerent skills data set). note data collected variety educational products integrated knewton’s adaptive learning platform used various classroom settings across world. products vary respect educational content used well students guided content. example students take initial assessment remediated areas needing improvement. products students start beginning work toward predeﬁned goal teacher. settings knewton receives data interaction tuple section utilized approximately responses randomly sampled students questions spanning roughly months. students worked fewer questions total excluded. pre-processing student history lengths ranged responses. overall percent correct responses figure accuracy metrics three data sets computed using rolling window previous responses function window length. response accuracy computed predicting correct majority responses window correct. evaluation method call online response prediction matches students ﬁrst split training testing populations. model ﬁrst trained training population model parameters student-level frozen. time testing student’s history train report diﬀerent metrics comparing predicted correctness probabilities observed correctness values. accuracy computed percent responses correctness coincides probability greater area curve probability correctness response. table enumerates ﬁelds chosen data identify items item groups yielded computationally tractable model best results. note irt-based models validation scheme estimates single number student point validation.for computational reasons feasible evaluate ﬁne-grained labels knewton whereas variants able process data ﬁnest levels. trained validated three models three data sets described sec. results evaluation task summarized figure results clearly indicate simple irt-based models well signiﬁcantly better across data sets. fact hirt best-performing model across board suggests grouping structure useful information exploit predicting student responses. indeed hirt model access strictly information models item group identiﬁer associated interaction. model ability infer item relationships data results indicate building knowledge advantageous variety educational settings. potential area explore learning hierarchical model purely data could proﬁt structured bayesian framework without requiring prior information expert labels. temporal model yielded higher accuracy knewton dataset data sets. understand eﬀects investigated degree temporal structure data aﬀects predictive performance looking naive windowed percent correct model performs function window length knewton data clear optimal window length integrating windows short long degraded performance indicative nontrivial temporal structure. however assistments data sets longer window lengths perform equal better shorter window lengths suggesting static models would well cases. indeed would explain tirt less baseline assistments shows signiﬁcant improvement knewton data set. however explain lags regardless amount temporal structure. finally note results figure contradict assistments data reported believe data cleaning issues speciﬁcally issue removing duplicates artiﬁcially boost online prediction accuracy discussed section indeed able reproduce performance reported applying implementation data recent work points speciﬁc method computing also signiﬁcantly aﬀects reported performance relative bkt-based models further demonstrates bkt-based models perform well variety data sets. results indicate simple irt-based models equal outperform variety data sets suggesting incorporating domain knowledge structured bayesian models comprises promising area future research modeling student interaction data. experience structured models easier train required less parameter tuning dkt. moreover computational demands hampered ability fully explore parameter space found computation time memory load prohibitive training tens thousands items. issues could mitigated reducing dimensionality without significantly impairing performance. work discriminative models necessary bridge currently irt-based models seem superior terms performance ease making suitable candidates real-world applications promising avenue research could explore combining advantages structured bayesian models large-scale discriminative models provided superior performance several domains particularly large-data regime. crucial challenge structured models accommodate diversity educational settings data collected retaining structure drives predictive power interpretability. addressing assessment challenge online system tutors assesses. user modeling adaption personalization g.-j. houben mccalla pianesi zancanaro eds.", "year": 2016}