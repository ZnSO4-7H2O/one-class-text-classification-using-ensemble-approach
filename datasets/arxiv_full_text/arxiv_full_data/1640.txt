{"title": "Know-Evolve: Deep Temporal Reasoning for Dynamic Knowledge Graphs", "tag": ["cs.AI", "cs.CL", "cs.LG"], "abstract": "The availability of large scale event data with time stamps has given rise to dynamically evolving knowledge graphs that contain temporal information for each edge. Reasoning over time in such dynamic knowledge graphs is not yet well understood. To this end, we present Know-Evolve, a novel deep evolutionary knowledge network that learns non-linearly evolving entity representations over time. The occurrence of a fact (edge) is modeled as a multivariate point process whose intensity function is modulated by the score for that fact computed based on the learned entity embeddings. We demonstrate significantly improved performance over various relational learning approaches on two large scale real-world datasets. Further, our method effectively predicts occurrence or recurrence time of a fact which is novel compared to prior reasoning approaches in multi-relational setting.", "text": "rally evolving systems. instance gdelt icews popular event based data repository contains evolving knowledge entity interactions across globe. thus traditional knowledge graphs need augmented temporal knowledge graphs facts occur recur evolve time graphs edge graphs temporal information associated figure shows subgraph snapshot temporal knowledge graph. static knowledge graphs suffer incompleteness resulting limited reasoning ability. work static graphs therefore focussed advancing entity-relationship representation learning infer missing facts based available knowledge. methods lack ability rich temporal dynamics available underlying data represented temporal knowledge graphs. effectively capturing temporal dependencies across facts addition relational dependencies help improve understanding behavior entities contribute generation facts time. example precisely answer questions like object prediction. donald trump mention availability large scale event data time stamps given rise dynamically evolving knowledge graphs contain temporal information edge. reasoning time dynamic knowledge graphs well understood. present know-evolve novel deep evolutionary knowledge network learns non-linearly evolving entity representations time. occurrence fact modeled multivariate point process whose intensity function modulated score fact computed based learned entity embeddings. demonstrate signiﬁcantly improved performance various relational learning approaches large scale real-world datasets. further method effectively predicts occurrence recurrence time fact novel compared prior reasoning approaches multirelational setting. reasoning concept artiﬁcial intelligence. host applications search engines question-answering systems conversational dialogue systems social networks require reasoning underlying structured knowledge. effective representation learning knowledge come fore important task. particular knowledge graphs gained much attention important model studying complex multi-relational settings. traditionally knowledge graphs considered static snapshot multi-relational data. however recent availability large amount event based interaction data exhibits complex temporal dynamics addition multi-relational nature created need approaches characterize reason tempopeople change time relationships. entities forge relationship newly formed edge drives preferences behavior. change effected combination historical factors compatibility historical factors entity instance countries tense relationships likely engage conﬂicts. hand countries forging alliance likely take confrontational stands enemies other. finally time plays vital role process. country peaceful characteristics years future various facts occur period. able capture temporal evolutionary effects help reason better future relationship entity. term combined phenomenon evolving entities dynamically changing relationships time knowledge evolution. paper propose elegant framework model knowledge evolution reason complex non-linear interactions entities multi-relational setting. idea work model occurrence fact multidimensional temporal point process whose conditional intensity function modulated relationship score fact. relationship score depends dynamically evolving entity embeddings. speciﬁcally work makes following contributions propose novel deep learning architecture evolves time based availability facts. dynamically evolving network ingest incoming facts learn update embeddings involved entities based recent relationships temporal behavior. besides predicting occurrence fact architecture ability predict time fact potentially occur possible prior relational learning approaches best knowledge. model supports open world assumption missing links considered false potentially occur future. supports prediction unseen entities novel dynamic embedding process. large-scale experiments real world datasets show framework consistently signiﬁcantly better performance link prediction stateof-arts account temporal evolving non-linear dynamics. work aims introduce powerful mathematical tool temporal point process framework temporal reasoning dynamically evolving knowledge graphs. potential open research direction reasoning time various multi-relational settings underlying spatio-temporal dynamics. temporal point process random process whose realization consists list events localized time {ti} equivalently given temporal point process represented counting process records number events time important characterize temporal point processes conditional intensity function stochastic model time next event given previous events. formally conditional probability observing event small window given history {tk|tk i.e. typically assumes event happen small window size i.e. survival analysis theory given history characterize conditional probability event happens functional form intensity often designed capture phenomena interests. common forms include poisson process hawkes processes self-correcting process power rayleigh process. rayleigh process non-monotonic process welladapted modeling fads event likelihood drops rapidly rising peak. intensity function weight parameter survival function temporal knowledge graph representation deﬁne temporal knowledge graph multirelational directed graph timestamped edges pair nodes. edge nodes represent event real world edge type represent corresponding event type. edge available multiple times allow duplicate edges self-loops graph. hence recurrent edges different time points every edge distinct subject object entities. represents creation relationship edge subject entity object entity time complete therefore represented dimensional tensor total number available time points. consider comprising edges denote globally ordered corresponding observed events {n}n evolutionary knowledge network present uniﬁed knowledge evolution framework reasoning temporal knowledge graphs. reasoning power know-evolve stems following three major components novel deep recurrent network learns non-linearly mutually evolving latent representations entities based interactions entities multirelational space time. large scale temporal knowledge graphs exhibit highly heterogeneous temporal patterns events entities. discrete epoch based methods model temporal behavior fail capture underlying intricate temporal dependencies. therefore model time random variable temporal point process model occurrence fact. concretely given observed events corresponding construct relationship-modulated multidimensional point process model occurrence events. characterize point process following conditional intensity function time current event recent time point either subject object entity involved event time represents intensity event involving thus λeseo triplet time given previous time point either involved event. modulates intensity current event based recent activity either entities’ timeline allows capture scenarios like non-periodic events previously unseen events. ensures intensity positive well deﬁned. relational score function ﬁrst term modulates intensity function relational compatibility score involved enti represent latent feature embeddings entities appearing subject object position respectively. rd×d represents relationship weight matrix attempts capture interaction entities speciﬁc relationship space matrix unique relation dataset learned training. time current event represent time point time therefore represent recently updated vector embeddings subject object entities respectively time entity embeddings evolve update time geseo able capture cumulative knowledge learned entities history events affected embeddings. represent latent feature embedding entity time low-dimensional vector superscript shown indicate embedding corresponds entity subject object position respectively. also relationship-speciﬁc low-dimensional representation relation type. latent representations entities change time entities forge relationships other. design novel deep recurrent neural network based update functions capture mutually evolving nonlinear dynamics entities vector space representations. consider event occurring time also consider event entity es’s p-th event entity eo’s q-th event. entities participate events heterogeneous pattern less likely although impossible. observed event update embeddings involved entities follows subject embedding figure realization evolutionary knowledge network architecture timeline. consecutive time points. focus event time point show previous events affected embeddings entities involved event. prev represent previous time points history hother respectively. stands hidden layer entities involved events prev notations mean exactly deﬁned text. label nodes edges embeddings directly relevant event time clarity. involved. timepoint time hence represents latest embedding entity updated event entity. represents latest embedding entity updated time accounts fact entity involved event interval current previous event represent relationship embedding entity corresponds relationship type event entity note relationship vectors static hidden evolve time. layer. semantics notations apply similarly object embedding update rd×l weight parameters network learned training. captures variation temporal drift subject object respectively. shared parameter captures recurrent participation effect entity. shared projection matrix applied consider compatibility entities previous relationships. represent simple concatenation operator. denotes nonlinear activation function formulations simple units replaced expressive units like lstm straightforward manner. experiments choose chosen differently. explain rationales deep recurrent architecture captures nonlinear evolutionary dynamics entities time. reasoning based structural dependency hidden layer reasons event capturing compatibility recent subject embedding recent object embedding previous relationship subject entity. accounts behavior within short period time entities tend form relationships entities similar recent actions goals. layer thereby uses historical information nodes involved current event edges created event. holds symmetrically hidden layer reasoning based temporal dependency recurrent layer uses hidden layer information model intertwined evolution entity embeddings time. speciﬁcally layer main components drift time ﬁrst term captures temporal difference consecutive events respective dimension entity. captures external inﬂuences entities experienced events allows smoothly drift features time. term contribute anything case multiple events happen entity time point exhibit high variation corresponding weight parameter capture variations along second recurrent term prevent relation-speciﬁc mutual evolution latent features subject object entities inﬂuence other. multi-relational setting affected relationship form. recurrent update entity embedding information hidden layer allows capture intricate non-linear evolutionary dynamics entity respect entity speciﬁc relationship space. updates entity representations driven events involving entities makes embeddings piecewise constant i.e. entity embedding remains unchanged duration events involving entity updates event happens dimension. justiﬁable entity’s features update forges relationship entity within graph. note ﬁrst term already accounts external inﬂuences. observed event time know-evolve considers incoming fact brings knowledge entities involved event. computes intensity event based relational compatibility score recent latent embeddings involved entities. embeddings piecewise constant time interval term make overall intensity piecewise linear standard mathematical choice efﬁcient computation point process framework. formulation naturally leads rayleigh distribution models time interval current event recent event either entities’ dimension. rayleigh distribution added beneﬁt simple analytic form likelihood used entity likelihood reaches maximum value thereby make precise entity predictions. efﬁcient training procedure complete parameter space model {{ve}e=ne {rr}r=nr wr}. although know-evolve gains expressive power deep architecture table shows memory footprint model comparable simpler relational models. intensity function allows maximum likelihood estimation facts objective function. concretely given collection facts recorded temporal window learn model minimizing joint negative likelihood intensity function written ﬁrst term maximizes probability speciﬁc type event entities; second term penalizes non-presence possible types events possible entity pairs given observation window. back propagation time algorithm train model. previous techniques bptt algorithm decompose data independent sequences train mini-batches sequences. exists intricate relational temporal dependencies data points setting limits ability efﬁciently train decomposing events independent sequences. address challenge design efﬁcient global bptt algorithm creates mini-batches events global timeline sliding window fashion allows capture dependencies across batches retaining efﬁciency. intractable survival term. compute second survival term since intensity function modulated relation-speciﬁc parameter relationship need compute survival probability pairs entities. next given relation entity pair denote total number events type involving either window intensity function piecewise-linear decompose integration term multiple time intervals inalso unnecessary. knowledge tensors inherently sparse hence plausible approximate survival loss stochastic setting. take inspiration techniques like noise contrastive estimation adopt random sampling strategy compute survival loss given mini-batch events relation mini-batch compute dyadic survival term across entities batch. algorithm presents survival loss computation procedure. procedure randomly avoid penalizing dimensions relationship still includes dimensions events them. computational complexity procedure orm) size mini-batch represent number entities relations mini-batch. experiments temporal knowledge graph data datasets global database events language tone integrated crisis early warning system recently gained attention learning community useful temporal kgs. gdelt data collected april icews dataset collected datasets contain records events include actors action type timestamp event. different hierarchy actions datasets test variety knowledge tensor conﬁgurations. note ﬁlter record dataset. process datasets remove duplicate quadruples mono-actor events self-loops. report main results full versions dataset. create smaller version datasets exploration purposes. table provide statistics data table demonstrates sparsity knowledge tensor. compare performance method following relational learning methods rescal neural tensor network multiway neural network transe transr. best knowledge existing relational learning approaches predict time fact. hence devised baseline methods evaluating time prediction performance multi-dimensional hawkes process model dyadic entity interactions multi-dimensional hawkes process similar here entity pair constitutes dimension pair collect sequence events dimension train test sequence. relationship modeled setup. recurrent temporal point process implement simpliﬁed version rmtpp predict marker. training concatenate static entity relationship embeddings augment resulting vector temporal feature. augmented unit used input global produces output vector test time given triplet vector compute conditional intensity event given history used predict next event time. appendix provides implementation details method competitors. report experimental results tasks link prediction time prediction. link prediction given test quadruplet replace entities dataset compute conditional density deseo resulting quadruplets including ground truth. sort quadruplets descending order density rank correct entity object position. also conduct testing applying ﬁltering techniques described rank entities generate true triplet replaces ground truth object. report mean absolute rank standard deviation hits filtered versions. time prediction give test triplet predict expected value next time fact occur. expectation deﬁned eeseo computed using equation report mean absolute error predicted time true time hours. sliding window evaluation. work concentrates temporal knowledge graphs interesting performance methods time span test compared single rank value. evaluation method help realize effect modeling temporal evolutionary knowledge. therefore partition test different slides report results window. datasets slide included weeks time. quantitative analysis link prediction results. figure demonstrate link prediction performance comparison datasets. know-evolve signiﬁcantly consistently outperforms competitors terms prediction rank without deterioration time. neural tensor network’s second best performance compared baselines demonstrate rich expressive power fails capture evolving dynamics intricate dependencies time. substantiated decreasing performance move test window time. second represents deviation error across samples given test window. method achieves significantly deviation error compared competitors making stable. finally high performance hits metric demonstrates extensive discriminative ability knowevolve. instance gdelt relations events many entities interact multiple relationships. complex setting methods depend static entity embeddings perform prediction unlike method effectively infers knowledge using powerful evolutionary network provides accurate prediction results. time prediction results. figure demonstrates know-evolve performs signiﬁcantly better point process based methods predicting time. uses speciﬁc parametric form intensity function limits expressiveness. further entity pair interaction modeled independent dimension take account relational feature fails capture intricate inﬂuence different entities other. hand rtpp uses relational features part input sees events globally cannot model intricate evolutionary dependencies past events. observe method effectively captures non-linear relational temporal dynamics. addition superior quantitative performance demonstrate effectiveness method providing extensive exploratory analysis appendix related work section discuss relevant works relational learning temporal modeling techniques. among various relational learning techniques neural embedding models focus learning low-dimensional representations entities relations shown stateof-the-art performance. methods compute score fact based different operations latent representations. models mainly categorized variants compositional models. rescal uses relation speciﬁc weight matrix explain triplets pairwise interactions latent features. neural tensor network expressive model combines standard layer bilinear tensor layer. employs concatenationprojection method project entities relations lower dimensional space. sophisticated models include holographic embeddings employs circular correlation entity embeddings neural association models deep network used probabilistic reasoning. translation based models. uses relation-speciﬁc matrices project subject object entities computes distance score fact entity vectors. proposed transe model computes score distance relation-speciﬁc translations entity embeddings. improved transe allowing entities distributed representations relation speciﬁc hyperplane distance contains comprehensive reviews empirical comparison relational learning techniques respectively. methods consider knowledge graphs static models lack ability capture temporally evolving dynamics. temporal point processes shown effective tool model various intricate temporal behaviors networks recently proposed novel co-evolutionary feature embedding process captures self-evolution co-evolution dynamics users items interacting recommendation system. relational setting proposed relational mining approach discover changes structure dynamic network time. proposes method capture temporal autocorrelation data improve predictive performance. proposes summarization techniques model evolving relational-temporal domains. recently proposed multiway neural network architecture modeling event based relational graph. authors draw synergistic relation static knowledge graph event wherein knowledge graph provide information entities participating events events turn contribute enhancement knowledge graph. capture evolving dynamics entities model time discrete points limits capacity model complex temporal dynamics. models dependence relationship time facilitate time-aware link prediction capture evolving entity dynamics. propose novel deep evolutionary knowledge network efﬁciently learns non-linearly evolving entity representations time multi-relational setting. evolutionary dynamics subject object entities captured deep recurrent architecture models historical evolution entity embeddings speciﬁc relationship space. occurrence fact modeled multivariate point process captures temporal dependencies across facts. superior performance high scalability method large real-world temporal knowledge graphs demonstrate importance supporting temporal reasoning dynamically evolving relational systems. work establishes previously unexplored connection relational processes temporal point processes potential open direction research reasoning time. project supported part iis- bigdata career iis- eager nvidia intel amazon aws. references aalen borgan ornulf gjessing hakon. survival event history analysis process point view. springer bordes antoine weston jason collobert ronan bengio yoshua. learning structured embeddings knowledge bases. conference artiﬁcial intelligence number epfl-conf- bordes antoine usunier nicolas garcia-duran alberto weston jason yakhnenko oksana. translating embeddings modeling multi-relational data. advances neural information processing systems d.r. lewis p.a.w. multivariate point processes. selected statistical papers david volume design investigations statistical methods applications dong gabrilovich evgeniy heitz geremy horn wilko murphy kevin strohmann thomas shaohua zhang wei. knowledge vault web-scale approach probabilistic knowledge fusion. proceedings sigkdd international conference knowledge discovery data mining hanjun trivedi rakshit upadhyay utkarsh gomez-rodriguez manuel song recurrent marked temporal point processes embedding event history vector. esteban cristobal tresp volker yang yinchong baier stephan krompa denis. predicting co-evolution event knowledge graphs. international conference information fusion farajtabar mehrdad wang yichen gomez-rodriguez manuel shuang hongyuan song coevolve joint point process model information diffusion network co-evolution. nips gutmann michael hyv¨arinen aapo. noisecontrastive estimation unnormalized statistical models applications natural image statistics. journal machine learning research loglisci corrado malerba donato. leveraging temporal autocorrelation historical data improving accuracy network regression. statistical analysis data mining data science journal nickel maximilian tresp volker kriegel hanspeter. three-way model collective learning multirelational data. proceedings international conference machine learning schein aaron zhou mingyuan blei david wallach hanna. bayesian poisson tucker decomposition learning structure international relations. arxiv. socher richard chen danqi manning christopher andrew. reasoning neural tensor networks knowledge base completion. advances neural information processing systems wang yichen theodorou evangelos verma apurv song stochastic differential equation framework guiding online user activities closed loop. arxiv preprint arxiv. mentioned section main paper intricate relational temporal dependencies data points setting limits ability efﬁciently train decomposing events independent sequences. address challenge design efﬁcient global bptt algorithm presented below. step training build computational graph using consecutive events sliding window ﬁxed size. move sliding window train till timeline similar fashion allows capture dependencies across batches retaining efﬁciency. implementation details know-evolve. algorithm algorithm demonstrate computational graph mini-batch signiﬁcantly different high variations interactions happening window. facilitate efﬁcient training dynamic computational graph setting leverage graph embedding framework proposed allows learn graph structure objective function potentially different computational graph batch. adam optimizer gradient clipping making parameter updates. using grid search method across hyper-parameters mini-batch size weight scale learning rate datasets. used zero initialization entity embeddings reasonable choice dynamically evolving entities. competitors. implemented reported baselines tensorﬂow evaluated methods uniformly. method grid search hyper-parameters embedding size chose ones providing best performance respective methods. baseline methods trained using contrastive max-margin objective function described adagrad optimization provided tensorﬂow optimizing objective function. randomly initialize entity embeddings typically done models. report dimensionality embeddings resulting number parameters various models. table illustrates know-evolve signiﬁcantly efﬁcient number parameters compared neural tensor network highly expressive demonstrated prediction performance section main paper. overall number parameters different dataset conﬁgurations comparable simpler relational models order magnitude. table comparison method various relational methods memory complexity. last columns provide example realizations complexity full versions gdelt icews datasets. correspond hidden layers used respective methods.he correspond entity relation embedding dimensions respectively. number entities relations dataset. gdelt icews borrow notations simplicity. shown model achieve high accuracy predicting future event triplet time event. here present case studies demonstrate ability evolutionary knowledge network perform superior reasoning across multiple relationships knowledge graphs. concentrate prediction quadruplet available test set. event relates news report assault croation prisoner cairo july model gives rank- object entity croatia baselines predict well ﬁrst consider relationship characteristics cairo croatia. current train span nodes cairo involved relationship subject croatia involved relationship object subject cairo involved assault relationship times object croatia involved assault times. mentioned earlier direct edge present cairo croatia relationship type assault. conventional reasoning methods consider static interactions entities speciﬁc relationship space fail account temporal effect certain relationships dynamic evolution entity embeddings. believe method able capture multi-faceted knowledge helps reason better competitors case. temporal effect. observed dataset many entities involved negative relationships last month training data compared earlier months year. further assault activities foreign prisoners reported cairo starting model successfully captures increased intensity events recent past. interesting observation overall cairo involved much higher number positive relationships compared negative ones would lead conventional baselines path reason entity instead model tries capture effect recent events. dynamic knowledge evolution. seen dataset cairo associated negative events towards year compared start year mostly involved positive cooperation relationships. prominent case croatia still showed change type relationships time. multiple instances cairo involved negative relationship node turn positive relationship croatia. signiﬁes features entities jointly non-linearly evolving features third entity different relationship spaces. concentrate prediction quadruplet available test set. event relates news report concerns military deal colombia canada july reported ottawa citizen. model gives rank- object entity ottawa baselines predict well test event relationship never seen training. relationship characteristics before consider current train colombia ottawa. nodes colombia span involved relationship node subject hand ottawa involved relationship nodes object total events). subject colombia involved cooperation relationship times object ottawa involved cooperation times. temporal effect. observed dataset colombia involved hundreds relationships venezuela relationships range across spectrum negative ﬁght positive engagement material cooperation. recently training countries mostly involved positive relationships. venezuela turn cooperation relationship ottawa thus inferred colombia affected recent interaction neighbors forming relationship canada. dynamic knowledge evolution. overall observed colombia involved positive relationships towards training period compared start. attributed events like economic growth better living standards better relations getting developed evolution colombia’s features positive direction. features ottawa continued evolve positive direction involved less negative relationships. interesting events exemplifying mutual evolution also observed. cases relationship colombia third entity negative following relationship time third entity forged positive relationship ottawa infer colombia’s strategic interest forge cooperation ottawa counter relationship third entity. provide reference links actual event news related edges figure predicted edge. unlike competitors entity embeddings model updated every event test model parameters remain unchanged training. balance advantage give method explore sliding window training paradigm baselines train ﬁrst months dataset evaluate ﬁrst test window. next throw away many days start train found test incorporate test data training. retrain model using previously learned parameters warm start. effectively baselines adapt evolving knowledge time. figure shows sliding window training contributes stable performance baselines across time window overall performance method still surpasses competitors. fundamental distinction multi-relational setting existence recurrence relations case traditional knowledge graphs. compare method best performing competitor different testing setups recurrent facts test facts test set. perform experiment gdelt- data. call test fact never seen training. expect proportion facts increase move time. case ranges total number events speciﬁc test window. figure demonstrates method performs consistently signiﬁcantly better cases.", "year": 2017}