{"title": "Maximin affinity learning of image segmentation", "tag": ["cs.CV", "cs.AI", "cs.LG", "cs.NE"], "abstract": "Images can be segmented by first using a classifier to predict an affinity graph that reflects the degree to which image pixels must be grouped together and then partitioning the graph to yield a segmentation. Machine learning has been applied to the affinity classifier to produce affinity graphs that are good in the sense of minimizing edge misclassification rates. However, this error measure is only indirectly related to the quality of segmentations produced by ultimately partitioning the affinity graph. We present the first machine learning algorithm for training a classifier to produce affinity graphs that are good in the sense of producing segmentations that directly minimize the Rand index, a well known segmentation performance measure. The Rand index measures segmentation performance by quantifying the classification of the connectivity of image pixel pairs after segmentation. By using the simple graph partitioning algorithm of finding the connected components of the thresholded affinity graph, we are able to train an affinity classifier to directly minimize the Rand index of segmentations resulting from the graph partitioning. Our learning algorithm corresponds to the learning of maximin affinities between image pixel pairs, which are predictive of the pixel-pair connectivity.", "text": "images segmented ﬁrst using classiﬁer predict afﬁnity graph reﬂects degree image pixels must grouped together partitioning graph yield segmentation. machine learning applied afﬁnity classiﬁer produce afﬁnity graphs good sense minimizing edge misclassiﬁcation rates. however error measure indirectly related quality segmentations produced ultimately partitioning afﬁnity graph. present ﬁrst machine learning algorithm training classiﬁer produce afﬁnity graphs good sense producing segmentations directly minimize rand index well known segmentation performance measure. rand index measures segmentation performance quantifying classiﬁcation connectivity image pixel pairs segmentation. using simple graph partitioning algorithm ﬁnding connected components thresholded afﬁnity graph able train afﬁnity classiﬁer directly minimize rand index segmentations resulting graph partitioning. learning algorithm corresponds learning maximin afﬁnities image pixel pairs predictive pixel-pair connectivity. supervised learning emerged serious contender ﬁeld image segmentation ever since creation training sets images ground truth segmentations provided humans berkeley segmentation dataset supervised learning requires parametrized algorithm images segmentations objective function quantiﬁes performance segmentation algorithm relative ground truth means searching parameter space segmentation algorithm optimum objective function. supervised learning method presented here segmentation algorithm consists parametrized classiﬁer predicts weights nearest neighbor afﬁnity graph image pixels followed graph partitioner thresholds afﬁnity graph ﬁnds connected components. objective function rand index recently proposed quantitative measure segmentation performance soften thresholding classiﬁer output adjust parameters classiﬁer gradient learning based rand index. figure segmentation algorithm. ﬁrst generate nearest neighbor weighted afﬁnity graph representing degree nearest neighbor pixels grouped together. segmentation generated ﬁnding connected components thresholded afﬁnity graph. afﬁnity misclassiﬁcation rates poor measure segmentation performance. afﬁnity graph makes error results poor segmentations graph generates perfect segmentation despite making many afﬁnity misclassiﬁcations maximin edges afﬁnity graph play role learning method call maximin afﬁnity learning image segmentation malis. minimax path edge standard concepts graph theory maximin opposite-sign sibling minimax. hence work viewed machine learning application graph theoretic concepts. malis focuses improving classiﬁer output maximin edges classifying edges incorrectly leads genuine segmentation errors splitting merging segments. best knowledge malis ﬁrst supervised learning method based optimizing genuine measure segmentation performance. idea training classiﬁer predict weights afﬁnity graph novel. afﬁnity classiﬁers previously trained minimize number misclassiﬁed afﬁnity edges optimizing segmentations produced partitioning afﬁnity graph. attempts train afﬁnity classiﬁers produce good segmentations partitioned normalized cuts approaches optimize genuine measure segmentation performance rand index. work bach jordan closest work. however minimize upper bound renormalized version rand index. approaches require many approximations make learning tractable. related work classiﬁers trained optimize performance detecting image pixels belong object boundaries classiﬁer also viewed boundary detector since nearest neighbor afﬁnity graph essentially boundary sign inversion. however combine classiﬁer graph partitioner produce segmentations. classiﬁer parameters trained optimize performance boundary detection optimize performance segmentation measured rand index. also methods supervised learning image labeling using markov conditional random ﬁelds image labeling similar multi-class pixel classiﬁcation rather image segmentation latter task require distinguishing multiple objects single image label. cases probabilistic random ﬁeld models used image parsing segmentation models either simplistic tractability reasons trained piecemeal. instance separately train low-level discriminative modules based boosting classiﬁer train high-level modules algorithm model joint distribution image labeling. models never trained minimize rand index. class segmentation algorithms constructed combining classiﬁer graph partitioner classiﬁer used generate weights afﬁnity graph. nodes graph image pixels edges nearest neighbor pairs pixels. weights edges called afﬁnities. high afﬁnity means pixels tend belong graph partitioner ﬁrst thresholds afﬁnity graph removing edges weights less threshold value connected components thresholded afﬁnity graph segments image. class segmentation algorithms it’s obvious single misclassiﬁed edge afﬁnity graph dramatically alter resulting segmentation splitting merging segments important learn optimizing measure segmentation performance rather afﬁnity prediction. well aware connected components exceedingly simple method graph partitioning. sophisticated algorithms spectral clustering graph cuts might robust misclassiﬁcations edges afﬁnity graph. instead? replies question. first simplicity graph partitioning derive simple direct method supervised learning optimizes true measure image segmentation performance. learning based sophisticated graph partitioning methods fallen short goal second even possible properly learn afﬁnities used sophisticated graph partitioning methods would still prefer simple connected components. classiﬁer segmentation algorithm also carry sophisticated computations representational power sufﬁciently great. putting sophistication classiﬁer advantage making learnable rather hand-designed. sophisticated partitioning methods clean afﬁnity graph using prior assumptions properties image segmentations. prior assumptions could incorrect. spirit machine learning approach large amount training data minimize prior assumptions. sophisticated partitioning methods indeed best achieving good segmentation performance suspect classiﬁer learn training data. best hope classiﬁer even better. image segmentation viewed special case general problem clustering image segments clusters image pixels. long rand proposed index similarity clusterings recently proposed rand index applied image segmentations deﬁne segmentation assignment segment label pixel indicator function pixels belong segment otherwise. given segmentations image pixels deﬁne function fraction image pixel pairs segmentations disagree. refer function rand index although strictly speaking rand index fraction image pixel pairs segmentations agree. words rand index measure similarity often apply term measure dissimilarity. paper rand index applied compare output segmentation algorithm ground truth segmentation serve objective function learning. figure illustrates rand index sensible measure segmentation performance. segmentation afﬁnity graph incurs huge rand index penalty relative ground truth. single wrongly classiﬁed edge afﬁnity graph leads incorrect merger segments causing many pairs image pixels wrongly assigned segment. hand segmentation corresponding afﬁnity graph perfect rand index even though misclassiﬁcations afﬁnity graph. short rand index makes sense strongly penalizes errors afﬁnity graph lead split merger errors. figure rand index quantiﬁes segmentation performance comparing difference pixel pair connectivity groundtruth test segmentations. pixel pair connectivities visualized symmetric binary block-diagonal matrices diagonal block corresponds connected pixel pairs belonging image segments. rand index incurs penalties pixels pairs must connected connected vice versa. corresponds locations matrices disagree. erroneous merger groundtruth segments incurs penalty proportional product sizes segments. split errors similarly penalized. recall segmentation algorithm works ﬁnding connected components thresholded afﬁnity graph. segmentation produced way. apply rand index train classiﬁer need simple relating indicator function rand index classiﬁer output. words would like characterizing whether pixels connected thresholded afﬁnity graph. this introduce concept maximin afﬁnity deﬁned pair pixels afﬁnity graph aklbe afﬁnity pixels paths graph connect pixels every path edge minimal afﬁnity. written minkl∈p means edge pixels path maximin path proof. deﬁnition pixel pair connected thresholded afﬁnity graph exists path them. path equivalent path unthresholded afﬁnity graph minimal afﬁnity threshold value. path turn exists maximin afﬁnity threshold value. consequence theorem pixel pairs classiﬁed connected disconnected thresholding maximin afﬁnities. segmentation produced thresholding afﬁnity graph ﬁnding connected components. connectivity indicator function heaviside step function. maximin afﬁnities computed efﬁciently using minimum spanning tree algorithms maximum spanning tree equivalent minimum spanning tree sign change weights. path maximum spanning tree maximin path. nearest neighbor afﬁnity graphs maximin afﬁnity pixel pair computed number graph edges number pixels inverse ackerman function grows computed time since computation sub-logarithmically. full matrix shared. note maximin afﬁnities required training testing. segmenting image test time connected components computation need performed takes time linear number edges |e|. since discontinuous function maximin afﬁnities make usual relaxation replacing hinge loss used standard loss square loss thus obtain cost function suitable gradient learning operations continuous differentiable loss function smooth afﬁnity smooth function gradient cost function well-deﬁned gradient descent used optimization method. deﬁne maximin edge pixel pair choose maximin edges random. cost function takes form nearest neighbor pixel pairs number nearest neighbors contrast malis cost function pairs pixels whether adjacent afﬁnity graph. note single edge maximin edge multiple pairs pixels afﬁnity appear multiple times malis cost function. roughly speaking malis cost function similar standard cost function except edge afﬁnity graph weighted number pixel pairs causes incorrectly classiﬁed. computing cost function gradient requires ﬁnding maximin edges pixel pairs. batch computation could used gradient learning. however online stochastic gradient comparison also show standard afﬁnity learning iteration learning methods pick random pair pixels random image. compute gradient weight single edge afﬁnity graph. however standard method picks nearest neighbor pixel pair trains afﬁnity edge them. maximin method picks pixel pair arbitrary separation trains minimal afﬁnity maximin path them. effectively connected components performs spatial integration nearest neighbor afﬁnity graph make connectivity decisions pixel pairs large distances. malis trains global decisions standard afﬁnity learning trains local decisions. malis superior truly learns segmentation superiority comes price. maximin computation requires iteration afﬁnity graph computed whole image. therefore slower standard learning method requires local afﬁnity prediction edge trained. thus computational price paid optimization true segmentation error. imaging brain tissue sufﬁciently high resolution well identifying synapses tracing axons dendrites images possible principle reconstruct connectomes complete wiring diagrams brain piece brain axons narrower diameter necessitating electron microscopy high spatial resolution cubic millimeter brain tissue yields teravoxel scale image sizes. recent advances automation making possible collect images image analysis remains challenge. tracing axons dendrites large-scale image segmentation problem requiring high accuracy. images used study inner plexiform layer rabbit retina taken using serial block-face scanning electron microscopy large image volumes voxels hand segmented reserved training testing purposes. classiﬁer smooth function parameters used maximin afﬁnity learning. used convolutional networks method restricted choice. convolutional networks previously shown effective similar images brain tissue trained identical four-layer standard afﬁnity learning second malis. contained feature maps layer sigmoid nonlinearities. ﬁlters size. afﬁnity classiﬁer uses cubic image patch classify afﬁnity edge. used square-square loss function margin noted earlier maximin afﬁnity learning signiﬁcantly slower standard afﬁnity learning need computing entire afﬁnity graph iteration standard afﬁnity training need predict weight single edge graph. reason constructed proxy training image dataset picking possible sized overlapping sub-images original training set. since sub-image smaller original image size afﬁnity graph needed predicted sub-image signiﬁcantly smaller leading faster training. consequence approximation maximum separation image pixel pairs chosen training less pixels. second means speeding maximin procedure pretraining maximin iterations using fast standard afﬁnity classiﬁcation cost function. trained total iterations point training error plateaued. figure quantiﬁcation segmentation performance electron microscopic images neural tissue. clustering accuracy measuring number correctly classiﬁed pixel pairs. curve precision-recall quantiﬁcation pixel-pair connectivity classiﬁcation shows near perfect performance. segmentation error measured number splits mergers. benchmarked performance standard maximin afﬁnity classiﬁers measuring pixel-pair connectivity classiﬁcation performance using rand index. training standard malis afﬁnity classiﬁers generated afﬁnity graphs training test images. principle training algorithm suggests single threshold graph partitioning. practice generate full spectrum segmentations leading over-segmentations under-segmentations varying threshold parameter. fig. plot rand index segmentations resulting range threshold values. images large numbers segments pixel pairs disconnected another leading large imbalancing number connected disconnected pixel pairs. reﬂected fact rand index segmentation algorithms. imbalance positive negative examples signiﬁcant problem training afﬁnity classiﬁer make comparisons classiﬁers difﬁcult interpret. instead precision-recall methodologies provide accurate quantiﬁcation accuracy classiﬁers even presence large class imbalance. curves observe maximin afﬁnity classiﬁer dramatically outperforms standard afﬁnity classiﬁer. positive results intriguing interpretation. poor performance connected components applied standard learned afﬁnity classiﬁer could interpreted imply local classiﬁer lacks context important good afﬁnity prediction; connected components poor strategy image segmentation since mistakes afﬁnity prediction edges merge split segments. contrary experiments suggest trained properly thresholded afﬁnity classiﬁcation followed connected components extremely competitive method image segmentations. paper trained afﬁnity classiﬁer produce afﬁnity graphs result excellent segmentations partitioned simple graph partitioning algorithm thresholding followed connected components. good performance training segmentation-based cost function powerful trainable classiﬁer predict afﬁnity graphs. trained segmentation algorithm fast. contrast classic graph-based segmentation algorithms figure cross-section segmentation test image. maximin segmentation correctly segments several objects merged standard segmentation even correctly segments objects missing groundtruth segmentation. segments merged standard segmentation merged locations visible cross section. pixels colored black machine segmentations correspond pixels completely disconnected neighbors represent boundary regions. partitioning phase dominates partitioning algorithm simple partition graphs time linearly proportional number edges graph. also require prior knowledge number image segments image segment sizes test time contrast graph partitioning algorithms formalism maximin afﬁnities used derive learning algorithm connections singlelinkage hierarchical clustering minimum spanning trees ultrametric distances. felzenszwalb huttenlocher describe graph partitioning algorithm based minimum spanning tree computation resembles segmentation algorithm part. ultrametric contour algorithm generates hierarchical segmentations nearly identical generated varying threshold graph partitioning algorithm. neither methods incorporates means learning labeled data work shows performance algorithms improved maximin afﬁnity learning.", "year": 2009}