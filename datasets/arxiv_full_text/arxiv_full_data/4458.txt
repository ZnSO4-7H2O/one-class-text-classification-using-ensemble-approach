{"title": "Deformable Classifiers", "tag": ["stat.ML", "cs.CV"], "abstract": "Geometric variations of objects, which do not modify the object class, pose a major challenge for object recognition. These variations could be rigid as well as non-rigid transformations. In this paper, we design a framework for training deformable classifiers, where latent transformation variables are introduced, and a transformation of the object image to a reference instantiation is computed in terms of the classifier output, separately for each class. The classifier outputs for each class, after transformation, are compared to yield the final decision. As a by-product of the classification this yields a transformation of the input object to a reference pose, which can be used for downstream tasks such as the computation of object support. We apply a two-step training mechanism for our framework, which alternates between optimizing over the latent transformation variables and the classifier parameters to minimize the loss function. We show that multilayer perceptrons, also known as deep networks, are well suited for this approach and achieve state of the art results on the rotated MNIST and the Google Earth dataset, and produce competitive results on MNIST and CIFAR-10 when training on smaller subsets of training data.", "text": "geometric variations objects modify object class pose major challenge object recognition. variations could rigid well non-rigid transformations. paper design framework training deformable classiﬁers latent transformation variables introduced transformation object image reference instantiation computed terms classiﬁer output separately class. classiﬁer outputs class transformation compared yield ﬁnal decision. by-product classiﬁcation yields transformation input object reference pose used downstream tasks computation object support. apply two-step training mechanism framework alternates optimizing latent transformation variables classiﬁer parameters minimize loss function. show multilayer perceptrons also known deep networks well suited approach achieve state results rotated mnist google earth dataset produce competitive results mnist cifar- training smaller subsets training data. grenander pioneered idea handling challenge geometric variability objects images generative framework using deformable templates variability population images modeled deformations applied prototype template. deformations explicitly parameterized represented latent unobserved random variables. statistical framework yields cost function measures distance deformed template data. typically form squares likelihood based measure usually assuming conditional independence pixel observation given latent variable. interrelated challenges given template compute deformation conditional image estimate template sample images. ﬁrst problem studied extensively wide variety contexts example problem template estimation received attention paper extend ideas domain generative models discriminative models. given classiﬁer compute class image deformation yielding optimal output class label image class highest output. words instead distance template class image framework uses cost function based class scores computed classiﬁer. furthermore given samples images diﬀerent classes train classiﬁer iterating following steps ﬁrst optimal deformation image diﬀerent classes given current parameters classiﬁer update parameters classiﬁer given optimal deformations training images class. since easily formulated using gradient descent type optimization need classiﬁers deformable respect parameters resect input. multilayer perceptrons also known deep networks natural choice. deep networks successful recent years wide range classiﬁcation detection tasks. expressiveness networks allows models explore possible variations data learn visual representations robust task-irrelevant variations. however variations need observed data training networks without special design networks generalize unobserved variations data. standard solution improving transformation-invariance classiﬁers data augmentation transformed versions original data generated added original data approach works well believe interest explore alternative explicit computation latent deformations performed classiﬁcation. theory means classiﬁer need ﬂexible since directly trying discriminate many diﬀerent instantiations classes rather needs learn discriminate images objects reference instantiation. furthermore obtaining reference pose object part output classiﬁcation assist additional visual tasks. task determining support object image. spatial transformer networks also transform image part classiﬁcation process. remove extraneous transformation variability priori introducing spatial transformation module classiﬁcation network. image data ﬁrst transformed reference instantiation independent class passed classiﬁed. information network uses ﬁrst transform image independent class therefore necessarily generic. believe essentially computed based ﬁrst second order statistics pixel data show sensitive clutter. however interest transformation network subsequent classiﬁcation network trained together using gradient descent. approaches transformation invariance explicitly transform network ﬁlters feature maps invariant selected types transformations another family approaches tries generalize convolutional architectures either extending feature space group space transformations warping input transformation equivariance implicitly encoded approaches either limited small transformations need keep models shallow high computational burden required consider additional transformations feature map. framework latent variables introduced separately class capture transformations data apply two-step training mechanism alternatively optimize latent variables neural network model parameters minimize designed loss function. emphasize latent variables optimized class separately. consequently unlike produces single transformed version original input produce transformed version class. transformation predicted directly data rather class estimated optimize output unit representing class. show framework applied existing neural network architecture oﬀers ﬂexibility types transformation considered model. apply framework training convolutional neural networks present competitive results mnist mnist-rot cifar- google earth dataset. addition improved classiﬁcation rates show estimated latent transformations indeed align images well allow estimate precise object supports case mnist correct object rotation case google earth. section describe related work latent variables machine learning literature. section layout deformable classiﬁer algorithm. section describe modiﬁcation spatial transformer network regresses parameters transformation image separately class. section describe experiments section show types networks used handle clutter case handwritten digits. model consists spatial transformer module contains localization network grid generator together classiﬁcation network trained using stochastic gradient descent. localization network predicts transformation parameters based input image. could parameters aﬃne general smooth deformation described example thin plate spline. grid generator transforms image resulting transformed image passed classiﬁer. transformation image deﬁned ‘weak’ sense follows. consider image domain continuum image deﬁned given parameterized family smooth deformation original formulation take smooth kernel function deﬁned approximates dirac delta function write formulation allows push application deformation computation derivatives onto smooth kernel avoids need deal explicit deformations derivatives image deﬁned discrete pixel grid. denote network predicting transformation parameters subsequent classiﬁcarespect easily propagated backwards network provided module deﬁned compute network trained estimated image passed obtain predicted transformation computed note spatial transformation computed directly image without knowing class. create ambiguities figure show image rotated digit rotated look like instantiations diﬀerent digit classes. intuitively spatial transformer module recognize class label image extract transformation parameters taking class label account. argue accurate estimate transformation possible unless image label captured even given class expects external information needed guide transformation. class labels images fully captured spatial transformer module spatial transformer module cannot produce accurate spatial transformation input. latent variables discriminative models studied framework multiple instance learning latent variables used capture variations instances within labeled bag. mi-svm formulation multiple instance learning initially proposed later reformulated latent work problem detect objects given class binary classiﬁer across image scoring window follows object non-object examples respectively. since maximum linear functions convex negative examples summand cost function convex positive examples convex authors propose step iteration. positive example optimal given current value optimize convex function similar vein paper incorporate latent variables deep neural networks capture transformations input. input image warped class separately based latent values optimize output class. training done entire batch using network parameter values gradient steps taken update network parameters input images warped. setting classiﬁer linear parameters choice compute optimal latent variable class examples. vector model parameters class feature mapping function parametrized setting multi-layer convolutional neural network. paramters common classes ﬁnal classiﬁcation depends last layer network parameterized β’s. latent variable introduced parametrize deformations test example model ﬁnds separate optimal latent value class terms output corresponding class. class output highest value yields ﬁnal classiﬁcation. together classiﬁcation also obtain optimal transformation image reference pose. step method optimal instantiation example class. ﬁrst glance might seem would simpler forgo non-target classes focus ﬁnding optimal instantiation example target class. note however approach often insuﬃcient. recall image transformed look like instantiations non-target class like examples show figure without competing optimal instantiations data non-target classes model might learning competitive negative examples. order minimize hinge loss equation design two-step training mechanism. example algorithm ﬁnds highest scoring latent values class based current model parameters. algorithm optimizes model parameters ﬁxing latent values. outline procedure two-step training algorithm algorithm deformable classiﬁers latent variables form discrete example ﬁnite rotations optimization performed exhaustively search continuous latent variables optimize equation respect gradient descent regularize magnitude optimization penalizing distance identity. range continuous variable large degree range rotations initialize gradient descent small discrete initial rotations take optimal value initializations paper aﬃne transformations thin plate spline transformations parameterizations gradient respect types transformations implemented eﬃciently deep learning package lasagne employ experiments. diﬀerent approach direct generalization original spatial transformer model class based spatial transformer modules class directly predict values class training testing. instead optimizing based gradient classiﬁer output training approach optimizes neural network parameters predict class-speciﬁc transformation. transformation image passed feature extraction network classiﬁer calculates class scores based features extracted diﬀerent class-speciﬁc transformations image figure precise denote network computing transformation class common feature extraction network full cstn computes training previous section alternate updating parameters classiﬁcation network parameters ﬁxed keeping classiﬁcation network parameters ﬁxed updating parameters transformation networks ﬁxed loss example given transformation network optimize parameter compute optimal instantiation example class make look close possible image object class result spatial transformer modules learn optimal instantiation example target class also learn compute competitive negative examples non-target classes. testing need optimization transformation class predicted directly again unlike spatial transformer module trained network approach constructs diﬀerent spatial transformer module class providing diﬀerent latent value class. downstream networks transformer module tied ﬁnal layer feeds corresponding class output unit. methods dc-gd dc-esgd cstn require parametrize transformation function form diﬀerentiable respect latent variable gradient either directly update latent variable update model parameters spatial transformer modules. angle rotation latent variable. choose architecture trained achieve competitive result mnist dataset. architecture consists consecutive convolutional blocks block composed convolutional layer blocks passed fully connected layer units ﬁnal layer units. initialize weights model training subset original mnist dataset train model optimal instantiations mnist-rot training data. experiment three diﬀerent approaches optimizing latent variable including dc-es dc-esgd. dc-esgd initialized eight diﬀerent rotations optimized iterations using gradient descent. choose value produces highest score. figure show example images rotated digits unrotated versions corrected using latent rotation angles estimated three approaches. compared cstn dc-es dc-esgd achieve better estimates rotated angles. exhaustive search approach constrained since search limited amount rotations gradient descent approach adjust rotation arbitrary angle creating better rotation-corrected images. table show error rate achieved diﬀerent models. using class-speciﬁc spatial transformer modules optimize latent variables able achieve error rate signiﬁcantly improved achieved conventional stn. best result achieved dc-esgd reaching error training framework allows model compare optimal instantiations image diﬀerent classes expand margin score target class highest score non-target classes. show important conduct following experiment ﬁrst train traditional model training images upright digits original mnist dataset multi-class hinge loss. trained model plugged framework without additional training latent rotation angles rotated digits class. compare approach model trained optimal instantiations. figure show class scores transformed image. note classiﬁer uses class score image transformed based output class although optimal latent rotation angles correct class labels captured figure examples rotation-corrected images separate classes using conventional trained upright digits trained rotated digits using dc-esgd rotation-corrected image show class scores right classiﬁer uses score class determined rotation. approaches similar trained using framework eﬀectively suppresses non-target class scores. examples generated conventional observe many undesired spikes scores non-target classes lead incorrect classiﬁcations. dc-esgd example rotated strong output class last display outputs class transformed using standard output class rotated class higher output class rotated class similar problem occurs rotated using standard rotate images achieves error rate worse result shown table train model original mnist dataset order limit transformation invariance learned data ﬁrst images class training dataset order capture local deformations data thin plate spline transformation latent variables. grid control-points used thin plate spline transformation resulting parameters modeling image deformations. before ﬁrst initialize model training mnist dataset train model using framework. experiment gradient descent optimize latent variables. figure show optimal transformed image thin plate splines classes. shown table able achieve error rate using framework major improvement compared results original stn. apply model cifar- dataset train model using ﬁrst images class training dataset test original cifar- test dataset. ﬁve-layer model achieve test error epochs training. choose architecture framework. initialize network ﬁrst training model cifar- train deformable classiﬁer. explore settings angle rotation latent variable model translation scale latent variables. figure show optimal transformation translation scaling objects cifar- images. show increase model performance using latent translation scaling even comparable semi-supervised approaches reported literature large complementary unlabeled training set. train model google earth dataset contains aerial photos streets bounding boxes around vehicles. henriques also angle annotation vehicle supplement dataset. dataset contains vehicles large images ﬁrst images used training rest testing. task dataset estimate rotation parameter vehicle image. ﬁrst learn horizontal detection model training classical model discriminate horizontal images background images. figure show image examples training detection model. model initialization dc-esgd training method trains model using images rotated vehicles cropped training images. trained latent variable model estimate rotation angles vehicles ﬁnding latent rotation parameters give maximal values score function. also build baseline -layer model following description last layer network contains node regress target rotation angles vehicles results shown table model optimal instantiations outperforms baseline model margin rotation errors contributed cases fronts mistaken rears. speciﬁcally show figure data predicted less rotation error predicted rotation error. ignore diﬀerence front rear relax problem estimating rotation angles achieve average test rotation error diﬀerent approach calculate rotation errors. denote ground handling clutter image paramount importance clutter lead signiﬁcant degradation classiﬁer performance observed training. thus investigate sensitivity approach diﬀerent types clutter observed training data. employ types clutter models. random clutter randomly select small image patches digit images place randomly around original digits. patches contain digit parts strokes curvatures. figure show examples images diﬀerent clutter types. note nearby clutter touch overlap original digit center. ﬁrst rows figure reference poses recovered approach images ﬂanking digit clutter reference poses images correct class labels shown here. model able adjust center digits obtain preferred poses. worth noting that digits training data size digits test data. ﬁrst rows figure show reference poses recovered approach images random clutter surrounding target objects. similarly model adjust pose target object center regardless surrounding random clutter. worth noting reference poses estimated objects surrounding random clutter diﬀerent captured objects ﬂanking digits. discuss following section show evidence prove approach less robust random clutter reference poses captured perfect. reference poses estimated surrounding clutter still exists aﬀect come classiﬁer. framework used estimate support masks objects used eliminate clutter. figure show comparison mean images original handwritten digits training pose-adjusted handwritten digits recovered thin plate splines nuisance transformations data removed obtain reference pose object clear mean images pose-adjusted digits much sharper mean images original digits used determine object support map. presence clutter object labels images known apply support maps correct class pose-aligned images clutter obtain decluttered images shown figure figure note decluttering step naturally achieved pre-trained model. useful dealing tasks objects training images clean background objects testing images surrounded clutter. note figure observe parts objects support masks shapes recovered reference poses cannot completely match support masks corresponding class indicating surrounding clutter aﬀecting classiﬁcation result. results shown figures assume knowledge correct class. known actual classiﬁcation setting. since approach estimate reference pose class separately apply support class passing downstream network output score class. class output highest value yields ﬁnal classiﬁcation. trained mnist dataset clear background tested original test dataset ﬂanking digit clutter approach improves classiﬁcation accuracy rate remove clutter test images using support maps. however test model original test dataset random surrounding clutter classiﬁcation accuracy rate drops shows approach less robust random surrounding clutter. figure examples original images ﬂanking digit clutter shown ﬁrst row. corresponding recovered reference poses correct class labels shown second row. decluttered images extracted applying object class support shown third using decluttering approach described section figure examples original images random clutter shown ﬁrst row. corresponding recovered reference poses correct class labels shown second row. decluttered images extracted applying object class support correct class shown third using decluttering approach described section class image class support applied subset visible image gets high score class instance second figure digit nine look like digit zero digit four digit seven deform apply support maps. note classiﬁcation model produce class score class separately label test example class highest score. therefore decluttered images look like images diﬀerent class target class classiﬁcation stage would confuse classiﬁer. show ﬁrst figure observe column clutter nearby region gets pulled digit center form object looks like digit ﬁve. apply support image remove clutter image looks exactly like digit ﬁve. caused much ﬂexibility deformation allowed thin-plate spline alleviate regularizing degree deformation. explained above image directly feed decluttered images diﬀerent classes downstream classiﬁer classiﬁcation. class scores produced decluttered image separately class produces highest score picked determine label example. since classiﬁcation model observes decluttered image certain class without aware decluttered images classes masked original image model simply information whether certain object class best explain scene original image. figure show examples misclassiﬁed digits corresponding optimal images captured corresponding images diﬀerent classes right show corresponding decluttered images feed downstream network produce class scores classiﬁcation. figure stack images produced training image optimal instantiation computed class corresponding class support mask applied. leftmost column original training image. resolve this apply two-step mechanism training testing images clutter observed training. train regular deformable classiﬁer estimate support class. training image optimal instantiation class computed using corresponding support applied yielding transformed cropped images show figure training image stack transformed cropped images train regular classify label example based stack input images. time since model able observe optimal deformed decluttered images classes richer information gets masked support maps better resolve subset problem. applying two-step mechanism classifying images clutter achieve classiﬁcation accuracy test images ﬂanking digit clutter classiﬁcation accuracy test images random surrounding clutter. respectively higher approach without two-step mechanism. work propose framework training deep neural networks optimal instantiations data. introducing latent variables parametrize transformation data class approach able obtain reference pose object classiﬁed consequently achieve better classiﬁcation rates smaller training sets. show approach applied existing neural network architecture compatible general types transformations including rotation translation scaling local deformations. presents non-generative approach estimating latent transformations used estimate templates diﬀerent classes averaging pose-corrected images. generative methods used classiﬁcation templates needed order compute likelihood class given test image. templates needed classiﬁcation used estimate object support identify object parts. furthermore introducing discrete latent variables believe possible estimate clusters mixture components diﬀerent object classes thus reﬁning estimated templates. clear advantage generative modeling examples class needed estimate template distribution latent variables. disadvantage modeling inadequacy noise models typically need assume conditional independence order model computationally tractable. setting class labels need known order update parameters network. essentially determined particular multi-class hinge loss use. note also possible ‘one-against-the-rest’ hinge losses class estimating class classiﬁer. case would learning deformable classiﬁer class separately implicitly template class even distribution deformations avoiding need provide generative model images. summarize much important information distribution samples class obtained generative modeling obtained framework proposed here provided classiﬁcation cost data available evaluate cost.", "year": 2017}