{"title": "Share your Model instead of your Data: Privacy Preserving Mimic Learning  for Ranking", "tag": ["cs.IR", "cs.AI", "cs.CL", "cs.LG"], "abstract": "Deep neural networks have become a primary tool for solving problems in many fields. They are also used for addressing information retrieval problems and show strong performance in several tasks. Training these models requires large, representative datasets and for most IR tasks, such data contains sensitive information from users. Privacy and confidentiality concerns prevent many data owners from sharing the data, thus today the research community can only benefit from research on large-scale datasets in a limited manner. In this paper, we discuss privacy preserving mimic learning, i.e., using predictions from a privacy preserving trained model instead of labels from the original sensitive training data as a supervision signal. We present the results of preliminary experiments in which we apply the idea of mimic learning and privacy preserving mimic learning for the task of document re-ranking as one of the core IR tasks. This research is a step toward laying the ground for enabling researchers from data-rich environments to share knowledge learned from actual users' data, which should facilitate research collaborations.", "text": "much research done general problem preserving privacy sensitive data applications question design eective systems without damaging users’ privacy? solutions anonymize data hide identity users example zhang dierential privacy approach query anonymization. however guarantee anonymized data eective original data. using machine learning-based approaches sharing trained model instead original data turned option transferring knowledge idea mimic learning model trained based signals original training data annotate large unlabeled data labels training signals training model. shown many tasks computer vision natural language processing transfer knowledge newly trained models perform well model trained original training data however trained models expose private information dataset trained hence problem preserving privacy data changed problem preserving privacy model. modeling privacy machine learning challenging problem much research area. preserving privacy deep learning models even challenging parameters safeguarded work studied vulnerability deep neural network service interaction model input-output black others proposed approaches protect privacy adversary full knowledge training mechanism access model’s parameters. instance abadi propose privacy preserving stochastic gradient descent algorithm oering trade-o utility privacy. recently papernot propose semi-supervised method transferring knowledge deep learning private training data. propose setup learning privacy-preserving student models transferring knowledge ensemble teachers trained disjoint subsets data privacy guarantees provided. investigate possibility mimic learning document ranking study techniques aimed preserving privacy mimic learning task. generally address research questions abstract deep neural networks become primary tool solving problems many elds. also used addressing information retrieval problems show strong performance several tasks. training models requires large representative datasets tasks data contains sensitive information users. privacy condentiality concerns prevent many data owners sharing data thus today research community benet research large-scale datasets limited manner. paper discuss privacy preserving mimic learning i.e. using predictions privacy preserving trained model instead labels original sensitive training data supervision signal. present results preliminary experiments apply idea mimic learning privacy preserving mimic learning task document re-ranking core tasks. research step toward laying ground enabling researchers data-rich environments share knowledge learned actual users’ data facilitate research collaborations. introduction deep neural networks demonstrate undeniable success several elds employing taking information retrieval problems shown supervised neural network models perform beer training dataset grows bigger becomes diverse information retrieval experimental empirical discipline thus access large-scale real datasets essential designing eective systems. however many information retrieval tasks sensitivity data users privacy issues researchers access large-scale datasets training models. permission make digital hard copies part work personal classroom granted without provided copies made distributed prot commercial advantage copies bear notice full citation page. copyrights third-party components work must honored. uses contact owner/author. sigir workshop neural information retrieval august shinjuku tokyo japan copyright held owner/author. -x-xxxx-xxxx-x/yy/mm. ./nnnnnnn.nnnnnnn denote i-th term query document respectively. weighting function assigns weight term vocabulary. shown simulates eect inverse document frequency important feature information retrieval compositionality function projects embedding-weighting pairs m-dimensional representation independent value taking element-wise weighted terms’ embedding vectors. initialize embedding function wordvec embeddings pre-trained google news weighting function idf. representation learning layer followed simple feedforward neural network composed hidden layers relu activation function output layer output layer fully-connected layer single continuous output tanh activation function. model optimized using hinge loss batches training instances dened follows below assess general possibility exploiting mimic learning document ranking task regardless privacy concerns. examine model papernot privacy preserving technique mimic learning. motivation mimic learning comes well-known property neural networks namely universal approximators i.e. given enough training data deep enough neural large enough hidden layers approximate function arbitrary precision general idea train deep wide network original training data leads model able express structure data well; model called teacher model. teacher model used annotate large unlabeled dataset. annotated used train neural network called student network. many applications shown student model makes predictions similar teacher model nearly even beer performance idea mostly employed compressing complex neural models ensembles neural models small deployable neural model performed preliminary experiments examine idea mimic learning task document ranking. question trained neural ranker training data annotate unlabeled data train model newly generated training data works nearly good original model? experiments neural ranker employed rank model proposed dehghani general scheme model illustrated model goal learn scoring function given pair query document model parameters model uses pair-wise ranking scenario training point-wise networks share parameters parameters updated minimize pair-wise loss. training instance elements sqdi indicates relevance score respect ground-truth. inference trained model treated point-wise scoring function score query-document pairs. model input query documents passed representation learning layer function learns representation input data instances i.e. consists three components embedding function weighting function compositionality function formally function dened distillation approach training student network. sets experiments train teacher model full supervision i.e. queries judgments using -fold cross validation. second experiments queries judgments used evaluation train teacher model using weak supervision setup proposed million queries query unlabeled training query teacher model. experiments separate million queries query unlabeled data annotated trained teacher model training student model. results obtained experiments summarized table results generally suggest train neural ranker using mimic learning. using weak supervision train teacher model student model performs good teacher model. case training teacher full supervision original training data small performance teacher model rather mostly fact teacher model overts train data able generalize well. however regularization eect mimic learning student model trained predictions teacher model signicantly outperforms teacher model previous section examined using idea mimic learning train neural ranker regardless privacy risks. section address second research question privacy preserving mimic learning methods eective training neural shown risk privacy problems adversary able query model model parameters exposed adversaries inspection. instance fredrikson show observing prediction machine learning models approximately reconstruct part training data ack). shokri also demonstrate possible infer whether specic training point included model’s training data observing predictions model ack). apply idea knowledge transfer deep neural networks private training data proposed papernot authors propose private aggregation teacher ensembles based teacher-student paradigm preserve privacy training data. first sensitive training data divided partitions. partition independent neural network model trained teacher. teachers trained aggregation step done using majority voting generate single global prediction. laplacian noise injected output prediction teacher aggregation. introduction noise protects privacy obfuscates vulnerable cases teachers disagree. aggregated teacher considered deferentially private submit input returns privacy preserving label. circumstances eciency reasons model needed deployed user device able generate shareable model privacy training data preserved papernot train additional model called student model. student model access unlabeled public data training. unlabeled public data annotated using aggregated teacher transfer knowledge teachers student model privacy preserving fashion. adversary tries recover training data inspecting parameters student model worst case public training instances privacy preserving labels aggregated teacher going revealed. privacy guarantee approach formally proved using dierential privacy framework. setup partitioning fully supervised training data problem leads small training sets enough training good teachers. experiments split training data three partitions contains million queries annotated method. train three identical teacher models. aggregated noisy predictions teachers train student network using knowledge distillation approach. congurations teacher student networks similar previous experiments presented table evaluate performance situations privacy parameter determines amount noise zero second noise parameter guarantees privacy risk report average performance teachers noise performance noisy non-noisy aggregated teacher performance student networks situations. results experiments reported table results table suggest using noisy aggregation multiple teachers supervision signal train neural ranker acceptable performance. compared single teacher setup previous section performance student network good average performance teachers. although student network performs beer teacher noisy aggregation setup. less case student together non-noisy aggregated teacher. believe drops performance student networks compared results previous section partitioning noise aggregation. also eect change amount training data teachers experiments. case enough training data partition teacher prediction determined less disagreement aggregation phase consequently beer signals training student model. conclusion recent success deep learning many elds also moving traditional statistical approaches neural network based approaches. supervised neural networks data hungry training eective model requires huge amount labeled samples. however many tasks enough datasets. many tasks ad-hoc retrieval task companies commercial search engines access large amounts data. however sharing datasets research community raises concerns violating privacy users. paper acknowledge problem propose approach overcome suggestion based recent success mimic learning computer vision tasks. research question mimic learning train neural ranker? answer question used idea mimic learning. instead sharing original training data propose train model data share model. trained model used knowledge transfer fashion label huge amount unlabeled data create datasets. showed student ranker model trained dataset labeled based predictions teacher model perform almost well teacher model. shows potential mimic learning ranking task overcome problem lack large datasets ad-hoc task open-up future research direction. shown literature even sharing trained model sensitive training data instead original data cannot guarantee privacy. second research question privacy preserving mimic learning methods eective training neural ranker? guarantee privacy users proposed idea privacy preserving mimic learning. showed using approach privacy users guaranteed also achieve acceptable performance. paper groundwork idea sharing privacy preserving model instead sensitive data applications. suggests researchers industry share knowledge learned actual users’ data academic community leads beer collaboration researchers eld. future direction research establish formal statements regarding level privacy would entail using privacy preserving mimic learning strengthen angel experimental evaluation. besides investigate kind neural network structure suitable mimic learning ranking task. acknowledgments research supported part netherlands organization scientic research exploratory political search project digging data challenge digging linked parliamentary data project research also supported ahold delhaize amsterdam data science bloomberg research grant program criteo faculty research award program dutch national program commit elsevier european community’s seventh framework programme grant agreement microso research ph.d. program netherlands institute sound vision netherlands organisation scientic research project hor- ci-- yandex. content represents opinion authors necessarily shared endorsed respective employers and/or sponsors. references mart´ın abadi andy goodfellow brendan mcmahan ilya mironov kunal talwar zhang. deep learning dierential privacy. proceedings sigsac conference computer communications security. jimmy rich caruana. deep nets really need deep?. advances neural information processing systems. cristian bucilua rich caruana alexandru niculescu-mizil. model compression. proceedings sigkdd international conference knowledge discovery data mining. mostafa dehghani hamed zamani aliaksei severyn jaap kamps bruce cro. neural ranking models weak supervision. international sigir conference research development information retrieval. fredrikson somesh omas ristenpart. model inversion aacks exploit condence information basic countermeasures. proceedings sigsac conference computer communications security. kezban dilek onal ismail sengor altingovde pinar karagoz maarten rijke. geing started neural models semantic matching search. arxiv preprint arxiv. nicolas papernot martin abadi ulfar erlingsson goodfellow kunal talwar. semi-supervised knowledge transfer deep learning private training data. international conference learning representations adriana romero nicolas ballas samira ebrahimi kahou antoine chassang carlo yoshua bengio. fitnets hints thin deep nets. arxiv preprint arxiv. reza shokri marco stronati vitaly shmatikov. membership inference aacks machine learning models. arxiv preprint arxiv. chen abhinav shrivastava saurabh singh abhinav gupta. revisiting unreasonable eectiveness data deep learning era. arxiv preprint arxiv. florian tram`er zhang juels michael reiter omas ristenpart. stealing machine learning models prediction apis. usenix security. sicong zhang yang lisa singh. anonymizing logs", "year": 2017}