{"title": "Discriminate-and-Rectify Encoders: Learning from Image Transformation  Sets", "tag": ["cs.CV", "cs.LG", "stat.ML"], "abstract": "The complexity of a learning task is increased by transformations in the input space that preserve class identity. Visual object recognition for example is affected by changes in viewpoint, scale, illumination or planar transformations. While drastically altering the visual appearance, these changes are orthogonal to recognition and should not be reflected in the representation or feature encoding used for learning. We introduce a framework for weakly supervised learning of image embeddings that are robust to transformations and selective to the class distribution, using sets of transforming examples (orbit sets), deep parametrizations and a novel orbit-based loss. The proposed loss combines a discriminative, contrastive part for orbits with a reconstruction error that learns to rectify orbit transformations. The learned embeddings are evaluated in distance metric-based tasks, such as one-shot classification under geometric transformations, as well as face verification and retrieval under more realistic visual variability. Our results suggest that orbit sets, suitably computed or observed, can be used for efficient, weakly-supervised learning of semantically relevant image embeddings.", "text": "complexity learning task increased transformations input space preserve class identity. visual object recognition example affected changes viewpoint scale illumination planar transformations. drastically altering visual appearance changes orthogonal recognition reﬂected representation feature encoding used learning. introduce framework weakly supervised learning image embeddings robust transformations selective class distribution using sets transforming examples deep parametrizations novel orbit-based loss. proposed loss combines discriminative contrastive part orbits reconstruction error learns rectify orbit transformations. learned embeddings evaluated distance metric-based tasks one-shot classiﬁcation geometric transformations well face veriﬁcation retrieval realistic visual variability. results suggest orbit sets suitably computed observed used efﬁcient weakly-supervised learning semantically relevant image embeddings. distribution examples learning problem visual object recognition exhibit variability across within semantic categories. former category-speciﬁc statistics; latter variety instances share semantics transformations preserve identity geometric photometric changes. transformations alter properties visual scene change semantic category object. recognition across novel views clutter occlusions generalization examples category hallmarks human primate perception. invariance transformations consistently explored computational objective representations computer vision figure discriminate-and-rectify encoder network convolutional layers followed pooling orbit-triplet loss using encoding part triplet. orbit-encode reconstructs canonical orbit element deconvolutional decoder output. tied weights denoted colors loss layers red. representations facilitate generalization downstream supervised tasks learned unsupervised semi-supervised settings distribution observations used obtaining non-linear similarity metrics reducing dimensionality disregarding nuisance directions deriving interpretable generative models. unsupervised learning used example pretraining neural networks goal improving convergence rates end-to-end learning algorithms. question theoretical practical interest conditions representations learned without explicit supervision match performance supervised learning methods implicitly account representation data learning unlabeled data alternative using labeled examples training multi-parameter deep neural networks building large-scale generic transferable learning systems economically. addition biological cognitive learning paradigms particularly perceptual domains vision speech predict learning generalization small number labeled examples abundance implicitly labeled observations weak supervision. natural source weak supervision formation equivalence relations classes input space necessarily related learning task. relations example temporal categorical generative partition space sets loosely refer obits paper. example orbits images object rotations frames video moving object partition orbit sets terms granularity lies in-between single-example task-speciﬁc semantic class partitions. paper propose using orbit sets deﬁned generic transformations weak supervision learning representations invariant metric space. points equivalent related transformation equivalent points forms orbit. orbits either explicitly generated implicitly speciﬁed opposed inference using explicit transformation model factoring nuisance using explicit pooling learn deep parametric embeddings using novel loss function incorporates orbit equivalence relations. proposed orbit metric loss generalizes triplet loss denoising autoencoders orbit sets promote approximate invariance reconstruction. separately orbit triplet study motivating special cases loss discriminative term implicitly promotes invariance selectivity respect examples drawn different orbits respectively orbit encoder loss generative term learns rectify de-transform mapping orbit points single canonical element. learned embeddings compared under parametrizations supervised triplet loss surrogate class loss full model orbit-generating process available spatial transformer networks learned embeddings deﬁne robust metrics semantically relevant distance-based supervised-sample regime tasks ranking retrieval matching clustering graph-construction relational learning. provide quantitative comparisons face veriﬁcation retrieval one-shot learning classiﬁcation results show partitioning input space according suitable orbit sets powerful weak supervision proposed encoding loss exploit effectively learn semantically relevant embeddings. invariance transformations orthogonal learning task subject extensive theoretical empirical investigation artiﬁcial biological perception recognition. number studies focused theoretical insights trade-off invariance selectivity sufﬁcient statistics optimality explicit parametrizations convolutions/pooling memory-based learning well constructing invariants compact groups maps robust rather invariant diffeomorphisms inspired feature extraction architectures object recognition texture classiﬁcation face veriﬁcation action recognition speech recognition paper rely theoretical framework relaxing assumptions e.g. compact groups exact invariance make generic orbit sets come implicit supervision include nongroup transformations partial orbits noisy samples. propose loss function proxy margin-based invariance selectivity representation used end-to-end trainable encoders rely particular parametrization require access model orbit generation process. side information form weak supervision employed various distance metric learning algorithms example variants triplet loss function rely knowing pairs corresponds similar samples supervised versions triplet loss used discriminatively-trained metric learning convolutional network parametrization aiming minimize true objective task triplet loss also used nonlinear dimensionality reduction learning transformation-invariant embeddings similar neighborhood graphs orbits work obtained side information temporal proximity assumed known training. representation learning surrogate classes populated data augmentation transformations explored exemplar framework autoencoder networks typically used dimensionality reduction unsupervised pretraining deep networks. different reconstruction requirements regularization terms lead useful encodings learning perform denoising sparse coding contractive approximations robustness respect temporal continuity convolutional autoencoders enforce local spatial robustness pooling method uses combination triplet loss explicit rectiﬁcation accuracy loss encoder-decoder network. idea using representation transformations robust embeddings explored explicit estimation parameters exact model generative process spatial transformer networks estimation latent representation transforming autoencoders distributed representation similar size training distance margin non-matching pairs |α|+ max{ hinge loss function. triplet loss based deﬁning point triplets using label agreement aims enforce autoencoders autoencoder composed encoding decoding assume euclidean spaces appropriate hypothesis spaces learned minimizing reconstruction loss typically square crossentropy loss. encoding parametrized linear using projection units ﬁlters rd×k offset nonlinear function applied element-wise reduced number parameters. maps multiple layers learned additional priors regularization activations hidden layers reconstructing perturbations convolutional structure pooling. transformations orbit sets consider family transformations maps denote action transformation represented generates point i.e. transformations parametrized algebraic structure e.g. form group begin reviewing relevant background concepts order provide context formulate clearly proposed losses weakly-supervised learning methods. learning representations feature data representation learning problem input space explicitly selected learned using principles denotes equivalence function composition i.e. ˜φ). remark feature selected hypothesis space functions practice parametrization elements renders resulting representation learning problem tractable necessary. remark kernel machines preselected implicitly induced kernel function φ)∀x deep networks parametrized typically linear projections non-linearities jointly learned predictor function. moreover involves multiple maps form compositions multiple representation layers representation express linear kernelized nonlinear mappings obtained solution regularized constrained minimization problem using form side information similarity pairs triplets points triplet loss large margin nearest neighbor loss developed supervised learning distance metric pulling together pushing apart samedifferent-class neighbors respectively. closely related contrastive transforming input feature map. stns introduce speciﬁc modiﬁcation parametrization input gθxi provides estimate applies inverse transformation gθxi module acts oracle provides rectiﬁed untransformed version input passed downstream embedding maps. resulting embedding robust construction transformations introduce novel loss function learning embedding distance metric using weak supervision memberships transformation orbits. loss aims jointly adaptively data-driven manner enforce invariance transformations captured orbit sets selectivity rectiﬁcation error representation. loss function independent embedding parametrization though implies siamese encoder-decoder network architecture paper learn deep convolutional encodings. orbit sets obtained either explicit transformations unlabeled input data e.g. sample generates orbit weak supervision signal involving data continuity e.g. subsets training correspond data collected sequentially multiple views. relax exact invariance condition using \u0001approximation zero-norm distance. terms deﬁnes sufﬁcient necessary condition points equivalent transformation orbit note requirement selectivity i.e. converse direction makes proper metric space invariant \u0001-approximation sense metric. deﬁnition orbit associated element points reached transformations i.e. given group structure transformations partition input space orbits deﬁning equivalence relations gx∀x result belongs orbit ogx∀g input space ∪x∈x g∈gogx ∪x∈xox. using fact orbit sets deﬁned equivalence relations extend deﬁnition relations memberships provided categorical labels. deﬁnition orbit associated element subset includes along equivalence class equivalence relation i.e. equivalence relation given function examples maps labels supervised learning task indexes vector quantization codewords case sequential data videos sequence membership classes codewords sequences respectively surrogate classes exemplar loss exemplar loss introduced combine data augmentation weak supervision training convolutional networks uses surrogate class point unlabeled training {xi}n surrogate class instances generated random transformations sampled class prototypes {gjxi}ki≤|g| embedding learned minimizing discriminative loss respect surrogate classes indexes original untransformed training serves surrogate class label points generated classiﬁer learnt jointly embedding. spatial transformer networks plausible forward model process generates orbits known i.e. suitable parametrization available stns trainable modules learn undo transformation explicitly learning problem; give examples orbit sets. augmentation given parametrized family transformations generate orbit samples given randomly sampling parameter vectors letting {gθj examples include geometric transformations e.g. typical data augmentation transforms acquisition data acquisition process part learning problem e.g. online/unsupervised learning included meta-data e.g. multiple samples object across time conditions views e.g. orbit associated samples sequence session temporal continuity sequential data videos orbit continuous segment video stream following plausible assumptions feature smoothness continuity representation time assume orbits {oxi} given either priori partition training number equivalence classes ∪xioxi augmentation {gθj given orbits consider triplets oxi} assigned positive example i.e. negative example i.e. oxi. assume orbit equipped canonical example oxi. deﬁnition orbit point provides reference coordinate system family transformations generate orbit. obtained generative process applied output identity transformation i.e. gx.. orbits categorical meta-data empirically chosen ‘regular’ view neutral condition proposed loss function reﬂected architecture fig. composed terms; discriminative term based triplet loss using distances constants control relative contribution term distance margin. loss independent parameterization depends selection triplets {ti} given orbits canonical instance orbit. orbit triplet loss orbit metric loss reduces triplet loss similarity dissimilarity speciﬁed orbit memberships. points orbit pulled together points different orbits pushed apart. minimizer pushed satisfy using triplets training set. note theoretical minimum e.g. using subgradient hinge loss satisﬁed. orbit triplet loss follows siamese network architecture tied-weight embedding trained using triplets input. following proposition shows case bounded-norm embeddings minimizing triplet loss thus pushing minimize leads operational deﬁnition selective robustness transformations tolerance margin proposition space functions norm i.e. bounded true invariant orbit transformations selective orbit identities according \u0001-approximate deﬁnition orbit metric loss reduces loss penalizes using additional decoder reconstruction error output point canonical orbit oxi. also error transformation rectiﬁcation applies input assumed transformation loss novel type autoencoder loss learns de-transform input. motivation generalization denoising autoencoders learn reconstruct clean versions noisy input transformations without explicit generative model using equivalence points within orbit. orbit encoders learn de-transform input adaptively transformations training orbits mapping points onto pre-selected canonical orbit element provides reference point every point seen gixc known transformation process. reconstruction error ||xc minimization pushes solution towards ‘inversion’ transformation jointly points training set. another rectiﬁcation objective trying reconstruct given artiﬁcially transformed version gixc. training requires pairs choice canonical orbit consistent across semantic class downstream task e.g. orbits class. loss enforces selectivity preserving sufﬁcient information reconstruct input irrespective transformation. rkl×kl− weight matrix rkl. consider convolutional maps groups ﬁlters correspond local kernel shifted support input i.e. ﬁlter sparse input projection convolution denotes convolution rfl×kl− nonlinearity hard rectiﬁer given |a|+ max{ applied element wise pre-activation output i.e. batch normalization applied addition pooling nonlinearities introduced number convolution layers order increase spatial invariance decrease feature sizes. ﬁlter layer looking corresponding support input φl−ifl=j takes maximum sets convolution values deﬁned grid neighboring values i.e. max{φl−in fl=j}. compared embeddings learned using proposed loss orbit joint special cases orbit triplet orbit encode three reference closely related methods supervised triplet exemplar standard autoencoder loss used learning input metric space using network/parametrization varying degrees supervision embeddings learned training test sets downstream tasks encoded used evaluate performance. embedding used training networks i.e. collection orbits kept separate data used downstream tasks. afﬁnemnist evaluations also compared methods embedding parametrization featuring spatial transformer networks module trained orbit supervision full supervision network training details figure input rectiﬁcations st-stn ot-stn stns produced convincing rectiﬁcations full supervision available learned identity weak supervision encoder-decoder trained proposed orbit metric loss produces accurate rectiﬁcations using weak supervision. created version mnist using random afﬁne transformation point original mnist dataset transformations sampled uniformly union following intervals rotation shearing factor scale factor translation dimension pixels. orbit consisted original mnist training augmented transformations sample resulting total images grouped orbits. orbit size single original image corresponding random transformations learned embeddings using employed one-shot classiﬁcation task assess invariance selectivity properties. training consisted images semantic class. drawn random original mnist validation test consisted images randomly drawn original mnist test figure shows t-sne plots learned embeddings random subset test set. qualitatively best separation grouping observed fully supervised triplet loss followed weakly supervised orbit joint loss figure nearest neighbor classiﬁcation using example-perclass mnist augmented afﬁne transformations. accuracies averaged random re-samples training shown different times training embeddings. convolutions small kernel batch normalization relu activation. spatial pooling layer used every layers convolutions. number channels doubled pooling layer ranging mnist multi-pie. four iterations convolution pooling followed ﬁnal fully-connected layer size decoder deconvolutional network reversing series operations encoder using convolutional reconstruction unpooling encoder decoder weights tied free biases. training done minibatch stochastic gradient descent using adam optimizer. mnist experiments used minibatches multi-pie selection triplets followed soft negative selection process values equal experiments selected cross-validation. stns modules used afﬁne-mnist comparisons consisted pooling-convolution-relu blocks ﬁlters size pooling regions size overlap followed linear layers. figure examples retrieval rectiﬁcation multi-pie. rows correspond canonical pose seec image seed image top- retrieved using orbit joint embedding top- retrieved using exemplar embedding reconstructed canonical pose using decoder network. shows classiﬁcation accuracy results embedding training epochs. iteration accuracy shown mean standard deviation error bars different labelled selections. expected supervised performed best unsupervised lower baseline. weakly-supervised methods orbit metric loss achieved accuracy followed spatial transformer network modules provided small improvement accuracy used full supervision however orbit information available difference performance. reﬂected fig. shows rectiﬁcation examples output module learned decoder method. multi-pie dataset contains images faces individuals captured distinct viewpoints different illumination conditions. acquisition carried across four sessions resulting dataset images. learning maps input metric space used images three sessions form embedding sets left images fourth session performance assessment downstream task. training embedding method access face identity image thus considering images subject belonging equivalence class set. weakly supervised methods hand access orbits formed partitioning embedding orbits state-of-the-art weakly-supervised loss using splits session multi-pie -test random splits mnist test elements orbit appearing one. selected stopping time gave best performance measure evaluated measure set. table shows mean s.d. splits corresponding p-values quantifying signiﬁcance difference purpose performance assessment used learned maps encoded held-out test figure shows relative distance landscape learned embeddings t-sne plots images subjects test set. weakly supervised appears similar better grouping separability properties fully supervised used distance-based tasks quantitatively evaluate embedding metric spaces same-different face veriﬁcation task face retrieval task. transformation-robust metric space face representation same-identity images closer identities nearest neighbor image class. measure area curve veriﬁcation mean top- precision retrieval. process training evaluating embedding repeated four possible splits across sessions multi-pie assess uncertainty performance measures. veriﬁcation task used unique pairwise distances embedding space considered possible decision thresholds integrated true positive false positive rates compute auc. retrieval task select closest point query image target search set. considered test image individually query using rest test target removing same-identity images illumination viewpoint made challenging task helped ensuring embeddings evaluated respect preference identity appearance e.g. excluding candidates strong pose illumination bias. performance measure report mean precision i.e. fraction queries yielded correct retrieval. veriﬁcation performance shown fig. mean s.d. across splits multi-pie sessions expected weakly supervised methods access orbit assignments training in-between loss access category-level labels unsupervised loss. orbit triplet learns quickly performance tends decrease iterations. methods learn comparable rates. joint orbit loss achieves best score. similar ranking holds retrieval task shown top- precision fig. evaluate generalization performance i.e. testing unseen examples trained embeddings applying cross-validation individually selecting number iterations. compared proposed table generalization using embedding-validation-test splits independent selection training stopping time using validation set. -values quantify signiﬁcance difference oj-ex oj-ot oj-oe oj-ex oj-ot oj-oe. consistently outperforms three generalization tasks. moreover performance either better statistically indistinguishable observation makes case joint loss result substantial improvements like one-shot classiﬁcation task afﬁne mnist. furthermore suggests careful selection relative weights triplet reconstruction terms loss e.g. cross-validation could beneﬁcial. introduced loss function combines discriminative generative term learning embeddings using weak supervision generic transformation orbits. showed resulting image embeddings induce metric space relevant distance-based learning tasks one-shot learning classiﬁcation face veriﬁcation retrieval. loss terms serve complementary purposes joint training advantageous supersedes state-of-the-art exemplar-based training applicable spatial transformer networks. transformations alter semantic category input present classical perception problems pitch shifts speech recognition pose illumination gait changes action recognition reﬂectance properties object categorization. work presented suggests explicitly deﬁning equivalence classes according transformations rich weak supervision signal exploited general class representation learning methods starting proposed loss function learn semantically relevant embeddings. embeddings deﬁne distance functions robust typical transformations useful categorization retrieval veriﬁcation clustering. future work assess relevance modalities video audio potential acquiring equivalence classes time continuity. material based upon work supported center brains minds machines funded award ccf-. dgx- used research donated nvidia corporation. stephen voinea acknowledges", "year": 2017}