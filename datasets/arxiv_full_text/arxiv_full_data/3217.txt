{"title": "Deep Neural Networks for Anatomical Brain Segmentation", "tag": ["cs.CV", "cs.LG", "stat.AP", "stat.ML"], "abstract": "We present a novel approach to automatically segment magnetic resonance (MR) images of the human brain into anatomical regions. Our methodology is based on a deep artificial neural network that assigns each voxel in an MR image of the brain to its corresponding anatomical region. The inputs of the network capture information at different scales around the voxel of interest: 3D and orthogonal 2D intensity patches capture the local spatial context while large, compressed 2D orthogonal patches and distances to the regional centroids enforce global spatial consistency. Contrary to commonly used segmentation methods, our technique does not require any non-linear registration of the MR images. To benchmark our model, we used the dataset provided for the MICCAI 2012 challenge on multi-atlas labelling, which consists of 35 manually segmented MR images of the brain. We obtained competitive results (mean dice coefficient 0.725, error rate 0.163) showing the potential of our approach. To our knowledge, our technique is the first to tackle the anatomical segmentation of the whole brain using deep neural networks.", "text": "present novel approach automatically segment magnetic resonance images human brain anatomical regions. methodology based deep artiﬁcial neural network assigns voxel image brain corresponding anatomical region. inputs network capture information different scales around voxel interest orthogonal intensity patches capture local spatial context downscaled large orthogonal patches distances regional centroids enforce global spatial consistency. contrary commonly used segmentation methods technique require non-linear registration images. benchmark model used dataset provided miccai challenge multi-atlas labelling consists manually segmented images brain. obtained competitive results showing potential approach. knowledge technique ﬁrst tackle anatomical segmentation whole brain using deep neural networks. quantitative research neuroimaging often requires anatomical segmentation human brain based magnetic resonance images quantitative research neuroimaging often requires anatomical segmentation human brain using magnetic resonance images instance abnormal volumes shapes certain anatomical regions brain found associated brain disorders including alzheimer’s disease parkinson analysis images therefore essential detect disorders monitor evolution evaluate possible treatments. anatomical segmentation brain requires segmentation protocol deﬁning region delineated resulting segmentations comparable brains. however manually segmenting brain timeconsuming expensive process cannot performed large scale. full automation would enable systematic segmentation mris soon image acquired. potential beneﬁts encouraged active ﬁeld research today dominated multi-atlas based patch-based methods machine learning methods consist training classiﬁers assign voxel anatomical region based various input features describing neighbourhood intensities location. recently deep neural networks particular convolutional neural networks proven state many computer vision applications contrary traditional shallow classiﬁers feature engineering crucial deep learning methods automatically learn hierarchies relevant features directly inputs motivated developments propose deep artiﬁcial neural network automated segmentation entire brain. article organised follows. section brieﬂy review existing segmentation methodologies deep neural networks. section describe proposed architecture algorithm. application miccai dataset presented section conclude discussion section work consider segmentation whole brain large number anatomical regions deﬁned segmentation protocol knowledge segmentation protocol implicitly given manually labelled brain mris. atlas consists image corresponding manual segmentation. multi-atlas based methods widely used methods. query image segment methods usually consist following steps ﬁrst similar atlases query image selected registered query image; second registration transformations applied labels atlases labels propagated produce segmentations query image; ﬁnally segmentations combined using fusion strategy. methods heavily rely registration step atlases non-linearly registered query image. global afﬁne rigid registration usually ﬁrst performed followed local non-rigid registration. latter registration step relies critical assumption brains similar enough accurately mapped another. however unlikely case query brain different atlases local area furthermore regions whose boundaries clearly identiﬁable contrast intensity arbitrarily deﬁned segmentation protocol likely less accurately registered. errors inevitably effect ﬁnal segmentation. registrations also computationally intensive usually responsible slowness atlas-based methods. paper take machine learning approach whereby given training consisting several atlases model trained classify voxel corresponding anatomical region. particular investigate whether recent advances representation learning prove beneﬁcial segmentation problem. deep learning sub-ﬁeld representation learning concerned learning multi-level hierarchical representations data level based previous lately burst activity around deep neural networks particular convolutional neural networks medical imaging segmentation problems. include approaches segmentation lungs cells elegans embryos biological neuron membrane tibial cartilage bone tissue cell mitosis amongst others. applications mostly convolutional networks take intensity patches inputs; occasionally spatial consistency enforced second stage post-processing computations probabilistic graphical models. despite increasing interest medical imaging deep neural networks considered problem whole brain segmentation anatomical regions. initial work carried segmentation single slice brain using local patches input comparison approach tackles segmentation whole brain introduces multi-scale input features enforce spatial consistency segmentation. designing algorithm classiﬁes voxel corresponding anatomical region. voxel must therefore described input vector input neural network. choice input particularly important capture enough information task parsimonious possible mostly computational reasons avoid overﬁtting. types inputs incorporated work order ensure local precision global spatial consistency. voxel local precision segmentation ensured following features. first patch size a×a×a centred voxel used capture local information high level detail. second three orthogonal patches size also centred voxel added purpose capturing slightly broader still local context around voxel interest. orthogonal patches seen tradesingle patch patch capture information require signiﬁcantly smaller amount memory storage dense patch allowing bigger patch sizes used. second inputs designed preserve global spatial consistency. unlike unstructured segmentation tasks different regions arbitrarily positioned image anatomical regions consistently preserve relative positions subjects. including global information therefore likely yield additional improvements. obvious strategy would simply increase size and/or patches introduced earlier span larger portions image cover figure architecture segnet optimised miccai dataset. pathways input feature. lower layers learn speciﬁc representations input features merged joint representation. dconvpool block represents convolutional layer followed pooling layer. colour indicates layer blocks share parameters. distances centroids estimated explained section parameter values shown selected miccai application convolutional layers kernels max-pooling windows. noise layer activated training model total parameters. distant anatomy. however would generate highdimensional inputs requiring large memory storage would computational complexity. instead extract large orthogonal patches downscale factor illustrated ﬁgure downscale operation simply reduces resolution patch averaging voxel intensities within small square windows size precisely size original full-resolution patches downscaled patches sizes neural network terminology operation equivalent mean-pooling stride result downscaled patch still captures large portions addition voxel intensities coordinates voxel space also expected informative anatomical segmentation purposes. however absolute coordinates predicated individual brain scans represented common reference space turn requires performing initial generally time consuming registration images. alternative explore relative distances voxel centroids additional inputs network. centroid region image deﬁned center mass uniformly weighted voxels region represents voxels belonging region distance simply taken euclidian voxel region centroids gives indication position voxel image thus region belongs unlike absolute coordinates distances invariant rotations translations. distances centroids also invariant brain scaling upon scaling patches processed convolutional layers detect local features different positions image. neurons convolutional layer compute outputs based subset inputs called receptive ﬁeld neuron. precisely neuron given convolutional layer depends spatial contiguous layer inputs case windows voxel intensities. therefore neuron learns particular local feature speciﬁc receptive ﬁeld. local connectivity considerably reduces number parameters thus potential overﬁtting layer. addition local connectivity convolutional layer also imposes groups neurons called feature maps share exactly weight values. precisely convolutional layer decomposed several feature maps whose neurons share weights differ receptive ﬁeld. means neurons feature detect feature different receptive ﬁelds image. local connectivity weight sharing constraints simply modelled convolution operations. outputs neurons feature layer given convolution operation weight matrix feature layer feature layer matrix respectively images. size size receptive ﬁelds neuron feature layer feature map. convolutional layers architecture followed max-pooling layers reduce size feature maps merging groups neurons. precisely datapoint max-pooling layer shifts square window feature select responsive neuron position window neurons discarded. output responsive neuron indicates feature detected corresponding feature receptive ﬁeld pooling window precise receptive ﬁeld feature lost. local information particularly important problem considered small windows. beneﬁts pooling layers signiﬁcantly reduce number parameters making training simpler reducing overﬁtting. enforces average distance centroids brains. practice correct distances voxel centroids would sufﬁcient localise precisely current voxel adding distances increase robustness resulting segmentation noise conﬁrmed experimental results. although distances computed exactly using training data centroids known unknown brains segmentation performed. deal issue propose two-stage algorithm ﬁrst stage provides segmentation brain without using distances second reﬁnement stage added further improve segmentation; section details. deep neural network proposed network architecture called segnet represented figure feed-forward network formed stacking layers artiﬁcial neurons. layer models representation data neurons feature detectors. recursively deeper neurons learn detect features formed detected previous layer. result hierarchy higher higher level feature detectors. natural images decomposed edges motifs parts regions regions themselves. segnetl denote function mapping inputs layer output. architecture expressing function segnetθ deﬁned segnetθ segnetk ◦···◦ segnetl ◦···◦ segnet represents parameters network i.e. weights biases. network architecture types input features corresponding pathways merged later network. lowest layers speciﬁc type input features learn specialised representations. apart distances centroids representations learnt convolutional pooling layers denoted dconvpool dconvpool respectively. higher layer architecture individual representations merged common representation across inputs. layers learn even higher level representations capture complex correlations across different input features. representations learnt fully connected layers denoted fullycon. product output space deﬁned ajbj represents parameters network. training cast minimisation carried stochastic gradient descent algorithm variant gradient descent algorithm commonly used train large networks large datasets update weights algorithm instead considering training datapoints compute gradient error function datapoint small batch training datapoints used. also added momentum term particularly beneﬁcial along long narrow valleys error function averages directions gradient. denotes update weight iteration momentum update rule given training segnet using distances centroids possible true segmentations available. however consider segmentation brain compute directly centroids. therefore propose following iterative procedure uses neural networks sequence. sub-network corresponds segnet without centroids pathway ﬁrst trained. given image sub-network used produce initial segmentation image enables compute approximated centroids region distances voxel approximated centroids. full segnet network taking centroids pathways additional input used obtain reﬁned segmentation. reﬁned segmentation used compute better approximation centroids. last steps repeated multiple times convergence i.e. changes segmentation output. practice observed that initial model already relatively accurate algorithm converges really fast iterations. initial model poor segmentation accuracy algorithm slightly longer converge illustrated ﬁgure initial model really algorithm improve initial accuracy. neuron rectiﬁer function called rectiﬁed linear unit contrary traditional sigmoid tanh functions less prone vanishing gradient problem prevented training deep networks several decades reason sharing weights layer blocks lowest layer believe lowest level features network learns patches whatever orientation patch. also divides number parameters ﬁrst layer reduces risk overﬁtting. experimentally found constraint slightly improves performance. number datapoints number dimensions dataset. basis initial tests decided extract randomly uniformly across brain sample approximately voxels atlases total voxels training purposes amounts approximatively available voxels dataset. voxel extracted dimensional input vector consisting patch voxel intensities three orthogonal patches voxel intensities three downscaled patches size containing averaged voxel intensities distances centroids. figure shows sample patches. validation dataset consisting data points also extracted atlases. early stopping applied error rate validation dataset patience epochs. although primarily interested dice coefﬁcient applied early stopping error rate stable dice coefﬁcient single misclassiﬁcation impacts latter former. ﬁnal architecture layers sizes convolution kernels voxel lies. enforce robustness noisy approximations centroids training stage neural network artiﬁcially corrupt distances centroids adding gaussian noise training datapoint. makes sure network relies less individual distances statistical properties group distances. figure example convergence algorithm fully-connected network trained miccai dataset poor initial accuracy. particular case approximated distances centroids updated iteration signiﬁcantly improve segmentation. tested approach dataset miccai challenge multi-atlas labelling. beginning competition organisers released atlases mris without segmentations. team required develop segmentation algorithm using atlases submit segmentations mris. quality segmentation assessed computing mean dice coefﬁcient anatomical regions. images dataset t-weighted structural mris obtained oasis project images manually aligned using translation rotation segmented neuromorphometric anatomical regions. non-cortical regions follow neuromorphometric protocol cortical regions follow braincolor protocol. winning team miccai challenge obtained overall mean dice coefﬁcient median coefﬁcient teams study performance segnet dataset despite fact deep learning techniques generally require much larger training datasets. computations in-memory using single nvidia tesla memory. therefore faced trade-off pooling windows parameters reported figure resulting architecture total parameters. used batch size data points. momentum learning rate tuned respectively code based theano python library compiles symbolical expressions c/cuda code gpus. figure comparison automatic manual segmentations cerebral white matter region right hemisphere example segmentation returned network using three orthogonal patches inputs manual segmentation segmentation returned segnet. contrary wrongly classiﬁes parts left hemisphere. table shows validation error rate various model architectures include input time whose parameters optimised training data. observed combined three orthogonal patches dramatically improves segmentation performance compared patches. also notice distances centroids addition invariance qualities signiﬁcantly outperform coordinates also observed that already manually segmented brains using estimated centroids yield equivalent results using true centroids. best model segnet selected basis validation error evaluated testing mris miccai challenge mean dice coefﬁcient error rate testing mris never used training selection architectures. figure illustrates well downscaled patches distances centroids enforce global spatial consistency segmentations. figure shows manual automatic segmentations particular mri. notice misclassiﬁed voxels tend boundaries designed deep neural network architecture automatically segment brain mris. benchmarked multi-atlas methods miccai challenge obtained competitive results contrary multi-atlas based methods rely non-linear registrations mris. therefore although proposed types input features corresponding architecture precisely delineate boundaries regions ensuring global spatial consistency. current memory constraints single cards opted multi-scale system different sizes intensity patches. three orthogonal patches signiﬁcantly outperformed individual patches proving excellent trade-off capture information considerably less memory dense patch. introduced input vectors ensuring global spatial consistency segmentation. first showed network learn surprisingly well relative positions regions large downscaled patches voxel intensities. second showed distances centroids despite imprecision provide robust inputs efﬁciently capture location voxel brain. robustness redundancy independence translations rotations. approach global consistency therefore enforced inputs model without resort complicated postprocessing conditional random ﬁelds commonly used literature. also observed distances centroids downscaled patches contain redundant information consider sets features obtain almost performance. hand downscaled patches advantage using averaged intensities distances centroids require preprocessing step approximate centroids using networks. hand downscaled patches take signiﬁcantly larger amount memory distances centroids. remaining errors rather local imprecision segmentations boundaries regions future work focus improving local precision example sampling training data points along boundaries. obtained best model optimising mean dice coefﬁcient indirectly considering plain negative loglikelihood cost function. however believe future research consider sophisticated cost function take account high class imbalance problem carried experiments weighted error datapoint attempts lead substantial improvements. also tried sample number experiments obtained good validation results training huge networks sometimes composed tens millions parameters relatively small amount data although trained networks overﬁt training data still generalise fairly well unseen mris. reason likely fact that contrary natural images brain mris highly structured relatively little variability regions brain another. explain relatively voxels sufﬁcient training. using training atlases order capture variability training would ideal solution reduce overﬁtting expect substantial improvements achieved increasing number training atlases. unfortunately atlases rare expensive obtain. work consider generating artiﬁcial atlases existing ones applying small transformations rotations scaling noise small distortions plausible real mris. instead creating whole artiﬁcial atlases transformations could included model noise layer corrupts distances centroids", "year": 2015}