{"title": "Generating Natural Adversarial Examples", "tag": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "abstract": "Due to their complex nature, it is hard to characterize the ways in which machine learning models can misbehave or be exploited when deployed. Recent work on adversarial examples, i.e. inputs with minor perturbations that result in substantially different model predictions, is helpful in evaluating the robustness of these models by exposing the adversarial scenarios where they fail. However, these malicious perturbations are often unnatural, not semantically meaningful, and not applicable to complicated domains such as language. In this paper, we propose a framework to generate natural and legible adversarial examples that lie on the data manifold, by searching in semantic space of dense and continuous data representation, utilizing the recent advances in generative adversarial networks. We present generated adversaries to demonstrate the potential of the proposed approach for black-box classifiers for a wide range of applications such as image classification, textual entailment, and machine translation. We include experiments to show that the generated adversaries are natural, legible to humans, and useful in evaluating and analyzing black-box classifiers.", "text": "complex nature hard characterize ways machine learning models misbehave exploited deployed. recent work adversarial examples i.e. inputs minor perturbations result substantially different model predictions helpful evaluating robustness models exposing adversarial scenarios fail. however malicious perturbations often unnatural semantically meaningful applicable complicated domains language. paper propose framework generate natural legible adversarial examples data manifold searching semantic space dense continuous data representation utilizing recent advances generative adversarial networks. present generated adversaries demonstrate potential proposed approach black-box classiﬁers wide range applications image classiﬁcation textual entailment machine translation. include experiments show generated adversaries natural legible humans useful evaluating analyzing black-box classiﬁers. impressive success extensive machine learning models various securitysensitive applications become crucial study vulnerabilities systems. dalvi show adversarial manipulations input data often result incorrect predictions classiﬁers. raises serious concerns regarding security integrity existing machine learning algorithms especially even state-of-the-art models including deep neural networks shown highly vulnerable adversarial attacks intentionally worst-case perturbations input adversaries generated effectively access gradients target models resulting much higher successful attack rates data perturbed random noise even larger magnitude. further training models including adversaries provide machine learning models additional regularization beneﬁts although adversarial examples expose blind spots machine learning models unnatural i.e. worst-case perturbed instances ones classiﬁer likely face deployed. this difﬁcult gain helpful insights fundamental decision behavior inside black-box classiﬁer decision different adversary change order prevent behavior classiﬁer robust natural variations data adversarial scenario? moreover often mismatch input space semantic space understand. changes input think meaningful like slight rotation translation images often lead substantial differences input instance. example show minimal changes lighting conditions fool automated-driving systems behavior adversarial examples unable discover. unnatural perturbations approaches cannot applied complex domains language enforcing grammar semantic similarity difﬁcult perturbing instances. therefore existing approaches adversarial examples text often result ungrammatical sentences examples generated require manual intervention liang paper introduce framework generate natural adversarial examples i.e. instances meaningfully similar valid/legible helpful interpretation. primary intuition figure adversarial examples. given instance existing fgsm approach adds small perturbations change prediction model instead random-looking noise framework generates natural adversarial examples differences shown meaningful changes strokes. behind proposed approach perform search adversaries dense continuous representation data instead searching input data space directly. generative adversarial networks learn projection normally distributed ﬁxed-length vectors data instances. given input instance search adversaries neighborhood corresponding representation latent space sampling within range recursively tightened. figure provides example adversaries digit recognition. given multi-layer perceptron mnist image test data approach generates natural adversarial example classiﬁed incorrectly classiﬁer. compared adversary generated existing fast gradient sign method adds gradient-based noise adversary looks like hand-written digit similar original input. further difference provides insight classiﬁer’s behavior fact slightly thickening bottom stroke thinning fools classiﬁer. apply approach image text domains generate adversaries natural grammatical semantically close input helpful interpret local behavior black-box models. present examples natural adversaries image classiﬁcation textual entailment machine translation. experiments human evaluation also demonstrate approach help evaluate robustness black-box classiﬁers even without labeled training data. section describe problem setup details framework generating natural adversarial examples continuous images discrete text data. given black-box classiﬁer corpus unlabeled data goal generate adversarial example given data instance results different prediction i.e. general instance comes underlying distribution distribution want generate well. want nearest instance terms manifold deﬁnes data distribution instead original data representation. unlike existing approaches search directly input space adversaries propose search corresponding dense representation space. words instead ﬁnding adversarial directly adversarial underlying dense vector space deﬁnes distribution back help generative model. searching samples latent low-dimensional space mapping space identify adversaries encourage adversaries valid semantically close original input. background generative adversarial networks tackle problem described above need powerful generative models learn mapping latent low-dimensional representation distribution estimate using samples gans class generative models trained procedures minimax game competing networks given large amount unlabeled instances training data generator learns noise distribution synthetic data close training data possible; hand critic trained discriminate output generator real data samples original objective function gans found hard optimize practice reasons theoretically investigated arjovsky bottou arjovsky reﬁne objective wasserstein- distance ex∼px] ez∼pz)]. wasserstein achieves improvement stability learning provides useful learning curves. number improvements framework introduced discuss section incorporate structure wgan relevant improvements part framework generating natural examples close training data distribution describe next. natural adversaries order represent natural instances domain ﬁrst train wgan corpus provides generator maps random dense vectors samples domain separately train matching inverter data instances corresponding dense representations. figure minimize reconstruction error divergence sampled encourage latent space normally distributed instead perturb dense representation generator test whether perturbation fools classiﬁer querying figure shows generation process. synthetic example included intuition appendix divergence distance images jensen-shannon distance text data. search algorithms propose approaches identify adversary utilize inverter obtain latent vector feed perturbations neighborhood generator generate natural samples iterative stochastic search incrementally increase search range within perturbations randomly sampled generated samples change prediction. among samples choose closest original adversarial example improve efﬁciency beyond naive search propose coarse-to-ﬁne strategy call hybrid shrinking search ﬁrst search adversaries wide search range recursively tighten upper bound search range denser sampling bisections. extra iterative search steps taken figure natural adversary generation. given instance framework generates natural adversaries perturbing inverted decoding perturbations query classiﬁer table adversarial examples mnist. shows images original test data others show corresponding adversaries generated fgsm lenet approach lenet. predictions classiﬁer shown corner image. tighten upper bound optimal hybrid shrinking search algorithm observe speedup achieving similar results algorithm search algorithms sample-based applicable black-box classiﬁers need access gradients. further guaranteed adversary i.e. upper bounds optimal adversary. image classiﬁcation focus adversarial example generation recent successes computer vision. apply approach standard datasets mnist lsun present generated natural adversaries. model details appendix handwritten digits scans human-written text provide intuitive deﬁnition natural i.e. generated images look like something person would write? words would human change digit order fool classiﬁer? train wgan mnist images following similar procedures gulrajani generator consisting transposed convolutional layers critic consisting convolutional layers. include inverter fully connected layers critic’s last hidden layer. train target classiﬁers generate adversaries against random forests trees lenet trained lecun treat classiﬁers black-boxes present generated adversaries table examples digit adversaries generated fgsm look like original digits eroded uninterpretable noise natural adversaries classiﬁers quite similar original inputs overall style shape provide informative insights classiﬁers’ decision behavior around input. take digit example dimming vertical stroke fool lenet predicting observe adversaries often look closer original images overall shape lenet. although generating impressive natural adversaries accurate lenet difﬁcult implies compared lenet requires substantial changes inputs fooled; words less robust lenet classiﬁcation. return observation later. church tower apply approach outdoor color images higher resolution. choose category church outdoor lsun dataset randomly sample amount images category tower resize resolution table textual entailment. pair premise hypothesis present generated adversaries three classiﬁers perturbing hypothesis last column provides true label followed changes prediction classiﬁer. training procedure similar mnist except generator critic wgan deep residual networks train classiﬁer classes test accuracy table presents original images classes corresponding adversarial examples. looking pairs observe generated adversaries make changes natural domain. example change classiﬁer’s prediction church tower adversaries sharpen roof narrow buildings change tree tower. observe similar behavior direction image eiffel tower changed church converting woman building narrowing tower. generating grammatical linguistically coherent adversarial sentences challenging task discrete nature text adding imperceptible noise impossible actual changes result grammatical text. prior approaches generating textual adversaries perform word erasures replacements directly text input space using domain-speciﬁc rule based heuristic based approaches require manual intervention. approach hand performs perturbations continuous space trained produce semantically syntactically coherent sentences automatically. adversarially regularized autoencoder encoding discrete text continuous codes. arae model encodes sentence lstm encoder continuous code performs adversarial training codes capture data distribution. introduce inverter maps continuous codes gaussian space -layer strided encoder yields coherent sentences lstms arae model however lstm works well decoder. train models generator inverter learn mappings noise continuous codes. train framework stanford natural language inference data labeled human-written english sentence pairs preprocessing zhao using present details architecture sample perturbations appendix textual entailment textual entailment task designed evaluate common-sense reasoning language requiring natural language understanding logical inferences text snippets. task classify pair sentences premise hypothesis three categories depending whether hypothesis entailed premise contradicts premise neutral generated translation leute einem restaurant essen sitzen. leute einem wohnzimmeressen sitzen. altere menschen eine stadtstraße hinuntergehen. mann eine straße entlang spielt. instance sentence there children present entailed sentence children smiling waving camera sentence kids frowning contradicts approach generate adversaries perturbing hypothesis deceive classiﬁers keeping premise unchanged. train three classiﬁers varying complexity namely embedding classiﬁer single layer average word embeddings lstm based model consisting single layer sentence representations treelstm uses hierarchical lstm parses top-performing classiﬁer task. examples comparing three classiﬁers shown table although classiﬁers correctly predict label classiﬁers accurate require much substantial changes sentences fooled. machine translation consider machine translation successful applications neural approaches also since practical translation systems behind black-box access apis. notion adversary however clear output translation system class. instead deﬁne adversary machine translation relative probing function tests translation certain properties ones lead linguistic insights languages detect potential vulnerabilities. generator inverter entailment adversaries access currently deployed google translate model english german. first consider scenario want generate adversarial english sentences speciﬁc german word introduced german translation. probing function would test translation presence word would found adversary probing function passes translation. provide example probing function introduces word stehen translation table since translation system quite strong adversaries surfacing vulnerabilities model instead used tool understand learn different languages design complex probing functions well especially ones target speciﬁc vulnerabilities translation system. consider translations english sentences contain active verbs e.g. people sitting restaurant eating german translation verbs well essen sitzen respectively. deﬁne probing function passes perturbed english sentence contains verbs translation them. adversary probing function english sentence similar original sentence reason translation missing verbs. table presents examples generated adversaries using probing function example tests whether essen dropped translation english counterpart eating appears source sentence adversaries thus suggest vulnerability google’s english german translation system word acting gerund english often gets dropped translation. table statistics adversaries models mnist include average adversaries proportion classiﬁer’s adversary largest compared others instance higher values correspond stronger robustness demonstrated higher test accuracy. test accuracy figure classiﬁer accuracy average adversaries. vary number neurons dropout rate respectively. present correlation accuracy average different classiﬁers. shows adversaries input image classiﬁers single hidden layer varying number neurons. section demonstrate approach utilized compare evaluate robustness black-box models even without labeled data. present experimental results images text data evaluations statistical analysis pilot user studies. robustness black-box classiﬁers apply framework various black-box classiﬁers images text observe useful evaluating interpreting models comparisons. primary intuition behind analysis accurate classiﬁers often require substantial changes instance change predictions noted previous section. following experiments apply efﬁcient hybrid shrinking search order quantify extent change adversary change original representation meaningful rmse pixels string edit distances reason generating natural adversaries correspond semantic distance underlying data manifold. instead distance adversary latent space i.e. order measure much adversary modiﬁed change classiﬁer prediction. also consider adversaries generated instance group classiﬁers count many times adversary classiﬁer highest present statistics table mnist textual entailment classiﬁers described section tasks observe accurate classiﬁers require larger changes inputs indicating generating adversaries even unlabeled data evaluate accuracy black-box classiﬁers. consider evaluation broader classiﬁers study effect changing hyperparameters models results train neural networks hidden layer varying number neurons exponentially figure observe average adversaries models similar trend test accuracy. generated adversaries single digit figure verify observation adversaries become increasingly different original input classiﬁers become complex. provide similar analysis ﬁxing model structure varying dropout rates figure observe similar trend. conﬁrm correlation holds generally train total classiﬁers differ layer sizes regularization amount training data plot test accuracy average magnitude change adversaries figure given strong correlation conﬁdent framework generating natural adversaries useful automatically evaluating black-box classiﬁers even absence labeled data. human evaluation carry pilot study human subjects evaluate natural generated adversaries whether adversaries think similar original ones correspond less accurate classiﬁers image classiﬁcation textual entailment select number instances randomly generate adversaries classiﬁers present questionnaire subjects evaluates natural legible generated adversary adversaries closer original instance. hand-written digits mnist pick images generate adversaries lenet obtain responses questions. table subjects agree generated adversaries quite natural also adversaries much closer original image lenet also compare adversaries lenet generated fgsm approach time subjects agree adversaries make changes original images natural carry similar pilot study textual entailment task evaluate quality perturbed sentences. present pairs sentences adversarial hypotheses lstm treelstm classiﬁers receive responses questions above. results table also validate previous results generated sentences found grammatical legible classiﬁers need substantial changes hypothesis tend accurate. leave detailed user study future work. fast gradient sign method proposed goodfellow generate adversarial examples fast rather optimally. intuitively method shifts input direction minimizing cost function. kurakin propose simple extension fgsm applying multiple times generates adversarial examples higher attack rate underlying idea same. another method known jacobian-based saliency attack introduced papernot unlike fgsm jsma generates adversaries greedily modifying input instance feature-wise. saliency computed gradients indicate important feature prediction important modiﬁed repeatedly instance changes resulting classiﬁcation. moreover observed practice adversarial examples designed model often likely successfully attack another model task given access transferability property adversarial examples makes practical attack evaluate deployed machine learning systems realistic scenarios data points meanwhile reduce classiﬁer accuracy signiﬁcantly. method capable generating adversaries black-box classiﬁers even without gradients random forests. also noise added methods uninterpretable natural adversaries generated approach provide informative insights classiﬁers’ decision behavior. discrete domains involved text adversaries text received less attention. liang generate adversarial examples evaluating reading comprehension systems predeﬁned rules candidate words substitution analyzing rephrasing input sentences. introduce framework understand neural network different levels representation erasure. however erasure words phrases directly often harms text integrity resulting semantically grammatically incorrect sentences. ribeiro replace tokens random words probability proportional embedding similarity. belinkov bisk explore approaches increase robustness character-based machine translation models text corrupted character-level noise. help expressive generative models approach instead perturbs latent coding sentences resulting legible generated sentences grammatical semantically similar original input. merits make framework suitable text applications sentiment analysis textual entailment machine translation. framework builds upon gans generative models thus capabilities gans directly effects quality generated examples. visual domains although lots appealing results produced gans training well known brittle. many recent approaches address improve training stability objective function gans gulrajani improve training wgan regularization gradient penalty instead weight clipping. practice observe need carefully balance capacities generator critic inverter introduced avoid situations model collapse. natural languages discrete nature non-differentiability applications related text generation relatively less studied. zhao propose incorporate discrete structure autoencoder continuous code space regularized wgan text generation. given concerns whether gans actually learn distribution worth noting also incorporate generative models variational auto-encoders framework used generate text controllable attributes explore future. focus gans adversarial training often results higher quality images vaes tend produce blurrier ones also plan apply fusion variant vaes gans α-gan rosca wasserstein auto-encoders tolstikhin note advanced gans introduced address issues directly incorporated framework. iterative stochastic search algorithm identifying adversaries computationally expensive since based naive sampling local-search. search based gradients fgsm applicable setup black-box classiﬁers discrete domain applications. improve efﬁciency hybrid shrinking search using coarse-to-ﬁne strategy ﬁnds upper-bounds using fewer samples performs ﬁner search restricted range. observe around speedup search achieving similar results iterative search. accuracy inverter mapping input corresponding dense vector latent space also important searching adversaries right neighborhood. experiments ﬁne-tuning latent vector produced inverter ﬁxed reﬁne generated adversarial examples investigate extensions search future. implicit assumption work generated samples within class added perturbations small enough generated samples look belong different classes perturbations large. however note also case fgsm approaches small noise imperceptible; large often ﬁnds noisy instances might different class observe behavior cases corresponding classiﬁers require much substantial changes input utilize approach evaluate black-box classiﬁers. paper propose framework generating natural adversaries black-box classiﬁers apply approach visual textual domains. obtain adversaries legible grammatical meaningfully similar input. show natural adversaries help interpreting decision behavior evaluating accuracy black-box classiﬁers even absence labeled training data. approach built upon recent work gans generate adversaries wide range applications including image classiﬁcation textual entailment machine translation code used generate natural adversaries available https//github.com/zhengliz/natural-adversary. would like thank ananya casey graff eric nalisnick pouya pezeshkpour robert logan anonymous reviewers discussions feedback earlier versions. would also like thank ishaan gulrajani junbo jake zhao making code available. work supported part adobe research part fico. views expressed authors reﬂect ofﬁcial policy position funding agencies. references david alvarez-melis tommi jaakkola. causal framework explaining predictions black-box sequence-to-sequence models. empirical methods natural language processing nilesh dalvi pedro domingos sumit sanghai deepak verma. adversarial classiﬁcation. proceedings sigkdd international conference knowledge discovery data mining ishaan gulrajani faruk ahmed martin arjovsky vincent dumoulin aaron courville. improved training wasserstein gans. advances neural information processing systems nicolas papernot patrick mcdaniel somesh matt fredrikson berkay celik ananthram swami. limitations deep learning adversarial settings. ieee european symposium security privacy nicolas papernot patrick mcdaniel goodfellow somesh berkay celik ananthram swami. practical black-box attacks machine learning. proceedings asia conference computer communications security mihaela rosca balaji lakshminarayanan david warde-farley shakir mohamed. variational approaches auto-encoding generative adversarial networks. arxiv preprint salimans goodfellow wojciech zaremba vicki cheung alec radford chen. improved techniques training gans. advances neural information processing systems christian szegedy wojciech zaremba ilya sutskever joan bruna dumitru erhan goodfellow fergus. intriguing properties neural networks. international conference learning representations fisher yinda zhang shuran song seff jianxiong xiao. lsun construction large-scale image dataset using deep learning humans loop. arxiv preprint shown figure example synthetic data effectively data instance corresponding latent dense vector help inverter reconstruct help generator gθ). naive classiﬁer horizontal line decision boundary adversarial examples points line given input data figure searching corresponding latent space approach ﬁnds left natural adversary closest semantic space exists within data manifold. however gradient-based approaches right adversarial input space regardless actual data distribution. algorithm shows pseudocode iterative search framework. starting corresponding input instance iteratively move search range outward latent space generated samples change prediction classiﬁer improve efﬁciency algorithm using coarse-to-ﬁne strategy combining recursive iterative search. ﬁrst search adversaries wide search range recursively tighten upper bound search range denser sampling bisections. extra iterative search steps taken tighten upper bound optimal hybrid shrinking search approach shown detail algorithm four times faster achieve similar adversaries iterative search. figure shows architecture framework continuous images. adopt wgan objective function equation apply gradient penalty proposed gulrajani generator obtained wgan train inverter optimizing equation handwritten digits mnist dataset train wgan latent generator consisting transposed convolutional layers relu activation critic consisting convolutional layers ﬁlter sizes strides include inverter fully connected layers dimensions critic’s last hidden layer. church outdoor tower images lsun dataset follow similar procedures gulrajani training wgan latent generator critic residual networks. pre-activation residual blocks convolutional layers relu activation. critic residual blocks performs downsampling using mean pooling second convolution generator contains residual blocks performing nearest-neighbor upsampling second convolution. include inverter fully connected layers dimensions critic’s last hidden layer. figure illustration synthetic data. training data lies complex manifold inverter maps input compact gaussian latent generator reconstructs data given binary classiﬁer decision boundary horizontal line input approach returns left natural adversary lies manifold existing approaches right adversary nearest impossible. algorithm iterative stochastic search latent space adversaries require target black-box classiﬁer input instance corpus relevant data hyper-parameters number samples iteration increment search range train generator inverter radius loop algorithm hybrid shrinking search latent space adversaries require target black-box classiﬁer input instance corpus relevant data hyper-parameters number samples iteration increment search range train generator inverter first recursive search then iterative search return adversarially regularized autoencoder encoding discrete text continuous codes shown figure arae model encodes sentence lstm encoder continuous code performs adversarial training codes generated noise data approximate data distribution. introduce inverter maps continuous codes figure model architecture text. model incorporates adversarially regularized autoencoder encoding discrete continuous code decoding continuous discrete generating samples. gaussian space layers varying ﬁlter sizes strides context windows encoding text continuous space decoder single-layer lstm hidden dimension also train mlps generator inverter learn mappings noise continuous codes continuous codes noise respectively. loss functions different components arae model autoencoder reconstruction loss wgan loss functions generator critic described equations respectively. ﬁrst train arae components encoder decoder generator using wgan strategy followed inverter loss function minimizing jensen-shannon divergence inverted continuous codes noise samples. train framework sentences length stanford natural language inference dataset hyper-parameters table shows examples perturbations generated automatically approach grammatical semantically close original sentences. dogs running deserted beach. playing electric guitar stage. dogs running grassy ﬁeld. dogs walking along path. dogs running hill. running grassy ﬁeld. running trail. table textual entailment. pair premise hypothesis present generated adversaries three classiﬁers perturbing hypothesis last column provides true label followed changes prediction classiﬁer. source sentence asian women sitting restraunt. asiatische frauen sitzen einem restaurant. asian kids standing restraunt. asiatische kinder stehen einem restaurant. people sitting ﬂoor. people standing ﬁeld. table adversaries dropped verbs english-to-german translation. left column contains original sentence adversary right column contains translations english translation provided legibility.", "year": 2017}