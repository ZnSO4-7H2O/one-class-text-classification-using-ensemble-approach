{"title": "Task-Guided and Path-Augmented Heterogeneous Network Embedding for  Author Identification", "tag": ["cs.LG", "cs.AI", "cs.IR", "stat.ML"], "abstract": "In this paper, we study the problem of author identification under double-blind review setting, which is to identify potential authors given information of an anonymized paper. Different from existing approaches that rely heavily on feature engineering, we propose to use network embedding approach to address the problem, which can automatically represent nodes into lower dimensional feature vectors. However, there are two major limitations in recent studies on network embedding: (1) they are usually general-purpose embedding methods, which are independent of the specific tasks; and (2) most of these approaches can only deal with homogeneous networks, where the heterogeneity of the network is ignored. Hence, challenges faced here are two folds: (1) how to embed the network under the guidance of the author identification task, and (2) how to select the best type of information due to the heterogeneity of the network.  To address the challenges, we propose a task-guided and path-augmented heterogeneous network embedding model. In our model, nodes are first embedded as vectors in latent feature space. Embeddings are then shared and jointly trained according to task-specific and network-general objectives. We extend the existing unsupervised network embedding to incorporate meta paths in heterogeneous networks, and select paths according to the specific task. The guidance from author identification task for network embedding is provided both explicitly in joint training and implicitly during meta path selection. Our experiments demonstrate that by using path-augmented network embedding with task guidance, our model can obtain significantly better accuracy at identifying the true authors comparing to existing methods.", "text": "heterogeneous networks ubiquitous. examples include bibliographic networks movie recommendation networks many online social networks containing information heterogeneous types different homogeneous counterparts heterogeneous networks contain multiple types nodes and/or links. example bibliographic networks node types include paper author more; link types include author-writepaper paper-contain-keyword fast emerging data problem mining heterogeneous network gained attention past years work interested problem mining heterogeneous bibliographic network speciﬁc consider problem author identiﬁcation double-blind review setting many peer review conferences/journals based. authors paper double-blind review visible reviewers i.e. paper anonymized content/attributes paper visible reviewers. however cases authors paper still unveiled content references provided. affected phenomenon questions exist whether double-blind review process really effective. fact wsdm year also conducts experiment trying answer question. ponder issue formulating author identiﬁcation problem aims designing model automatically identify potential authors anonymized paper. instead dealing full text directly treat information anonymized paper nodes bibliographic network keyword nodes venue nodes reference nodes. illustration problem found figure serving study existing reviewing system problem broader implications general information retrieval recommender system model asked match queried document certain target reviewer recommendation abstract paper study problem author identiﬁcation double-blind review setting identify potential authors given information anonymized paper. different existing approaches rely heavily feature engineering propose network embedding approach address problem automatically represent nodes lower dimensional feature vectors. however major limitations recent studies network embedding usually general-purpose embedding methods independent speciﬁc tasks; approaches deal homogeneous networks heterogeneity network ignored. hence challenges faced folds embed network guidance author identiﬁcation task select best type information heterogeneity network. address challenges propose task-guided pathaugmented heterogeneous network embedding model. model nodes ﬁrst embedded vectors latent feature space. embeddings shared jointly trained according task-speciﬁc network-general objectives. extend existing unsupervised network embedding incorporate meta paths heterogeneous networks select paths according speciﬁc task. guidance author identiﬁcation task network embedding provided explicitly joint training implicitly meta path selection. experiments demonstrate using pathaugmented network embedding task guidance model obtain signiﬁcantly better accuracy identifying true authors comparing existing methods. permission make digital hard copies part work personal classroom granted without provided copies made distributed proﬁt commercial advantage copies bear notice full citation ﬁrst page. copyrights components work owned others author must honored. abstracting credit permitted. copy otherwise republish post servers redistribute lists requires prior speciﬁc permission and/or fee. request permissions permissionsacm.org. wsdm february cambridge united kingdom copyright held owner/author. publication rights licensed acm. isbn ----//. http//dx.doi.org/./. network mining problems good representations data important demonstrated many previous work unlike traditional supervised learning dense vectorized representations directly available networked data hence many traditional methods network settings heavily rely problem speciﬁc feature engineering although feature engineering incorporate prior knowledge problem network structure usually time-consuming problem speciﬁc extracted features simple complicated data sets several network embedding methods proposed automatically learn feature representations networked data. idea behind network embedding learning nodes vector space proximities among nodes preserved. similar nodes expected placed near vector space. purpose embeddings independent tasks usually designed homogeneous networks comes author identiﬁcation problem heterogeneous networks existing embedding methods cannot applied directly. unique challenges brought problem embed network guidance author identiﬁcation task embeddings learned suitable task compared general network embedding. select best type information heterogeneity network. shown previous work proximity heterogeneous networks richer homogeneous counterparts semantic connection nodes likely dependent type connection form. address mentioned challenges propose taskguided path-augmented network embedding method. model nodes ﬁrst embedded vectors. embeddings shared jointly trained according task-speciﬁc networkgeneral objectives author identiﬁcation task objective embeddings used speciﬁcally designed model score possible authors given paper general heterogeneous network embedding objective embeddings used predict neighbors node. combing objectives learned network preserve network structures/proximities well beneﬁcial author identiﬁcation task. better utilize heterogeneous network structure extend existing unsupervised network embedding incorporate meta paths derived heterogeneous networks select useful paths according author identiﬁcation task. compared traditional network embedding method uses author identiﬁcation task explicit guidance inﬂuence network embedding joint learning also implicit guidance select meta paths based network embedding performed. worth mentioning although model originally targeted author identiﬁcation problem also extended task-oriented embedding problems heterogeneous networks. propose task-guided path-augmented heterogeneous network embedding framework applied author identiﬁcation problem double-blind review setting many tasks. demonstrate effectiveness task guidance network embedding speciﬁc task interest; also show usefulness meta-path selection heterogeneous network embedding. section ﬁrst introduce concept heterogeneous networks meta paths introduce embedding representation nodes. finally formal deﬁnition author identiﬁcation problem given. heterogeneous networks deﬁnition heterogeneous network deﬁned network multiple types nodes and/or multiple types links. denoted nodes links. heterogeneous network also associated node type mapping function maps node predeﬁned node type link type mapping function maps link predeﬁned link type. worthing noting link type automatically deﬁnes node types ends. bibliographic network seen heterogeneous network centered paper information paper represented neighboring nodes. node types network include paper author keyword venue year link types include author-write-paper paper-contain-keyword network schema shown figure deﬁnition meta path path deﬁned network schema denoted form lm−−→ represents compositional relations given types. meta path deﬁne adjacency matrix cardinality equal number nodes denote connectivity nodes meta path. multiple meta paths considered given network adjacency matrices represent examples meta paths deﬁned network schema figure include paper keyword paper paper year paper. examples easy heterogeneous network even compare nodes type going different paths lead different semantic meanings. embedding representation nodes computational summarized figure note ﬁnal densely-connected layer bias term thus weight matrix seen author node embeddings. ﬁnal layer output score vector candidate authors. positive number usually referred margin loss penalty incur score positive pair least larger score sample triple used randomly select paper author sample negative author pre-deﬁned noise distribution discrete distribution based author degree author path-augmented general heterogeneous existing network embedding techniques based idea that embeddings nodes learned neighbor prediction predict neighborhood given node i.e. linking probability node node existing network embedding methods observed neighborhood node usually deﬁned original network random walk original network heterogeneous network easily enrich semantic neighbors considering different types meta paths shown different meta paths encode different semantic given users hard calculate similarity distance directly. obtain better data representation embedding methods widely adopted nodes network mapped common latent feature space. embedding measure similarity/distance nodes directly based arithmetic operations like product embedding vectors. paper matrix represent embedding table nodes. size matrix total number nodes number dimensions. feature vector node denoted ddimensional vector. author identiﬁcation problem networks network schema shown figure paper represent neighbors given network neighbor nodes t-th node type. node types include keyword reference venue year task. denote true authors paper author identiﬁcation problem. given papers represented {xp} {ap} goal learn model rank potential authors every anonymized paper based information ranked authors section introduce proposed model details. model composed major components author identiﬁcation based task-speciﬁc embedding path-augmented general network embedding. ﬁrst introduce separately combine single uniﬁed framework meta paths selected according author identiﬁcation task. task-speciﬁc embedding author idensubsection propose supervised embedding-based model rank potential authors given information paper model ﬁrst maps node latent feature space gradually builds feature representation anonymized paper based observed neighbors network. finally aggregated paper representation used score potential author. stages aggregation build feature representation paper based node embeddings. ﬁrst stage builds feature vector t-th node type averaging node embeddings work. former focuses direct information related speciﬁc task latter better explore global diverse information heterogeneous information network. motivates model single uniﬁed framework. sub-models combined levels follows. joint objective formed combining task-speciﬁc network-general objectives joint learning performed. task serves explicit guidance network embedding. meta paths used network-general embedding selected according author identiﬁcation task. task provides implicit guidance network embedding helps select meta paths. joint objective function deﬁned weighted linear combination sub-models regularization term embedding embedding vectors shared submodels =ltask−specif ωlnetwork−general trade-off factor task-speciﬁc networkgeneral components. network-general embedding used; supervised embedding used. regularization term added avoid over-ﬁtting. optimize objective utilize asynchronous stochastic gradient descent samples randomly drawn training performed parallel challenge different tasks learn different data sources. solve problem design sampling based task scheduler. basically worker ﬁrst draws task according draws samples selected task update parameters according samples. order reduce task sampling overhead selected task trained mini-batch data samples instead single sample. sample mini-batch triplets sample negative nodes update parameters according gradients sample mini-batch triplets update parameters according gradients links. example connections authors encode multiple similarities interested topic associated afﬁliation. clearly types connections indicate different semantics. inspired phenomenon generalize existing network embedding techniques incorporate different meta paths propose path-augmented network embedding. path augmented network embedding instead using original adjacency matrices original link type onehop meta path consider meta paths meta path-augmented adjacency matrices network embedding indicates network connectivity under speciﬁc meta path normalize learned embedding dominated meta paths large weights. since inﬁnite many potential meta paths considered network embedding select limited number useful meta paths. selection meta paths discussed next sub-section assume collection meta paths selected now. learn embeddings preserve proximities among nodes induced meta paths follow neighbor prediction framework model conditional neighbor distribution nodes. heterogeneous networks multiple types paths starting node neighbor distribution node conditioned node given path type deﬁned follows negative node sampled pre-deﬁned noise path total negative nodes distribution sampled positive node furthermore bias term added adjust densities different paths. learn parameters adopt stochastic gradient descent goal maximizing likelihood function. training procedure given follows. ﬁrst sample path uniformly randomly sample link according weights negative nodes used also sampled according pre-deﬁned smoothed\" node degree distribution speciﬁc edge type finally parameters updated according gradients approximated sample log-likelihood maximized. combined model task-speciﬁc embedding sub-model path-augmented general embedding sub-model capture different perspectives netthe noise distribution returns nodes type speciﬁed end-point path rithm efﬁcient iteration thread major components edge negative node sampling take constant time alias table gradient update linear w.r.t. number links number embedding dimensions. thirdly mini-batch reasonable size overhead switching tasks ignorable. meta path selection implicit guidance potential meta paths induced heterogeneous network inﬁnite every relevant useful speciﬁc task interest. utilize author identiﬁcation task guidance help select meta paths best help task hand. path selection problem formulated given pre-deﬁned candidate paths r··· want select subset paths rselected certain utility maximized. since ﬁnal goal author identiﬁcation task deﬁne utility generalization performance task. worth noting problem neither differentiable continuous. total number combinations exponential number candidate paths. employ following steps select relevant paths greedy fashion. greedy additive path selection. sort paths according performance obtained step above gradually paths selected pool. experiments additive combination paths path combination best performance selected. need experiments times means number candidate paths. since every experiment takes minutes case selection scheme affordable avoid exponential number combinations. aminer citation network used throughout experiments. prepare evaluation split papers training test according publication time. papers published treated training papers published treated test set. based training papers heterogeneous bibliographic network extracted. ﬁrst extract papers contain information title authors references venue dataset. extract keywords combining unigram phrases extracted using method proposed schema network figure meta paths augmentation. length- paths presented original network also consider various length- meta paths candidate paths general heterogeneous network embedding. although path similarity measures explored simplicity weights path number path instances. example attended twice jack attended three times path jack weight six. augmented network adding meta paths hundreds millions links much original network. many candidate paths symmetric contain different information sides consider directions. finally detailed statistics length- paths presented table better understand statistics network„ figure shows three different types degree distributions papers. seen ﬁgure papers contain quite sparse information authors references keywords medium authors reference keywords. lack information makes problem automatic author identiﬁcation even harder. baselines experimental settings supervised feature-based baselines. widely used similar author identiﬁcation/disambiguation problems thread methods ﬁrst extract features pair training data applies supervised learning algorithm learn ranking/classiﬁcation functions. following them extract related features pair paper author training since original network contains true paper-author pairs order negative samples paper-author pair sampled negative pairs randomly replacing authors. supervised algorithm consider logistic regression support vector machines random forests lambdamart methods grid search best hyper-parameters regularization penalty maximum depth trees ﬁrst report experimental results path selection since selected paths used joint training model. candidate paths consider length- length- paths presented table paths total. introduced section greedy algorithm involving stages used path selection single path performance evaluation additive path selection. performance single meta-path used network-general embedding. plot indicates performance author prediction task validation dataset. horizontal line indicates performance task-speciﬁc embedding model. note paths sorted according performance paths help improve author identiﬁcation task shown ﬁgure. figure shows results additive path selection demonstrate performance combined model metapaths added gradually. graph shows performance joint model based speciﬁc additive selection paths. single path added network-general embedding sequentially according rank single path performance experiments. example third label +pa\" includes three paths a-p-p a-p-w p-a. observe author identiﬁcation performance grow ﬁrst during ﬁrst several additive selection paths starts decrease paths. suggests ﬁrst several paths relevant helpful latter ones less relevant noisy thus harmful network-general embedding. also veriﬁes hypothesis heterogeneous network embedding based different meta paths lead different based general heterogeneous network embedding learned embeddings used score author task-speciﬁc author identiﬁcation framework. since directly combined author identiﬁcation task cannot perform path selection speciﬁc task. default paths used embedding original network i.e. length- paths. length- paths method form pre-training task-speciﬁc embedding. pre-training found useful improve neural network based supervised learning instead training task-speciﬁc author identiﬁcation randomly initialized embedding vectors ﬁrst pre-train embedding nodes using networkgeneral embedding initialize supervised embedding training pre-trained embedding vectors. candidate authors. million authors training data total number candidate authors paper large. supervised feature-based baselines cannot scale large amount candidate time consuming storage intensive extract store features candidate paper-author pairs hence conduct comparisons mainly based sub-sampled author candidate randomly sample negative authors combined true authors paper form candidate total authors. completeness also provide quantitative qualitative comparisons different embedding methods whole candidate million authors. since author identiﬁcation problem posed ranking problem usually returned results interest adopt commonly used ranking metrics mean average precision recall investigate impact using different meta paths learning embeddings prediction task consider several types paths original length- network paths presented network schema figure augmented paths combining length- length- paths selected paths procedure. table shows results different embedding models trained based pre-given meta paths. observe adding length- paths results actually become worse might irrelevant noisy paths. however mean consider augmented paths unnecessary. using greedy selected paths length- length- paths performance models improved demonstrate path selection play important role learning task-related embeddings. performance comparison baselines table shows performance comparison baselines proposed method. pre-train network-general model access task-speciﬁc path selection original length- network paths used. method signiﬁcantly outperforms baselines including supervised feature-based baselines variants embedding methods. surprise task-speciﬁc embedding model performs quite badly without pre-trained embedding vectors signiﬁcantly lower methods. conjecture overﬁtting largely alleviated pre-training joint learning unsupervised network-general embedding. examine superior performance method compared traditional methods group papers medium author degrees report results groups. figure shows method outperforms baseline methods almost groups papers signiﬁcantly papers less frequent authors. suggests method better understand authors fewer links. traditional feature based methods difﬁcult extract useful information/feature them model still utilize propagation authors learn useful embeddings them. whole author candidate set. test real-world author prediction setting also conduct evaluation whole candidate including million authors variants embedding methods. compare embedding methods supervised feature based methods cannot scale whole candidate set. results shown figure large candidate thus longer evaluation time randomly sample test papers single experiment results averaged experiments. observe that among variants embedding methods combined method consistently outperforms variants. case studies show types case studies demonstrate performance differences proposed method variants author degree calculated based number papers he/she published training data. embedding methods. ﬁrst type case study shows ranking authors given terms used learned embedding nodes make sense. second type case study shows ranking authors given information anonymized paper original task. table shows ranking authors given term variational inference\". results returned authors combined methods reasonable followed general network embedding. task-speciﬁc embedding model sometimes give less reasonable results. table shows ranked authors selected papers. since information provided paper quite limited number whole candidate author million many true authors presented list. however combined method predict true authors accurately methods. also authors returned list related paper’s topic true authors sensible consider potential authors paper. parameter study efﬁciency test study hyper-parameters trade-off term combing task-speciﬁc embedding network-general embedding. result shown figure best performance obtained objectives combined appropriately. model trained efﬁciently multi-core parallelization. experiments conducted desktop core memory. experiments embedding methods ﬁnished minutes. conduct quantitatively experiment compare times training speedversus number threads used figure almost network-general whye mohammad khan edward challis ruslan salakhutdinov michael jordan zoubin ghahramani matthias seeger david dunson pradeep ravikumar combined michael jordan whye zoubin ghahramani john william paisley david blei welling alexander ihler eric xing ryan prescott adams thomas grifﬁths although severe lack information papers embedding based algorithm still identify true authors reasonable accuracy ranks even million candidate authors. believe model improved utilizing complete information incorporating advanced text understanding techniques. near future human expert still much accurate identifying authors paper he/she familiar with algorithms much better paper less familiar domains. interesting observation figure table that authors higher number past publications easier algorithm predict authors publication records substantially harder. suggests highly-visible authors easier detect relatively junior researchers harder identiﬁed. perspective think cording author identiﬁcation task. guidance provided learning network embedding explicitly joint objective implicitly path selection. experiments demonstrate usefulness meta paths heterogeneous network embedding show combining tasks model obtain signiﬁcantly better accuracy identifying true authors comparing existing methods. potential future work includes author prediction interactions authors considered prediction task deeper analysis text given full text papers given. gradient descent. proceedings international conference computational statistics chang tang g.-j. aggarwal huang. heterogeneous network embedding deep architectures. proceedings sigkdd international conference knowledge discovery data mining sydney embedding-based anomaly detection heterogeneous categorical events. proceedings twenty-fifth international joint conference artiﬁcial intelligence miami c.-l. y.-c. t.-w. c.-h. tsai w.-c. chang k.-h. huang t.-m. s.-w. y.-s. y.-c. combination feature engineering ranking models paper-author identiﬁcation proceedings workshop many work devoted mining heterogeneous networks past years study networks multiple types nodes and/or links meta paths proposed studied many existing work mining heterogeneous networks rely feature engineering adopt embedding methods automatic feature learning. network embedding also attracts lots attentions recent years many methods technically inspired word embedding different traditional graph embedding methods multi-dimensional scaling isomap laplacian eigenmap network embeddings scalable shown better performance existing network embedding methods based homogeneous network others based heterogeneous networks work extends existing embedding methods leveraging meta paths heterogeneous networks supervised task guide selection meta paths. problem author identiﬁcation brieﬂy studied before also notice similar author identiﬁcation/disambiguation problem participants asked predict paper truly written author. however different setting different sense existing authors unknown double-blind setting consider reference paper important sources information. similar problems social information networks also studied collaboration prediction major difference work methodology methods mostly based heavy feature engineering adopt automatic feature learning. paper study problem author identiﬁcation under double-blind review setting posed author ranking problem heterogeneous networks. embed network under guidance author identiﬁcation task better exploit heterogeneous networks multiple types nodes links propose task-guided path-augmented heterogeneous network embedding model. model nodes ﬁrst embedded vectors latent feature space. embeddings shared jointly trained task-speciﬁc network-general objectives. extend existing unsupervised network embedding incorporate meta paths heterogeneous networks select paths acquality phrases massive text corpora. proceedings sigmod international conference management data melbourne mikolov chen corrado dean. efﬁcient estimation word representations vector space. arxiv preprint arxiv. zhang semantic path based personalized recommendation weighted heterogeneous information networks. proceedings international conference information knowledge management melbourne co-author relationship prediction heterogeneous bibliographic networks. international conference advances social networks analysis mining taiwan aggarwal chawla. happen? relationship prediction heterogeneous information networks. proceedings ﬁfth international conference search data mining seattle pathselclus integrating meta-path selection user-guided object clustering heterogeneous information networks. transactions knowledge discovery data zhang h.-j. zhang yang lin. graph embedding extensions general framework dimensionality reduction. ieee transactions pattern analysis machine intelligence sturt khandelwal norick han. personalized entity recommendation heterogeneous information network approach. proceedings international conference search data mining york city traditional supervised models consider author features paper-author paired features ranking authors given paper. follows ﬁrst show author features utilized. paper references related number references cited author ratio references cited author number author’s citations references ratio author’s citations references number references written author ratio references written author ratio author’s papers references paper words related number shared word number unique shared word ratio shared words ratio unique shared words paper venue related whether author attend venue number times author attend venue ratio times author attend venue paper year related number papers author published last years ratio papers author published last years", "year": 2016}