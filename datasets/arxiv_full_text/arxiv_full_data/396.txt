{"title": "Learning Discriminative Features via Label Consistent Neural Network", "tag": ["cs.CV", "cs.LG", "cs.MM", "cs.NE", "stat.ML"], "abstract": "Deep Convolutional Neural Networks (CNN) enforces supervised information only at the output layer, and hidden layers are trained by back propagating the prediction error from the output layer without explicit supervision. We propose a supervised feature learning approach, Label Consistent Neural Network, which enforces direct supervision in late hidden layers. We associate each neuron in a hidden layer with a particular class label and encourage it to be activated for input signals from the same class. More specifically, we introduce a label consistency regularization called \"discriminative representation error\" loss for late hidden layers and combine it with classification error loss to build our overall objective function. This label consistency constraint alleviates the common problem of gradient vanishing and tends to faster convergence; it also makes the features derived from late hidden layers discriminative enough for classification even using a simple $k$-NN classifier, since input signals from the same class will have very similar representations. Experimental results demonstrate that our approach achieves state-of-the-art performances on several public benchmarks for action and object category recognition.", "text": "hand unlike large-scale diverse static image data annotated data action recognition tasks usually insufﬁcient since annotating massive videos prohibitively expensive. therefore limited annotated data learning discriminative features deep neural network lead severe overﬁtting slow convergence. tackle issues previous works introduced effective practical techniques relu drop-out improve performance neural networks considered directly improving discriminative capability neurons. features learned backpropagating prediction error output layer hidden layers receive direct guidance class information. worse deep networks early hidden layers often suffer vanishing gradients leads slow optimization convergence network converging poor local minimum. therefore quality learned features hidden layers might potentially diminished tackle problems propose supervised deep neural network label consistent neural network learn discriminative features recognition. approach provides explicit supervision i.e. label information late hidden layers incorporating label consistency constraint called discriminative representation error loss combined classiﬁcation loss form overall objective function. beneﬁts approach two-fold explicit supervision hidden layers problem vanishing gradients alleviated faster convergence observed; discriminative late hidden layer features lead increased discriminative power classiﬁers output layer; interestingly learned discriminative features alone achieve good classiﬁcation performance even simple k-nn classiﬁer. practice formulation easily incorporated neural network trained using backpropagation. approach evaluated publicly available action object recognition datasets. although present experimental results action object recognition method applied tasks image retrieval compression restorations etc. since generates class-speciﬁc compact representations. deep convolutional neural networks enforce supervised information output layer hidden layers trained back propagating prediction error output layer without explicit supervision. propose supervised feature learning approach label consistent neural network enforces direct supervision late hidden layers novel way. associate neuron hidden layer particular class label encourage activated input signals class. speciﬁcally introduce label consistency regularization called discriminative representation error loss late hidden layers combine classiﬁcation error loss build overall objective function. label consistency constraint alleviates common problem gradient vanishing tends faster convergence; also makes features derived late hidden layers discriminative enough classiﬁcation even using simple k-nn classiﬁer since input signals class similar representations. experimental results demonstrate approach achieves state-of-the-art performances several public benchmarks action object category recognition. convolutional neural networks exhibited impressive performances many computer vision tasks image classiﬁcation object detection image retrieval large amounts training data available automatically learn hierarchical feature representations discriminative previous hand-crafted ones encouraged impressive performance static image analysis tasks several cnn-based approaches developed action recognition videos although promising results reported advantages approaches traditional ones overwhelming videos static images. compared static images videos larger variations appearance well high complexity introduced temporal evolution makes learning features recognition videos challenging. adding explicit supervision late hidden layers discriminative representation error lcnn learns discriminative features resulting better classiﬁer training output layer. representations generated late hidden layers discriminative enough achieve good performance using simple classiﬁer. label consistency constraint alleviates problem vanishing gradients leads faster convergence training especially limited training data available. achieve state-of-the-art performance several action object category recognition tasks compact class-speciﬁc representations generated lcnn directly used applications. cnns achieved performance improvements traditional hand-crafted features image recognition detection retrieval etc. availability large-scale image datasets recent technical improvements relu drop-out convolution batch normalization data augmentation based random ﬂipping jittering contrast normalization helps speed convergence avoiding overﬁtting. alexnet initiated dramatic performance improvements static image recognition current state-of-the-art performance obtained deeper sophisticated network architectures vggnet googlenet recently researchers applied cnns action event recognition videos. initial approaches image-trained models extract frame-level features aggregate video-level descriptors recent work trains cnns using video data focuses effectively incorporating temporal dimension learning good spatial-temporal features automatically two-stream cnns perhaps successful architecture action recognition currently. consist spatial trained video frames temporal trained optical ﬁelds. streams capturing spatial temporal information separately late fusion produces competitive action recognition results. obtained performance gain exploring deeper two-stream network architectures reﬁning technical details; achieved stateof-the-art action recognition integrating two-stream cnns improved trajectories fisher vector encoding. also worth comparing lcnn limited prior work aims improve discriminativeness learned features. performs greedy layer-wise supervised pre-training initialization ﬁne-tunes parameters layers together. work introduces supervision intermediate layers part objective function during training optimized backpropagation integrated rather layer-wise greedy pretraining ﬁne-tuning. replaces output softmax layer error-correcting coding layer produce error correcting codes network output. network still trained back-propagating error output direct supervision added hidden layers. deeply supervised introduces classiﬁer hidden layer ﬁnal objective function linear combination prediction losses hidden layers output layer. using all-layer supervision balancing multiple losses might challenging network non-trivial tune since classiﬁer output layer used test time effects classiﬁers hidden layers difﬁcult evaluate. similarly also adds identiﬁcation veriﬁcation supervisory signals hidden layer extract face representations. work instead adding prediction loss hidden layer introduce novel representation loss guide format learned features late hidden layers only since early layers cnns tend capture lowlevel edges corners mid-level parts shared across categories late hidden layers class-speciﬁc denote training sample label layers denote output layer objective function. input data output network. therefore network architecture concisely expressed represents network parameters layer linear operation {w}i=...n; non-linear activation function prediction error softmax loss. network trained figure example lcnn structure. label consistency module added hidden layer fully-connected layer fcl. representation transformed output transformed representation layer fcl+.. note applicability proposed label consistency module limited fully-connected layers. sparse representation classiﬁcation assumes testing sample well represented training samples class similarly dictionary learning recognition maintains label information dictionary items training order generate discriminative classspeciﬁc sparse codes neural network representation certain layer generated neuron activations layer. class distribution neuron highly peaked class enforces label consistency constraint neuron. leads discriminative representation learned class-speciﬁc neurons. observed early hidden layers tend capture low-level features shared across categories edges corners late hidden layers class-speciﬁc improve discriminativeness features lcnn adds explicit supervision late hidden layers; speciﬁcally associate neuron certain class label ideally neuron activate sample corresponding class presented. label consistency constraint neurons lcnn imposed introducing discriminative representation error loss late hidden layers form part objective function training. equation classiﬁcation error output layer discriminative representation error equation discussed detail below hyper parameter balancing terms. suppose want supervision layer. denote training sample corresponding representation produced layer deﬁned activations neurons layer. discriminative representation error deﬁned difference transformed representation ideal discriminative representation rnl×nl linear transformation matrix binary vector nl]t denotes ideal discriminative representation indicates ideal activations neurons neuron associated certain class label ideally activates samples class. therefore sample class neuron assigned class neurons associated classes activated corresponding entry zero. notice parameter needed learned pre-deﬁned based label information training data. figure examples learned representations layers using lcnn baseline curve indicates average representations different testing videos class dataset. ﬁrst rows correspond class third fourth rows correspond class curves every rows correspond spatial temporal two-stream framework action recognition. representations using vggnet-; histograms representations representations using lcnn; histograms representations representations using vggnet-; histograms representations representations using lcnn; histograms representations representations using lcnn. entropy values representations computed lcnn generate lower-entropy representations class compared vggnet-. color color bars represents class subset neurons. black dashed lines indicate curves highly peaked class. ﬁgure best viewed color zoom class. addition discriminative representations classiﬁer especially linear classiﬁers output layer achieve better performance. discriminative property important performance linear classiﬁer. example lcnn architecture shown figure linear transformation implemented fullyconnected layer. refer ‘transformed representation layer’. create ‘ideal representation layer’ transforms class label corresponding binary vector feed outputs layers euclidean loss layer. experiments allocate neurons late hidden layer class follows assuming neurons layer classes ﬁrst allocate ⌊nl/m⌋ neurons class allocate remaining neurons classes high intra-class appearance variation. therefore neuron late hidden layer associated category label input signal category certainly neurons representacolumn ideal discriminative representation corresponding training sample. ideal representations ensured input signals class similar representations different classes dissimilar representations. discriminative representation error forces learned representation approximate ideal discriminative representation resulting neurons label consistency property i.e. class distributions neuron layer extremely peaked lcnn trained stochastic gradient descent. need compute gradients equation w.r.t. network parameters compared standard difference lies gradient terms i.e. since parameters related newly added discriminative error parameters independently evaluate approach action recognition datasets thumos three object category datasets cifar- imagenet caltech implementation lcnn based caffe toolbox verify effectiveness label consistency module train lcnn ways discriminative representation error loss only; combination softmax classiﬁcation error loss equation refer networks trained ways ‘lcnn-’ ‘lcnn-’ respectively. baseline softmax classiﬁcation error loss network training. refer ‘baseline’ following. note baseline lcnn trained parameter setting initial model experiments. table classiﬁcation performance different two-stream approaches dataset results copied original papers. vggnet* result obtained testing model shared ‘baseline’ results running two-stream implementation provided vggnet- architecture used stream. lcnn baseline trained parameter setting initial model. difference between lcnn- baseline explicit supervision layer lcnn-. lcnn- remove softmax layer baseline network explicit supervision layer. maximum prediction score; k-nn transformed representation represent image video frame optical ﬁeld simple k-nn classiﬁer. lcnn- always uses ‘k-nn’ classiﬁcation lcnn- either ‘argmax’ ‘k-nn’ classiﬁcation. dataset consists video clips action classes every class clips. video examples class class given figure terms evaluation standard split- train/test setting evaluate approach. split contains around clips training rest testing. choose popular two-stream basic network architecture action recognition. consists spatial taking video frames input temporal taking -frame stacking optical ﬁelds. late fusion conducted outputs vggnet- architecture streams explicit supervision added late hidden layer second fully-connected layer. speciﬁcally feed output layer fully-connected layer produce transformed representation compare ideal discriminative representation implementation explicit supervision shown figure since classes layer vggnet output dimension output size around neurons associated class. streams balance loss terms. beneﬁts adding explicit supervision late hidden layers. demonstrate beneﬁts adding explicit supervision late hidden layers. ﬁrst obtain baseline result running standard two-stream implementation provided uses softmax classiﬁcation loss train spatial temporal nets. remove softmax layers two-stream explicit supervision hidden layers. call network ‘lcnn-’. next maintain softmax layers standard two-stream explicit supervision layers. call network ‘lcnn-’. please note parameter setting initial model three types neural networks. results summarized table seen results lcnn- even without help classiﬁer label consistency constraint alone effective learning discriminative features achieves better classiﬁcation performance baseline. also adding explicit supervision late hidden layers improves classiﬁcation results output layer also generates discriminative representations achieve better results even simple k-nn classiﬁer addition compare lcnn state-of-the-art approaches table discriminability learned representations. visualize representations test videos generated late hidden layers figure seen entries layer representations figure peaked corresponding class forms good approximation ideal discriminative representation. please note video testing class certainly neurons classes shown figure indicates sharing features classes prohibited. notice discriminative capability achieved testing indicates lcnn generalizes well without severe overﬁtting. representations figures entropy decreased means discriminativeness previous layers beneﬁts backpropagation disfigure effects parameter selection k-nn neighborhood size classiﬁcation accuracy performances dataset. spatial temporal nets trained lcnn- sensitive selection streams generates ﬁnal prediction score. during testing sample frames video spatial temporal nets. class scores testing video obtained averaging scores across sampled frames. experiments fuse spatial temporal prediction scores using simple weighted average rule weight temporal spatial net. table mean average precision performance thumos validation set. results copied ‘baseline’ results running two-stream implementation provided lcnn baseline trained parameter setting initial model. result also better using method reported criminative representation error introduced lcnn. figure plot performance curves range using lcnn-. observe approach insensitive selection likely increase inter-class distances generated class-speciﬁc representations. smaller training testing errors. investigate convergence testing error lcnn network training. plot testing error training error w.r.t. number epochs spatial figure seen lcnn smaller training error baseline converge quickly alleviate gradient vanishing explicit supervision late hidden layers. addition lcnn smaller testing error compared baseline means lcnn better generalization capability. next evaluate approach challenging thumos challenge action dataset. includes video clips dataset training temporarily untrimmed videos classes validation. employ standard mean average precision thumos recognition task evaluate lcnn. two-stream based vggnet- discussed section explicit supervision added layers. train using data. used evaluation tool provided dataset provider evaluate performance requires probabilities category testing video. classiﬁcation schemes i.e. argmax k-nn different approaches generate probability prediction testing video. argmax directly output layer. k-nn scheme given representation layer compute sample’s distances classes prefigure examples direct supervision late hidden layers including layer architectures including vggnet alexnet cccp layer network-in-network loss/fc loss/fc pool/ googlenet symbol three dots denotes layers network. sented nearest neighbors convert similarity weights using gaussian kernel classes similarity; ﬁnally calculate probability normalization similarity vector. obtained baseline running two-stream implementation provided compare lcnn results baseline state-of-the-art approaches thumos dataset. results summarized table lcnn- better baseline lcnn- improve performances. results spatial stream outperform results results temporal stream comparable based experiment lcnn highly effective generalizes well complex testing data. object recognition cifar- dataset cifar- dataset contains color images classes split training images testing images. compare lcnn- several recently proposed techniques especially deeply supertable test error rates different approaches cifar dataset. results copied ‘baseline’ result network network following lcnn- also trained implementation provided difference baseline lcnn- explicit supervision cccp layer lcnn-. vised adds explicit supervision hidden layers. underlying architecture also choose network network follow data augmentation techniques zero padding side corner cropping random ﬂipping training. lcnn- explicit supervision cascaded cross channel parametric pooling layer late convolutional layer. ﬁrst ﬂatten output convolutional layer dimensional vector feed fully-connected layer obtain transformed representation. implementation shown figure hyper-parameter training. classiﬁcation adopt argmax classiﬁcation scheme. baseline result lcnn- constructed implementation provided parameter setting initial model. compare lcnn- result baseline stateof-the-art approaches including results summarized table regardless data augmentation lcnn- consistently outperforms previous methods including baseline results impressive since adds loss every hidden layer training lcnn- adds discriminative representation error loss late hidden layer. suggests adding direct supervision category-speciﬁc late hidden layers might effective early hidden layers tend shared across categories. table recognition performances using different approaches imagenet validation set. result copied original paper results copied ‘baseline’ result running googlenet implementation caffe toolbox. difference baseline lcnn- explicit supervision three layers lcnn-. section demonstrate lcnn combined state-of-the-art architecture googlenet recent deep layers achieved best performance ilsvrc ilsvrc classiﬁcation challenge contains million training images images validation categories. tackle deep network architecture construct lcnn googlenet implementation caffe toolbox adding explicit supervision multiple late hidden layers instead single one. speciﬁcally shown figure discriminative representation error losses added three layers loss/fc loss/fc pool/×s weights used three softmax loss layers evaluate approach terms top- top- accuracy rate. adopt argmax classiﬁcation scheme. baseline result running googlenet implementation caffe toolbox. lcnn- googlenet trained imagenet dataset scratch parameter setting. results listed table lcnn- outperform baseline evaluation metrics parameter setting. please note result reported googlenet simply running implementation caffe. goal show network becomes deeper learning good discriminative features hidden layers might become difﬁcult solely depending prediction error loss. therefore adding explicit supervision late hidden layers scenario becomes particularly useful. table comparisons lcnn approaches caltech dataset. results copied original papers. ‘baseline’ ‘baseline*’ results ﬁne-tuning alexnet model vggnet- model caltech dataset respectively. lcnn- lcnn- ‘baseline’ trained parameter setting. lcnn- ‘baseline*’ trained parameter setting well. fair comparison previous work follow standard classiﬁcation settings. training time images randomly chosen category form training images category tested. imagenet trained model alexnet vggnet- ﬁne-tune caltech dataset. built lcnn alexnet vggnet- respectively experiment. explicit supervision added second fully-connected layer hyperparameter baseline result ﬁne-tuning alexnet caltech. ﬁnetune lcnn parameter setting initial model. similarly obtained baseline* result lcnn results based vggnet-. results summarized table limited amount data available approach makes better training data achieves higher accuracy. lcnn outperforms baseline results deep learning approaches representing state-of-the-art task. introduced label consistent neural network supervised feature learning algorithm adding explicit supervision late hidden layers. introducing discriminative representation error combining traditional prediction error neural networks achieve better classiﬁcation performance output layer discriminative representations hidden layers. experimental results show approach operates stateof-the-art several publicly available action object leads faster convergence speed recognition dataset. works well limited video image data presented. approach seamlessly combined various network architectures. future work includes applying discriminative learned category-speciﬁc representations computer vision tasks besides action object recognition. acknowledgement work supported intelligence advanced research projects activity department interior national business center contract number dpc. u.s. government authorized reproduce distribute reprints government purposes notwithstanding copyright annotation thereon. disclaimer views conclusions contained herein authors interpreted necessarily representing ofﬁcial policies endorsements either expressed implied iarpa doi/nbc u.s. government. references bengio lamblin popovici larochelle. greedy layer-wise training deep networks. nips donahue hendricks guadarrama rohrbach venugopalan saenko darrell. long-term recurrent convolutional networks visual recognition description. cvpr gorban idrees y.-g. jiang roshan zamir laptev shah sukthankar. thumos challenge action recognition large number classes. http//www.thumos.info/ yang convolutional neural networks human action recognition. icml shelhamer donahue karayev long girshick guadarrama darrell. caffe convolutional architecture fast feature embedding. pages", "year": 2016}