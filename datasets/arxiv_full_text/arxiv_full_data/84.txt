{"title": "A Joint Model for Question Answering and Question Generation", "tag": ["cs.CL", "cs.AI", "cs.LG", "cs.NE"], "abstract": "We propose a generative machine comprehension model that learns jointly to ask and answer questions based on documents. The proposed model uses a sequence-to-sequence framework that encodes the document and generates a question (answer) given an answer (question). Significant improvement in model performance is observed empirically on the SQuAD corpus, confirming our hypothesis that the model benefits from jointly learning to perform both tasks. We believe the joint model's novelty offers a new perspective on machine comprehension beyond architectural engineering, and serves as a first step towards autonomous information seeking.", "text": "propose generative machine comprehension model learns jointly answer questions based documents. proposed model uses sequence-to-sequence framework encodes document generates question given answer significant improvement model performance observed empirically squad corpus conﬁrming hypothesis model beneﬁts jointly learning perform tasks. believe joint model’s novelty offers perspective machine comprehension beyond architectural engineering serves ﬁrst step towards autonomous information seeking. question answering task automatically producing answer question given corresponding document. provides humans efﬁcient access vast amounts information also acts important proxy task assess machine literacy reading comprehension. thanks recent release several large-scale machine comprehension/qa datasets ﬁeld undergone signiﬁcant advancement array neural models rapidly approaching human parity benchmarks however previous models treat task natural language generation pointing answer span within document. alongside question generation also gained increased popularity task generate natural-language question conditioned answer corresponding document. among many applications question generation used improve systems recurring theme among previous work propose joint model asks answers questions investigate joint-training setup affects individual tasks. hypothesize question generation help models achieve better performance. motivated partly observations made psychology devising questions reading increase scores comprehension tests joint model also serves novel framework improving performance outside networkarchitectural engineering characterizes previous studies. although question answering asking tasks appear symmetric differences. first answering questions existing datasets extractive requires selecting span text within document question asking comparatively abstractive requires generation text appear document. furthermore pair typically speciﬁes unique answer. conversely typical pair associated multiple questions since valid question formed information relations uniquely specify given answer. tackle joint task construct attentionbased sequence-to-sequence model takes document input generates question conditioned answer output. address mixed extractive/abstractive nature generative targets pointer-softmax mechanism learns switch copying words document generating words prescribed vocabulary. joint training realized alternating input data between question-answering question-generating examples model. demonstrate empirically model’s performance squad state improves joint training. novelty joint model generate abstractive answers. joint-learning multiple related tasks explored previously machine translation instance firat demonstrated translation quality clearly improves models trained single language pair attention mechanism neural translation model shared jointly trained multiple language pairs. question answering wang jiang proposed ﬁrst neural models squad dataset. squad deﬁnes extractive task wherein answers consist word spans corresponding document. wang jiang demonstrated learning point answer boundaries effective learning point sequentially tokens making answer span. many later studies adopted boundary model achieved nearhuman performance task however boundarypointing mechanism suitable open-ended tasks including abstractive question generation. forcing extractive boundary model onto abstractive datasets currently yields stateof-the-art results mainly current generative models poor evaluation unsolved. earlier work question generation resorted either rule-based reordering methods slot-ﬁlling question templates techniques often involve pipelines independent components difﬁcult tune ﬁnal performance measures. partly address limitation end-to-end-trainable neural models recently proposed question generation vision language. example used sequence-tosequence model attention mechanism derived encoder states. yuan proposed similar architecture addition improved model performance policy gradient techniques. several neural models questioning component proposed purpose improving models objective shared study. yang devised semi-supervised training framework trained model labeled data artiﬁcial data generated separate generative component. buck used policy gradient reward train sequence-to-sequence paraphrase model reformulate questions existing dataset generated questions used train existing model distinction model harness process proposed model adopts sequence-to-sequence framework attention mechanism pointer-softmax decoder speciﬁcally model takes document condition sequence input outputs target sequence {qa} condition corresponds question word sequence answer-generation mode answer word sequence question-generation mode also attach binary variable indicate whether data-point intended a-gen q-gen. intuitively help model learn modalities easily. empirically performance improves slightly addition. word input sequence ﬁrst embedded character-level informaembedding layer vector tion captured ﬁnal states bidirectional long short-term memory model character sequences ﬁnal concaterepresentation word token nates wordcharacter-level embeddings. subsequently encoded another bilstm annotation vectors better encode condition also extract encodings document words appear condition sequence. procedure particularly helpful q-gen mode condition sequence typically extractive. extracted vectors condition aggregation bilstm produce extractive condition encoding speciﬁcally take ﬁnal states condition encodings account different extractive abstractive nature questions answers a-gen mode rnn-based decoder employs pointer-softmax mechanism generation step decoder decides adaptively whether generate decoder vocabulary point word source sequence recurrence pointing decoder implemented lstm cells here corresponds embeddings equation training gold targets used teacher-force sequence generation training i.e. inference generation condiw<t tioned previously generated words i.e. ˆw<t. words multiple occurrence since exact references document cannot reiabled determined aggregate probability words encoder pointing decoder test time beam search used enhance ﬂuency question-generation output. decoder also keeps explicit history previously generated words avoid repetition output. conduct experiments squad corpus machine comprehension dataset consisting crowd-sourced question-answer pairs wikipedia articles. simple preprocessing performed including lower-casing texts dataset using nltk word tokenization. test split squad hidden public. therefore take question-answer pairs training validation ofﬁcial development data report test results. note answers dataset strictly extractive therefore constrain pointer-softmax module point decoding steps answer generation mode. ﬁrst layers tanh activation ﬁnal layer uses sigmoid activation highway connections present ﬁrst second layer. also attach entropy softmax distributions input ﬁnal layer postulating quantities help guide switching mechanism indicating conﬁdence pointing generating. addition empirically observed improve model performance. ﬁrst establish baselines without multi-task training. speciﬁcally model a-gen trained generate answer given document question i.e. conventional model. analogously model q-gen trained generate questions documents answers. joint-training realized feeding answer-generation question-generation data model alternating fashion mini-batches. addition compare answer-generation performance sequence model variant match-lstm model mentioned earlier contrast existing neural models point start boundaries extractive answers model predicts sequence document positions answer. makes comparable setup. note however model additional capacity exact match gold answer sequences evaluate answer generation bleu gold question sequences evaluate question generation. however existing studies shown task question generation often exhibits linguistic variance semantically admissible; renders inappropriate judge generated question solely matching gold sequence therefore assess quality generated questions pretrained neural models well language model compute perplexity model answer measure score answer produced model. choose mlstm pretrained model train squad split mentioned section performance test pretrained language model train single-layer lstm language model combination text corpus quora question pairs corpus gold questions squad. latter corpora included tailor purpose assessing question ﬂuency reason ignore semantic equivalence labels quora dataset. validation perplexity pretrained language model. evaluation results provided table a-gen performance improves signiﬁcantly joint model increase percentage points. performance q-gen worsens joint training decrease relatively small. furthermore pointed meanwhile although model perform well mlstm task added capability generating questions. mlstm uses advanced encoder tailored model uses bidirectional lstm encoding. model uses advanced decoder based pointer-softmax enables generate abstactively extractively. ﬁner grained analysis ﬁrst categorize test answers based entity types stratify performance comparison a-gen jointqa. categorization relies stanford corenlp generate constituency parses tags tags answer spans seen figure joint model signiﬁcantly outperforms single model categories. interestingly moving average performance exhibits upward trend a-gen model performance decreases across answer types suggesting joint model helps single model performance weakest. qualitatively observed interesting shifts attention joint training. example positive case table gold question asks direct objectnixon verb endorse a-gen model predicts indirect object kennedy instead. contrast joint model asks appositive vice president question generation presumably table examples behaviour changes possibly induced joint training. gold answers correspond text spans green. positive negative cases answers produced joint model highly related generated questions. primes model attention towards correct answer nixon. analogously negative example attention joint model appears shifted joint training towards answer incorrect closer generated question. note examples table come validation thus possible joint model memorize gold answers question-generation mode priming effect must come form knowledge transfer q-gen a-gen joint training. implementation details proposed model follows. encoder vocabulary indexes words dataset. decoder vocabulary uses words sorted frequency gold questions training data. encourages model generate frequent words decoder vocabulary copy less frequent ones document. word embedding matrix initialized dimensional glove vectors dimensionality character representations number hidden units encoder/decoder cells. dropout applied rate embedding layers well hidden states encoder/decoder rnns across time steps. proposed neural machine comprehension model jointly answer questions given document. hypothesized question answering beneﬁt synergistic interaction tasks parameter sharing joint training multitask setting. proposed model adopts attention-based sequenceto-sequence architecture learns dynamically switch copying words document generating words vocabulary. experiments model conﬁrm hypothesis joint model outperforms qacounterpart signiﬁcant margin squad dataset. although evaluation scores still lower stateof-the-art results achieved dedicated models proposed model nonetheless demonstrates effectiveness joint training question generation thus offers novel perspective promising direction advancing study references agarwal manish mannem prashanth. automatic gapproceedﬁll question generation text books. ings workshop innovative building educational applications association computational linguistics al-rfou rami alain guillaume almahairi amjad angermueller christof bahdanau dzmitry ballas nicolas bastien fr´ed´eric bayer justin belikov anatoly belopolsky alexander theano python framework fast computation mathematical expressions. arxiv preprint arxiv. buck christian bulian jannis ciaramita massimiliano gesmundo andrea houlsby neil gajewski wojciech wang wei. right questions active question reformulation reinforcement learning. arxiv preprint arxiv. chali yllias golestanirad sina. ranking automatically generated questions using common human queries. international natural language generation conference collobert ronan weston jason bottou l´eon karlen michael kavukcuoglu koray kuksa pavel. natural language processing scratch. journal machine learning research dunn matthew sagun levent higgins mike guney ugur cirik volkan kyunghyun. searchqa dataset augmented context search engine. arxiv preprint arxiv. hermann karl moritz kocisky tomas grefenstette edward espeholt lasse will suleyman mustafa blunsom phil. teaching machines read comprehend. advances neural information processing systems manning christopher surdeanu mihai bauer john finkel jenny rose bethard steven mcclosky david. stanford corenlp natural language processing toolkit. nguyen rosenberg song jianfeng tiwary saurabh majumder rangan deng marco human generated machine reading comprehension dataset. arxiv preprint arxiv. papineni kishore roukos salim ward todd wei-jing. bleu method automatic evaluation proceedings anmachine translation. nual meeting association computational linguistics association computational linguistics jeffrey socher richard manning christopher glove global vectors word representation. proceedings conference empirical methods natural language processing serban iulian vlad garc´ıa-dur´an alberto gulcehre caglar sungjin chandar sarath courville aaron generating factoid questions recurrent neural networks arxiv preprint factoid question-answer corpus. arxiv. singer harry donlan dan. active comprehension problem-solving schema question generation comprehension complex short stories. reading research quarterly trischler adam wang tong yuan xingdi harris justin sordoni alessandro bachman philip suleman kaheer. newsqa machine comprehension dataset. arxiv preprint arxiv. wang wenhui yang furu chang baobao zhou ming. gated self-matching networks reading comprehension question answering. proceedings annual meeting association computational linguistics yuan xingdi wang tong gulcehre caglar sordoni alessandro bachman philip subramanian sandeep zhang saizheng trischler adam. machine comprehension text-to-text neural question generation. arxiv preprint arxiv.", "year": 2017}