{"title": "Net2Vec: Quantifying and Explaining how Concepts are Encoded by Filters  in Deep Neural Networks", "tag": ["cs.CV", "cs.AI", "stat.ML"], "abstract": "In an effort to understand the meaning of the intermediate representations captured by deep networks, recent papers have tried to associate specific semantic concepts to individual neural network filter responses, where interesting correlations are often found, largely by focusing on extremal filter responses. In this paper, we show that this approach can favor easy-to-interpret cases that are not necessarily representative of the average behavior of a representation.  A more realistic but harder-to-study hypothesis is that semantic representations are distributed, and thus filters must be studied in conjunction. In order to investigate this idea while enabling systematic visualization and quantification of multiple filter responses, we introduce the Net2Vec framework, in which semantic concepts are mapped to vectorial embeddings based on corresponding filter responses. By studying such embeddings, we are able to show that 1., in most cases, multiple filters are required to code for a concept, that 2., often filters are not concept specific and help encode multiple concepts, and that 3., compared to single filter activations, filter embeddings are able to better characterize the meaning of a representation and its relationship to other concepts.", "text": "figure diversity broden images activate certain alexnet conv ﬁlters motivates investigate extent single ﬁlter encodes concept fully without needing units exclusively without encoding concepts. image’s corner number denotes n-th maximally activating image given ﬁlter. masks generated slightly modiﬁed netdissect approach upsampled ﬁrst thresholding smoothness. access limited training data relation capacity paper particular convolutional neural network learned training complete. neural network seen sequence functions mapping input image intermediate representation. ﬁnal output network usually easy interpret meaning intermediate layers less clear. understanding information carried representations ﬁrst step understanding networks work. effort understand meaning intermediate representations captured deep networks recent papers tried associate speciﬁc semantic concepts individual neural network ﬁlter responses interesting correlations often found largely focusing extremal ﬁlter responses. paper show approach favor easy-to-interpret cases necessarily representative average behavior representation. realistic harder-to-study hypothesis semantic representations distributed thus ﬁlters must studied conjunction. order investigate idea enabling systematic visualization quantiﬁcation multiple ﬁlter responses introduce netvec framework semantic concepts mapped vectorial embeddings based corresponding ﬁlter responses. studying embeddings able show cases multiple ﬁlters required code concept often ﬁlters concept speciﬁc help encode multiple concepts compared single ﬁlter activations ﬁlter embeddings able better characterize meaning representation relationship concepts. deep neural networks keep setting records almost problems computer vision understanding black-box models remains limited. without developing understanding difﬁcult characterize work around limitations deep networks improvements come intuition trialand-error. deep learning mature much better theoretical empirical understanding deep networks required. several questions need answering deep network able solve problem classifying image generalize well despite vidual ﬁlters deep network responsible capturing particular semantic concepts. idea low-level primitives edges texture motifs recognized ﬁrst layers network complex objects scenes deeper ones. excellent representative line research recent network dissection approach authors paper introduce dataset broden contains pixel-level segmentation hundreds lowhigh-level visual concepts textures parts objects. study correlation extremal ﬁlter responses concepts seeking ﬁlters strongly responsive particular ones. similar studies clear correlations feature responses various concepts interpretation intrinsic limitations. seen simple counting argument number available feature channels usually smaller number different concepts neural network need encode interpret complex visual scene. suggests that least representation must combinations ﬁlter responses represent concepts words least part distributed. overview. goal paper beyond looking individual ﬁlters study instead information captured combinations neural network ﬁlters. paper conduct thorough analysis investigate semantic concepts objects parts encoded ﬁlters. order make analysis manageable introduce netvec framework aligns semantic concepts ﬁlter activations. learned concept embeddings used weight ﬁlter activations perform semantic tasks like segmentation classiﬁcation. concept vectors used investigate quantitatively qualitatively overlap ﬁlters concepts. novelty lies outlining methods beyond simply demonstrating multiple ﬁlters better encode concepts single ones quantifying describing concept encoded. principally gain unique interpretive power formulating concepts vectors embeddings. using netvec look ﬁrst questions extent individual ﬁlters sufﬁcient express concept? multiple ﬁlters required code single concept? extent ﬁlter exclusively code single concept? ﬁlter shared many diverse concepts? answer questions depends speciﬁc ﬁlter concept consideration demonstrate quantify overlap ﬁlters concepts show many cases notions exclusive overlap hold. means that interpret semantic concepts ﬁlter activations corresponding quantifying relationship concepts representation seem obvious much research explaining concepts encoded deep networks roughly falls qualitative categories interpretable visualizations single ﬁlters encode semantic concepts; demonstrations distributive encoding limited explanatory power concept encoded. work present methods seek marry interpretive beneﬁts single ﬁlter visualizations quantitative demonstrations concepts encoded across multiple ﬁlters part analysis also highlight problem visualizing inputs maximally activate ﬁlter propose evaluating power explanatory visualizations well explain whole distribution ﬁlter activations extreme ones related work visualizations. several methods proposed explain single ﬁlter encodes visualizing real generated input activates ﬁlter; techniques often used argue single ﬁlters substantially encode concept. contrast shows visualizing real image patches activate layer’s ﬁlters random basis applied also yields semantically coherent patches. visualize segmentation masks extracted ﬁlter activations conﬁdent maximally activating images; also evaluate visualizations using human judgments. distributed encodings. demonstrates pascal classes require hidden units perform classiﬁcation well. similar concludes hidden units encode semantic concepts robustly measuring overlap image patches activate hidden unit ground truth bounding boxes collecting human judgments whether patches encode systematic concepts. compares using individual ﬁlter activations using clusters activations units layer shows clusters yielded better parts detectors qualitatively correlated well semantic concepts. probes intermediate ﬁlters training linear classiﬁers activations analyzing classiﬁers different layers points training. pre-trained network probed inputs reference probe dataset learning weight collected probe activations perform various semantic tasks. every concept probe dataset concept weight learned task recognizing concept. resulting weights interpreted concept embeddings analyzed understand concepts encoded. example performance semantic tasks using learned concept weights span ﬁlters layer compared using single ﬁlter subset ﬁlters. remainder section provide details learn concept embeddings learning segment classify concepts. also outline compare embeddings arising using restricted ﬁlters including single ﬁlters. brieﬂy discuss dataset used learn concepts. data. build broden dataset recently introduced probe alexnet trained imagenet dataset representative model image classiﬁcation. broden contains images pixelimage-level annotations concepts across categories scenes objects parts materials textures colors exclude scene concepts validation examples. thus concepts consider image-level annotations segmentation annotations image-level annotations provided scene texture concepts. note paradigm generalized probe dataset contains pixelimage-level annotations concepts. post-relu activations convolutional layers alexnet probed. section show learning segment concepts used induce concept embeddings using either ﬁlters available layer single ﬁlter. also show embeddings used quantify degree overlap ﬁlter combinations concepts. task performed broden concepts segmentation annotations excludes scene texture concepts. filter layer used generate segmentation image ﬁrst thresholding rhl×wl activation ﬁlter input rh×w× upsampling result needed match resolution ground truth segmentation mask i.e. denotes bilinear upsampling function. computes intersection union difference binary segmentation masks produced ﬁlter ground-truth segmentation masks note sets merged images subset data {train val}. best ﬁlter argmaxk iouset selected training validation score iouset reported. differ following ways threshold upsampling order evenly compare method described below; bilinearly upsample without anchoring interpolants center ﬁlter receptive ﬁelds speed upsampling part experimental pipeline; determine best ﬁlter concept training split xtrainc rather whereas distinguish training validation set. order compare single-feature concept embeddings representations ﬁlter combinations also learn solve segmentation task using combinations ﬁlters extracted neural network. this learn weights number ﬁlters layer linearly combine thresholded activations. then linear combination passed sigmoid function predict segmentation mask start considering single ﬁlter segmentation following paradigm three minor modiﬁcations listed below. every ﬁlter corresponding activation activation’s quantile determined computed respect distribution ﬁlter activations probe images indicator function event. sigmoid irrelevant evaluation threshold mask effect training predicted weights concept weights fact learned using stochastic gradient descent momentum minimize per-pixel binary cross entropy loss weighed mean concept size respect analogous learning weights ﬁlters ones. train classiﬁers last three alexnet layers layers special case corresponding single ﬁlter. comparison method select subsets ﬁlters segmentation task last layer using start investigating popular hypothesis whether concepts well represented activation individual ﬁlters not. order quantify this consider learned weights combine information ﬁlter activations layer compare single ﬁlter used perform segmentation classiﬁcation broden. figure shows that average using learned weights combine ﬁlters outperforms using single ﬁlter segmentation classiﬁcation tasks evaluated validation data. improvements quite dramatic concepts. instance even simple concepts colors ﬁlter combinations outperform individual ﬁlters iouset suggests that even ﬁlters speciﬁc concept found optimally encode fully cover overlap concept. line accepted notion deep layers improve representational quality task performance generally improves layer depth increases trends color concepts being notable exception. furthermore average performance varies signiﬁcantly concept category consistently singlemulti-ﬁlter classiﬁcation plots suggests certain concepts less wellaligned linear combination ﬁlter space. many ﬁlters required encode concept? answer question observe varying number ﬁlters learn concept weights affects performance figure shows mean performance saturates different various concept categories tasks. classiﬁcation task concept categories saturate however scenes reaches near optimal performance around much quickly materials. segmentation task performance peaks much earlier materials parts objects also observe performance drop reaching optimal peaks materials parts segmentation class. highlights segmentation task similar single ﬁlter case concept weights learned xtrainc score computed thresholded masks xvalc reported. addition evaluating score per-image scores computed well note choosing single ﬁlter analogous setting one-hot vector selected ﬁlter otherwise recovering single-ﬁlter segmenter section output rescaled sigmoid function concept classiﬁcation alternate task concept segmentation problem classifying concept used induce concept embeddings. case discuss ﬁrst learning embeddings using generic ﬁlter combinations reduce using small subset ﬁlters similar segmentation paradigm concept weight vector bias term learned combine spatially-averaged ﬁlter activations linear combination passed sigmoid function obtain concept posterior probability concept training images xtrain divided positive subset xtrainc+ images contain concept complement xtrainc− images not. general positive negative sets unbalanced sizes training images sets sampled equal probability order re-balance data evaluate performance calculate classiﬁcation accuracy balanced validation set. order compare using ﬁlters layer subset ﬁlters even individual ﬁlters must learn corresponding concept classiﬁers. concept learning weights explained before choose absolute weight |wk|. then learn weights bias used weight activations ﬁlters. next investigate extent single ﬁlter used encode many concepts. note figure suggests single ﬁlter might activated different concepts; often different concepts ﬁlter appears activated related latent concept human-interpretable i.e. ‘wheel’ detector ﬁlter also activated various different types vehicles ‘animal torso’ ﬁlter also involved characterizing animals like ‘sheep’ ‘cow’ ‘horse’ using single best ﬁlters identiﬁed segmentation classiﬁcation tasks explore often ﬁlter selected best ﬁlter encode concept. figure shows distribution many ﬁlters encode many concepts interestingly around relu ﬁlters selected encoding least concepts segmentation classiﬁcation tasks respectively substantial portion ﬁlters layer never selected. ﬁlters selected encode numerous concepts covered exclusively overlapped single concept. ﬁlters selected encode concepts likely involved detecting highly discriminative features. section propose standard visualizing non-extreme examples show singlemulti-ﬁlter perspectives uniﬁed demonstrate viewing concept weights embeddings ﬁlter space figure results concept category segmentation classiﬁcation tasks show that average using learned weights combine ﬁlters performs using single ﬁlter standard error shown. failure cases. average multi-ﬁlter approach signiﬁcantly outperforms single-ﬁlter approach segmentation classiﬁcation tasks table shows around concepts hold. segmentation percentage increases layer depth. upon investigation discovered concepts learned weights outperform best ﬁlter either examples concept i.e. small concept training dataset size i.e. mostly |xtrainc| leads overﬁtting small objects i.e. small mean concept size around less image thus training size weighted loss unstable difﬁcult particularly later layers spatial resolution. similar analysis classiﬁcation results shows small concept dataset size also causing overﬁtting failmany visual explanation techniques demonstrated value showing visualizations inputs maximally activate ﬁlter whether maximally-activating image patches training dataset learned generated maximally-activated inputs ﬁlter segmentation masks maximally-activating images probe dataset however useful approaches fail consider visualizations might differ across distribution examples. figure shows using single ﬁlter segment concepts yields individual score many examples concept; examples simply considered metric. often occurs activations survive τ-thresholding step suggests single ﬁlter consistently strongly given concept. argue visualization technique still work informative non-maximal examples. figure automatically select visualize examples decile non-zero portion individual distribution using learned concept weights best ﬁlters identiﬁed visualized categories. ‘dog’ ‘airplane’ visualizations using weighted combination method predicted masks informative salient examples even lowest percentile ideally using decile sampling method visualizations appear salient even examples lower deciles. however examples using best single ﬁlter visualizations interpretable higher deciles contrast maximally activating examples shown section show high-quality visualizations ‘dog’ ‘plant’ ‘airplane’ well seems window detector ‘house’ ﬁlter however activating images ﬁlter identiﬁed best ﬁlter ‘airplane’ coherent airplane concept. figure highlights correlated relationship learned concept weights scores achieved individual ﬁlters; visually ﬁlter’s score appears correlated associated weight value passed relu i.e. max. broden concepts segmentation annotations alexnet layer computed correlation {iouset}k=...k; table shows relu around segmentation concepts signiﬁcantly correlated thus show figure empirical distribution individual scores using best single ﬁlter learned ﬁlter-combining weights ‘dog’ ‘train’ object concepts show using single ﬁlter leads many absolute misses well lower per-example scores figure examples images maximally activated aligned best relu ﬁlters learned weights ‘house’ ‘dog’ ‘plant’ ‘airplane’ concepts comparison non-maximal examples figure slightly smoother visualizations activations upsampled thresholded. finally learned weights considered embeddings dimension corresponds ﬁlter given layer. then leverage rich literature word embeddings derived textual data better understand concepts similar network space among things. knowledge ﬁrst work learns semantic embeddings aligned ﬁlter space network visual data alone. w|w|). table shows closest concepts cosine tance denotes notes examples suggest embeddings segmentation classiﬁcation tasks capture slightly different relationships concepts. speciﬁcally nearby concepts segmentation space appear similar-category objects example automatically selected decile non-zero portion distribution individual scores predicted relu segmentation masks using best ﬁlter well learned weights overlaid. mals case ‘cat’ ‘horse’ nearest ‘dog’) whereas nearby concepts classiﬁcation space appear concepts related compositionally note ‘street’ ‘bedroom’ categorized scenes thus lack segmentation annotations. vector arithmetic. table shows also vector arithmetic adding subtracting concept embeddings meaningful results. instance observe analogy relationship ‘grass’−‘green’ ‘sky’−‘blue’ believable results nonunderstanding embedding space. using t-sne components figure visualizes randomly selected concepts relu embedding spaces corresponding segmentation classiﬁcation tasks. uppermost parts visualizations observe ‘cushion’ ‘sofa’ ‘seat cushion’ clustered together segmentation embedding ‘hand’ ‘torso’ ‘neck’ near another classiﬁcation embedding. k-means clustering also reveals semantically similar concepts near another embedding space conclusion present netvec paradigm learning concept embeddings aligned layer’s ﬁlter space. answer binary questions does single ﬁlter encode concept fully exclusively? also introduce idea ﬁlter concept coverage overlap outline methods answering scalar versions questions asking extent...? also propose fair standard visualizing non-extreme examples bring explanatory power visualizations space explaining distributed concept encodings conceptualizing learned weights embeddings. powerful interpretable paradigm limited linear nature; future work done explore non-linear ways concepts better aligned ﬁlter space.", "year": 2018}