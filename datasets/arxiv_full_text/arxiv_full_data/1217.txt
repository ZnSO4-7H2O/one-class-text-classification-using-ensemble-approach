{"title": "Training CNNs with Low-Rank Filters for Efficient Image Classification", "tag": ["cs.CV", "cs.LG", "cs.NE"], "abstract": "We propose a new method for creating computationally efficient convolutional neural networks (CNNs) by using low-rank representations of convolutional filters. Rather than approximating filters in previously-trained networks with more efficient versions, we learn a set of small basis filters from scratch; during training, the network learns to combine these basis filters into more complex filters that are discriminative for image classification. To train such networks, a novel weight initialization scheme is used. This allows effective initialization of connection weights in convolutional layers composed of groups of differently-shaped filters. We validate our approach by applying it to several existing CNN architectures and training these networks from scratch using the CIFAR, ILSVRC and MIT Places datasets. Our results show similar or higher accuracy than conventional CNNs with much less compute. Applying our method to an improved version of VGG-11 network using global max-pooling, we achieve comparable validation accuracy using 41% less compute and only 24% of the original VGG-11 model parameters; another variant of our method gives a 1 percentage point increase in accuracy over our improved VGG-11 model, giving a top-5 center-crop validation accuracy of 89.7% while reducing computation by 16% relative to the original VGG-11 model. Applying our method to the GoogLeNet architecture for ILSVRC, we achieved comparable accuracy with 26% less compute and 41% fewer model parameters. Applying our method to a near state-of-the-art network for CIFAR, we achieved comparable accuracy with 46% less compute and 55% fewer parameters.", "text": "yani ioannou duncan robertson jamie shotton roberto cipolla antonio criminisi university cambridge microsoft research {yairc}cam.ac.uk {a-durobejamieshoantcrim}microsoft.com propose method creating computationally efﬁcient convolutional neural networks using low-rank representations convolutional ﬁlters. rather approximating ﬁlters previously-trained networks efﬁcient versions learn small basis ﬁlters scratch; training network learns combine basis ﬁlters complex ﬁlters discriminative image classiﬁcation. train networks novel weight initialization scheme used. allows effective initialization connection weights convolutional layers composed groups differently-shaped ﬁlters. validate approach applying several existing architectures training networks scratch using cifar ilsvrc places datasets. results show similar higher accuracy conventional cnns much less compute. applying method improved version network using global max-pooling achieve comparable validation accuracy using less compute original vgg- model parameters; another variant method gives percentage point increase accuracy improved vgg- model giving top- center-crop validation accuracy reducing computation relative original vgg- model. applying method googlenet architecture ilsvrc achieved comparable accuracy less compute fewer model parameters. applying method near state-of-the-art network cifar achieved comparable accuracy less compute fewer parameters. convolutional neural networks used increasingly succesfully solve challenging computer vision problems image classiﬁcation object detection human pose estimation however recent improvements recognition accuracy come expense increased model size computational complexity. costs prohibitive deployment low-power devices fast analysis videos volumetric medical images. promising aspect cnns memory computational efﬁciency standpoint convolutional ﬁlters ﬁlters usually limited spatial extent learned weights shared across image spatial domain provide translation invariance thus illustrated fig. comparison fully connected network layers convolutional layers much sparser connection structure fewer parameters leads faster training test better generalization higher accuracy. paper focuses reducing computational complexity convolutional layers cnns sparsifying connection structures. speciﬁcally show representing convolutional ﬁlters using basis space comprising groups ﬁlters different spatial dimensions signiﬁcantly reduce computational complexity existing state-of-the-art cnns without compromising classiﬁcation accuracy. contributions include novel method learning small basis ﬁlters combined represent larger ﬁlters efﬁciently. rather approximating previously trained networks figure network connection structure convolutional layers. input image transformed layer neural network output image size. connection weight maps show pairwise dependencies input output pixels. node connected input pixels. output pixels depend subset input pixels note sparsity increases opening potentially efﬁcient implementation. train networks scratch show convolutional layer representation improve efﬁciency classiﬁcation accuracy. describe initialize connection weights effectively training networks composite convolutional layers containing groups differentlyshaped ﬁlters found critical importance training method. much previous work increasing test-time efﬁciency cnns. promising approaches work making hardware-efﬁcient representations. example gupta vanhoucke achieve trainingtest-time compute savings quantization network weights originally represented ﬂoating point numbers. however relevant work approaches depend network connection structures efﬁcient approximations previously trained networks learning rank ﬁlters. efﬁcient network connection structures. shown signiﬁcant redundancy trained weights cnns lecun suggest method pruning unimportant connections within networks. however requires repeated network re-training infeasible modern state-of-the-art cnns requiring weeks training time. show geometric increase number dimensions ﬁlters deeper networks managed using low-dimensional embeddings. authors show global average-pooling used decrease model size networks fully connected layers. simonyan zisserman show stacked ﬁlters small spatial dimensions operate effective receptive ﬁeld larger ﬁlters less computational complexity. low-rank filter approximations. rigamonti approximate previously trained cnns low-rank ﬁlters semantic segmentation curvilinear structures within volumetric medical imagery. discuss approaches enforcing l-based regularization learn approximately rank ﬁlters later truncated enforce strict rank approximating pre-learned ﬁlters tensor-decomposition many rank- ﬁlters. neither approach learns rank ﬁlters directly indeed second approach proved successful. work jaderberg also approximates existing ﬁlters previously trained networks. separable ﬁlters optimization minimizing reconstruction error already learned full rank ﬁlters. achieve speed-up loss accuracy text recognition problem. however since method demonstrated text recognition clear well would scale larger data sets challenging problems. insight methods show that least respective applications rank approximations full-rank ﬁlters learned convolutional networks increase test time efﬁciency signiﬁcantly. however approximations pre-trained networks unlikely improve test accuracy increase computational requirements training. learning separable filters. mamalet garcia propose training networks separable ﬁlters task digit recognition mnist dataset. train networks sequential convolutional layers horizontal vertical ﬁlters achieving speed-up factor relative increase test error .our approach generalizes this allowing horizontal vertical ﬁlters layer avoiding issues ordering. also demonstrate decrease error challenging datasets. convolutional filters convolutional layers produce output ‘images’ convolving input images learned ﬁlters. typical convolutional layer illustrated fig. c-channel input image size pixels convolved ﬁlters size create d-channel output image. ﬁlter represented independent weights. therefore computational complexity convolution ﬁlter c-channel input image follows describe schemes modifying architecture convolutional layers reduce computational complexity. idea replace full-rank convolutional layers modiﬁed versions represent number ﬁlters linear combinations basis vectors i.e. lower rank representations full rank originals. existing scheme reducing computational complexity convolutional layers replace sequence regular convolutional layers ﬁlters rectangular spatial domain shown ﬁrst convolutional layer ﬁlters size w××c producing output feature channels. second convolutional layer ﬁlters size producing output feature channels. means full rank original convolutional ﬁlter bank represented rank approximation formed linear combination separable basis ﬁlters. computational complexity scheme ﬁrst layer horizontal ﬁlters second layer vertical ﬁlters total note jaderberg scheme approximate existing full rank ﬁlters belonging previously trained networks using retrospective ﬁtting step. work contrast train networks containing convolutional layers architecture scratch. effect learn separable basis ﬁlters combination weights simultaneously network training. work introduce another scheme reducing convolutional layer complexity. works representing convolutional ﬁlters linear combinations basis ﬁlters illustrated fig. scheme uses composite layers comprising several sets ﬁlters ﬁlters different spatial dimensions outputs basis ﬁlters combined subsequent layer containing ﬁlters spatial dimensions illustrated fig. here composite layer contains horizontal vertical ﬁlters outputs concatenated channel dimension resulting intermediate m-channel feature map. ﬁlter responses linearly combined next layer ﬁlters give d-channel output feature map. case ﬁlters applied input feature channels followed ﬁlters output channels basis ﬁlters. number horizontal vertical ﬁlters same computational complexity interestingly conﬁguration fig. gives rise linear combinations horizontal vertical ﬁlters cross-shaped spatial domain. illustrated fig. ﬁlters learned ﬁrst convolutional layer the‘vgg-gmp-lr-join’ model described results section trained using ilsvrc dataset. note that general different sizes basis ﬁlter might used composite layer. example fig. shows combination three sets ﬁlters spatial dimensions also note interesting option omit linear combination layer instead allow connection weights subsequent network layer learn combine basis ﬁlters preceding layer possibility explored practice results section. method uses combination ﬁlters composite layer similar ‘googlenet’ szegedy uses ‘inception’ modules comprising several ﬁlters different sizes ranging case however implicitly learning linear combinations less computationally expensive ﬁlters different orientations rather combinations ﬁlters different sizes. amongst networks similar computational requirements googlenet accurate large scale image classiﬁcation tasks partly heterogeneous ﬁlters inception modules also low-dimensional embeddings global pooling. figure learned cross-shaped filters. cross-shaped ﬁlters learned weighted linear combination basis ﬁlters ﬁrst convolutional layer ‘vgggmp-lr-join’ model trained using ilsvrc dataset. determine standard deviations used weight initialization approach similar described glorot bengio layers followed relu). appendix show details derivation generalizing approach initialization ‘composite’ layers comprising several groups ﬁlters different spatial dimensions main contributions work. validate approach show replace ﬁlters used existing state-of-the-art network architectures low-rank representations described reduce computational complexity without reducing accuracy. characterize computational complexity using number multiply accumulate operations required forward pass however observed strong correlation multiply-accumulate counts runtime implementations networks described note caffe timings differ initial convolutional layers input sizes much smaller blas less efﬁcient relatively small matrices multiplied. methodology. augment training randomly cropped mirrored images scale photometric augmentation over-sampling. allows compare efﬁciency different network architectures without factor computational cost various augmentation methods used elsewhere. training every model except googlenet adjust learning rate according schedule initial learning rate learning rate iteration weight decay respectively validation accuracy levels manually reduce learning rate factors validation accuracy longer increases. unless otherwise indicated aside changing standard deviation normally distributed weight initialization explained used standard hyper-parameters given model. results test-time augmentation. evaluated classiﬁcation accuracy vgg- based architectures using datasets imagenet large scale visual recognition challenge places. ilsvrc dataset comprises training images object classes commonly evaluated top- top- accuracy image validation set. places dataset comprises training images scene classes evaluated top- top- accuracy image validation set. vgg- -layer convolutional network introduced simonyan zisserman family network architectures used simonyan zisserman obtain state-of-the-art accuracy ilsvrc uses fewer convolutional layers therefore single training. training vgg- based models used standard hyperparameters detailed simonyan zisserman initialization follows compare accuracy number different network architectures detailed appendix table results ilsvrc given table plotted fig. results places given table plotted fig. baseline compared version network described variant replaces ﬁnal pooling layer ﬁrst fully connected layer global pooling operation similar global average pooling used szegedy evaluated accuracy baseline vgg- network global max-pooling without datasets. trained networks stride ilsvrc dataset stride larger places dataset. globally max-pooled variant vgg- uses fewer parameters original network gives consistently better accuracy almost percentage points lower top- error ilsvrc baseline vgg- network ilsvrc used network baseline rest experiments. separable filters. evaluate separable ﬁlter approach described replaced convolutional layer vgg- sequence layers ﬁrst containing horizontally oriented ﬁlters second containing vertically oriented ﬁlters ﬁlters applied sequence represent kernels using dimensional basis space. unlike jaderberg trained network scratch instead approximating full-rank ﬁlters previously trained network. compared original vgg- network separable ﬁlter version requires approximately less compute. results shown table ilsvrc table places. accuracy network approx. lower baseline vgg--gmp network ilsvrc broadly comparable places. approach give signiﬁcant reduction computational complexity follows nonetheless interesting separable ﬁlters capable achieving quite high classiﬁcation accuracy challenging tasks. simple horizontal/vertical basis. demonstrate efﬁcacy simple rank ﬁlter representation illustrated fig. created network architecture replacing convolutional layers vgg- sequence layers. ﬁrst layer comprises half ﬁlters half ﬁlters whilst second layer comprises number ﬁlters. resulting network approximately faster original gives broadly comparable accuracy ilsvrc places datasets. tion trained network vgg-gmp-lr-join-wfull mixture ﬁlters preserving total number ﬁlters baseline network network signiﬁcantly accurate ‘vgg-gmp-lr-join’ baseline top- center crop accuracy ilsvrc computational savings approx. baseline. note accuracy approx. percentage point higher googlenet. implicitly learned combinations. addition network similar vgg-gmp-lr-join without convolutional layer used contributions ﬁlters interestingly elimination extra layers gives additional compute saving model compute baseline reduction accuracy. seems consequence fact subsequent convolutional layer capable learning effective combinations ﬁlter responses even intermediate relu non-linearity. also trained network double number convolutional ﬁlters i.e. equal number ﬁlters ﬁlters shown fig. found increase accuracy still approximately faster baseline network. low-dimensional embeddings. attempted reduce computational complexity ‘gmp-lr’ network vgg-gmp-lr-lde network using stride ﬁrst convolutional layer adding low-dimensional embeddings szegedy reduced number output channels half convolutional layer using convolutional layers detailed appendix table reduces computation signiﬁcantly approx. compared baseline decrease top- accuracy ilsvrc percentage points. note however network remains percentage points accurate original vgg- network faster. table ilsvrc results. accuracy multiply-accumulate count number parameters baseline vgg- network efﬁcient versions created methods described paper. table places results. accuracy multiply-accumulate operations number parameters baseline ‘vgg--gmp’ network separable ﬁlter network described jaderberg efﬁcient models created methods described paper. networks trained stride places dataset. figure ilsvrc results. multiply-accumulate operations v.s. top- error vgg-derived models ilsvrc object classiﬁcation dataset efﬁcient networks closer origin. models signiﬁcantly faster baseline network case ‘gmp-lr-x’ factor almost slightly lowering error. note ‘gmp-lr’ ‘gmp-lr-join’ networks accuracy showing explicit linear combination layer unnecessary. googlenet introduced szegedy efﬁcient network ilsvrc getting close state-of-the-art results fraction compute model size even vgg-. googlenet inception module composite layer homogeneously-shaped ﬁlters output average pooling operations. concatenated used input successive layers. googlenet-lr network within inception modules replaced ﬁlters low-rank ﬁlters replaced layer ﬁlters low-rank ﬁlters. googlenet-lr-conv network similarly replaced ﬁrst second layer convolutional layers layers respectively. results shown table intermediate losses used training contain fully-connected layers googlenet test time model size signiﬁcantly smaller training time model size. table also reports test time model size. low-rank network delivers comparable classiﬁcation accuracy using less compute. networks produce comparable accuracy within order magnitude compute. note although caffe pre-trained googlenet model top- accuracy training network using given model deﬁnition including hyper-parameters training schedule different random initialization top- accuracy table googlenet ilsvrc results. accuracy multiply-accumulate count number parameters baseline googlenet network efﬁcient versions created methods described paper. network-in-network cifar- object classification cifar- dataset consists images classes images class. split standard sets training images test images baseline cifar- dataset used network network architecture published test-set error also used random crops training network error like state cifar results pre-processed training test data training time mirror augmentation random sub-crops. results cifar experiments listed table plotted fig. table network-in-network cifar- results. accuracy multiply-accumulate operations number parameters baseline network-in-network model efﬁcient versions created methods described paper. architecture uses ﬁlters layers. found could replace ﬁlters comparable accuracy. suggested simonyan zisserman stacked ﬁlters effective receptive ﬁeld larger ﬁlters less computational complexity. nin-c network replaced ﬁrst convolutional layer layer second convolutional layer layers. network faster standard model model parameters. using low-rank ﬁlters network trained nin-c-lr network similar accuracy approximately original network’s computational complexity model parameters. somewhat surprising networks based learning ﬁlters less representational ability able well better cnns full ﬁlters task image classiﬁcation. however interesting small-scale image structure well-characterized low-rank ﬁlters e.g. edges gradients. experiments training separable model ilsvrc places show surprisingly high accuracy considered challenging problems approx. top- accuracy ilsvrc enough obtain comparable accuracies models based. given discriminative ﬁlters learned image classiﬁcation appear low-rank instead structure architectures basis ﬁlters illustrated fig. allows networks learn effective combinations complex simple ﬁlters. furthermore restricting many complex spatial ﬁlters learned architecture prevents over-ﬁtting helps improve generalization. even models square ﬁlters obtain comparable accuracies baseline model since rank- cross-shaped ﬁlters effectively learned combination ﬁlters capable representing complex local pixel relations rank- ﬁlters. paper presented method train convolutional neural networks scratch using lowrank ﬁlters. made possible initializing networks weights takes consideration presence differently shape ﬁlters composite layers. validation image classiﬁcation three popular datasets conﬁrms similar higher accuracy state much greater computational efﬁciency. recent advances state-of-the-art accuracy cnns image classiﬁcation come cost increasingly large computational complex models. believe results show learning computationally efﬁcient models fewer relevant parameters prevent overﬁtting increase generalization thus also increase accuracy. paper addressed spatial extents convolutional ﬁlters cnns however channel extents also exhibit redundancy highlighted jaderberg exploited form low-dimensional embeddings szegedy intend explore methods extended learn combine even smaller basis ﬁlters ﬁlters diverse shapes. goodfellow warde-farley david mirza mehdi courville aaron bengio yoshua. maxout networks. proceedings international conference machine learning yangqing shelhamer evan donahue jeff karayev sergey long jonathan girshick ross guadarrama sergio darrell trevor. caffe convolutional architecture fast feature embedding. arxiv preprint arxiv. krizhevsky alex sutskever ilya hinton geoffrey imagenet classiﬁcation deep convolutional neural networks. pereira burges c.j.c. bottou weinberger k.q. advances neural information processing systems curran associates inc. szegedy christian yangqing sermanet pierre reed scott anguelov dragomir erhan dumitru vanhoucke vincent rabinovich andrew. going deeper convolutions. corr abs/. start training network weights initialized random using samples drawn gaussian distribution standard deviation parameter speciﬁed separately layer. found setting parameters critical success network training difﬁcult right particularly published parameter settings used elsewhere suitable network architectures. unsuitable weight initialization training fail exploding gradients back propagated gradients grow large cause numeric overﬂow vanishing gradients back propagated gradients grow small effect dwarfed weight decay loss decrease training determine standard deviations used weight initialization approach similar described glorot bengio layers followed relu). approach works ensuring magnitudes backpropagated gradients remain approximately throughout network. otherwise gradients inappropriately scaled factor ﬁnal back-propagated signal would scaled potentially much larger factor follows adopt notation similar follow derivation appropriate standard deviation weight initialization. however also generalize approach initialization ‘composite’ layers comprising several groups ﬁlters different spatial dimensions main contributions work. vector representing pixel output feature vector represents subregion c-channel input feature map. weight matrix number ﬁlters size ﬁlter i.e. ﬁlter spatial dimensions operating input feature channels bias. finally output previous layer passed activation function denote derivatives loss respect input output pixels. vector gradients respect channels single pixel input feature represents pixels channels output feature map. matrix ﬁlter weights arranged right order back-propagation whd. note simply reshaped also note elements correspond pixels output image forwards dependency input image pixel corresponding back propagation element related element ∆xl+ ∆xl+ derivative activation function relu case zero equal probability. like glorot bengio assume independent other. thus equation implies zero mean initialized distribution symmetric around zero. thus figure composite layer. composite layers convolve input feature groups convolutional ﬁlters several different spatial dimensions. group ﬁlters spatial dimension outputs concatenated create channel output feature map. composite layers require careful weight initialization avoid vanishing/exploding gradients training. weight initialisation composite layers. initialization scheme described assumes layer comprises ﬁlters spatial dimension extend scheme composite convolutional layers containing groups ﬁlters different spatial dimensions denotes group index n}). layer response concatenation responses group ﬁlters vector representing response pixel output feature map. whc× vector represents different shaped sub-region input weight matrix number ﬁlters feature map. size ﬁlter i.e. ﬁlter spatial dimension operating input feature channels. figure multiply-accumulate operations caffe cpu/gpu timings. forward pass convolutional layer ‘vgg-gmp-lr’ network. caffe timings well correlated multiply-accumulate operations layers. characterized computational complexity using number multiply accumulate operations required forward pass give close possible hardware implementation independent evaluation computational complexity method. however observed strong correlation multiply-accumulate counts runtime implementations networks described note caffe timings differ initial convolutional layers input sizes much smaller blas less efﬁcient relatively small matrices multiplied. figures compare published top- ilsvrc validation error v.s. multiply-accumulate operations number model parameters several state-of-the-art networks error rates networks reported obtained different combinations computationally expensive training test time augmentation methods including scale photometric ensembles multiview/dense oversampling. makes difﬁcult compare model architectures especially respect computational requirements. state-of-the-art networks msra-c vgg- oversampled googlenet orders magnitude larger computational complexity networks. fig. multiplyaccumulate operations plotted scale increasing model size and/or computational complexity test-time augmentation cnns appears diminishing returns decreasing validation error. models without training test time augmentation show comparable accuracy networks vgg- training test time augmentation less computational complexity model size. particular ‘googlenet-lr’ model much smaller test-time model size network comparable accuracy. table state single models extra augmentation. top- ilsvrc validation accuracy single view augmented test-time multiply-accumulate count number parameters various state models various training test-time augmentation methods. multi-model ensemble msra-c current state network. following several plots results reasons space consideration main section paper. include results vgg-derived models places googlenet-derived models ilsvrc ﬁnally results network-in-networkderived models cifar- figure computational complexity single state-of-the-art ilsvrc models. test-time multiply-accumulate operations v.s. top- error state networks using single model. note difference accuracy computational complexity vgg- model with/without extra augmentation. ‘vgg-gmp-lr-join-wfull’ model without extra augmentation accurate vgg- extra augmentation much less computationally complex. figure number parameters state-of-the-art ilsvrc models. test time parameters v.s. top- error state models. main factor reduced model size global pooling lack fully-connected layers. note ‘googlenet-lr’ model almost order magnitude smaller network comparable accuracy. figure googlenet ilsvrc results. multiply-accumulate operations v.s. top- error googlenet-derived models ilsvrc object classiﬁcation dataset. figure network-in-network cifar- results. multiply-accumulate operations v.s. error network-in-network derived models cifar- object classiﬁcation dataset.", "year": 2015}