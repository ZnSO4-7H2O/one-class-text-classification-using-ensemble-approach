{"title": "Search Engine Guided Non-Parametric Neural Machine Translation", "tag": ["cs.CL", "cs.AI", "cs.LG"], "abstract": "In this paper, we extend an attention-based neural machine translation (NMT) model by allowing it to access an entire training set of parallel sentence pairs even after training. The proposed approach consists of two stages. In the first stage--retrieval stage--, an off-the-shelf, black-box search engine is used to retrieve a small subset of sentence pairs from a training set given a source sentence. These pairs are further filtered based on a fuzzy matching score based on edit distance. In the second stage--translation stage--, a novel translation model, called translation memory enhanced NMT (TM-NMT), seamlessly uses both the source sentence and a set of retrieved sentence pairs to perform the translation. Empirical evaluation on three language pairs (En-Fr, En-De, and En-Es) shows that the proposed approach significantly outperforms the baseline approach and the improvement is more significant when more relevant sentence pairs were retrieved.", "text": "paper ﬁrst notice ability incorporating arbitrary meta-data neural machine translation allows naturally extend model neural machine translation system explicitly takes account full training consisting source-target sentence pairs build neural machine translation system considers given source sentence translated also training sentence pairs process translation. propose novel extension attention-based neural machine translation seamlessly fuses information streams corresponds current source sentence training sentence pairs respectively. major technical challenge designing neural machine translation system scale training parallel corpus often consists hundreds thousands millions sentence pairs. address issue incorporating off-the-shelf black-box search engine proposed neural machine translation system. proposed approach ﬁrst queries search engine indexes whole training given source sentence proposed neural translation system translates source sentence incorporating retrieved training sentence pairs. proposed translation system automatically adapts search engine ability retrieve relevant sentence pairs training corpus. evaluate proposed search engine guided neural machine translation three language pairs jrcacquis corpus consists documents legal domain. corpus selected demonstrate efﬁcacy proposed approach training corpus test sentences similar domain. experiments reveal proposed approach exploits availability retrieved training sentence pairs well achieving signiﬁcant improvement strong baseline attention-based neural machine translation. paper extend attention-based neural machine translation model allowing access entire training parallel sentence pairs even training. proposed approach consists stages. ﬁrst stage– retrieval stage– off-the-shelf black-box search engine used retrieve small subset sentence pairs training given source sentence. pairs ﬁltered based fuzzy matching score based edit distance. second stage–translation stage– novel translation model called search engine guided seamlessly uses source sentence retrieved sentence pairs perform translation. empirical evaluation three language pairs shows proposed approach signiﬁcantly outperforms baseline approach improvement signiﬁcant relevant sentence pairs retrieved. neural machine translation recently proposed paradigm machine translation single neural network often consisting encoder decoder recurrent networks trained end-to-end source sentence corresponding translation. success neural machine translation already adopted major industry players machine translation often attributed advances building training recurrent networks well availability large-scale parallel corpora machine translation. neural machine translation characteristically distinguished existing approaches machine translation phrase-based statistical machine translation projects sequence discrete source symbols continuous space decodes back corresponding translation. allows easily incorporate auxiliary information neural machine translation system long auxiliary information could encoded continuous space using neural network. property noticed recently used copyright association advancement artiﬁcial intelligence rights reserved. neural machine translation paper start recently proposed widely used attention-based neural machine translation model. attentionbased neural translation model conditional recurrent language model conditional distribution possible translations given source sentence xtx}. conditional recurrent language model autoregressive model estimates correspond read-out function maps hidden state distribution target vocabulary recurrent activation function summarizes previously decoded target symbols respect timedependent context vector respectively. functions parametrized parameters learned jointly maximize log-likelihood training parallel corpus. composed bidirectional recurrent network encoder attention mechanism. source sequence ﬁrst encoded annotation vector htx} concatenation hidden states forward reverse recurrent networks. attention mechanism implemented feedforward network single hidden layer computes attention score hidden state given previously decoded target symbol previous decoder hidden state attention-based neural machine translation system end-to-end trained maximize likelihood correct translation given corresponding source sentence. testing given source sentence translated searching likely translation trained model. entire process training testing considered compressing whole training corpus neural machine translation system training corpus discarded training over. translation memory translation memory computer-aided translation tool widely used professional human translators. database pairs source phrase translation. database constructed incrementally human translator translates sentences. source sentence present phrases original sentence queried translation memory corresponding entries displayed human translator speed process translation. problem sparsity exact matches rarely occur approximate string matching often used. paper consider general notion translation memory translation phrase pairs kind translation pairs stored. general deﬁnition training parallel corpus also considered translation memory. saves building phrase table another active research topic requires efﬁcient ﬂexible retrieving relevant translation pairs given source sentence issue data sparsity ampliﬁes. motivates come efﬁcient query algorithm tied together downstream translation model overcome problem data sparsity. propose non-parametric neural machine translation model guided off-the-shelf efﬁcient search engine. unlike conventional neural machine translation system proposed model discard training corpus maintain actively exploit test time. effectively makes proposed neural translation model fully non-parametric model. proposed nonparametric neural translation model consists stages. ﬁrst stage retrieval stage proposed model queries training corpus equivalently translation memory retrieve source-translation pairs given current source sentence. maximize computational efﬁciency ﬁrst utilize off-the-shelf highlyoptimized search engine quickly retrieve large similar source sentences translations top-k pairs selected using approximate string matching based edit distance. second stage given source sentence translated attention-based neural machine translation model refer search engine guided neural machine translation incorporates retrieved translation pairs ﬁrst stage. order maximize retrieved pairs build novel extension attentionbased model performs attention source symbols also retrieved symbols allow model option copy target symbol directly retrieved translation pairs. overall architecture simple translation example proposed seg-nmt shown fig. reference. figure overarchitecture proposed seg-nmt. shaded includes module handles translation pairs retrieved ﬁrst stage. heat maps represent attention scores source sentences corresponding translations clearly practical size training corpus often order hundreds thousands even tens millions. overcome issue scalability incorporating offthe-shelf search engine speciﬁcally apache lucene. lucene retrieve initial translation pairs based source side similarity score re-rank them. final selection process initial translation pairs returned lucene. rank translation pairs within design test methods selecting ﬁnal initial based similarity scores. ﬁrst method top-k retrieval simply return similar translation pairs second method returns adaptive number translation pairs based coverage symbols current source sentence within retrieved translation pairs. select greedily starting similar translation pair described alg. translation stage second stage build novel extension attention-based neural machine translation seg-nmt seamlessly fuses current source sentence retrieved translation pairs. high level proposed seg-nmt ﬁrst stores target symbol retrieved translation pair key-value memory. time step decoder seg-nmt ﬁrst performs attention current source sentence compute time-dependent context vector based key-value memory queried. seg-nmt fuses information context vector current source sentence retrieved value key-value memory generate next symbol. similarity score function paper constrain setting neural translation model trainable. assume availability trainable sentence similarity functions. allows focus entirely effectiveness proposed algorithm agnostic choice similarity metric. constraint follow earlier work fuzzy matching score deﬁned algorithm greedy selection procedure maximize coverage source symbols. require input translation memory obtain subset using off-the-shelf search re-rank retrieved pairs using similarity initialize dictionary selected pairs initialize coverage score ...| return off-the-shelf search engine computational complexity similarity search grows linearly size translation memory case contains pairs training corpus. despite simplicity computational efﬁciency similarity score translation model speciﬁed parameter obtain target symbol decoder’s hidden state associated time-dependent context vector summarizes subset source sentence best describes yt). consider value store retrieved translation pairs key-value memory. note approach agnostic many translation pairs retrieved ﬁrst stage. matching retrieval time step segnmt decoder ﬁrst compute context vector given previous decoder hidden state previously decoded symbol annotation vector context vector used querying keyvalue memory. instead hard matching propose soft matching based bilinear function compute matching score key-value slot scores used retrieve value keyvalue memory. case decoder’s hidden states case target symbols consider computed score probability corresponding target symbol. pcopyτ similarly pointer network. incorporation consider separate approaches incorporating retrieved values key-value memory motivated ﬁrst approach called deep fusion weighted-average retrieved hidden state decoder’s hidden state approaches gating variable target symbol require different source information variable determined automatically proposed seg-nmt. introduce another feedforward network computes fgate. gate closes retrieved pairs useful predicting next target symbol opens otherwise. algorithm learning seg-nmt require search engine model model initialize number returned answers stopping criterion draw translation pair obtain memory pairs reference memory ...k generate dynamic keys coverage preliminary experiments notice access pattern key-value memory highly skewed toward small number slots. motivated coverage penalty propose augment bilinear matching function coverage vector learning inference proposed model including ﬁrst second stages trained end-to-end maximize loglikelihood given parallel corpus. practical training preprocess training parallel corpus augmenting sentence pair translation pairs retrieved search engine ensuring exact copy included retrieved set. alg. detailed description. testing search whole training retrieve relevant translation pairs. similarly standard neural translation model beam search decode best translation given source sentence. principal idea seg-nmt shares major similarities example-based machine translation indexes parallel corpora sufﬁx arrays retrieves translations test time. however best knowledge seg-nmt ﬁrst work incorporating attention-based neural machine translation architectures trained end-to-end efﬁciently showing superior performance scalability compared conventional statistical ebmt. seg-nmt also largely motivated recently proposed multilingual attention-based neural machine translation models. similar multilingual models model takes account information current source sentence. allows model better cope uncertainty ambiguity arising single source sentence. recently kind larger context translation applied cross-sentential modeling translation current sentence done respect previous sentences. devlin proposed automatic image caption generation model based nearest neighbours. approach given image queried training pairs images corresponding captions. proposed median caption among nearest neighboring captions generated caption given image. approach shares similarity ﬁrst stage proposed seg-nmt. however unlike approach learn generate sentence rather simply choose among retrieved ones. bordes proposed memory network large-scale simple question-answering using entire freebase. output module memory network used simple n-gram matching create small candidate facts freebase. candidates scored memory network create representation used response module. similar approach exploits black-box search module generating small candidate set. similar approach recently proposed deep reinforcement learning pritzel store pairs observed state corresponding value key-value memory build non-parametric deep network. consider conﬁrmation general applicability proposed approach wider array problems machine learning. context neural machine translation kaiser also proposed external key-value memory remember training examples test time. lack efﬁcient search mechanism update memory jointly translation model unlike proposed approach paper. important property proposed seg-nmt relies external black-box search engine retrieve relevant translation pairs. search engine used training testing obvious next step allow proposed seg-nmt intelligently query search engine instance reformulating given source sentence. recently nogueira proposed taskoriented query reformulation neural network trained black-box search engine maximize recall relevant documents integrated proposed seg-nmt. leave future work. data jrc-acquis corpus evaluating proposed seg-nmt model. jrc-acquis corpus consists total body european union applicable member states. text corpus well structured text corpus related making ideal test evaluate proposed seg-nmt relies availability appropriate translation pairs training set. corpus also used investigating combination translation memory phrase-based statistical machine translation making suitable proposed method evaluate select three language pairs namely en-fr en-es en-de evaluation. language pair uniformly select sentence pairs random development test sets. rest used training removing sentence contains special characters only. sentences lengths training dev/test sets respectively. lowercase text byte-pair encoding extract vocabulary subword symbols. table detailed statistics. retrieval stage apache lucene index whole training retrieve pairs source sentence initial retrieval. pairs scored current source sentence using fuzzy matching score select top-k relevant translation pairs. vary among training among testing investigate trade-off retrieval translation quality. testing also evaluate effect adaptively deciding number retrieved pairs using proposed greedy selection algorithm translation stage standard attention-based neural machine translation model gated recurrent units encoder decoder. train vanilla model well proposed seg-nmt based conﬁguration scratch using adam initial learning rate minibatch sentence pairs. early-stop based development performance. evaluation beam search width figure bleu scores fr→en using varying numbers retrieved translation pairs testing. model trained once. adaptive refers proposed greedy selection alg. become less related current source sentence. best quality achieved proposed greedy selection algorithm alg. used case translation pairs retrieved average. deep shallow fusion directions en-fr implemented tested deep shallow fusion incorporating information retrieved translation pairs. deep fusion only bleu scores development improved baseline respectively improvements respectively. suggests proposed model effectively exploits availability target symbols retrieved translation pairs. experiments thus done using shallow fusion only. examples list good examples proposed method makes mistake fig. examples proposed seg-nmt selects term phrase used retrieved pair whenever ambiguities multiple correct translations. instance ﬁrst example seg-nmt translated précis exact used retrieved pair baseline model chose precise. similar behavior found examen second example. behavior helps proposed seg-nmt generate translation style choice vocabulary match better translations training corpus improves overall consistency translation. efﬁciency general points computational complexity increases. ﬁrst point occurs retrieval stage incurs almost overhead rely efﬁcient search engine translation stage complexity indexing key-value memory grows w.r.t. tokens retrieved pairs. increase however constant case proposed seg-nmt parametrize metric matrix similarity score function diagonal initialized identity matrix. initialized gating network fgate feedforward network single hidden layer like attention mechanism fatt. either deep fusion shallow fusion experiments. table present bleu scores obtained three language pairs using three approaches; carbon copy target side retrieved translation pair highest matching score baseline translation model proposed seg-nmt model. evident table proposed segnmt signiﬁcantly outperforms baseline model cases improvement merely copying similar translation training set. fr-en en-fr also present performance using copynet variant uses copying mechanism directly target side searched translation pair. copynet variant helps much proposed approach. conjecture happens proposal using key-value memory captures relationship source target tokens retrieved pairs tightly. fuzzy matching score v.s. quality fr→en broke development bins according matching score retrieved translation pair computed bleu score bin. shown fig. note improvement grows relevance retrieved translation pair increases. veriﬁes seg-nmt effectively exploits retrieved translation pairs also suggests future improvement case relevant translation pair exists training set. effect retrieved translation pairs proposed model trained used varying number retrieved translation pairs. test model trained fr→en different numbers retrieved translation pairs present bleu scores fig. notice translation quality increases number retrieved pairs increase approximately four degrades. believe happens retrieved sentences figure three examples fr→en test set. proposed seg-nmt model translation pair retrieved training set. token translation proposed approach corresponded token retrieved pair shaded blue according gating variable show source sentence. source side retrieved pair. target side retrieved pair. translation proposed approach. translation baseline. reference translation. proposed practical non-parametric extension attention-based neural machine translation utilizing off-the-shelf black-box search engine quickly selecting small subset training translation pairs. proposed model called seg-nmt learns incorporate sourcetarget-side information retrieved pairs improve translation quality. empirically showed effectiveness proposed approach jrc-acquis corpus using language pair-directions. although proposed approach context machine translation generally applicable wide array problems. embedding input modality ﬁxed vector space using approximate search approach instance used open-domain question answering seamless fusion multiple sources information retrieved search engine core. leave future work.", "year": 2017}