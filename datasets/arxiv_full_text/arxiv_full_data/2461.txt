{"title": "Inferring Cognitive Models from Data using Approximate Bayesian  Computation", "tag": ["cs.HC", "cs.AI", "cs.LG", "stat.ML"], "abstract": "An important problem for HCI researchers is to estimate the parameter values of a cognitive model from behavioral data. This is a difficult problem, because of the substantial complexity and variety in human behavioral strategies. We report an investigation into a new approach using approximate Bayesian computation (ABC) to condition model parameters to data and prior knowledge. As the case study we examine menu interaction, where we have click time data only to infer a cognitive model that implements a search behaviour with parameters such as fixation duration and recall probability. Our results demonstrate that ABC (i) improves estimates of model parameter values, (ii) enables meaningful comparisons between model variants, and (iii) supports fitting models to individual users. ABC provides ample opportunities for theoretical HCI research by allowing principled inference of model parameter values and their uncertainty.", "text": "abstract important problem researchers estimate parameter values cognitive model behavioral data. difﬁcult problem substantial complexity variety human behavioral strategies. report investigation approach using approximate bayesian computation condition model parameters data prior knowledge. case study examine menu interaction click time data infer cognitive model implements search behaviour parameters ﬁxation duration recall probability. results demonstrate improves estimates model parameter values enables meaningful comparisons model variants supports ﬁtting models individual users. provides ample opportunities theoretical research allowing principled inference model parameter values uncertainty. introduction become relatively easy collect large amounts data complex user behaviour. provides exciting opportunity data potential help researchers understand possibly predict user behavior. unfortunately remained difﬁcult explain users given data set. sufﬁciently general capture broad range behaviors. model attempting explain real-world observations must cover complex interplay factors including users interested individual capacities choose process information recent research shown progress direction creating models complex behavior constructing model faced inference problem parameter values model values agree literature prior knowledge resulting predictions match observations unfortunately problem less systematically studied hci. goal paper report investigation ﬂexible powerful method inferring model parameter values called approximate bayesian computation applied many scientiﬁc problems example climatology goal infer model climate sensor readings infectious disease epidemiology epidemic model reports infection spread. inference great applications theory-formation particular testing models identifying anomalies ﬁnding explanations observations. however principled inference method have knowledge applied complex cognitive models hci. interested principled methods inferring parameter values would especially useful process models behaviour. models usually deﬁned simulators thus inference difﬁcult perform using direct analytical means. process models created example based cognitive science control theory biomechanics game theory foraging economic choice computational rationality absence principled inference methods models approaches permission make digital hard copies part work personal classroom granted without provided copies made distributed proﬁt commercial advantage copies bear notice full citation ﬁrst page. copyrights third-party components work must honored. uses contact owner/author. copyright held owner/author. denver ----//. http//dx.doi.org/./. simpler models regression models exist well-known methods ﬁnding parameter values ordinary least squares. technical terms models generally likelihood function—deﬁning likelihood parameter values given observations—that could written closed form. task solution objectives. given those constraints situation machine learning infer optimal behavior policy. however achieving inverse inferring constraints assuming behavior optimal exceedingly difﬁcult. assumptions data quality granularity previously explored methods inverse reinforcement learning problem tend unreasonable often noisy aggregate-level data exists often case studies. application case recent model menu interaction model studied previously captured adaptation search behavior consequently changes task completion times various situations model makes parametric assumptions user example visual system uses reinforcement learning obtain behavioral strategy suitable particular menu. inverse problem study obtain estimates properties user’s visual system selection time data however complexity model parameter values originally tuned based literature. later study demonstrate able infer parameter values model based observation data predictions improve baseline parameter values still agree literature. best knowledge also ﬁrst time inverse reinforcement learning problem solved based aggregate-level data. also demonstrate applicability inference general situations model development modeling individuals. study demonstrate allows make meaningful comparisons multiple model variants comparable parameters dataset. presents method speeding development kind complex models though automatic inference model parameter values. study demonstrate allows infer model parameter values individual users. discover overall individual models outperform populationlevel model larger data thus demonstrating beneﬁt individual models. comparison would possible individual models based literature alone information generally applies population level. overview approach paper concerned inference model parameter values data also called inverse modeling. inverse modeling answers question what parameter values model assuming observed data generated model? goal assess usefulness approximate bayesian computation end. figure paper studies methodology inference parameter values cognitive models observational data hci. bottom ﬁgure behavioral data times targets menu selections. ﬁgure cognitive model generates simulated interaction data paper approximate bayesian computation investigated identify model parameter values yield best real data simulator-generated data keeping parameter values reasonable given prior knowledge. included simplifying models traditional inference methods possible; using values adopted literature adjusting without studying effect behavior; manually iterating values lead acceptable performance. compared this principled inference methods might reduce potential ambiguity miscalculation bias model parameter values could properly conditioned literature prior knowledge well observation data. particularly promising inferring values process model parameters naturalistic data—a problem known difﬁcult cognitive science reason make assumptions model apart researcher able repeatedly simulate data using different parameter values. performs inference systematically simulating user behavior different parameter conﬁgurations. based simulations estimates parameter values lead behavior similar observations also reasonable considering prior knowledge plausible parameter values. challenging representative example paper looks recent process model class behavioral strategies learned using reinforcement learning models assume users behave maximize utility given limits capacity. models predict user behave situations constrained environment physical structure user interface goals trade-off time effort; user’s cognitive perceptual capabilities memory capacity ﬁxation duration. class models called computational rationality models explored previously example snif-act economic models search foraging theory adaptive interaction recent interest class beneﬁt that compared classic cognitive models requires predeﬁned speciﬁcation user’s figure overview inference process models observed user data priors parameters algorithm approximates posterior distribution parameter values. algorithm iterates choosing values parameters model generating simulated user data. models generating simulated data requires ﬁrst training reinforcement learning agent using given parameter values. write formula likely parameter values given data. complex models formula might exist often possible write explicit likelihood function evaluates likelihood parameters given observed data yobs. likelihood function evaluated efﬁciently inverse modeling done even reinforcement learning models however inverse reinforcement learning possible precise observations available environment states actions agent took applications rarely case. likelihood function model evaluated efﬁciently generally options left. traditional model parameters based past models existing literature. acceptable predicted behavior researcher might tuned parameters hand predictions satisfactory. however process generally guarantees ﬁnal parameters close likely values. alternative solution seen used context before would likelihood-free inference methods allow model parameters estimated without requiring likelihood function evaluated directly. methods derived based mathematical principles thus offer performance guarantees least asymptotic case. method explain next detail. approximate bayesian computation principled method ﬁnding parameter values complex models including simulators based observed data prior knowledge. repeatedly simulates data using different parameter values order regions parameter space lead simulated data similar observed data. different algorithms differ example choose parameter values. main beneﬁt generality assumption needed researcher able repeatedly simulate observations different parameter values. therefore paper examine particular simulator approach general value. precise used following recurring scenario inputs model unknown parameters prior knowledge reasonable values yobs still plausible given prior knowledge. process using depicted figure first researcher implements model executable simulator. values well-known parameters model hand. inferred parameters prior probability distribution deﬁned researcher based prior knowledge plausible values. researcher deﬁnes observations yobs conditioned next researcher deﬁnes discrepancy function quantiﬁes similarity observed simulated data meaningful researcher. finally algorithm run; selects parameter values {θi} simulator conditional distribution parameter values also known posterior constructed based simulations. bolfi variant used paper paper employs recent variant called bolfi reduces number simulations still able adequate estimates overview method shown figure main idea bolfi learn statistical regression model—called gaussian process—for estimating discrepancy values feasible domain smaller number samples densely cover whole parameter space. justiﬁed situation small changes yield large changes discrepancy. additionally interested ﬁnding regions discrepancy small bolfi uses modern optimization method called bayesian optimization selecting locations simulate. concentrate samples parameter regions likely lead discrepancy simulated data. approach resulted naive would simulate large amount samples densely covering parameter space keep lowest discrepancy values. method also known rejection abc. however case simulations take multiple hours each approach infeasible total computation time. figure left bolfi ﬁnds parameter values best able reproduce empirical observations right bolfi ﬁrst constructs statistical regression model predicting discrepancy values associated different parameter values uses lower conﬁdence bound values choosing next sample location θnext. case model menu selection case looks recent model visual search menus introduced chen purpose model predict visual search behavior task completion times person searching item vertical menu. model presents particularly challenging problem inference parameter values substantial computation required reinforcement learning algorithm calculate search behavior policy given particular parameter set. parameters chen al.’s model describe cognitive characteristics user duration saccade searching menu. contrast chen parameters largely values literature inference problem study estimate parameter values based limited behavioral data click times menu items. across studies condition parameter values model it’s variants type data different settings. introduction computational rationality important property model examine computes computationally rational policies—behavior patterns optimized maximize utility agent given bounds goals bounds include limitations observation functions actions agent perform. bounds deﬁne space possible policies. computationally rational agents model cognition heavily inﬂuenced rational analysis method explaining behavior terms utility idea used example information foraging theory economic models search computational rational agents used model number phenomena applications relevant paper include menu interaction visual search models reinforcement learning methods compute optimal policies applying prerequisites. first environment needed state agent observe actions agent perform change state. environment commonly markov decision process designed approximate real-world situation real user faces. second reward function required—a mapping states environment real numbers—which deﬁnes kind states valuable agent algorithm ﬁnds optimal policy experimenting environment updating policy until convergence. resulting policy—and thus predicted behavior—naturally depends parameters environment reward function researcher. environment menu composed eight items arranged semantic groups four items each items group share semantic similarity. conditions menu either item present menu absent. beginning episode agent shown target item. task agent select target item menu present otherwise declare menu contain target item. agent possible actions ﬁxate items select ﬁxated item declare item present menu fixating item reveals semantic relevance agent whereas selecting item quitting ends episode. action agent observes state environment represented variables semantic relevances observed menu items current ﬁxation location. agent receives reward action. ﬁxation action agent gets penalty corresponds time spent performing saccade previous location ﬁxation item. agent performs correct action large reward given—otherwise action results large penalty. agent selects actions based expected cumulative rewards action allows agent receive starting current state—also known q-value stateaction pair terminology. q-values learned training phase million training episodes using q-learning algorithm. select action agent compares q-values action state chooses action highest value. figure case model simulation process ﬁgure computational rationality model user interaction drop-down menus adapted chen q-table constructed training phase; simulation phase kept ﬁxed. description fixation duration time cost selecting item probability recalling semantic relevances menu items ﬁrst ﬁxation episode probability perceiving semantic relevance menu items ﬁxated item comply reduce complexity state space assumed detectable difference length items. thus used model variant chen detectable feature semantic similarity target item. study reported below explore three additions model effect predictions. model parameters inferred across studies listed table experiments results rest paper show three case studies used improve current modeling practices. studies chen model core problem inverse modeling given aggregate observation data likely parameter values distribution predictions made model agree observations. study compared manual tuning demonstrate improve model inferring parameter values data compared common practice setting manually based literature. study model development demonstrate helps improving models ﬁtting multiple models data exposing differences anomalies. study modeling individual differences demonstrate individual models conditioning model individual data. dataset chen subset study reported bailly based study design nilsen study label shown user must click correct item menu elements quickly possible. items repeated multiple times understand practice effects. multiple menus used target position absence/presence target systematically varied. movement data collected processed ﬁxation saccade durations. twenty-one paid participants took part study. details study produced data reported implemented bolfi algorithm python. parts source code later published within open-source library likelihood-free inference running experiments study compared manual tuning ﬁrst study analyze much improve predictions made model conditioning values parameters observation data instead standard practice choosing parameter values manually. case study chosen represent common setting research aggregate data available. used model chen compared parameter values inferred based literature original paper predicted task completion times ﬁxation durations models compared observation data simplicity inferred value parameter ﬁxation duration fdur. rest model parameter values identical baseline model. value parameter conditioned observed aggregate task completion times chen value parameter based study brumby results shown figure parameter value inferred lead model predictions matching better observation data used modelling. holds ﬁxation duration. detail ground truth aggregated manually model predicted whereas model predicted predictions used maximum posteriori value predicted ﬁxation duration corresponds values often encountered e.g. reading tasks summary inferring ﬁxation duration parameter value using lead improved predictions compared setting parameter value manually based literature. inferred parameter value also reasonable based literature. observations resulting models closer inspection predictions made models exposed problematic issues improvements study ﬁrst issue aggregate predictions accurate predictions better compared manual tuning even abc-ﬁtted predictions reasonable split sub-cases according whether target present menu not. clearly visible figure notice predicted target absent actually around four times long actual user behavior. second issue concerns search strategies predicted model. chen showed model able learn behavior strategy agent would look ﬁrst topmost item second item figure comparison manual tuning inference predictions made conditioning parameter values aggregate-level observed data prior knowledge agree better observation data seen model predictions made setting parameter values manually based literature searched parameter values resulted small discrepancy model predictions observed aggregate-level data left column manual tuning parameter values based literature manual tuning. center column inference value fdur conditioned observation data using abc. right column observation data bailly aggregated data conditions. data target absent menu. data target present menu. ﬁrst item second semantic group. seen clear spike ﬁfth item proportion gazes target feature. however every attempt replicate result succeeded similar variation predicted strategies observed abc-ﬁtted model well. conclusion likely exist multiple behavior strategies almost equally optimal algorithm different local optima different realizations. possible q-learning guaranteed globally optimal strategy given inﬁnite amount learning samples; ﬁnite samples guaranteed. issue inference behavioral strategies discuss detail inferred strategies report results able repeat reliably. study model development next demonstrate used model improvement cycle models proposed compared. baseline start model introduced study features issues observed study show multiple different models conditioned observation data technical difference original implementation original q-learning performed predetermined menu realizations whereas generated menu every training session. original implementation thus converged slightly faster explored smaller part state space. figure study repeated execution chen model yields variations search patterns. none three independent realizations able reproduce noticeable spike item observation data. charts illustrate average proportions gazes target search episodes function target location. larger proportions indicate targets location average found earlier fewer gazes non-target items required. variant ﬁrst observed recorded ﬁxation duration longer target item present. hypothesized user might spend time conﬁrming judgment target item physically making selection using pointer. allow model capture behavior added additional delay dsel selection action. example mathematical model bailly implements similar selection latency. variant observed users able decide target item present menu using ﬁxation menu. hypothesis users able memorize menus allowing naturally ﬁnish task much faster recalled menu layout. capture behavior allowed agent instantly observe full menu ﬁrst ﬁxation probability prec. variant also observed study inferred number ﬁxations cases larger observation data. models predicted average ﬁxations target absent target present hypothesis user might observed semantic relevance neighboring items using peripheral vision allowing ﬁnish task smaller number ﬁxations. model chen peripheral vision component applied size-related information hypothesis also justiﬁed experiment setup bailly neighboring items fall within fovea thus making physiologically possible user observe semantic relevance neighboring items. capture behavior allowed agent observe semantic relevance items ﬁxated item menu probability psem implementation order able inference parameters needed make small additions simulator code interface setting values parameters implement described changes model. side described names priors parameters increased amount locations simulate. locations justiﬁed parameter increases size parameter space needs searched. also noticed study models able replicate behavior well menu conditions time. reason make small adjustment discrepancy function compared menu conditions separately. allow models better replicate full observed behavior. details provided appendix. predictions observation data. partly expected complex models general able dataset better. however priors able regularize parameter values reasonable ranges thus avoid over-ﬁtting models data. baseline model able predict behavior user well many variables. value fdur tcts predicted baseline model whereas ground truth predicted ﬁxation duration still reasonable although side compared observed means furthermore predicted number ﬁxations items menu whereas users performed ﬁxations. variant improved predictions baseline. value normal fdur dsel predicted tcts already reasonable estimate target present although still truth target absent. predicted ﬁxation durations improvement baseline present condition target absent condition. predicted numbers ﬁxations nearly identical baseline. variant improved predictions baseline variant value fdur dsel prec predicted tcts ﬁrst time able predict lower target absent case. however variation target absent quite large; predicted standard deviation whereas ground truth predicted ﬁxation durations already close ground truth target present condition. predicted numbers ﬁxations considerable improvement previous estimates. variant provided still slight improvements previous results. value fdur dsel prec psem predicted tcts slightly observations variant however variation distributions closer observed values variant predicted ﬁxation durations similar variant predicted numbers ﬁxations slightly better variant conclude able multiple model variants observation data make meaningful comparisons different models this. observed quality predictions increased added additional assumptions model expected figure study exposes changes model result changes predictions parameter values conditioned empirical data. baseline model study conditioned observed behavior target conditions time. variant selection delay feature added baseline variant menu recall feature added variant variant peripheral vision feature added variant observation data study reported results parameter values. color coding figure data target absent menu. data target present menu. models became ﬂexible also provided evidence features probably reﬂect actual user behavior well. furthermore found useful hypothesis comparison avoided manually trying large number different parameter values manually values lead reasonable predictions. study individual differences modeling research aims understanding general patterns user behavior. however understanding individuals differ important theoretical practical reasons. hand even seemingly simple interfaces like input devices show large variability user behavior. hand adaptive user interfaces ability-based design rely differentiating users based knowledge capabilities. ﬁnal case looks problem individual differences inverse modeling. study select group users individual model users. compare good predictions individual models able produce compared model data users dataset selected representative users study ﬁrst selected users dataset observations menu condition leaving users. ordered users based difference population mean summed menu conditions. good distribution different users experiment selected users furthest third furthest ﬁfth furthest away population mean well users closest third closest population mean. previous section. simplify analysis infer values parameters user keeping rest ﬁxed. inferred parameters prec psem. based study seemed less variation fdur dsel whereas memory acuity peripheral vision could plausibly vary individuals. ﬁxed value fdur dsel according estimate study selected users collected observations user dataset conditioned parameter values individual model user small dataset. parameter values population level model inferred study variant accuracy predictions made user individual model compared predictions made population level model. comparison considered predicted tcts numbers ﬁxations condition observed values report magnitude prediction errors. results predicted parameter values collected table individual model parameter values deviate around percentage points population level model parameter values reasonable magnitude individual variation. calculated magnitude prediction errors models taking absolute difference model predicted means observed data means feature. prediction errors population level model population data individual user data shown figure overall prediction errors population level model tend larger individual users whole population. shows population level models good explaining population level dynamics perform badly used explaining subject level dynamics. furthermore could expected prediction errors population level model tend larger users differ population mean. presents clear motivation developing individual models could help understand subject level dynamics especially regarding users differ population mean. prediction errors individual models individual user data shown figure overall observe rather consistent quality predictions made individual user models. exception user furthest away mean. likely user might performed task overall different rest users. example number ﬁxations taken user target absent target present. could indicate user unusually careful examining menu declaring target present. improvements prediction error magnitude changing population level model individual model shown figure overall trend individual user models improve prediction quality although always parts. users prediction errors decreased least three four predicted features. conclude using able models data individual users resulting individual models able produce better predictions population level model ﬁtted whole participant pool. performing modeling task would possible choosing values based literature information tends apply population level models. hand choosing parameter values manually user would required considerable amount manual labour able automate. moreover inverse modeling helped expose behavioral pattern well explained model discussion conclusion demonstrated applicable inverse modeling computationally rational models complex human behavior based aggregate behavioural data. highlighted advantages alternative methods inferring model parameter values hci. first method applicable wide range models relies assumptions. second parameter value estimates conditioned observation data well prior figure study leftmost prediction error population level data population level model right prediction errors individual users population level model. unit unit number ﬁxations ﬁxation. figure study decrease prediction error using individual models instead population level model individual users unit unit number ﬁxations ﬁxation. knowledge researcher might situation. over-ﬁtting model observation data avoided could happen tried maximize ability model replicate data. third inference process produces full posterior distribution parameter space instead point estimate allowing better analysis reliability estimates. study demonstrated able achieve better model compared setting model parameter value based literature manual tuning. also identiﬁed problems existing state-of-the-art model visual search related quality predictions convergence issues. study demonstrated applicability model comparison ﬁtting four different models dataset comparing resulting predictions inferred model parameter values. also proposed improvements existing state-of-the-art model demonstrated resulted improved quality predictions. together contributions help address substantial problem understanding interactive behaviour evident human factors years problem estimate model parameter values given strategic ﬂexibility human cognitive system consequences strategic ﬂexibility make difﬁcult test theories underlying information processing architecture; behaviour merely strategic mistakenly taken evidence architectural theory architectural parameters inverse modeling methods general addresses problem establishing principled mathematical relationship observed behaviour model parameter values. future inverse modeling might provide general framework implementing adaptive interfaces able interpret user behavior determine individual preferences capabilities intentions rather merely mapping actions directly effects. summary consider provide ample opportunities widespread research activity applications core inference methodology solving inverse problems arising research. acknowledgments work supported academy finland tekes supported eu-funded speedd project funded european research council european union’s horizon research innovation programme computational resources provided aalto science project. appendix bolfi implementation implemented bolfi python following details. used gaussian process model python library model discrepancy. kernel matern variance scale noise variance ﬁrst ninit sample locations drawn quasi-random sobol sequence remaining sample locations decided follows. created function computed lower conﬁdence bound µgp− bσgp. used asynchronous parallel sampling needed acquire multiple locations reasonable also sufﬁciently well apart. purpose created function calculated radial-basis function kernels centered locations currently sampled ∑p∈p aexp/l). used acquisition function next sample location minx additionally chance location drawn prior instead acquisition function. study model trained q-learning million training episodes simulated episodes visualizing behavior predicted trained model. observation data target item absent sessions chen paper assumed absent cases. tried splits training data large overdifference results. subsequent experiments also used split might remove possible source bias. prior fdur truncated gaussian distribution mean prior intuition values between likely whereas values could still accepted data really supported values bolfi computed discrepancy locations using cores. simulated episodes used ﬁrst calculating discrepancy. done sensible compare datasets similar size. altogether model ﬁtting took individual sample taking discrepancy based mean standard deviation aggregate task completion time. constructed would mean accurately standard deviation lower priority formula used reasonable scale used feature aggregate tct. study prior dsel truncated gaussian distribution mean selected initial best guess delay second peak observed ﬁxation duration target present around thought likely normal ﬁxation duration around however relatively high uncertainty this chose quite prior. prior prec psem uniform distributions uninformative priors used uncertain possible true values parameters. discrepancy average parameter space sizes varied chose number samples cpus case separately. baseline samples cpus variant samples cpus variant samples cpus variant samples cpus study prior prec truncated gaussian distribution prior psem similar mean priors based knowledge gained study thus centered estimate variant reasonably allow individual variation. discrepancy study total simulated sessions used ﬁrst calculating discrepancy match individual dataset sizes. users computed samples using cpus myroslav bachynskyi gregorio palmas antti oulasvirta tino weinkauf. informing design novel input methods muscle coactivation clustering. transactions computer-human interaction http//dx.doi.org/./ andrew howes. model visual search selection time linear menus. proceedings annual conference human factors computing systems. http//dx.doi.org/./. robert baloh andrew sills warren kumley vicente honrubia. quantitative measurement saccade amplitude duration velocity. neurology http//dx.doi.org/./wnl... duncan brumby anna jacqueline chung byron fernandes. knowing looking change visual search behavior?. proceedings sigchi conference human factors computing systems. http//dx.doi.org/./. oulasvirta andrew howes. emergence interactive behavior model rational menu search. proceedings annual conference human factors computing systems. doihttp//dx.doi.org/./. andy cockburn kristensson jason alexander shumin zhai. hard lessons effort-inducing interfaces beneﬁt spatial learning. proceedings sigchi conference human factors computing systems. http//dx.doi.org/./. bayesian optimization likelihood-free inference simulator-based statistical models. journal machine learning research http//jmlr.org/papers/v/-.html andrew howes richard richard lewis alonso vera. rational adaptation task processing constraints implications testing theories cognition action. psychological review doihttp//dx.doi.org/./a marko järvenpää henri vuollekoski michael gutmann vehtari jukka corander samuel kaski. elfi engine likelihood-free inference nips workshop advances approximate bayesian inference. https//github.com/hiit/elfi accurate practical predictive models active-vision-based visual search. proceedings annual conference human factors computing systems. http//dx.doi.org/./. erick lauber. modern computational perspectives executive mental processes cognitive control here? control cognitive processes attention performance xviii optimal state estimation control visual search explaining distractor ratio effects. proceedings annual conference cognitive science society. cognitive science society. uniﬁed theories cognition modeling visual attention menu selection. chi’ extended abstracts human factors computing systems. http//dx.doi.org/./. interaction utility maximization approach understanding human interaction technology. synthesis lectures human-centered informatics http//dx.doi.org/./sedvyhci mikael sunnåker alberto busetto elina numminen jukka corander matthieu foll christophe dessimoz. approximate bayesian computation. plos computational biology http//dx.doi.org/./journal.pcbi. anind dey. maximum entropy inverse reinforcement learning. proceedings association advancement artiﬁcial intelligence conference artiﬁcial intelligence.", "year": 2016}