{"title": "Multi-Task Pharmacovigilance Mining from Social Media Posts", "tag": ["cs.LG", "cs.AI", "cs.CL"], "abstract": "Social media has grown to be a crucial information source for pharmacovigilance studies where an increasing number of people post adverse reactions to medical drugs that are previously unreported. Aiming to effectively monitor various aspects of Adverse Drug Reactions (ADRs) from diversely expressed social medical posts, we propose a multi-task neural network framework that learns several tasks associated with ADR monitoring with different levels of supervisions collectively. Besides being able to correctly classify ADR posts and accurately extract ADR mentions from online posts, the proposed framework is also able to further understand reasons for which the drug is being taken, known as 'indication', from the given social media post. A coverage-based attention mechanism is adopted in our framework to help the model properly identify 'phrasal' ADRs and Indications that are attentive to multiple words in a post. Our framework is applicable in situations where limited parallel data for different pharmacovigilance tasks are available.We evaluate the proposed framework on real-world Twitter datasets, where the proposed model outperforms the state-of-the-art alternatives of each individual task consistently.", "text": "reactions injuries caused intake drugs known adverse drug reactions happens fourth leading cause death united states preventive steps monitoring detection collectively called pharmacovigilance critical ensure safety patients’ health. initial activities toward pharmacovigilance clinical trials fail reliably signal negative effects could potentially caused drug certain restrictions calling need post-market surveillance. nevertheless potentially harmful drugs remain unflagged traditional post-market monitoring methods suffer under-reporting incomplete data delays reporting owing presence large user base social media vast amount data gets generated. compared clinical information retrieval electronic health records pose problem limited access free accessibility data presents lucrative source medical data. data recently caught attention researchers public health monitoring. taskoriented crowdsourcing platforms designed collect patient feedbacks introduced popular platform healthrelated data form posts/ tweets exchanged users twitter. posts cover wide range topics concerning health experience getting disease/illness symptoms drugs taken harmful reactions them. social media platforms offer robust source health-related data patients found consult learn other’s shared health-related experiences fact data up-to-date generated patients overcomes weaknesses traditional surveillance techniques. thus social media indispensably important could complement traditional information sources effective pharmacovigilance studies well potentially serve early warning system unknown adrs however users different background knowledge various linguistic preferences tend generate social media posts diverse expressions ambiguous mentions pose series challenges pharmacovigilance studies diversely expressed adrs twitter nonmedical terms craft one’s tweet prevalent. example never sleeping sleep deprived used describe insomnia. ‘phrasal’ adrs framed casual words could easily merge irrelevant words post make detection task difficult. indications misidentified adrs ‘indication’ health-related post defined medical condition disease illness drug prescribed treat indications adrs referred abstract social media grown crucial information source pharmacovigilance studies increasing number people post adverse reactions medical drugs previously unreported. aiming effectively monitor various aspects adverse drug reactions diversely expressed social medical posts propose multi-task neural network framework learns several tasks associated monitoring different levels supervisions collectively. besides able correctly classify posts accurately extract mentions online posts proposed framework also able understand reasons drug taken known ‘indications’ given social media post. coverage-based attention mechanism adopted framework help model properly identify ‘phrasal’ adrs indications attentive multiple words post. framework applicable situations limited parallel data different pharmacovigilance tasks available. evaluate proposed framework real-world twitter datasets proposed model outperforms state-of-the-art alternatives individual task consistently. concepts information systems content analysis feature selection; information extraction; computing methodologies information extraction; multi-task learning; neural networks; keywords multi-task learning pharmacovigilance adverse drug reaction attention mechanism coverage recurrent neural network social media reference format shaika chowdhury chenwei zhang philip multi-task pharmacovigilance mining social media posts. conference april lyon france. york pages. https//doi.org/./. introduction various prescription drugs intended taken medical treatment released market. however studies found many drugs counterproductive harmful paper published creative commons attribution international license. authors reserve rights disseminate work personal corporate sites appropriate attribution. april lyon france published creative commons license. isbn ----//. https//doi.org/./. tweet starting think paroxetine turns panic attacks fat. tweet ideas treating depression naturally paxil making gain unwanted pounds water weight...thanks figure shows common tweets pharmacovigilance taken social media shared task twitter dataset token denotes ‘drug’ taken blue denotes ‘indication’ green ‘adr’. tweet drug paroxetine taken treat panic attacks adverse reaction weight gain mentioned fat. panic attacks instance indication adr. tweet drug paxil prescribed treat indication depression causes adrs gain unwanted pounds water weight. cases possible indications ’panic attacks’ ’depression’ mislabeled commonly occur adrs well. previous works pharmacovigilance studies focused solving tasks separately. tweet containing mention also medical mentions indications beneficial effects important incorporate representations ensure disambiguity trying learn task. lexicon-based approaches commonly adopted earlier approaches tokens text fragment looked corpus containing mentions. however occurrence non-medical terminologies describe adrs social media makes unsuitable. machine learning approaches naive bayes support vector machine maximum entropy require hand-engineered features. trying conquer problems propose multi-task framework based sequence learning model jointly learns several related pharmacovigilance tasks. mining pharmacovigilance forms interesting multi-task problem complimentary pharmacovigilance tasks supervision different levels jointly learned. data related tasks share semantic syntactic similarities leveraging shared representations improve learning efficiency prediction accuracy. joint learning objective functions tasks transfer learned task tasks improve them. suitable pharmacovigilance tasks contain data occurrences multiple medical terms otherwise makes identification certain category medical term difficult. incorporate ideas extending basic recurrent neural network encoder-decoder multi-task model shares encoder among tasks uses different decoder task. assumption shared encoder would learn predictive representations capturing nuances task hence help disambiguate ’adr’ ’indication’. hand task-specific decoder decodes shared encoder representation produce task-specific output. furthermore incorporating multi-granular supervision different tasks decoder successfully produce output sentence word level. recent years seen spike sequence-to-sequence models difficult learning tasks like machine translation summarization sequence-to-sequence model takes sequence input encoder projects intermediate encoded representation passed decoder generate sequence output. proposed architecture shown figure recurrent neural network-based encoderdecoder model augmented attention coverage mechanism handle multiple tasks pharmacovigilance. reason using sequence sequence model model multiple tasks able capture shared representations encoder generate outputs task multiple decoders. propose multi-task learning framework three pharmacovigilance tasks classification labeling indication labeling— hypothesizing interactions tasks joint learning would improve learning generalization ability individual task. works classification detection tried learn single objective function jointly learning multiple objective functions tasks introduce novel approach pharmacovigilance seen boost performance. moreover learned features multiple tasks help reduce false positives mislabeling indications adrs vice versa. adr\\indication occurs phrase rather single word make detection task difficult. adding coverage attention mechanism helps overcome accumulates attention previous decoder time steps facilitates learning previous adr\\indication words phrase. designed unified machine learning framework learn several pharmacovigilance tasks social media posts simultaneously. best knowledge problem studied carefully scope novel research. adding coverage attention mechanism shown improve detection ’phrasal’ also single worded adrs indications. preliminary tasks multi-task framework jointly learn three pharmacovigilance tasks input tweet representation encoded shared encoder. task modeled sequence classification sequence labeling problem. description task given below. figure model architecture. different colors task-specific decoder. shade colored block indicates value. example second word panic indication gets higher attention weight helps successfully labeling indication. classification binary classification task separate assertive posts. classes ‘adr’ ‘notadr’ ‘adr’ label indicates post mention ‘notadr’ means although medical terms drugs indications. total number classes labeling sequence labeling task aiming identify post. detected adrs tagged ‘adr’ label. tries find likely sequence tags given input sequence sequence highest probability. indication labeling sequence labeling task aiming identify indication post. detected indications tagged ‘indication’ label. like labeling tries find tagged sequence highest probability. used tags annotate tokens input indication labeling. ‘ind’ corresponds token indication mention denotes non-indication word. model proposed multi-task framework depicted figure composed mainly three components embedding module encoder decoder. embedding module intended capture meaning semantic associations pharmacovigilance words. tasks common encoder shared representations generated capturing indication contextual information. lastly decoders employ combined attention coverage mechanism facilitate detection indications various lengths. component encoder-decoder model described detail following subsections. word representations medical terms tweet post take different roles medical word phrase mean different things different context. example ‘panic attacks’ occur well indication depending mention drug patterns. order capture meanings well semantic relationships context used generate word embeddings. character representation word also generated capture morphological features. character representations help capturing representations words ‘sleeping’ word embedding matrix might entry ‘sleep’. character representation similar implemented named entity recognition encoder hidden state previous decoder hidden state decoding timestep battn learnable attention parameters. finding attention score using attention function encoder state decoder state preceding current output state tells exactly attention input sequence decoding. context vector along previous decoder hidden state outputs label generated previous timestep yt−. aligned encoder hidden state used compute decoder state time step indication labeling tasks. coverage mechanism. colloquial nature conversations social network adrs expressed everyday language also take phrasal form. consider following example tweet took seroquel. freaking sleeping miss appt tomorrow sleeping taking phrase form. phrasal adrs also expressed list adrs illustrated tweet user hated effexor. makes hungry dizzy lethargic. culminated large weight gain hungry dizzy lethargic list adrs occurring phrase drug effexor. found preliminary experiments attention cannot detect words phrases introduce coverage decoder solve problem. every decoder timestep keep track coverage vector implemented summarization. coverage vector sums attention distribution previous decoder timesteps. however unlike impose window previous decoder timesteps adrs comprised words considering attention previous timesteps include attention non-adr words jeopardize attention distribution phrase located post. coverage vector case word phrasal identified attentive words based attention distribution neighboring words help locate words helps secure label words phrasal adr. coverage also contributes avoiding mislabeling indication vice versa implicitly keeps track location word. unlike conventional additive attention character representation word sentence denoted vocabulary size characters. similar word embedding first character embedding vector character looking character-embedding matrix dimensions character-embedding. sequence character-embedding vectors e_chart word bidirectional lstm final character representation e′_chart obtained concatenating forward backward final states. encoder single layer bi-directional encoder lstm basic recurrent unit ability incorporate long-term dependencies purpose encoder capture shared representations multiple tasks representations include contextual information forward backward directions outputs task depend previous future elements sequence. pass input sequence bi-lstm serve purpose. bi-lstm achieves passing input sequence original order forward lstm encodes hidden state time step also reversed copy input sequence passed backward lstm encodes hidden state forward backward hidden states concatenated represent final hidden state encoder time step. decoder decoder side allocate single layer uni-directional lstm attention mechanism task order produce output specifically task. coverage mechanism integrated attention mechanism give model sense much attention already assigned far. attention mechanism. conventional encoder-decoder sequence-to-sequence tasks shown limitations tries decode fixed-length encoded vector generating output fact last encoder hidden state required hold summary timesteps practice doesn’t hold especially longer sentences attention come long tasks ranging image captioning machine translation peeking encoder states weighing according relevance current output generate produces attention distribution. attention distribution gives signal attend input sequence. experimental settings datasets classification twitter dataset social media shared task classification dataset created tweets collected using generic brand names drugs along phonetic misspellings. contains binary annotations referring ‘adr’ ‘notadr’ respectively. although original dataset contains total tweets could download tweets given ids. consider tweets overlap tweets labeling dataset belonging ‘adr’ class. another tweets randomly sampled ‘notadr’ class. done tasks share encoder exploit shared input representations. manually labeled supplemental dataset discussed existing dataset. divided tweets randomly training test validation datasets splits %-%-%. labeling labeling twitter dataset social media shared task extraction contains around tweets annotated tweet start offset offset semantic type umls annotated text span related drug. however time study annotated tweets available download. supplemented dataset small dataset tweets collected december twitter. split %-%-% training test validation datasets. customized dataset include annotations. indication labeling corpus splits used indication labeling labeling. customized dataset include indication annotations. training details implementation based open source deep learning package tensorflow glove toolkit used pre-train word embeddings used initialize embeddings model. specifically used model trained twitter glove able generate word-embeddings uses encoder states find attentive words summing attention values assigned provides information model attended beginning sentence. learns boundaries attention indication words. defined attention mechanism word sleeping first example attention focused words seroquel freaking identify guarantee attend similar words recognize part phrase since frequently appear words irrelevant mention. augmenting attention mechanism coverage hypothesize also focusing words attended previous time steps properly tagged adr. decoding attention words seroquel freaking helpful tagging sleeping correctly. hence hybrid attention coverage module enable capturing words phrase otherwise attention missed. labeling indication labeling context vector decoder timestep coni viewed final representation word used decoder state predict output timestep. training data size means inputs true label predicted label probability. θclas θsrc collection shared parameters among tasks encoder parameters classification decoder. words unique twitter dataset. number units lstm cell dimensionality word char embeddings respectively. forget biases lstms every epoch perform mini-batch training parallel task corpus batch size regularization done non-recurrent connections dropout rate used adam optimization method learning rate training. weights biases attention coverage component initialized xavier initialization. development used tune value hyper-parameter weight loss task. setting losses labeling indication labeling classification used final experiments gave best results development set. results discussion evaluation precision recall score evaluation measures. particular class precision recall defined respective equations number true positives number false negatives number false positives. score calculated precision recall tagging tasks namely indication labeling approximate matching predicted labels phrasal words actual labels. approximate matching works checking spans phrase could identified correctly ‘adr’ tags. example following tweet cymbalta days. cold turkey sweats migraine tremors days after. actual span sweats migraine tremors predicting ‘adr’ three spans combinations would considered correct. approximate match precision recall calculated baselines could find previous work performs multi-task learning pharmacovigilance tasks compare baseline methods state-of-the-art approaches independent tasks demonstrate effectiveness proposed model. pretrained-fixed architecture model known bidirectional long short-term memory combines forward backward uses word embeddings features. blstm-random word-embeddings randomly initialized treated learnable parameters. blstm-pretrained-learnable blstm-pretrained-fixed pre-trained word-embeddings trained large non-domain specific twitter dataset. difference blstm-pretrainedlearnable treats words-embedding values learnable parameters blstm-pretrained-fixed fixed constants. crnn state-of-the-art model classification task. crnn convolutional neural network concatenated recurrent neural network. used basic unit convolutional layer. cnna state-of-the-art model classification task. cnna convolutional neural network attention mechanism incorporated. mt-noatten multi-task framework pharmacovigilance tasks without attention. non-attention decoder case. mt-atten multi-task framework pharmacovigilance tasks attention mechanism. coverage turned training. mt-atten-cov proposed multi-task framework pharmacovigilance tasks combined attention coverage mechanism. first experiment train multi-task model jointly three parallel datasets corresponding three tasks. results task experiment compared baselines depicted table purpose coverage able greater coverage adr/ indication words adr/ indication phrase turn classification decoder tagging tasks. results classification task reported mt-attencov model. remaining tasks observe method outperforms baselines terms precision recall f-score. although approximate matching would consider identification adr/ indication span true positive would expect comparable results mt-atten-cov mt-atten models fact mt-atten-cov superior results empirically confirms incorporating coverage attention helps capturing ‘phrasal’ single words attended attention mechanism. achieve score improvement labeling indication labeling respectively mt-atten model. experimental values indication labeling task happen across models sparsity tweets containing indication words. nevertheless gain improvement model baselines. gain score improvement mt-noatten model classification detection indication labeling respectively. examining precision recall results better performance model attributed improvement both. second third experiments train model separately classification detection tasks respectively provide comparison results model trained experiment one. indication detection performed independent task previous works provide table comparison classification task test results previous approaches. single-atten-cov task refers independent task model trained classification dataset. table comparison labeling task test results previous approaches. single-atten-cov task refers independent task model trained labeling dataset. separate table comparisons previous approaches table multi-task model improves performance terms score classification compared single task model. detection task results table makes improvement. empirical findings cast light shared input representations interactions tasks result mutual benefit tasks. comparing independent classification models other advantage using attention classification task singleatten-cov average improvement crnn cnna. although cnna incorporates attention model assume using encoder-decoder attention helpful. similarly detection table single task detection model outperforms best model among blstm classification performance multi-task model attained higher scores crnn cnna models respectively detection multi-task model improves best performing blstm models. case study deeper insight augmenting coverage attention mechanism benefits model sample several tweets test dataset. tags predicted model tweets compared baseline mt-atten model. usernames anonymized privacy concerns. order validate results model produced visualize attention heatmaps tweets depicted figure following tweets illustrate ability model correctly label single word ‘adr’ mt-atten model makes wrong prediction. justifies higher precision recall gained model mt-atten. degree attention received source word decoding target word tweet visualized figure darker shades denote higher score. predicting target token ‘zombie’ attention given words ‘zombie’ ‘venlafaxine’ ‘difficult’ ‘illness’. coverage attentive words ‘difficult’ ‘illness’ previous timesteps also attended. words facilitated predicting ‘adr’ word. furthermore indication words ‘bipolar’ ‘depression’ receiving attention weights prevented mislabeling. tweet crying randomly nothing everything. sigh. thank effexor withdrawls exit system already. true tags mt-atten mt-atten-cov crying withdrawls attention heatmap tweet shown figure first word ’crying’ overall attention words. also happens first word sentence coverage passed. reason detected baseline model. whereas second ‘withdrawals’ source words ‘crying’ ‘randomly’ ‘at’ ‘nothing’ attended others. moreover ‘effexor’ ‘withdrawals’ attention previous word ‘effexor’ also instrumental right assignment ‘withdrawals’. related work pharmacovigilance social media pharmacovigilance become active area research initial work pharmacovigilance social media performed detection extraction tasks health forum data works also focused investigating posts mentioning adverse reactions associated fewer number drugs. years wide range drugs used platforms twitter emerged valuable source monitoring prevalent tasks pharmacovigilance studies detection posts containing mention extraction mentions posts scarcity annotated resources study works performed using small annotated datasets work used large unannotated dataset employing unsupervised approach extraction lexicons knowledge bases widely used resource however medical terms rarely used social media posts raise mapping issues. applying deep neural networks pharmacovigilance found recent works approaches benefit explicitly specify features rather learn training process. mention ‘indication’ co-occurs adrs post previous work performed ‘indication’ detection/extraction separate task. although works used features machine learning approach sparsity ‘indications’ issue. multi-task approach includes ‘indication’ extraction separate task show interaction related tasks improve learning all. multi-task learning multi-task learning models become ubiquitous many machine learning applications areas ranging natural language processing speech recognition computer vision multi-task learning encoder-decoder come three flavors one-to-many many-to-one many-to-many approaches one-to-many models tasks share common encoder task-specific decoder. oneto-many approach used translation task source language multiple target languages. shared encoder captured syntactic semantic similarity existing across different languages. hand many-to-one approach suitable tasks decoder easily shared multi-source translation. lastly many-to-many approach allows multiple encoders decoders. one-to-many approach similar spirit used joint slot filling intent detection tasks. however work following differences learns tasks jointly coverage attention mechanism. pre-trained word embeddings. conclusion performing pharmacovigilance twitter augment existing surveillance system suffers various clinical limitations. work provide end-to-end solution three detection extraction tasks. problems conventionally approached separately didn’t leverage interactions tasks. exploiting similarity tasks have proposed multi-task encoder-decoder framework. tasks share encoder model interactions semantic/syntactic similarity them. decoder produce output specific task. empirical findings validate learning tasks jointly improves precision recall state-of-the-art approaches. additionally proposed solution hybrid attention model coverage deal adrs occurring phrases. results case studies show hybrid model able achieve higher phrasal word coverage compared baselines also able identify single adrs correctly. acknowledgments work supported part grants iis- cns- nsfc references martín abadi paul barham jianmin chen zhifeng chen andy davis jeffrey dean matthieu devin sanjay ghemawat geoffrey irving michael isard tensorflow system large-scale machine learning.. osdi vol. adrian benton lyle ungar shawndra hill sean hennessy annie chung charles leonard john holmes. identifying potential adverse effects using approach medical hypothesis generation. journal biomedical informatics jiang bian umit topaloglu towards large-scale twitter mining drug-related adverse events. proceedings international workshop smart health wellbeing. brant chee richard berlin bruce schatz. predicting adverse drug events personal health messages. amia annual symposium proceedings vol. american medical informatics association kyunghyun bart merriënboer dzmitry bahdanau yoshua bengio. properties neural machine translation encoder-decoder approaches. arxiv preprint arxiv. anne cocos alexander fiks aaron masino. deep learning pharmacovigilance recurrent neural network architectures labeling adverse drug reactions twitter posts. journal american medical informatics association ocw. clark freifeld john brownstein christopher menone wenjie ross filice taha kass-hout nabarun dasgupta. digital drug safety surveillance monitoring pharmaceutical products twitter. drug safety rachel ginn pranoti pimpalkhute azadeh nikfarjam apurv patki karen o’connor abeed sarker karen smith graciela gonzalez. mining twitter adverse drug reaction mentions corpus classification benchmark. proceedings fourth workshop building evaluating resources health biomedical text processing. xavier glorot yoshua bengio. understanding difficulty training deep feedforward neural networks. proceedings thirteenth international conference artificial intelligence statistics. trung huynh yulan alistair willis stefan rüger. adverse drug reaction classification deep neural networks. proceedings coling international conference computational linguistics technical papers. vasileios lampos elad yom-tov richard pebody ingemar cox. assessing impact health intervention user-generated internet content. data mining knowledge discovery robert leaman laura wojtulewicz ryan sullivan annie skariah jian yang graciela gonzalez. towards internet-age pharmacovigilance extracting adverse drug reactions user posts health-related social networks. proceedings workshop biomedical natural language processing. association computational linguistics bing lane. attention-based recurrent neural network models joint intent detection slot filling. arxiv preprint arxiv. minh-thang luong quoc ilya sutskever oriol vinyals lukasz kaiser. multi-task sequence sequence learning. arxiv preprint arxiv. azadeh nikfarjam graciela gonzalez. pattern mining extraction mentions adverse drug reactions user comments. amia annual symposium proceedings vol. american medical informatics association azadeh nikfarjam abeed sarker karen o’connor rachel ginn graciela gonzalez. pharmacovigilance social media mining adverse drug reaction mentions using sequence labeling word embedding cluster features. journal american medical informatics association apurv patki abeed sarker pranoti pimpalkhute azadeh nikfarjam rachel ginn karen o’connor karen smith graciela gonzalez. mining adverse drug reaction signals social media going beyond extraction. proceedings biolinksig peleg tiffany leung manisha desai michel dumontier. crowdsourcing patient-reported outcomes future evidence-based medicine? case study back pain. conference artificial intelligence medicine europe. springer jeffrey pennington richard socher christopher manning. glove global vectors word representation. proceedings conference empirical methods natural language processing abeed sarker rachel ginn azadeh nikfarjam karen o’connor karen smith swetha jayaraman tejaswi upadhaya graciela gonzalez. utilizing social media data pharmacovigilance review. journal biomedical informatics richard tzong-han tsai shih-hung wen-chi chou yu-chun ding jieh hsiang ting-yi sung wen-lian hsu. various criteria evaluation biomedical named entity recognition. bioinformatics oriol vinyals alexander toshev samy bengio dumitru erhan. show tell neural image caption generator. proceedings ieee conference computer vision pattern recognition. stephen sijia yanshan wang tamara timmons harsha uppili steven bedrick william hersh hongfang liu. intrainstitutional collections patient-level information retrieval. journal association information science technology christopher yang haodong yang ling jiang zhang. social media mining drug safety signal detection. proceedings international workshop smart health wellbeing. ieee journal translational engineering health medicine vasileios lampos russell gorton ingemar cox. infectious intestinal disease surveillance using social media content. proceedings international conference digital health conference.", "year": 2018}