{"title": "RetiNet: Automatic AMD identification in OCT volumetric data", "tag": ["cs.CV", "cs.LG", "cs.NE"], "abstract": "Optical Coherence Tomography (OCT) provides a unique ability to image the eye retina in 3D at micrometer resolution and gives ophthalmologist the ability to visualize retinal diseases such as Age-Related Macular Degeneration (AMD). While visual inspection of OCT volumes remains the main method for AMD identification, doing so is time consuming as each cross-section within the volume must be inspected individually by the clinician. In much the same way, acquiring ground truth information for each cross-section is expensive and time consuming. This fact heavily limits the ability to acquire large amounts of ground truth, which subsequently impacts the performance of learning-based methods geared at automatic pathology identification. To avoid this burden, we propose a novel strategy for automatic analysis of OCT volumes where only volume labels are needed. That is, we train a classifier in a semi-supervised manner to conduct this task. Our approach uses a novel Convolutional Neural Network (CNN) architecture, that only needs volume-level labels to be trained to automatically asses whether an OCT volume is healthy or contains AMD. Our architecture involves first learning a cross-section pathology classifier using pseudo-labels that could be corrupted and then leverage these towards a more accurate volume-level classification. We then show that our approach provides excellent performances on a publicly available dataset and outperforms a number of existing automatic techniques.", "text": "optical coherence tomography provides unique ability image retina micrometer resolution gives ophthalmologist ability visualize retinal diseases age-related macular degeneration visual inspection volumes remains main method identiﬁcation time consuming cross-section within volume must inspected individually clinician. much acquiring ground truth information cross-section expensive time consuming. fact heavily limits ability acquire large amounts groundtruth subsequently impacts performance learning-based methods geared automatic pathology identiﬁcation. avoid burden propose novel strategy automatic analysis volumes volume labels needed. train classiﬁer semi-supervised manner conduct task. approach uses novel convolutional neural network architecture needs volume-level labels trained automatically asses whether volume healthy contains amd. architecture involves ﬁrst learning cross-section pathology classiﬁer using pseudo-labels could corrupted leverage towards accurate volume-level classiﬁcation. show approach provides excellent performances publicly available dataset outperforms number existing automatic techniques. keywords optical coherence tomography convolutional neural networks agerelated macular degeneration pathology identiﬁcation ophthalmology machine learning large optical coherence tomography reshaped ﬁeld ophthalmology ever since inception early core uses infrared-light interferometry image tissue order characterize anatomical structures beyond surface. given simplicity affordability safety surprise gained widespread popularity disease diagnosis treatment. similarly gained traction medical ﬁelds histopathology skin cancer analysis indeed ability image posterior part micrometer resolution imaging allows visualization retinal layers importantly numerous pathological markers intraretinal ﬂuid drusens cysts illustrated fig. markers observed cross-sectional images b-scans apostolopoulos sznitman artorg center university bern switzerland. e†c. ciller radiology department cibm lausanne university university hospital lau‡s. zanet ecole polytechnique federale lausanne switzerland. wolf bern university hospital inselspital switzerland. figure example b-scan cross-section patient foveal area. visible multiple retinal layers including retinal pigment epithelium bruch´s membrane latter perturbed drusen manifest bumps disrupting continuous layer. linked number conditions including age-related macular degeneration diabetic retinopathy currently affect world population million people worldwide respectively moreover pathologies major cause blindness developed countries alarmingly number people either diseases projected skyrocket affecting estimated million people million people genetic factors race smoking habits ever growing world population responsible pathology growth gained signiﬁcant importance recent years screening process remains time consuming however. effect volumes also referred c-scans comprised cross-sectional b-scans. traditionally inspection b-scan necessary order properly rule-out retinal diseases. process particularly tedious time-consuming nature also multiple cross-sections need inspected simultaneously identify elusive scarce traces early-stage ocular diseases. context automated algorithms pathology identiﬁcation volumes would great beneﬁt clinicians ophthalmologists access devices becomes common nation-wide screening programs commence recently research given variety image processing methods imaging. included techniques image denoising strategies improved image reconstruction dosimetry laser control systems instrument detection surgical procedures speciﬁc pathology identiﬁcation various groups explored automatic detection retinal pathologies using machine learning techniques either focusing segmentation relevant pathological markers classiﬁcation b-scans cscans effective extent works leveraged b-scan level groundtruth information order learn classiﬁcation functions. detailed labels unfortunately often available such limit usability solutions. present strategy towards automatic pathology identiﬁcation c-scans using volume level annotations. this introduce novel convolution neural network architecture named retinet directly estimates state c-scan solely using image data without needing additional information. core approach uses taskspeciﬁc volume pre-processing strategy ﬂatten normalize data oct-speciﬁc manner train b-scan using pseudo-labels could corrupted order pre-learn ﬁlters respond relevant image features reuse learned features c-scan level takes mosaic b-scans input classiﬁes entire c-scan once. using publicly available dataset show approach highly effective separating control subjects outperforms existing state-of-the-art methods image classiﬁcation. addition show retinet outperforms excellent recent networks computer vision literature trained scratch also surpasses performance state-of-the-art pretrained networks adapted ﬁlters. last show approach provides high performances terms accuracy learning pathology-speciﬁc ﬁlters capable identifying pathological markers effectively. remainder article organized follows following section discusses relevant related work. sec. describes detail approach retinet architecture. following this describe experimental section evaluation several baseline strategies sec. conclude ﬁnal remarks sec. venhuizen regions interest automatically extracted around center c-scan intensity threshold. principal component analysis applied region dimensionality reduction followed k-means clustering order build words representation used combination random forest classiﬁer. classiﬁer trained patients healthy controls evaluated balanced patients healthy controls. dataset previously used farsiu developed semi-automatic classiﬁcation method patients. given manually-corrected segmentations bruch´s membrane retinal pigment epithelium inner limiting membrane layers calculated number metrics total thickness retina; thickness drusen apexes rpe; abnormal thickness score; abnormal thinness score. these trained linear regression models using different combinations metrics. srinivasan presented method classifying diabetic macular edema healthy c-scans using multiscale histogram gradients features support vector machine classiﬁer. b-scan ﬁrst resized resolution pixels denoised using block matching ﬁltering algorithm ﬂattened. dataset method public available preprocessed form unfortunately limits ability compare recently lemaitre followed direction extracting local binary patterns features healthy patients suffering dme. b-scans denoised using non-local means algorithm ﬂattened. different linear non-linear classiﬁers explored identify performed best. finally schlegl employed patch-based convolutional neural network classify retinal tissue intra-retinal cysts subretinal fluid healthy categories providing information location pathology. train classiﬁer using three different ground truths weak-labeling wherein single label applied whole c-scan; weaklabeling semantic information wherein coarse information location pathology applied along weak label; full-labeling wherein classiﬁer trained per-voxel ground truth whole c-scan. latter approach yields best results healthy classes respectively. weak-labeling approach performs signiﬁcantly worse respectively setting closely related present work. speciﬁcally present novel method automatically evaluate healthy volumes. strategy important advantages existing methods relies volume level labels trained evaluates complete volumes shot making simpler use. show sec. approach allows signiﬁcant performance gains existing methods. original figure different retina b-scans variations position tilt. b-scans highlighted layers blue respectively. corresponding b-scans ﬂattening applied. white dotted lines illustrate regions cropped reduce b-scan sizes. overall goal work automatically evaluate whether volume contains amd. main challenges tackling problem lies fact relatively volumes typically available training classiﬁcation models even though volumes large size labels denoting presence pathology available volume level cross-section level. perform effective volume classiﬁcation follow deep approach describe following section novel architecture general approach relies threestage process. ﬁrst oct-speciﬁc normalization data-augmentation strategy volumes order improve overall generalization classiﬁcation performance. here reduce image dimensionality ﬂatten scans order regularize data. similarly make symmetries particular eyes order augment data effectively. second stage attempts learn pathology-speciﬁc features cross-section b-scan levels using volume-level labels. here make relatively simple network learn ﬁlters relevant image data. last stage remap volume large image mosaic train volume-level network leveraging previously learned ﬁlters operate b-scan level. notation formulation without loss generality assume training data comprised volumes. volume dimension b-scan cross-section consists image depth penetrating light source. volume denote volume associated class label corresponds control volumes corresponds pathological volumes goal learn classiﬁcation function using training labels available. importantly assume information available labels seen fig. high variability positions respect anatomy distortion retinal layers. particular retinal layers tilted shifted vertically distorted acquisition process varying intensity. addition signiﬁcant portions images contain little informative content area retinet network layout. single b-scans taken input figure layers classiﬁed classif icat layer. weak labels derived retinet network layout. bvolume label used train network. scans entire volume concatenated vertically single image input. layers transferred retinet weights network. additional adaption block added composed repeated layers convolutions average pooling batch normalization. such order provide compact consistent training volumes interested normalizing reducing size volumes. unfortunately simply cropping b-scan would ill-suited since retina curved would either remove informative data result marginal resizing. propose effective normalization ﬂattening strategy. ﬂattening approach consists aligning individual layers rectifying curvature normalizing variations volume intensities. ﬁrst detect layer applying anisotropic ﬁlter empirically experiments. compute difference gaussians ﬁltered responses estimate layer maximal gradient pixels. naturally responses noisy incorrect cases. reason secondorder polynomial model noisy responses using ransac outlier detection warp estimated vertical line centered image height. order reduce smaller size mension image resize seen fig. areas contain noise. reason crop depth every voxel. finally intensity variations common looking acquisitions different patients. order regularize across variations voxel intensities normalized zero mean standard deviation one. data augmentation increase number samples training dataset reduce overﬁtting particular take advantage bilateral symmetry effectively double number samples. resulting samples biologically plausible i.e. optic disc fovea vessels remain correct spots relative other removes latent sample bias different counts left right eyes dataset. recall data inherently volumetric amount available data relatively small. given challenging learning context ﬁrst learn features efﬁcient detecting typical structures learning classify b-scans. labels volume level propose learn b-scan level classiﬁer using approximately correct weak labels particular note control volumes labels indicate lack diagnosis individual b-scan cross-sections pathology free. conversely volumes subjects diagnosed contain number control non-pathological b-scans. particular labels could incorrect volumes. learn classiﬁcation function proceed constructing feed-forward whose architecture illustrated fig. network every single gray-scale input passed convolutional layers small kernels max-pooling layers. deﬁne consecutive layers layers. following layers classiﬁcation achieved using consecutive fully connected layers using soft-max activation outputs classes denote latter layers classif icat layers. throughout entire network convolutional dense layers make leaky rectiﬁed linear units activations. point refer network retinet train network ﬁrst begin initializing layer parameters randomly using glorot uniform sampling make extreme learning shown increase regularization forcing convolutional layers broader features space. practice classif icat layers initialized allow change. freeze layers allow layers modiﬁed learning phase. sec. show effect learning strategy compared traditional regimes. show later experiments performance network limited must learn weak labels make volumetric information make ﬁnal decision. possible test classiﬁcation fact correct true label b-scan known. reason proceed second stage attempts classify complete c-scan input channel shot. proposed network depicted fig. instead setting network takes input vertical image stacked b-scans resulting sized image. using learned layers previous section include network invariant size input ideally learned anatomical pathological structures relevant. followed consecutive blocks convolutional layers average-pooling batch normalization. finally classif icat layer without transferring weights retinet deﬁne network conﬁguration retinet train retinet freeze layers learned b-scans respond preserve useful features extracted previous phase. rest network trained using true labels learn remainder network layers. pathology identiﬁcation literature general computer vision literature. also provide qualitative results method illustrating different activation maps produced network show different stages approach beneﬁt overall performance. method trained evaluated publicly available dataset duke university dataset made available methods deﬁne quantitative indicators presence intermediate amd. spectral domain volumes present volumes come subjects intermediate remaining subjects volumes collected healthy subjects. scans centered foveal pit. volume acquired a-scans b-scan b-scans volume. results volume dimensions general volumes isotropic. illustrate part strategy inﬂuences overall performance well compare approach performs contrast existing techniques literature outline number baselines compare directly -layer variant deep approach image classiﬁcation described pre-trained network imagenet dataset ﬁne-tuned resulting ﬁlters using dataset. that modiﬁed receptive ﬁeld network match b-scan resolution exchanged classiﬁcation layer network fully-connected layer size resnet similar evaluated pre-trained version -layer residual network described highly tuned parameters network maintained size receptive ﬁeld opting instead resize input volume dimension match. before exchange classiﬁcation layer fullyconnected layer size densenet recent architecture network huang extends residual network concept using complete graph skip connections. implemented densenet dense blocks growth rate trained entire network dataset. dseg patch-based classiﬁcation scheme pathological identiﬁcation described schlegl re-implemented trained dataset. lack location information per-voxel classiﬁcations ground truth data focused weak-labeling approach described paper. retinet consists retinet classiﬁer described sec. learned extreme learning comparing retinet baseline performance gain provided retinet network construction. addition attempted train resnet using data given large size networks small size dataset yielded extremely poor classiﬁcation methods. avoid bias omit methods experiments. partition dataset randomized equi-sized subsets using four training testing total cross-validations network. methods trained partitions using folds. random seed preserved across runs order remove dataset-dependent bias. figure comparison training validation loss retinet retinet extreme retinet notice extreme learning conﬁguration avoids overﬁtting compared regular training. retinet effective either loss decreasing throughout training regime. noisiness retinet likely caused small amount c-scans dataset i.e. fewer compared amount b-scans conﬁgurations. trained network maximum epochs fold using early stopping patience epochs avoid over-ﬁtting relied adadelta algorithm optimize parameters network. networks except dseg optimized minimizing categorical cross-entropy predictions versus ground truth. dseg optimized minimizing mean squared error described densenet resnet networks trained evaluated b-scan level using weak labeling scheme label complete c-scan applied b-scan subject. ﬁnal c-scan classiﬁcation prediction deﬁned mean score b-scan level predictions. maximum achievable b-scan level accuracy limited roughly mislabelings individual b-scans well acquisition artifacts provide version retinet implementation online. complete list parameters used found table. selected using experimental validation. fig. show learning rate network parameters training data validation set. initial experiments interested characterizing performance strategy. fig. directly compare performances retinet retinet retinet terms classiﬁcation performance. results shown ﬁgure attained -fold cross-validation. first show fig. curves three strategies. addition traditional metric also show fig. false negative rate versus false positive rate. metric informative clinical perspective clinical cost classifying pathological volume healthy volume much higher around. particular false negative rate retinet false positive rate interesting context screening indicates human would need evaluate pathological scans case false positive rate indicates reduced proportion healthy scans would still need examine automatic classiﬁcation algorithm. allowing error predicted subjects would require inspection healthy population. this observe retinet difﬁculty learning correctly volume labels given trained weak labels. illustrated training validation loss plots fig. retinet effectively lacks generalization capabilities heavily overﬁts data. contrast retinet extreme learning framework allows stronger regularization mitigates signiﬁcant amount overﬁtting present retinet such difference classiﬁcation performance retinet retinet attributed weak labels nature strategy. sense results highlight retinet overcomes lack b-scan level labels weak labels exploited c-scan level. illustrate network learns however visualize network activation maps fig. show four examples volumes network responds them. case show three b-scans volume associated fundus view retinal layer projection activation last convolutional layer retinet particular cases activation maps responding strongly different locations volume differently healthy volumes. last learning two-stage network appears learn even epochs indicating overﬁtting likely limited. time notice learning general consistently noisy framework likely limited number c-scans available training. fig. outlines performance retinet baseline methods terms well fnr/fpr. across metrics retinet appears outperform baselines. number interesting conclusions addition drawn results. first off-the-shelf computer vision networks perform exceptionally well natural images densenet resnet strong tendency overﬁt data. second densenet performs similarly resnet even though trained scratch converges quickly. resnet could successfully trained scratch however relatively figure comparison retinet mosaic state-of-the-art image classiﬁcation networks resnet densenet well weakly-labeled approach described schlegl resnet pre-trained imagenet ﬁne-tuned dataset. results -fold cross-validation. comparisons respect false negative rate versus false positive rate curves curves. small dataset. last dseg approach speciﬁcally developed application appears difﬁculties generalizing training weak labels. consistent authors conclusion well experiments retinet achieves area curve compares favorably semi-automatic method farsiu achieved reported best case automatic method venhuizen achieved compare methods directly report scores published results data. sense appears though retinet provides stable strategy capable leveraging volumetric information uses volume level labels training. fig. shows examples retinet correctly incorrectly predicts different volume labels. article proposed novel strategy automatic identiﬁcation volumes. strategy advantageous requires volume-level labels opposed crosssectional labels making easier train groundtruth acquisition point view. approach involves novel two-stage deep learning architecture ﬁrst phase focuses learning features domain speciﬁc focuses volume classiﬁcation task latter phase. validated approach using publicly available data compared performance method techniques domain computer vision literature. showed approach well terms performance also well respect clinically relevant metric. said method still difﬁculties identifying mild cases shown fig. difference healthy pathological visibly challenging. sense focus future developing strategies identifying early-stages disease look diseases differ another.", "year": 2016}