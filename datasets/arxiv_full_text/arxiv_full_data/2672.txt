{"title": "Optimal Warping Paths are unique for almost every Pair of Time Series", "tag": ["cs.LG", "cs.AI", "stat.ML"], "abstract": "Update rules for learning in dynamic time warping spaces are based on optimal warping paths between parameter and input time series. In general, optimal warping paths are not unique resulting in adverse effects in theory and practice. Under the assumption of squared error local costs, we show that no two warping paths have identical costs almost everywhere in a measure-theoretic sense. Two direct consequences of this result are: (i) optimal warping paths are unique almost everywhere, and (ii) the set of all pairs of time series with multiple equal-cost warping paths coincides with the union of exponentially many zero sets of quadratic forms. One implication of the proposed results is that typical distance-based cost functions such as the k-means objective are differentiable almost everywhere and can be minimized by subgradient methods.", "text": "update rules learning dynamic time warping spaces based optimal warping paths parameter input time series. general optimal warping paths unique resulting adverse eﬀects theory practice. assumption squared error local costs show warping paths identical costs almost everywhere measure-theoretic sense. direct consequences result optimal warping paths unique almost everywhere pairs time series multiple equal-cost warping paths coincides union exponentially many zero sets quadratic forms. implication proposed results typical distance-based cost functions k-means objective diﬀerentiable almost everywhere minimized subgradient methods. time series audio video sensory signals represent collection time-dependent values vary speed since euclidean distance sensitive variations application time series related data mining tasks give unsatisfactory results consequently preferred approaches compare time series apply elastic transformations ﬁlter variations speed. among various techniques common elastic transformation dynamic time warping dynamic time warping based concept warping path. warping path determines stretch given time series warped time series certain constraints. cost warping along warping path measures dissimilar warped time series are. exponential many diﬀerent warping paths determines cost warping time series optimal warping path warping path minimum cost. optimal warping paths exist unique general recent research directed towards extending standard statistical concepts machine learning methods time series spaces endowed distance. examples include time series averaging k-means clustering self-organizing maps learning vector quantization warped-linear classiﬁers lowest common denominator approaches repeatedly update parameter time series. addition update directions based optimal warping paths following properties hold figure variations speed implications comparing time series shown blue yellow. time series similar shape diﬀer speed along regions. plot euclidean distance warps i-th points time series onto another shown gray lines. since euclidean warping sensitive variations speed shapes preserved peaks aligned points regions. plot euclidean warping leaves time series unchanged results large dissimilarity score indicated gray shaded area. plot optimal warping preserves shape time series. double arrows indicate segments stretched dynamic time warping. plot warped time series obtained optimal warping left segment yellow right segment blue time series stretched align time series. resulting dissimilarity zero better reﬂects similarity shape euclidean distance. non-uniqueness optimal warping paths complicates algorithmic design learning methods spaces theoretical analysis. situations non-uniqueness result adverse eﬀects. example repulsive updating learning vector quantization ﬁnds theoretical justiﬁcation cases corresponding optimal warping path unique given problems caused non-uniqueness desirable optimal warping paths unique almost everywhere. case non-unique optimal warping paths occur exceptionally easier handle shortly. therefore interested prevalent unique optimal warping paths are. colloquial term almost everywhere precise measure-theoretic meaning. measure quantiﬁes size set. generalizes concepts length area volume solid body deﬁned three dimensions respectively. term almost everywhere ﬁnds roots notion negligible set. negligible sets sets contained measure zero. example function everywhere continuous negligible. generally property said true almost everywhere false negligible. property optimal warping unique almost everywhere means pairs time series non-unique optimal warping path negligible. cost functions machine learning methods euclidean spaces k-means learning vector quantization non-diﬀerentiable negligible set. cases common practice ignore points resort subgradient methods. direct consequences theorem optimal warping paths unique almost everywhere property holds union exponentially many zero sets quadratic forms. results hold uniwell multivariate time series. implication non-unique optimal warping paths adverse eﬀects learning exceptional cases safely handled. example learning amounts gradient descent update rules almost everywhere. time series warping paths ﬁrst deﬁne time series. denote d-dimensional euclidean space. d-variate time series length sequence consisting elements denote time series length elements denote warping paths lmn. warping path departs upper left southeast steps allowed move given point next point finally introduce optimal warping paths. warping path deﬁnes alignment time series relating elements cost aligning issue measure theory every subset given measurable. family measurable subsets called σ-algebra measure function assigns non-negative value every measurable subset certain conditions satisﬁed. introduce concepts formally assume denotes power subsets system called σ-algebra following properties ﬁrst show optimal warping paths unique almost everywhere. geometrically describe location non-unique set. finally discuss implications proposed results learning spaces. consists pairs aligned along diﬀerent warping paths identical cost. obviously subset next theorem states measure zero. theorem lebesgue-borel measure space. describe geometric form multi-path identify thus pairs time series summarized henceforth denoted denote -matrices elements finally zero function form delannoy number delannoy number |pmn| counts number warping paths lattice lmn. table presents ﬁrst delannoy numbers half million warping paths -lattice showing union trillions. thus multi-path time series length union octillion zero sets open question number zero sets form multi optimal-path example figure indicates multi optimal-path much smaller multi-path remark explanation regard euclidean space. pair time series varying values delannoy number hence multi-path consists zero sets quadratic forms indicated colored curves. subset multi optimal-path highlighted curve segments. convey line argument suﬃcient restrict problem averaging time series representative other complex learning problems. contrast computing average euclidean spaces time series averaging non-trivial task complexity class currently unknown challenge time series averaging minimize non-diﬀerentiable cost function show almost-everywhere uniqueness optimal warping paths implies almost-everywhere diﬀerentiability cost function provides stochastic update rule. step size optimal warping path also apply stochastic update rule cases optimal warping path unique. case ﬁrst select optimal warping path update updating non-diﬀerentiable points according rule well-deﬁned. addition unclear whether update directions always directions descent learning problems general. next result conﬁnes issues negligible set. corollary directly follows prop. together theorem summary almost-everywhere uniqueness optimal warping paths implies almost-everywhere diﬀerentiability individual cost latter turn implies update rule well-deﬁned stochastic gradient step almost everywhere. arguments section essentially carry learning problems spaces k-means self-organizing maps learning vector quantization. assume problem transfer proposed results learning based similarity scores applied warped-linar classiﬁers learning vector quantization supervised classiﬁcation scheme introduced kohonen basic principle shared variants margin-growth principle principle justiﬁes diﬀerent learning rules corresponds stochastic gradient update rules diﬀerentiable cost function exists. k-means algorithm scheme generalized spaces section illustrate unique optimal-warping path necessary condition satisfy margin-growth principle spaces proved theorem representative example describe simplest algorithms d-dimensional euclidean space consisting class labels. algorithm assumes codebook prototypes corresponding class labels classiﬁer assigns input point class closest prototype learns codebook basis training initialization algorithm repeats following steps termination randomly select training example determine prototype closest attract diﬀerent variants extended spaces replacing squared euclidean distance squared distance update rule based optimal warping path current input time series closest prototpye. asymmetric learning margin-growth principle always holds attractive force repulsive force optimal warping path unique remark proposition states uniqueness optimal warping path implies diﬀerentiability converse statement hold general. general approach arrive prop. corollary follows first show function locally lipschitz continuous invoke rademacher’s theorem assert almost-everywhere diﬀerentiability rule calculus functions have remark measure-theoretic geometric analytical concepts based euclidean spaces rather spaces. reason contemporary learning algorithms formulated current solution input time series ﬁrst projected euclidean space optimally warping length. update step performed ﬁnally updated solution projected back space. therefore understand form learning warping multi-path negligible corresponds union zero sets exponentially many quadratic forms. subset multi-path multi optimal-path also negligible. therefore optimal warping paths unique almost everywhere. implications proposed results adverse eﬀects learning spaces caused non-unique optimal warping paths controlled learning spaces amounts minimizing respective cost function gradient descent almost everywhere. appendix presents proof theorem proposition ﬁrst consider univariate case sections section introduces useful representation proving main results contribution derives auxiliary results. section proves proposed results univariate case. finally section generalizes proofs multivariate case. path. thus regard embedding matrices warping path injective linear maps embed time series matrix multiplication express cost aligning time series along warping path squared euclidean distance induced embeddings. deﬁnition valence warping matrix oriented following sense warping matrix rm×n aligns time series time axis time series diagonal elements valence matrix complementary warping matrix rn×m warps time series time axis time series diagonal elements complementary valence matrix rn×n counts number elements warping path length induced embedding matrices rl×m rl×n. denotes aggregated embedding matrix induced warping path valence warping matrices complementary valence warping matrices denotes cost aligning along warping path show proposition ﬁrst deﬁne notion piecewise smooth function. function piecewise smooth continuous neighborhood ﬁnite collection continuously diﬀerentiable functions reduce multivariate case univariate case. following assume d-variate time series warping path elements first observe d-variate time series consists individual component time series next construct embeddings warping path. d-variate time warping embeddings induced maps form", "year": 2017}