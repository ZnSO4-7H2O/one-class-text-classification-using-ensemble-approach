{"title": "Context Embedding Networks", "tag": ["cs.LG", "cs.AI", "cs.CV", "stat.ML"], "abstract": "Low dimensional embeddings that capture the main variations of interest in collections of data are important for many applications. One way to construct these embeddings is to acquire estimates of similarity from the crowd. However, similarity is a multi-dimensional concept that varies from individual to individual. Existing models for learning embeddings from the crowd typically make simplifying assumptions such as all individuals estimate similarity using the same criteria, the list of criteria is known in advance, or that the crowd workers are not influenced by the data that they see. To overcome these limitations we introduce Context Embedding Networks (CENs). In addition to learning interpretable embeddings from images, CENs also model worker biases for different attributes along with the visual context i.e. the visual attributes highlighted by a set of images. Experiments on two noisy crowd annotated datasets show that modeling both worker bias and visual context results in more interpretable embeddings compared to existing approaches.", "text": "figure context inﬂuences similarity estimates. hypothesize estimating similarity according particular visual attribute inﬂuenced combination innate biases context decisions made. compared worker worker strong prior bias towards using gender attribute. inﬂuenced context images worker also groups based gender. worker sees context worker ultimately groups based expression prior bias. fig. example three different crowd workers estimating similarity clustering collection images. workers’ decision visual attribute compare images explained factors workers innate preference towards certain attributes based past experiences related images worker observes biases towards certain attributes. call ﬁrst bias worker prior second bias context. hypothesis different sets images highlight different visual attributes workers. majority existing work often assumes workers behave list attributes speciﬁed advance addition similarity estimates workers also indicate attributes used make decision dimensional embeddings capture main variations interest collections data important many applications. construct embeddings acquire estimates similarity crowd. similarity multi-dimensional concept varies individual individual. however existing models learning crowd embeddings typically make simplifying assumptions individuals estimate similarity using criteria list criteria known advance crowd workers inﬂuenced data see. overcome limitations introduce context emaddition learning interbedding networks pretable embeddings images cens also model worker biases different attributes along visual context i.e. attributes highlighted images. experiments three noisy crowd annotated datasets show modeling worker bias visual context results interpretable embeddings compared existing approaches. large annotated datasets vital ingredient training automated classiﬁcation inference systems. labeling datasets made possible crowdsourcing services enable purchasing annotations crowd workers. unfortunately ﬁne-grained categorization challenging untrained workers. alternative obtaining annotations experts equally impractical fact many domains experts instead obtaining semantic ﬁne-grained category-level labels workers label images terms similarities differences. intuitively much easier untrained workers requires comparison images task humans naturally good approach however presents challenges different workers different criteria estimating similarity pairs images workers inﬂuenced images making decisions i.e. ‘context’. larity estimates provided different crowd workers. contributions ﬂexible model produces embedding input images. achieved modeling worker bias image context i.e. degree worker inﬂuenced attributes present given images. empirical evaluation annotations real crowd workers showing cens outperform existing approaches producing interpretable disentangled low-dimensional feature spaces. learning embeddings goal embedding algorithms learn dimensional representation collection objects objects close potentially high dimensional input space also close embedding space. embeddings useful large number tasks face recognition estimating clinical similarities medical patients learned pre-deﬁned feature vectors representing input objects similarity estimates obtained crowd combination crowdsourced annotations come form pairwise relative similarity estimates presenting workers sets images opposed pairs triplets efﬁcient acquiring estimates similarity another approach learn function extract meaningful features input data training similarity labels e.g. advantage able also embed objects observed training time. different notions similarity limitation methods typically assume objects compared using single similarity criteria. given pair triplet images estimate similarity valid visual attribute trait invalid another. example fig. comparing faces according gender expression result different grouping. practice workers different criteria unless speciﬁcally told attribute use. overcome limitation body work attempts learn embeddings alternative notions similarity represented embedding space. common approach instruct workers provide additional information regarding attribute used making decision. information come multiple forms category labels user provided text descriptions part correspondence annotations similar propose model inspired produces separate embedding similarity criteria instead learning single embedding tries satisfy constraints. contrast learn uniﬁed embedding alternative notions similarity extracted masking different dimensions space. however visual attribute used similarity estimate assumed known. also learn weighted feature representation input examples require category level labels order learn cross-category attributes. model learns different weight vector triplet resulting large number parameters. propose generative model learning attributes crowd workers instructed specify attribute interest text perform similarity estimates query images based pre-deﬁned attributes. majority methods assume extra information addition pairwise triplet labels available model. instead make context information present images show crowd workers. modeling crowd crowdsourcing annotations effective gathering large amount labeled data difﬁculty arises using annotations noisy workers behave differently. solution problem model ability biases worker resolve better quality annotations speciﬁc clustering propose bayesian model workers cluster data noisy pairwise annotations. efﬁciently gather large number labels workers presented successive grids images asked cluster images multiple different groups. modeling individual workers linear classiﬁers embedding space allow different worker biases. however assume workers consistent criteria making decisions change time. approach also learns individual worker models also making strong context information provided image grid. attribute discovery dimensional attribute based representations images beneﬁt interpretable pixel information addition providing semantically understandable descriptions images also used applications zero shot learning attributes discovered various means mining noisy images associated text descriptions crowdsourcing work explicitly produce ‘nameable’ attributes qualitatively observe embeddings model produces often disentangled along embedding dimensions. crowdsource task image similarity estimation dataset containing images referenced crowd worker presented image grid displaying collection images {ig} group many categories wish grid items results pairwise labels e.g. single grid items produces figure context embedding networks composed three neural networks trained jointly. worker encoder network models workers’ annotation behavior context encoder network models attributes highlighted particular images. jointly networks referred attribute encoders used weight embeddings produced image encoder network ﬁnal embedding respects similarity estimates worker dimensional space dimension corresponds different visual attribute. number annotations individual pairs. across grids real workers often inconsistent attributes cluster number clusters create. pair images shown grid clustered worker assigned positive label grouped together otherwise. results training pairwise similarity labels present model deﬁne loss function used train involves joint training three networks model workers grid context image embedding respectively fig. ﬁrst networks referred attribute encoders third image encoder. workers deﬁne attribute encoder network takes input one-hot encoding worker outputs dimensional worker attribute activation vector grid outputs dimensional grid attribute activation vector represents degree visual prominence attribute grid network trained grid attribute activation dimensions high values correspond salient visual attributes highlighted input grid. intuitively attribute variance collection images inﬂuence attributes noticeable workers. instance collection images similar along attributes except peak activation hand image varies along many different attributes close uniformly distributed. attribute vectors worker context encoders combined produce ﬁnal attribute encoder output seek learn non-linear mapping image disentangled euclidean coordinate dimension embeds image dimensional attribute speciﬁc subspace. achieve siamese network architecture image encoder network shared parameters take input encoding image outputs dimensional embedding vector although image embedding network learns embedding input image directly enough data possible learn feature extractor images similarly present model terms pairwise loss also possible triplet loss image encoder. brevity point forward omit s-hot encoding function notation learning crowd ignoring worker context information embedding learned using siamese networks contrastive training loss deﬁned max{ distance image embedding space. negative margin prevents over-expanding embedding manifold user provided label. contrastive loss alone encourage network learn dimensional attribute speciﬁc embeddings assumes crowd workers compare images using visual attributes. overcome this weight distance metric attribute activation vectors hypothesize worker’s decision cluster along particular attribute depends prior preferences speciﬁc visual attributes context highlighted images grid. based assumption deﬁne three variants distance metric weighted attribute activation vectors mixed attribute activation vector. exploring different non-linear methods mixing found simple summation sufﬁciently captures relationship biases. experiments section compare performance three different models. model biased workers concentrated worker attribute activation vector dominate mode +ag. alternatively workers weak prior preferences worker attribute activations grid attribute activations dictate mode. intuitively attribute activation vector serves mask indicates embedding dimension weighted heavily loss e.g. encouraging sparsity along relu non-linearities assume grids clustered along attribute uni-modal grids clustered mixture attributes multi-modal peaks corresponding attribute dimensions used. inspired dual margin contrastive loss proposed include positive margin term loss function prevent images overlapping embedding space could lead ﬁtting. ensures images pushed closer current embedding separated denote general attribute activation vector depending model variant crowd worker’s decision group images active decision choosing group images together seen passive decision. become problem workers group images different levels detail. example grid shapes containing squares triangles circles stars might clustered groups squares non-squares worker. second worker group images four different shape types. embedding model might incorrectly assume different attribute used separate images fact different level granularity ‘shape’ used workers. overcome problem introduce additional positive similarity weight captures relative importance positive similarity labels compared dissimilarity labels ensures model learn high level attributes workers cluster different levels detail. example above although cross category labels circles triangles stars positive labels generated within circle triangle star groups agree positive labels generated within non-square group thus allowing network learn high level attribute i.e. shape used workers same. show impact performance supplementary materials. regularization cens require number dimensions hyperparameter. however observe setting large number regularizing model tends subset available embedding dimensions. show cens recover meaningful lowdimensional embeddings noisy data. network architectures training details hyperparameters tuning described supplementary material. perform experiments following three datasets celeba contains images different celebrity faces select random subset images dataset instruct workers advance cluster attribute grid respecting four visual attributes gender expression skin color gaze direction. although expect workers deviate instructions deﬁnite ground truth attributes allow quantify attribute retrieval accuracy. unaware attribute selected grid. total workers clustered grids yielding similarity training pairs. retina medical dataset comprising fundus images retina belonging patients varying degrees diabetic retinopathy images contain number visual indicators disease hard exudates fundus images crop image patches. patches provide localized view contain indicator features disease. dataset challenging discover meaningful attributes disease indicator features visually subtle types images unfamiliar crowd. provide instructions attributes workers attend dataset. here workers clustered grids yielding similarity pairs. birds larger dataset composed bird head images made randomly selected species dataset demonstrate scalability cens. workers clustered grids yielding similarity labels. figure data collection gui. workers group images perceive visually similar assigning different groups. create groups grid images. grid images randomly sampled given dataset. using possible groups workers clustered images ﬁrst clicking group button right side page clicking desired images. group asked provide short text description used evaluation. image cluster worker converted pairwise similarity labels worker clustered minimum grids order receive reward ensuring worker encoder network sufﬁcient data learn from. variants model standard siamese network e.g. assumes pairwise similarity labels come notion similarity standard triplet network e.g. learns embeddings given similarity labels form similar bayesian crowd clustering workers modeled linear classiﬁers embedding space entangled image embedding individual worker models jointly learned variational methods. learns entangled image embedding similarity triplets disentangled masks learned separately pre-known attribute. baseline represents situation similarity dimension used worker known. cen-worker encoder only ﬁrst variant model uses worker modeling learn attribute activations weight embeddings cen-context encoder only model context information weight embeddings cen-mixture full model incorporates worker context information learn network weights worker bias grid context dataset. grid clustered worker take mode dimension attribute activation vector model’s prediction apred argmaxkak. attribute predict used cluster images. depending model variant used. examine annotations provided workers grids different apred quantify proportion attribute actually used. fig. show confusion matrix illustrating worker grid pair cen-mixture model able accurately predict attribute used. gender ﬁrst column denote proportion grid submissions apred submissions clustered along gender. attributes obtain attribute prediction accuracy. fig. plot entropy distribution confusion matrix ground truth attributes scattered throughout attribute predictions vice versa. cen-mixture model outperforms variants across four ground truth attributes. although workers encouraged focus four different attribute options experiment practice abide instructions proportion noise data signiﬁcant. celeba dataset approximately hits completed either clustered different attributes wearing glasses noisy submissions images separated different groups. also observed workers using different levels detail clustering attribute. example gaze attribute workers labeled looking left looking right etc. demonstrate model’s robustness perform experiments data without ﬁltering annotation noise. evaluation worker model learned worker encoder refer supplementary material. fig. shows attribute speciﬁc embeddings four subspaces learned celeba dataset. fig. shows embedding clearly separates images according gender. left expression subspace people smiling teeth showing right show serious unhappy expressions. middle ambiguous expressions. fig. shows subspace embedded along skin color attribute. ends darker skinned lighter skinned people. fig. shows subspace gaze direction people showing people either looking camera away again middle people wearing sunglasses looking ambiguous directions making difﬁcult assess gaze direction. fig. show attribute speciﬁc embeddings learned figure attribute retrieval accuracy. left predicted embedding dimensions cen-mixture model compared ground truth visual attributes celeba dataset. right quantify disentangled learned embeddings are. lower entropy indicates models better capture ground truth attributes along individual embedding dimensions. figure cluster names. keywords provided workers celeba. colored labels indicate manual grouping performed workers ﬁner grained distinctions compared others. retina dataset supervision given workers attributes attention select four dimensions highly activated learned dimensional embedding vector. attribute dimensions attain trivial activations. shows robust value fig. shows ﬁrst dimension seemingly showing presence absence optic disc feature retina. fig. shows subspace discriminates patches blood vessels present without. blood vessels mostly concentrated visually prominent around optic disc meaning attributes highly correlated. regardless capable distinguishing between attributes images displaying blood vessels without optic discs correctly embedded fig. fig. plots attribute groups laser scars fig. groups hard exudates indicator diagnosing diabetic retinopathy comparison embedding qualities baselines presented supplementary material. figure celeba attribute speciﬁc embeddings. plot shows four different embedding dimensions produced cen-mixture mode. vertical axis subplot randomly assigned visualization purposes. show representative images embeddings space yellow boxes. learns disentangle attributes. figure retina attribute speciﬁc embeddings. show subset four embeddings dimensions produced cen-mixture model retina dataset. dimensions correlated well visual features diabetic retinopathy. bedding space learned birds dataset. ellipse center corresponds mean gaussian distribution embedding coordinates ground truth species. observe compact clusters directly correlate ground truth species. please refer supplementary materials confusion plots ground truth species embedding clusters. varying amount training data. measure accuracy various model’s predictions similarity estimates unseen grid clustered known worker. grid input worker input image pair model predicts group test made dataset consists entire grids present training set. allows measure well generalizes sets images. able synthesize image grids highlight speciﬁc attributes useful active learning data collector seeks obtain similarity estimates along particular visual attributes. randomly generate million image grids individually pass context encoder extract grid attribute activation vectors grid. take softmax activation select grids entropy thus choosing grids highly expressive particular attribute. fig. shows generated grid lowest entropy gaze attribute. variance among images along attributes gender skin color gaze direction high variance gaze attribute. suggests order image grid emphasize particular attribute contained items similar high variance attribute. figure birds t-sne embedding. show t-sne plot four dimensional embedding produced full model birds dataset. indexed ellipses centered gaussian mean different ground truth species. clusters correlated well ground truth species birds. ture multiple attributes used cluster images lowest prediction accuracy bayesian crowd clustering model worker grid models attain similar prediction accuracies challenging retina dataset workers found difﬁcult discover various attributes cluster thus often ﬁxated single attribute hits. however still beneﬁt modeling context cen-mixture model achieves prediction accuracy model learned masks obtains highest accuracy important note model trained triplets pre-labeled true similarity attributes used cluster them. fig. shows pairwise prediction accuracy model plotted varying number training samples birds dataset. bayesian crowd clustering model worker grid models attain similar prediction accuracies cenmixture substantially outperforms baselines prediction accuracy accuracy model uses ground truth labels. figure synthesized image grids. context encoder used generate collections images highlight speciﬁc attributes. shown grid high variance along gaze direction attribute variance others. conclusion future work proposed novel deep neural network jointly learns attribute speciﬁc embeddings worker models grid context models crowd. comparing several baseline methods show model accurately predicts attributes used individual workers result produces better quality image embeddings. future work plan incorporate relative similarity estimates learning representations directly images although currently model worker individually practice similarity different workers could discovered clustering finally grid context encoder enables generate sets images highlight speciﬁc attributes. combining encoder active learning potentially speed collection annotations crowd", "year": 2017}