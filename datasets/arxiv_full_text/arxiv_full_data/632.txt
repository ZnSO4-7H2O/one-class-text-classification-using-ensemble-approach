{"title": "Programmable Agents", "tag": ["cs.AI", "cs.NE", "stat.ML"], "abstract": "We build deep RL agents that execute declarative programs expressed in formal language. The agents learn to ground the terms in this language in their environment, and can generalize their behavior at test time to execute new programs that refer to objects that were not referenced during training. The agents develop disentangled interpretable representations that allow them to generalize to a wide variety of zero-shot semantic tasks.", "text": "build deep agents execute declarative programs expressed formal language. agents learn ground terms language environment generalize behavior test time execute programs refer objects referenced training. agents develop disentangled interpretable representations allow generalize wide variety zero-shot semantic tasks. paper shows build agents execute declarative programs expressed simple formal language. agents learn ground terms language environment experience. learned groundings disentangled compositional; test time agents perform tasks involve novel combinations properties successfully. agents learn distinguish distinct properties referenced together training; trained tasks always reference objects conjunction shape color agents generalize test time tasks reference objects either property isolation. completely novel object properties referenced principle exclusion agents able successfully complete tasks reference novel objects way. works even agents never encountered programs involving type reference training. referring objects possess multiple novel properties also successful referring objects combinations known unknown properties. agents robust catastrophic forgetting. train subset tasks agents accomplish novel tasks zero-shot switch training novel tasks performance original tasks degrade. agents implemented deep neural networks trained reinforcement learning. agents learn programs refer properties objects properties assigned objects world entirely experience interacting environment. natural interpretable assignments properties objects emerge without direct supervision properties assigned. auxiliary prediction control tasks required good performance representations learned agents extremely interpretable. explicit mapping activation maps programmable layers agents terms programs execute. visualizing activation maps provides immediately interpretable picture agents assign properties objects world. extremely powerful generalization agents achieve made possible novel programmable network architecture. programmable networks impose sophisticated bottleneck agent’s representations whose structure ensures representations generalize. work paper builds recent lines work deep learning. resurgence modular networks decomposed recomposed compute different functions. neural module networks modularity visual question answering particularly inﬂuential thinking. type approach also recently seen great success answering questions involve relational reasoning second recent trend follow rise relational neural network architectures particularly interaction networks neural physics engine high level works relational architectures subsumed various neural approaches graph processing. nice overview recent techniques found gilmer compositionality become topic great interest machine learning robotics cognitive science central research language compositional neural architectures paired different forms attention impressive results natural language interfaces database tables language acquisition navigation environments present different deep approach grounding symbols perception introduce visual question answering auxiliary task improve zero-shot generalization. programs specify hard deterministic gating also reminiscent building neural networks infer execute computer programs popular topic recent research. different approaches problem focus networks infer programs networks execute programs networks jointly although much overlap many approaches. majority works model networks imperative programming style although researchers also begun explore structuring networks functional programs well work depart previous work considering networks execute simple declarative language. paradigmatic examples declarative languages prolog sql. declarative paradigm provides appealing ﬂexible describe tasks agents general framework follows goal speciﬁed state world satisﬁes relation objects. objects associated sets properties vocabulary properties gives rise system base sets sets objects share named property full universe discourse boolean algebra generated base sets. require things program. veriﬁer access true state environment inspect state determine satisﬁes program. also need search procedure inspects program well summary environment state decides modify environment bring program closer satisfaction. components correspond directly components standard setup. notably veriﬁer reward function search procedure agent several advantages thinking way. ﬁrst building semantic tasks becomes straightforward need specify program obtain reward function depends semantic properties objects environment. consequently easily speciﬁy diverse combinatorial tasks. another advantage framing places emphasis squarely generalization tasks. program interpreter useful must enumerate programs might want front. goal perform combinatorial tasks able specify behaviors test time accomplished successfully without additional training. type generalization quite difﬁcult achieve deep paper focus reaching blocks simplicity individual tasks belies complexity achieve. challenge agents ground terms programming language environment test time able execute programs terms novel ways. figure programmable reaching environment consists square arena robot center. blocks scattered randomly task episode reach towards speciﬁc block identiﬁed combination shape color. leftmost frame shows training episode remaining frames show various types generalization agents trained setting capable including operating single properties varying numbers objects novel shapes. figure shows several visualizations programmable reaching environment consists mechanical center large table. simpliﬁed version jaco body stereotyped basic geoms ﬁnger actuators disabled. episode ﬁxed number blocks appear random locations table. block shape color combination guaranteed uniquely identify block within episode. programmable reaching environment implemented mujoco physics engine hence objects subject friction contact forces gravity etc. task reaching environment hand near target block changes episode. task communicated agent integers specifying target color shape respectively. complexity environment varied changing number colors shapes blocks take. work consider variants. also control number blocks appear table episode four blocks training study generalization numbers. possible blocks allowed table episode generator ensures reaching task always achievable actuated rotating joints results continuous actions range observable features positions joints along angular velocities. joint positions represented angle joint joint coordinates. results total body features describing state arm. objects represented using position well quaternion representing orientation represented coordinate frame hand. block also -hot encoding shape color total object features block. provide object features blocks table well hand bodies compose arm. write reaching program environment speciﬁes hand near cube. condition checked automatically veriﬁer produce reward function takes values veriﬁer interprets near thresholding distance arguments exposed agent values reward function takes different states. show zero-shot generalization partition possible target blocks train test conditions. train agent choosing target randomly train conditions episode evaluate agent performance reaching blocks test conditions never targets training. call assignment targets train test conditions design. left panel figure shows designs consider variants reaching environment. rows columns matrix correspond different shapes colors respectively cell matrix corresponds different task. cells color coded yellow figure left different designs environments. center relationship features detectors applied produce disentangled representation right example detectors interact program. property detector outputs shown binary ease interpretation practice learned continuous values. begin explaining program operates given mapping objects properties denoted explained below. later sections expand explain assignment properties objects learned assignment process made differentiable enable training behavioural objective; however clarity presentation easiest begin simplifying assumption assignments properties objects crisp known. input program matrix whose columns objects rows properties. elements matrix indicates object property figure shows relevant objects identiﬁed example reaching program equation example environment contains four blocks robot hand total objects. object properties color shape together enough uniquely identify relevant objects program expressed indicator function obtained combining rows explained below. corresponds particular property referenced program values rows serve indicator functions subsets objects corresponding property. used select groups objects standard boolean operations implemented applying elementwise operations rows figure shows equation obtained. functions speciﬁcation correspond operations intersection union respectively. result vector whose elements form indicator function objects. corresponding indicator function contains robot hand cube excludes remaining objects. call result operation relevant objects vector denote vector play role stream reasoning process agents. order rows columns arbitrary. take advantage assign indexes named properties arbitrary order. type assignment done language models words model vocabulary assigned indexes embedding matrix imposes loss generality beyond restricting programs ﬁxed vocabulary properties. note none operations described section depend number objects. take advantage ﬂexibility experiments show behaviors learn generalize different numbers objects environment. program execution described previous section makes operations indicator functions uniquely deﬁned sets crisp; however uniqueness lost sets soft. would like apply programs soft sets assignment properties objects learned backprop. requires operations apply soft sets also differentiable. many ways meet requirements; purposes convenient choose following assignment veriﬁed operations self-consistent reduce standard boolean operations particular assignment convenient operation always gives non-zero derivatives arguments. discussion section assumed assignment properties objects given; however much interesting agents learn create matrix rather provided environment. architecture learning populate elements role detectors. detector operates matrix features similar columns correspond objects rows opaque vectors populated whatever information environment provides objects. create detector property vocabulary. detector small neural network maps columns value detectors applied independently column matrix detector populates single groups detectors corresponding sets mutually exclusive properties outputs coupled softmax. example learning matrix figure column output softmaxes colors shapes. columns ﬁlled whatever features environment provides position orientation etc. features must enough information identify properties vocabulary information permitted entangled features must disentangled relationship diagrammed figure would simple pre-train detectors property provide agent. however contributions paper show network architecture need this. agents learn identify meaningful properties objects reason sets objects formed combinations properties completely way. point described completely separate processing object. agent receives matrix whose rows features columns objects. apply battery detectors column create matrix rows properties columns objects. program applies elementwise operations rows create relevant objects vector order allow reasoning relationships objects introduce message passing scheme exchange information objects selected relevant objects vector. message passing operation closely resembles interaction network additional features. figure left performance canonical programmable architectures environment variants. center training generalization curves programmable agents learned detectors trained reaching variants. learning somewhat unstable cases successful agents learn generalize perfectly. right training generalization curves distilled agents trained variant exploiting ground truth property information training time substantially stabilizes learning. resulting transformed features object operation applied column resulting vectors aggregated columns matrix function produces local transformation features single object provides message object implement functions small mlps structurally message passing operation similar interaction networks neural physics engine messages objects mediated edge weights determined using modiﬁed version neighborhood attention operation duan recall relevant objects vector elements interval understand included consider happens means object relevant object current task. case resulting also effect message equation contribute words task-irrelevant objects pass messages task-relevant objects relational reasoning. consider different types relations programs would parameterizing message passing operation based relation achieved. since consider reaching tasks extra complexity needed present work. message passing output produced computing mlpω p)). full details appendix section look various ways agents implemented programmable networks generalize. throughout section refer different variants programmable reaching environment using names indicated left panel figure agents trained using deterministic policy gradient actor critic programmable networks. appendix full details training setup. start showing programmable reaching environment poses non-trivial challenge. perhaps immediately obvious individual tasks simple. design possible target blocks seen training readily solved standard deep architectures. standard architectures fail generalization unseen combinations properties. figure generalization experiments. column shows performance distribution single agent zero-shot tasks different conditions. text full description. standard architecture compare architecture similar lillicrap modiﬁed feature based observations. call canonical architecture shown achieve good performance many continuous control tasks. performance canonical architecture designs shown left plot figure reward step effectively perfect performance environments. curves canonical architecture achieves good performance tasks trained case completely fails generalize behavior reaching held target. good performance veriﬁes merely capacity problem; network trained four tasks able achieve four. center plots figure show performance curves programmable agent training evaluation conditions designs. learning always stable nonetheless successful many cases. emphasize difﬁculty stability rather performance; agents succeed training perform well generalization. stability training improved taking advantage ground truth property information critic training time. setting actor still learns detectors critic not. call distilled model learning curves distilled agents design shown right figure architecture partitions objects sets different properties achieve strong generalization. figure shows zero-shot performance agents fully learned detectors trained design. column summarizes reward step achieved agent testing episodes different generalization conditions. figure also shows baseline conditions. train condition corresponds agent tested episodes tasks trained random condition corresponds performance agent random weights. show results programmable agent successful training agents canonical architecture design. even tasks seen training canonical architectures better random. zero-shot conditions figure follows eval shows performance zero-shot tasks design shown figure color/shape shows performance color shape speciﬁed. color/shape shows performance color shape reach speciﬁed. blocks show performance zero-shot tasks different numbers blocks ignore blocks shows performance zero-shot tasks presence figure left performance off-diagonal diagonal tasks environment. training begins off-diagonal tasks switches diagonal tasks steps dashed black line shows point transitions off-diagonal task pushed replay buffer. right learned property matrix produced adjacent environment state. appendix additional visualizations. reach shape shows performance reaching blocks novel shape reach color shows performance reaching blocks novel color reach shape color shows performance reaching block introduce blocks adding additional shape color possible blocks appear table ignore blocks condition blocks properties appear table distractors never target reaching program. shape color conditions modify environment generation process ensure target uniquely identiﬁed speciﬁed color shape. apart train random conditions every episode every task figure zero-shot. every program speciﬁes target agent training time. showing generalization different numbers blocks ability ignore novel distractor blocks showing agent reaching zero-shot target conditions. right panel figure shows learned detector outputs successful agent. ﬁgure shows agent correctly identify properties objects referenced programs executes. agents robust catastrophic forgetting. show trained collection agents environment steps. ﬁrst steps follow train condition design remaining steps switch training test conditions. plots figure show performance curves agents training test conditions throughout full steps training. performance train condition degrade even millions steps switching training tasks. programmable network architecture enables build agents execute declarative programs expressed formal language. agents learn ground terms programs environment leverage grounded terms generalize beyond tasks trained agents achieve nearly perfect generalization variety zero-shot tasks standard deep architectures completely fail. achieved small concessions deep learning zeitgeist. assume boundaries objects agent observations known object properties agents reason must come predeﬁned vocabulary similar restriction word based language modelling. also ﬁxed mapping programs architecture. future work focus improving robustness training scaling method deal types properties relations. also interested extending method work vision. bratko. prolog programming artiﬁcial intelligence. pearson education shin song. making neural programming architectures generalize recursion. devin gupta darrell abbeel levine. learning modular neural network policies multi-task multi-robot transfer. ieee international conference robotics automation devlin uesato bhupatiraju singh mohamed kohli. robustfill neural program graves wayne reynolds harley danihelka grabska-barwi´nska colmenarejo grefenstette ramalho agapiou hybrid computing using neural network dynamic external memory. nature kulkarni narasimhan saeedi tenenbaum. hierarchical deep reinforcement learning integrating temporal abstraction intrinsic motivation. advances neural information processing systems pages lillicrap hunt pritzel heess erez tassa silver wierstra. continuous control deep reinforcement learning. international conference learning representations ling yogatama dyer blunsom. program induction rationale generation learning mikolov sutskever chen corrado dean. distributed representations words phrases compositionality. advances neural information processing systems pages socher huval manning semantic compositionality recursive matrixvector spaces. proceedings joint conference empirical methods natural language processing computational natural language learning pages socher perelygin chuang manning potts recursive deep models semantic compositionality sentiment treebank. proceedings conference empirical methods natural language processing agents trained using actor critic programmable networks. full architecture actor critic shown figure actor critic share programmable structure share weights. relationship explained main text derivation relevant objects vector actor critic vector produced taking weighted columns using denote columns write motivation weighting columns incorporating message passing weights equation want include information relevant objects role precisely identify objects. reducing columns ﬁxes size independent number objects. point architectures actor critic diverge. recall networks share weights fact different vectors consider. distinguish activations actor critic using denote produced actor denote produced critic. actor produces action using single linear layer followed tanh bound range actions computation critic slightly complex. although contains information observation contain information action critic requires. combine action passing single linear layer added observations consumed agent collected columns matrix column object environment objects include blocks table also hand robot arm. discussed section object described position orientation represented coordinate frame hand. block also shape color represented agent using -hot vectors. possible colors possible shapes total property features object. also provide joint positions observations joints total features represent arm. full observation matrix built appending positions column effectively represents object body pose relative way. means environment four blocks observation shape addition above also provide agent index hand need learn detect body. reaching episode lasts seconds controls issued second intervals total observations episode agents trained either frames collect experience replay buffer capacity frames training. action sample batch transitions replay buffer used update actor critic. target network actor critic stabilize training copy latest parameters target networks episode agents trained discount factor computing updates actor clip element gradient critic range training exploration noise follows ornstein–uhlenbeck process standard deviation damping factor programmable networks hidden layer size units actor critic. neighborhood attention operation using context query size units. detectors implemented logistic regressions object features. structure canonical actor critic networks shown figure experiments networks units hidden layer tanh activations throughout. weights initialized following strategy lillicrap training canonical networks used environment parameters programmable networks. settings discounting target networks exploration noise also same. canonical networks accept vectors observations obtain observations canonical networks ﬂattening matrix vector ensuring objects properties always appear locations ﬂattened vector. directs agent reach cube red. method referencing absence properties highlights another type generalization taking place. speciﬁed three logical operations equation not; however training programs form make operation. nonetheless agents still capable executing programs contain negations. reason works operations equation compatible. demorgan’s laws require negation interact particular rules classical logic require laws hold. deﬁnition chosen satisﬁes relations enough operation acquire negation semantics networks. referencing novel colors shapes works similar way. example vocabulary colors three appeared training data. label colors give best performance since leverages model’s assumption every object exactly color using technique equation write program reach block shape color ﬁgures show environment state along corresponding columns corresponding different properties annotated corresponding color shape terms. generic names indicate un-grounded concepts.", "year": 2017}