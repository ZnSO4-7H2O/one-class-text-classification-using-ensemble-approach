{"title": "Bayesian Optimization of Text Representations", "tag": ["cs.CL", "cs.LG", "stat.ML"], "abstract": "When applying machine learning to problems in NLP, there are many choices to make about how to represent input texts. These choices can have a big effect on performance, but they are often uninteresting to researchers or practitioners who simply need a module that performs well. We propose an approach to optimizing over this space of choices, formulating the problem as global optimization. We apply a sequential model-based optimization technique and show that our method makes standard linear models competitive with more sophisticated, expensive state-of-the-art methods based on latent variable models or neural networks on various topic classification and sentiment analysis problems. Our approach is a first step towards black-box NLP systems that work with raw text and do not require manual tuning.", "text": "along nuisances interact decisions like hyperparameter selection. example using higher-order n-grams means features need stronger regularization training iterations. generally decisions instance representation made humans heuristically; work ﬁrst automate them. technique instantiates sequential modelbased optimization smbo bayesian optimization approaches shown work well hyperparameter tuning though popular computer vision techniques received little attention nlp. apply technique logistic regression range topic sentiment classiﬁcation tasks. consistently method ﬁnds representational choices perform better linear baselines previously reported literature that cases competitive sophisticated non-linear models trained using neural networks. training data consist collection pairs dtrain d.in d.on input text document output output space. overall training goal maximize performance function machine-learned model held-out dataset ddev classﬁcation proceeds three steps ﬁrst maps input vector representation. second classiﬁer learned inputs outputs finally resulting classiﬁer argue technique also applicable applying machine learning problems many choices make represent input texts. choices effect performance often uninteresting researchers practitioners simply need module performs well. propose approach optimizing space choices formulating problem global optimization. apply sequential model-based optimization technique show method makes standard linear models competitive sophisticated expensive state-of-theart methods based latent variable models neural networks various topic classiﬁcation sentiment analysis problems. approach ﬁrst step towards blackbox systems work text require manual tuning. introduction researchers practitioners spend considerable amount time comparing machine-learned models text differ relatively uninteresting ways. example categorizing texts words include bigrams tf-idf weighting good idea? choices matter experimentally often leading differences performance little consistency across tasks datasets combination choices works best. unfortunately differences tell little language problems machine learners supposed solve. propose decisions automated similar hyperparameter selection given particular text dataset classiﬁcation task introduce technique optimizing space representational choices coefﬁcients output learned using logistic regression training data. denote concatenation hence parameters understood function training data representation function performance function turn function held-out data ddev x—also dtrain simplicity write rest clear context. typically ﬁxed model designer perhaps experimentation learning focuses selecting parameters logistic regression many linear models training step reduces convex optimization n|o| dimensions—a solvable problem still costly large datasets and/or large output spaces. seeking maximize respect wish carry training times necessary. choosing understood problem selecting hyperparameter values. therefore turn bayesian optimization family techniques recently introduced selecting hyperparameter values intelligently solving parameters costly. approach based sequential model-based optimization iteratively chooses representation functions round makes choice nonparametrically-estimated probabilistic model evaluates f—we call trial. iterative search algorithm goal balance exploration options exploitation previously-explored options good choice found small number trials. algorithm given xt—an expensive operation involves training select parameters assessing performance held-out data. third probabilistic model updated using nonparametric estimator. acquisition function good acquisition function returns high values either value predicted high uncertainty value high; balancing classic tradeoff exploitation exploration. criterion called expected improvement expectation choice exceed chosen depending surrogate model discussed below. options acquisition function include maximum probability improvement minimum conditional entropy gaussian process upper conﬁdence bound combination selected widely used acquisition function shown work well range tasks. another common approach surrogate gaussian process like bergstra preliminary experiments found perform favorably. further tpe’s tree-structured conﬁguration space advantageous allows nested deﬁnitions hyperparameters exploit experiments research smbo active many implementations publicly available; hpolib library libray takes input function treated black box—in case logistic regression trainer wraps liblinear library based trust region newton method —and speciﬁcation hyperparameters. setup learner logistic regression. optimize text representation based types n-grams used type weighting scheme removal stopwords. n-grams parameters minimum maximum lengths weighting scheme consider term frequency tf-idf binary schemes. last also choose whether remove stopwords constructing feature vectors document. furthermore choice representation interacts regularizer training convergence criterion consider regularizers penalty squared penalty also hyperparameters regularization strength training convergence tolerance. table complete list hyperparameters experiments. ﬁxed deﬁnition here prefer high probability probability maximize quantity draw many evaluate candidates according according note need given explicit form. order evaluate need compute joint distributions pend graphical model hyperparameter space—which allowed form tree structure. computed similarly using trials lowing. associate hyperparameter node graphical model; consider dimension denoted random variable ranges discrete uses reweighted categorical distribution probability proportional smoothing parameter plus counts occurrences continuous-valued constructs probability distribution placing truncated gaussian distribution centered standard deviation greater distances left right neighbors. simplest version node independent compute multiplying individual probabilities every node. treestructured version multiply probabilities along relevant path excluding nodes. table hyperparameters considered experiments. half hyperparameters related text representation bottom half logistic regression hyperparameters also interact chosen representation. treebank dataset rottentomatoes.com website. binary classiﬁcation task goal predict whether review positive negative obtained dataset http//nlp.stanford. edu/sentiment. electronics product reviews amazon dataset consists electronic product reviews subset large amazon review dataset. following setup johnson zhang text section ignore summary section. also consider positive negative reviews. obtained dataset http//riejohnson.com/ cnn_data.html. congressional vote transcripts u.s. congressional ﬂoor debates. dataset includes debates controversial bills similar previous work consider task predict vote speaker speech segment obtained http//www.cs.cornell.edu/ ˜ainur/sle-data.html. benchmark topic newsgroups dataset classiﬁcation dataset publicly available copy http//qwone.com/ ˜jason/newsgroups. topics dataset. derived four topic classiﬁcation tasks dataset. ﬁrst task classify documents across topics. second task classify related science documents four science topics third fourth tasks talk.religion.misc alt.atheism comp.graphics comp.windows.x. consider realistic setting removed header information article since often contain label information. standard datasets evaluating text categorization models benchmark results available. total eight tasks four sentiment analysis tasks four topic classiﬁcation tasks. table descriptive table classiﬁcation accuracies best hyperparameters dataset experiments. shows accuracies logistic regression model. correspond n-grams n-grams respectively. stop. whether perform stopwords removal not. reg. regularization type strength regularization strength conv. convergence tolerance. regularization strength round nearest integer readability. baselines dataset select supervised nonensemble classiﬁcation methods previous literature baselines. case emphasize comparisons best-published linear method best-published method overall. followings always means linear svm. methods trained evaluated training/testing data splits; cases standard development sets available used random training data development set. stanford sentiment treebank logistic regression model outperforms baseline reported socher used unigrams specify weighting scheme baseline. result still state-of-the-art based recursive neural tensor networks paragraph vector show logistic regression comparable recursive matrix-vector neural networks second-best these outperforming reported feed-forward neural networks variants johnson zhang used baselines. varied representations used term frequency normalization unit vectors weighting scheme ﬁnding outperformed term frequency. method achieved best performance binary weighting consider. close convolutional neural networks state-of-the-art. outperforms svms feed-forward neural networks restricted boltzmann machine approach presented dahl compressive feature learning method svm-unigrams svm-{ }-grams svm-{ }-grams nn-unigrams nn-{ }-grams nn-{ }-grams compressive feature learning lr-{ }-grams words sequential table comparisons imdb reviews dataset. results wang manning result dahl results johnson zhang }-grams compressive feature learning results paskov congressional vote method outperforms best reported results yessenalina multi-level structured model based latent-variable svm. show comparisons well-known weaker baselines well. table comparisons u.s. congressional vote dataset. svm-link exploits link structures min-cut result bansal svm-sle result reported yessenalina cluding distributed structured output model strong logistic regression baseline paskov uses -grams heuristic normalization elastic regularization; method found unigrams bigrams binary weighting penalty achieved better results. table comparisons newsgroups dataset classifying documents topics. disriminative result larochelle bengio compressive feature learning lr--grams results paskov distributed structured output result srikumar manning newsgroups talk.religion.misc alt.atheism comp.graphics comp.windows.x wang manning report bigram na¨ıve bayes model achieving tasks respectively. method achieves using slightly different setups discussion text input hyperparameters. results suggest seemingly mundane representation choices raise performance simple linear models comparable much sophisticated models. achieving results matter deep expertise domain engineering skill; choices automated. experiments considered logistic regression downcased text; choices— stemming count thresholding normalization numbers etc.—can offered optimizer additional feature options like gappy n-grams. becomes widely used applications believe automating choices attractive need train high-performance model quickly. this approach based minimum description length using unlabeled data select higher-order n-grams features. technically semi-supervised method. results compare logistic regression elastic regularization heuristic normalizations. this method designed structured prediction srikumar manning also applied classiﬁcation. attempts learn distributed representation features labels. authors used unigrams elaborate weighting scheme. figure classiﬁcation accuracies development data amazon electronics stanford sentiment treebank congressional vote datasets. plot green solid line indicates best accuracy found dotted orange line shows accuracy trial. general model able obtain reasonably good representation trials. optimized representations. task chosen representation different. possible hyperparameter choices experiments used least datsets example congressional vote dataset need bigrams whereas amazon electronics dataset need unigrams bigrams trigrams. binary weighting scheme works well datasets except sentence-level sentence analysis task tf-idf weighting scheme selected. regularization best cases one. believe expert would likely make particular choices except kind trial-and-error process method automates efﬁciently. often believe researchers make initial choices stick experiments optimizing choices give stronger baselines. training time. trials dataset experiments. figure shows trial accuracy best accuracy development data increase number trials three datasets. trials generally enough model obtain good results although search space large. presence unlimited computational resources bayesian optimization slower grid search hyperparameters since latter easy parallelize. realistic research development environments certainly impractical increasingly widespread instances personalized machine learning. bayesian optimization approach experiments performed sequentially. attempts predict hyperparameters next based information previous trials. work parallelize bayesian optimization making possible leverage power multicore architectures transfer learning multitask setting. treat dataset independently create separate model them. also possible learn previous datasets learn datasets simultaneously improve performance. potential reduce number trials required even further. bardenet swersky yogatama mann perform bayesian optimization settings. beyond linear models. logistic regression classiﬁcation model experiments show simple linear models competitive sophisticated models given right representation. models considered course ensembles increasing number options lead need trials evaluating take longer sophisticated models. demonstrated using simplest classiﬁcation models even simple choices text representation matter quite lot. structured prediction problems framework could also applied structured prediction problems. example part-of-speech tagging features include character n-grams word shape features word type features. optimal choice different languages always same approach automate process. beyond supervised learning. framework could also extended unsupervised semisupervised models. example document clustering also need construct representations documents. log-likelihood might serve performance function. range random initializations might considered. investigation approach nonconvex problems like clustering exciting area future work. used bayesian optimization approach optimize choices text representations various categorization problems. sequential modelbased optimization technique identiﬁes settings standard linear model competitive sophisticated stateof-the-art methods topic classiﬁcation sentiment analysis. every task dataset optimal choices; though relatively uninteresting researchers directly linked domain linguistic expertise choices effect performance. approach ﬁrst step towards black-box systems work text require manual tuning. references mohit bansal clair cardie lillian lee. power negative thinking exploiting label disagreement min-cut classiﬁcation framework. proc. coling. james bergstra daniel yamins david cox. making science model search hyperparameter optimization hundreds dimensions vision architectures. proc. icml. thomas desautels andreas krause joel burdick. parallelizing explorationexploitation tradeoffs gaussian process bandit optimization. proc. icml. katharina eggensperger matthias feurer frank hutter james bergstra jasper snoek holger hoos kevin leyton-brown. towards empirical foundation assessing bayesian optimization proc. nips workshop hyperparameters. bayesian optimization. rong-en kai-wei chang cho-jui hsieh xiangrui wang chih-jen lin. liblinear library large linear classiﬁcation. journal machine learning research richard socher jeffrey pennington eric huang andrew christopher manning. semi-supervised recursive autoencoders predicting sentiment distributions. proc. emnlp. richard socher alex perelygin jean jason chuang chris manning andrew chris potts. recursive deep models semantic compoproc. sitionality sentiment treebank. emnlp. niranjan srinivas andreas krause sham kakade matthias seeger. gaussian process optimization bandit setting regret experimental design. proc. icml. julien villemonteix emmanuel vazquez eric walter. informational approach global optimization expensive-to-evaluate functions. journal global optimization.", "year": 2015}