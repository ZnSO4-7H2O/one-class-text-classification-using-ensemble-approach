{"title": "SmoothGrad: removing noise by adding noise", "tag": ["cs.LG", "cs.CV", "stat.ML"], "abstract": "Explaining the output of a deep network remains a challenge. In the case of an image classifier, one type of explanation is to identify pixels that strongly influence the final decision. A starting point for this strategy is the gradient of the class score function with respect to the input image. This gradient can be interpreted as a sensitivity map, and there are several techniques that elaborate on this basic idea. This paper makes two contributions: it introduces SmoothGrad, a simple method that can help visually sharpen gradient-based sensitivity maps, and it discusses lessons in the visualization of these maps. We publish the code for our experiments and a website with our results.", "text": "common approach understanding decisions image classiﬁcation systems regions image particularly inﬂuential ﬁnal classiﬁcation. approaches additional de-noising effect sensitivity maps. techniques seem additive effect; performing together yields best results. paper compares smoothgrad method several gradient-based sensitivity methods demonstrates effects. provide conjecture backed empirical evidence technique works might reﬂective network classiﬁcation. also discuss several ways enhance visualizations sensitivity maps. finally also make code used generate ﬁgures paper available along examples compared method https//goo.gl/efvzee. explaining output deep network remains challenge. case image classiﬁer type explanation identify pixels strongly inﬂuence ﬁnal decision. starting point strategy gradient class score function respect input image. gradient interpreted sensitivity several techniques elaborate basic idea. paper makes contributions introduces smoothgrad simple method help visually sharpen gradient-based sensitivity maps discusses lessons visualization maps. publish code experiments website results. interpreting complex machine learning models deep neural networks remains challenge. understanding models function important building applications problem right. health care domains education many domains interpretability important. example pneumonia risk prediction case study showed interpretable models reveal important surprising patterns data complex models overlooked. reviews interpretable models case interest image classiﬁcation systems. finding explanation classiﬁcation decision could potentially shed light underlying mechanisms systems well helping enhancing them. example technique deconvolution helped researchers identify neurons failed learn meaningful features knowledge used improve network consider system classiﬁes image class given input image many image classiﬁcation networks compute class activation function class ﬁnal classiﬁcation class determined class highest score. mathematically clean locating important pixels input image proposed several authors e.g. functions piecewise differentiable image construct sensitivity simply differentiating respect input particular deﬁne represents derivative intuitively speaking represents much difference tiny change pixel would make classiﬁcation score class result might hope resulting would highlight regions. practice sensitivity label seem show correlation regions label present however sensitivity maps based gradients typically visually noisy shown fig. moreover image shows correlations regions human would pick meaningful rough best. figure noisy sensitivity based gradient class score gazelle image classiﬁcation network. lighter pixels indicate partial derivatives higher absolute values. section details visualization. maps faithful descriptions network doing. perhaps certain pixels scattered seemingly random across image central network making decision. hand also possible using gradient proxy feature importance optimal. seeking better explanations network decisions several prior works proposed modiﬁcations basic technique gradient sensitivity maps; summarize examples here. issue using gradient measure inﬂuence important feature saturate function words strong effect globally small derivative locally. several approaches layerwise relevance propagation deeplift recently integrated gradients attempt address potential problem estimating global importance pixel rather local sensitivity. maps created techniques referred saliency pixel attribution maps. another strategy enhancing sensitivity maps change extend backpropagation algorithm itself goal emphasizing positive contributions ﬁnal outcome. examples deconvolution guided backpropagation techniques modify gradients relu functions discarding negative values backpropagation calculation. intention perform type deconvolution clearly show features triggered activations high-level units. similar ideas appear suggest ways combine gradients units multiple levels. follows provide detailed comparisons vanilla gradient maps created integrated gradient methods guided backpropagation. note terminology although terms sensitivity saliency pixel attribution used different contexts paper refer methods collectively sensitivity maps. possible explanation noise sensitivity maps knowledge directly addressed literature derivative function ﬂuctuate sharply small scales. words apparent noise sees sensitivity essentially meaningless local variations partial derivatives. given typical training techniques reason expect derivatives vary smoothly. indeed networks question typically based relu activation functions generally even continuassess smoothgrad technique performed series experiments using neural network image classiﬁcation results suggest estimated smoothed gradient leads visually coherent sensitivity maps unsmoothed gradient resulting visualizations aligning better–to human eye–with meaningful features. sensitivity maps typically visualized heatmaps. finding right mapping channel values pixel particular color turns surprisingly nuanced large effect resulting impression visualization. section summarizes visualization techniques lessons learned process comparing various sensitivity work. techniques universally useful regardless choice sensitivity methods. absolute value gradients sensitivity algorithms often produce signed values. considerable ambiguity convert signed values colors. choice whether represent positive negative values differently visualize absolute value only. utility taking absolute values gradients depends characteristics dataset interest. example object interest color across classes positive gradients indicate positive signal class. hand imagenet dataset found taking absolute value gradient produced clearer pictures. possible explanation phenomenon direction context dependent many image recognition tasks invariant color illumination changes. instance classifying ball dark ball bright background would negative gradient white ball darker background would positive gradient. capping outlying values fig. gives example strongly ﬂuctuating partial derivatives. ﬁxes particular image image pixel fraction maxixi plots values entry gradient vector maxi short line segment space images parameterized show fraction maximum entry order verify ﬂuctuations signiﬁcant. length segment small enough starting image ﬁnal image looks human. furthermore image along path correctly classiﬁed model. partial derivatives respect green blue components however change signiﬁcantly. figure partial derivative respect values single pixel fraction maximum entry slowly moves gradient vector maxi away baseline image ﬁxed location random sample ﬁnal image indistinguishable human origin image given rapid ﬂuctuations gradient given point less meaningful local average gradient values. suggests create improved sensitivity maps instead basing visualization directly gradient could base smoothing gaussian kernel. directly computing local average highdimensional input space intractable compute simple stochastic approximation. particular take random samples neighborhood input average resulting sensitivity maps. mathematically means calculating figure effect noise level method images gazelle class imagenet sensitivity obtained applying gaussian noise input pixels samples averaging them. noise level corresponds distinguishable humans outlying values potential throw color scales completely. capping extreme values relatively high value leads visually coherent maps without post-processing step maps almost entirely black. multiplying maps input images techniques create ﬁnal sensitivity multiplying gradient-based values actual pixel values multiplication tend produce visually simpler sharper images although unclear much attributed sharpness original image itself. example black/white edge input lead edge-like structure ﬁnal visualization even underlying sensitivity edges. however result undesired side effect. pixels values never show sensitivity map. example encode black image classiﬁer correctly predicts black ball white background never highlight black ball image. hand multiplying gradients input images makes sense view importance feature contribution total score example linear system makes sense consider xiwi fig. shows effect noise level several example images imagenet column corresponds standard gradient refer vanilla method throughout paper. since quantitative evaluation remains unsolved problem focus qualitative evaluation. observe applying noise seems balance sharpness sensitivity maintain structure original image.we also observe range noise gives generally good results inception ideal noise level depends input. fig. similar experiment mnist dataset. sample size first inspect visual coherence second test discriminativity image monkey spoon would expect explanation monkey classiﬁcation concentrated monkey rather spoon vice versa. regarding visual coherence fig. shows side-by-side comparison method three gradient-based methods integrated gradients guided backprop vanilla gradient. among random sample images inspected found smoothgrad consistently provide visually coherent maps integrated gradients vanilla gradient. guided backprop provides sharp maps prone failure especially images uniform background. contrary observation smoothgrad highest impact object surrounded uniform background color exploring difference interesting area investigation. possible smoothness class score function related spatial statistics underlying image; noise differential effect sensitivity different textures. fig. compares discriminativity method methods. image least objects different classes network recognize. visually show discriminativity compute sensitivity maps classes scale calculate difference plot values diverging color images smoothgrad qualitatively shows better discriminativity methods. remains open question understand properties affect discriminativity given method e.g. understanding guided backprop seems show weakest discriminativity. vanilla sensitivity maps noisy images. mind smoothing procedure used augment gradient-based method. fig. show results applying smoothgrad combination integrated gradients guided backprop. observe augmentation improves visual coherence sensitivity maps methods. smoothgrad discussed applied classiﬁcation networks as-is. situations premium legibility however natural whether similar modify network weights sensitivity maps sharper. idea parallel ways smoothgrad well-known regularization technique adding noise samples training method also improves sharpness sensitivity map. fig. fig. show effect adding noise training time and/or evaluation time mnist inception model respectively. interestingly adding noise training time seems also provide de-noising effect sensitivity map. lastly techniques seem additive effect; performing together produces visually coherent combinations. gradientexperiments described suggest based sensitivity maps sharpened forms smoothing. first averaging maps made many small perturbations given image seems signiﬁcant smoothing effect. second effect enhanced further training data perturbed random noise. results suggest several avenues future research. first provided plausibility argument conjecture noisy sensitivity maps noisy gradients would worthwhile look evidence theoretical arguments support disconﬁrm hypothesis. certainly possible sharpening effect smoothgrad causes differential effect random noise different textures. second addition training noise direct methods create systems smoother class score functions. example could train explicit penalty size partial derivatives. create figure discriminativity different methods. image visualize difference scale scale logits ﬁrst second class scale normalizes gradient values values plotted using diverging color method represented columns. spatial coherent maps could penalty large differences partial derivatives class score respect neighboring pixels. also worth investigating geometry class score function understand smoothing seems effective images large regions near-constant pixel values. area exploration better metrics comparing sensitivity maps. measure spatial coherence might existing databases image segmentations already making progress systematic measurements discriminativity could also valuable. finally natural question whether de-noising techniques described generalize network architectures tasks. thank chris olah generously sharing code helpful discussions including pointing relation contractive autoencoders mukund sundararajan qiqi useful discussions. references bach sebastian binder alexander montavon gr´egoire klauschen frederick m¨uller klaus-robert samek wojciech. pixel-wise explanations nonlinear classiﬁer decisions layer-wise relevance propagation. plos baehrens david schroeter timon harmeling stefan kawanabe motoaki hansen katja ˜aˇzller klaus-robert. explain individual classiﬁcation decisions. journal machine learning research doshi-velez finale yaorong kohane isaac. comorbidity clusters autism spectrum disorders electronic health record time-series analysis. pediatrics figure effect noise level estimated gradient across mnist images. sensitivity obtained applying gaussian noise inference time averaging fig. samples. hughes michael elibol huseyin melih mccoy thomas perlis doshi-velez finale. supervised topic models clinical interpretability. arxiv preprint arxiv. been glassman elena johnson brittney shah julie. ibcm interactive bayesian case model empowering humans intuitive interaction. technical report massachusetts institute technology seong joon benenson rodrigo khoreva anna akata zeynep fritz mario schiele bernt. exploiting saliency object segmentation image level labels. arxiv preprint arxiv. simonyan karen vedaldi andrea zisserman andrew. deep inside convolutional networks visualising image classiﬁcation models saliency maps. arxiv preprint arxiv. szegedy christian zaremba wojciech sutskever ilya bruna joan erhan dumitru goodfellow fergus rob. intriguing properties neural networks. arxiv preprint arxiv. szegedy christian vanhoucke vincent ioffe sergey shlens wojna zbigniew. rethinking inception architecture computer vision. proceedings ieee conference computer vision pattern recognition zhou bolei khosla aditya lapedriza agata oliva aude torralba antonio. learning deep features discriminative localization. proceedings ieee conference computer vision pattern recognition", "year": 2017}