{"title": "Explaining How a Deep Neural Network Trained with End-to-End Learning  Steers a Car", "tag": ["cs.CV", "cs.LG", "cs.NE", "cs.RO"], "abstract": "As part of a complete software stack for autonomous driving, NVIDIA has created a neural-network-based system, known as PilotNet, which outputs steering angles given images of the road ahead. PilotNet is trained using road images paired with the steering angles generated by a human driving a data-collection car. It derives the necessary domain knowledge by observing human drivers. This eliminates the need for human engineers to anticipate what is important in an image and foresee all the necessary rules for safe driving. Road tests demonstrated that PilotNet can successfully perform lane keeping in a wide variety of driving conditions, regardless of whether lane markings are present or not.  The goal of the work described here is to explain what PilotNet learns and how it makes its decisions. To this end we developed a method for determining which elements in the road image most influence PilotNet's steering decision. Results show that PilotNet indeed learns to recognize relevant objects on the road.  In addition to learning the obvious features such as lane markings, edges of roads, and other cars, PilotNet learns more subtle features that would be hard to anticipate and program by engineers, for example, bushes lining the edge of the road and atypical vehicle classes.", "text": "part complete software stack autonomous driving nvidia created neural-network-based system known pilotnet outputs steering angles given images road ahead. pilotnet trained using road images paired steering angles generated human driving data-collection car. derives necessary domain knowledge observing human drivers. eliminates need human engineers anticipate important image foresee necessary rules safe driving. road tests demonstrated pilotnet successfully perform lane keeping wide variety driving conditions regardless whether lane markings present not. goal work described explain pilotnet learns makes decisions. developed method determining elements road image inﬂuence pilotnet’s steering decision. results show pilotnet indeed learns recognize relevant objects road. addition learning obvious features lane markings edges roads cars pilotnet learns subtle features would hard anticipate program engineers example bushes lining edge road atypical vehicle classes. previous report described end-to-end learning system self-driving cars convolutional neural network trained output steering angles given input images road ahead. system called pilotnet. training data images front-facing camera data collection coupled time-synchronized steering angle recorded human driver. motivation pilotnet eliminate need hand-coding rules instead create system learns observing. initial results encouraging although major improvements required system drive without need human intervention. gain insight learned system decides thus enable system improvements create trust system paying attention essential cues safe steering developed simple method highlighting parts image salient several methods ﬁnding saliency described authors. among sensitivity based approaches deconvolution based ones complex ones like layer-wise relevance propagation believe simplicity method fast execution test car’s nvidia drivetm computer along nearly pixel level resolution makes especially advantageous task. pilotnet training data contains single images sampled video front-facing camera paired corresponding steering command turning radius vehicle. training data augmented additional image/steering-command pairs simulate vehicle different off-center off-orientationpoistions. augmented images target steering command appropriately adjusted steer vehicle back center lane. pilotnet architecture shown figure network consists layers including normalization layer convolutional layers fully connected layers. input image split convolutional layers designed perform feature extraction chosen empirically series experiments varied layer conﬁgurations. strided convolutions used ﬁrst three convolutional layers stride kernel non-strided convolution kernel size last convolutional layers. convolutional layers followed three fully connected layers leading output control value inverse turning radius. fully connected layers designed function controller steering note training system end-to-end hard boundary parts network function primarily feature extractors serve controller. visualization mask shows regions input image contribute output network. regions identify salient objects. algorithm block diagram shown figure process creating visualization mask illustrated figure visualization mask overlaid input image highlight pixels original camera image illustrate salient objects. results various input images shown figure notice image base cars well lines indicating lanes highlighted nearly horizontal line crosswalk ignored. middle image lanes painted road parked cars indicate edge road highlighted. lower image grass edge road highlighted. without coding detections show pilotnet mirrors human drivers would visual cues. figure blowup pilotnet monitor. image captured front-facing camera. green rectangle outlines section camera image neural network. bottom image displays salient regions. note pilotnet identiﬁes partially occluded construction vehicle right side road salient object. best knowledge vehicle particularly pose here never part pilotnet training data. salient objects found method clearly appear ones inﬂuence steering conducted series experiments validate objects actually control steering. perform tests segmented input image presented pilotnet classes. class meant include regions signiﬁcant effect steering angle output pilotnet. regions include pixels correspond locations visualization mask threshold. regions dilated pixels counteract increasing span higher-level feature layers respect input image. exact amount dilation determined empirically. second class includes pixels original image minus pixels class objects found method indeed dominate control output steering angle would expect following create image uniformly translate pixels class maintaining position pixels class image input pilotnet would expect signiﬁcant change steering angle output. however instead translate pixels class keeping class ﬁxed feed image pilotnet would expect minimal change pilotnet’s output. figure illustrates process described above. image shows scene captured data collection car. next image shows highlighted salient regions identiﬁed using method section next image shows salient regions dilated. bottom image shows test image dilated salient objects shifted. predictions indeed born experiments. figure shows plots pilotnet steering output function pixel shift input image. blue line shows results shift pixels include salient objects line shows results shift pixels included salient objects. yellow line shows result shift pixels input image. shifting salient objects results linear change steering angle nearly large occurs shift entire image. shifting background pixels much smaller effect steering angle. thus conﬁdent method indeed important regions image determining steering. describe method ﬁnding regions input images pilotnet makes steering decisions salient objects. provide evidence salient objects identiﬁed method correct. results substantially contribute understanding pilotnet learns. examination salient objects shows pilotnet learns features make sense human ignoring structures camera images relevant driving. capability derived data without need hand-crafted rules. fact pilotnet learns recognize subtle", "year": 2017}