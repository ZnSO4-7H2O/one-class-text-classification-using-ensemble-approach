{"title": "What you need to know about the state-of-the-art computational models of  object-vision: A tour through the models", "tag": ["cs.CV", "cs.AI", "cs.LG", "q-bio.NC"], "abstract": "Models of object vision have been of great interest in computer vision and visual neuroscience. During the last decades, several models have been developed to extract visual features from images for object recognition tasks. Some of these were inspired by the hierarchical structure of primate visual system, and some others were engineered models. The models are varied in several aspects: models that are trained by supervision, models trained without supervision, and models (e.g. feature extractors) that are fully hard-wired and do not need training. Some of the models come with a deep hierarchical structure consisting of several layers, and some others are shallow and come with only one or two layers of processing. More recently, new models have been developed that are not hand-tuned but trained using millions of images, through which they learn how to extract informative task-related features. Here I will survey all these different models and provide the reader with an intuitive, as well as a more detailed, understanding of the underlying computations in each of the models.", "text": "junejo extended idea self-similarity patterns spatial domain temporal domain. using perform human action recognition video self-similarity features also used creating visual words bag-of-visual words framework. verall self-similarity descriptor useful basis fast scalable object recognition object detection system. system robust non-rigid deformations objects allows searching objects similar shape despite large changes texture colors pose. lobal self similarity descriptor descriptor extension local self-similarity descriptor mentioned above. local self-similarity captures selfsimilarities within relatively small regions. gssim however uses selfsimilarity globally capture spatial arrangements self-similarity long range similarities within entire image authors suggest order take full advantage self-similarity features computed globally rather locally. however makes gssim features computationally expensive. empirically compare local ssim versus global ssim features tested pascal ethz shape classes dataset. results suggest global ssim outperform locale features classification detection. similar local ssim global ssim features also used complementary features conventional image descriptors bow. model population simple complex cells modelled luminance images inputs. gabor filters different orientations sizes usually used simple cell receptive fields. then receptive fields complex cells modelled performing operation", "year": 2014}