{"title": "Variable Rate Image Compression with Recurrent Neural Networks", "tag": ["cs.CV", "cs.LG", "cs.NE"], "abstract": "A large fraction of Internet traffic is now driven by requests from mobile devices with relatively small screens and often stringent bandwidth requirements. Due to these factors, it has become the norm for modern graphics-heavy websites to transmit low-resolution, low-bytecount image previews (thumbnails) as part of the initial page load process to improve apparent page responsiveness. Increasing thumbnail compression beyond the capabilities of existing codecs is therefore a current research focus, as any byte savings will significantly enhance the experience of mobile device users. Toward this end, we propose a general framework for variable-rate image compression and a novel architecture based on convolutional and deconvolutional LSTM recurrent networks. Our models address the main issues that have prevented autoencoder neural networks from competing with existing image compression algorithms: (1) our networks only need to be trained once (not per-image), regardless of input image dimensions and the desired compression rate; (2) our networks are progressive, meaning that the more bits are sent, the more accurate the image reconstruction; and (3) the proposed architecture is at least as efficient as a standard purpose-trained autoencoder for a given number of bits. On a large-scale benchmark of 32$\\times$32 thumbnails, our LSTM-based approaches provide better visual quality than (headerless) JPEG, JPEG2000 and WebP, with a storage size that is reduced by 10% or more.", "text": "large fraction internet trafﬁc driven requests mobile devices relatively small screens often stringent bandwidth requirements. factors become norm modern graphics-heavy websites transmit low-resolution low-bytecount image previews part initial page load process improve apparent page responsiveness. increasing thumbnail compression beyond capabilities existing codecs therefore current research focus byte savings signiﬁcantly enhance experience mobile device users. toward propose general framework variable-rate image compression novel architecture based convolutional deconvolutional lstm recurrent networks. models address main issues prevented autoencoder neural networks competing existing image compression algorithms networks need trained regardless input image dimensions desired compression rate; networks progressive meaning bits sent accurate image reconstruction; proposed architecture least efﬁcient standard purpose-trained autoencoder given number bits. large-scale benchmark thumbnails lstm-based approaches provide better visual quality jpeg jpeg webp storage size reduced more. task image compression thoroughly examined years researchers teams joint pictures experts group designed ubiquitous jpeg jpeg image formats. recently webp algorithm proposed order improve image compression rates especially high-resolution images become common recent years. efforts approach compression problem empirical standpoint human experts design various heuristics reduce amount information needing retained determine ways transform resulting data that’s amenable lossless compression. work almost exclusively focused compression large images low-resolution thumbnail images usually ignored standard image compression algorithms tend make assumptions image scale. example usually assume patch high-resolution natural image contain redundant information. fact higher-resolution image likely component patches contain mostly low-frequency information. fact exploited image codecs such codecs tend efﬁcient compressing high-resolution images. however assumptions broken creating thumbnails high-resolution natural images patch taken thumbnail much likely contain difﬁcult-to-compress high-frequency information. large-scale compression thumbnails important application terms reducing disk storage making better limited internet bandwidth. enormous numbers thumbnails currently transmitted across page previews photo galleries search engine results numerous applications. such improvements thumbnail compression signiﬁcantly improve experience users accessing content low-bandwidth connections. recent years neural networks become commonplace perform tasks decades accomplished algorithms heuristics. instance image recognition object detection current state-of-the-art algorithms based neural networks. natural also employ powerful class methods improve task image compression especially image sizes carefully designed hand-tuned compressors. consider image codec broadly analysis/synthesis problem bottleneck middle signiﬁcant body research aimed toward teaching neural networks discover compressive representations. work synthesis small images often part cifar much work focused class neural networks known autoencoders however standard autoencoders operate number hard constraints made infeasible drop-in replacement standard image codecs. constraints variable-rate encoding typically possible visual quality output hard ensure; they’re typically trained particular scale able capture redundancy scale. explore several different ways neural network-driven image compression improve compression rates allowing similar ﬂexibility modern codecs. achieve ﬂexibility network architectures discuss must meet following requirements compression rate capable restricted prior budget; compressor able encode simpler patches cheaply model able learn large amounts existing imagery order optimize compression process toward real-world data. basic principles using feed-forward neural networks image compression known time context networks assist even entirely take many processes used part traditional image compression pipeline learn efﬁcient frequency transforms effective quantization techniques improved predictive coding etc. recently autoencoder architectures become viable means implementing end-to-end compression. typical compressing autoencoder three parts encoder consumes input transforms bottleneck representing compressed data transformed decoder something resembling original input. three elements trained end-to-end deployment encoder decoder normally used independently. bottleneck often simply neural layer allows compression rate visual ﬁdelity encoded images controlled adjusting number nodes layer training. types autoencoder encoding bottleneck simple vector beneﬁcial neural net-based classiﬁcation tasks images repeatedly downsampled convolution pooling operations entire output network might contained single node. decoder half autoencoder however network must proceed opposite direction convert short vector much larger image image patch. upsampling process spatially-aware resembling backward convolution commonly referred deconvolution long short-term memory networks type recurrent neural network proven successful tasks speech recognition machine translation many extensions standard lstm model possible including explicitly incorporating spatial information leads various types convolutional lstms better suited image compression. experiment models also simpler recurrent architectures residual error autoencoder input another. start describing general neural network-based compression framework discuss details multiple instantiations architecture. subsection describes different architecture builds previous model improves compression results. architecture discuss function takes image patch input produces encoded representation. representation processed binarization function across architectures discussed section finally architecture also consider decoder function takes binary representation produced generates reconstructed output patch. taken together three components form autoencoder basic building block compression networks. architectures offset scale applied -bit input images give range values range compatible values emitted tanh. neural network architectures share conceptual stages encoder network followed quantizer decoder network. addition framework tuned image compression supports variable compression rates without need retraining storing multiple encodings image. make possible transmit incremental information design take account fact image decoding progressive. design goal mind consider architectures built residuals goal minimizing residual error reconstruction additional information becomes available decoder. formally chain multiple copies residual autoencoder deﬁned chaining explicit case feed-forward-only networks implicit recurrent structure case lstm networks cases equal original input patch represents residual error stages. non-lstm architectures memory expect predict residual itself. case full reconstruction recovered summing residuals stage penalized difference prediction previous residual vectors trivially serializable/deserializable image transmission wire control network compression rate achieved simply putting constraints allowance binary bottleneck helps force network learn efﬁcient representations compared standard ﬂoating-point layers many redundant patterns effect output. binarization process consists parts. ﬁrst part consists generating required number outputs continuous interval second part involves taking real-valued representation input producing discrete output value. ﬁrst step binarization process fully-connected layer tanh activations. second part following raiko possible binarization deﬁned bbin standard linear weights bias transform activations previous layer network. models formulation forward pass. backward pass back-propagation take derivative expectation since pass gradients unchanged. order ﬁxed representation particular input networks trained likely outcome considered replaced binf deﬁned compression rate determined number bits generated stage corresponds number rows matrix number stages controlled number repetitions residual autoencoder structure. simplest instantiation variable rate compression architecture composed stacked fully-connected layers. order make search architectures feasible decided number outputs fully-connected layer constant used tanh nonlinearity. given functions encoding stage number since statistics residuals change going stage considered distinct approaches ﬁrst share weights across stages second learn distinct weights independently stage. details architecture given figure following lstm formulation notation proposed zaremba superscripts denote hidden indicate layer number subscripts indicate time steps. afﬁne transform state l-th lstm layer time step deﬁne finally denote element-wise multiplication input ﬁrst lstm layer time step figure fully-connected residual autoencoder. depict two-iteration architecture goal ﬁrst iteration encode original input patch goal second iteration encode residual ﬁrst level’s reconstruction. -bit results reported table iterations giving bits each. blocks marked fully-connected neural network layers units tanh nonlinearities. loss applied residuals training simple measure. figure fully-connected lstm residual encoder. lstm blocks represent lstm layers units. ﬁgure shows unrolling lstm needed training time steps. actual architecture would ﬁrst blocks functionality second realized feeding residual previous pass back ﬁrst lstm block. results reported table repeated feeding back done times generate representations. vertical connections lstm stages unrolling shows effect persistent memory instead lstm. loss applied residuals training simple measure. note contrast figure network ﬁrst step used predict previous step’s residual error lstm architecture step predicts actual output. figure convolutional deconvolutional residual encoder. convolutional layers depicted sharp rectangles deconvolutional layers depicted rounded rectangles. loss applied residuals. sigm denotes sigmoid function. equations sigm tanh applied element-wise. alternate formulation lstm useful reduces numbers separate operations needed evaluate step allows efﬁcient implementation gpu. encoder fully-connected layer followed stacked lstm layers. decoder opposite structure stacked lstm layers followed fully-connected layer tanh nonlinearity predicts values exact architecture used experiments given figure section proposed fully-connected residual autoencoder. extend architecture replacing fully-connected layers convolution operators encoder deconvolutional operators decoder ﬁnal layer decoder consists convolution three ﬁlters converts decoded representation values. depict architecture figure deconvolutional operator deﬁned transpose convolutional operator. denote convolutional operator stride denote stride operator stride factor i.e. multi-channel image pixel coordinate note transpose inﬂation operator ﬁnal architecture combines convolutional deconvolutional operators lstm. equation convolutions deﬁne convolutional lstm replacing transformation plus bias. transformation function convolutional lstm stride subscript belonging refers depth output feature maps. note second convolution term represents recurrent relation convolutional lstm input output must size. therefore convolutional lstm stride greater stride applied ﬁrst convolution term second term always computed stride one. finally build encoder architecture replace second third convolutional layers figure convolutional lstm layers. decoder cannot replace convolutional operations deconvolution fact input deconvolution often different spatial dimension output. purposes deﬁning deconvolutional lstm becomes subscripts differentiate weights associated convolution deconvolution operations. construct deconvolutional lstm decoder replace second third deconvolutional layers deconvolutional decoder figure deconvolutional lstm. non-convolutional approaches presented here natural assign varying number bits patch allowing varying number iterations encoder. could determined target quality metric natural case convolutional approaches similar method also employed. input image needs split patches patch processed independently thereby allowing different number bits region. however approach disadvantages discussed paper. order train various neural network conﬁgurations used adam algorithm proposed kingma experimented learning rates loss normalized number pixels patch also number total time steps needed fully encode patch. employed perceptual weighting improve compression evaluation ssim measure. training used unmodiﬁed error measure. experimented number steps needed encode patch varying fully connected networks chose bits step patch allowing tune compression rate increments bits. scaled patch size allowed control compression increments bits. convolutional/deconvolutional networks encoders reduce input patch convolution operations strides. experimented binary output bits pixel resolution yielding tunable compression rate increments bytes block. evaluating image compression algorithms non-trivial task. metric commonly used context peak signal-to-noise ratio however psnr biased toward algorithms tuned minimize loss. would fair comparison methods like jpeg tuned minimize form perceptual loss. evaluation protocol instead employ structural similarity index popular perceptual similarity measure proposed wang since we’re evaluating compression performance small images smooth images addition since we’re interested quantifying well local details preserved split images patches compute ssim patch color channel independently. ﬁnal score average ssim patches channels. analyzing results higher score implies better reconstruction score representing perfect reconstruction. lowest possible score note metrics emulate human visual system better ssim chose ssim ubiquity ease comparison previous work. benchmark dataset contains million random color images collected public internet. included dataset image must originally pixels axes. qualiﬁed images downsampled losing original aspect ratios. downsampling eliminates pre-existing compression artifacts images. ﬁnal images stored losslessly used training testing. training lstm models images used; remaining aside evaluation. evaluating image codecs subset data containing random images. table summarizes results benchmark comparing lstm approaches jpeg codecs webp. avoid unfairly penalizing codecs unavoidable cost headers exclude header size metrics. note also since standard codecs tuned exact byte budget search encoder quality setting leads whose size close possible never less than target size. average leads jpeg webp image consuming slightly space allow lstm models. analysis images contain considerable detail perceptually relevant. seen figure compressing images without destroying salient visual information hallucinating false details challenging. bitrates spatial resolution jpeg block artifacts become extremely prominent webp either introduces blocking overly blurs image depending strength internal ﬁlter. color smearing artifacts codecs’ default chroma subsampling also clearly visible. compared jpeg non-convolutional lstm model slightly reduces inter-block boundaries images also lead increased color bleeding furthermore visual quality never exceeds jpeg average measured ssim shown figure motivates convolutional lstm model eliminates block artifacts avoiding excessive smoothing. strikes best balance preserving real detail avoiding color smearing false gradients hallucinated detail present original image. note convolutional lstm model exhibits perceptual quality levels equal better jpeg webp lower average bitrate. improvement despite fact that unlike jpeg webp lstms perform chroma subsampling preprocess. however jpeg quality levels used figure disabling subsampling leads costly increase jpeg’s bitrate instead greater. means desired preserve chroma ﬁdelity would need drastically terms coding efﬁciency took autoencoder architecture given budget either bytes compared ssim convolutional lstm encoder targets. cases lstm model produces ssim values equivalent autoencoder even though resulting model ﬂexible. describe various methods variable-length encoding image patches using neural networks demonstrate given benchmark fully-connected lstm model perform jpeg convolutional/deconvolutional lstm model able signiﬁcantly outperform jpeg ssim perceptual metric. figure rate-distortion graph showing ssim different codecs different target rates. results averaged images jpeg webp hold-out million images lstm models. convolutional lstm model provides highest ssim across rates though expect webp provide better ssim higher rates. current approach gives favorable results versus modern codecs small images codecs include entropy coder element tend improve greater resolution meaning choosing arbitrarily large test image always possible defeat approach like described work. therefore obvious need extend current work function arbitrarily large images taking advantage spatial redundancy images manner similar entropy coding. although presented solution dynamic assignment convolutional case fully satisfactory solution potential introduce encoding artifacts patch boundaries. another topic future work determining dynamic assignment algorithm compatible convolutional methods present creating artifacts. chen wang yeung d.-y. wong w.-k. w.-c. convolutional lstm network machine learning approach precipitation nowcasting. corr abs/. http//arxiv.org/abs/..pdf. figure effect ﬁrst four bits compressing image. image left created using single block. subsequent images additional processed lstm decoder ﬁnal image created running four steps algorithm thus allowing total four bits used encode block. order better understand network architecture proposed section initially limited terms capacity target namely restricted output step trained network compress grayscale images. took simpler network encoded popular image time. figure shows effect ﬁrst four steps encoding. figure depicts behavior additional bits four blocks image using network. zoomed-in version apparent network ﬁrst learns differentiate dark light patches using ﬁrst bit. given additional network able introduce solid shades gray. starts introducing simple gradients reﬁned fourth", "year": 2015}