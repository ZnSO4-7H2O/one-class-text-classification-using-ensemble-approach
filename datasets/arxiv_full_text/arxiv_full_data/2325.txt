{"title": "Overlapping Mixtures of Gaussian Processes for the Data Association  Problem", "tag": ["stat.ML", "cs.AI", "cs.LG"], "abstract": "In this work we introduce a mixture of GPs to address the data association problem, i.e. to label a group of observations according to the sources that generated them. Unlike several previously proposed GP mixtures, the novel mixture has the distinct characteristic of using no gating function to determine the association of samples and mixture components. Instead, all the GPs in the mixture are global and samples are clustered following \"trajectories\" across input space. We use a non-standard variational Bayesian algorithm to efficiently recover sample labels and learn the hyperparameters. We show how multi-object tracking problems can be disambiguated and also explore the characteristics of the model in traditional regression settings.", "text": "work introduce mixture address data association problem i.e. label group observations according sources generated them. unlike several previously proposed mixtures novel mixture distinct characteristic using gating function determine association samples mixture components. instead mixture global samples clustered following trajectories across input space. non-standard variational bayesian algorithm eﬃciently recover sample labels learn hyperparameters. show multi-object tracking problems disambiguated also explore characteristics model traditional regression settings. data association problem arises multi-target tracking scenarios. given observations represent positions number moving sources cars airplanes data association consists inferring observations originate source data association found tracking problems instance computer vision surveillance sensor human observer little eﬀort required distinguish noisy trajectories example representing paths followed objects time. speciﬁc case observation target available time instant measurement instants equally spaced time although neither properties required general. typical multi-target tracking algorithms operate online. include joint kalman ﬁlters joint particle ﬁlters given predicted positions targets number candidate observed positions usually make instant data association decisions based nearest-neighbor criteria statistically sophisticated approaches joint probabilistic data-association filter multiple hypothesis tracker important disadvantage classical techniques usually require determine large number parameters. drawback motivated development several conceptually simpler approaches based motion geometry heuristics however approaches usually limited speciﬁc scenarios show diﬃculties presence noise several trajectories cross other. data association techniques signiﬁcantly improved postponing decisions enough information available exclude ambiguities although causes number possible trajectories grow expopaper present algorithm based gaussian processes able consider available data points batch form whilst avoiding exponential growth potential tracks. result capable deal diﬃcult data association problems trajectories come close even cross other. furthermore algorithm require knowledge model underlying data need time instants evenly spaced contain observations sources. gaussian processes powerful tool bayesian nonlinear regression. combined mixture models applied describe data local non-stationarities discontinuities components mixture model prior probability given component typically provided gating function. role gating function dictate priori likely responsible data given region input space i.e. gating network forces component mixture localized. work follow diﬀerent approach inspired data association problem. particular given location input space multiple targets perhaps corresponding multiple objects tracking system. interested constructing mixture model associate targets separate components. ambiguity posterior distribution targets reﬂect this. therefore propose simple mixture model component global scope. assignment data performed sample-wise independently input space localization. words gating function used. call model overlapping mixture brought attention proposed model bears resemblance work however focus application clearly diﬀerent. objective cluster trajectories according similarity whereas work tackle task clustering observations trajectories also uses standard variational bayesian algorithm whereas work take advantage non-standard variational algorithms derive tighter bound. vide brief review regression setting. section ﬁrst introduces omgp model discusses perform eﬃcient learning hyperparameter selection predictions using model. experiments several data sets provided section wrap section brief discussion. recent years gaussian processes attracted attention nice analytical properties state-of-the-art performance regression tasks section provide brief summary main results regression details. assume multi-dimensional inputs corresponding scalar outputs yn}m available. regression task given input obtain predictive distribution corresponding observation based covariance function speciﬁes degree coupling encodes properties power level smoothness etc. best-known covariance functions anisotropic squared exponential. form unnormalized gaussian length-scales diagonal matrix containing lengthscale input dimension. length-scale controls fast correlation outputs decays separation along corresponding input dimension grows. collectively refer kernel parameters dealing multi-output functions instead single observations sets available corresponding diﬀerent output dimension. case assume independence across outputs perform procedure independently dimension. provide reasonable results problems correlation between diﬀerent dimensions expected take advantage knowledge model jointly using multi-task covariance functions overlapping mixture gaussian processes model assumes output produced evaluating functions corresponding input adding gaussian noise association samples latent functions determined correlation diﬀerent trajectories known exist trajectories jointly modeled single using covariance function accounts dependence. would increase computational complexity inference model following derivations still applied. hyperparameters known possible approximately compute posterior using variational approximation. jensen’s inequality construct lower bound marginal likelihood follows lower bound variational distribution equality attained p}|x objective therefore variational distribution maximizes thus becomes approximation true q})q. assume given available) possible analytically maximize respect setting derivative zero constrainfore limitations conventional regarding size data sets applied however posterior probability indicator close zero sample longer aﬀects trajectory dropped computation thus reducing cost. furtherever quality bound sensitive changes model hyperparameters approach results slow convergence. solution problem described advantages maximizing alternative tighter bound likelihood shown. kl-corrected lower bound lcorrvb computed analytically advantage respect depending since possible integrate p|x) analytically. bound lcorrvb alternatively obtained following recent work optimally removing standard bound. context work lcorrvb referred marginalized variational bound made clear lcorrvb corresponds simply when given optimal choice made. words hyperparameters choses according lcorrvb would provide result. thus learning performed simply optimizing lcorrvb respect course strategy maximizes lcorrvb valid computing lcorrvb according provided expression without incurring numerical errors challenging practice since several inversions maybe unstable needed. also note take arbitrarily small values thus direct inversion possible. implementation-friendly expression explicit inverses avoided omgp model used variety tasks. data association problem task hand cluster observations trajectories achieved assigning observation trajectory likely generated i.e. assign label maxmnm n-th observation computations necessary. tasks however necessary obtain predictive distributions output space locations. variational approximation predictive distributions computed analytically. i.e. gaussian mixture approximate posterior. mixing factors prior probabilities component given hyperparameters model typically constant inputs. note correspondence predictive equations standard predictions regression diﬀerence noise component scaled sample according particular posterior probability sample belonging current trajectory decays amount noise associated sample proportionally grown thus reducing eﬀect posterior process. though description omgp oriented towards batch data association tasks model also successfully applied online tasks using data grows time. samples included arrive learning process re-started initializing state obtained solution previous problem. depending constraints given problem many diﬀerent optimizations made avoid explosion computational eﬀort using low-rank updates. note however since model elements latent function form fully connected graph markovian property hold computation time required update constant. possible workaround achieve constant-time updates constatsize data sets instance corresponding sliding window perform low-rank updates include remove samples. however pursue option work. section investigate behavior omgp data association tasks regression tasks showing versatility model. implementation omgp matlab dual-core desktop memory yielding executions times order seconds experiment. ﬁrst apply omgp perform data association data set. sources perform circular motions clockwise counterclockwise depicted fig. available observations represent measured positions sources known time instants. however known observed position corresponds source. since trajectories circles center radius sources cross twice revolution making clustering problem diﬃcult. however shown fig. omgp capable successfully identifying unknown trajectories. fig. illustrates uncertainty estimated labels. speciﬁcally shows decrease posterior probability correct labels whenever sources come close. figure observations sources move opposite circles. data association solution obtained omgp. posterior probability correct label observations coming source details refer problem posed consists tracking sources estimating unknown state vector given correct initial states consider complex scenario adding third source initial state sources certain instant. apply sir/mcjpda ﬁlter omgp perform data association observations. sir/mcjpda ﬁlter consists joint particle ﬁlters perform tracking multiple sources combined joint probability data association technique provides instantaneous data association. number particles used experiment order operate correctly sir/mcjpda ﬁlter requires complete knowledge used state-space model initial state vectors note omgp completely blind regard. omgp algorithm operated ﬁrst incremental online setting. illustration purposes also include results batch version omgp algorithm. trajectories obtained method found fig. along predicted measurements. although sir/mcjpda ﬁlter initially performs correctly encounters diﬃculties point sources come close. point shows erroneous assignments least trajectory. mistakes mainly state vector depending previous state proves insuﬃcient sources close multiple consecutive measurements. online version omgp show problem. smoothest solution obtained batch omgp performs global evaluation entire trajectories. number observations assigned wrong trajectories nerr total observations. observed versions omgp algorithm obtain superior results compared sir/mcjpa. furthermore sir/mcjpda requires complete knowledge state-space model initial state vectors omgp require knowledge underlying model. interestingly data association problem found contexts beyond standard multi-target tracking scenarios digital communications third experiment apply omgp data association problem occurs wireless communication networks. interference alignment concept recently emerged solution raise capacity wireless multiple-input multiple-output networks underlying idea along spatial dimensions interference transmitters must aligned receiver subspace orthogonal signal space. order implement interference alignment scenarios multiple subcarriers digital ﬁlter must applied transmit antenna. consider -user interference channel antennas node ofdm modulation using subcarriers allows possible ﬁlter responses subcarrier. since smooth frequency responses implemented smoothest solution possible choices selected. combinatorial problem corresponds data association problem smoothest curve interest. data used experiment consists simulated data sets data obtained mimo test setup using subcarriers. fig. illustrate solutions obtained omgp data sets. simulated data sets fig. fig. represent reasonably simple data association problems performance omgp realworld data fig. shows capable correctly distinguishing smoothly-varying solution surrounding noisy data. matter fact able successfully implement omgp setting parallel ungoing research project. figure data association results obtained omgp diﬀerent interference alignment problems. shows solutions ﬁrst simulated data set. show solutions ﬁrst second simulated data sets shows solution real-world data set. note complex values simply simply treated two-dimensional real data experiment. consider data fig. corresponds observations three independent functions. normal would fail produce valid multimodal outputs previously proposed mixtures would restrict component local parts space. omgp properly label observation according generating function provide multimodal predictive distributions depicted fig. fig. also interpreted measurements position three particles moving along dimension snapshots taken irregular time intervals snapshot introduces noise position measurement necessarily capture position since mixture diﬀerent covariance function possible capture unrelated outliers another interpolate main function. easily achieved mixture ard-se covariance function another i.e. white noise. consider problem regression noisy sinc outliers introduced fig. observe omgp identiﬁes outliers ignores them resulting much better predictive means variances. finally fig. shows results running omgp motorcycle data components identiﬁed might might correspond actual physical mechanisms alternatively producing observations. predictive variances show improved behavior respect standard work introduced novel mixture model inspired multi-target tracking problems. model important diﬀerence respect previous approaches using global mixture components assigning samples components relying value output space instead input space simple eﬃcient algorithm inference relying variational bayesian framework provided. model applied practice improved kl-corrected variational bound learn omgp model oﬀers promising results tracking moving targets illustrated experimentally section compares favorably established methods ﬁeld. also imaginative application model using diﬀerent covariance functions able adapt approach robust regression heteroscedastic noise. naive implementation limits applicability thousand data samples. however recent advances sparse approximations greatly enable approach applied much larger data sets. authors wish thank oscar gonz´alez university cantabria providing data used interference alignment experiment. ﬁrst second authors supported micinn grants tec--c- consolider-ingenio csd- additionally funding support part collaborative eﬀort provided pascal’s internal visiting programme.", "year": 2011}