{"title": "A Multivariate Discretization Method for Learning Bayesian Networks from  Mixed Data", "tag": ["cs.AI", "cs.LG"], "abstract": "In this paper we address the problem of discretization in the context of learning Bayesian networks (BNs) from data containing both continuous and discrete variables. We describe a new technique for <EM>multivariate</EM> discretization, whereby each continuous variable is discretized while taking into account its interaction with the other variables. The technique is based on the use of a Bayesian scoring metric that scores the discretization policy for a continuous variable given a BN structure and the observed data. Since the metric is relative to the BN structure currently being evaluated, the discretization of a variable needs to be dynamically adjusted as the BN structure changes.", "text": "paper address discretization bayesian taining ables. multivariate continuous account variables. bayesian scoring scores tinuous variable observed ative structure currently evaluated needs dynamically structure networks approaches learning data simplifying assumptions made circumvent implementa­ tion theory. variables continuous often restrictive world domains continuous possible cretize apply well established learning alternative data based limited sities action tion general marred often prohibitive cases discretization empirical evidence sion appeals discretization parametric advantage however rious dependencies strategies cretization ables individually without action discretization tion distinguish tion whereby account majority rently mind. current methods discretization considering class variable teractions previously reasons seem appropriate interaction mary importance learning probabilistic main variables. strategies knowledge multivariate needs learning general case letters realization ters x<l) latter tation instantiations. tors bold upper case letters instantiation given sponding denote main interest complete domain x<l) full instantiations arbi­ marginal trary subsets denoted respectively ther probability pending metric discretization tinuous similar technique continuous consideration technique scoring continuous order define scoring bayesian strategy data. assume underly­ discrete observed discretization problem allows cation bayesian tion defined posterior discretization data. since proposed dependent discretization ically dependence variables discretization network. many derived properties scoring metric based principle. tion bayesian paradigm however make explicit many modeling approach could left implicit provides dis­ cretization process. remainder section work formalism data containing describe section tion. first introduce single generalize section defined pair bayesian directed acyclic nodes arcs xixj rep­ resenting variables probability sible instantiations denote parents essential markov property asserts independent property multivariate terms univariate tions variable parents pai. application markov property torization instantiation task learning work structure conditional lished nition network high-scoring metric scoring bayesian prediction average taining general tempt made high scoring classification also preferable gain insight dencies assume approach mainder basic idea bayesian imize probability network assumptions implicit. network same purpose suffices calculate term prior probability ture needs given input. term marginal likelihood also called evidence measures tures fits data. computation evaluation analytical veloped discrete normally however containing unlikely feasible used clear definition node vector rameters necessary ditional cordingly tribution tion parent pai. finally specifies given database cases observing observation given decomposition vector form \"'dirichlet gamma function aijk cxijk part dirichlet prior specification. variable number cases xi's parent takes j-th value value equation denote group terms notation likelihood terms x<n}}. previously pose discretization marginal case one-variable informally problem scoring formalized data generated involves assume density observed variable underlying variable discretization density assume follows mial distribution described parameters tion general restrict elimination possible ability zero whenever.y equation computation given number data points aging approximate application also known plug-in approximation tion yields posterior argmaxa]. selection tion policy discretization posterior tionality maximizes furthermore prior probability imum likelihood discretization lihood logp. computation straightforward. sumption dirichlet fully specify give probabilistic meaning policy notation denote discretization corresponding tion policy erated. furthermore discretization policies denotes part prior specifica­ tion notice slight change notation made explicit dependency cretization policy tics whose range partitioned computation equation conditional choice assume within interval values continuous equation termination policy. nent rewards also rewards clear looking expressed function uniform density. becomes smaller thus increasing interval. equal increasing variable general component lead overfitting discrete fact component measures discretized number values limit case one-value variable highest component always probability tion discrete component score takes maximum attainable out). terms cancel result establish model complexity allow analytical computation rel­ evant statistics. discretization applied already discrete variable subsets priately appropriate choice tional dirichlet component discrete component multinomial conditional continuous. prior resulting form distribution contains datapoints ever intervals tional distribution repeated ditional scribed continuous huffman code whose length frequency occurrence interval. frequency value repetitions within interval equal length code tribution section tive priors previously variable number categories points factorizing informative specify. example cated poisson distribution mean bution sensible penalizes large values favored term only. given uniform assumed. alternatively could defined based definition line\" discretization \"distance\" suring difference baseline. baseline discretization tion) generalize previous {xl> uni­ variate derlying havior observed continuous assume existence crete variables able governs continuous ship fully specified a-induced densities case conditioning fact complete mechanism dependencies implied fact probabilistic variables variables tion corresponds structure continuous unique parent ins' contains parent graphical troduction discrete transformation immediate continuous parents able i.e. equation probability continuous ized product variables taining terms ai)). thus ingredients scoring tion policy analogously assumption taken log-likelihood data given structure need extra term logp). metric computed {ai} pai} discretiza­ tion policies denote discrete ciated variables first then scoring cases database demultivariate terms equation score ficient policy term depend discretization well discretization variables pai. immediate dency selecting given variable structure local score children contains follows change discretization pute term sdyaj; chi. previously surprisingly rived based consequence discretization discretization network empty d-separator discrete variables continuous variables variable possibly variables problem continuous problem besides recomput­ variables need replace tiation variable holding problem. variable discretization thus modify available exact approximate inference return probable instantiation variables probable discretization instead. method outlined efficient putting space joint discretizations dent variables start initial ables. cretization single discretization peat process prove given amount inference another informative regards priors policies space discretization prior could specification useful finely grained dis­ cretization \"coarser\" solely another density specification believe accurate", "year": 2013}