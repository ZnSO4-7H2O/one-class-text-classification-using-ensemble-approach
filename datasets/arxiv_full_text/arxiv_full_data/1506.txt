{"title": "Multimodal Explanations: Justifying Decisions and Pointing to the  Evidence", "tag": ["cs.AI", "cs.CL", "cs.CV"], "abstract": "Deep models that are both effective and explainable are desirable in many settings; prior explainable models have been unimodal, offering either image-based visualization of attention weights or text-based generation of post-hoc justifications. We propose a multimodal approach to explanation, and argue that the two modalities provide complementary explanatory strengths. We collect two new datasets to define and evaluate this task, and propose a novel model which can provide joint textual rationale generation and attention visualization. Our datasets define visual and textual justifications of a classification decision for activity recognition tasks (ACT-X) and for visual question answering tasks (VQA-X). We quantitatively show that training with the textual explanations not only yields better textual justification models, but also better localizes the evidence that supports the decision. We also qualitatively show cases where visual explanation is more insightful than textual explanation, and vice versa, supporting our thesis that multimodal explanation models offer significant benefits over unimodal approaches.", "text": "figure given question image pointing justiﬁcation explanation model predicts answer multimodal explanations point visual evidence decision provide textual justiﬁcations. show considering multimodal explanations results better visual textual explanations. generated explanations compare methods understand methods generalize important access ground truth human explanations. unfortunately dearth datasets include examples humans justify speciﬁc decisions. thus collect datasets act-x vqa-x allow train evaluate novel model call pointing justiﬁcation explanation model. pj-x explicitly multimodal incorporates explanatory attention step allows model visually point evidence justify model decision text. illustrate utility multimodal explanations consider figure examples question healthy meal? asked pj-x model correctly answers either depending visual input. justify image healthy generated textual justiﬁcation mentions kinds unhealthy food image addition mentioning unhealthy food model able point image. likewise justify image right healthy textual explanation model mentions vegetables. note pj-x model points vegetables mentioned textual explanation deep models effective explainable desirable many settings; prior explainable models unimodal offering either image-based visualization attention weights text-based generation post-hoc justiﬁcations. propose multimodal approach explanation argue modalities provide complementary explanatory strengths. collect datasets deﬁne evaluate task propose novel model provide joint textual rationale generation attention visualization. datasets deﬁne visual textual justiﬁcations classiﬁcation decision activity recognition tasks visual question answering tasks quantitatively show training textual explanations yields better textual justiﬁcation models also better localizes evidence supports decision. also qualitatively show cases visual explanation insightful textual explanation vice versa supporting thesis multimodal explanation models offer signiﬁcant beneﬁts unimodal approaches. explaining decisions integral part human communication understanding learning humans naturally provide deictic textual modalities typical explanation. build deep learning models also able explain decisions similar ﬂuency visual textual modalities. previous machine learning methods explanation able provide text-only explanation conditioned image context task able visualize active intermediate units deep network performing task unable provide explanatory text grounded image. propose model jointly generate visual textual explanations using attention mask localize salient regions generating textual rationales. argue train effective models measure quality propose activity recognition testbeds studying explanations challenging important visual tasks interesting properties explanation. widely studied multimodal task requires visual textual understanding well commonsense knowledge. newly collected dataset includes complementary pairs questions answers. complementary pairs question semantically similar images different answers. images semantically similar models must employ ﬁnegrained reasoning answer question correctly. interesting useful setting measuring overall performance also interesting studying explanations. comparing explanations complementary pairs easily determine whether explanations focus important factors making decision. additionally collect annotations activity recognition using mpii human pose dataset activity recognition still images relies variety cues pose global context interaction humans objects. though recognition model potentially classify activity correctly capable indicating factors inﬂuence decision process. furthermore classifying speciﬁc activities requires understanding ﬁnegrained differences ﬁnegrained differences interesting difﬁcult capture explaining neural network decisions. present act-x vqa-x novel datasets human annotated multimodal explanations activity recognition visual question answering. datasets allow train pointing justiﬁcation model goes beyond current visual explanation systems producing multimodal explanations justifying predicted answer post-hoc visual pointing textual justiﬁcation. datasets also allow effectively evaluate explanation models show pj-x model outperforms strong baselines importantly generating multimodal explanations outperform models produce visual textual explanations. release model architecture learned weights datasets upon acceptance paper. explanations. early textual explanation models span variety applications feedback teaching programs generally template based. recently developed deep network figure comparison descriptions vqa-x explanations focus evidence pertains question answer instead generally describing scene. act-x explanations task speciﬁc whereas descriptions generic. generate natural language justiﬁcations ﬁne-grained object classiﬁer. however unlike model provide multimodal explanations. furthermore could train reference human explanations datasets existed. provide datasets reference textual explanations enable research direction textual explanation generation. variety work proposed methods visually explain decisions. methods discriminative visual patches whereas others understand intermediate features important decisions e.g. certain neuron represent. model pj-x points visual evidence attention mechanism intuitive convey knowledge important network without requiring domain knowledge. unlike prior work pj-x generates multimodal explanations form explanatory sentences attention maps pointing visual evidence. prior work investigated well generated visual explanations align human gaze however answering question humans always look image regions necessary explain decision. example given question what name restaurant? human gaze might capture buildings settling restaurant. contrast collect annotations allow annotators view entire image point relevant visual evidence making decision. furthermore visual explanations collected conjunction textual explanations build evaluate multimodal explanation models. visual question answering attention. initial approaches used full-frame representations recent approaches form spatial attentable dataset statistics vqa-x act-x unique unique questions unique unique answers expl. explanations avg. average number words comple. pairs complementary pairs visual ann. visual annotations. tion base method winner challenge however element-wise product opposed compact bilinear pooling. explored element-wise product method however improves performance applying hyperbolic tangent multimodal pooling whereas improve applying signed square-root normalization. activity recognition. recent work activity recognition still images relies variety cues pose global context speciﬁcally considers additional image regions considers global image feature addition region activity occurs. generally works mpii human activities dataset provide ground truth location human test time contrast consider realistic scenario make assumptions activity occurs test time. model relies attention focus important parts image classiﬁcation explanation. propose multimodal explanation tasks visual textual components deﬁned visual question answering activity recognition testbeds. train evaluate models task collect multimodal explanation datasets visual question answering explanation activity explanation dataset collect textual visual explanations human annotators. explanation dataset visual question answering dataset contains open-ended questions images require understanding vision language commonsense knowledge answer. consists approximately mscoco images questions image answers question. fundamental visual property color. thus provide textual explanations questions beyond trivial cases. this consider annotations collected human must answer question. questions require humans higher generally interesting explain. additionally consider complementary pairs dataset complementary pairs consist question similar images give different answers. complementary pairs particularly interesting explanation task allow understand whether explanations name correct evidence based image content whether memorize content consider based speciﬁc question types. action explanation dataset mpii human pose dataset contains images extracted youtube videos. dataset select images pertain activities resulting images total. image collect three explanations. data annotation annotators complete sentence tell person because.. action ground truth activity label. also least words avoid mentioning activity class sentence. dataset also comes sentence descriptions provided figure examples descriptions explanations. ground truth pointing. addition textual justiﬁcations collect visual explanations humans vqa-x act-x datasets order evaluate well attention model corresponds humans think evidence answer human-annotated visual explanations collected amazon mechanical turk segmentation interface opensurfaces project annotators provided image answer allow training tasks. speciﬁcally want rely natural language justiﬁcations classiﬁcation labels supervision. design model learn point latent way. pointing rely attention mechanism allows model focus spatial subset visual representation. ﬁrst predict answer given image question using answering model. given answer question image generate visual textual explanations multimodal explanation model. overview model presented figure answering model. visual question answering goal predict answer given question image. activity recognition explicit question. thus ignore question equivalent setting question representation vector ones. base answering model overall architecture model replace unit simpler element-wise multiplication pool multimodal features. found leads similar performance much faster training detail extract spatial image features last convolutional layer resnet- followed convolutions giving spatial image feature. encode question -layer figure human visual annotations vqa-hat vqa-x. aggregate annotations image normalize create probability distribution. distribution visualized image heatmap. class label act-x). asked segment objects and/or regions prominently justify answer. dataset randomly sample images test split image collect annotations. examples seen figure comparing vqa-hat. thorough comparison between dataset vqa-hat dataset currently viable datasets different splits overlap small. however present qualitative comparison figure ﬁrst vqa-x annotation ﬁner granularity since segments objects interest accurately vqa-hat annotation. second annotation contains less extraneous information vqa-hat annotation. since relu max. next predict attention ¯αnm apply softmax produce normalized soft attention visual pointing αpointx aims point evidence generated explanation refer combine spatial image feature using element-wise multiplication followed signed square-root normalization dropout layers convolutions relu between. process gives attention ¯αnm. apply softmax produce normalized soft attention map. attention used take weighted image features representation combined lstm feature predict answer classiﬁcation problem answers provide extended formalized version supplemental. multimodal explanation model. argue generate multimodal explanation condition question answer image. instance able explain because vancouver police figure model needs question i.e. people arrest someone? answer i.e. image i.e. vancouver police banner motorcycles. model pooling image question answer representations generate attention visual pointing. visual pointing used create attention features guide generation textual justiﬁcation. speciﬁcally answer predictions embedded d-dimensional space followed tanh nonlinearity fully connected layer yembed allow model learn attend relevant spatial location based answer image question combine answer feature question-image embedding answering model. applying convolutions element-wise multiplication followed signed square-root normalsection detailing experimental setup present quantitative results ablations done textual justiﬁcation visual pointing tasks discuss implications. additionally provide analyze qualitative results tasks. model training hyperparameters. answering model pj-x pre-trained training freeze ﬁnetune weights answering model training multimodal explanation model textual annotations vqa-x dataset signiﬁcantly smaller original training set. activity recognition answering explanation components pj-x trained jointly. spatial feature size pj-x limit answer space frequently occurring answers training whereas activity recognition answer embedding size tasks. evaluation metrics. evaluate textual justiﬁcations w.r.t bleu- meteor rouge cider spice metrics measure degree similarity generated ground truth sentences. also include human evaluation since automatic metrics always reﬂect human preference. randomly choose data points test splits vqa-x act-x datasets model predicts correct answer data point human subjects judge whether generated explanation better than worse than equivalent ground truth explanation report percentage generated explanations equivalent better ground truth human explanations least human judges agree. visual pointing task earth mover’s distance measures distance probability distributions region. code compute emd. also report rank correlation used computing rank correlation follow scale generated attention human ground-truth annotations vqa-x/act-x/vqa-hat datasets rank pixel values compute correlation ranked lists. ablate pj-x compare related approaches vqa-x act-x datasets automatic human evaluations generated explanations. details compared models. compare stateof-the-art using publicly available code. fair comparison resnet features extracted entire image training generated sentences conditioned image class label. uses discriminative loss enforces generated sentence contain class-speciﬁc information backpropagate policy gradients training language generator thus involves training separate sentence classiﬁer generate rewards. model discriminative loss/policy gradients require deﬁning reward. note trained descriptions. similarly ours descriptions ablation train pj-x descriptions instead explanations. ours attention similar sense attention mechanism involved generating explanations however discriminative loss trained explanations instead descriptions. descriptions explanations. ours signiﬁcantly outperforms ours descriptions large margin datasets expected descriptions insufﬁcient task generating explanations. additionally ours compares favorably even case ours generates textual justiﬁcations conditioned prediction ground-truth answer. results demonstrate limitation training explanation systems descriptions thus support necessity having datasets speciﬁcally curated explanations. ours descriptions performs worse certain metrics compared attributed additional training signals generated discriminative loss policy gradients investigation left future work. unimodal explanations multimodal explanations. including attention generating textual justiﬁcations allows build multimodal explanation model. aside immediate beneﬁt providing visual rationale model’s decision learning point visual evidence helps generating better textual justiﬁcations. seen table ours greatly improves textual justiﬁcations compared ours attention datasets demonstrating value designing multimodal explanation systems. table evaluation textual justiﬁcations. evaluated automatic metrics bleu- meteor rouge cider spice reference sentence human automatic evaluation always explanation. proposed model compares favorably baselines. details compared models. compare model following baselines. random point randomly attends single point grid. uniform generates attention uniformly distributed grid. addition baselines also compare pj-x attention maps generated stateof-the-art systems improved localization textual explanations. evaluate attention maps using earth mover’s distance rank correlation vqa-x act-x datasets table table observe ours outperforms baselines random point uniform also answering model datasets metrics. attention maps generated answering model receive training signals textual annotations trained predict correct answer whereas attention maps generated pj-x multimodal explanation model latently learned supervision textual annotations. experiment results imply learning generate textual explanations helps improve visual figure vqa-x qualitative results image pj-x model provides answer justiﬁcation points evidence justiﬁcation. show pairs images complementary pairs. figure qualitative results comparing insightfulness visual pointing textual justiﬁcation. left example demonstrates visual pointing informative textual justiﬁcation whereas right example shows opposite. e.g. grassy lawn mountainous area person-object interaction e.g. pushing lawn mower riding bicycle mowing lawn mountain biking respectively. explanations require determining many multiple cues appropriate justify particular action. model points visual evidence important understanding human activity. example classify mowing lawn figure model focuses person grass well lawn mower. model also differentiate similar activities based context e.g.mountain biking road biking. explanation consistent incorrect prediction. generating reasonable explnations correct answers important also crucial system behaves face incorrect predictions. analysis would provide insights whether explanation generation component model consistent answer prediction component not. figure explanations consistent incorrectly predicted answer vqa-x act-x. instance bottom-right example model attends vacuum-like object textually justiﬁes prediction vacuuming. consistency answering model explanation model also shown table drop performance explanations conditioned predictions instead ground-truth answers section address advantages generating multimodal explanations. particular look cases visual explanations informative textual explanations vice versa. also investigate multimodal explanations help humans diagsection present qualitative results vqax act-x datasets demonstrating model generates high quality sentences attention maps point relevant locations image. vqa-x. figure shows qualitative results vqa-x dataset. show pairs images form complementary pairs textual justiﬁcations able capture common sense discuss speciﬁc image parts important answering question. example asked zoo? explanation model able discuss concept represents i.e. animals enclosure. determining whether water calm requires discussing speciﬁc image regions textual justiﬁcation discusses foam waves. visually notice attention model able point important visual evidence. example figure question zoo? visual explanation focuses ﬁeld case fence another. act-x. figure shows results act-x dataset. textual explanations discuss variety visual cues important correctly classifying activities global context ﬁrst capable providing natural language justiﬁcations decisions well pointing evidence image. collected novel explanation datasets crowd sourcing visual question answering activity recognition i.e. vqa-x act-x. quantitatively demonstrated learning point helps achieve high quality textual explanations. also quantitatively show using reference textual explanations train model helps achieve better visual pointing. furthermore qualitatively demonstrated model able point evidence well give natural sentence justiﬁcations similar ones humans give. nose performance system. complementary explanations. multimodal explanations support different tasks support other. interestingly figure present examples visual pointing insightful textual justiﬁcation vice versa. looking left example figure rather difﬁcult explain leaning language model resorts generating correct uninsightful sentence. however concept easily conveyed looking visual pointing result. contrast right example shows opposite. looking patches presented visual pointing result necessarily conﬁrm scene cloudy also unclear attending entire region desired behavior. textual justiﬁcation succinctly captures rationale. examples clearly demonstrate value generating multimodal explanations. diagnostic explanations. evaluate auxiliary task humans guess whether system correctly incorrectly answered question. predicted answer shown; image question correct answer textual/visual explanations. contains correctly answered questions. compare model models used ablations table table indicates explanations better explanations model helpful models trained descriptions also models trained generate textual explanations only.", "year": 2018}