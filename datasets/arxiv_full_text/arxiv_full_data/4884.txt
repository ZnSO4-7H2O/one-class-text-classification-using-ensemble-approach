{"title": "Bank Card Usage Prediction Exploiting Geolocation Information", "tag": ["cs.LG", "cs.AI"], "abstract": "We describe the solution of team ISMLL for the ECML-PKDD 2016 Discovery Challenge on Bank Card Usage for both tasks. Our solution is based on three pillars. Gradient boosted decision trees as a strong regression and classification model, an intensive search for good hyperparameter configurations and strong features that exploit geolocation information. This approach achieved the best performance on the public leaderboard for the first task and a decent fourth position for the second task.", "text": "abstract. describe solution team ismll ecmlpkdd discovery challenge bank card usage tasks. solution based three pillars. gradient boosted decision trees strong regression classiﬁcation model intensive search good hyperparameter conﬁgurations strong features exploit geolocation information. approach achieved best performance public leaderboard ﬁrst task decent fourth position second task. goal year’s ecml-pkdd discovery challenges predict behaviour customers hungarian bank otpbank. challenge divided tasks. ﬁrst task predict every bank branch number visits customers second task predict whether customer apply credit card next months. tasks anonymized customer information bank activities provided. labeled data made available used supervised machine learning predict targets disjoint customers evaluation measure task area curve common measure imbalanced classiﬁcation problems. evaluation measure task little exotic. average cosine cosine every customer ﬁrst task assumed relation number visits customer among branches. enabled tackle diﬀerent regression tasks branches. independently trained regression model branch predicts customer often visit branch based past information branch. classical example count data hence tackled task poisson regression problem. task select bank branches wanted make predictions. simply chose highest predicted number visits best achieve good score case predictor performs reasonable. considered task classiﬁcation task. minimized logistic loss considered class imbalance choosing appropriate class weight. tasks used gradient boosted decision trees prediction feature hyperparameter selection split labeled data training data dtrain validation data dvalid performance dvalid reﬂect performance hidden test data. task infer customers activities behaviour disjoint customers basic customer information well customer’s activities ﬁrst half given test customers. thus decided split given labeled data customers selecting dtrain remaining dvalid uniformly random. ﬁrst months activities validation customers provided validation purposes. problem actually predicting data customers overcome problem. basic information customers available including location income gender. gender nature binary features already binned three categories. employed information features transforming one-hot encoding. furthermore internal classiﬁcation bank whether customer considered wealthy given month. distinguished customers following categories customers classiﬁed wealthy observed months wealthy observed months ﬁrst wealthy changed wealthy ﬁrst wealthy changed wealthy changed classiﬁcation once. applying one-hot encoding added information features. finally information month customer possesses credit card bank provided. analogously categories wealthy classiﬁcation created categories credit card time-series information. besides using basic customer features wanted information customer’s activities. found many features improved performance task internal data split many features improvement public leaderboard. thus feature used number activities channel committed customer. figure shows predictive features. task considered location information activities bank branches customers irrelevant used aforementioned features. however task information impactful information. feature used distance residence customer bank branch quite obvious choice. digging data many customers using bank branches away residence. tried cover also adding maximum minimum mean median distance bank branch customer’s activities. finally added k-nearest-neighbors predictions using euclidean distance residence customers distance function. features follow simple assumption customers live nearby visit bank branches. figure provides insight intermediate feature selection experiments task clearly shows importance location-aware features. based experiment used features credit card information task figure shows relative frequency speciﬁc feature taken splitting variable. again shows importance location-aware features task fig. plot visualizes relative relevance features used task higher score often feature used building tree. location-aware features prove highly predictive. model trained training partition data dtrain using hyperparameter conﬁguration corresponding predictions validation partition dvalid. then problem hyperparameter tuning hyperparameter conﬁguration loss function given predictions groundtruth minimized. tackled black-box optimization problem using sequential modelbased optimization figure presents progress optimization process conducted parallel cores train/validation split well results public leaderboard task task tried diverse ways ensembling using diﬀerent base models achieve improvement. averaged predictions models best hyperparameter conﬁguration using diﬀerent seeds. fig. searching good hyperparameter conﬁguration cores parallel. public leaderboard score shown best hyperparameter conﬁgurations validation set. best single models task achieved cosine score cosine score leading overall score validation split. performance test much smaller. possible reason might temporal eﬀects predictions test customers learn data solution based strong ensemble methods smart feature engineering intense search optimal hyperparameter conﬁgurations. task paid leading best solution regarding public leaderboard well decent result task", "year": 2016}