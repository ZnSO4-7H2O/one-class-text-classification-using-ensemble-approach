{"title": "Active Learning for Speech Recognition: the Power of Gradients", "tag": ["cs.CL", "cs.LG", "stat.ML"], "abstract": "In training speech recognition systems, labeling audio clips can be expensive, and not all data is equally valuable. Active learning aims to label only the most informative samples to reduce cost. For speech recognition, confidence scores and other likelihood-based active learning methods have been shown to be effective. Gradient-based active learning methods, however, are still not well-understood. This work investigates the Expected Gradient Length (EGL) approach in active learning for end-to-end speech recognition. We justify EGL from a variance reduction perspective, and observe that EGL's measure of informativeness picks novel samples uncorrelated with confidence scores. Experimentally, we show that EGL can reduce word errors by 11\\%, or alternatively, reduce the number of samples to label by 50\\%, when compared to random sampling.", "text": "training speech recognition systems labeling audio clips expensive data equally valuable. active learning aims label informative samples reduce cost. speech recognition conﬁdence scores likelihood-based active learning methods shown effective. gradient-based active learning methods however still well-understood. work investigates expected gradient length approach active learning end-to-end speech recognition. justify variance reduction perspective observe egl’s measure informativeness picks novel samples uncorrelated conﬁdence scores. experimentally show reduce word errors alternatively reduce number samples label compared random sampling. state-of-the-art automatic speech recognition systems large model capacities require signiﬁcant quantities training data generalize. labeling thousands hours audio however expensive time-consuming. natural question achieve better generalization fewer training examples. active learning studies problem identifying labeling informative data potentially reducing sample complexity. much active learning help large-scale end-to-end systems however still open question. speech recognition community generally identiﬁed informativeness samples calculating conﬁdence scores. particular utterance considered informative likely prediction small probability predictions distributed uniformly labels though conﬁdence-based measures work well practice less attention focused gradient-based methods like expected gradient length informativeness measured norm gradient incurred instance. previously justiﬁed intuitively measuring expected change model’s parameters formalize intuition perspective asymptotic variance reduction experimentally show superior conﬁdence-based methods speech recognition tasks. additionally observe ranking samples scored correlated conﬁdence scoring suggesting identiﬁes aspects instance conﬁdence scores cannot capture. applied active learning sequence labeling tasks work ﬁrst know apply speech recognition particular. gradient-based methods also found applications outside active learning. example suggests stochastic gradient descent sampling training instances probabilities proportional gradient lengths speed convergence. perspective variance reduction importance sampling problem shares many similarities problems found active learning. denote utterance corresponding label speech recognition system models conditional distribution parameters model typically implemented recurrent neural network training collection pairs denoted parameters model estimated minimizing negative log-likelihood training conﬁdence scoring used extensively proxy informativeness training samples. speciﬁcally considered informative predictions uniformly distributed labels best prediction label probability taking instances confuse model methods effectively explore under-sampled regions input space. intuitively instance considered informative results large changes model parameters. natural measure change gradient length motivated intuition expected gradient length picks instances expected largest gradient length. since labels unknown computes expectation gradient norm possible labelings. interprets expected model change. following section formalize intuition show follows naturally reducing variance estimator. indicates reduce test data need minimize expected variance test set. called fisher information ratio criteria hard optimize. easier surrogate maximize tr). substituting practical issue know advance. could instead substitute estimate pre-trained model reasonable assume close true batch selection works taking samples largest gradient norms rnns gradients potential label obtained back-propagation. another practical issue marginalizes possible labelings speech recognition number labelings scales exponentially number timesteps. therefore marginalize probable labelings. obtained beam search decoding method almost except gradient’s norm squared provided formal characterization complement intuitive interpretation expected model change notational convenience denote subsequent sections. empirically validate speech recognition tasks. experiments takes spectrograms utterances passing d-convolutional layers followed seven bi-directional recurrent layers fully-connected layer softmax activation. recurrent layers batch normalized. timestep softmax activations give probability distribution characters. loss computed timestep-wise probabilities. base model trained hours transcribed speech data. then selects subset -hour unlabeled dataset. query labels selected subset incorporate training. learning rates tuned small validation instances. trained model tested -hour test report loss character error rate word error rate conﬁdence score methods easily extended setup. speciﬁcally probabilities characters compute entropy timestep average them. method denoted entropy. could also take likely prediction calculate loss normalized number timesteps. method denoted pctc following sections. figure performance metrics various percentages queries. shows greater reduction error smaller amounts data. deﬁnition strategies converge query percentage approaches implement marginalizing likely labels compare with random selection baseline entropy pctc. using base model method queries variable percentage unlabeled dataset. queries included training model continues training convergence. fig. reports metrics test query percentage varies. active learning methods outperform random baseline. moreover shows steeper rapid reduction error approaches. speciﬁcally querying unlabeled dataset lower lower relative random. performance querying random suggesting using lead approximate decrease data labeling. useful understand three active learning methods differ measuring informativeness instance. compare methods take rankings informativeness given methods plot ranking-vs-ranking coordinate system. plot close diagonal implies methods evaluate informativeness similar way. fig. shows ranking-vs-ranking plots pctc entropy entropy. observe pctc rankings entropy rankings correlated. likely related model uncertainty. contrast gives different rankings entropy suggests able identify aspects instance uncertainty-based measurements cannot capture. figure difference active learning methods rank informativeness samples. rankings normalized informative. pctc entropy shown correlated. appears uncorrelated entropy data samples highlighted circle considered informative uninformative entropy. investigate samples entropy yield vastly different estimates informativeness e.g. elements circle fig. particular samples consist short utterances containing silence ﬁller words. investigation required understand whether samples noisy outliers whether fact important training end-to-end speech recognition systems. formally explained variance reduction perspective experimentally tested performance end-to-end speech recognition systems. initial experiments show notable gain random selection outperforms conﬁdence score methods used community. also show measures sample informativeness different conﬁdence scores giving rise open research questions. experiments reported query samples single batch. also worth considering effects querying samples sequential manner. future validate approach sequential queries seek make informativeness measure robust outliers. references amodei ananthanarayanan anubhai deep speech end-to-end speech recognition english mandarin. international conference machine learning graves fernandez gomez schmidhuber. connectionist temporal classiﬁcation labelling unsegmented sequence data recurrent neural networks. proceedings international conference machine learning settles craven. analysis active learning strategies sequence labeling tasks. proceedings conference empirical methods natural language processing. association computational linguistics varadarajan deng acero. maximizing global entropy reduction active learning speech recognition. international conference acoustics speech signal processing", "year": 2016}