{"title": "Learning to Pivot with Adversarial Networks", "tag": ["stat.ML", "cs.LG", "cs.NE", "physics.data-an", "stat.ME"], "abstract": "Several techniques for domain adaptation have been proposed to account for differences in the distribution of the data used for training and testing. The majority of this work focuses on a binary domain label. Similar problems occur in a scientific context where there may be a continuous family of plausible data generation processes associated to the presence of systematic uncertainties. Robust inference is possible if it is based on a pivot -- a quantity whose distribution does not depend on the unknown values of the nuisance parameters that parametrize this family of data generation processes. In this work, we introduce and derive theoretical results for a training procedure based on adversarial networks for enforcing the pivotal property (or, equivalently, fairness with respect to continuous attributes) on a predictive model. The method includes a hyperparameter to control the trade-off between accuracy and robustness. We demonstrate the effectiveness of this approach with a toy example and examples from particle physics.", "text": "several techniques domain adaptation proposed account differences distribution data used training testing. majority work focuses binary domain label. similar problems occur scientiﬁc context continuous family plausible data generation processes associated presence systematic uncertainties. robust inference possible based pivot quantity whose distribution depend unknown values nuisance parameters parametrize family data generation processes. work introduce derive theoretical results training procedure based adversarial networks enforcing pivotal property predictive model. method includes hyperparameter control tradeaccuracy robustness. demonstrate effectiveness approach example examples particle physics. machine learning techniques used enhance number scientiﬁc disciplines potential transform even scientiﬁc process. challenges applying machine learning scientiﬁc problems need incorporate systematic uncertainties affect robustness inference metrics used evaluate particular analysis strategy. work focus supervised learning techniques systematic uncertainties associated data generation process uniquely speciﬁed. words lack systematic uncertainties corresponds case process generates training data unique fully speciﬁed accurate representative real world data. contrast common situation systematic uncertainty present training data representative real data. several techniques domain adaptation developed create models robust binary type uncertainty. generic situation several plausible data generation processes speciﬁed family parametrized continuous nuisance parameters typically found scientiﬁc domains. broader context statisticians long working robust inference techniques based concept pivot quantity whose distribution invariant nuisance parameters assuming probability model data target labels nuisance parameters consider problem learning predictive model conditional observed values robust uncertainty unknown value introduce ﬂexible learning procedure based adversarial networks enforcing pivot respect derive theoretical results proving procedure converges towards model optimal statistically independent nuisance parameters tune trade-off accuracy robustness particular best knowledge contribution ﬁrst solution imposing pivotal constraints predictive model working regardless figure architecture adversarial training binary classiﬁer nuisance parameters adversary models distribution nuisance parameters observed output classiﬁer. maximizing antagonistic objective classiﬁer forces towards prior happens independent nuisance parameter therefore pivotal. problem statement begin family data generation processes data target labels nuisance parameters continuous categorical. assume prior incorporating effect uncertainty goal learn regression function parameters minimizes loss classiﬁcation values r|y| correspond classiﬁer scores used mapping hard predictions regression. augment initial objective inference based robust value nuisance parameter remains unknown test time. formal enforcing robustness require distribution conditional invariant nuisance parameter thus wish function values words looking predictive function pivotal quantity respect nuisance parameters. implies independent random variables. stated eqn. pivotal quantity criterion imposed respect marginalized out. situations however class conditional independence nuisance preferred stated requiring joint training adversarial networks ﬁrst proposed build generative model capable producing samples random noise speciﬁcally authors generative model adversarial classiﬁer whose antagonistic objective recognize real data generated data models trained simultaneously learns produce samples difﬁcult identify incrementally adapts changes equilibrium models distribution whose samples identiﬁed chance. assuming enough capacity distribution eventually converges towards real distribution work repurpose adversarial networks means constrain predictive model order satisfy eqn. illustrated fig. adversarial model parameters associated loss model takes input realizations produces output function modeling posterior probability density intuitively s|z) varies corresponding correlation captured contrast s|z) invariant require perform poorly close random guessing. training additionally minimizes performance therefore acts regularization towards eqn. takes discrete values represented probabilistic classiﬁer r|z| whose output estimated probability mass similarly takes continuous values model posterior probability density sufﬁciently ﬂexible parametric family distributions parameters depend adversary take form i.e. need neural network long exposes differentiable function sufﬁcient capacity represent true distribution. fig. illustrates concrete example mixture gaussians modeled mixture density network output corresponds estimated value corresponding parameter distribution estimated probability density evaluated score generative adversarial networks propose train simultaneously carry considering value function without loss generality adversarial training procedure obtain formally presented algorithm case binary classiﬁer modeling reasons explained sec. respectively expected value negative log-likelihood optimization algorithm consists using stochastic gradient descent alternatively solving eqn. finally case class conditional pivot settings same except adversarial term restricted theoretical results section show setting algorithm respectively expected value negative log-likelihood minimax solution eqn. corresponds classiﬁer pivotal quantity. setting nuisance parameter considered random variable prior goal function independent random variables. importantly classiﬁcation respect considered context marginalized means classiﬁer minimizing optimal respect necessarily results hold nuisance parameters taking either categorical continuous values. abuse notation denotes differential entropy latter case. finally proposition derived non-parametric setting assuming enough capacity. proposition exists minimax solution eqn. optimal classiﬁer pivotal quantity. reduces case pˆˆθr expected entropy es∼f conditional distribution nuisance parameters. expectation corresponds conditional entropy random variables written accordingly value function restated function depending only minimizes negative log-likelihood happens parameters optimal classiﬁer. case reduces minimum value maximizes conditional entropy since properties entropy. note latter inequality holds discrete differential deﬁnitions entropy. proposition suggests step algorithm adversary allowed reach optimum given updated improve sufﬁciently small steps converge classiﬁer optimal pivotal provided classiﬁer exists. therefore adversarial term regarded select among class optimal classiﬁers function also pivotal. despite former theoretical characterization minimax solution eqn. note formal guarantees convergence towards solution algorithm case ﬁnite number steps taken remains proven. practice assumption existence optimal pivotal classiﬁer hold nuisance parameter directly shapes decision boundary. case lower bound figure example. conditional probability densities decision scores without adversarial training. resulting densities dependent continuous parameter indicating pivotal. associated decision surface highlighting fact samples easier classify values hence explaining dependency. conditional probability densities decision scores built adversarial training. resulting densities almost identical other indicating small dependency associated decision surface illustrating adversarial training bends decision function vertically erase dependency hyper-parameter controlling trade-off performance independence respect nuisance parameter. setting large value preferably enforces pivotal setting close rather constraint optimal. lower bound strict note however exist distinct equally good solutions minimizing eqn. zero-sum game increase accuracy would exactly compensated decrease pivotality vice-versa. best navigate pareto frontier maximize higher-level objective remains question open future works. interestingly ﬁnally emphasize results hold using output input adversary. could similarly enforce intermediate representation data pivotal e.g. necessary. section empirically demonstrate effectiveness approach example examples particle physics. notably approaches compare case continuous nuisance parameters explained sec. case binary parameters expect results much different previous works. continuous nuisance parameter represents uncertainty location mean second gaussian. goal build classiﬁer predicting given probability distribution invariant respect nuisance parameter assuming gaussian prior generate data zi}n train neural network minimizing without considering adversary network architecture comprises dense hidden layers nodes respectively tanh relu activations followed dense output layer single node sigmoid activation. shown fig. resulting classiﬁer pivotal conditional probability densities decision scores show large discrepancies values nuisance parameters. shown here classiﬁer trained data generated nominal value would also pivotal. figure physics example. approximate median signiﬁcance function decision threshold output trading accuracy independence pileup results beneﬁt terms statistical signiﬁcance. consider joint training adversary implemented mixture density network modeling mixture gaussians. network architecture comprises dense hidden layers nodes relu activations followed output layer nodes corresponding means standard deviations mixture coefﬁcients gaussians. output nodes mean values come linear activations output nodes standard deviations exponential activations ensure positivity output nodes mixture coefﬁcients implement softmax function ensure positivity normalization. running algorithm initialized classiﬁer obtained previously adversarial training effectively reshapes decision function becomes almost independent nuisance parameter shown fig. conditional probability densities decision scores similar other indicating residual dependency nuisance theoretically expected. dynamics adversarial training illustrated fig. losses evaluated iteration. ﬁrst iterations observe global objective minimized making classiﬁer less accurate hence corresponding increase results classiﬁer pivotal hence associated increase total beneﬁt. learning goes minimizing requires making predictions accurate hence decreasing even less dependent hence shaping towards prior indeed eventually starts decreasing remaining bounded minθf approximated dashed line ﬁrst plot. similarly tends towards differential entropy prior case standard normal) shown dashed line second plot. finally note ideal situation classiﬁer optimal pivotal unreachable problem shown third plot offset dashed line approximating binary case experiments high energy colliders like searching evidence particles beyond described standard model particle physics. wide array theories predict existence massive particles would decay known particles boson. boson unstable decay quarks produce collimated sprays particles known jets. exotic particle heavy boson moving fast relativistic effects cause jets decay merge single -jet’. -jets rich internal substructure. however jets also produced ubiquitously high energy colliders mundane processes leads challenging classiﬁcation problem beset number sources systematic uncertainty. classiﬁcation challenge used common substructure studies distinguish normal jets produced copiously -jets potentially coming exotic process. reuse datasets used challenging right classiﬁcation problem made difﬁcult presence pileup multiple proton-proton interactions occurring simultaneously primary interaction. pileup interactions produce additional particles contribute signiﬁcant energies jets unrelated underlying discriminating information. number pileup interactions vary running conditions collider want classiﬁer robust conditions. taking liberty consider extreme case categorical nuisance parameter corresponds events without pileup corresponds events pileup average independent pileup interactions overlaid. expect able function simultaneously minimizes classiﬁcation loss pivotal. thus need optimize hyper-parameter eqn. respect higher-level objective. case natural higher-level context hypothesis test null hypothesis events alternate hypothesis mixture events. absence systematic uncertainties optimizing simultaneously optimizes power classical hypothesis test neyman-pearson sense. include systematic uncertainties need balance classiﬁcation performance robustness uncertainty since still performing hypothesis test null wish impose pivotal property events. higher level objective approximate median signiﬁcance natural generalization power hypothesis test systematic uncertainties taken account several values train classiﬁer using algorithm consider adversarial term conditioned only outlined sec. architecture comprises hidden layers nodes respectively tanh relu relu activations terminated single ﬁnal output node sigmoid activation. architecture same uses relu activations hidden nodes. previous example adversarial training initialized pre-trained. experiments performed subset samples training evaluated independent test samples. training testing samples weighted null hypothesis corresponded events alternate hypothesis included additional events prior thresholding allows probe efﬁcacy method proposed representative background-dominated high energy physics environment. results reported averages runs. fig. illustrates without adversarial training peaks contrast pivotal constraint made stronger peak moves higher maximum value around trading classiﬁcation accuracy robustness pileup thereby results beneﬁt terms power hypothesis test. setting high however results decrease maximum focusing capacity strongly independence expense accuracy. effect optimizing yields principled effective approach control trade-off accuracy robustness ultimately maximizes power enveloping hypothesis test. continous case recently independent group used approach learn classiﬁers independent mass continuous attribute. results studies show adversarial training strategy works well real-world problems continuous attributes thus enhancing sensitivity searches physics lhc. learning pivot related problem domain adaptation goal often stated trying learn domain-invariant representation data. likewise method also relates problem enforcing fairness classiﬁcation stated learning classiﬁer independent chosen attribute gender color age. families methods problem equivalently stated learning classiﬁer pivotal quantity respect either domain selected feature. example unsupervised domain adaptation labeled data source domain unlabeled data target domain recast learning predictive model also pivot respect domain context certainly among closest work domain invariance fairness enforced adversarial minimax setup composed classiﬁer adversarial discriminator. following line work method regarded uniﬁed generalization also supports continuously parametrized family domains enforcing fairness continuous attributes. related work based strong limiting assumption binary random variable particular based minimization form divergence distributions reason works cannot directly generalized non-binary continuous nuisance parameters practical theoretical point view. notably kamishima enforces fairness prejudice regularization term based empirical estimates p|z). approach principle sufﬁcient handling non-binary nuisance parameters requires accurate empirical estimates values quickly becomes impractical cardinality increases. contrast approach models conditional dependence adversarial network allows generalization without necessarily requiring growing number training examples. common approach account systematic uncertainties scientiﬁc context take ﬁxed classiﬁer built training data nominal value nuisance parameter propagate uncertainty estimating p|z) parametrized calibration procedure. clearly classiﬁer however optimal overcome issue classiﬁer sometimes built instead mixture training data generated several plausible values nuisance parameter. certainly improves classiﬁcation performance respect marginal model reason expect resulting classiﬁer pivotal shown previously sec. alternative parametrized classiﬁers directly take parameters additional input variables hence ultimately providing statistically powerful approach incorporating effect systematics underlying classiﬁcation task. practice parametrized classiﬁers also computationally expensive build evaluate. particular calibrating decision function i.e. approximating continuous function remains open challenge. contrast constraining pivotal yields classiﬁer directly used wider range applications since dependence nuisance parameter already eliminated. work proposed ﬂexible learning procedure building predictive model independent continuous categorical nuisance parameters jointly training neural networks adversarial fashion. theoretical perspective motivated proposed algorithm showing minimax value value function corresponds predictive model optimal pivotal tune trade-off power robustness. empirical point view conﬁrmed effectiveness method example particle physics example. terms applications solution used situation training data representative real data predictive model applied practice. scientiﬁc context presence systematic uncertainty incorporated considering family data generation processes would worth revisiting scientiﬁc problems utilize machine learning light technique. moreover approach also extends cases independence predictive model respect observed random variables desired fairness classiﬁcation. references adam-bourdarios cowan germain guyon kégl rousseau higgs boson machine learning challenge. nips workshop high-energy physics machine learning volume page baktashmotlagh harandi lovell salzmann unsupervised domain adaptation domain invariant projection. proceedings ieee international conference computer vision pages feldman friedler moeller scheidegger venkatasubramanian certifying removing disparate impact. proceedings sigkdd international conference knowledge discovery data mining pages acm. gong grauman connecting dots landmarks discriminatively learning domain-invariant features unsupervised domain adaptation. proceedings international conference machine learning pages goodfellow pouget-abadie mirza warde-farley ozair courville bengio generative adversarial nets. advances neural information processing systems pages", "year": 2016}