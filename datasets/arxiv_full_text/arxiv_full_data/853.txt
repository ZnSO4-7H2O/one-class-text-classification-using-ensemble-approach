{"title": "Deep learning for neuroimaging: a validation study", "tag": ["cs.NE", "cs.LG", "stat.ML"], "abstract": "Deep learning methods have recently made notable advances in the tasks of classification and representation learning. These tasks are important for brain imaging and neuroscience discovery, making the methods attractive for porting to a neuroimager's toolbox. Success of these methods is, in part, explained by the flexibility of deep learning models. However, this flexibility makes the process of porting to new areas a difficult parameter optimization problem. In this work we demonstrate our results (and feasible parameter ranges) in application of deep learning methods to structural and functional brain imaging data. We also describe a novel constraint-based approach to visualizing high dimensional data. We use it to analyze the effect of parameter choices on data transformations. Our results show that deep learning methods are able to learn physiologically important representations and detect latent relations in neuroimaging data.", "text": "deep learning methods recently made notable advances tasks classiﬁcation representation learning. tasks important brain imaging neuroscience discovery making methods attractive porting neuroimager’s toolbox. success methods part explained ﬂexibility deep learning models. however ﬂexibility makes process porting areas difﬁcult parameter optimization problem. work demonstrate results application deep learning methods structural functional brain imaging data. also describe novel constraint-based approach visualizing high dimensional data. analyze effect parameter choices data transformations. results show deep learning methods able learn physiologically important representations detect latent relations neuroimaging data. main goals brain imaging neuroscience—and possibly natural sciences— improve understanding investigated system based data. case amounts inference descriptive features brain structure function non-invasive measurements. brain imaging ﬁeld come long anatomical maps atlases towards data driven feature learning methods seed-based correlation canonical correlation analysis independent component analysis methods highly successful revealing known brain features details recovering features differentiate patients controls starting resting state revolution revealing consistent patters data uncontrolled resting experiments classiﬁcation often used merely correctness checking tool main emphasis learning brain. perfect oracle explain conclusions would useful mainly facilitate inference ways oracle draws conclusions. oracle deep learning methods breaking records taken areas speech signal image video text mining recognition improving state classiﬁcation accuracy sometimes prior decade struggled obtain improvements differentiates classiﬁers however automatic feature learning data largely contributes improvements accuracy. presently seems closest solution oracle reveals methods desirable tool brain imaging. another distinguishing feature deep learning depth models. based already acceptable feature learning results obtained shallow models—currently dominating neuroimaging ﬁeld—it immediately clear beneﬁts would depth have. considering state multimodal learning models either assumed analyzed modalities cross-modal relations sought level mixture coefﬁcients deeper models better intuitive notion cross-modality relations example relations genetics phenotypes indirect happening deeper conceptual level. work present recent advances application deep learning methods functional structural magnetic resonance imaging consists brain volumes smri static volumes—one subject/session—while fmri single subject dataset comprised multiple volumes capturing changes experimental session. goal validate feasibility application investigating building block deep generative models—a restricted boltzmann machine competitive examining effect depth deep learning analysis structural data determining value methods discovery latent structure large-scale dataset measure feature learning performance shallow model comparable existing methods known brain physiology. however measure cannot used deeper models investigated. demonstrate classiﬁcation accuracy provide complete picture either. able visualize effect depth gain insight learning process introduce ﬂexible constraint satisfaction embedding method allows control complexity constraints deliberately choosing local constraints able reﬂect transformations deep belief network learns applies data gain additional insight. prior investigating beneﬁts depth learning representations fmri smri data would like shallow model–which rbm— family meets ﬁeld’s expectations. mentioned introduction number methods used feature learning neuroimaging data belong single matrix factorization class. quick comparison small subset methods simulated data; continue extensive comparison approach trusted neuroimaging ﬁeld. similarly relies bipartite graph structure even artiﬁcial neural network sigmoid hidden units case infomax compare against. note difference applies weight matrix temporal dimension data imposing independence spatial dimension applies weight matrix high dimensional spatial dimension instead restricted boltzmann machine markov random ﬁeld models data distribution parameterizing gibbs distribution bipartite graph visible hidden normalization term energy system. visible variable case fmri data represents voxel fmri scan real-valued approximately gaussian distribution. case energy deﬁned biases standard deviation parabolic containment function visible variable centered bias general parameters need learned along parameters. however practice normalizing distribution voxel zero mean unit variance faster effective number choices affect quality interpretation representations learned fmri rbm. encouraging sparse features l-regularization using hyperbolic tangent hidden units non-linearity essential settings respectively facilitate spatial temporal interpretation result. weights updated using truncated gibbs sampling method spatial temporal cross correlation accuracy function spatial overlap true sources lines indicate average correlation color-ﬁll indicates standard errors around mean. figure shows correlation spatial maps time course estimates ground truth spca snmf. correlations averaged across sources datasets. showed best overall performance. snmf also estimated well showed inferior performance estimation likely non-negativity constraint. based results broad adoption ﬁeld focus comparing infomax rbm. figure shows full ground truth sources along estimates single representative dataset. thresholded represented contours visualization. results synthetic datasets showed similar performance slight advantage regard estimation slight advantage regards estimation. also showed comparable performance estimating cross correlations also called functional network connectivity data used work comprised task-related scans healthy participants gave written informed irb-approved consent hartford hospital compensated participation. participants scanned auditory oddball task involving detection infrequent target sound within series standard novel sounds. scans acquired olin neuropsychiatry research center institute living/hartford hospital siemens allegra dedicated head scanner equipped mt/m gradients standard quadrature head coil consisted -min runs scans second used ﬁnal dataset. data post-processed using software package motion corrected using inrialign subsampled voxels. complete fmri dataset masked mean mean image across dataset removed giving complete dataset size voxels volumes. voxel normalized zero mean unit variance. constructed using gaussian visible units hyperbolic tangent hidden units. hyper parameters range) learning rate weight decay selected showed reduction reconstruction error training signiﬁcant reduction span receptive ﬁelds respectively. parameter value outside ranges either resulted unstable slow learning uninterpretable features trained batch size approximately epochs allow full convergence parameters. ﬂipping sign negative receptive ﬁelds identiﬁed labeled spatially distinct features corresponding brain regions afni excluding features high probability corresponding white matter ventricles artifacts normalized fmri volume time series mean zero used trained feed-forward mode compute time series fmri feature. done better compare mean removed preprocessing. work-ﬂow outlined figure figure shows comparison resulting features obtained infomax ica. general performs competitively providing–perhaps surprisingly used regularization—sharper localized features. recognize subjective measure list features figure section note features lack negative parts corresponding features. note case regularized weights algorithms starts resemble approaches explain similar performance. however differences possible advantages generative nature enforcement component orthogonality moreover block structure correlation matrix feature time courses provide grouping physiologically supported provided ica. example figure supplementary material section below. perhaps working hard enforce spatial independence subtly affects time courses cross-correlations turn. observed comparable running times implementation validating depth effect since results demonstrate feature-learning performance competitive state proceed investigating effects model depth. turn fmri smri data. commonly assumed deep learning literature depth often improving classiﬁcation accuracy. investigate indeed true smri case. structural data convenient purpose subject/session represented single volume label control patient case. compare data hundreds volumes belong subject disease state. important property goals feature learning facilitate discovery ability operate generative mode ﬁxed values chosen hidden units thus allowing investigate features model learned and/or weighs important discriminative decisions. however going property section focusing instead validating claim network’s depth provides beneﬁts neuroimaging data analysis. using discriminative mode dbn’s operation provides objective measure depth effect. training splits stages pre-training discriminative tuning. pre-trained treating layers rbm—trained unsupervised inputs previous layer—and later ﬁne-tuned treating feed-forward neural network. latter allows supervised training error back propagation algorithm. schema following augmenting soft-max layer ﬁne-tuning stage. operate data samples brain volumes fmri smri case. ﬁve-minute fmri experiment seconds sampling rate yields volumes subject. smri studies number participating subjects varies paper operate subject-volumes datasets. transformations learned deep learning methods look intuitive hidden node space generative sampling trained model provide sense model learned anything useful case data contrast natural images fmri smri images look intuitive. instead nonlinear embedding method control whether model learned useful information assist investigation fact learned. purposes embedding display complex high dimensional dataset intuitive representative data sample. ﬁrst requirement usually leads displaying data samples points -dimensional second elusive approach addresses differently. embedding approaches include relatively simple random linear projections—provably preserving neighbor relations —and complex class nonlinear embedding approaches attempt organize properties diverse family aimed representing nonlinear embedding methods single constraint satisfaction problem framework hypothesize method places samples satisfy speciﬁc constraints. although work complete proven useful current study. brieﬂy outline ideas section provide enough intuition method section since control constraints framework study effect deep learning choose least amount work—while still useful—letting hard part. complicated method t-sne already complex processing preserve structure dataset hard infer quality determined deep learning method embedding. existing method provided least amount work solutions well chose framework. explicitly states constraints satisﬁed thus lets reason deep learning effects within constraints methods—where constraints implicit—this would harder. constraint satisfaction problem requiring solution satisﬁes constraints. well known examples boolean satisﬁability problem multiple important csps packing molecular conformations recently error correcting codes freedom setup point constraints without controlling global interactions makes formulation attractive representation nonlinear embedding problem. pursuing property iterative divide concur algorithm solver representation. algorithm treat point solution variable assign constraints variable needs satisfy points gets replica constraint involved into. algorithm alternates divide concur projections. divide projection moves replica points nearest locations satisfy constraint participate concur projection concurs locations replicas point placing average location map. idea avoid local traps combining divide concur steps within difference single location update represented denote divide concur projections user-deﬁned parameter. concur projection differ subsets replicas across different methods representable framework divide projection unique deﬁnes algorithm behavior. paper choose divide projection keeps nearest neighbors point higher dimensional space also neighbors map. simple local neighborhood constraint allows assess effects deep learning transformation leaving mapping decisions deep learning. note general dataset able satisfy constraint point exactly neighbors original space algorithm however guaranteed solution exists oscillates otherwise. oscillating behavior detectable used stop algorithm. found informative watching dynamics points keep oscillating provide additional information structure data. another practically important feature algorithm deterministic. given parameters converges solution regardless initial point. points participates constraint complexity algorithm quadratic. simple neighborhood constraints samples/points. combined data four separate schizophrenia studies conducted johns hopkins university maryland psychiatric research center institute psychiatry london western psychiatric institute clinic university pittsburgh combined sample comprised schizophrenia patients matched healthy controls contained ﬁrst episode chronic patients sites whole brain mris obtained signa scanner using identical parameters software. original structural images segmented native space resulting gray white matter images spatially normalized gray white matter templates respectively derive optimized normalization parameters. parameters applied whole brain structural images native space prior segmentation. obtained voxel gray matter images used study. figure shows example orthogonal slice views gray matter data samples patient healthy control. main question section evaluate effect depth smri. answer question investigate classiﬁcation rates improve depth. sequentially investigate dbns depth. experiments learned even larger number hidden units tends keep around features driving rest zero. classiﬁcation rate reconstruction error still slightly improves however number hidden units increases. observations affected choice hidden units ﬁrst layers third. hidden unit connected units previous layer results connectivity structure layers common conventional approach constructing models. note larger networks lead similar results. pre-train layer unsupervised discriminatively ﬁne-tune models depth adding softmax layer models training back propagation. estimate accuracy classiﬁcation -fold cross validation ﬁne-tuned models splitting subject dataset approximately class-balanced folds. train rbf-kernel logistic regression k-nearest neighbors classiﬁer using activations top-most hidden layers ﬁne-tuned models training data fold input. testing performed likewise test data. also perform -fold cross validation data. table summarizes precision recall values f-scores standard deviations. models demonstrate similar trend accuracy slightly increases depth- depth- improves signiﬁcantly. table supports general claim deep learning community improvement classiﬁcation rate depth even smri data. improvement classiﬁcation even simple classiﬁer indicates character transformation learns applies data changing data manifold organize classes neighborhoods. ideally make general conclusion transformation need analyze several representative datasets. however even working data closer view depth effect using method introduced section although seem provide signiﬁcant figure effect dbn’s depth neighborhood relations. shown iteration algorithm color differentiates classes training validation data. although data becomes separable depth depth continues distilling details pull classes apart. improvements smri classiﬁcation depth- depth- model keeps learning potentially useful transformaions data. using simple local neighborhoodbased embedding. figure displays maps data well depth activations deeper networks place patients control groups apart. additionally figure displays subjects train hold subjects also getting increased separation depth. dbn’s behavior potentially useful generalization larger diverse data become available. mapping method essential properties facilitate conclusion provide conﬁdence result already mentioned local properties deterministic nature algorithm. latter leads independence resulting maps starting point. depends models parameter k—the size neighborhood—and data. section focus smri data collected healthy controls huntington disease patients part predict-hd project huntington disease genetic neurodegenerative disease results degeneration neurons certain areas brain. project focused identifying earliest detectable changes thinking skills emotions brain structure person begins transition health diagnosed huntington disease. would like know deep learning methods assist answering question. study t-weighted scans collected multiple sites representing multiple ﬁeld strengths multiple manufactures weighted scans axial volumetric spoiled-gradient echo series weighted scans volumetric mprage series images segmented native space normalized common template. correlating normalized gray matter segmentation template eliminating poorly correlating scans obtain dataset scans patients healthy controls. used scans imbalanced sample pre-train tune model architecture section three depths. table lists average f-score values classes data depth levels. note drop data recovery depth limited capacity levels reduced network ability differentiate groups representational capacity depth network compensates initial bottleneck. this conﬁrms previous observation depth effect however help main question predict-hd study. note however table previous section evaluates generalization ability table demonstrates changes dbn’s representational capacity depth testing data. investigate utility deep learning approach scientiﬁc discovery augment embedding method section figure shows scans patients healthy controls. point smri volume shown figures although used complete data train discriminative ﬁne-tuning access binary label control patient. addition that information severity disease high. color coded information figure bright yellow orange network discriminates patients disease severity results spectrum map. note neither t-sne embedding spectrum even patient groups data. important property method help support future discovery information disease. conclusions investigations show deep learning high potential neuroimaging applications. even shallow already competitive model routinely used ﬁeld produces physiologically meaningful features highly focal time course cross correlations connect meaningful functional groups depth indeed help classiﬁcation increases group separation. apparent smri datasets collected varying conditions multiple sites each different disease groups pre-processed differently. strong evidence dbns robustness. furthermore study shows high potential dbns exploratory analysis. figure demonstrates conjunction mapping method reveal hidden relations data. difﬁcult initially workable parameter regions hope researchers won’t difﬁculty starting baseline provide paper. bharat biswal zerrin yetkin victor haughton james hyde. functional connectivity motor cortex resting human brain using echo-planar mri. magnetic resonance medicine m.j. brookes woolrich luckhoo price j.r. hale m.c. stephenson g.r. barnes s.m. smith p.g. morris. investigating electrophysiological basis resting state networks using magnetoencephalography. proceedings national academy sciences asja fischer christian igel. introduction restricted boltzmann machines. progress pattern recognition image analysis computer vision applications pages springer karl friston andrew holmes keith worsley poline chris frith richard frackowiak. statistical parametric maps functional imaging general linear approach. human brain mapping quoc rajat monga matthieu devin chen greg corrado jeff dean andrew building high-level features using large scale unsupervised learning. international conference machine learning. jingyu vince calhoun. parallel independent component analysis multimodal analysis application fmri data. biomedical imaging nano macro isbi ieee international symposium pages ieee shashwath meda nicole giuliani vince calhoun kanchana jagannathan david schretlen anne pulver nicola cascella matcheri keshavan wendy kates robert buchanan large scale investigation gray matter differences schizophrenia using optimized voxel-based morphometry. schizophrenia research moosmann eichele nordby hugdahl calhoun. joint independent component analysis simultaneous eeg-fmri principle simulation. international journal psychophysiology vinod nair geoffrey hinton. rectiﬁed linear units improve restricted boltzmann machines. proceedings international conference machine learning pages potluru calhoun. group learning using contrast application functional structural schizophrenia. circuits systems iscas ieee international symposium pages marcus raichle mary macleod abraham snyder william powers debra gusnard gordon shulman. default mode brain function. proceedings national academy sciences jing tulay adali qingbao jiayu chen vince calhoun. review multivariate methods multimodal fusion brain imaging data. journal neuroscience methods correlation matrices results fmri dataset section provided figure ordering components performed separately method. network named physiological function depth explaining current paper. modularity apparent visually quantitatively. modularity deﬁned averages across subjects ica. values signiﬁcantly greater also note scale correlation values different highlights overestimated strong values. figure correlation matrices determined averaged subjects. note color scales different correlation matrix scale also provided inset feature groupings determined separately using matrices known anatomical functional properties. figure sample pairs consisting thresholded standard deviations. pairing done spatial correlations temporal properties visual inspection. values indicate spatial correlation sms.", "year": 2013}