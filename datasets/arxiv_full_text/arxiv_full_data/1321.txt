{"title": "Predictive Encoding of Contextual Relationships for Perceptual  Inference, Interpolation and Prediction", "tag": ["cs.LG", "cs.CV", "cs.NE"], "abstract": "We propose a new neurally-inspired model that can learn to encode the global relationship context of visual events across time and space and to use the contextual information to modulate the analysis by synthesis process in a predictive coding framework. The model learns latent contextual representations by maximizing the predictability of visual events based on local and global contextual information through both top-down and bottom-up processes. In contrast to standard predictive coding models, the prediction error in this model is used to update the contextual representation but does not alter the feedforward input for the next layer, and is thus more consistent with neurophysiological observations. We establish the computational feasibility of this model by demonstrating its ability in several aspects. We show that our model can outperform state-of-art performances of gated Boltzmann machines (GBM) in estimation of contextual information. Our model can also interpolate missing events or predict future events in image sequences while simultaneously estimating contextual information. We show it achieves state-of-art performances in terms of prediction accuracy in a variety of tasks and possesses the ability to interpolate missing frames, a function that is lacking in GBM.", "text": "propose neurally-inspired model learn encode global relationship context visual events across time space contextual information modulate analysis synthesis process predictive coding framework. model learns latent contextual representations maximizing predictability visual events based local global contextual information top-down bottom-up processes. contrast standard predictive coding models prediction error model used update contextual representation alter feedforward input next layer thus consistent neurophysiological observations. establish computational feasibility model demonstrating ability several aspects. show model outperform state-of-art performances gated boltzmann machines estimation contextual information. model also interpolate missing events predict future events image sequences simultaneously estimating contextual information. show achieves state-of-art performances terms prediction accuracy variety tasks possesses ability interpolate missing frames function lacking gbm. theoretical neuroscience proposed order rapidly process constant inﬂux sensory inputs complex noisy full ambiguity brain needs learn internal models world generate expectations predictions based memory context speed facilitate inference. comprehension achieved synthesized prediction expectation mediated recurrent feedback higher visual areas early visual areas explains incoming signals framework recently popularized ballard psychology neuroscience predictive coding theory understood generally framework hierarchical bayesian inference predictive coding idea generalized non-visual systems even uniﬁed theory brain however computational utility power conceptual models remains elucidated. work propose framework learn internal models contextual relationships visual events space time. internal models context allow system interpolate missing frames image sequences predict future frames. internal models learned latent variables help accomplish tasks rescaling weights basis functions represented neurons synthesis process framework predictive coding. model inspired related memisevic hinton’s gated boltzmann machines gated autoencoder also model spatiotemporal transformations image sequences. gated machines modeling -way multiplicative interaction make strong assumption role neural synchrony utilized learning inference. generalizing model n-way interaction problematic involves multiplicative interaction. result machines primarily used learn transformation frames. prediction accomplished applying transformation estimated based ﬁrst frames second frame generate/predict third frame. cannot interpolate missing frame middle given frame frame missing frame. model explicitly deﬁnes cost function based mutual predictability. ﬂexible propagate information directions predict future frames interpolate missing frames uniﬁed framework. formulation synchrony required. evidence multiple frames weighed summed together similar spatiotemporal ﬁltering input signals visual cortical neurons primary visual cortex. inference latent context variables nonlinear accomplished minimizing prediction error synthesized image sequence observed sequence. crucial difference which case deep learning networks relies one-pass feedforward computation inference. model exploiting top-down bottom-up processes minimize predictive coding cost function learning inference able estimate meaningful accurate contextual information. framework predictive coding contextual modulation allows model accomplish similar functions also makes ﬂexible achieve functions integrating frames performing interpolation. model also biologically plausible standard predictive coding model prediction error signals used update contextual representation only replace feedforward input next layer. model also provides framework understanding contextual modulation inﬂuence certain constructive generative aspects visual perception. proposed model seeks learn relationships visual events spatial temporal neighborhood provide contextual modulation image reconstruction interpolation prediction. conceptualized autoencoder contextual modulation context-dependent predictive coding model. predictive coding model states brain continually generates models world based context memory predict sensory input. synthesizes predicted image feeds back match input image represented lower sensory areas. mismatch between prediction input produces residue signal used update top-down models generate predictions explain away inputs model extends standard predictive coding model using residue signals update contextual representation turn modulates image synthesis process rescaling basis functions neurons adaptively synthesized images frames temporal neighborhood maximally predict another. problem formulated following energy function input signal predicted signal contextual latent variables ...n collection parameters model learned including feedforward connections receptive ﬁelds neurons hidden layer feedback connections modulate generation second term function regularization term makes contextual latent variables sparse. serves balance importance prediction error term regularization term. note cost function considered generalization classical energy functional bayesian formulation computer vision ﬁrst data term term replaced generative model second smoothness prior term replaced contextual relationship priors. objective model learn relationship contexts modulate predictive synthesis process maximize mutual predictability synthesized images across space and/or time. describe prediction generated model. model’s information depicted circuit diagram shown figure consists input layer hidden layer performs spatiotemporal ﬁlter operation input layer prediction layer represents prediction generated contextual modulation latent contextual representation layer prediction error signals propagated drive updating contextual representation figure left computational circuit predictive encoder. right graphical model representation predictive encoder expansion sequence arbitrary length units visible layer represents sequence images representing image frame x...n indicates sequence video image frames. note visible layer necessary visual events present since model possesses ability predict missing events available partial observations based principle mutual predictability. units hidden layer deﬁned number units deﬁnes index xt’s neighbors provide local temporal support returns size set. rb×d weight matrix learned parameters. viewed feature ﬁlter particular visual event image frame considered feedforward weight neuron neuron’s spatial receptive ﬁeld particular time frame. ﬁlter hidden spatiotemporal ﬁlter corresponding rows particular sequence related unit response spatiotemporal ﬁlter frame receptive ﬁeld neuron whose activity particular sequence image frames deﬁnition neighborhood ﬂexible. temporal neighborhood made causal including frame model would still work. here non-causal symmetrical neighborhood underscore fact model used model spatial context back forth time modify interpretation past events based current evidence recent history. additional crucial hidden layer latent variables used model contextual information. computed minimizing residue errors sequence reconstructed image frames input frames. ﬁltered weight matrix provide feedback rescale contribution latent variable activity generating prediction signal ˆxt. section study contextual representation greater details. prediction prediction layer given weights basis functions ﬁlter contextual representation generate modulating signal element-wise product thus contribution neuron predicted activity feedforward input rescaled context modulation produce weight spatial synthesis basis function modulator viewed high-dimensional distributed representation context structure modeled low-dimensional contextual representation made sparse sparsity term. combining equations together prediction generated context-dependent predictive coding model given computationally update contextual latent variables driven residue signals ˆxt. model also considered factor graph shown figure together expansion sequence arbitrary length factor node corresponds mutual predictability deﬁned equation consecutive frames modulated contextual representation contextual representation evolve time thus priors smoothness constraint imposed temporal evolution shown graphical model though priors imposed current implementation. abstract graphical model level model similar autoencoder well memisevic hinton’s gated boltzmann machines difference concrete formulation model well learning inference algorithms discussed introduction. unsupervised parameters learning training dataset composed image sequences i.i.d sample unknown distribution. objective optimize following problem adopt em-like algorithm updates parameters imputes hidden variable alternatively keeping ﬁxed. update stochastic gradient descent update based following update rule free parameter learning rate deﬁnes mini-batch used training time momentum term weighted free parameter momentum term helps avoid oscillations iterative update procedure speed learning process. free parameters experiments chosen guidance hinton algorithm implemented using theano provides highly optimized symbolic differentiation efﬁcient automatic gradient calculation respect objective function. idea denoising also used learn robust ﬁlters. estimate given ﬁxed estimate contextual representation sequence solving following optimization problem independently parallel computed eqn.. better exploit quadratic structure objective function solve convex optimization problem using efﬁcient quasi-newton method limited memory bfgs algorithm instead gradient descent training batch data ﬁrst update parameter using step stochastic gradient descent iterate steps l-bfgs estimate hidden variable inference partial observation refers prediction reconstruction missing image frame trained model given observed neighboring frames sequence. problem posed optimization problem simultaneously estimates latent variables contextual representation missing event/frame optimization problem solved efﬁciently iteratively alternating top-down bottom-up estimation procedure. top-down estimation hallucinates missing event based neighboring events higher-level contextual representation. bottom-up procedure uses prediction residue error update contextual representation. speciﬁcally minimizing eqn. realized alternately estimating iteratively. estimate given learned current estimation method eqn.. estimate given learned current estimation estimate missing event/frame solving following optimization problem eqn. considers prediction optimization problem factors role predicting/constructing neighbors. notice objective function standard quadratic function closed form solution step. video sequence predicting future frame interpolating missing frame formulated accomplished uniﬁed framework. ﬁrst experiment trained model using movies synthesized natural images. movie sequence exhibited either translation rotation scaling transformation. trained models type transformation movies independently well mixture three. show results feedforward ﬁlters models trained three frames algorithm however limited three frames also show results model trained relatively longer sequences frames images used generate training movie sequences random samples whitened natural images used olshausen field translation rotation patch size pixels. translation steps sampled interval uniformly rotation angles uniformly sampled intervals. scaling mixture motion cases patch size pixels. scaling ratio uniformly sampled mixture motion training simply combination three types single-transformation movies constant transformation parameter. models trained single type motion used contextual representation units training sequences size models trained three types motions used contextual representation units training sequences size used unsupervised parameters learning algorithm described earlier learning rate momentum every model trained epochs. figure shows feedforward ﬁlters learned translation resemble fourier basis quadrature phase difference frames. figure shows ﬁlters learned rotation fourier basis polar coordinates also quadrature phase polar angle frames. ﬁlters learned scaling shown figure depicts ﬁlters trained scaling. resemble rays emanating center circles contracting center reﬂecting trajectories points scaling. figure shows ﬁlters trained motion mixture appear encode transformations distributed manner using localized gabor ﬁlters similar receptive ﬁelds simple neurons primary visual cortex. figure shows ﬁlters trained frames rotation sequences. demonstrates model used learn longer sequence ﬁlters. found training time scales linearly understand information encoded contextual relationship latent variables used t-sne method pattern content transformation content clustered low-dimensional space. applied model pre-trained motion mixture combination test data synthetic movies generated randomly translating rotating scaling image patches. image patches randomly sampled different datasets translation steps less pixel frame rotation angles less scaling ratio sampled keep different transformations distinct. visualize activities z-layer using hinton’s t-sne algorithm figure response sequences three databases. observed content data three databases mixed together indicating latent variables cannot discriminate image patterns. hand transformations relatively well clustered segregated suggesting transformations distinctly encoded decoded from investigate transformations distinctly represented trained based decode three transformations test sequence inferred context representation computed probability three svms chose classiﬁcation highest probability. svms trained using product kernel function only. confusion matrix shown table suggests contextual representations encode content-invariant transformation information. also compared representational power inferred model computed using bottom-up top-down processing transformation latent variables computed using one-pass feedforward computation. compared -frame version model -way trained svms model decode type transformation. shown table model comparable fact outperforms models time needed training comparable faster gbm. addition trained linear regression model using contextual representation regressor predict/estimate transformations namely translation velocity angular rotation velocity scaling factor. denotes three transformation parameters. relative regression error deﬁned |ρgroundtruth−ρpredicted| cumulative distribution functions relative regression error estimates figure shows contextual representation contains sufﬁcient information transformation parameters. crucial feature model ability predict interpolate. note perform prediction interpolation. ﬁrst tested model’s ability interpolation prediction using training sequences generated three datasets face images mnist handwritten digits natural images evaluated performance predicting interpolating rotation norb dataset test drew image three databases applied transformation generate another transformed image. pair images feed nodes model trained using mixture transformation sequences natural images previous section. bottom-up top-down process simultaneously infer latent contextual variables subsequent frame prediction model. would ﬁrst inferred applied second frame generate third frame. contrast prediction next frame model limited second frame could based many previous frames stipulated model. figure prediction results generated model based ﬁrst rows frames. figure shows results predictions given ﬁrst second frames. demonstrate model’s ability accomplish prediction using top-down bottom-up algorithm. ﬁndings show contextual representation encoded sufﬁcient content-invariant transformation information providing contextual modulation generate predictions. used similar parameter setting michalski chirp sequence contained frames second partitioned non-overlapping -frame intervals yielding dimensional input vectors. frequency chirp signals varies task predict subsequent intervals given ﬁrst intervals. rmse results interval subsequent intervals predicted shown table table rmse prediction interpolation interpolation accomplished way. provided model simultaneously inferred. second figure shows interpolation results; cannot perform computation. next tested model challenging norb dataset contains images objects rotation different views lighting conditions. categories objects objects category taken camera directions camera elevations illuminations. trained model object categories. within category data divided training test based elevations. test model included images taken particular elevations training included image sequences taken elevations. elevation camera ﬁxed object rotating across frames. train model category took sequences three successive frames object particular condition learn -input model. tested model input images sequence taken untrained elevations. prediction results norb dataset obtained similar manner face digit cases presenting image frames infer simultaneously. results prediction shown third column object instance figure results comparable reported actually slightly better performance prediction interpolation results normalized output images matching pixel histogram output image input images using histogram matching techniques. figure left prediction results norb. right interpolation results norb. receptive ﬁelds model trained three consecutive frames database exhibited quadrature phase relationship adjacent frames. means ﬁlters phase shift degrees. responses ﬁlters missing direction motion underdetermined movement could either direction. model fails interpolate case. improved temporal resolution model training ﬁlters sequences develop quadrature phase relationship ﬁxed ﬁlters train sequences. allowed adjacent ﬁlters model ﬁner phase difference yielded reasonable interpolation results shown figure elegant solution problem requires investigation. reported performance model prediction interpolation quantitatively table also used -way prediction test described section models trained using mixture motion sequences tested image sequences. result suggests model comparable fact slightly outperforms gated machines prediction. additionally model perform interpolation possible gbm. paper presented predictive coding framework learn encode contextual relationships modulate analysis synthesis perception. discussed introduction model distinct standard predictive coding model addition conceptually novel might biologically plausible. model shares similarities autoencoder model differs model uses contextual representation gate prediction synthesis process autoencoder utilize context autoencoder relies solely fast feed-forward computation model utilizes fast top-down bottom-up procedure update contextual representations modulate image synthesis inference. contextual variables considered generalized form smoothness constraint early vision implemented locally interneurons particular visual area. contribution work demonstrating ﬁrst time usefulness local contextual modulation predictive coding auto-encoder framework. recurrent neural networks still provide state-of-the-art performance sequence modeling. requires data train. thus despite power modeling short long sequences particularly trained large dataset falters limited dataset like norb database. predictive encoder proposed learns contextual latent variables provide information transformation explicitly rnns latent variables used represent content images transformations encoded connections. transforms encoded latent variables predictive encoder directly related perceptual variables motion velocity optical binocular disparity. model shares similar goals gated boltzmann machine learning transformational relationships model utilizes different mechanism uniﬁed framework inference interpolation prediction. consider state-of-art method learning transform limited amount data thus mostly focused quantitative evaluation predictive encoder model performance gbm. found model comparable superior performance relative gated boltzmann machine terms inference prediction additionally able perform interpolation. model relies standard spatiotemporal ﬁltering feedforward path without need n-way multiplicative interaction neural synchrony required gbm. thus simpler conceptualization maybe biologically plausible. important recognize model currently module uses latent variables encode spatiotemporal local context transformation. module used build recurrent neural networks model temporal evolution contextual variables stacked form deep networks learn hierarchical features layer local spatiotemporal contextual representations. acknowledgments research supported research grants nsfc- wang lee’s labs acknowledge support nvidia corporation donation gpus research. mingmin zhao chengxu zhuang supported peking university tsinghua university undergraduate scholarships respectively visited carnegie mellon carry research. bergstra james breuleux olivier bastien fr´ed´eric lamblin pascal pascanu razvan desjardins guillaume turian joseph warde-farley david bengio yoshua. theano math expression compiler. proceedings python scientiﬁc computing conference gourier nicolas hall daniela crowley james estimating face orientation robust detection salient facial structures. workshop visual observation deictic gestures. fgnet cambridge hinton geoffrey. practical guide training restricted boltzmann machines. momentum hinton geoffrey osindero simon yee-whye. fast learning algorithm deep belief lecun yann huang bottou leon. learning methods generic object recognition invariance pose lighting. computer vision pattern recognition cvpr proceedings ieee computer society conference memisevic roland. gradient-based learning higher-order image features. iccv. ieee michalski vincent memisevic roland konda kishore. modeling deep temporal dependentodorovic freek maris eric lange floris prior expectation mediates neural adaptation repeated sounds auditory cortex study. journal neuroscience", "year": 2014}