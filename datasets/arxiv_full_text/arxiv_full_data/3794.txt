{"title": "Neural Architectures for Robot Intelligence", "tag": ["cs.RO", "cs.CV", "cs.HC", "cs.LG", "cs.NE", "q-bio.NC", "I.2.9; I.2.10; I.2.6; H.1.2; H.2.8; I.5.4"], "abstract": "We argue that the direct experimental approaches to elucidate the architecture of higher brains may benefit from insights gained from exploring the possibilities and limits of artificial control architectures for robot systems. We present some of our recent work that has been motivated by that view and that is centered around the study of various aspects of hand actions since these are intimately linked with many higher cognitive abilities. As examples, we report on the development of a modular system for the recognition of continuous hand postures based on neural nets, the use of vision and tactile sensing for guiding prehensile movements of a multifingered hand, and the recognition and use of hand gestures for robot teaching.  Regarding the issue of learning, we propose to view real-world learning from the perspective of data mining and to focus more strongly on the imitation of observed actions instead of purely reinforcement-based exploration. As a concrete example of such an effort we report on the status of an ongoing project in our lab in which a robot equipped with an attention system with a neurally inspired architecture is taught actions by using hand gestures in conjunction with speech commands. We point out some of the lessons learnt from this system, and discuss how systems of this kind can contribute to the study of issues at the junction between natural and artificial cognitive systems.", "text": "abstract argue direct experimental approaches elucidate architecture higher brains beneﬁt insights gained exploring possibilities limits artiﬁcial control architectures robot systems. present recent work motivated view centered around study various aspects hand actions since intimately linked many higher cognitive abilities. examples report development modular system recognition continuous hand postures based neural nets vision tactile sensing guiding prehensile movements multiﬁngered hand recognition hand gestures robot teaching. regarding issue learning propose view real-world learning perspective data mining focus strongly imitation observed actions instead purely reinforcement-based exploration. concrete example eﬀort report status ongoing project robot equipped attention system neurally inspired architecture taught actions using hand gestures conjunction speech commands. point lessons learnt system discuss systems kind contribute study issues junction natural artiﬁcial cognitive systems. remarkable feats nature evolution information processing architectures brains. despite components compared transistor devices slow accuracy high manufacturing tolerances evolution found architectures operate highly complex perception control tasks real time outperforming sophisticated technical solutions speed also robustness adaptability. main architectural feature leads properties simple massively parallel processing current capabilities artiﬁcial systems look much advanced actually are. processing power modern microprocessors used larger numbers begin become comparable sizeable portions brain tissue believe still lack concepts required shape processing power brain-like capabilities. much brain research past present often dictated experimental constraints emphasized bottom approach properties individual neurons even synapses center. recent years seen advent methods signiﬁcantly help complement top-down approach. argue work recent years decades accumulated point form quite reasonable guesses computational contribution quite substantial number brain areas. detailed elucidation exact nature computations still need long time research nevertheless hope many details decisive operation overall system. support view results recent studies brain organization revealed rather tight interconnectivity majority brain centers making likely structure level shapes system properties much details modules themselves. fig. depicts view intermodule-connectivity brain. nodes indicate major processing centers line represents major interconnection bundle. technique multidimensional scaling used depict processing centers positions spatial distance reﬂect degree interconnectedness. diagrams like summarize huge amounts anatomical data give bird’s view brain architecture. figure multidimensional scaling plot connectivity functional areas brain functional areas indicated labelled nodes major connectivity bundles lines. technique multidimensional scaling used brain centers node positions spatial proximity nodes reﬂects high degree mutual interconnectivity. fact technical control systems well-known heavy feedback connections almost entirely determine dynamic system behavior eﬀectively disguising almost dynamical details exhibited modules would operate open loop mode. therefore even rather crude approximations diﬀerent brain module functions give chance gain signiﬁcant insights functioning overall system provided architectural level right. view correct signiﬁcant part challenge exploration possible architectural patterns could organize computational contributions collection sensor- motormemory modules coherent sensorimotor-processing activity. controlled experimental alterations actual brain architectures diﬃcult least higher animals ethically highly objectionable task domain robotics oﬀers much wider experimental possibilities current technology matured point approximate reasonable spectrum isolated perceptual memory motor capabilities allowing explore architectures integration functions artiﬁcial cognitive systems. behind approach expectation computational architecture brains large extent shaped computational demands tasks solve indeed case important explore computational architectures primarily tasks likely typical brains solve. evolutionary perspective likely candidate navigation basic behaviors contributes capabilities animal. however example insect navigation also shows evolution cognition apparently driven demands additional gave rise ability navigation alone. argued development cognition closely linked capability purposively one’s environment cause changes therefore expect need control sophisticated manipulators particularly form arms hands major driving force shaping factor cognitive processing architecture brain. fact closer look reveals particular control hands human connected large number highly demanding many ways generic information processing tasks whose coordination already forms major base intelligent behavior. regarding perception ﬁrst major issue visual recognition hands hand actions. since hands major focus action also higher primates good visual recognition hands motions well highly variable postures even higher level actions. interestingly recognition tasks found correlated activity neurons show rather selective responses visually perceived hand actions fig. therefore task recognition hands actions suitable starting place investigate minimal demands architecture visual system sec. report ongoing work towards goal visually based recognition hand actions. figure selective neuron response visually perceived hand actions bottom shows associated activity trace neuron macaque animal observes action sequence depicted corresponding column above. apparently recorded neuron responds selectively interaction hand silent remaining visually similar trials. touch another modality closely linked hands. haptic perception objects highly developed humans known initial processing steps somatosensory cortex resembles visual processing however also signiﬁcant diﬀerences haptic perception usually closely coupled ﬁnger movements unlike retinal surface eyes skin ﬁngers undergoes complex changes three-dimensional arrangement space relative object surfaces. computational point view poses formidable challenge doubt addressed level architecture suitable coordinate operation tactile sensors active ﬁnger control. recent years developed ﬁnger force sensors provide least rudimentary touch force information ﬁnger tips three ﬁngered hand sec. brieﬂy report research help approach issues control ﬁnger synergies grasping fusion touch sensory modalities vision. finally issue carrying hand actions themselves. increases demands underlying architecture even further besides integration perception action additional elements need state context memory well planning. neural structures involved stages appear farther removed direct sensory input motor output include areas parietal cortex premotor supplementory motor area. carry task systems must operate highly preprocessed representations reﬂect important invariants task level holding object aligning another controlling constrained movement screwing onto screw. time operation structures exhibits enormous ﬂexibility ability learning make possible account enormous range human manual activities. therefore major challenge architectural level understand neural adaptivity lower system levels manifest progressive shaping interactions among neural modules large. words understand principles required realize learning architecture substantial number coarsely adapted skills become coordinated diﬀerent ways allow goal-directed sequences manual actions. research unsupervised reinforcement learning algorithms tried address issue however limited success. remarkable demonstrations unsupervised skill learning simple tasks learning complex tasks usually leads exponentially growing learning times quickly becomes unrealistic even tasks moderate complexity additionally success demonstrations usually relies often rather ingeniously encoded input data. typical real world learning situations diﬀer markedly this usually characterized extremely high-dimensional sensory input vision touch part challenge learning system regularities input guide successful execution intended task. task detecting regularities shares many issues still rather young ﬁeld datamining datamining goal detect patterns regularities often huge amounts data order support decisions make predictions improve control industrial process modern datamining systems seen analogous endeavor carried nature evolving brains endow company similar organism sensors perceptual capabilities exploit useful regularities surround order improve ﬁtness. brains evolved processing sensory signals largely familiar with datamining techniques attempt imitate similar capabilities although currently much lower level data artiﬁcial man-made domains economic systems medical databases industrial processes internet. therefore surprising many methods ﬁeld datamining closely related mathematics underlie many models brain operation. exploit analogies fruitful sides brain modeling beneﬁt rapid progress current datamining methods insight brain mechanisms inspire datamining techniques. however seems doubtful alone suﬃcient realize highlevel learning architecture. even sophisticated machine learning methods unlikely remove curse dimensionality limits possibilities unsupervised learning high-dimensional spaces. therefore appears promising towards high-level learning detect required high-level structures input data themselves instead trying completely re-construct search high-dimensional search space. attractive approach along lines intimately connected observation interpretation hand actions oﬀered paradigm imitation learning watching action sequence oﬀers learner chance strongly reduce search space confronted focus exploration less narrow neighborhood successful example to-be-learned skill. make feasible however requires identify essential elements action sensory stream remap context observer. ﬁrst step requires highly developed vision capability ability detect relations image sequences. second step requires matching observed situation one’s context; goes well beyond simple geometric transformation since involved objects relationships usually analogous identical situation learner wants operate. therefore approach imitation learning implemented rather highly developed base sensory preprocessing opens door detect useful regularities complex world. turn price making learning feasible approaches solve learning problem more intelligent search strategies alone doomed fail comes complexity real world tasks since address much harder problem invention compared imitation. recognition hand postures constitutes complex tasks routinely eﬀortlessly carried brains. contrast everyday objects hands deformable objects characterized continuous degrees freedom associated large conﬁguration space makes recognition continuous hand postures much harder problem e.g. classiﬁcation discrete hand conﬁgurations. result robust accurate recognition hand postures requires address many issues general vision systems. still task suﬃciently circumscribed make implementation complete recognition architecture feasible. following describe architecture hierarchical recognition system employs several artiﬁcial neural nets order extract monocular video images human hand explicit representation three-dimensional hand posture computer-rendered articulated model hand follow posture viewed human hand figure task artiﬁcial neural recognition system extract monocular video image human hand shape order permit tracking seen hand posture computer rendered articulated hand model line previous remarks described recognition system attempt follow biological detail. instead meant explore particular processing architecture whose modules coarsely mimic principles thought underlie processing visual system. allows study signiﬁcance principles processing properties system level contribution multiple processing streams achieve better robustness hierarchical coarse-to-ﬁne strategy focus important parts image. ﬁrst step pixel image transformed lower-dimensional feature vector neural activities. discrete grid image positions position location number receptive ﬁelds formal neurons chosen gabor functions diﬀerent resolution orientation choice functions motivated observation gaborlike response characteristics visual neurons also favorable mathematical properties gabor functions capture important local image information. resulting activity pattern provides initial holistic input representation image. studied extraction hand posture directly holistic activity patterns means neural learning algorithms found simple single-stage architecture rather limited achievable accuracy hand posture identiﬁcation. figure two-level processing hierarchy determining ﬁnger location ﬁnger lower level network determines focus region upper level network attempts determine ﬁnger location. computation ﬁnal hand posture attempt ﬁrst extract holistic input representation meaningful stable object features chose present task ﬁnger locations image. solution subtask attempted single step; instead processing hierarchy neural network operating holistic input representation ﬁrst computes coarse estimate centers image subregions ﬁnger tips located. subsequently second level processing hierarchy provide ﬁnger subregion extra network applying analogous processing ﬁrst stage entirely focused selected ﬁnger subregion identiﬁed ﬁrst global network using gabor functions correspondingly reduced length scale figure left local linear networks supervised learning. locally valid linear implemented linear perceptron activated subregion input space. subregions deﬁned layer competitive gating neurons. right analysers unsupervised classiﬁcation. analyser valid subregion input space orients axes along directions maximal variance data distribution subregion. underlying mathematical principle networks representation input-output mapping combination local linear maps case supervised learning representation stimulus density collection local principal component analyzers situations share idea using layer competitive neurons tessellate feature space number smaller thus manageable subregions employ within subregion locally linear representation type approach become popular recent years considered suitable training algorithms detail elsewhere present situation required training data consist suﬃcient number monochrome hand images ﬁnger -locations must explicitly provided ﬁrst network directly trained data; subsequently network second stage trained image subregions identiﬁed trained global network ﬁrst stage pairs target output values). fig. shows typical hand postures extracted ﬁnger locations obtained global network alone improved locations including corrections local networks increase accuracy obtained ﬁnger locations employ another architectural principle known exist brain fusion multiple processing channels present task fuse three diﬀerent processing streams ﬁrst stream obtained gaussian activity proﬁle centered ﬁnger location determined stage detection network ﬁnger. activity proﬁle represents conﬁdence measure presence corresponding ﬁnger achieves maximum estimated position decays smoothly moves away point. second processing stream motivated observation ﬁnger tips tend located intensity edges. thus compute second processing stream edge image input distribution. fig. column shows product ﬁrst processing streams intensity modulated edge maximum modulation point closest approach ﬁnger position estimated network. three processing streams normalized yield images conﬁdence values pixel-wise multiplied obtain ﬁnal result highest values result image used probable position candidate alternative position ﬁnal step obtained features used identify hand posture. large debate extent vision system actually achieves reconstruction perceived objects survey). many arguments available intensity pattern real world images subject many degradations allow full general shape reconstruction local algorithms seems visual system figure psom-based mapping ﬁngertip positions hand postures. bottom rectangle coincides viewing area enclosing hand shapes vertical axis denotes image depth. fan-like grid structure belongs ﬁnger indicates ﬁnger positions traversed independently varying joint parameters discrete values. resulting point used training data psom network achieves smooth interpolation depicted fan-like structures thereby yielding smooth relationship ﬁnger positions viewing plane ﬁnger depth well associated joint parameters eﬃciently available views index shape memory provides access object properties. little known precise nature shape memory general level viewed providing shape models provide suﬃcient constraints make available information interpretable within architecture available information consists coordinate pairs ﬁnger. obviously insuﬃcient d-reconstruction even ﬁnger positions alone alone entire hand posture. however real hand postures ﬁnger joints highly correlated available degrees freedom fully used. instance angles last joints ﬁnger fulﬁll hand postures approximately relation since driven tendon. another simpliﬁcation equate joint angles determine ﬂexion ﬁngers. constraint exactly correspond situation human hand good approximation. constraints represent hand posture parameters number parameters available coordinate pairs which therefore identiﬁed data alone. required mapping ﬁnger joints image locations rather straightforward analytically computed system requires inverse transformation much harder cannot given closed form. therefore learning approach processing stage. ﬁnger train parameterized self-organizing using data analytically computable forward transform. psom generalization well-known self-organizing replaces discrete lattice continuous manifold combined useful property makes available learned mapping automatically also associated inverse fig. illustrates psom-generated mapping d-fingertip positions joint-angle space. development system provided many insights usefulness biologically motivated processing principles architectural level vision system. fig. gives impression system’s accuracy. contrast systems similar objective present approach work without special hand markers makes extensive learning several processing levels. resemble cortical processing visual areas major diﬀerence acquisition tactile perception object much interactive process visual counterpart. case hands intimately connected sophisticated control mechanical interaction shape-variable sensory surface grasped object. makes establishment computational models even bigger challenge vision. time gulf tactile sensing hands current technical solutions much larger case vision rather good camera sensors available. however active nature makes understanding haptic perception issue insights brain controls action. approach issue technical robot systems study control multiﬁngered robot hands haptic discrimination manipulation objects. fig. shows three-ﬁngered robot hand developed technical university munich used explore issues involved. ﬁnger approximately size human ﬁnger moved four joints total three degrees freedom joints actuated hydraulically allows fast forceful movement control price hysteresis eﬀects introduced friction within hydraulic cylinders actuators. prevents implementation reliable joint angle control purely based pressure data actuators makes additional tactile force sensing even important necessity. equip hand basic tactile sensing developed miniaturized ﬁnger sensors allow measure ﬁnger force vector caused object contact. early prototype sensors used types pressure sensitive foils mimic tonic phasic responses skin used control static force react rapid force changes indicating e.g. object slipping based experiences prototype succeeded subsequent simpliﬁed sensor design much easier fabricate maintain allowed obtain tonic phasic signals single sensor material obviously information gained sensors much limited provided tactile skin covering entire hand. however seen case artiﬁcial vision system information ﬁnger locations visual image carries already surprisingly large part information hand posture. similarly hope knowledge ﬁnger forces provide important part information necessary control grasping actions. following assumption implemented control architecture basic ﬁnger synergies involved dextrous grasping control based minimization error function formed weighted error signals diﬀerent sensory modalities ﬁrst inputs provided force measurements ﬁnger tips. second inputs provided pressures hydraulic actuators. finally third inputs encodes piston positions actuator unit. specifying suitable sets weighting coeﬃcients error contributions endow ﬁngers diﬀerent types reactive behavior. switching behaviors achieved ﬁnite state automaton whose state transitions become triggered either sensory events top-down signals whose states activate weighting coeﬃcients particular ﬁnger behavior. scheme implemented several simple grasp primitives preshaping hand grasping object closing ﬁngers object contact maintaining target force level holding object reacting preset compliance human tries take object away. primitives permit robust grasping roundish objects; however tactile discrimination ﬁnger sensors insuﬃcient permit automatic grasps complex objects. remedy extended sensing system non-biological adding hand camera evaluates close view object order orient ﬁngers appropriately successful grasp. grasping itself setup permits combined tactile information ﬁnger sensors visual information camera. initial results integration sensory channels judge grasp reliability e.g. although particularly described hand posture recognition system relies heavily learning algorithms attain capabilities think learning well many similar artiﬁcial systems still diﬀers much biological nervous systems suspect main reason microscopic learning rules operating level formal neurons mark; grounded wellestablished principles hebbian learning error correction would expect sophisticated learning rules future diﬀer detail much principle. however suspect main diﬀerence lies level architecture organizes ﬁrst major diﬀerence biological systems learning really integrated operation system. instead training phase separate training occurs level system modules level system whole. features rather typical current approaches exploit learning systems comprised several adaptive modules. second diﬀerence need carefully prepared training data sets input target values typically must provided well-deﬁned positions data vector diﬀerences make learning still rather artiﬁcial limited. real world situations oﬀer nice separation operation training phase; also oﬀer nicely labeled training data vectors give even less opportunity system surgery permit training individual modules. think sketched problems reﬂect lack good architecture speciﬁcally supports learning. issue training inner modules addressed quite forcefully context multilayer perceptron type approaches approach faced difﬁculties scaling issues discussed earlier; also well known multilayer perceptrons vulnerable catastrophic interference used incremental learning diﬃculty exhibited much lesser extent other local network models radial basis functions local linear maps kernel based approaches recently popular support vector machine hand models usually lack elegant scheme backpropagating training signals entire modules made multilayer perceptron attractive construction modular systems. however well known backpropagation step leads signiﬁcant attenuation training signal technique tends limited shallow architectures seldom possess four hidden layers. circumvent diﬃculties researchers developed arsenal various often rather heuristic tricks important strategies combination training incremental network construction cascade correlation architecture allows also modules oﬀer error backpropagation mechanism however approaches view best provide partial solution problems. suspect severe reason limitations current learning approaches undue emphasis view learning task identifying unknown input-output mapping assuming input target values given. latter assumption almost totally unfulﬁlled real world learning situations. paradigm reinforcement learning tries address issue weakening requirements available training information extent learning system informed relative success failure. leads conditions many real world situations; time greatly impoverished conditions acquire useful information make learning task much harder. prevented reinforcement learning scale situations realistic complexity exception select number cases ingenious encoding task variables succeeded focus search reinforcement learning algorithm promising part state space outset view promising lift learning complexity real world situations impoverish conditions information acquisition paradigm reinforcement learning instead large eﬀorts gaining rich information environment possible. approach also seems much better line living brains obviously devote large proportion processing capacity extract useful regularities rich spectrum sensory inputs actively coordinate available sensors processing resources order optimize process various ways. optimization might also require combined supervised unsupervised learning strategies recently suggested subdivision brain neocortex cerebellum basal ganglia might reﬂect architecture three structures provide substrate unsupervised supervised reinforcement learning respectively. following section argue main task system extraction useful regularities environment shares many goals computational issues ﬁeld datamining suggest consider realization powerful learning architectures datamining perspective. datamining ﬁeld emerged last decade response needs created explosive growth data acquired many ﬁelds science also ﬁnance business enterprises communication networks areas daily life automated data analysis situations become main challenges future since explosive growth data acquisition abilities seems face imminent limit. particular business ﬁnance sectors early detection important trends regularities acquired data vital importance survival company. explosive growth data acquisition abilities rules solution relies human inspection. therefore companies also scientists position develop tools autonomously process large collections data looking patterns regularities often vaguely characterized advance detection. situation analogous faced brains higher animals they connected huge number sensors continuously acquire data high rate. again relevant amount information sensory data constitutes tiny fraction total volume often encoded subtle patterns must detected massive background noise irrelevant signal variability. case living organisms extremely high survival value e.g. recognizing predator early even highly masked complex visual acoustic background obvious highly impressed superb solutions crafted natural evolution response needs. vision world created process imposes imagination strong bias world aware perception species-speciﬁc solution extracting particular combination sensory data streams behaviorally relevant regularities mediated categories deeply engrained conscious existence greatest diﬃculty imagining anything beyond rendering result species speciﬁc solution. brains species connected sensors provide access sensory dimensions totally alien ultrasonic reﬂections electric magnetic ﬁeld lines polarization light name cases attracted considerable research. therefore think much activity brains rather aptly characterized sophisticated form datamining evolved nature rapid highly performant extraction even subtle regularities huge amounts sensory data representation stable entities suitable basis rapid decisions reactions involving comparably low-dimensional motor apparatus organism. perspective task developing datamining system might best viewed task building artiﬁcial brain sensory domain occur nature domain particular application. conversely expect search deeper insights processing strategies real brains might beneﬁt experiences methods developed ﬁeld datamining. employed datamining brain modeling major task ﬁelds need dimension reduction ﬁrst step cope high bandwidth incoming data. reﬂected high amount attention devoted ﬁelds methods principal component analysis independent component analysis well nonlinear generalizations self-organizing maps autoassociator-networks. another important issue domains identiﬁcation regularities structures data various kinds putting cluster algorithms prototype formation identiﬁcation manifolds shared focus. closely related issues model extraction classiﬁcation prediction seen development neural network based classiﬁers non-linear regression recently support vector machine approach whose neurobiological signiﬁcance still awaits clariﬁcation. hard believe prominent presence methods ﬁelds largely coincidental. instead think situation reﬂects rather tight relationship tasks ﬁelds exploited future research. particular experience current work shows realization powerful learning architectures beneﬁt program least ways datamining contribute many techniques well-suited create ﬁrst layer representations reﬂect important regularities invariances environment oﬀer stable features sensory data themselves. described hand posture recognition system created layer still design. automatic data-driven construction essential step avoid limiting need manually prepared training data. already able carry program considerable extent somewhat diﬀerent domain discrete object classiﬁcation using combination clustering currently working towards extending techniques include cases involving continuous manifolds. methods data visualization recently data soniﬁcation help summarize inner state complex learning system various compact ways facilitate monitoring learning process human observer. directly learning process itself provides researcher additional windows learning dynamics helpful gain insights interactions occur among learning modules. explored approach still rather simple situations next target apply method gesture instructed robot system described following sections. make disappear curse dimensionality plagues approach attempts learn everything autonomous unsupervised exploration. overcome problem requires oﬀer learner useful information reinforcement alone provide next section argue paradigm imitiation learning appears promising need. learning datamining perspective alone still would confront learner formidable task make large number diﬃcult discoveries huge search space. everyday experience suggests least human learning rather diﬀerent occasionally learn things pure exploration discovery acquire much larger number skills imitation observed successful actions others. imitation learning still highly non-trivial reasons fully pointed below provides learner outset much richer information suitable narrow search spaces considerably general weaker learning strategies unsupervised reinforcement learning provide much smaller missing information. term imitation learning might suggest learning follows paradigm becomes extremely easy. unfortunately means true. reasons least threefold usually observed action cannot copied verbatim must instead transformed adapted learner’s situation usually diﬀers several respects model. related problem available input often provides partial information e.g. case hand action learner able visually follow spatiotemporal geometry hand movements sensory access tactile sensations forces accompany successful carrying action. finally observed action available form level sensory inputs embedded usually complex background sensory events directly relevant action interest. learner extensive preprocessing extract input concise representation observed action serve starting point solving remaining issues place operations objects laying table indicated manual pointing gestures human instructor follow exactly paradigm imitation learning scenario shares many issues central imitiation learning developed solutions serve sound basis makes proper imitation learning feasable next step. realization gravis complement described functional modules hand posture recognition ﬁnger control signiﬁcant number modules subtasks performing various coordinate transformations robot manipulator control object recognition following section describe gravis system fully. however lack space details involved modules; instead concentrate discussion architecture level particular attention mechanism allows system focus processing resources parts input likely contain useful information following instructor’s actions. gravis central task watch human instructor commands carry out. gravis result ongoing larger scale research eﬀort aiming towards systematic investigation principles needed build artiﬁcial cognitive systems communicate human intuitive including acquisition skills learning. result interest role hands understanding sensorymotor intelligence links intuitive demonstration-based communication major part development gravis centered around recognition learning carrying hand actions gestures context communication. currently gravis able recognize threedimensional pointing gestures instructor interprete commands pick objects laying around table deploy positions designated pointing gestures. obviously important element mode communication establishment continuous maintenance shared focus attention robot human user since majority robot work tasks related vision geometry view important role deictic spatial gestures process robot equipped active stereo camera system enable attention mechanism shift attention across large portion visual scene. implementation attention mechanism layered system topographically organized neural feature maps whose task integration diﬀerent low-level cues continually updated focus attention structure loosely motivated current neurobiological picture sensory integration mechanisms superior colliculus responsible targeting visual saccades. attractive feature approach simple extensibility additional layers allowing ﬂexible integration feature types attention control mechanism. similar approaches however fewer less complex maps investigated also context project detail vision system computes stereo images number feature maps indicating presence oriented edges hsi-color saturation intensity motion skin color. main goals system recognize track human hands multiply diﬀerence skin segmentation result moving skin treated feature right. weighted feature gaussian smoothing favor small saccades location maximal activity attention used deﬁne next ﬁxation point. multiplicative nature manipulation allows direct ﬁxations whole regions according availability top-down information finally fade-out task suppress activity recently visited regions also areas would command ﬁxations incompatible joint limits camera head. however order maintain interest pointing gestures moved skin always additively superimposed fade-out map. last step location maximal activity attention centered nearest object vicinity stereo matching algorithm used estimate depth obtain stereo correction centers cameras ﬁxation point weighted summation topographic maps provides also convenient top-down propagation information higher processing levels perceptual level. instance interaction human user modify attention diﬀerent mechanisms. hand gesture recognition system detects pointing gesture image d-direction pointing ﬁnger computed projection viewing plane used deﬁne sector-shaped pointing cone emanating figure pointing gesture evaluated several steps using skin segmentation mult-layer perceptrons classify pointing corresponding restriction attention region interest generated projected table indicated square lower middle display. points interest image stereo matching candidates ﬁxations case pointing information available. pointing ﬁnger scene. pointing cone represented correspondingly localized activity manipulation layer multiplied point-wise attention restrict explorative attention next step area pointing cone additionally spoken instruction references colored object corresponding weight corresponding color increased bias attention system towards spots image. increases probability ﬁxations blobs time decay mechanism drives weighting back default level. attention system component coordinate activity primarily visuo-spatially directed modules gravis system entire task gesture-controlled pick-and-place operations requires participation considerable number perceptual motor basis skills. fig. provides simpliﬁed overview mutual interactions. besides already mentioned visuo-spatial modules hand recognition hand tracking ﬁngertip recognition pointing recognition stereo matching additional modules deal motor control d-ﬁxations stereo camera system recognition target object orientation corresponding grasp choice pre-shaping hand figure functional modules gravis architecture blocks depict software modules circles hardware control arrows control ﬂow. dashed line shows behavior sequence object deployment starting rest-position lower left corner. organize control modules implementing skills represent primarily motor-directed aspects robot’s behavior ﬁnite-state automata activate de-activate mutually exclusive behavior modules. several modules implemented using artiﬁcial neural networks adapt changing characteristics task realized hierarchical fashion similar hand recognition system described above. separate processes running parallel several workstations communicating distributed message passing communication system developed earlier purpose project. hardware level current system comprises already mentioned binocular camera head equipped color-cameras motorized lenses total dof’s three-ﬁngered robot hand described sec. hand mounted puma manipulator dofs operated real time additionally equipped wrist camera view end-eﬀector region. usually systems complexity described gravis system beyond research prototypes rather portable product easily manner diﬀerent laboratory. time systems still extremely simple biological point view. ﬁrst answer question systems kind gravis allow experimentally explore interactions collection sensory memory motor skills context real-world tasks instead highly simpliﬁed artiﬁcial problems characteristic tasks brains evolved for. experiments give clues processing strategies might otherwise diﬃcult obtain. instance exploration behavior generated attention module tends ﬁxate repetitively upon interesting points cases objects. typical emerging regularity grounded perception-action loop instance used establish visual memory temporal integration stabilizes salient points. though case regularity rather obvious detectable chain d-ﬁxations alone availability technical system open kind surgery conjunction datamining techniques discussed sec. oﬀers chance detect also subtle patterns implicit dependencies mutual relationships sensory signals intermediate representations behavioral states actions point less obvious emergent processing strategies. consider complex chain events fig. instance repetitive pointing objects regularities typically manifest easily detectable hardware level sensory signals stage single module alone. endow system eﬃcient learning architecture requires collect information diﬀerent hierarchical levels many modules generate useful combined representations deﬁne appropiate learning several stages calibration hardware-near feedback loops highlevel organisation interactions functional modules. though remain many questions integrating levels attentional mechanism discussed provides ﬂexible approach generate well regularities exploited higher level modules propagate top-down higher level knowledge modulate lower level processing. human brain compared robotic system much complex would expect cognitive abilities well rely multi-scale hierarchy processing thus understanding require explanations reaching level neural connectivity level interrelations functional modules element organisation mutual relationships. second answer connected important issue totally absent small systems issue scaling. simple tasks invite many workable approaches number gets drastically reduced task requirements increase. instance earlier work found postures computer-rendered hand conﬁgurations could rather accurately predicted single monolithic neural trained sufﬁcient number computer generated pictures input known joint angles output values. however found unable generalize pure black-box approach identiﬁcation hand postures real human hands. initial attempts rapidly revealed visual variability real hand much larger computer hand model used previous work. contributing factors higher shape variability also visual eﬀects shadows variability lighting modeled artiﬁcial images. another factor limited amount training data could produced synthetic images generated almost unlimited amounts becomes diﬃcult prepare than thousand real hand images training. finally computer rendered hand image joint angles known construction real images information absent. factors less directly related issues scaling transition computer rendered real images involved signiﬁcant up-scaling image variability; time size available training corpus scaled downward addition learning algorithm adapted workable much restricted training information training information necessity introducing intermediate representation level information obtained separate stage. task intermediate representation twofold represent sensory input features could eﬀectively correlated available training information construct representation data-driven learning. reduce task complexity remaining stages condensing task-relevant information features stable respect non-relevant changes sensory input. third answer closely related issue scaling construction larger systems provides suﬃciently realistic opportunities explore architectural principles organization larger collection functional modules communication. implementation gravis required many places also handcrafted heuristics make things work number general principles proved valuable many situations vertical organization several hierarchically organized processing stages stage modest goal cautious narrowing solution space instead attempting early ﬁnal result horizontal organization several processing streams directed goal used diﬀerent computational strategies proved eﬃcient achieving robustness extensible way. extent work reported useful neuroscience? certainly fully aware work reported make direct contribution modeling biological brain structures themselves since systems provide direct correspondences experimentally observable neural structures. would even claim close correspondence terms functional units interaction patterns. however think approaches kind described useful impression computational challenges problems solved brain explore feasability general computational strategies underlie current hypotheses processing brain system level. example building systems extract posture hands images study diﬀerent representational schemes cope problem representing information complex articulated shape. implemented system permits study strategies multiple processing streams exploited increase robustness. employing learning algorithms train artiﬁcial system upper bounds required number training views order achieve particular recognition accuracy. building actual systems also confronts limitations current learning approaches e.g. need labelled training examples eﬃcient learning often conjunction system surgery train individual modules provides time experimental platform explore ways overcome limitations develop long learning architectures come abilities closer living systems. since abilities self-generated actions well imitation observed actions likely crucial forms real-world learning also need build interactive robot systems exempliﬁed gravis system reported here. illustrated systems permit study biologically motivated computational strategies topographic activity maps attention control behavior-based architectures consisting interconnected networks basis behaviors. again individual modules system cannot matched directly onto putative counterparts brain. despite absence correspondence system gravis permits explore feasability particular computational approaches case map-based attention control within behavior-based architecture inspired current ideas action chains might controlled neural system. robot systems provide useful scratchpad better assessing workability ideas complex perception-action system might achieve observed highly ﬂexible coordination sensing acting capabilities. thus towards clearer picture suﬃcient conditions generate particular capabilities. last least comforting architectural principles line current views brain function prove valuable solution demanding tasks machine perception. thus research", "year": 2004}