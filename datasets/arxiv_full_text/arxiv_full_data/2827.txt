{"title": "Global Model Interpretation via Recursive Partitioning", "tag": ["cs.LG", "cs.AI", "stat.ML"], "abstract": "In this work, we propose a simple but effective method to interpret black-box machine learning models globally. That is, we use a compact binary tree, the interpretation tree, to explicitly represent the most important decision rules that are implicitly contained in the black-box machine learning models. This tree is learned from the contribution matrix which consists of the contributions of input variables to predicted scores for each single prediction. To generate the interpretation tree, a unified process recursively partitions the input variable space by maximizing the difference in the average contribution of the split variable between the divided spaces. We demonstrate the effectiveness of our method in diagnosing machine learning models on multiple tasks. Also, it is useful for new knowledge discovery as such insights are not easily identifiable when only looking at single predictions. In general, our work makes it easier and more efficient for human beings to understand machine learning models.", "text": "general picture model. modern machine models usually trained tested millions data samples. practical researcher review interpretation model diagnostics. whatâ€™s more machine learning models used inform population level decisions economic policy change global eect estimate would helpful thousands local explanations. local global machine learning model interpretation paper going address. interpreting machine learning model globally mean representing trained machine learning model aggregated human understandable way. done extracting important rules model learned training data would apply testing data. rules aect substantial portion data model perspective thus useful inform decision impacting globally data samples. simplest example rules coecients could learn linear regression model. coecients represent magnitude changes output unit change input variables. assumption linear model coecients identical data sample. used widely eect estimation observational studies randomized experiments. another globally interpretable machine learning model decision tree presents decision rules straightforward tree structure. however linear regression decision tree lack high predictive power. means people tradeo between predictability interpretability properties desired. work propose method global interpretation recursive partitioning build global interpretation tree wide range machine learning models based local explanations. recursively partition input variable space maximizing dierence contribution input variables averaged local explanations divided spaces. binary tree call interpretation tree describing decision rules approximation original machine learning model. figure describes work building global model interpretation. trained machine learning model data want explain generate contribution matrix local explanations either using model specic heuristics local model interpreter send contribution matrix global interpretation recursive partitioning algorithm. algorithm returns interpretation tree generally describes machine learning model fully comprehensible human beings. contributions paper follows abstract work propose simple eective method interpret black-box machine learning models globally. compact binary tree interpretation tree explicitly represent important decision rules implicitly contained black-box machine learning models. tree learned contribution matrix consists contributions input variables predicted scores single prediction. generate interpretation tree unied process recursively partitions input variable space maximizing dierence average contribution split variable divided spaces. demonstrate eectiveness method diagnosing machine learning models multiple tasks. also useful knowledge discovery insights easily identiable looking single predictions. general work makes easier ecient human beings understand machine learning models. introduction ough machine learning advances greatly many areas recent years computer vision natural language processing limited interpretability hinders impacting areas require clearer evidence decision making health care economy. domains widely used machine learning models linear regression decision trees people easily understand. deploy cuing-edge machine learning domains transparent mechanisms needed explain sophisticated models users. limited interpretability also harms improving machine learning models. black-box behavior makes dicult diagnose models. without good understanding model works lots eort wasted model parameters tuning. machine learning researchers trying better interpret machine learning models. recent progresses include designing specic neural network structure imposes linear constraints weights input variables decision function using model structure based heuristics decompose prediction scores approximating model linearly local area track predictions using inuence functions back training data however work provide local interpretation. interpretation generated particular sample data. desired want know people also directly build globally interpretable model including additive models predicting pneumonia risk rule sets generated sparse bayesian generative model however models usually specically structured thus limited predictability preserve interpretability. uses queries build tree approximate neural networks. generally discusses presenting machine learning models dierent levels. recursive partitioning resulting tree structure intuitive present rule sets model interactions input variables. used long time analyze heterogeneity subgroup analysis survey data recently applied study heterogeneous causal treatment eects good global model interpretation task want extract rules machine learning model rules aected interactions input variables. feature selection methods select subset important features input variables machine learning model trained. model interpretability could beneted process reduces dimension input variables making model compact easier presented useful input high dimensional feature selection process could either conducted model embedded ough feature selection global model interpretation tasks extract important variables combinations dierent global model interpretation post model process. represent trained model compact comprehensible good delity original model. goal make predictions using representation understand predicts. contrast feature selection discards unimportant variables predictions solely based selected ones. follow cart work build interpretation tree including growing large initial tree pruning using validation best tree size selection. describe tree building process detail introduce contribution matrix method takes input. contribution matrix mentioned local model interpretation methods generate contribution single input variable predicted score specic data sample. detail machine learning model take input variables given data sample generates quantity i-th variable measure importance variable prediction made. call quantity contribution variable data samples total could generate contribution matrix using local model interpretation methods shown table contribution variable predicted score sample contribution matrix represents model thinks variable importances corresponding prediction. propose ecient eective method address literature globally interpreting many machine learning models. interpretation form easily understandable binary tree could used diagnose interpreted model inform population level decisions. cart like algorithm build interpretation tree could model interactions input variables. able heterogeneity variable importances among dierent subgroups data. experiments showcase method discover whether particular machine learning model behaving reasonable overt unreasonable paern. rest paper organized follows. section describes works closely connected work. section presents global interpretation recursive partitioning algorithm. section applies girp computer vision natural language processing health care predictive models structured tabular data. section concludes paper. related work four parts existing work closely related method local model interpretation global model interpretation recursive partitioning eects estimation feature selections. several ways achieve local model interpretation. first people structure model output linear terms input variables weights could used measure importance. example uses neural aention mechanism generate interpretable aention weights recurrent neural networks. however stochastic training process used aentions shown unstable second uses model specic heuristics decompose predicted scores input variables. described methods regularized regression gradient boosted machine. locally approximating sophisticated models using simple interpretable model could explain individual predictions. gradient vector sparse linear methods tried local explainer finally inuence functions robust statistics used track particular prediction back training data responsible conclusion local model interpretation methods work single data sample level generating contributions straightforward obtain contribution matrix features explicit individual contributions could generated along predictions like linear regression however cases need workaround identify variables contributions could aributed analyzing convolutional nerual networks segmentation images generated carry contributions. experiment diagnosing scene classication deep learning method semantic segmentation algorithm applied scene images break semantic meaningful segments well. workarounds problem specic aect formation contribution matrix. growing large initial tree move forward step build interpretation tree growing large initial tree. greedy process cart adopted. input variable could apply split based values variable divide data samples subgroups. note split based input variable value contribution denote input values discriminate contribution type split depends type variable binary split criteria could ordinal could apply criteria constant value. categorical denote subset possible values variable could apply split criteria. convenience assume data samples meet split criteria right subset others subset subsets data samples consider quantity below spliti means split variable term quanties average contribution variable subset second term right subset dierence terms measures dierently variable contributes predicted score larger dierence discriminative model think variable nding maximum could know import variable model perspective. used measure split strength terms variable importance. search possible splits variables best initial split. dividing data sample follow cartâ€™s greedy approach recursively partition child nodes reach pre-set threshold maximum tree depth minimum number samples node. result step would large initial tree explicitly represents discriminative rules model implicitly contains. denote large initial tree pruning greedy approach grow initial tree rules contained initial tree overly optimistic real world problem generalize well. need procedure prune improve generalizability. consider internal nodes nodes contain split split corresponds split value dened equation suppose interpretation tree internal node stands number internal nodes maximize internal nodes need removed nodes less larger nodes would removed resulting tree would simpler vice versa. decide internal nodes remove? dene quantity internal nodes purpose. denote subtree root. quantity intuitively denes average split strength internal nodes subtree dened iteratively remove subtree smallest initial full tree greedy process grow initial tree process would result series nested tree ...tk ...t}. null tree contains node. proved randomly split held-out validation dataset. rest data trained machine learning model contribution matrix; equation split initial node; recursively partition right child nodes full tree reaching maximum tree depth minimum number data samples node; equation calculate average split strength internal node iteratively remove internal nodes smallest split strength series nested tree ...tk ...t}; held-out validation equation calculate gvalidation ...tk ...t}. largest gvalidation selected best sized interpretation tree; select best sized tree decide best sized tree interpretation tree i.e. value best? held-out validation making decision. feed validation data ...tk ...t} calculate internal node choice hyperparameters hyperparameters approach maximum depth interpretation tree minimum number data samples within leaf internal node. mostly chosen empirically depending problem seing. full algorithm generate interpretation tree described table move forward demonstrate multiple datasets using various machine learning models. interpretation tree. first apply proposed global interpretation recursive partitioning algorithm scene understanding deep learning model computer vision. second text classication task words important random forest classier. finally intensive care unit mortality prediction using recurrent neural network medical records demonstrates approach tabular data. cases dierent obtaining contribution matrix. explain detail them. scene understanding many computer vision tasks greatly advanced deep learning scene understanding breakthroughs accuracy help multi-million item labeled dataset large scale deep neural networks however successful neural network architectures computer vision scene understanding neural networks easily understandable trained end-to-end black-box way. whatâ€™s more shows many popular network architectures easily fooled. ough workarounds proposed examine evidence neural predictions single prediction level could eciently used millions training testing data samples. people need tool extract general rules contained model whole data. rules make sense humans could trust models generalize well real world. demonstration understand deep residual network trained scene understanding place dataset specic send images ground truth label kitchen living room bedroom bathroom validation dataset images category trained model collect predicted probabilities four categories. obtain contribution matrix apply scene parsing algorithm dilated convolutional network segment image semantically meaningful parts. perturb part noise re-evaluate perturbed image scene understanding neural network prediction scores four categories. using varying scores contribution semantic part image calculated sparse linear regression model local model interpreter erefore could obtain contribution semantic category prediction scores four scene categories form contribution matrix. figure describes process clearly. geing contribution matrix measures importance semantic category scene categories image could global interpretation recursive partitioning algorithm generate interpretation tree category kitchen living room bedroom bathroom. maximum depth resulting tree node contains least images. results shown figure four levels resulting trees presented space limit. actual best-sized tree usually levels height. node interpretation tree numbers images nodes shown. accuracy number measures proportion images correctly identied ground truth category tree. split variable figure example image four categories bedroom living room kitchen bathroom place scene understanding dataset column image. second column shows semantic categories found semantic segmentation algorithm dilated convolutional network image. column shows actual semantic segmentation contains several superpixels image. using local prediction interpreter could contribution superpixel i.e. semantic category predicted scores. column presents important semantic superpixel highlighted green corresponding ground truth category score respectively. bedroom image superpixels important. living room image sofa window pane replace important. kitchen image cabinet important. finally bathroom image toilet screen door play important role. explanations seem reasonable human being. node also shown. contribution number average contribution split variable right child node. trees kitchen living room bedroom bathroom scenes model cabinet sofa toilet discriminative semantic categories match common sense. besides approach also reveals useful rules model following. example sofa cushion replace combination achieve accuracy identifying living room cabinet stove dishwasher combination gets perfect accuracy kitchen. ndings increase condence black-box residual network based scene understanding deep learning model picking right important object scene make decisions. text classication turn aention text classication task. reports text classiers picking unreasonable words discriminate articles related christianity ones related atheism using subset -newsgroups corpus. showcasing phenomenon randomly picked articles want check corpus level model words unrelated concepts classify articles. purpose proposed approach generate interpretation tree using words articles features. train random forest classier trees achieves accuracy test classify christianity atheism articles. tf-idf vectorizer transfer article vectors send classier. contribution matrix building interpretation tree. local interpreter removing word articles monitoring change predicted score regression evaluating contribution word. running global interpretation recursive partitioning algorithm obtain interpretation tree shown figure maximum tree depth minimum number data samples node results show words found tree related concepts either christianity atheism except christians lower levels. important words pulled posting rutgers look like coincidental fake correlations captured model. reports imbalanced word frequency words classes corpus. model denitely overts paerns would generalize well classifying articles. nding implies would beer practice train robust text classication machine learning models multiple corpora less likely overing corpus specic features. text classication example show girp interpretation tree could used diagnose models overt data reveal incorrectly learned paern. tabular data predicting mortality structured tabular data widely exist kinds relational databases represent various types events transactions. hospitals standardized codes record medical diagnosis procedure pharmacy codes. mimic database kind medical database contains intensive care unit medical records publicly available. apply retain algorithm mimic database predict mortality intensive care unit retain specically designed interpretable recurrent neural network produce contributions past medical events predicted event using neural aention mechanism figure text classication interpretation tree explain random forest model classifying christianity atheism related articles. unfortunately tree model picking unreasonable words posting rutgers important features. could expect generalizability model. right mortality interpretation tree explain recurrent neural network model predicting mortality using past medical records. codes found algorithm relevant high risk mortality. however stochastic optimization process shown contributions stable recurrent neural network model re-trained re-sampling training data. apply proposed global interpretation recursive partitioning global interpretation retain model making sense local interpretations unstable. past diagnosis codes used predict whether patient icu. contribution diagnosis code generated retain along prediction. convenience interpretation aggregate diagnosis codes dierent time frames though retain predicts continuous time series. collect contributions organize contribution matrix. sent girp generate interpretation tree shown figure maximum tree depth minimum number data samples node relevant diagnosis found algorithm convalescence palliative care month indicates mortality making sense diagnosis probably means medical treatments tried doctors nothing patientsâ€™ situation. hand other perinatal jaundice month seems protective factor death icu. also reasonable mostly jaundice life threatening needs emergent care. codes comment rationality lack health care knowledge. however gure help doctors relations medical conditions death well investigated medical practice. proposed method could potentially help discovering important conclusion discussion paper propose simple eective method interpret black-box machine learning models globally local explanations single data samples. global interpretation rened local explanations thus ecient used diagnose trained model extract knowledge show global interpretation recursive partitioning algorithm represent many types machine learning models compact manner. demonstrate algorithms using various kinds machine learning models dierent tasks. shown deep residual network looking right object classifying scenes. contrast text classication interpretation tree indicates random forest classier focusing wrong words discriminate texts dierent topics. besides proposed method also useful extract decision rules sophisticated models. rules hidden black-box models critical know want impact outcome. showcase usage extracting disease comorbidities leading high mortality intensive care unit. conclusion method helps people understand machine learning models eciently making easier check model behaving reasonably make knowledge discovers. however proposed method limited several ways. first lack quantitative measure delity interpretation tree original explained machine learning model. ough alistair johnson pollard shen li-wei lehman mengling feng mohammad ghassemi benjamin moody peter szolovits anthony celi roger mark. mimic-iii freely accessible critical care database. scientic data inuence functions. arxiv preprint arxiv. igor kononenko ecient explanation individual classications using game theory. journal machine learning research benjamin letham cynthia rudin tyler mccormick david madigan interpretable classiers using rules bayesian analysis building beer stroke prediction model. annals applied statistics andy liaw mahew wiener. classication regression random zahra mungloo-dilmohamud yasmina jaufeerally-fakim carlos peËœnareyes. meta-review feature selection techniques context microarray data. international conference bioinformatics biomedical engineering. springer nguyen jason yosinski clune. deep neural networks easily fooled high condence predictions unrecognizable images. proceedings ieee conference computer vision paern recognition. marco tulio ribeiro sameer singh carlos guestrin. trust you? explaining predictions classier. proceedings sigkdd international conference knowledge discovery data mining. zhixiang huang kilian weinberger alice zheng. gradient boosted feature selection. proceedings sigkdd international conference knowledge discovery data mining. chengliang yang chris delcher elizabeth shenkman sanjay ranka. predicting -day all-cause readmissions hospital inpatient discharge data. e-health networking applications services ieee international conference ieee chengliang yang chris delcher elizabeth shenkman sanjay ranka. machine learning approaches predicting high utilizers health care. international conference bioinformatics biomedical engineering. springer interpretation tree directly developed contributions generated original model lose details extract general rules. donâ€™t know important details high predictability. second though present split strength measure variable importance interpretation tree condence measure unknown. linear methods popular evidence based studies partially easier condence interval estimation. complexity underlying probabilistic distributions sophisticated machine learning methods dicult estimate condence intervals split strengths interpretation tree. finally proposed method needs contribution matrix input dicult obtain feature representation input variables well established speech recognition. diculty closely connected broader problem theories information boleneck understanding machine learning models identify important high level features ignore noises. sometimes even explicit feature representation available form contribution matrix group eects features well captured current method. mechanisms similar group lasso could added solve problem. limitations mentioned points good direction future work. want quantify delity interpretation tree explained original model. considering seing bootstrapping methods condence interval estimation direct probabilistic distribution estimation dicult. last representation learning methods could incorporated algorithm contribution matrix dicult obtain. pose exciting challenges making machine learning transparent human beings. martin atzmueller omas roth-berghofer. mining analysis continuum explaining uncovered. research development intelligent systems xxvii. springer david baehrens timon schroeter stefan harmeling motoaki kawanabe katja hansen klaus-robert ËœaË‡zller. explain individual classication decisions. journal machine learning research david bolei zhou aditya khosla aude oliva antonio torralba. network dissection antifying interpretability deep visual representations. arxiv preprint arxiv. rich caruana johannes gehrke paul koch marc sturm noemie elhadad. intelligible models healthcare predicting pneumonia risk hospital -day readmission. proceedings sigkdd international conference knowledge discovery data mining. edward choi mohammad taha bahadori jimeng joshua kulas andy schuetz walter stewart. retain interpretable predictive model healthcare using reverse time aention mechanism. advances neural information processing systems.", "year": 2018}