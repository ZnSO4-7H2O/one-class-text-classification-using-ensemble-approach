{"title": "Randomized Structural Sparsity via Constrained Block Subsampling for  Improved Sensitivity of Discriminative Voxel Identification", "tag": ["cs.CV", "stat.ML", "G.3, I.5.2"], "abstract": "In this paper, we consider voxel selection for functional Magnetic Resonance Imaging (fMRI) brain data with the aim of finding a more complete set of probably correlated discriminative voxels, thus improving interpretation of the discovered potential biomarkers. The main difficulty in doing this is an extremely high dimensional voxel space and few training samples, resulting in unreliable feature selection. In order to deal with the difficulty, stability selection has received a great deal of attention lately, especially due to its finite sample control of false discoveries and transparent principle for choosing a proper amount of regularization. However, it fails to make explicit use of the correlation property or structural information of these discriminative features and leads to large false negative rates. In other words, many relevant but probably correlated discriminative voxels are missed. Thus, we propose a new variant on stability selection \"randomized structural sparsity\", which incorporates the idea of structural sparsity. Numerical experiments demonstrate that our method can be superior in controlling for false negatives while also keeping the control of false positives inherited from stability selection.", "text": "paper consider voxel selection functional magnetic resonance imaging brain data ﬁnding complete probably correlated discriminative voxels thus improving interpretation discovered potential biomarkers. main diﬃculty extremely high dimensional voxel space training samples resulting unreliable feature selection. order deal diﬃculty stability selection received great deal attention lately especially ﬁnite sample control false discoveries transparent principle choosing proper amount regularization. however fails make explicit correlation property structural information discriminative features leads large false negative rates. words many relevant probably correlated discriminative voxels missed. thus propose variant stability selection randomized structural sparsity incorporates idea structural sparsity. numerical experiments demonstrate method superior controlling false negatives also keeping control false positives inherited stability selection. decoding neuroimaging data also called brain reading kind pattern recognition impressive results guessing image subject looking brain activity well medical diagnosis e.g. ﬁnding whether person healthy control patient. pattern recognition typically consists important components feature selection classiﬁer design. predictive classiﬁcation accuracy designed classiﬁers received attention existing literature feature selection even important goal many practical applications including medical diagnosis selected voxels used biomarker candidates however traditional feature selection methods fail discover stable manner complete discriminative features accurately. mainly construct concise classiﬁer often select minimum subset features ignoring correlated redundant informative features addition stability selected features often ignored inclusion noisy features exclusion informative features aﬀect prediction accuracy main objective. therefore large number uninformative noisy voxels carry useful information category label could included ﬁnal feature detection results informative possibly redundant features might missed. paper focus feature selection functional data voxel considered feature. features often correlated redundant. focus completeness stability feature selection i.e. discover many possible informative possibly redundant features accurately stably contrast existing methods mainly subset discriminative features expected uncorrelated. potential biomarkers general three main categories supervised feature selection algorithms ﬁlters embedded methods wrappers ﬁlter methods usually separate feature section classiﬁer development. example fisher score among representative algorithms category. wrapper methods predictive model score feature subsets. subset used train model tested hold-out features scored according predictive power. embedded models perform feature selection learning. words achieve model ﬁtting feature selection simultaneously. following sparsity related feature selection models typical embedded methods mainly focus paper. paper consider commonly used supervised learning identify discriminative brain voxels given training fmri data. classiﬁcation problem considered often regression problem treated similar way. consider following linear model. binary classiﬁcation information rn×p given training fmri data unknown weights reﬂecting degree importance voxel. multivariate inverse inference problem identiﬁcation discriminative voxels based values weight vector importance proportional absolute values components. therefore feature selection also called support identiﬁcation context features corresponding nonzero components considered relevant features. considering common challenge ﬁeld curse dimensionality focusing sparsity-based voxel selection methods sparsity motivated prior knowledge discriminative voxels small portion whole brain voxels hard-to-interpret solutions selected voxels often scattered though might useful concise classiﬁer expected. speciﬁcally highly correlated features small portion representative voxels selected resulting large false negative rate potential biomarker hard trust. addition denote support true sparse vector number nonzeros success ﬁnite sample recovery plain norm regularized model smaller subsets columns design matrix larger must well conditioned. particular design matrix suﬃciently well conditioned correlated columns corresponding noisy subspace thus extend plain sparse learning model incorporate important structural features brain imaging data brain segregation integration order achieve stable reliable interpretable results. mentioned above common hypotheses made fmri sparsity relevant data analysis sparsity compact structure. highly discriminative voxels implied classiﬁcation task; compact structure relevant discriminative voxels grouped several distributed clusters voxels within cluster similar behaviors correspondingly strongly correlated. thus making hypotheses important review state-of-the-art existing works direction. elastic regression tries make voxel correlation adding regularization also called tikhonov regularization classical penalty deal highly correlated features. recently penalties added consider correlated features besides tikhonov regularization example penalization total-variation penalization used simultaneously voxel selection penalization used make assumption activations spatially correlated weights voxels close piece-wise constant. addition ℓ-fusion penalty used successive regression coeﬃcients known vary slowly also interpreted terms correlations successive features cases models based norm certain smoothing penalty might achieve improved sensitivity plain norm regularized model make explicit prior grouping structural information features correspondingly another class methods make explicit segregation integration brain based structured sparsity models proposed extend well-known plain norm regularized models enforcing structured constraints solution. example discriminative voxels grouped together clusters groups often known prior information however many cases grouping information available beforehand either anatomical regions approximation data driven methods obtain grouping information hierarchical agglomerative clustering top-down step prune generated tree hierarchical clusters order obtain grouping information structural sparsity helps select correlated discriminative voxels necessary completeness selected discriminative voxels result feature selection stable likely include many noisy uninformative voxels. years idea ensemble applied reduce variance feature selection result among them important class methods high dimensional data analysis stability selection eﬀective voxel selection structure estimation based subsamplings aims alleviate disadvantage plain norm regularized model either selected chance non-informative regions even worse neglected relevant regions provide duplicate redundant classiﬁcation information part worrying instability potential deceptiveness informative voxel sets information non-local distributed correspondingly major advantage stability selection control false positives i.e. able obtain selection probability threshold based theoretical boundary expected number false positives. addition stability selection sensitive choice sparsity penalty parameter stability selection applied pattern recognition based brain fmri data achieved better results plain norm regularized models example scors application stability selection designed particular characteristics neuroimaging data. notice focusing feature selection here. prediction classiﬁcation accuracy ensemble averaging idea already applied reduce prediction variance examples include bagging methods forests randomized trees order make assumption discriminative voxels often spatially contiguous result distributed clusters proposed idea using common stability selection together clustering speciﬁcally clustering subsampling training samples random rescaling features resampling stability selection. added clustering helps improve conditioning resulted sub-matrices training data matrix. however random rescaling implemented stability selection voxel-wise fails consider spatial contiguity clustered discriminative voxels. paper propose variant stability selection based structural sparsity called randomized structural sparsity. implemented adoption constrained block subsampling technique voxel-wise fmri data analysis contrast single voxel-wise subsampling classical stability selection. expect achieve improved sensitivity selected discriminative voxels. show empirically blocked variant stability selection achieve signiﬁcantly better sensitivity alternatives including original stability selection keeping control false positives voxel selection. need point algorithm beyond simple summation stability selection structural stability. following extra important advantage many cases structural information clustering structures rough approximation i.e. neighboring voxels brain area might highly correlated though necessarily informative a.k.a. discriminative subsampling scheme help remedy supervised reﬁning outlining true shapes discriminative regions showed numerical experiments. compared randomized ward logistic algorithm proposed algorithm needs perform clustering once therefore computationally eﬃcient. rest paper organized follows. section introduce algorithm stable voxel selection. section demonstrate advantages algorithm based synthetic data real fmri data terms higher sensitivity speciﬁcity. section short summary work possible future research directions given. denote fmri data matrix rn×p number samples number voxels corresponding classiﬁcation information rn×. consider binary classiﬁcation main ideas applied models take following sparse logistic regression classiﬁcation example show existing diﬃculties corresponding eﬀorts detail. structured sparsity models beyond plain norm regularized models proposed enforce structured constraints solution structure deﬁned based feature correlation. important special case common make clustering grouping structure adopt group sparsity induced norm follows. grouping information. compared main difference regularization term; using mixed norm. model belongs family structural sparsity regularized feature selection models. resulting penalty incorporating parcellation information shown improve prediction performance interpretability learned models provided grouping structure relevant addition number selected candidate features allowed much larger additional group structure incorporated particularly group contains considerable redundant features therefore parcellation able help improve sensitivity voxel selection however group sparsity-induced norm regularized model expected improve sensitivity respect plain norm regularized model adopted mixed norm grouping information reliable enough. obtaining appropriate might possible practice either prior anatomical knowledge data-driven methods based voxel correlation. however many methods obtaining incorporating available classiﬁcation labelling information. therefore possible subset voxels certain group discriminative. case model often fails make segmentation likely simultaneously choose voxels certain group simultaneously choose none them adoption norm. addition like plain norm regularized model diﬃculties choosing proper regularization parameter lack ﬁnite sample control false positives still exist. mentioned above eﬀective control false positives reduce diﬃculty choosing proper regularization parameter applying sparsity regularization based models stability selection applied voxel selection connection selection brain image analysis however control false positives achieved large false negative rate often expected especially case redundant correlated voxels correlation prior explicitly taken consideration. paper stably identify discriminative voxels including probably correlated ones better interpretation discovered potential biomarkers. achieve goal incorporate spatial structural knowledge voxels stability selection framework. novelty research propose randomized structural sparsity aims integrate stability selection common structural sparsity. important component randomized structural sparsity subsampling based stability selection rather original reweighting-based stability selection shown former likely yield improvement latter whenever latter improves standalone pure regularization model moreover subsampling easier extend block subsampling combine structural sparsity. ﬁrst brieﬂy explain subsampling-based stability. training data matrix rn×p subsampling based stability selection consists applying baseline i.e. pure regularization model random submatrices size rounded nearest integer number returning features largest selection frequency. original stability selection roughly considered special case except original stability selection reweighs feature random weight uniformaly sampled positive number subsampling intuitively seen crude version simply dropping randomly large part features important component randomized structural sparsity incorporate structural information parcelling information brain consideration. kind partition information based either prior anatomical knowledge brain partition clustering results based fmri data done structural sparsity model randomized structural sparsity general concept might diﬀerent speciﬁc implementations practice depending different data types applications. voxel-wise fmri data analysis propose speciﬁc implementation named constrained block subsampling constrained mean parcelling information respected certain degree. block subsampling adopted speciﬁcally cluster consists highly correlated voxels. block subsampling selected voxels cluster considered group. particular chosen voxels lying cluster noted addition order make every brain partition especially small sizes chance sampled block subsampling borrow idea proportionate stratiﬁed sampling i.e. sampling fraction used within partition. purpose reduce false negatives especially sizes diﬀerent partitions quite range. correspondingly solve following group-sparsity based recovery model. corresponding parts respectively based selected voxels subsampling predeﬁned partitions brain based either biological knowledge data driven learning estimation clustering. indices selected samples current subsampling. notice constrained block subsamplings respects prior knowledge also provides ﬂexibility resulting discriminative regions shape ﬁnal selected voxels cluster portion subsampling makes selection frequency score able outline shapes true discriminative regions whose sizes exactly sizes original partitions deﬁned kind ﬂexibility important neighboring voxels belonging brain area necessarily signiﬁcantly discriminative voxels though might highly correlated. words seek sets correlated voxels similar associations response part correlated features similar association response mentioned furthermore case small samples high dimensional feature space need consider bias-variance dilemma bias-variance tradeoﬀ general would like little bias save variance dimensionality reduction decrease variance simplifying models correspondingly still baseline subproblem stability selection framework prefer simple averaging idea applied showed variables features positively correlated average strong feature yielded lower variance individual variables. speciﬁcally averaging voxels picked block subsampling lying group single super-voxel model reduced following dimensional version number clusters. ˜wg′ average voxels subset cluster corresponding averaged thus number variables sparse recovery model greatly reduced number clusters. resulted recovery problem much smaller scale therefore solved quite eﬃciently. addition properties resulting data matrix greatly improved de-correlation clustering correlated columns. analysis better-posed compatibility constant proposed idea averaging also called feature agglomeration also applied j-th column selected large magnitude represented picked blocked voxels lying group counted selected non-clustered space. corresponding score updated notice averaging subsamplings simple spatial smoothing diﬀerent sumsampling results diﬀerent stability selection iterations. therefore boundaries detected discriminative regions trusted certain accuracy. ﬁrst obtain structural information brain. perform data-driven clustering operation partition voxels many patches according strong local correlations. algorithm common k-means spatially constrained spectral clustering algorithm implemented written python software used experiments. denote groups clustering algorithm whose cardinality denoted usually much less comparable notice number unknowns reduced number clusters i.e. number samples fraction total samples example paper typically choose least times larger number samples smaller times number samples practice. next comes constrained block subsamplings. denote number resamplings blocked variant stability selection diﬀerent classical stability selection terms subsampling features i.e. columns data matrix shares classical stability selection performing subsampling observations i.e. rows data matrix subsampling fraction denote indices selected rows cardinality rounded nearest integer number. contrained block subsamplings applied voxels i.e. columns mentioned last section. notice algorithm runs clustering following constrained block subsamplings resulted much smaller size problem number unknows equal number clusters. therefore algorithm computationally expensive. mainly random subsampling observations i.e. rows paper also pointed random subsampling terms observations general guarantee ﬁnite control false positives even though diﬀerent base methods adopted. therefore using complicated base method plain norm regularized model ﬁnite control false positives still achieved. however corresponding theoretical result terms bounding ratio expected number false positive selections natural adopt structural sparsity regularized models base methods stability selection. pointed regularization term incorporating parcellation information shown improve interpretability learned models detection sensitivity voxel selection functional data provided parcellation information quite relevant. however parcellation information might accurate. ﬁxed brain parcellation indeed might bring certain degree bias arbitrariness. paper turn help block subsamplings. present intuitive explanation section thorough study eﬀect block subsampling reducing arbitrariness presented paper constitutes important future research topic. need point method proposed suﬀers bias caused ﬁxed parcellatoin clustering performed step stability selection randomized rescaling feature. however computational point view adopted onetime parcellation helps improve computational eﬃciency clustering takes large proportion running times algorithm algorithm preliminary comparison running time diﬀerent algorithms presented section paper compare algorithm classical univariate voxel selection method state-of-the multi-voxel pattern recognition methods including t-test ℓ-svm logistic regression ℓ-svm logistic regression randomized logistic regression smooth lasso tv-l randomized ward logistic randomized logistic regression based original stability selection random reweighing features. eﬃcient projections) software randomized logistic regression written based available logistic regression code. randomized ward logistic implemented python integrated nilearn great python software neuroimaging analysis http//nilearn.github.io/index.html. kindly provided source code developers. hyper-parameters regularization parameters choices mostly based cross validation unless speciﬁed otherwise. algorithm block size might aﬀect performance algorithm given number blocks inherent trade-oﬀ choice block size. limited number randomizations allowed blocks likely match geometry true support easily result many false positives. condition small blocks likely result many false negatives likely ignorance local correlations neighboring voxels. block size optimized following experiments probable prior knowledge discriminative regions still achieves impressive performance. synthetic data real fmri data experiment respectively. subsampling rate synthetic data real fmri data total resamplings respectively. resampling number random logistic regression experiments. choice number resamplings empirical here. would like demonstrate method achieve better control false positives false negatives alternative methods incorporation stability selection structural sparsity. synthetic data directly precision-recall curve since know true discriminative features. precision fraction retrieved instances relevant recall fraction relevant instances retrieved. also plot ﬁrst discriminative voxels discovered diﬀerent algorithms number true discriminative features. provides snapshot display many noisy features included selected features diﬀerent algorithms. real fmri data ﬁrst show brain maps obtained feature weights thresholded visualization purposes meaning zeros obtained actually zeros. able determine discriminative regions revealed diﬀerent algorithms based visual inspection. addition vision inspection experience would also like objective threshold. general voxels whose corresponding weights larger magnitude threshold considered discriminative voxels shown brain maps. however setting threshold value quite diﬃcult adopt diﬀerent schemes diﬀerent situations. study threshold setting reach paper consider cross-validation based prediction accuracy threshold value corresponding highest prediction accuracy. however pointed prediction accuracy variable selection diﬀerent goals. different features might result level classiﬁcation accuracy. therefore often acceptable develop heuristic setting threshold value feature selection beyond cross validation method another kind important method threshod value based control multivariate p-values main feature algorithm improved sensitivity maintaining good speciﬁcity. order prove extra probably discriminative regions discovered algorithm true stable positives adopt following methods. take extra selected voxels construct classiﬁer perform classiﬁcation test data. satisfying classiﬁcation accuracy least prove existence true positiveness. notice that mentioned prediction accuracy reliable criterion model selection high prediction accuracy generally tell least portion voxels truly discriminative. high prediction accuracy achieved likely believe corresponding brain regions discriminative though sizes might accurate. perform false positive estimation scheme based permutation test order calculate ratio false positives among ﬁnally selected voxels simulated simple case control analysis model work brain images including voxels interest. generated observations group i.e. control group case group. discriminated clustered features total voxels frontal lobe parietal lobe occipital lobe subcortical regions. cluster contained voxels showed figure yellow. elements ﬁrst clustered features representing index persons group representing index ﬁrst clustered features representing index features cluster. gaussian i.i.d distributed. elements three clustered features spatially distributed patterns gaussian i.i.d distributed constrained linear condition representing index persons group representing index last three clustered features representing index features cluster. above also gaussian i.i.d distributed. features spatially clustered diﬀerent brain regions. also simulated voxels whole brain image gaussian noise. notice distributed multivariate discriminative patterns consists voxels last clusters respectively. clustering algorithm used algorithm k-means number clustering equal would like show method achieve accuracy completeness terms discovery discriminative features. accuracy means small false positive rate completeness means small false negative rate. figure precision-recall curve demonstrate advantage method. precision fraction retrieved instances relevant recall fraction relevant instances retrieved. still keeping good control false positives algorithm together randomized ward logistic sensitive i.e. discovering alcomplete discriminative features. notice standard stability selection i.e. randomized algorithm work well case. figure plot identiﬁed discriminative voxels corresponding weights largest magnitude diﬀerent involved algorithms number true discriminative voxels displayed subplot upper-right corner. algorithm together randomized ward logistic algorithm discover clustered true positive features others. moreover algorithm computationally eﬃcient randomized ward logistic clustering once. notice synthetic data therefore hard visualize performance comparison algorithm directly displaying precision-recall curve figure nevertheless figure useful supplement illustration performance achieved sensitivity speciﬁcity diﬀerent voxel-selection algorithms. experiment identify brain activation pattern chinese-chess problem-solving task professional chinese-chess grandmasters. masters chinese chess recruited studied. subjects right-handed history psychiatric neurological disorder. fmri scanning subjects presented kinds stimuli blank chessboard patterns chinese chess spot game checkmate problems. condition presented s-long break between. block repeated nine times diﬀerent problems block. break block also blocks overall. consideration delay blood oxygenation level dependent eﬀect hypothesis master solve problem less selected th-th images state block classiﬁcation. number observations subject classiﬁcation among blank states task states. used averaged data grandmasters. data acquisition preprocessing scanning performed siemens trio system research center west china hospital sichuan university chengdu china. t-weighted fmri images obtained gradient-echo echo-planar pulse sequence voxel size=. mm). fmri images preprocessed using statistical parametric mapping- spatial transformation included realignment normalization performed using three-dimensional rigid body registration head motion. realigned images spatially normalized standard stereotaxic space using montreal neurological institute echoplanar imaging template. spatial smoothing ﬁlter employed brains three-dimensional volume convolution isotropic gaussian kernel increase signal-to-noise ratio. then fmri time series task condition high-pass ﬁlter cut-oﬀ used remove low-frequency noise. among fmri samples size clustering algorithm used algorithm k-means number clusters equal figure shows brain maps based weights scores voxels different algorithms. scores thresholded visualization purposes meaning zeros obtained actually zeros. observe despite fairly noisy signiﬁcant localized discriminative regions brain identiﬁed diﬀerent algorithms visually recognized. even number selected voxels method expected achieve best balance controlling false positives false negatives. general identifying potential biomarkers controlling false positives ﬁrst priority. need treated carefully controlled strictly. need threshold value ﬁlter least apparent noisy features either scattered wrong regions existing conﬁrmed knowledge. carefully threshold values results diﬀerent algorithms order control false positives obtain cleaner brain map. notice experiments common threshold-setting method based prediction accuracy cross validation work well simple cognitive task involvement many noisy features using small number true positives also achieve nearly accuracy. figure result thresholding apparent noisy features either scattered unreasonable area. false positives expected well controlled. algorithm sensitive identiﬁed several extra brain regions. construct classiﬁers based extra regions test predictive power. accurate extra regions likely relevant. take look result figure viewpoint brain science. multivariate pattern feature selection methods successfully identiﬁed least partial task-related prefrontal parietal occipital lobe regions. results indicate co-working pattern cognitive network default mode network human brain board game task state. however compared alternative algorithms besides common stability selection proposed method identiﬁes much brain regions medial prefrontal cortex precuneus gyrus functional structural central hubs default mode network occipital lobe contains parts visual cortex. common stability selection i.e. randomized logistic regression able identify medial prefrontal gyrus misses precuneus. moreover common stability selection likely return result slightly scattered match second hypothesis continuousness compactness. even greater concern fact scattered results make diﬃcult distinguish true positives false positives. addition common stability selection required many subsamplings example times compared method takes subsamplings. result veriﬁes main advantages method namely computational eﬃciency especially important high dimensional problems. section present running time comparison diﬀerent algorithms. method also better inference quality incorporation prior structural information fmri data. mentioned before computational eﬃciency also comes even smaller size subproblem adoption averaging idea within cluster. figure score maps estimated diﬀerent methods fmri datasets using ﬁrst sessions training data. despite fairly noisy located discriminative brain regions diﬀerent algorithm well highlighted. also test algorithm public block-design fmri dataset study face object representation human ventral temporal cortex downloaded http//data.pymvpa.org/datasets/haxby/. figure score maps estimated diﬀerent methods fmri datasets using ﬁrst sessions training data. threshold determined based crossvalidation highest prediction accuracy. algorithm achieve best performance ﬁnding larger number true discriminative voxels alternatives keeping false positives level. alternatives large number false positives except randomized ward logistic method however ﬁnds small number true discriminative voxels although estimated false positives consists subjects runs subject. subjects passively viewed greyscale images eight object categories grouped blocks separated rest periods. image shown followed inter-stimulus interval. full-brain fmri data recorded volume repetition time stimulus block covered roughly volumes. complete description experimenfigure score maps estimated diﬀerent methods fmri datasets using ﬁrst sessions training data. despite fairly noisy located discriminative brain regions diﬀerent algorithm well visually recognized. design fmri acquisition parameters previously obtained results reference smoothing operation data. paper consider fmri data ﬁrst subject classifying house consists sessions total. number samples ﬁrst sessions number training samples evenly increases number sessions adopt spatially constrained spectral clustering algorithm implemented python software pyclusterroi number clustering number sessions evenly increases number sessions figure score maps estimated diﬀerent methods fmri datasets using ﬁrst sessions training data. threshold determined based crossvalidation highest prediction accuracy. algorithm achieve best performance ﬁnding large number true discriminative voxels alternatives keeping false positives level. alternatives larger number false positives except randomized ward logistic method however ﬁnds small number true discriminative voxels although estimated false positives ﬁrst sessions training samples perform feature selection obtain prediction score selected features remaining sessions used test samples. limited length paper show brain maps obtained ﬁrst sessions training data. figures brain maps based scores diﬀerent methods ﬁrst sessions respectively. scores thresholded visualization purposes. figures show thresholded maps diﬀerent algorithms ﬁrst sessions training data respectively. threshold values diﬀerent algorithms diﬀerent. t-test based common requirement p-value less control. rest methods based cross-validation linear ℓ-svm classiﬁer used remaining sessions used test data. candidate threshold value corresponding best prediction accuracy algorithm chosen. speciﬁcally algorithm almost threshold-setting procedure python code randomized ward logistic algorithm basically ﬁrst rank voxels according selection scores thresholds step size select ﬁnal threshold value corresponding high classiﬁcation accuracy testing general algorithm among sensitive table prediction accuracy classiﬁer voxels selected subtract selected methods respectively. ﬁrst sessions training data rest sessions test data. algorithms. order test whether extra voxels selected algorithm convincing prediction power build logistic regression classiﬁcation model based extra voxels prediction accuracy resulted classiﬁer listed table extra voxels selected method give high classiﬁcation accuracy showing least part extra selected voxels could relevant voxels task. following paragraph explain validate trueness discovered discriminative voxels viewpoint neuroscience. results threshold unthreshold maps show phenomenon described original case study included. area mean response regions across categories selected consistency common regions within diﬀerent cluster settings axial view. unthresholded mapping contours quite similar diﬀerent numbers clusters leftmost column; thresholded mapping selected features near positions. variant stability selection algorithm maintains ﬁnite sample control false positives. algorithm’ advantage improved sensitivity feature selection comparing alternatives. since ground truth evaluation tested whether detected voxels regions various algorithms stable unlikely false positives. adopting false positive estimate scheme used based permutation test cross validation. figure result algorithm shows selection voxels likely false positives. tv-l smooth lasso found larger number discriminative voxels respecno. selected means number selected voxels thresholding table using ﬁrst sessions. no.false positives number probable false positives among selected voxels estimated permutation test cross-validation suggested tively also voxels respectively likely false positives. even original stability selection i.e. rand estimated false positives among selected discriminative voxels. l-svm l-logistic also around estimated false positives. ttest false positives. algorithm shares common components randomized ward logistic algorithm results quite diﬀerent. randomized ward logistic method conservative terms controlling false positives least default settings. selected voxels false positives false positive estimate scheme. however reveals discriminative voxels. conservation case even observed unthresholded figures contrast algorithm ﬁnds large number true discriminative voxels keeps false positives level. summary result table look predictive power best selected voxels diﬀerent algorithms. prediction results reported figure consider pick sessions training data remaining sessions test data randomly pick sessions sessions consider possible combinations. average prediction accuracy among combinations presented. algorithm among achieve highest predictive accuracy. notice randomized ward logistic reveals small number discriminative voxels prediction accuracy also high. high predictive accuracy directly prove sensitivity speciﬁcity feature selection results still suggests quality identiﬁcation voxels diﬀerent algorithm degree. least prediction experiments performed windows matlab running desktop intel core quad-core processor processor base frequency .ghz memory though parallel implementations involved algorithms. listed running time different algorithms test problems based chess-master data haxby cognitive task data table list running smooth lasso ℓ-svm logistic regression t-test general take much shorter time listed algorithms. notice random ward clustering algorithm written python algorithm written matlab. python general computationally eﬃcient computer language matlab. advantage algorithm terms computational eﬃciency comparing random ward clustering algorithm remarkable. notice random ward clustering algorithm running time signiﬁcant longer chessmaster test problem haxby test problem. number features chess-master test problem number features haxby test problem spatially constrained ward clustering method used random ward clustering algorithm empirically takes notably much longer time number features increases. random ward clustering algorithm take longer time alternative algorithms expected running time still acceptable general. finally would like point random ward clustering algorithm tv-l algorithms directly default settings provided python software. computational eﬃciency could much diﬀerent diﬀerent parameters used. presented running time diﬀerent algorithms rough reference. voxel selection important decoding fmri data. paper propose simple computationally eﬃcient method data-driven voxel selection also called support identiﬁcation potential biomarker extraction propose randomized structural sparsity structural variant classical stability selection speciﬁc implementation constrained block subsamplings. apply existing sparse multi-variate classiﬁers logistic regression case fmri data strong correlations distributed multivariate discriminative patterns. however results mostly empirical might need perform theoretical support order better understand advantages address limitations. example theoretical results false positive rate false negative rate feature selection algorithm need presented future work. addition need study possible bias arbitraries brought one-time parcellation. moreover would like hierarchical ward clustering spatially constraints algorithm future. showed general ward’s clustering performs better alternative methods regard reproducibility accuracy furthermore eﬀectively distinguish true positives false positives needs better addressed. thanks prof. alexandre gramfort telecom paristech kindly providing python smooth lasso tv-l code integration nilearn package. thanks ga¨el varoquaux parietal team inria kindly providing randomized ward logistic algorithm written python. would also like thank anonymous reviewers many constructive suggestions greatly improved paper. work supported programs project natural science foundation china specialized research fund doctoral program higher education china fundamental research funds central universities", "year": 2014}