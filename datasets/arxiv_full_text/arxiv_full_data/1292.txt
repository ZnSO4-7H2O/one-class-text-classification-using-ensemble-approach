{"title": "End to End Learning for Self-Driving Cars", "tag": ["cs.CV", "cs.LG", "cs.NE"], "abstract": "We trained a convolutional neural network (CNN) to map raw pixels from a single front-facing camera directly to steering commands. This end-to-end approach proved surprisingly powerful. With minimum training data from humans the system learns to drive in traffic on local roads with or without lane markings and on highways. It also operates in areas with unclear visual guidance such as in parking lots and on unpaved roads.  The system automatically learns internal representations of the necessary processing steps such as detecting useful road features with only the human steering angle as the training signal. We never explicitly trained it to detect, for example, the outline of roads.  Compared to explicit decomposition of the problem, such as lane marking detection, path planning, and control, our end-to-end system optimizes all processing steps simultaneously. We argue that this will eventually lead to better performance and smaller systems. Better performance will result because the internal components self-optimize to maximize overall system performance, instead of optimizing human-selected intermediate criteria, e.g., lane detection. Such criteria understandably are selected for ease of human interpretation which doesn't automatically guarantee maximum system performance. Smaller networks are possible because the system learns to solve the problem with the minimal number of processing steps.  We used an NVIDIA DevBox and Torch 7 for training and an NVIDIA DRIVE(TM) PX self-driving car computer also running Torch 7 for determining where to drive. The system operates at 30 frames per second (FPS).", "text": "trained convolutional neural network pixels single front-facing camera directly steering commands. end-to-end approach proved surprisingly powerful. minimum training data humans system learns drive trafﬁc local roads without lane markings highways. also operates areas unclear visual guidance parking lots unpaved roads. system automatically learns internal representations necessary processing steps detecting useful road features human steering angle training signal. never explicitly trained detect example outline roads. compared explicit decomposition problem lane marking detection path planning control end-to-end system optimizes processing steps simultaneously. argue eventually lead better performance smaller systems. better performance result internal components self-optimize maximize overall system performance instead optimizing human-selected intermediate criteria lane detection. criteria understandably selected ease human interpretation doesn’t automatically guarantee maximum system performance. smaller networks possible system learns solve problem minimal number processing steps. used nvidia devbox torch training nvidia drivetm self-driving computer also running torch determining drive. system operates frames second cnns revolutionized pattern recognition prior widespread adoption cnns pattern recognition tasks performed using initial stage hand-crafted feature extraction followed classiﬁer. breakthrough cnns features learned automatically training examples. approach especially powerful image recognition tasks because convolution operation captures nature images. also using convolution kernels scan entire image relatively parameters need learned compared total number operations. cnns learned features commercial twenty years adoption exploded last years recent developments. first large labeled data sets large scale visual recognition challenge become available training validation. second learning algorithms implemented massively parallel graphics processing units tremendously accelerate learning inference. paper describe goes beyond pattern recognition. learns entire processing pipeline needed steer automobile. groundwork project done years defense advanced research projects agency seedling project known darpa autonomous vehicle sub-scale radio control drove junk-ﬁlled alley way. dave trained hours human driving similar identical environments. training data included video cameras coupled left right steering commands human operator. many ways dave- inspired pioneering work pomerleau built autonomous land vehicle neural network system. demonstrated end-toend trained neural network indeed steer public roads. work differs years advances apply data computational power task. addition experience cnns lets make powerful technology. dave demonstrated potential end-to-end learning indeed used justify starting darpa learning applied ground robots program dave’s performance sufﬁciently reliable provide full alternative modular approaches off-road driving. dave’s mean distance crashes meters complex environments. nine months effort started nvidia sought build dave create robust system driving public roads. primary motivation work avoid need recognize speciﬁc human-designated features lane markings guard rails cars avoid create collection then else rules based observation features. paper describes preliminary results effort. figure shows simpliﬁed block diagram collection system training data dave-. three cameras mounted behind windshield data-acquisition car. time-stamped video cameras captured simultaneously steering angle applied human driver. steering command obtained tapping vehicle’s controller area network bus. order make system independent geometry represent steering command turning radius meters. instead prevent singularity driving straight smoothly transitions zero left turns right turns training data contains single images sampled video paired corresponding steering command training data human driver sufﬁcient. network must learn recover mistakes. otherwise slowly drift road. training data therefore augmented additional images show different shifts center lane rotations direction road. images speciﬁc off-center shifts obtained left right camera. additional shifts cameras rotations simulated viewpoint transformation image nearest camera. precise viewpoint transformation requires scene knowledge don’t have. therefore approximate transformation assuming points horizon ground points horizon inﬁnitely away. works terrain introduces distortions objects stick ground cars poles trees buildings. fortunately distortions don’t pose problem network training. steering label transformed images adjusted would steer vehicle back desired location orientation seconds. block diagram training system shown figure images computes proposed steering command. proposed command compared desired command image weights adjusted bring output closer desired output. weight adjustment accomplished using back propagation implemented torch machine learning package. training data collected driving wide variety roads diverse lighting weather conditions. road data collected central jersey although highway data also collected illinois michigan pennsylvania york. road types include two-lane roads residential roads parked cars tunnels unpaved roads. data collected clear cloudy foggy snowy rainy weather night. instances resulting glare reﬂecting road surface scattering windshield. data acquired using either drive-by-wire test vehicle lincoln using ford focus cameras placed similar positions lincoln. system dependencies particular vehicle make model. drivers encouraged maintain full attentiveness otherwise drive usually march hours driving data collected. train weights network minimize mean squared error steering command output network command either human driver adjusted steering command off-center rotated images network architecture shown figure network consists layers including normalization layer convolutional layers fully connected layers. input image split planes passed network. ﬁrst layer network performs image normalization. normalizer hard-coded adjusted learning process. performing normalization network allows normalization scheme altered network architecture accelerated processing. convolutional layers designed perform feature extraction chosen empirically series experiments varied layer conﬁgurations. strided convolutions ﬁrst three convolutional layers stride kernel non-strided convolution kernel size last convolutional layers. follow convolutional layers three fully connected layers leading output control value inverse turning radius. fully connected layers designed function controller steering note training system end-to-end possible make clean break parts network function primarily feature extractor serve controller. ﬁrst step training neural network selecting frames use. collected data labeled road type weather condition driver’s activity train lane following select data driver staying lane discard rest. sample video fps. higher sampling rate would result including images highly similar thus provide much useful information. selecting ﬁnal frames augment data adding artiﬁcial shifts rotations teach network recover poor position orientation. magnitude perturbations chosen randomly normal distribution. distribution zero mean standard deviation twice standard deviation measured human drivers. artiﬁcially augmenting data undesirable artifacts magnitude increases simulator takes pre-recorded videos forward-facing on-board camera human-driven data-collection vehicle generates images approximate would appear were instead steering vehicle. test videos time-synchronized recorded steering commands generated human driver. since human drivers might driving center lane time manually calibrate lane center associated frame video used simulator. call position ground truth. simulator transforms original images account departures ground truth. note transformation also includes discrepancy human driven path ground truth. transformation accomplished methods described section simulator accesses recorded test video along synchronized steering commands occurred video captured. simulator sends ﬁrst frame chosen test video adjusted departures ground truth input trained cnn. returns steering command frame. steering commands well recorded human-driver commands dynamic model vehicle update position orientation simulated vehicle. simulator records off-center distance distance traveled virtual car. off-center distance exceeds meter virtual human intervention triggered virtual vehicle position orientation reset match ground truth corresponding frame original test video. simulation networks provide steering commands simulator ensemble prerecorded test routes correspond total three hours miles driving monmouth county test data taken diverse lighting weather conditions includes highways local roads residential streets. estimate percentage time network could drive metric determined counting simulated human interventions interventions occur simulated vehicle departs center line meter. assume real life actual intervention would require total seconds time required human retake control vehicle re-center restart self-steering mode. calculate percentage autonomy counting number interventions multiplying seconds dividing elapsed time simulated test subtracting result figure screen shot simulator interactive mode. section explanation performance metrics. green area left unknown viewpoint transformation. highlighted wide rectangle horizon area sent cnn. trained network demonstrated good performance simulator network loaded drivetm test taken road test. tests measure performance fraction time performs autonomous steering. time excludes lane changes turns road another. typical drive monmouth county ofﬁce holmdel atlantic highlands autonomous approximately time. also drove miles garden state parkway zero intercepts. figures show activations ﬁrst feature layers different example inputs unpaved road forest. case unpaved road feature activations clearly show outline road case forest feature maps contain mostly noise ﬁnds useful information image. demonstrates learned detect useful road features human steering angle training signal. never explicitly trained detect outlines roads example. figure sees unpaved road. subset camera image sent cnn. bottom left activation ﬁrst layer feature maps. bottom right activation second layer feature maps. demonstrates learned detect useful road features human steering angle training signal. never explicitly trained detect outlines roads. empirically demonstrated cnns able learn entire task lane road following without manual decomposition road lane marking detection semantic abstraction path planning control. small amount training data less hundred hours driving sufﬁcient train operate diverse conditions highways local residential roads sunny cloudy rainy conditions. able learn meaningful road features sparse training signal system learns example detect outline road without need explicit labels training. work needed improve robustness network methods verify robustness improve visualization network-internal processing steps.", "year": 2016}