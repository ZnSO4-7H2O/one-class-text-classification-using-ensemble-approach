{"title": "A practical approach to dialogue response generation in closed domains", "tag": ["cs.CL", "cs.NE"], "abstract": "We describe a prototype dialogue response generation model for the customer service domain at Amazon. The model, which is trained in a weakly supervised fashion, measures the similarity between customer questions and agent answers using a dual encoder network, a Siamese-like neural network architecture. Answer templates are extracted from embeddings derived from past agent answers, without turn-by-turn annotations. Responses to customer inquiries are generated by selecting the best template from the final set of templates. We show that, in a closed domain like customer service, the selected templates cover $>$70\\% of past customer inquiries. Furthermore, the relevance of the model-selected templates is significantly higher than templates selected by a standard tf-idf baseline.", "text": "amazon already collection ‘blurbs’ copy paste replies. however blurbs centrally managed particular agent unannotated number thousands. practice overhead searching right blurb agent uses handful blurbs regularly. therefore approach response generation two-fold problem determining templates created based past agent replies customer questions choosing correct template response inquiry. template-based approach addresses issues affect existing dialogue generation systems namely relevance text quality diversity need annotated customer intents. templates extract ﬁltered high relevance speciﬁcity corrected consistency tone enriched addition slots customer proﬁle metadata forms context. furthermore ﬁxed templates allows better tune text-tospeech systems produce natural-sounding speech. built prototype response generation model based online chats customers agents evaluated random sample past chat conversations. showed selected templates cover large portion past customer inquiries human evaluators preferred model-selected templates templates retrieved tf-idf baseline. system customer-facing conclude discussing work remaining. recently deep learning-based systems question answering dialogue focus academic industrial research. dialogue systems vinyals serban demonstrated encoder-decoder networks lstm units generate dialogue based help desk movie script corpuses. question answering problems sukhbaatar able achieve competitive performance so-called babi tasks memory networks limited supervision last year google launched smart reply email response recommendation system recommends short replies gmail volume inbox mobile application google’s messaging allo also uses technology recommend responses mobile chats. paper applied siamese-like network encoders build response generation system subset customer service chats related item delivery problems. context information retrieval lowe also used similar network retrieve next reply corpus ubuntu technical help chats. describe prototype dialogue response generation model customer service domain amazon. model trained weakly supervised fashion measures similarity customer questions agent answers using dual encoder network siamese-like neural network architecture. answer templates extracted embeddings derived past agent answers without turn-by-turn annotations. responses customer inquiries generated selecting best template ﬁnal templates. show that closed domain like customer service selected templates cover past customer inquiries. furthermore relevance model-selected templates signiﬁcantly higher templates selected standard tf-idf baseline. index terms dialogue response generation human-computer interaction conversational agents millions shoppers contact amazon’s customer service department every year customers choose telephone online chat email channels. customers contact amazon telephone especially laborintensive form communication. need agent labor highly seasonal hiring agents requires signiﬁcant ramp-up time training. furthermore amazon’s order volume increases signiﬁcantly year-over-year makes scaling customer service sub-linearly order volume especially crucial. machine learning dialogue generation provide opportunity make existing agents efﬁcient allow total automation issue resolution present ﬁrst steps towards practical dialogue system customer service domain amazon. work focus solely response generation module system given customer inquiry generate text response likely answers question asked. effective dialogue system would automate handling large percentage customer interactions potentially generating signiﬁcant savings labor costs reducing perceived response times customers allowing customer service scale better increasing demand. well-established domains like customer service large human-generated corpuses already exist. indeed amazon’s internal online chat corpus rich source data building response generation model independently transcribed speech past phone calls. amazon’s chat corpus also contains customer-selected issue labels order-related entities etc. corpus model training experiments. open domain dialogue generation remains topic ongoing research hypothesize closed domains like ﬁnite response templates would cover vast majority interactions. fact customer service agents across system generate replies ﬁxed templates need perform beam search generate text directly. simpliﬁes engineering effort required deployment speeds response generation since responses longer token limit inbox suggests. secondly clustering techniques manual inspection extract initial templates perform clustering fully automatic fashion without need intent clusters initialized human expertise. clustering around pre-speciﬁed intents important open domain corpus like emails since would huge number topic clusters dataset whereas closed domains less important. paper organized follows section provides details dual encoder network model. section discusses create pool template answers dual encoder network model selects from. section presents evaluations system section discusses future improvements. used year amazon customer service chat transcripts item delivery issues creating training data. text split agent customer turns tokenized ﬁltered sensitive customer information converted lowercase. extract meaningful question-answer pairs select every customer turn conversation ends question mark; agent turn considered correct reply. matching pairs constitute positive samples. create non-matching pairs customer questions question randomly select agent turn follows customer question corpus. created million training samples positive negative ratio training dataset. dataset extracted small fraction total contact volume handled year. table shows positive negative examples training data. answer separate lstm encoders. encoders generate dimensional embeddings question answer. embeddings concatenated passed multi-layer perceptron outputs probability question answer match. lstm networks widely used encoding sentences dimensional embeddings various nlprelated tasks. showed lstm’s achieved state-ofthe-art performance various sequential classiﬁcation tasks. presently lstm-based classiﬁers standard baselines text classiﬁcation tasks. applied lstm’s create sentence embeddings machine translation. showed lstm-based embeddings used transfer learning across diverse tasks including semantic relatedness paraphrase extraction information retrieval. work used lstm’s encoding question answer sentences shown figure time word mapped embedding lstm time updating hidden state lstm. hidden state lstm last time step used embedding entire sentence. trained dual encoder model keras theano among hyperparameter combinations tried optimal error development obtained hyperparameters listed table used adam perform stochastic optimization network parameters. network total million parameters. idea system pool pre-constructed answer templates. ideal pool would contain common agent responses item delivery issues; appropriate answers pool system cannot recommend reasonable answer. hand pool size can’t large computational cost. pool randomly sampled agent answers cover almost common questions item delivery issues prediction time dual encoder network would score question-answer pairs input customer question. ﬁrst step randomly sampled agent answers historical item delivery-related chats generated embeddings using trained answer encoder analysis shows embeddings able capture semantic similarity beyond simple vocabulary overlap answer templates selected help k-means clustering. applied mini-batch k-means k-means++ initializations cluster answer embeddings clusters. form template cluster take text agent answer embedding closest cluster center. finally created pool answer templates human review. prediction time system pair customer question every pre-constructed answer template trained dual encoder network produce measure well answer matches question. system recommend top-k answers agents ranked probability. note answer embeddings full answer templates precomputed stored computational efﬁciency. siﬁcation task. based customer intent predicted model system present customer predetermined response. common example would prewritten dialogue combined state tracking used systems travel restaurant reservation applications however even something simple item delivery issues total number possible types customer questions close extending approach domains customer service would impractical. contrast approach beneﬁt needing annotated data. data needed train model customer questions agent answers them already exist historical chat transcripts. dual encoder produces sets embeddings customer questions another agent answers. table shows nearest neighbors selected questions embedding space. also present nearest neighbors selected answers. contrast nearest neighbors found tf-idf vectorization lstm embeddings seem capture semantic similarity since tf-idf essentially based search term overlap. example lstm embeddings various kinds responses customer greetings even search terms overlap much tf-idf ﬁnds ones share tokens common. compare dual encoder network tf-idf baseline answer ranking task. task paired randomly sampled customer questions correct answer randomly sampled incorrect answers. task correct answer simply agent response templatized. question answers ranked based probabilistic output dual encoder network. ranking compared produced tf-idf term weights. compare mean reciprocal rank precision algorithms table metrics dual encoder network signiﬁcantly outperforms tf-idf baseline. also present examples customer questions matching answers table tf-idf baseline perform well task because even vocabulary overlap contains signal retrieving answer given question many cases answer question overlap recruited rotating pool agents evaluate well system works end-to-end. randomly selected questions used system tf-idf baseline recommend answers agent asked questionanswer pairs assign relevance score answer relevant somewhat relevant irrelevant. evaluations done questions algorithms. note given question maybe appropriate answer. example answers like sorry can’t cancel order page relevant answers question cancel order since it’s late?. table shows sample model-based answers questions figure shows human evaluation relevance score distribution system tf-idf. general system shows high relevance recommendations compared tf-idf baseline modeltable nearest neighbors questions replies. second column based embeddings question encoder reply encoder. third column based search results retrieved corpus based tf-idf. another metric examined within three answers often least very relevant answer. among randomly sampled questions system able recommend least relevant answer among questions tf-idf baseline questions. average relevance score tf-idf model whereas average relevance score dual encoder baseline shown template-based approach dialogue response generation works well customer service domain. demonstrate even absence fully automated dialogue system nonetheless possible select highly relevant answers customer questions translate reduction time spent customer contact. though currently testing system online chats believe template-based approach would extend naturally speech-driven system telephone conversations. number future directions pursue make system complete. would like determine correct polarity given template based state customer’s orders. example customer inquiring shipment arrived reply either shipment expected on-time late internal shipment data. would also like rerank list suggested templates using customer context expand slots templates ﬁlled automatically internal systems. authors would like thank kevin small helpful discussions assistance reviewing drafts. would also like thank customer service associates helped evaluate system provided domain-speciﬁc feedback design. sculley web-scale k-means clustering arthur vassilvitskii k-means++ advantages careful seeding proceedings eighteenth annual acmsiam symposium discrete algorithms", "year": 2017}