{"title": "Humor in Collective Discourse: Unsupervised Funniness Detection in the  New Yorker Cartoon Caption Contest", "tag": ["cs.CL", "cs.AI", "cs.MM", "stat.ML"], "abstract": "The New Yorker publishes a weekly captionless cartoon. More than 5,000 readers submit captions for it. The editors select three of them and ask the readers to pick the funniest one. We describe an experiment that compares a dozen automatic methods for selecting the funniest caption. We show that negative sentiment, human-centeredness, and lexical centrality most strongly match the funniest captions, followed by positive sentiment. These results are useful for understanding humor and also in the design of more engaging conversational agents in text and multimodal (vision+text) systems. As part of this work, a large set of cartoons and captions is being made available to the community.", "text": "yorker publishes weekly captionless cartoon. readers submit captions editors select three readers pick funniest one. describe experiment compares dozen automatic methods selecting funniest caption. show negative sentiment human-centeredness lexical centrality strongly match funniest captions followed positive sentiment. results useful understanding humor also design engaging conversational agents text multimodal systems. part work large cartoons captions made available community. yorker cartoon caption contest running years. week editors post cartoon readers come funny caption pick submitted captions readers pick weekly winner. contest become cultural phenomenon generated discussion makes cartoon funny paper take computational approach studying contest gain insights diﬀerentiates funny captions rest. developed unsupervised methods ranking captions based features originality centrality sentiment concreteness grammaticality humancenteredness etc. used methods independently rank captions corpus selected captions method. then performed amazon mechanical turk experiments asked turkers judge selected captions funnier. early work mihalcea strapparava investigate whether classiﬁcation techniques distinguish humorous non-humorous text. training data consisted humorous one-liners nonhumorous one-liners derived reuters news titles proverbs mihalcea pullman took work further. looked four semantic classes relevant human-centeredness persons social groups social relationships personal pronouns. showed social relationships personal pronouns high prevalence humor. mihalcea pullman also looked sentiment; found humor tends strong negative orientation reyes used features well others build humor taxonomy. classiﬁed tweets type topic barberi focused classifying tweets irony education humour politics. zhang also looking tweets used manually crafted features based inﬂuential humor theories linguistic norms aﬀective dimensions. work diﬀers previous research several ways. first previous work focused automatically distinguishing humorous non-humorous text. case goal rank humorous texts perform binary classiﬁcation. second we’re aware work deals speciﬁcally cartoon captions although methods speciﬁc captions include features based objects depicted cartoons. cartoon captions tokenized using clearnlp three selected captions including winning caption frequent n-grams captions manually labeled objects visible cartoon tﬁdf scores captions antijokes sites devoted undeveloped dozen unsupervised methods ranking submissions given contest. controls three captions selected editors yorker well antijokes. methods broke ties randomly. methods used diﬀerent directions methods baselines split groups or=originality based ge=generic cu=content ny=original yorker contest co=control. similarity contest centroid highest/lowest lexrank largest/smallest cluster highest average tﬁdf presence freebase entities caption sentiment human-centeredness syntactically complex concrete unusually formatted text ﬁrst place oﬃcial second place oﬃcial third place oﬃcial antijokes built lexical network captions contest. used lexrank identify central caption contest highest lexrank score also used graph clustering method previously used king cluster captions contest thematically; sizes clusters comprise method tﬁdf scores used build lexical network used method theseus theseus tell back labyrinth soon happy hour theseus left theseus tell lost elsie seen bessie tell moooooved wife tell china shop kicked china shop merrill lynch tell quit went pamplona wife tell went pamplona wife tell minotaur friend wife tell home minotaur jeez minotaur drink around hear minotaur joke time merrill lynch tell back good ready wife working late merrill-lynch commercial tell left pamplona last need back china shop matador tell merrill lynch tell figure shows pairwise similarities captions minicorpus. seven clusters identiﬁed louvain method. solid lines represent high cosine similarity pair captions. captions mini-corpus shown figure seven clusters figure identiﬁed louvain method. solid lines represent high cosine similarity pair captions. computed syntactic complexity using concreteness authors paper labeled objects cartoons used evaluation. computed often objects referred caption. computed counting punctuation marks unusually formatted words caption. method least similar centroid highest lexrank smallest lexrank small cluster tﬁdf oﬃcial winner oﬃcial runner oﬃcial third place syntactically complex concrete well formatted freebase positive sentiment negative sentiment people antijoke table comparison methods. score corresponds pairs seven judges agreed signiﬁcantly score requires diﬀerence votes. score includes pairs best methods bold. used amazon mechanical turk compare outputs diﬀerent methods baselines. consisted cartoon well captions turkers determine captions funnier. given four options funnier funnier both funny neither funny. know method used produce caption pairs captions methods compared cartoon assessed turkers. report three evaluations table evaluation corresponds number votes favor given method minus number votes against. ﬁrst corresponds pairs which seven judges diﬀerence least votes favor caption. level signiﬁcant agreement happened cases diﬀerence least votes happened pairs third evaluation corresponds pairwise comparisons including ties. refers number times constraint score calculated averaging number votes favor minus number votes probability random process generate diﬀerence least votes compared dozen methods selecting funniest caption among submissions yorker caption contest. using side side funniness assessments found methods consistently select funnier captions negative sentiment human-centeredness lexical centrality. surprisingly knowing traditions yorker cartoons negative captions funnier positive captions. captions relate people consistently deemed funnier. ﬁrst methods consistent ﬁndings mihalcea pullman interestingly also showed captions reﬂect collective wisdom contest participants outperformed semantic outliers. next strongest features positive sentiment proper formatting. making corpus public research shared task funniness detection. corpus includes selected cartoons captions cartoon manual annotations entities cartoons automatically extracted topics contest funniness scores. paper used unsupervised methods funniness detection. next explore supervised ensemble methods. also explore recognition creative uses language well semantic features.", "year": 2015}