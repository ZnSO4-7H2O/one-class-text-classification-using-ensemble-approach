{"title": "Sequence-to-Sequence Models Can Directly Translate Foreign Speech", "tag": ["cs.CL", "cs.LG", "stat.ML"], "abstract": "We present a recurrent encoder-decoder deep neural network architecture that directly translates speech in one language into text in another. The model does not explicitly transcribe the speech into text in the source language, nor does it require supervision from the ground truth source language transcription during training. We apply a slightly modified sequence-to-sequence with attention architecture that has previously been used for speech recognition and show that it can be repurposed for this more complex task, illustrating the power of attention-based models. A single model trained end-to-end obtains state-of-the-art performance on the Fisher Callhome Spanish-English speech translation task, outperforming a cascade of independently trained sequence-to-sequence speech recognition and machine translation models by 1.8 BLEU points on the Fisher test set. In addition, we find that making use of the training data in both languages by multi-task training sequence-to-sequence speech translation and recognition models with a shared encoder network can improve performance by a further 1.4 BLEU points.", "text": "present recurrent encoder-decoder deep neural network architecture directly translates speech language text another. model explicitly transcribe speech text source language require supervision ground truth source language transcription training. apply slightly modiﬁed sequence-to-sequence attention architecture previously used speech recognition show repurposed complex task illustrating power attention-based models. single model trained end-to-end obtains state-of-the-art performance fisher callhome spanish-english speech translation task outperforming cascade independently trained sequence-to-sequence speech recognition machine translation models bleu points fisher test set. addition making training data languages multi-task training sequence-to-sequence speech translation recognition models shared encoder network improve performance bleu points. index terms speech translation sequence-to-sequence model sequence-to-sequence models recently introduced powerful method translation subsequently model adapted applied various tasks image captioning pose prediction syntactic parsing also state neural machine translation model also recently achieved promising results automatic speech recognition even without language models successes possible sequence-to-sequence models accurately model complicated probability distributions. makes possible apply model even situations precise analytical model difﬁcult intuit. paper show single sequence-to-sequence model powerful enough translate audio language directly text another language. using model similar listen attend spell process ﬁlterbank input features using recurrent encoder. encoder features used along attention model build conditional next-step prediction model text target domain. unlike however text translated domain target source language text used. conventionally task performed pipelining results system trained source language machine translation system trained translate text source language text target language. however motivate end-to-end approach several different angles. first virtue end-to-end model parameters jointly adjusted optimize results ﬁnal goal. training separate speech recognition translation models lead situation models perform well individually work well together error surfaces compose well. example typical errors system exacerbate errors translation model trained errors input training. another advantage end-to-end model that inference single model lower latency compared cascade independent models. additionally end-to-end models advantages resource settings since directly make corpora audio language transcript another. arise example videos captioned languages. also reduce labeling budgets since speech would need transcribed language. extreme cases source language writing system applying separate system would require ﬁrst standardizing writing system signiﬁcant undertaking make several interesting observations experiments conversational spanish english speech translation. models model performs surprisingly well without using independent language models either source target language. model performs well without seeing source language transcripts training leverage multi-task setting improve performance. finally show end-to-end model outperforms cascade independent seqseq models. early work speech translation translating audio language text another used lattices system inputs translation models giving translation model access speech recognition uncertainty. alternative approaches explicitly integrated acoustic translation models using stochastic ﬁnite-state transducer decode translated text directly using viterbi search paper compare integrated model results obtained cascaded models spanish english speech translation task approaches also lattices inputs. post used gmm-hmm system. kumar later showed using better model improved overall results. subsequently showed modeling features boundary system improve performance. carry notion much deﬁning end-to-end model entire task. recent work speech translation asr. instead used unsupervised model cluster repeated audio patterns used train words translation model. seqseq models used align speech translated text directly predict translations. work similar uses las-like model utilize sequence-to-sequence attention architecture similar described model composed three jointly trained neural networks recurrent encoder transforms sequence input feature frames x..t sequence hidden activations h..l optionally slower time scale full encoded input sequence h..l consumed decoder network emits sequence output tokens y..k next step prediction emitting output token step conditioned token emitted previous time step well entire encoded input sequence decoder’s dependence input mediated attention network summarizes entire input sequence ﬁxed dimensional context vector passed subsequent layers using skip connections. computed ﬁrst decoder layer output output step train seqseq models end-to-end speech translation baseline model speech recognition. found architecture variation works well tasks. channel ﬁlterbank features extracted windows size stacked delta delta-delta features. output softmax models predicts symbols described detail section includes english spanish lowercase letters. encoder composed total layers. input features organized tensor i.e. features deltas delta-deltas concatenated along ’depth’ dimension. passed stack convolutional layers relu activations consisting kernels shape depth time frequency. strided downsampling sequence time total factor decreasing computation performed following layers. batch normalization applied layer. downsampled feature sequence passed single bidirectional convolutional lstm layer using ﬁlter finally passed stack three bidirectional lstm layers size direction interleaved -dimensional linear projection followed batch normalization relu activation compute ﬁnal -dimensional encoder representation created concatenating dimensional embedding symbol emitted previous time step -dimensional attention context vector networks used compute contain single hidden layer units. passed stack four unidirectional lstm layers units. finally concatenation attention context lstm output passed softmax layer predicts probability emitting symbol output vocabulary. network contains parameters. implement tensorflow train using teacher forcing minibatches utterances. asynchronous stochastic gradient descent across replicas using adam optimizer initial learning rate decayed factor steps. weight decay used weight beginning step gaussian weight noise added lstm weights decoder embeddings. tuned hyperparameters maximize performance fisher/dev set. decode using beam search rank pruning hypotheses beam width using scoring function proposed utilize language models. baseline model found neither length normalization coverage penalty needed however helpful permit emitting end-of-sequence token log-probability greater next probable token. speech translation found using length normalization improved performance bleu points. also train baseline seqseq text machine translation model following reduce overﬁtting small training corpus signiﬁcantly reduce model size compared encoder network consists four encoder layers base architecture bottom layer bidirectional lstm remaining layers unidirectional. decoder network consists stacked lstm layers. encoder decoder lstm layers contain units. attention network uses single hidden layer units. character-level vocabulary input output speech model described emits. apply dropout probability during training reduce overﬁtting. train using single replica. training converges steps using minibatches sentence pairs. supervision source language transcripts incorporated speech translation model co-training auxiliary model shared parameters e.g. model using common encoder. equivalent multi-task conﬁguration models training protocols described modiﬁcations workers randomly select model optimize step introduce weight noise steps decay learning rate overall steps. figure example attention probabilities multi-task model decoders. attention roughly monotonic whereas translation attention contains example word reordering typical seqseq models attending primarily frames emitting living here. recognition decoder attends frames emitting corresponding spanish phrase vive aqui. decoder also conﬁdent translation attention tends smoothed across many input frames output token. consequence ambiguous mapping spanish sounds english translation. conduct experiments spanish fisher callhome corpora telephone conversations augmented english translations split training utterances according provided segment annotations preprocess spanish transcriptions english translations lowercasing removing punctuation. models common tokens represent spanish english characters containing lowercase letters alphabets digits space punctuation marks well special start-of- end-of-sequence unknown tokens. following train models hour fisher train tune hyperparameters fisher/dev. report speech recognition results word error rates translation results using bleu scores computed moses toolkit multi-bleu.pl script lowercase reference text removing punctuation. provided fisher reference translations single reference callhome. common seqseq models shallow decoder generally comprised recurrent layer contrast seqseq models often much deeper decoders e.g. layers analogy traditional system think seqseq encoder behaving acoustic model decoder acts language model. additional complexity translation task compared monolingual language modeling motivates higher capacity decoder network. therefore experiment varying depth stack lstm layers used decoder speech translation performance improves decoder depth increases four layers table despite intuition obtained similar improvements performance task increasing decoder depth suggesting tuning decoder architecture worth investigation speech settings. compare multi-task training strategies one-to-many encoder shared speech translation recognition tasks many-to-one decoder shared speech text translation tasks. found ﬁrst strategy perform better. also found performing updates finally vary much encoder network parameters shared across tasks. intuitively expect layers near input less sensitive ﬁnal classiﬁcation task always share encoder layers conv lstm vary amount sharing ﬁnal stack lstm layers. shown table found sharing layers encoder yields best performance. suggests encoder learns transform speech consistent interlingual subword unit representation respective decoders able assemble phrases either language. construct baseline cascade spanish seqseq model whose output passed spanish english model. seqseq model attains state-of-the-art performance fisher callhome datasets compared previously reported results hmm-gmm dnn-hmm systems shown table performance fisher task signiﬁcantly better callhome since contains formal speech consisting conversations strangers callhome conversations often family members. contrast model slightly underperforms compared previously reported results using phrase-based translation systems shown table amount training data fisher corpus much smaller typically used training systems. additionally models used characters training targets instead wordphrase-level tokens often used machine translation systems making vulnerable e.g. spelling errors. table compares performance different systems full speech translation task. despite access source language transcripts stage training end-to-end model outperforms baseline cascade passes best spanish output model bleu points fisher/test set. obtain additional improvement bleu points fisher datasets multi-task conﬁguration spanish transcripts used additional supervision sharing single encoder sub-network across independent decoders. model converged four days training multitask models continued improve ﬁnal bleu point improvement taking weeks. informal inspection cascade system outputs yields many examples compounding errors model makes insertion deletion signiﬁcantly alters meaning sentence model recover. illustrates advantage end-to-end approach translation decoder access full latent representation speech without ﬁrst collapsing n-best list hypotheses. large performance bleu points remains results table assume perfect indicating signiﬁcant room improvement acoustic modeling component speech translation task. present model directly translates speech text different language. striking characteristics architecture essentially attention-based neural system. direct speech-to-text translation happens computational footprint speech recognition end-to-end models number parameters utilize decoding algorithm narrow beam search. end-to-end trained model outperforms asr-mt cascade even though never explicitly searches transcriptions source language decoding. interpret proposed model’s encoder decoder networks respectively acoustic translation models explicit concept source transcription. sub-networks exchange information abstract highdimensional real valued vectors rather discrete transcription lattices traditional systems. fact reading transcriptions source language abstract representation requires separate decoder network. jointly training decoder networks multiple languages regularizes encoder improves overall speech translation performance. interesting extension would construct multilingual speech translation system following single decoder shared across multiple languages passing discrete input token network select desired output language. schuster chen norouzi macherey krikun macherey google’s neural machine translation system bridging human machine translation arxiv preprint arxiv. anastasopoulos chiang duong unsupervised probability model speech-to-translation alignment low-resource languages arxiv preprint arxiv. casacuberta federico vidal recent efforts spoken language translation ieee signal processing magazine vol. speech translation coupling recognition translaieee matusov kanthak integration speech recognition statistical machine translation. proceedings interspeech b´erard pietquin servan besacier listen translate proof concept end-to-end speech-to-text translation nips workshop end-to-end learning speech audio processing xingjian chen wang d.-y. yeung w.-k. wong w.-c. convolutional lstm network machine learning approach precipitation nowcasting advances neural information processing systems abadi barham chen chen davis dean devin ghemawat irving isard tensorﬂow system large-scale machine learning proceedings usenix symposium operating systems design implementation srivastava hinton krizhevsky sutskever salakhutdinov dropout simple prevent neural networks overﬁtting. journal machine learning research vol. papineni roukos ward w.-j. bleu method automatic evaluation machine translation proceedings annual meeting association computational linguistics. association computational linguistics johnson schuster krikun chen thorat vi´egas wattenberg corrado google’s multilingual neural machine translation system enabling zero-shot translation arxiv preprint arxiv. casacuberta vidal vilar barrachina garcıa-varea llorens martınez molau some approaches statistical ﬁnite-state speech-to-speech translation computer speech language vol. post kumar lopez karakos callison-burch khudanpur improved speech-to-text translation fisher callhome spanish–english speech translation corpus proceedings iwslt", "year": 2017}